<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Garbage-First Collector: Current and Future Adaptability and Ergonomics—Manual Tuning | Coder Coacher - Coaching Coders</title><meta content="Garbage-First Collector: Current and Future Adaptability and Ergonomics—Manual Tuning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Garbage-First Collector: Current and Future Adaptability and Ergonomics—Manual Tuning</b></h2><h5 class="post__date">2015-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vZGSY0gjhiY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is the garbage first collector the
current and future adaptability and
ergonomics so what you're going to see
in this session is you're going to get a
look under the hoods of g1 and so g1 is
the latest garbage collector from
hotspot guaranteed to solve all of your
GC problems so you're going to get a
deep dive into its adaptability and
ergonomics there hasn't been a lot of
information out there about this type of
thing so I think that you're gonna find
a lot of value in this especially as you
start to take a look at g1 and start to
do an evaluation of it there's also at
the end of this as a few slides and a
discussion about the future sort of
plans with adaptability and things that
are in store for g1 as we keep moving
forward so there's a couple of people up
here along with me I'm charlie hunt the
architect performance engineering at
salesforce.com I've got John cuts person
up here who is a GC engineer at Azul
largely responsible for g1 in the state
that is in today John has been doing
hotspot development work of some kind or
another for well over ten years if you
were at the session that Monica and I
did last year
you probably heard me talk about g1 and
its adolescence days had a little
problem with doing garbage collections
before Eden space was full a situation
or condition we promptly referred to as
premature evacuation it was through
John's wisdom and psychological
forensics that he was able to nurture g1
to a health and we no longer had those
types of situations or we have an
occasional lapse once in a while but it
was John's John's hard work and and
dedication that were able to address
those issues
Monica Beckwith up here largely
responsible for an enormous amount of
the performance testing that it was done
with g1 and continues to do that I
myself also involved in perform
testing Monica is the performance
architect at server G a a startup in
based on Austin correct
okay McKinney Texas based out of
McKinney Texas a low-power
type of solution for a JVM if I'm
correct okay so enough about us on 2g
one so the agenda here is we're going to
present some key concepts to understand
related to G one if you're relatively
new to G see the good news is you're
going to be on a level playing field
with most of the guys that are very
experienced with the other hotspot
collectors if you're very familiar with
the other hotspot collectors you kind of
throw all of that away and start over
well maybe not all of it but there's a
lot of new concepts related to this
garbage collector so we're going to give
you an idea of what that particular key
concept is the definition of it the
ergonomics and adaptability associated
with it and then we'll move on at the
tail end of talking about some future
adaptability and then we got a couple of
slides here if you want to dig a little
bit deeper into some additional
information and of course if you have
questions we'll be glad to entertain
those at the end so four key concepts
here we'll be talking about something
called remembered sets a marking
threshold and a concurrent cycle a
collection set and collections different
types of garbage collections a thing
called humongous allocations evacuation
failures my favorite subjects and
reference processing so I'm going to
turn this over to John and John's gonna
educate us on on remembered sets and
once John concludes in his section we'll
turn it over to to Monica and then I'll
come back again and so we'll do a little
bit of juggling back and forth here so
you won't get bored thank you thanks
charlie
Wow as a lot of people aren't there
so forgive me for BFM sound a little bit
nervous so Charlie said I was delta del
peru one spent four years under tony
apprentices developing it and getting
that going and as i said that sub is
definitely an experience i loved so
remember it sets what are they well so
remembered sets our g ones equivalent as
a card table
did people know what the card table is
okay so what what does it do it we g one
use these remembered sets to track
references effectively their incoming
pointer sets so each region is given
basically is allocated I remembered set
and the basically G one walks them
during GC to find the references that it
has to actually keep each region has its
own so that allows the GC worker sets to
actually walk them independently with no
interference from the other threats
which would what would happen we are
global card table and as I said it's so
you basically are only scanning the
references are actually associated that
with you know events but point into that
particular region and so as a result you
actually don't even need to scan the
entire card table looking for references
into the region we maintain ref
remembered sets for both Oh too young
references and all too old which is a
slightly different concept from the
other hot water collectors where they're
mostly maintained for ot young
references so here's a quick diagram it
gives you an idea of what it is just a
symbolic representation so region two
actually has two incoming references one
from region one and one from region two
three and region 3 and region one don't
have any so they remember sets are empty
as it fills a reference there so you can
actually read more information but the
article I
that link so how do we maintain revenue
remember it says well so the remembered
sets are actually implemented or
maintained using a post rate barrier so
what does that mean well after the java
application does a field rate we record
the card they can be containing the
field into each add local buffer when
that buffer gets filled it gets pushed
onto a global cure when the number of
buffers on the global queue goes above a
certain level the concurrent threads
start kicking in and they start pulling
these buffers offer this global queue
and the scan the cards contained they
update the remembered sets of the
referenced objects and its uses the rate
barrier is a very very cheap rate
barrier uses a very simple and cheap
operation to detect cross region
references it's effectively a shift in
an XOR and you know as unfortunately
they do get dense so we do have a
mechanism where we have as entries get a
date you know we sometimes go up
granularities and they get more and more
dense and I'll go into more detail about
the granularity is in the way of site
okay so is it talk to Burt we basically
fill up the buffer we we process the
buffers concurrently the threads which
do this are actually tiered what I mean
by this is that they're stet
so when we hit the number afresh when we
had a number the first thread kicks in
when we hear another threshold the next
thread the next thread gets kicked we
can over threshold the next care thread
gets cake gets kicked and when we have a
certain and so on until all the actual
concurrent refinement threads are
actually running and there are still
more mutation going on in the
application there's still a lot more
rates and even be the refinement threads
can't keep up G 1 tells them the
application threads go ahead update the
remembered set yourself that can be bad
you don't want to do that you read don't
want disorder and they
the application if we can okay so as I
say there's three levels of granularity
so we start off remembered sets are kind
of empty as we add references we hit the
sparse that's a very very small hash
table I think it can hold up to sixteen
distinct regions and from each region it
can hold up to like four distinct cards
no no I saved cards because the card
could contain many references so as a
result it basically becomes very easy to
scan that there's only a few cards which
we need to we need to fetch from the
remembered set in order to find those
references but as we start as we add
more and more entries suppose we get
more and more cards from our region then
we have to bump that up to the the fine
green table fine green table is an open
hash table and basically there's a
certain number that's a function of the
the heap region size and basically each
entry corresponds to a region and within
each entry there's a bitmap
corresponding to card indices so again
when we have a set bit and there it
basically means that we have a reference
in that card on that region pointing to
the owning region over remember exam
again fairly reasonably fastest can
usually not a problem within the GC
pauses however when we get to when we
have when the hash table and the fine
grain entries fills up we have to push
our regions and regions a bitmap into
the course level and that is one bit per
region so if you have a set bit there
that basically says there's a reference
from the other region pointing into me
so in order to find that reference we
potentially have to scan the entire
region again not a good thing we want to
try and avoid that every time okay so I
think that's it for gives a good idea of
remembered sets
so now we're going to go on to another
key concept of g1 which is it's
concurrent marking cycle and the
markings resh hold okay so g1 does
concurrent marking and g1 triggers as
concurrent marking using a threshold
which is based upon the occupancy of the
heap you can see the flag they're
initiating heap occupancy percent which
we have lovingly called I hope for short
and when you went basically g1 detects
that the occupancy goes above that level
it basically starts I think a concurrent
marking cycle a concurrent marking cycle
is made up of both stop the world and
concurrent phases so it actually gets
kicked off with an initial mark GC pause
so it sends a young GC event and
piggybacks the marking off of a young GC
event then kicks into the concurrent
mode of marking and basically what
that's doing is is basically walking the
object walking the the heap region by
region finding the live references and
at the end we have a stop and our stop
the world phase called remark pause
similar to CMS which effectively dreams
and empties and finished it completes
the marking so as I said some of us some
items are are concurrent summer stop the
world as we are marking each region we
also are keeping track of how much live
data we actually account we turn each
object and so at the end of marking we
know exactly how much is live within
each region and that allows us to order
the regions for the best collection
strategy the region's rest will order
based upon GC efficiency which is a
ratio of how long it would take to
collect and how much live data is with
them so the whole idea is we want to
collect its garbage first right so we
want to collect those regions which are
fairly high in garbage but are fairly
low overhead to collect sooner we want
to give as much memory back to the
application sir
at the end of marking if we detect
either any regions are completely free
of any life data they just get freed up
right away we you know just we don't
even just give it straight back to the
free list okay so I hope so here's a
quick diagram the Green Line shows you
the the actual I hope value I'm sorry
the blue dotted line shows you that I
hope value and what this slide basically
shows you is you know the effect of IHOP
and Ibaka and its dependency on heap
occupancy so all we've done is they'll
either is delay the start of the
marketing cycle and as you can see the
the heap occupancy is all but higher
before the marketing cycle kicks in
slowly comes me though and I'm building
underneath the blue line marking stops
goes up back down and one thing you'll
probably notice is the scales are not
just not the same but the actual marking
cycles themselves are slightly longer
when it comes to when you increase the I
hope it's it's just a slight legacy
because you got more stuff to mark
through okay and another tuning exercise
one piece of advice was actually given
to increase the IHOP and this I think
was given in the Institute article as
well it was a scenario which was
mentioned there and we basically were
seeing a lot and lot of mixed GCS so a
combination of old and young data and
playing around with the IHOP managed to
change the makeup of the GC pauses and
reduce the more expensive mix GCS and so
as a result the application was running
tickety-boo after that okay so if it's
this reiterates and makes GCS a bit more
expensive and so by increasing the IHOP
we changed the makeup of those pauses to
be mark we're doing much more young VCS
a lot more data to die and it's a City
the results fall for themselves and the
benchmark in the inferior article and
I'm going to hand over to Monica who's
going to talk about collection
sets and the actual collection mechanism
so first of all I'd like to thank John
John is my G 1 GC mentor and I'm so glad
he could make it today and share the
developmental details so thank you ok so
I'm gonna talk about collection set in
collections and let's get started
so what is a collection set it's
basically a set of regions that will be
collected during an evacuation pause so
for a young collection the collection
set will only have the young regions and
all of the young regions for mixed
collection you will have the young
regions and the old regions and the way
the old regions will be selected I'll
discuss that later so what happens why
is so what happens during a collection
all the live data in the collection set
is evacuated or copied as you may know
it during a GC cycle so now so this is a
very important option to print adaptive
size policy it kind of helps you look
into the ergonomics of what's actually
happening and and it this is basically a
GC log that has the print adaptive size
policy enabled so the highlighted
section here in blue it shows you how
the C set was constructed in brown you
can see that was a young young
evacuation pause and a C set consisted
of all the Eden regions as well as the
survivor regions and the predicted time
came up to 160 point seven two
milliseconds and then further down the
third the third para you can see that
the past time target was 200
milliseconds in this case so this is how
the collection set looks for mixed
collection so I already covered the
young regions so I've highlighted only
the the part where the old regions were
added to the collection set in this
particular case it it decided on 134
regions because the reclaim percentage
was under the threshold so
we have a threshold Jiwon has a
threshold of 10% that's the heat waste %
and I'll talk about that more but and so
in with with print adaptive size policy
you know exactly what was going on and
how these connection sets were happening
so I wanted to show you how a log of
that so let's talk a bit more about
collection set and here I'm showing
mixed collections and for one such
collection I'm just depicting how the
collections that would look so the dark
green shows old yet old regions and
they're also shown humongous regions
here and the light green shows young
regions so for a mixed collection all of
the young regions would be a part of the
collection set as shown by the tick mark
and a few of the old regions would be a
part of the collection set as shown by
the tick marks the only two regions I
think here and none of the humongous
regions will be a part of the collection
set and I'll talk more about the
humongous regions later but I just
wanted to highlight it here in this
diagram so copying happens all the live
objects get copied either to survivors
or some of them get promoted so one of
the read one of the survivor regions
apparently got promoted into to the old
generation and all of the survivors from
the young got into the new young-young
regions and a few of the a few of the
live data from the old regions got into
the old generation as well so after
reclamation happens you see all the
collections that the regions in the
collection set were compacted right and
it returned back to the free set the
feed list okay so see set Argan onyx and
adaptability so see set for young it
depends entirely on your past time
target and I'll talk more about this
later but basically what I'm saying here
is that based on your past time target
your young generation will be sized and
foresee set for the young collection it
has to have all your regions into
generation so it kind of directly clan
ties to your past time target the second
thing that I want everybody to know is
that the cset for mixed connection
depends on two things the first is mixed
GC count target and the second one is
old C set threshold percent so basically
a minimum number out of the calculations
out of these two is what it reminds the
see set so mix GC kind of gives you a
minimum that needs to be there and then
the max is set out of by the old C set
threshold percent and I'll talk about
that in the next slide so like I said
mix GC count target sets a minimum
number minimum limit on the old regions
that could be added to the collection
set and the goal for g1 is not to exceed
the count target the maximum limit is
said by the g1 old C set region
threshold percent and it kind of is the
upper limit and it's dependent on the
your total heap it's a percentage of
total heap the cset region threshold
percent defaults to 10 the mix GC count
target defaults to 8 so here's an
example there are three different lawns
I just copied snippets out of those the
first one tells you that the predicted
time was too high so g1 went with the
minimum number of old regions in this
case we're only 12 so that one is
basically your count target your count
target calculated that for each mix
cycle you can you'll add 12 regions and
and then g1 went with the minimum
because your project predicted time was
too high in the second one your old C
set region number reached minimum what
that means is again your counter gets
said that you need 140 to all regions to
be collected during the mix cycle and
that really is what was taken so your
prediction time was not too high so it
just went with the minimum the third one
says that your rec claimable percentage
was under the threshold so we like I
said we have a threshold
of 10% by default that's called the heap
waste percent and and we went under the
threshold so we're not gonna add any
more regions so even though the max
number we could have gone up to was 308
based on your old C set threshold
percent we only chose to have 134
regions in the collection set so again
talking more about mixed collections so
like I said young regions all young
regions are added into in a collection
into a collection and for all regions
the selection is made up based on two
things first something called
makes GC live threshold percent it
basically sets a limit per region of the
lot of the liveness so if the so I think
John mentioned that earlier something
called GC efficiency so we calculate per
region what's the liveness factor and
and if it's more if it's it's it's the
limit which is default is 65 if we think
that it's too expensive to collect if it
has more live data in it we will not
consider that region a candidate for
collection during any mix collection so
that's a cut off per region the second
one is g1 heatwaves percent and that's
when in the past two snippets you saw
reclaimer both percentage not over
threshold so that is what this
particular option sets so it's the
amount of heap you're willing to waste
so g1 will not collect 10% which is the
default off the heap because because
it's too expensive so you can change
this to on the command line but the
default is 10% okay talking a little bit
more about young collection so as I
mentioned it's based on the max GC pause
Milly's which is defaults to 200 but you
can definitely set it on the command
line I encourage to set it on the
command line always and the the young
generation size is a
there's a min and a max cap to it the
min is 5% of your Java heap and the max
is 60% of your Java heap so based on
your pause target Boston target the
young generation will be sized anywhere
from 5 percent to 60 percent so that's
the past target is a very important
option that everybody should use for
your application now there's something
also called prediction logic and
basically it determines how much time it
will take to collect a region so Jeevan
has kind of attracts historical data
such as you know our set sizes and and
surviving data etc and then it'll say
it's going to take X amount of time to
collect a region and then at every
collection it resizes the young
generation so you can see it in your log
if you do the print adaptive size policy
enabled you can see what the younger
generation size was at every collection
so let's move on to old regions so g1
does collects all regions three
different ways the first one we already
spoke about during a mixed collection
and I mentioned the criteria I mentioned
how the C sets are selected I mentioned
how the old regions are selected so
that's exactly what it is and you will
see if you have the print adaptive size
policy enabled you will see that it
decided to start with mix GCS because it
had candidate regions and it also knows
that the reclaimer will bytes were over
the threshold so it's gonna start a
mixed GC cycle the next one John
mentioned that in his during his talk
something called entirely free regions
so during the concurrent cycle during
cleanup you will see something like this
in your and you don't have to have
adaptive size policy enabled for this
well this is just your print GC details
output and you'll see something that
during cleanup we g1 picked up one gig
of free regions and so basically it was
13 gigs first and it dropped to 12 gigs
the size and and that was because it
found entirely free regions so it
doesn't have to wait till mix GC to pick
up that rate and those free regions it
will just pick it up and
to the free list and of course the final
one is during full collections where it
collects and compacts all regions and
that's an example how it will look it
the heap was about 1 0 1 8 Meg's and
after a full GC drop down to 369 Meg's
okay so let's talk about something very
interesting and I've seen lots of issues
with this particular problem and and and
I'll talk about what it is and first
actually so what are humongous objects
so for G one humongous objects or
anything that span objects that span 50%
or more of your region size so so
ideally we we want not that many
humongous objects and I'll tell you why
and also we hope that they are
long-lived so why is that humongous
objects are allocated directly into the
old generation and then we and then into
something we called humongous regions
and why do we do that
basically we're avoiding unnecessary
copying back and forth because when the
data is live we have to move it right
and that's the compaction part of it
copying by a compaction so imagine we
would do that for humongous objects and
it's basically an unnecessary so we
directly are allocated into the old
generation and we call them humongous
regions and large objects basically
objects that are larger than the region
size will need contiguous regions so
that's why we hope that they're not that
many humongous objects and we also hope
that there are long-lived because
they're taking space out of the old
generation alright pop quiz time so what
would G 1 do I have shown four objects
here the first one is less than 50% of
your g1 region the second one is equal
to 50% of the g1 region the third one is
greater than 50% of your g1 region and
then fourth one is greater than the
region itself so I've shown two things
again the same color dark green and
light green dark green is an old
generation region and the young gender
and the light green is young generation
so what would you want
you g1 will allocate the object number
one out of the young generation objects
two three and four will be allocated out
of own generations and they will be
called humongous regions and object 4
since its greater than the region size
itself will need contiguous regions so
here is how it will look
object 1 is not humongous and it'll be a
young young generation region and other
objects that are not humongous can be
allocated white after that so that heaps
that space is not wasted but for objects
2 3 &amp;amp; 4 the space shown in gray is
wasted space because that region is now
humongous region and and the fourth one
especially is a contiguous region and it
has that amount of wasted space in it so
why am I talking about humongous objects
so as of summer update for T initial
heap science your x ms determines the
region size and g1 strives to have 2048
regions and the regions can range from 1
Meg to 32 Meg's and the factor is to a
factor of 2 so if there's a vast
difference between your initial signs
and your maximum heap size normal
objects your normal objects could look
humongous to g1 and that's a problem
because remember we're hoping that not
too many objects are humongous we're
also hoping that they're long lived and
normal objects tend to be usually not
long-lived so I'm going to show you a
snippet here again for this one we had
the region sized that form X g1 decided
that the region should be 4 Meg's and
and I've highlighted things in blue
first one shows that it was a concurrent
cycle was requested second one shows the
allocation request was little over 4
Meg's and then third one shows that it
was a concurrent humongous allocation so
I've listed those things here the
concurrent cycle was requested because
the
occupancy remember the IHOP that John
mentioned so that I hop was higher than
threshold so that's why we requested a
concurrent cycle so even for humongous
region when you're when we're allocating
into out of all generation the same
principle applies second thing we noted
that the allocation was slightly over 4
Meg's and the gng ones region sizes 4
Meg's in this particular case and things
that I've not shown here and that were
evident from the log there were too many
humongous allocations concurrent cycles
could not keep up with those allocations
and it resulted in two space exhausted
messages and eventually full GCS so how
did we fix it so we found out of course
the to the print adaptive size policy we
knew that the region size the object
size was little over 4 Meg's
so based on the factor of 2 the next
size up would be 8 Meg's but but that's
likely it being slightly over 4 Meg's
it's greater than 50% of 8 Meg's so we
go to the next size up which is 16 Meg's
in this case so we set G 1 heap region
size equal to 16 Meg's on the command
line and those objects that were
humongous to g1 before were now normal
because of this change on the command
line okay let's talk about economics of
humongous allocation humongous
allocation remember I mean I showed that
the drawing of with regions and the
collection said during a mixed
collection I told that humongous regions
are not included in the mixed collection
and and that's something that people
need to keep in mind the only time we
collected humongous objects are during a
cleanup during the concurrently cleanup
odds right so and of course during full
G's is because we collect everything and
live objects live humongous objects are
compacted through during full of full GC
so some things about him on these
objects that you need to keep in mind
are those three points listed up there I
think that concludes my talk and I'm
gonna hand it off to Charlie and his
favorite topic thanks Monica if there
was one thing I wanted you to take away
from this presentation is the subject of
evacuation failures and how to avoid it
how to identify it what to do that's
going to be probably the most frequent
thing that I've observed in looking at
GC logs and this is the thing that you'd
want to strive to avoid so think of the
evacuation failures as full GCS and
other types of garbage collectors in
hotspots so this is a thing you want to
try to avoid so evacuation failures can
essentially evacuation failures indicate
that g1 is ran out of heap Regents that
ran out of available regions to evacuate
live objects - and this can happen in
two different scenarios one of them can
occur while you're copying objects to
survivor Regents are evacuating Eden and
survivors into a available survivor
region the other case that it can happen
is while you're promoting or copying
live objects into the old generation so
there's a little bit different than the
sort of notions of what you saw in like
with promotion failures with parallel GC
or with CMS GC so you could have this
evacuation failure type of issue going
on that's associated with young GCS or
with mix GCS prior to 7 update 40
evacuation failures showed up in the
logs as a two space overflow so you'd
see this text and the GC log line that
would say to space overflow that's a
little bit confusing and I've seen some
people confuse this with the notion of a
survivor space in the sense that there's
not enough space in a survivor space we
overflowed objects into old generation
as I as mentioned earlier that's not
always the case it's basically the case
that we just don't have an available
region that we can evacuate objects to
it doesn't necessarily apply to a
survivor region in southern update 40 we
decided to change the name of the to
space overflow to a to space exhausted
so the exhausted is saying we've
exhausted a to space to where we're
trying to evacuate objects to perhaps
this name will end up taking on a
different change again someday that
better reflects the sort of scenario
that we're out of available regions to
evacuate
six-two I'm sure there'll be some
discussion that'll go on on the hotspot
mailing lists about what we eventually
call this but I think there's potential
here for improvements for this
particular term so how do we avoid
evacuation failures so if you see these
in the logs the first thing you should
do is grab a baseline was setting the
initial and Max Java heap size and a
pause time target g1 is all about
adaptability and ergonomics unlike CMS
for instance were you do it and you're
expected to do an enormous amount and
potentially an enormous amount of
fine-tuning throw that away when you
start looking at g1 start with an
initial and a max Java heap size and set
a pause time target then start little
off and looking for a to space exhausted
start looking for those exotic
evacuation failures then start taking a
look at if you're seeing these
evacuation failures an able print
adaptive size policy and if you see too
many humongous allocations if you start
seeing this thing that Monica just
described with humongous allocations
increase the g1 heap region size another
thing that you should do to have a
question
yes and I would highly recommend for
when you're using g1 to set the initial
and max-heap sizes to the same there are
some clearly there's going to be some
cases where maybe you would want to set
them differently but I as a general
recommendation I always suggest to
people to set the initial and max Java
heap size is the same so another thing
that I recommend people to do is to take
the instrumentation from your GC logs
and plot the heap sizes and the heap
occupancies from the logs and what
you're looking for here is where's that
marking threshold being initiated and
are you able to keep up at the pace of
collecting objects through the
concurrent cycle and the mix GCS at the
rate at which you're promoting a sort of
an area that I call losing the race are
you losing the race with the concurrent
marking cycle and the mixed collections
with the promotion's of objects being
promoted from young generation in the
old generation so in other words is your
marking threshold too high you can also
take a look at this and say is the
marking threshold too low so you saw in
a couple of graphs earlier in the
presentation where John was showing a
difference in where we were setting the
marking threshold so the thing that you
look at here is how much am i reclaiming
on a given concurrent marking cycle and
a mix GC cycle am i getting much return
in the investment in my cpu cycles that
I'm spending there so that would be
another thing that you can see as you
plot these heap occupancies and keep
sizes another thing you can take a look
at is my concurrent cycles taking too
long in other words does it look like
it's taking a long time from the time
that marking has been initiated until I
see the ending of the concurrent cycle
and if that looks to be a long time you
can increase the count of the concurrent
GC threads another area to take a look
at is sometimes the survivor spaces get
exhausted and there's a command-line
option called g1 reserved % it's a false
ceiling it defaults to 10
so 10% of the Java heap can be set aside
as survivor space there's a fall a a cap
here of 50% so if you think about this
it'd be highly unlikely that you'd have
an application where you'd utilize 50%
of the Java heat for survivors basis
probably not too likely on the reference
processing reference processing is
probably the second most common issue
that I see with g1 because I think a lot
of people are starting to leverage
reference objects in some way or another
reference objects is not a real popular
subject with me it does create a lot of
additional overhead shouldn't say a lot
of additional overhead it creates
additional overhead for GCS because they
have to be treated specially because
they have implications on object
lifetimes so they have to be handled a
little bit specially so this is probably
the second most common sort of issue
that I see with what you want and it's
not only disc g1 I see with other
garbage collectors too so what we have
here is a a chart or we've taken the GC
pauses and we've taken the time that's
reported for CPU time so this would be
the last line of the GC log with print
DC details and we're taking the user CPU
time the system CPU time the real time
and then we're drawing a line here that
gives us the scaling factor
so what's circled here in light green is
the remark pauses and the other pauses
are listed here also for g1 and we see a
rather sharp drop in our scaling factor
at these remark pauses so clearly
there's something going on here and
those remark pauses that appears to be
single threaded if we go look at the GC
log what we end up finding on a GC
remark is we're seeing that reference
processing here is taking a vast
majority of the time in our GC pause and
we also see in the detail lines in our
other parts of our g1 print GC details a
lot of time spent in reference
processing so this is not a good
situation
the way that we rectify this is we
enable parallel reference processing and
this is enabled with the command line
off in parallel ref proc enabled so
again we take the same data and we plot
that and you can see that we've got a
much better scaling factor here so we're
paralyzing multi-threading the reference
processing so we look at the GC log line
and we see something here that looks
much much better on to our final topic
of future adaptability I'm going to turn
this back over to Monica and Monica was
largely the driver of brainstorming with
John on the future adaptability and the
sorts of insights and the things that
are kind of in the pipeline as g1
continues to evolve and mature Thank You
charlie so John mentioned about marking
threshold and he did mention that it was
it was a fixed value 45% so one of the
things that I see in all the logs that I
have looked at and it's really a common
pattern that I see it's those are
evacuation failures caused by not having
an ideal adaptive more ideally adaptive
marking threshold so I get these logs
and look at it and I said okay you're
marking threshold is it too high too low
yadda yadda yadda so what would be nice
and this is in CMS already people who
have you CMS would know that this to be
true CMS already has adaptive marking
threshold and it does have a kind of
like a static override so you could go
ahead and say I'd like a value of X if
you didn't want to go with the adaptive
threshold you would say I want to go
with the value of X only for the first
concurrent cycle and then go on and do
make it make it adaptive as you would
like or you could say that I want to
have static value of X throughout my
concurrent cycles also another thing
that CMS has is a static max value so it
has a cut-off
it's like I'm not gonna check you know
when I'm adapting my mark
threshold I'm not gonna go beyond this
value I think it's 65% or something I'm
not sure of that value so wouldn't it be
nice to have something similar for g1
and why why not just why'd you stop at
the adaptiveness of the threshold you
could also make the cutoff adaptive as
well so basically we already have that
kind of information within g1 we have
the promotion great information how much
are we promoting we have the live data
set information basically how much free
space we have right after the after the
concurrent marking we would know how
much free space we have we also know how
much time do we take during a concurrent
collection so we could have we could
easily make it adaptive and then we
could for the adaptive cutoff all we
would need to know is again the number
of free regions we have basically your
live data set
the second future adaptability for g1 is
something that I covered earlier about T
mungus objects so what if he had an
adaptive region size now this I know it
we haven't really discussed and I would
like John to help me here as well
because there are certain things you
know we spoke about how about indeed you
know having a full collection and then
changing the region size based on that
and I'd you know this is up for
discussion and John and I discussed it
yesterday a bit so John do you wanna
talk about you have to come here I guess
so Charlie actually mooted this idea I
think it Java one college I have one
conference I think Oh two years ago
perhaps even three years ago so yeah
they don't say that so this would be a
nice thing to have but there is some
caveats the first one is right away is
now you would need to load up the region
size the current weed barrier fixed
region size it's a shift and an XOR to
detect cross region reference know
you're adding a load to that and that
Lord is probably gonna cache miss cache
miss and and as a result that's going to
add some
overhead the next thing is now you have
to also remap your entire heap to
potentially different region sizes no
you could turn around and say okay at
the end of a few GC compact as much as
you can and say let's say the region
size now is going to be X so before the
fill GC region size was was y never
changing it to X again not necessarily
difficult but as I said the would move
there would be some caveats and you know
it would be nice to avoid the the
humongous objects size issue and this is
why the assumption has always been that
they are few and far between and so
versus you know you should you need to
actually know your application I'm not
going to say when or if any of these
things come that's for Oracle to decide
but that would be the overhead
associated with the adaptive region size
it might help it could also be a
user-specified thing you know perhaps
monitoring your application through a
visual VM which you've entered and say
oh we're starting to see Laura I need
perhaps start to see larger allocations
and you turn around say okay let's let's
watch change the region size and that
could be a user generated flag Kirk
so let me repeat Kurt's questions or
Kirk just basically said why is the why
is a humongous threshold 50% of the
region why don't you use the entire
region well the answer is correct we do
use the entire region but 50% is the
minimum size of a humongous object so if
you have one which is 60% you're still
going to use the downside of using the
old ICU isn't know those implicit
assumptions within g1 code that
basically does one-to-one correspondence
the our sets would become incredibly
complicated because know you're tracking
a bunch of objects and also the fill GC
code and some of the other code that
basically doesn't you know and doesn't
even look at humongous objects of if it
doesn't need to so one of the things you
would be potentially doing is you would
have to effectively scan the are sets of
humongous objects and humongous objects
sometimes can be very very popular and
we you know as I said it's just always
been an assumption that they're there
they're not very they're not very many
of them and they're not and they're
always fairly long lived you know as I
said it's it was at the same decision
when g1 was was was first was first
developed and I don't think anybody's
revisited a sensor ok so another thing
that I see very often that leads to
evacuation failures is something that's
listed here it's is the you know the the
range of nursery it had the maximum is
60% the minimum is the is 5% of your
Java heap so what happens if it if the
person if the end user doesn't use the
max GC pause Millie's in fact we're
going to have a lab tomorrow and I'm
going to demo that so if somebody goes
with the default of 200 milliseconds and
because of the default and the way their
application is for you know to use of
all the 200 milliseconds which do you
want things it can do
it will be mainly increase the nursery
up to 60% of your Java heat but your
live data is is more than you know so it
spans more than 50% say of your of your
heap so now your old generation is not
sized enough to accommodate all the live
data and then you have an evacuation
failures so one other idea that I had
was to make the nursery adaptive so
based on your live data you will cap
your nursery size and basically what the
translate is that only expand your
nursery if you have free spaces you know
if you have freed regions so that's
listed in that bug over there
reducing the cost of your kitchen
failures I think John want to talk about
that again so we have these bugs you
know you can go and click on them and
look at the bugs later okay just say a
few words were reducing the cost of
evacuation folios as Charlie mentioned
the code that handles survive evacuation
failures is is actually inherently
serial it's very serial some of these
bugs which are listed on this on this
light talk about paralyzing parts of it
so there's self forwarding of objects
the restoration of the headers walking
through you know because important part
of the reason is if we get an evacuation
failure we have some objects copied and
some objects not you know and we also we
have to update the remembered sets and
update references to to the objects that
were copied so currently that is you
know serial there are but there are bugs
associated in and the Oracle bug
database to paralyze that and it is a
work in progress okay so I'll take so
improving our sets again the there's a
couple of things that were on the cards
here number one was you know that the
format it's it's extremely large it
takes up a lot of space there has been
some work done to reduce that space and
try and get them if you just if the the
the footprint overhead and then the
other thing is we've seen in a few logs
is just the are say up to 18 times
during the actual GC stopped or OTC
itself is quite high no there is a flag
we turn and say that that basically
tries to set these flags are set the
thresholds for refinement to make to
allow you up to 10% of the stop twirl
pause to actually complete the are set
up dating but occasionally especially
for mix GCS we've seen times where we
will rate passed up and and that implies
to me that the refinement thresholds are
not being set correctly and so there's
some you know the ideas are based upon
you know to revisit these a calculation
of these thresholds based upon GC type I
to be honest with you I think we start
to we start too late and I think we need
to reduce those numbers I've looked at
the calculation it looks fine but I know
from the logs just or something wrong
with that next thing was smarter and
adept adaptable criteria for selecting
regions in the collection set well
summary things are is as we get you know
the regions are definitely sorted left
to right on GC GC efficiency is that the
rate is at the rate sorting order
perhaps if you're running out of space
perhaps we want to screw efficiency and
start try to reclaim as much space as we
can we want to slip the postern goal
somewhere because we need that space we
don't want a full GC remember avoiding
the fill GC is is really what we want to
do at all costs mm-hm
smarter and adaptable makes collections
so it feeds into that because basically
if we were smarter a bit select in which
regions we can collect you know Candida
then we can select you know we can do a
better job of selecting them during an
individual GC perhaps we want to Amara
tine so if we're prepared to handle a
more
level rather than spiky gcj recent
duration time
perhaps we could pair an expensive
region with an inexpensive region that
kind of thing again there's a couple bug
reports associated with that she said
and the mixed collections well when I
was talking about them if you remember I
mentioned about four different options
right and they all had this fixed
default so if you do see problems with
those what do you have to do you have to
go back and set those things to a
different valley on the command line now
why do we have to do that why shouldn't
it be adaptive right you shouldn't have
to go and do that the application has
enough in from I mean the g1 GC has
enough information that it should make
it adapt it by itself right so that one
of the ideas John and I discussed and we
have it in the bug report I think and
that's basically just an example with
respect to count target the mix GC can't
count target so why doesn't g1 do you
know kind of increase it by itself to a
cap or decrease it if the cap is too is
not getting enough regions per
collection right so it should be
adaptable and that's something that we
have discussed over there in that bug
report okay if you want more information
there are some articles online on the
web there's a link to our Charlie and my
previous talk last year's talk there's
also a Q Khan talk that Charlie and I
did it's not up there but you can search
for it and some articles about g1 in
general talking about the internals and
stuff like that all right we have about
four minutes for questions so if you
have them please shoot before we start
with questions if if this felt like a
freight train coming at you a little bit
of help on the way on Wednesday
afternoon the three of us are also doing
a session where we'll go through two
different examples where we're doing an
evaluation of g1 and in one case we're
starting from parallel GC and migrating
to two g1 and in the other case we're
by grating from CMS GC to g1 so you get
a sense of okay so how do we go about
evaluating g1 and then what did we find
what approach did we use what was our
steps in our methodology so you'll get a
sense of what our approach is and what
our methodology is and what we found as
we went through these two particular
examples so that may help you connect
some of the dots with some of the things
that you saw here
okay so questions
so the question is around the where we
set the the marking threshold IHOP where
we want that to be initiated and if it's
higher than or I should say if the heap
occupancy of live data size if you will
is higher than that and the answer to
that question is I think it kind of
depends on your performance goals and
I'd say performance goals in the sense
of capacity are you willing to sacrifice
the CPU cycles that is going to take to
continually execute those concurrent
cycles so if your heap occupancy is
higher than the threshold once the
marking is completed and the mix GC
cycles is done you're going to start
another marking cycle right away in some
scenarios and some applications and its
performance goals that may be totally
fine that may be what you want to
accomplish in other cases maybe you need
those or want those additional CPU
cycles to be available for capacity
reasons generally what I see in the
financial services types of applications
you're willing to trade off CPU cycles
for throughput and low latency so
whether you burn additional CPU cycles
you're not worried about the capacity so
it takes a backseat to the throughput
and latency goal but you tend to see as
you move towards an enterprise app you
tend to say well I want a certain amount
of additional capacity to take on
additional load think about an
enterprise app with a you know it's got
a database back and it's got a middle
middle tier and it's hosting some kind
of a website you probably want some
additional capacity from a CPU
standpoint to take on additional load so
there you may say well maybe I don't
want to have that situation where I'm
starting that marking cycle where it's
running continuously or I'm setting it
above the epoch or below the live data
size so it's really a question of what
your performance goals are that's my
take on it unless you guys have an
alternative take on it that's kind of my
position
yeah I tend to agree with that and you
also have to watch your your allocation
and promotion rate because you want to
make sure that that GC cycle finishes so
if you up your your your I hope to
accommodate your life data set because
of CPU capacity then you stole me end up
losing out there because you may have to
give it more concurrent marking threads
in order to finish the marking cycle in
a timely fashion so the question is
around parallel reference processing and
basically the question is are there any
sort of drawbacks to having parallel
reference processing enabled by default
I may be wrong in this historically but
I seem to remember this goes back to the
days of when Sun Microsystems was still
around this was being looked at and
evaluated and I've seen to remember that
there was one workload that we were
executing this time that we saw some
kind of degradation on you may have some
knowledge additional knowledge on why
parallel reference processing is not
enabled by default so I've done some
testing and this was with this was with
a CRM application and what what what I
ended up seeing was then when so there's
a there's a cut-off basically if you
don't have too many references and and
this application did have only about one
or two types of them and the remainder
there were not that many so what happens
is when you turn it on there's an
overhead to it so if you don't have
enough number of those even for that you
know having the parallel reference
enabled will still have that overhead so
I I score this with and without so ones
that had lots of references that those
profited from it but the ones that did
not have that many references to it they
did not profit and and John Massa needs
to actually
like okay you know he he's got more
experience with it and he's done some
more experiments and and that's the
reason why we all right there he's right
there and and and that's the reason why
we did not keep it on as a default so
there's the reason we mention it here
this is the reason I mention it here is
because we see these things come up
every so often it doesn't mean that we
have seen this for all applications it's
that if you do a lot of reference
processing in your application you need
to know about this option it doesn't
apply to all applications that's sorry
that's so what Kirk is saying is you
know what that you know what the queue
depth is I'm sorry Jon I'll let you jump
in in a second so the with the thing I
was going to say is if you know what the
queue depth is and you say okay if I
reach some threshold and the queue depth
of the reference queue why not fire up
additional threads so that to me it
comes back to the same question it
depends on the application domain that
you're in and what your performance
goals are maybe you're not willing to
sacrifice those additionally you're
willing to sacrifice and trade-off a
little bit longer pause for this
additional CPU cycles you might make
available
not all customers are willing to do that
that that I completely agree Kirk I
won't decide I don't disagree with that
I'm just pointing out for capacity
reasons some people are not willing to
burn all CPUs there are some people are
very sensitive to using increased CPU
cycles
so yeah I mean I think those ways you
could could achieve the goal I mean
number so number one if you do you can
do back-to-back marketing cycles by
setting the I hope to be zero or even
just like one one percent the other
thing you could probably do is to set a
very very very aggressive post time goal
so that's basically gonna you you may
end up promoting because you're gonna
end up causing a very very small young
generation and if you drop that the the
minimum boned
but Monica listed which was 5% again
dropped that only 1% then again you're
effectively turning g1 into single
generational mode close enough and so
then you'll pretty much be doing
back-to-back GCS okay okay so if you
have additional questions there's a JV
on performance buff later this evening
there's also a GC buff John do you know
what time the GC buff is so there's 715
there's a GC buff so feel free to bring
your additional questions to either one
of those Bob's there'll be plenty of
experts yeah so it's up here on the
slide so I encourage you to bring those
additional questions you know I'm sure
you'll get plenty of answers thanks
everyone for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>