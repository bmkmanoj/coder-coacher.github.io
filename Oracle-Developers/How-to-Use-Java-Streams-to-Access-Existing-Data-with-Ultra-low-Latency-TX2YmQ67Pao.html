<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Use Java Streams to Access Existing Data with Ultra low Latency | Coder Coacher - Coaching Coders</title><meta content="How to Use Java Streams to Access Existing Data with Ultra low Latency - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>How to Use Java Streams to Access Existing Data with Ultra low Latency</b></h2><h5 class="post__date">2018-04-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TX2YmQ67Pao" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay hi how are you doing today today we
are going to talk about the need for
speed but before that I will show the
opposite of speed do you know what that
is
have you seen it before maybe added it
into your code it's always as
frustrating even though if this is red
or blue or anything it's always
frustrating to have this progress form
because do you know what the brain how
the brain acts when they get get delays
if something is ten seconds then hundred
percent of people are tired they
actually leave the room or start
thinking of something else
three of the seconds you become
frustrated even at three seconds more
than half or the people leave the site
one second you can experience the delay
but it's it's acceptable and actually
hundred milliseconds that is when your
brain think that its direct response but
don't take my word for it I will make a
test and experiment on you so please
don't leave you will feel how long is
ten seconds and I will be completely
silent I start now
what did you think that's pretty and
seconds is long it's really long and now
let's try three seconds I start now it's
a little bit better but still long and
now one second I I was actually
surprised the first time I saw that one
second is also long did you did you see
it's acceptable now 100 milliseconds
that was immediate
wasn't it so when we develop
applications we need to get below 1
seconds
100 milliseconds if it's the best but
stick to the right of this line and
actually it's not only your brain that
make its a problem it also will give
your company less pageviews Google said
that they lost 20 percent of the traffic
with only half a second delay and my son
said that they lost 1 percent of sales
for every 100 milliseconds delay and
people starts to worry if you are doing
a pain transaction it takes too long you
will start to think that this company is
not reliable and you will tell your
friends that this company is not good
enough because you feel frustrated so
it's actually not only a it's also about
a problem about money to the company
what we have talked about now is the web
delay problem it's what your you can
experience as a human being but if you
start to take other application like IOT
e aí
micro services logistics then tech
science it's much more complicated it's
a lot of dependencies and thousands of
calculations that's need to be done and
then you make the problem much bigger so
if we go back to the hundred
milliseconds and we divide this in a lot
of different steps we come down to that
each steps needs to be done in nano
second
so that this is the latency requirement
and this is how you feels when we get
this challenge
it's it's not easy but we are here today
to explain the Speedman solution to the
problem speed went is three things we
developed it because we wanted to do
something that could give you
ultra low latency at the same time as we
wanted to stick to a Java make it really
easy to develop and the third thing was
that we wanted to stick to our existing
database we didn't want to migrate to
another platform so let's start with the
ultra-low latency to you thank you so
much yeah when I talk about ultra-low
latency I mean we are in the nanoseconds
so maybe perhaps we are able to retrieve
a stream and execute it in 200
nanoseconds or maybe 300 nanoseconds and
I'm going to tell you how how short that
period of time release but there are
many solutions to do this so I'm going
to talk about some strategies that had
been applied in the history before and
explain why they don't work so let's
start with clusters of nodes so let's
say we have one node where la in San
Francisco and another one perhaps in New
York or in Boston here and just the
sheer distance imposes latency due to
the physics of laws of physics the speed
of light so the speed of light is kind
of 15 milliseconds but then we are in
fiber so it's 2/3 slower and then it's
back again it's 45 milliseconds and we
were talking about 200 nanoseconds so
this is orders of magnitude off the
short it's it's too slow but maybe if we
took the other extreme and just had to
Linux servers glued together with with
the
duct tape around and we connect them
with a cable like this directly we no
switches or anything then we can come
down with some tweaks to maybe 40
microseconds and if we do busy polling
and the CPU affinity we can come down to
maybe 30 and if we're really an expert
maybe 25 but this is still you know
hundred times slower remember what you
need a round-trip delay so it doesn't
work and even though apart from that we
have to add delay from rotor switches
and if you are running in the cloud then
usually there was networks of a virtual
or software network so there are even
slower so that doesn't work either so
let's check another solution maybe we
can have our data in another process but
that doesn't work either because even
the inter process company communication
is in the milliseconds and when if you
do a context switch in your machine you
will kind of ruin your caches in your
CPU and your TLB so that will make your
application slower and everything slower
so this is and they were order of one
magnitude to slow so let's assume that
we have everything as object into memory
into the actual grm itself well then if
we have much data we will be subject to
garbage collect and if you have more
than maybe 20 gigs or so your latency
will easily exceed one second because if
you do garbage collect then it will
exceed one second easily if you mutate
your your heap and of course by
definition a garbage collect but totally
ruin your L l one two and three caches
they will be completely reset because
the j1 will iterate over your entire
memory set so this is like 1 million
times 2 is low so let's talk about
actual physical times just to read a
64-bit memory is 100 nanoseconds and our
objective is to complete a stream in 200
nanoseconds so then we understand that
we have to be really careful let's go
back to this cable again I think this
cable is about
well I I'm about two meters so it's
about three meters and if you take the
speed of light this means that this is
maybe ten nanoseconds here ten
nanoseconds out of 200 seconds just the
speed of light this is five percent of
the time we have so you understand that
it's it's not easy to do okay but of
course we have caches in the CPU so an
l3 is to 20 nanoseconds l2 is seven and
l1 is maybe half a nanosecond and the
CPU registers themselves is by
definition zero so we need to work with
that kind of model instead of working
with other solutions so let's take over
what overall look at micro service
architecture example so in this example
we have some controlling entities at the
top and then they have the actual work
being done with the green guys at the
bottom and they split some kind of
strategy so they they use a subset of
the data each and every one and they
communicate with the high-speed bus and
then there is external communication so
in order to understand how we shall
deploy this in an efficient way we need
to understand how the CPU actually works
so this is an Intel CPU and it has four
course and the course you can see in the
outer portion at the top and the bottom
is the actual logic and the further into
the middle you come you see the caches
and in the middle the biggest area of
everything is the l3 caches
and they are all shared between the CPUs
whereas the l2 and l1 is typically not
shared and assigned to a particular CPU
instance core so one or two like this if
we have our multi service micro service
architecture doctor instances for
example pin down to this particular CPU
and we can view the l3 as a as a bus
basically then we can do things very
efficiently
and also if you want to do things
efficiently in a CPU you need to
understand that there is a higher layer
if you have several CPUs physical CPU
chips on your on your server they are
actually connected with the high-speed
bus creating another layer of hierarchy
so this is called a Numa radium's
so we need to understand how this works
- in order to build a performance system
okay so the conclusion is we have to
invite this guy here on to the silicon -
really again this kind of speed so just
to illustrate this let's talk about the
l1 CPU cache it takes half and on a
second and that corresponds to 4 inches
for the speed of light and if you
compare that to your database query that
takes one second now arguably it can
take much less than 1 second but it
could also take a lot of of more time
than 1 second so how far will them light
move in one second and one you're
thinking about astronomy for example our
4 is one light second that is correct
but I want to use an analogy so I use
the distance to the moon it's about one
second not really but almost so the
conclusion here is don't place your data
honorable keep it in a JVM and I was
supposed to laugh because this was fun
ok so talk about ease of development we
are using standard Java streams when we
are querying for example a database or
in memory so we haven't came up with an
own API we stick to the one that already
exists for good reasons so I wrote an
article about this in Java magazine I I
just had a back-to-back talk in the room
next door and I told the audience there
there's why we can use streams instead
of sequel queries and we can also use
stream streams as querying in our in
memory database structure and of course
sequel is very similar to streams there
are a remarkable resemblance between
them so
countess count limitlessly meant and so
on and group buyers collect grouping by
for example so it's easy to think when
you think sequel you can very easily
understand streams and vice versa so
let's take a look at this I'll in my
previous presentation I also talked
about declarative constructs so the
first query there says that we want to
retrieve all films with a rating equal
to pg-13 and that is decorative because
it doesn't say how the database you do
it it's free to do its own way it can
iterate over all the fields or you can
use an index or you can use some other
kind of means which is built-in in that
particular database the same is true for
streams the first row retrieves a stream
that when consumed will contain all the
fields but after the second line another
stream is created that is only
containing those streams fulfilling that
particular predicate and the stream
might evaluate all entities but it might
also do some other things for example
using an ending memory index so this is
a picture showing their previous way of
doing things with the going to mix
sequel and in Java and that creates of
course a lot of product problems because
they are inherited different whereas in
the right-hand stream we use just Java
and express things with streams and
functional programming which of course
gives a better flow so and the things
that it's Java stream actually makes
execution even faster than just being a
stream itself so let's dive into one
example in this example we have
streaming overall films and filtering
out all the fields that has a rating or
pg-13 then we collect them using a JSON
collector and the cool thing with this
stream it's that even we even though
we're reasoning about films and we are
seeing obviously we are using film
objects when we express through streams
the films object never exists
and that is little bit tricky to to wrap
your hand around but this is only a way
a notation to reason about stream or
films but that don't have to exist and I
will explain how because the first
filter says that we can use an in memory
index the table shows all the indexes we
have by default speed mental index on
all columns and it's a very lightweight
indexing mechanism so it's not that
expensive so we will use the index for
the rating and we can immediately
retrieve those films that satisfy that
predicate in this case we have them at
address 0 and 523 so we can go that
directly and the collector dictates that
it will only retrieve certain columns so
we don't have to materialize the stream
we only have to look at that particular
columns so we never have to materialize
a film and that is this is important if
you have hundred columns even 300
columns in the table because then it's
very costly to materialize each and
every so we haven't actually really
materialized anything except for the
columns we needed and we haven't created
an intermediate objects because this
collector here also works off heap so it
will collect all the json representation
of heap and will not create a single
intermediate object meaning that is very
efficient and it doesn't pollute your or
mutate your heat so it's fast and it's
deterministic so and also spirit is
written very carefully so we can make
use of escape analysis and allocation of
objects on the heap have you heard about
the escape analysis anyone here ok this
is kind of a very hidden feature in Java
under certain conditions
Java is able to optimize away object
creation and create them on the stack if
the object doesn't escape the method you
are handling them within so that's
crucial for stream performance they
introspect their own pipeline so before
since thought they look at their own
pipeline and trying to rearrange
breakout use indexes and reorder things
to to get it more efficiently before the
actual stream starts and we have our
feed storage and indexing and collectors
and aggregate they don't create
intermediate objects and also the
snapshots in memory are immutable so
there's a first snapshot and then after
while there is a second snapshot but
they are never mutated and that also
allows very low latency because you if
you want to have neutrality then you
have to be able to handle a mutual
exclusion and that is slow so I'm going
to show you a speed demo and just in my
last talk I had this circular database
which is a film database so I'm going to
show you some examples here let me show
can you see this okay so first of all I
go to start because it takes a while for
this to execute so let me first say that
I don't want to use acceleration
not to start okay now it started it so
I'm going to do jmh benchmark jmh is a
benchmarking tool that's built into the
recent versions of Java and what I'm
showing here on the screen are two
streams one is very simple or relatively
simple and other one is more complex now
the simple stream creates a stream that
will only contain those elements that
has a rating each Pro to pg13 like in my
previous examples and they count them so
that's quite simple but the more complex
stream is more complex of course thus
its name so it will create a stream of
all the films sorted in length
descending order it will skip over the
first 745 films then it will look at the
next five films it will extract the
Gantt get rental duration property over
film and then we do something called
summer statistics now the summer
statistics method is built into the java
stream interface and this will compete
compute things like max minimum and
average in count so this is nothing that
Speedman has come up with this is
standard Yola stream interface so and if
a run is with the database the complex I
was able to crank out 2,000 operations
per second and if I use the more simple
one it's about 5,400 so I will take this
value I'm going to paste it in here for
the time being so now let's go back and
let's do in memory instead I just change
this parameter and I rerun everything
yeah
and it will run the same tests it I
haven't changed anything now in the
stream they look exactly the same so
when you're using in-memory acceleration
you don't have to change your
application you only have to have a
single row as saying if you want
acceleration or if you don't want
acceleration so now running it runs
exactly the same test as before so let's
see what happens I can already now
reveal that it's going to be
considerably faster so there we are
almost twenty million streams per second
and that's astounding because the
average latency here will be less than
200 nanoseconds for an entire stream now
remember just accessing main memory was
100 nanoseconds so I think it's quite so
let's fill in this value here so that's
almost 20 million and let's take this
guy and paste it in so now you get a
view of other difference speed and
difference here and even if I would you
know let's take this 5,400 and write
54,000 multiply it with 10 still it's
just a few pixels so you understand that
there's a huge difference here so that's
my demo
so let's find my way back yeah
yeah
in memory had the first example I ran
towards a database that was installed in
my laptop here and it was all running
locally and the database was set up
standard it was a standard my Sikh in my
sequel database and Iran's pigment and
Speedman 300 sequel queries which was
sent to the database and then processed
in a JVM whereas in the night another
example the code was exactly the same
but instead of connecting to a database
it ran off heap memory in memory instead
so that was the difference good question
thank you okay so using existing
infrastructure and I think that's now
your part yes so sometimes when per said
that you need to think of how the
architecture is I I guess that he needs
that he needed to think about when he
developed speed mint but you as the
developer when you use pigment you get
this automatically so this was a certain
explanation how it could be this fast so
if you have an Oracle database or if you
have a ver a code or sequel server or
anything you can stick to it and just
let the application itself generate the
code for you you can deploy it anywhere
it's very good reducing drop current
kinetics you can use it in the cloud it
works with IntelliJ or I guess you were
used to use NetBeans or Eclipse and the
old guy yeah you can work with spring
JBoss or any web server integration and
it's also important to know that you can
it's a stepwise introduction if you have
a Java project and you have a certain
part of it that is slow you can rewrite
just this part so you don't need to
start all over or do a gigantic project
from start you can take this little
piece and start often just try it out
and it works from Java 8 and that's the
good thing with the developed speed
meant with no need to take care of Java
7 so we started off with all the good
things that came with it with the other
8 so this is one reason why it could
work so well and when we tried it out in
Java 10 now just for fun because we know
that most of you will not have Java 10
for long time we were happy to see that
it was much faster and but you can also
use rest it works also with the rest
interface so when is speed meant good we
often got a question about is it
possible to fit terabytes and into your
memory and actually it is you can get
already now seven terabytes as a memory
and it's not it's not expensive so it's
a very cheap solution to just buy more
RAM and get this speed we are working
with a lot of different companies we
have for instance the transportation
company they had an Oracle database and
they had six million records in the data
set and they had we took them 102
seconds before spearmint and after we
could get under this medical one second
the same thing with this telecom company
they have actually five minutes it
started it off and they went to take
coffee and then they came back
and we managed to get it down to one
second healthcare industry was an AAS
400 db2 application they couldn't
migrate to another platform so they was
sticked with this old technology and we
also managed to get below one second and
FinTech that's a very common use case
where you need to have there we could
get down to 100 milliseconds this is
portfolio IQ this application is called
and we tried it out with and without
Speedman's so to try this out on the
Speedman website you will find in that
initializer and you just click in your
database type what kind of JDBC driver
you want if you want for instance spring
plug in so that or anything you can
enable the in-memory acceleration if you
want to try this or you can disable it
and you will automatically get the palm
XML file that you can move into your
project so that's what we wanted to tell
you today if you want a tri license you
can just contact us or you can if you
wanted to try out it the on github you
can just go there and do that so do we
have any questions
it's it's using JDBC so it's on top of
JDBC you can say it's like if you have
heard about hibernate hibernate it's
also over em so it's something similar
to or comparable to to hibernate which
is kind of converting between databases
the world and the object-oriented world
and for that you get this street and a
reasonable question gets the treat how's
the license model license model is
open-source it's Apache - and for the
enterprise in-memory acceleration it's
an enterprise license model and you can
talk about Karina because that's her
department yeah
or question is can I use canna filter on
any column or how many filters can I use
is that correct okay so so you can use
composite index or single index so if
you have a composite index off of two
columns you can have two filters for
example that can be applied directly
using indexes just like a database and
the solution will evaluate which index
will give the best result so if one
index will give the result of a thousand
entities and now they just ten then it
will apply the most aggressive filter in
memory and then apply and then use the
other filters in the loop so to speak so
it's cat yeah it's a kind of a query
engine you can say that works with all
the filters and knows all the indexes
and knows the cost of materializing
different columns and so on yeah yeah
yeah the question is can you apply
partition and the answer is yes we
support partition data out of the box so
you can partition the data in for
example integers or using any objects
that petition you data and then you have
already gained a level of of querying so
to speak because then in your partition
you know that that partition key all is
to say or at least is the same as the
set of partition keys you have selected
for that particular instance it was a
question I missed somewhere here okay
YouTube okay process where you load your
all your data into the TV in memory and
yes there is and the good thing is that
this thing can happen under the hood you
don't have to care about it because it
can be loaded in the background so when
you start typically you pull in a one
snapshot but then after maybe an hour
you want to refresh your snapshot and we
can say I want a new snapshot and when
that is loaded into memory perhaps a
minute later then your queries will be
made against that new snapshot and the
old queries that are still working with
continue with the old snapshot because
otherwise it wouldn't be consistent and
you can you can do a replay database
updates too but the normal thing is that
you create snapshots regularly but yes
you can also replace a tibay so if you
have for example an event sourcing
system or something like that you can
replay those events and update your
snapshot dynamically and create a new
snapshot which is basically an old
snapshot but maybe just a few entities
changed and that is a very simple and
cheap operation so you can create
hundreds nap shots per second if you
want per second
did you get the tree yeah okay then we
will have an out of memory exception so
you have to make sure that your data can
fit but there are ways to control how
much memory you want to allow
application to use maybe I don't want to
allow my application to consume all my
RAM because I have other applications so
there are protection mechanism for that
but but there's one requirement you have
to make sure that you fit the data you
want to work with yes I think there are
many contributors and which is the most
contributing depends on the application
application of course in terms of
latency the biggest contributor is that
you have already have it in memory
because just just going out in TCP back
and forth will take ages compared to
just accessing memory but in terms of
sheer computational power it's more like
how you handle the indices and how you
can optimize your stream that is more
important in terms of raw performance
yeah I mean typically if you have an
application that application also have
has to have a bunch of RAM because you
have to be able to access your data from
your application so they're running in
the same JVM and that this may be a bit
different from other solutions where you
typically have a smaller client that
will do some query but does this
prohibitive if you want to have
ultra-low latency so that's a design
decision we took otherwise we wouldn't
be low like the ultra-low latency but
that's a consequence of that that is
correct
yeah yeah that's your turn
that's correct it depends I know that my
sequel isn't you know super optimal in
using it synthesis but currently you can
only have indexes of grade two in
statement that means that again maximum
apply to indices at the same time if you
don't use partitioning then it's the
third level but this is something we are
working with them and quite soon you'll
be able to use any number of of filters
but then of course you must have that
index in memory it and it becomes more
and more cause space consuming if you
want an index of five columns for
example and what you have all
combination of those fives it's going to
be tricky so I think this is a low of a
fundamental law of computer science but
it's reasonable to have maybe up to
three or four indexes but then it's
going to be a combinatorial explosion of
the different combinations because you
have to apply them in right order
because an index is has a given order
and you can't just use something in the
other order so typically what Streetman
does is is that it's trying to sort
predicates in an order that is already a
multi column index on and try to apply
it in that order and if it can it will
do if you can't then it just creates
saves in a single index
yeah yes and no it's not possible in the
off-the-shelf product but we have done
it in customer product it requires some
tweaking but it's possible to do it so
we use memory mapping in that case we
mapped memory to a certain file and that
file is of course done on an SSD drive
somewhere locally so it's possible to do
it and the good thing with that solution
too is that if you have a micro service
architecture and maybe have three or
four instances of that backer service
they can share the same map and file so
when you restore that application even
though you might have a terabyte of data
it's up and running immediately because
the operating system is managing all the
paging and everything so it's good in
some cases to have that not only from
memory perspective but also from a
system architecture perspective yeah
yeah we have measured against both
ordinary databases and other in memory
solutions so on it and it of course
depends on the workload in Anthropy of
data you have but we have seen many
times maybe a factor of 10,000 times
faster than a database and hundred times
faster than other solutions that are in
memory
maybe notes or using objects but I think
that we are not the best for every case
we have our sweet spot and there have
their sweet spot so I'm not saying that
we are the best in the world but it has
some good most yeah but it has some good
applications especially in ultra-low
latency
yeah in this in this particular product
we saw have with a portfolio management
we had a database with all the traders
and all the papers and and all the you
know different business area order
profit and loss and everything and
everything was pulled into memory in
that particular application and the
logic was applied and then it has a rest
interface
so there was web the webpage calls for
this REST API and then the logic sits in
the application which has access to the
in memory growth so that is how it works
yeah and everything sits on the massive
if you would have had two of those you
would have to have a set of two
snapshots
it's only a server-side and it sits on
the same JVM yeah yeah yes you can do
like you can do it with file mapping is
one replication strategy you can use
there are other ways to do with you you
can have one master no that will send
events to participating members so there
is a cluster solution too but it's kind
of out of the scope for this
presentation but you can use some
existing frameworks for that I don't
know the name of it right now but it's
in the Netflix stack I don't remember
the name of it right now but you can use
that kind of replication
okay well questions no more question no
more treats thank you thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>