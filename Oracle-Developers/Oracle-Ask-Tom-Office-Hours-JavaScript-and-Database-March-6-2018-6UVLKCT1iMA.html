<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Oracle Ask Tom Office Hours: JavaScript and Database | March 6, 2018 | Coder Coacher - Coaching Coders</title><meta content="Oracle Ask Tom Office Hours: JavaScript and Database | March 6, 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Oracle Ask Tom Office Hours: JavaScript and Database | March 6, 2018</b></h2><h5 class="post__date">2018-03-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6UVLKCT1iMA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">perfect okay thanks for joining us folks
- this is our second office hours
session and today we're going to talk
about acing processing and various
patterns and nodejs standard safe harbor
statement here don't make any purchasing
decisions based on what I say today
although I don't intend to show you
anything you can already do today with
us today is Chris Jones as well as
Dwayne howdy how's it going guys
cool good good good I have a couple
items to talk about in terms of news and
announcements but I'm gonna let Chris
actually talk about both of these so
would you want to say on these Chris if
I can read them on your small screen on
my I'm a exhuming I've got two really
busy beta yeah that's fine
so actually they're three announcements
only two here cuz I can tell you the
third one so get up
iö pages so for a long time we've just
referred people to the github comm you
know source code repository to read the
documentation from a file called API dot
MD we've just moved that across to this
github pages site which is just so it's
not used to github just a site they
automatically create for us with a click
link and so this is now what I'm going
to refer to as the sort of main home for
Oracle documentation and there's also
you go back up a couple of levels there
there's also like you know the official
home page on the on that site so we're
gonna start moving all the links across
for this and hopefully people will
they'll start using this for doc one
thing which I didn't get around to
during a diagram for but I'll explain
very briefly is that this will then let
us push changes to the source code
repository into documentation there but
not into the documentation dan was just
showing you on this dot io page
and that means that users with node
which you kind of got and running really
well just refer to a sort of steady
version of the doc which is consistent
with the version irani where as active
development land in the source code repo
were busy pushing in changes and things
which may not immediately available or
may be incorrect or whatever whatever so
that's kind of just one of the
reasonings there plus also a get up bio
page it just makes everything easier
we've got similar pages for other
drivers as well also the second point
you had there on that slide was oh yes
so yum repository so anybody using you
know Red Hat Linux is CentOS things like
that can now get packages from us for
for node itself and there is actually if
you really wanted a an RPM package for
the Oracle driver I think they're just a
little bit behind at this stage but I
know they're working really hard they're
pushing out a thousand million packages
out there to make everything available
for on the one repository including
something makes people know as they
eople EPL packages so there are a couple
of thousand packages there so they're
just busy pushing a lot of stuff out
there to make Oracle Linux easier for
users and then the third thing which
wasn't mentioned there was they actually
did create a kind of skunkworks Facebook
group so you know in Oracle we have lots
of processes Matamata so there is a
Facebook group out there which you can
search for and I'm just pushing out a
couple of you know released
announcements things like that
effectively a kind of Twitter feed but
on Facebook because I know that Facebook
gets used in in some places more than
Twitter so if you want to go and search
for content but no js' JavaScript Oracle
database Python PHP all of a sort of
scripting thing is that our group looks
after here in Oracle database world just
go on to Facebook and search for that
and you can find it
but thanks to did you have a link on
that last one oh yeah I did I will shoot
that through you in a few seconds hang
on okay let me pop that up dad to do
let's put that on the chat there we go
so zoom four people are not familiar
with it does have a kind of chat feature
and you might see something like
flashing in your screen at the moment oh
cool chat sign I had not seen that yet
I'll have to get into that excellent
alright obviously it's an open forum so
just be polite to etc etc I'll do my
best
alright so let's go ahead and get into
today's topic and I'm just gonna try to
keep these slides open like this I don't
want to go full screen at the toggle
back and forth but if it is difficult to
see anything just let me know give me a
heads up and take a look at it
so of course I'm assuming that everyone
here knows what node J s is so I won't
get bogged down and into that too much
oh and another side note if you have any
questions at any point in time or you
want to explore something further just
shoot me a message in chat and I'll do
my best to keep an eye on that you don't
need to wait to the end or anything like
that so basically nodejs was created
back around 2009 by a guy named Ryan
Dahl and at the time what the project
was all about the problem that they were
trying to solve was doing networking
efficiently because generally up until
that point the way you would handle
network requests that were inbound as
you would accept the request and then
potentially spawn many processes perhaps
writing the files or communicating with
the database and while those processes
were doing that kind of work the process
of channeling the connection would stay
open and this model just didn't scale
very well at all and that's where
concepts such as event loops came in and
Ryan Dahl was looking at applying
javascript to this entire
new world and he found JavaScript to be
a really good language to do this with
and what my images can't be displayed
you see here Oh No
boy oh boy well that's a bummer I'm not
gonna try and debug all this right now
what I'll do instead is just kind of
talk to these points sure all right so
basically with functions his first class
the idea was JavaScript just offered
this out of the box and the idea was
well it had to do with the fact that it
was created to handle this very thing
from the very beginning so when we look
at a very simple website example as I
have here blow that up some so what
we're looking at is a typical scenario
where we're just in the body of a
webpage we see a button and we have a
script tag so we have some JavaScript in
the page and what we're doing is
declaring a function called on load and
unload inside of it has another function
called on click and so when we're
talking about first class the idea is
that unlike some programming languages
in JavaScript when we have a function it
can be treated just like any other
variable and we need a disability
because of the dynamic and asynchronous
nature of JavaScript from the very
beginning in this case we're seeing an
example where we take the button and we
register an event listener on the click
event and you see this pointer here to
the name of a function which was
declared above it so this is one of sort
of the two ingredients you would need to
get async work done and JavaScript and
and that was supported for quite some
time and the other one is known as
closure and so with closure what we
needed was the ability to have a
function within a function in this case
the onclick function is declared within
onload and you see that on click within
that phone
and it's referring to the variable
declared in the outer function scope and
so this is basically in some different
languages like say PL sequel for example
which is my background for the longest
time something like this just wasn't
possible when the on click function
eventually ran in the future when the
click event occurred on the button this
function would not have access to that
outer reference of the button because
the onload function would have finished
running long before then but in the case
of JavaScript JavaScript goes ahead and
ensures that when an inner function is
referring to a variable declared in the
scope of an outer function that it can
maintain access to that going forward
and so you had these concepts they're
already built into JavaScript
well Brian Dahl started to do was apply
those than to networking which is where
no J's came from that's sort of the
background on that despite that fact
this is probably my only image that's
working
still even though javascript is sort of
known for being able to work with events
when rising stack ran a poll recently to
find out what developers love about
nodejs
you know speed of development obviously
ranked rather high but absolutely dead
last was this asynchronous coding and
the reason for that is of course what
we're talking about today there's
basically lots of different ways to do
it but it really wasn't until recently
that we got to a point where
asynchronous development is finally
getting easier and that's thanks to
async awaiting the JavaScript gods doing
some really complex stuff behind the
scenes for us to make the code that we
write a lot simpler so these slides here
I pretty much talk about some examples
that I'm going to run through and some
of the patterns will be using the
node.js pattern which I'll just talk
about in code instead there are some
basic and pacing flows that you'll find
yourself needing to code from time to
time the first of which is a sequential
flow this is where you're doing various
tasks and before you can go to the next
task the first task has to complete what
it's doing and another type of flow
might be if you're doing something in
parallel and then of course you might
combine these types of flows depending
on the workload that you're trying to
handle and I wanted to look at a couple
different flows the first of which being
a scenario that I think is rather
typical and enterprise style development
header detail transaction where you
insert a header record and you need to
get back the primary key ID before you
can continue inserting detail records
and another one I want to look at is
sort of a different style of development
or writing asynchronous code which is
doing some kind of ETL via stream so
we'll take a look at both of those but
before I continue I did want to address
his question in the queue what is
currently supported for rack service and
and FCF I know you're working on
application continuity but not sure what
currently supported I'll let Chris
tackle that one yeah this is an
interesting one so Dan mentioned the
future things we have the event flag how
do I explain this especially for people
who don't know what's going on the
Oracle client tools you know no dark
will be be Python etc can listen for
events from the database so these fast
application notification events the
session pool the connection pool that we
use in note Oracle TB can handle these
events in certain ways in terms of
closing dead sessions if a database is
disappeared in the backend automatic
automatically reconnecting to another
database Iraq is a clustered database
that we have and so typically you might
have cost of a couple three maybe sets
of processors running the database
accessing the shared database files and
one of those sets of processors has gone
one of the database instances and our
two can continue doing work so the
session pool will be able to reconnect
one of those surviving instances to make
sure the connections are available for
users in the application so we
effectively support anything that OCI
supports we as providers that it's
through the session pool so you can
already use this events flag there's an
aura underscore events environment
variable you can set to turn on this
event listener so that node Oracle
didn't is listening for those events you
can also set it through the aura access
dot XML file which is which is actually
documented in the Oracle TP manual and
then in two point two which is upcoming
we've just exposed an extra horrible DB
dot events attribute you know boolean
true false just to enable us events so
that the node Oracle DB processors are
listening for these events coming
through and then effectively it's it's
the fan and the fell over that we're
targeting for that and there's something
also called
runtime load balancing which will work
with the session pool so I think I'm
gonna leave it there that's quite a
complex topic to go any further but
effectively were listening to the events
as long as the database is configured to
send the events and we're just behaving
like any
call interface client CC client
excellent thanks Chris
there's a follow-up question let me see
this is related events will only trigger
if they're in or access XML correct
yeah if the flag is is our own oh I'm
sorry
I got am i confusing it with ya sorry
I'm I'm I was confusing affairs it's
really in the morning for me not that I
was confusing it with the addition flag
which was also will be coming rogue
native support for enterprise based
redefinition which is the PL sequel
versioning so you can access different
versions of PL sequel objects and that
does have a environment variable called
aura underscore Edition mm-hmm sorry I'm
completing the two things together so
apologies for confusing you there with
the environment variable but for the
moment you'll need to use our access not
XML which means you need to version 12
client library or aqua client library
when we push out the next release 2.2 of
node Oracle DB then we'll just have this
extra property which you'll be able to
say it just to make a little bit easier
excellent thank you sir
so continuing on this is the first
scenario we'll be looking at which is
just a simple header detail scenario and
so I want you to imagine that we have
some kind of REST API may be listening
on domain.com slice API slash orders and
we're going to Incept some post likes
post request coming in and the order
that will be processing is this guy
right here so just a real small order so
obviously the name here is for the
parent thing and then you have a detail
array with several child things that you
need to get into the database so that's
the basic scenario
the first pattern I want to explore is
the header detail and handling the
incoming requests using anonymous
callbacks which is oftentimes where node
developers tend to start in the very
beginning and so we have that pattern
here
is reorganizing a few windows okay so
what you see is I'm bringing in the
driver and then I have a function here
called post and the post is going to
take in that order that we sell them in
and ago and eventually when everything's
processed or finished processing it will
invoke this callback function in either
a pass along the error that occurred
during processing or be returned null
for the air and then the header ID that
was inserted so the very first thing we
do is we go to the driver we get our
connection and this is that nodejs style
callback pattern that I was describing
earlier so basically the way that it
works sort of two things need to be true
first of all the last function that
you're passing into an async API in this
case get connection is the async API so
the last parameter passed to that
function would need to be the callback
function so if we had any other
parameters they would be in front like
one two and so on and then in that
callback function the first parameter is
reserved for errors so the very first
thing we need to do is check to see if
any errors occurred and if so this
return here becomes really important as
we want to short-circuit the logic and
not continue processing if an error
occurred and this is just how it worked
with the node.js callback style pattern
so we get our connection if you get to
this point you can assume success so we
can then use that connection to execute
in this case the insert statement going
into our header table we see here an
example of using some bind variables who
are binding the value of name in but the
ID is actually a bind out the type is
number passing along another
function this time to handle the success
or failure of this async insert so we
have again some error handling logic in
the beginning we do have to close the
connection if even if an error occurred
and then eventually send back the signal
as to what error had occurred but if we
get to this point then you can assume
success that your insert succeeded so
you can get the ID out of your outlines
and assign that to a variable in this
case header ID and then we can start
inserting detail records now using
anonymous callbacks this is where things
tend to get a little sloppy and we're
starting to see some of the weaknesses
if you will of anonymous callbacks so if
I come down you see the first detail
record being inserted further along you
see the second and further along you
finally see the third and in addition to
this nesting and hard-coding of these
callbacks and hard coding meaning that
it's not able to handle a dynamic number
of detail records because it simply
couldn't there's no way of handling it
with anonymous callback functions if you
come to the very bottom you'll notice
this shape starting to take place here
and this is something that sometimes
developers call the the Pyramid of doom
or you know there's different names for
it but in any case we've fallen for it
here and so
no just developers often end up here and
they kind of pulled a hair out like wise
node so hard that's that's sort of like
level one so the good it actually does
work and I can prove this actually so if
I come here to sequel developer if you
look at this header row we currently
don't see any data in it
and if we open this directory up and a
terminal what I have is a test file here
and so what the test file does is it
brings in the driver it first creates a
connection pool and if you saw the DB
config here you'd see it's just one
single connection but I do prefer to
write the the examples using connection
pool so people get in that habit and
then depending on the additional flag
that's passed in it'll pull out whatever
tests it needs to run the test according
to its API and then log some some of the
results so if I run this
you
you
with node tests and we run the first
test you see it pulls out the header
detail with anonymous callback tests it
runs that and it gets back an idea of 35
we come back to our header row we see
our parent thing and then if we look in
the detail we see all the detail rows
that had a record as well so it works
but the bad of course is that we fell
into the pyramid of Doom we're unable to
handle the arbitrary collection links
coming in obviously very hard to
maintain and of all the solutions this
one by far has the most amount of code
despite being the least flexible so
we're up to about 118 lines of code cool
let's move on and see if we can do
better so as no developers get more
comfortable with JavaScript they
eventually stumble upon named functions
and you're seeing here the 30,000 foot
overview of what's happening so here's a
function called post here's one called
create order and here's one called
create detail so we're starting to sort
of separate out the work some and if we
look at our named function example
you'll see overall we're down to about
ninety four lines of code but things do
start to get a bit better here so we
taken the post just like before we have
the order as well as the callback that's
eventually going to be called back or
invoked when the the operation succeeds
or fails as a unit we have very similar
patterns in terms of the callbacks and
checking for errors that hasn't really
changed at all but what has changed is
inside the post we have this other
function here create order so rather
than continue to nest and nest and
that's the nest now we can pull this out
a little bit and invoke another function
this in this case a name function called
create order because we're no longer
nesting one of the easy things that
happens with the anonymous callback
pattern and just unlimited nesting is
that scope management is maybe a bit
easier because you can always refer to
parameters and variables and higher
levels of scope but in the case of
separating out your name functions you
now need to start to pass the scope
around so if in the post handler if this
is where you get your connection and
then you want to invoke create order
you're going to have to pass the
connection along that create order
should be using so a little bit tricky
there but I think the benefits
definitely are a good thing here so here
we move into creating the header record
same binds as before same error handling
as before but now we get our header ID
and this is where things get a little
bit interesting because the name
functions can handle these arbitrary
collection links so you see I'm invoking
create details once and passing along
some state as I mentioned before but and
create details
notice that I'm passing in zero for the
index meaning that we're at the very
first record of the details that we want
to insert and it's not until that value
reaches the length of the array that
we're trying to insert or work with here
that it will go ahead and short-circuit
and complete the operation well as long
as it's not
and we'll insert a detail record and
down here you're seeing a an example of
recursion a manual implementation of
recursion where I'm calling that same
function again and I'm just incrementing
the index by one so we can come through
here we can iterate three times and
that's why we see that reduction in the
code overall I won't belabor this much
more after this but just to prove that
it's working we can run that come back
to our
had a row here and we'll see the next
one coming in so I won't continue to
prove that each of these does work but
in fact they do so the good here
obviously less nesting were handling
arbitrary collection lengths easier to
read and maintain but on the bad side I
don't like this really tight coupling
that happens and the fact that you don't
have to pass state around this is just
the reality and of course the manual
recursion was not great so the next
pattern I want to look at is the async
module and the async module is by far
one of the most popular modules that was
ever introduced into the node ecosystem
or NPM so to install it pretty
straightforward just do an NPM install
async and then save that and once you
have that module installed you get
access to I believe over or close to 120
methods and utility functions and
they're grouped into three different
groups the primary groups of a two here
collections and control flow and
collections are a set of methods that
are available to you for working with
arrays essentially and then control flow
is something similar but working more
for the structure of your code so you'll
often see the names are similar in these
similar patterns it's just exactly how
they're used within your code can vary a
little bit and one of the powerful
things about async is that it has really
handy methods such as this one here like
Q and in fact just today I was in the
github issues tracker talking with
somebody about maybe using this
particular method because it's there and
it's easy and straightforward to use you
don't have to reinvent the wheel when
you want something like a queue
so this is what it starts to look like
if you go ahead and use the async module
and this isn't a complete story so let
me show you
what the same transaction
like using the async module so the first
thing to note is that we're bringing in
async and I'm calling the series method
which is one of these control flow
methods so in terms of control flow what
we're saying is there are a series of
functions that I want to execute and I
want to execute these in series or
sequentially and if we kind of collapse
this a bit what you'll really see is
that the series method is taking two
parameters here and the first parameter
is an array and it's an array of
functions and the way I like to think of
async is that it is essentially
extending out the nodejs style callback
pattern that we always see a no JSO
there's not a lot of learning anything
new here which is great you can just
kind of use what you already know
so async series is taking an array of
functions to be executed sequentially
followed by a function that will either
a be executed when all of these
functions finish successfully or B when
an error occurs in which case the rest
of the functions will not be executed
and you'll be passed along the error
that occurred instead so you can see
what I'm doing here the first function
is the one responsible then for getting
the connection so it can get the
connection and in this case in terms of
state management rather than pass things
around which I could have done with
another method like waterfall instead of
doing that I've just decided to declare
some variables up here in a higher level
of scope so that other methods such as
insert header and details can get to it
so we just assign that higher up in
scope and then we invoke this callback
this is not the callback that was passed
to post but rather this is the callback
that async passed our first function and
this is the way that we let async know
that it's finished or that we're
finished processing this function and it
can go ahead then and invoke the next
function so it goes ahead and does that
so with insert header similar logic to
what we saw before only this time we
just invoke the callback
signal it can proceed we get to the
details and this is where I'm using yet
another method with an async but rather
than the control flow that you saw
before this is one of these methods that
operates on a collection so you're
seeing an example of both of the types
of functions you might be using with
async
so in the case of each series what we do
is start with a an array of data that we
want to iterate in this case it's the
details array and the order a function
that should be invoked once for each
element in that array and then finally a
callback of course that will be invoked
when either everything completes or an
error occurs and so for each iteration
of this details array this function will
be invoked and it'll pass along the
actual detail or single row within the
element as well as another callback that
we invoke to tell async to go to yet the
next element in the array and so you
kind of see how how acing is working
here it's all just based on passing
these callbacks to the weekend signal
when the async engine should continue to
the next unit of work at the very end
here you see I'm committing that
transaction and then finally this
function runs closes the connection and
we're done we can pass back that header
ID so that's the async module
minted in the chat was them I was
working with but they're using node six
or no acing support so actually what I'm
what I'm looking at here is called the
async module and and two examples from
here I'm going to get to what you're
referring to which is that the native
async function support in JavaScript
which is also known as async await but
in terms of this what this is
this is a module
a sink so I said I wouldn't run this
test but I guess I will what I'm going
to do is delete a sink and I'm going to
say
run the third test and we're getting an
error here because the async module does
not exist so even if you were in node
six here all you have to do is in NPM
and install a sync typically followed
with a save command it'll go out it'll
pull that in and we can rerun the test
and now you see it succeed so this is
one of those things that you really
don't have to wait for a later version
of node 4 and believe me even when you
learn some of the concepts that I'll
show you here in a moment you still
don't want to forget about this module
because although there's now built in
async await and this kind of stuff and
promises and all that that's nice but
this module is still incredibly powerful
and useful and you'll find yourself
coming back to it when you're doing
really complex flows maybe not the
simple stuff anymore as we're working
with here write a header detail but for
complex stuff when you're thinking ah
maybe I need a Q or something like that
then async is still really really handy
all right
so the good fixed our problem with
nesting we can work with collections
really easily and on the bad is this yet
just another form will call back he'll
perhaps perhaps not it depends on how
you look at it alright so let's move on
and we'll talk about the next thing that
I think most node developers get into
once once they're comfortable with async
processing and really the you know that
the default no Jaya style callbacks then
they can take on promises this is sort
of like you know you have to do one
before the next have to crawl before you
can walk and walk before you can run
but once you've really mastered
callbacks then I think you're ready to
move on to promises and so promises
started actually a long time ago and in
sort of user land there were lots of
modules I think Bluebird is perhaps one
of the most popular examples of these
modules it's actually still used quite
heavily today but eventually the spec it
became a reality as part of the language
and so promise support is now built in
you don't have to do anything to include
it and in fact one of the things I liked
when they added support for promises was
the simpler implementation if you will
then you might have seen previous to
that working with the third-party
modules so the way it works when you
start working with promises you're
starting to work with objects that can
have one or three states either pending
resolved or rejected and you can chain
promises together which can make for
really nice clean code without having
the nests too much and you can chain
using then and catch methods which we'll
take a look at and you can use them
catch in a similar pattern as you might
have in JavaScript with try-catch which
wasn't really possible in JavaScript but
you can do it here with the async module
or rather with promises so here you're
seeing the header detail example the
30,000 foot overview and this is kind of
what it looks like
now on line 8 here what we're looking at
is a call to the drivers get connection
method and if you look at previous
examples of that same call you'll notice
that it accepted a callback function and
when you passed along the callback
function then it would not return a
promise but here what you're seeing is
the first time we're using it and
expecting it to return a promise so all
of the drivers asynchronous methods so
get connection create pool execute
commit all of those are overloaded such
that if you do not pass a callback
function it will go ahead then and
return a promise question in the queue
is are these examples going to be shared
absolutely I will make sure to share
them immediately after the talk so what
we're doing here is invoking get
connection let me get into the code
actually so you see here in fact this is
the first example all of the previous
examples the post function took a
callback function in other words because
we were exploring different patterns
with the callback patterns the post API
that we had exposed to the test file
itself except that a callback but when
we move now into promises what you see
is the API itself is no longer accepting
a callback the idea being of course that
if you're all in with promises all of
your API is are going to be promise
based so you're seeing here an example
of what a promise based API would look
like so in this case the post function
is taken in the order to be created and
let's collapse this in and you can see
rather clearly here now what the post is
really doing is simply returning a new
instance of a promise and when you
create a new promise you're going to
pass in what's called a resolver
function and this function is going to
have two parameters passed to it when
it's run resolve and reject and it's up
to you the implementer of the API to
invoke one of these two functions and
you're going to invoke resolve when
everything completes successfully and
you're going to invoke reject if
something goes wrong within your
execution of the function
so we'll open this up and you'll see
that like before I'm going to the driver
and getting out a connection and what I
do is I chain off of that so what's
happening here is get connection is
returning a promise and when it returns
that promise immediately it's in the
pending state it's not resolved yet or
rejected but I can use then to wait
before I continue to the next step
sorry there's a question in the queue
when does it make sense to use the node
driver to connect to Oracle when does it
make sense to use rest or or it's it's a
good question I think it it may come
down to sort of your comfort level with
languages so for example if you're a
long time Oracle database developer
comfortable with sequel and PL sequel I
think it would be a perfectly good
choice to go with boards or Oracle rest
data services because it's not going to
be anything really new to learn orange
handles a lot of the underlying plumbing
for you
however if you're a JavaScript developer
or if you prefer like a lower level of
control then oftentimes drivers and
language specific drivers that you're
comfortable with they're going to be a
better choice I think the official
answer is it never makes sense to use
words maybe that's a job that's not true
it certainly certainly has a place it's
is one of those things where you then
rely on other people to start doing
infrastructure set up for you whereas
things like node and Python whatever you
can pretty much just get on with and do
yourself so there are sort of pros and
cons in terms of the administration as
well you get differences in terms of
security models you're not going to be
using all its for data loading we've
seen a lot of people trying to do data
loading in certain large volumes of data
so you're not going to be using that
using rest and audits we've already had
questions here today about the failover
and fast connection and stuff like that
you know I think I think you see
definite advantages there if you can
spread your meteors out
so you know it as the mid-tier so you
can spread those out in terms of
reliability so pretty
pretty obvious some of the cases and the
rest is dance there's a you're almost
business decisions plus your comfort
level use the right Bruce or I talk for
the job exactly that's always a good
thing to do thanks Chris all right back
on the promises so what we have here is
a function returning a promise I'm
chaining off of that promise with Ben
and something magical happens with then
when you either use van or catch you're
passing a callback function so with
promises by the way you can't escape
callback functions surprise surprise
you'll never escape them in JavaScript
but what we're doing is passing a
callback function to then but this
callback function will not be executed
until the promise that was returned from
get connection is either resolved or
rejected and to get to the Ben path it
would have to be resolved then our
function is going to be invoked and when
it is it will be supplied the connection
that was created as a result of the
connection method succeeding now inside
of the body what I'm doing here is I'm
returning the result of a call to
connection dot execute and as I
mentioned all of our async methods are
overloaded so that if you don't pass a
callback function and you do not see one
here it will return a promise so within
the Ben block I'm returning a promise so
the next ven block will not execute
until that promise is resolved this is a
little bit of black magic it's just kind
of handling some of this stuff for us
but it is definitely convenient now what
you're seeing right here is my biggest
gripe with promises and remember we had
this scenario where we have three detail
records and what we what we need to do
is of course do a single insert for each
of the three and you see what this looks
like with promises so to do a promise
chain what you first have to do is
kickstart things by invoking promise not
resolve this just gives you a resolved
promise and then I'm coming in here and
I'm using a for each loop on the details
array so this is a synchronous
Loup so I'm looping three times in the
current call stack and I'm setting
promise chain equal to itself and then
I'm chaining the then call making
another you know like then on top so I
personally find this to be really
confusing it does work but I'm
definitely not a fan of this pattern
here I think it's overly complex and
just going back to the async module
where we were inserting the detail rows
I think async clearly wins here you know
saying each series this is the array we
want to iterate this is the function
that should be executed once for each
element in the array is definitely far
better than winding up a promise chain
that you're then going to unwind via
this return call here this is going to
make sure that all three of the inserts
succeed before continuing on to the next
end call question in the queue is there
an advantage of naming those callbacks
as opposed to keeping them as
asynchronous so the named callbacks here
but you see it's not as opposed to
asynchronous oh no sorry you said
anonymous I said I synchronous yes you
said it correctly so aside from
documentation no there is no advantage
these could definitely be anonymous
functions there used to be some issues
with respect to logging if you only had
asynchronous functions and your error
output log you'd get an anonymous
function as opposed to a name function
you wouldn't maybe know where to look
but I believe that's no longer the case
so no there's really no benefit other
than maybe a self-documenting code if
you will all right coming down a bit
further what we see here is the first
example where then is taking two
callbacks so the first is what you saw
before and it is the callback that will
be invoked upon the successful
completion of the previous operation in
this case all of those inserts
succeeding if that succeed
then we can go ahead and commit the
transaction the second callback function
here is for an error path so then can
actually be used both for success and
error if you do pass to callback
functions or you could just use catch to
just catch a single one in this case I
just want to show an example and in fact
this flow lends itself well to this
splitting up in a single handler so I'm
using commit here this is the first time
you've seen an explicit rollback and
then I'm going to reject that promise
because something failed
I'm not resolving it yet until finally
we close the connection I could have
resolved that up there it's really not a
problem
note that when you close the connection
I'm returning out the promised return
from that it's possible an error would
have occurred during the close so I go
ahead then and catch any errors that
could have occurred this is really
important when you're building promise
chains make sure you have a catch on the
end if there's anything that could have
gone wrong prior to that step especially
in later versions of node they're just
going to stop masking uncaught errors
and so you you could kill the node at
the main thread could die when they stop
masking that back for you so you
definitely want to do that a couple of
questions in the queue here so so
there's a common most folks with respect
to these anonymous callback functions
tend now to use echo script six arrow
style functions totally agree I tend to
avoid them if only to make the code a
bit clearer to folks that are not yet at
that level because I kind of see this as
getting more and more abstract over time
and so I think sometimes JavaScript code
today looks almost mysterious like how
in the world does it stop working so I
like to use some of the older constructs
still for folks that are on that
learning path
all orders mad border executors similar
to build the chain that is an
interesting question so I spent a lot of
the time a lot of my time in the forum
trying to help people work through
asynchronous code and debug issues
anytime I start to see promise all in
orders map I start to wonder if there's
an issue and in fact we were kind of
debugging through one today
the idea is you want to keep control of
your code in the JavaScript layer and
it's very easy and no to kind of take a
bunch of work and unfortunately my
images weren't working earlier but you
know when you're doing different types
of work you can either maintain control
in the main event loop in your
JavaScript code via queues and the type
of code I have written here or you can
take a unit of work let's say inserting
three detail records and you can throw
that over the queue to libuv where it
has its background threads and a queue
in front of the background threads now
here's the thing this connection can
only do one thing at a time so if you if
you do a loop a synchronous loop here
and you're saying con dot execute three
times this insert statement or let's
imagine in fact the details here not
three rows but a million rows if you
will right so we're saying okay for a
million times do a synchronous loop and
we call execute insert well what's going
to happen is a million different calls
are going to go over to libuv and
they're going to be queued up for work
now let's imagine that the very first of
those million rows fails
well the transactions obviously going to
be rolled back right there's no need to
process any of the other 999 thousand
rows and yet because you've passed them
over you can't get them back they're all
going to have to fail before you can go
ahead and do your rollback so the idea
is you really want to maintain control
of your code and that's why you have to
keep it in the main event loop
you're using promise all I'm not saying
it's not possible to use that right but
you have to think through what you're
doing in order to do so
you
so another comment in the queue is
connection it would be synchronous and
the end connections can tap yep exactly
that's correct good point
also I don't think you need a new outer
promise but can return the main promise
chain so that's a fair point let me see
here I could in this particular example
return the main promise chain the
advantage of wrapping if you will just
lend itself to some control when needed
and but in this particular case as long
as you have to catch on the end here
yeah it should unwind itself just fine
yep that's a fair point I think I got
called
that today in the forum as well all
right let's move on to the next pattern
and actually I guess the last we're
going to have time to look at today
so this is when we get into async/await
and as I mentioned before you really do
have to spend some time sort of
mastering callbacks before you move on
to promises and you really have to spend
some time before you move on to this
next thing which your async functions
also known as async await so basically
we got some new keywords in JavaScript
and they came in they were inherited
from v8 they're supported in node seven
point six and above and the new keyword
that you start with is async and you
just put this in front of a function
declaration and then you have access to
the await keyword within the body of
that async function and what ends up
happening is sort of like black magic
but basically you can put a weight in
front of a function that returns a
promise and the processing within the
async function will stop it will not
continue until the promise is resolved
and then basically control comes back to
that thread and it continues on as
though it was synchronous in nature so
it helps us sort of unwind some of our
code and write code as though it were
synchronous although it's still
executing as it always had before so
here's that 30,000 foot overview of the
solution written using a single weight
what you're seeing here is a construct
that in the beginning I like to point
out does not work with async functions
and that's the try catch finally blocked
this is how you might see code typically
written in a language like Java that is
connecting to a database using the
connection to do some work and
eventually releasing the connection
whether or not an error occurs you want
to release the connection often times in
the finally block it's a nice clean way
to structure your code and one of the
most popular uses of try catch finally
you can't use it in JavaScript when do
an async work until you get into this
async function here so with async
functions all of a sudden constructs
that did not make sense before such as
try-catch such as looping you know a
synchronous loop now you can do
asynchronous for loops all of a sudden
the language the features that you
wanted to use asynchronously before you
all of a sudden can let's take a look at
this pattern
and what you see here is
triblock and so note that if an error
occurs I'm just saying a way to con
rollback and then finally we go ahead
and close that connection so this is
that single place where I'm going to
close that connection but the bulk of
the work is going to be done within the
try so I put the async keyword in front
of the function that makes post an async
function and one of the nice things
about facing functions is that by
default they're going to return a
promise so you don't need to do any of
that you know custom return a promise
it's handled for you by default and so
in our try block I'm using the await
keyword because we know that get
connection returns a promise so
literally what's going to happen in
terms of the execution of this code the
the thread will stop here it will
process this asynchronously and then if
it succeeds and gets a connection they
will come back to our thread return the
result of the promise to this con right
here and then continue on with the
processing as though it had never left
before and this is a concept known as
co-routines it's something that's been
available in JavaScript for a long time
now via generators and whatnot but I
think only now with async await this
this capability is now fairly usable by
mere mortals such as myself so we get
our connection and then we can use it to
do the insert into the header record and
note how clean the code is starting to
get here get a connection no nesting we
can say all right now use the connection
to do something like insert a header row
the result of a call will be here we can
then use that to get our header ID and
now here's something really neat what
you're seeing is a loop that previously
would have been a synchronous loop but
simply by putting the await keyword in
front of the execute column this does in
fact become an asynchronous loop so if
the first iteration of this loop fails
none of the other elements in this array
will be processed immediately will drop
down into the catch block but if
everything succeeds we can go ahead and
commit and note that I'm returning this
header ID
rather than resolving it as you would
have seen in the provost promise example
I'm returning this out and and it goes
ahead then and resolves that in the
outer scope of the promise for you
really it that's going on here with
catch finally so this is definitely
where I think folks should be heading as
somebody commented already they're
currently using node six something and
so they don't have it available to them
so that's a bummer
hopefully you'll be moving over to node
8 or above in the near future where you
can start to make use of this technology
so I already talked about the good and
the bad just keep in mind that you
really do have to have Stila I think of
good understanding of promises in order
to make good use of these I'll just
point out and maybe we'll have time to
get into this in the next session but
node does support streams out of the box
so I'll just move quickly through these
last we'll do some examples in the next
session there are four different classes
for streams out-of-the-box readable
writable duplex and stream and there's
as you would expect with something like
a stream object built-in support for
things like buffering and back pressure
to make sure that the streams are
working efficiently and we do support
streams out of the box here you've seen
an example of query stream which is
going to return a read consistent view
of the data so with respect to the point
I'm the query was executed but rather
than give you the result set which is
often how we process these you can get
back a query stream and and process the
array using this object just set up your
event handlers and then you can handle
that the data coming in alternatively
you can pipe stream so you can kind of
compose you can take a write stream from
a file in a read stream here like select
star from M and you can stream the read
stream into the write stream writing it
directly to the file you can do
different combinations introduce
transform streams in the middle it's a
really nice way to simplify some of the
code one other library I'll point out
that's gaining some attention is rxjs
and this is the reactive X extensions
for JavaScript this is a pattern
or a library that's sort of available in
lots of different languages and to
varying degrees but it is supported in
JavaScript as well a lot of useful
operators similar in a way to what we
saw with the async module but different
in useful patterns so things like delay
and retry if you're on networks that
maybe aren't as reliable as you'd like
them to be maybe you want to build in
some really easy retry logic you can
certainly do that with rxjs
and I don't have any of my slides but
that's alright it's four o'clock anyway
so I'll just say thank you to everybody
for joining if you have any questions
feel free to stick around and we'll just
address them
as they come into the queue hopefully
we'll see you next month for the next
session and as I said we'll at least
finish working with maybe some Stream
examples and that kind of stuff and then
we'll go on to another topic and
speaking of other topics many buddy has
any suggestions favorites whatever they
want to talk about just throw it out
there and we'll try and do that as the
you sort of icebreaker
you
yeah somebody wants to yeah
cover some club yeah we couldn't we can
do clubs don't forget to read the manual
on clubs there's a lot of stuff in there
there are almost two kinds of clubs you
have huge huge clubs and normal clubs
yeah we can something discuss discuss
that is the idea to stream a club to a
file or stream a club across a network
request howhow did you want to handle
that and we can unmute you if you want
to talk yeah yeah with respect to see
lobs I was all documentation and
basically what I implemented was
utilizing the returning into in in the
sequel code to outline that whatever I'm
transferring into the co-op field
wondering if there's a way instead of
using that returning into and targeting
the outlines they will just create like
an empty Sealab object and then stream
it's straight in there before I
committed yeah we have the thing called
temporary lobs which you can create
there's a great lob method in node
Oracle DB so you can create a temporary
lob and stream into that and then insert
it into the database however that uses
temporary tablespace in the database so
I think is actually gonna be less
efficient oh really oh no using the
crate lob and we're getting a lot
locator and then streaming into the lob
locator
go ahead Anthony just say if you have
the full string already available you
can also just insert the string directly
yeah sort of the small lob sizes you
know keep megabytes etc use the string
yeah so it's really a matter of tuning
temporary lobs also have one little
quick switch amongst friends here as we
are speaking technically they you need
to make sure you close them properly
before you get rid of the connection
although I think Anthony has done some
work there but to try and track that but
but traditionally they weren't released
at the end of connection so unless
you're using the later versions of node
Oracle TB
you definitely to make sure that you're
following documentation on closing the
temporary lobs before you close
connections otherwise you could end up
with lob leaks and run out of temporary
tablespace Anthony did a lot of work in
the underlying layers of the data access
code stuff the thing we call Oh dpi
that's sort of common layer we're using
now for a couple of the database drivers
and then we've got other people using it
for us drivers and Haskell and go
drivers and things like that but he's
done a lot of reference counting work
there to try and just make that all work
for you so certainly in this latest
release to 12.1 of node oracle DB then
you can pretty much do what i mean and
it'll take care of it for you I have a
question with down actually yeah feel
free to say no but can you show me an
example of using the async modules queue
method I've never had an interaction
with that module before and I wasn't
sure what you meant you know what we
might do is just take a peek at a at
their dock into an example they have up
there
I meant actually to have one together
today and I can certainly do that for
next time we can take a look at we can
take a look at some stream examples and
queue examples as well but the way this
works when you come to their page they
have all their dock on on github io so
you just want to click this link here to
skip over to that and that's one of the
control flow examples yeah it's right
there in the middle there is it yeah
there's things I'd have found it
eventually all right so let's see if we
can break this down see what it's doing
so async queue and one of the things
that makes it really easy is that the
second parameter here is the queue
concurrency so async can go ahead and
monitor for example how many of these
functions are running at any given point
in time and you can adjust that as
needed
so retain all right it's going to do
this work and eventually invoke this
call back then they take the cue and
they add some data to it so it's just
going to start processing using this
function is essentially but it really is
that simple and in the case of the
driver which you might do in terms of
where data is coming into the queue it
could be from a file in which case you
might be using a streamer to convert a
very large file into a readable stream
and then as the stream is eveni emitting
events arose you could be pushing the
data then into a queue or you might be
reading the data rather than from a file
it might be streaming and from a
database using either the query stream
or or the former object the Anthony I'm
blanking here was they called the result
set so so you could either use either of
those objects but in any case as data is
coming in then from the database you're
pushing that into the queue and just
letting this little function here handle
it for you if that's not enough let me
ask you this do you have a general kind
of use case where you want to use it I
can make sure to have an example ready
for you for next time you know it was
the one you were going back and forth
with connection connection queue issue
mm-hmm
where is your data coming from by the
way you're working with up to four
hundred thousand records yet at a time
right yeah it's coming from this
reporting API basically I work with the
database marketing team here and for
each campaign we sent out we need
contact level reporting back and those
are and we navigated them into our
Oracle database so it's those resources
that I was having issues with with
giving with managing connections so when
you say it comes from an API you're
actually issue
a network request saying hey give me
these rows they are returning four
thousand four hundred thousand rows to
you and then you want to move that into
Oracle databases at fair yeah got it
okay and when they're returning the data
are they returning it to you as a stream
or are they materializing the results
set and then you're having the process
that as one giant chunk the chunk it
basically excellent yeah fantastic okay
so I can definitely put together an
example for you that would basically
emulate those those various touch points
consuming an API that's streamable and
then moving that data into a queue and
then processing it as a queue the
difficulty I think and I mentioned this
with with what you're doing the biggest
thing that I struggle with is using
multiple connections and sort of having
each one commit because we're reading
this you know for up to four hundred
thousand rows and then we're calling
some some individual connections to do
the insert work and if any one of those
fails we have no longer the ability to
roll back the transaction as a single
unit of work so I mentioned that there
before and it doesn't seem to be so much
an issue for you for some folks it may
be so yeah as a business rule we sort of
we address that as a business rule
saying do we want partial reporting data
coming back or do we want sort of like
an all-or-none type of deal and since
we're running it pretty much daily I
think we sort of said having partial
data at any given point of time is okay
as long as it's within seven days so
within seven days we would need the full
result set but if one of if if one of
the batches failed to insert at any
given point of time it's okay so that's
why I treated them I basically paralyzed
the connection so for each 10,000
treated as a transaction and if that
transaction fail it's okay but you must
be materializing the data that comes
across the network
some what up to up to those arrays of
10,000 rows is that right yeah uh-huh
you know what may be interesting for you
is rather than buffering up to 10,000
actually I kind of like the fact that
you're doing that I kind of see why
you're doing that you may not notice
much of a performance difference if you
did go down to a single connection have
you have you experimented with that I
haven't only the the the ease of fixes I
can just send the batch size into
whatever the full result set yeah I
would say to give it a shot because uh
something's telling me you're not going
to notice that big of a difference
because your producer here is not
reading a local file which of course can
generate data much faster you're already
coming across the wire right so you're
you're sort of you're acting as your own
buffering agent and you're doing it
groups at 10,000 sending that across the
Oracle is a single roundtrip and so
while you may be buffering a bit more
than 10,000 I don't know if it'd be a
whole lot more it's certainly worth a
shot and then you can always say well
hey it didn't perform the way we wanted
it to so we're willing to sacrifice the
the transaction control but if but if it
does work fast enough why not keep that
transaction control that might work
better point so we've definitely talked
about implementing batch DML in node
Oracle db2 make it easier to more
efficiently insert and update records in
the database we just have this huge
queue of work and things we want to do
obviously we're looking after other
drivers we mentioned the Python a node
epi and we also got PHP etc there
and so although that's kind of high out
the list I really don't have any
timeframe for when that's gonna gonna
get in sorry about that but we are aware
that it would be useful for you let us
know how that experiment goes be curious
I
are there any other questions
any other high priority wishlist items
for the driver for no dark will they be
for for people using them see queuing
shake you
that wasn't me yeah I mean everybody has
a different use case I was just
interesting you know do people want to
do binding of objects to people on call
timeouts
you know we're seeing pushes for
sharding support and some of this is
something as simple than others to do
some was just a pass-through to the OCI
layer other things because OCI that
that's the Oracle call interface has a
lot of modes we have to kind of sit back
and really evaluate what's the you know
the 80/20 rule whatever what's the most
requests a bit so we don't just overload
everybody with a thousand options and
then we are trying to think about some
futures as well in the database and just
try to make sure we're sort of
simplifying things rather than making a
complex and getting rid of stuff so so
have a let me just continue talking so
there a couple of questions there from
Danilo about hosting packages
let me I'm just going to share my screen
I don't know what's underneath I'm gonna
steal it from you Dan and I'm gonna
share which is screen desktop one will
do and I can't see where the question
has got to get up there okay I can't see
the questions pop up anymore for
whatever reason since it's got blank on
that half the screen so yell out if
there any questions pop up so the bottom
line is that that some people do want to
self host packages and we have this
directory in the source code called
package which is the one that we use
when we're building the binary packages
should we stick that up there on github
so there are kind of a couple of a
couple of components when you do the
install nowadays and the version two of
node Oracle DB there's a sort of generic
package top-level package which is
hosted on the NPM repository and
yawn and places like that and that just
has the javascript files but no binaries
but it has an install target so when
this gets unpackaged by npm the install
target tries to go and download you know
a suitable binary for whichever version
of node and version of ODB and platform
etc etc so there two components there
and there's a make file in this
directory which I can show you which
actually we just use and a couple of
targets here the dependency checking is
not the best but it works pull requests
welcome and effectively you're going to
get out three variants of top-level
packages plus and you can get the binary
packages as well separate one for each
platform so by magic of setting a couple
of environment variables the difference
between this is what we call the sort of
generic package which is the one that
you're using when you do there are
production installs and this one we use
for internal testing is really just
where it goes to look for those binaries
when it downloads the binaries with that
install target and so you can just set a
couple of environment variables before
you run make or before you you build
this package and that will determine
where this package is going to look for
binary packages so you run NPM package
you run make binary package for
whichever platforms you want and as long
as you have these couple of environment
variables set before you do all of that
then you're going to end up with a
staging file and you can call this
anything you can move this anywhere and
then just add this to your dependencies
in your your package dot JSON file and
that would then install you know a
couple of quirks there to get the
plumbing right in terms of where it's
looking but that that's pretty much it
did any other questions pop up on the
zoom which as I say is kind of come
blank on the right hand side for me no
not yet
I did want to just mention or ask rather
I believe it was fondest that I was I
was talking with before about the
queuing one more idea just occurred to
me and I've done this in the past
where when when you make that HTTP
request and and you're ingesting that
data have you actually worked with that
as a stream and tried calling pause on
your incoming request
I haven't actually know so I've done
that myself in the past where that that
kind of goes back to the the built in
back pressure and we're talking about
streaming or piping streams it's sort of
something you get for free but if you do
need to drop down to lower levels the
node stream api's extreme expose methods
such as pause and resume and literally
at the HTTP de layer you can sort of
pause a stream and signal upstream that
they shouldn't send you more data yet
that may also be worth exploring if you
find using a single connection maybe
you're you're trying to buffer in sets
of 10,000 and and it's getting up to you
know 20 30 100 thousand you can't push
it to Oracle fast enough maybe just try
adding a few pauses until you get back
you know drop a note belief beneath a
certain threshold so then you're then
you're doing the buffering yourself that
may also work for you definitely gonna
try thanks a lot cool okay any other
questions actually I'll just get back to
that the question there I say about this
install again so the question just to
clarify is any of it you can build
pretty much binaries for any platform
architecture that you like
not just Linux 64 and node 6 or anything
like that we personally inside Oracle
and you push out 64-bit binaries just
because there's too much choice out
there we have to limit it somehow
everybody's coming to 64-bit but if
you're running on 32-bit you know that
those made binary packages well I'll
still work somebody asked me how rxjs
compares to other things would I what I
use it would I not let me just show you
something real quick on that this is one
of the websites I find myself going to
from time to time this is
in PM stat and it looks a little crazy
until you get maybe down to here where
you're looking at weekly downloads or
monthly downloads but this just kind of
shows you when you compare the async
module to rxjs there is definitely some
increased attention on on rxjs without a
doubt but the the number of folks using
async compared to rxjs
is just far greater and so my my
suggestion would be to start with
callbacks including async module then
get into promises and then async await
and if you find yourself in a situation
that requires rxjs maybe give it a shot
but I will say most folks it's a fairly
different way of thinking it's it's
going to kind of turn things around in a
way that you may not be ready for and I
would say that most folks aren't going
to use it for the little handy dandy
thing they need every once in a while
like they might do with a sink but
rather they're going to entirely reshape
their their application to be using this
our sink or rxjs paradigm so that's it's
not a small deal it's usually a bigger
deal and it's it's like a complete
application rewrite doesn't mean it's
not worth doing it's just a it's not as
trivial as bringing an async for thing
or two
you
you
key clicking I was not on mute just
trying to check out that stat site looks
really good
cool all right well I do not see any
more questions so I guess we'll go ahead
and call it there just say thanks again
to everybody for joining and hopefully
we'll see you in about another month
thanks Dan
thanks very much bye everyone take care
see ya bye bye well I might</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>