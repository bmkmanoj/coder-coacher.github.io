<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Eigenfaces Code - Intro to Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Eigenfaces Code - Intro to Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Eigenfaces Code - Intro to Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LgLYw-G4sLQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now for the next few videos I'm going to
show you an actual coded up example of
PCA as applied to facial recognition
this is taken and adapted from an
example on the SK learn documentation so
I'll include a link to the original code
so you can go in and take a look at it
but I want to walk you through some of
the most important parts so the first
thing that the code does is import a set
of pictures of famous world leaders from
about 10 to 15 years ago the next thing
that it does is it splits it into a
training and testing set very good but
then this block right here is where the
PCA actually happens you'll see in this
example and sometimes in the literature
that PCA is also called eigenfaces
when it's applied to facial recognition
so in this line here we actually see the
PCA being created
it's called randomized PCA and SK learn
and then it's also being fit to the
training data then what this line does
here is it asks for the eigenfaces
the eigenfaces are basically the
principal components of the face data so
it takes the PCA components and then it
reshapes them because right now they're
just strings of numbers and it wants to
turn those back into squares so that
they look like pictures you can also see
that the number of principal components
that are being used in this example is
150 and if you look at the example code
on the SK learn documentation page
you'll see that the original
dimensionality of these pictures is over
1,800 so we've gone from 1,800 features
down to 150 a compression factor of more
than 10 then the last thing that I do
with PCA is I transform my data when I
perform the fit command I'm just
figuring out what the principal
components are it's these transform
commands where I actually take my data
and transform them into the principal
components representation and the rest
of this code is creating an SVM remember
that SVC is what it's called an S Caylor
and a support vector classifier they do
a little bit of fancy footwork here to
figure out exactly what parameters of
the support vector machine they want to
use and then using the principal
components as the features they try to
identify in the test set who appears in
a given picture now I'll show you what
this looks like when I run this code
first thing that it does is it prints
out a doc string just tells me what's
going on and then some information about
the data set so I have 1288 samples with
1,850 features available to me in the
input feature space seven different
people are appearing and then we use 150
eigenfaces from the 960
faces in our training set the next thing
that appears is a list of the people in
our data set and how often we get them
correct precision recall f1 score and
support are things that are sort of
related to the accuracy their evaluation
metrics we'll talk a lot about those in
a coming lesson you can see that in
general though it's getting things
correct roughly 60 to almost 90 percent
of the time so even though we've reduced
our dimensionality by a factor of 10
we're still having really good
performance and then the thing that's
really cool that I love about this
example is they actually show you the
eigenfaces
so this is the first principal component
of our data this is the second principal
component the third one so this image
here represents the maximal variation
that it sees across all the data it's a
little bit hard to understand exactly
what that means in this example it would
be better if it sets something like how
far apart the eyes are or whether the
person wears glasses or not instead what
we get are these kind of ghost images
but then using these composite images
together as features in an SVM it can be
very powerful in predicting whose face
we see and then last but not least
there's a little printout that gives you
12 representative faces and the
algorithms best guess about who it is
and the actual answer so you can see it
doesn't always get them correct this one
right here it thinks is Tony Blair but
it's actually a George W Bush but on
most of them is getting it correct
pretty cool</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>