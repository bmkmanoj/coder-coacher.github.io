<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Defining Inductive Learning - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Defining Inductive Learning - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Defining Inductive Learning - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WYYe93__FpI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so we should take a moment to
define inductive learning so inductive
learning is is learning from examples
it's the kind of kind of learning
problem that we've been looking at the
whole time but we haven't been very
precise about all the various quantities
that we want to be able to talk about so
the number of properties that we
actually you know need to be thinking
about when we go and define what an
inductive learning problem is and and
measure what an inductive learning
algorithm does so one of them is just a
simple thing like what's the probability
that the training is actually going to
work you know whatever it is that it's
trying to produce it may be that in some
cases because the data is really noisy
or just you know got a got a bad set of
data it might not actually work so we
generally talk about a quantity like 1
minus Delta as the probability of
success Delta here obviously is a
probability of failure and this is just
1 minus M there's also issues like the
number of examples to train on how many
how much data does the to the algorithm
get to see dessert a letter you like for
that Charles um no okay is there a
letter you like I don't know sometimes I
like em for a number of samples but I
thought maybe you want you would want n
because you know things tend to grow
within yeah I did one in but then I
thought well we can't use in because we
use in for everything else there's also
something that we really haven't talked
about yet but you could imagine that the
complexity the hypothesis class might
matter why do you think that could come
into play Charles well if you don't have
a very complex hypothesis class and
there's some things well do mean
complexity the class or complexity of
the hypotheses in the class that's a
good question
we mean the complexity of the class or
the complexity of the hypotheses in the
class well well depends on how we
measure complexity but the complexity of
the class could be like the sum of the
complexities of all the hypotheses in
the class so it could be both hmm well
if you mean you know hypothesis class is
complexified has very complex hypotheses
then you could say well if you have a
hypothesis class that can't represent
much then it'll be hard for you to well
represent much be hard for you to learn
anything complicated so that's right
that's right what now could you see a
downside to having a complexity class or
sorry a hypothesis class that is very
very complex you mean like my daughter
sure I think you could it'd be much
easier to overfit right so getting
something that
he works well might be challenging you
might need a lot more data to kind of
nail down what your acted what you're
really talking about so it's a bit of a
double-edged sword all right so then
there's another issue as well you know
it may be easy to learn if you don't
have to learn very well so the accuracy
to which the target concept is
approximated often written as epsilon is
another thing that's going to be
important in understanding the
complexity of learning algorithm and and
so those are kind of the main complexity
related quantities that I wanted to talk
about but there's also some choices as
to how the learning problem is actually
framed there's the manner in which
training examples are presented and
there's the manner in which training
examples are selected for presentation
and we're going to talk about both of
these let me just first say that when I
talk about the manner in which training
examples are presented there's there's
two that I think are really really
important to look at one is batch and
that's mostly what we've looked at so
far that there's a training set that's
fixed and handed over to the algorithm
in a big bolus right a big group a big
batch a big batch exactly or it could
also be presented online so one at a
time so we say to the training algorithm
or the learning algorithm here's an
example and then it has to predict what
the label is and then the algorithm can
say oh here's what the right label is
let's try again here's another example
and it can go back and forth like that
we haven't really talked about
algorithms that work that way but it is
useful in the in the context of
computational learning theory to have
both kinds of algorithms I have
different sorts of behavior all right so
let's talk about the manner which
training examples are selected</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>