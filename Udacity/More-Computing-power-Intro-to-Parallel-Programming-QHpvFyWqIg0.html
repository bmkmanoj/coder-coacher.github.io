<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>More Computing power - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="More Computing power - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>More Computing power - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QHpvFyWqIg0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so one of the questions I ask the
students in the classes that I teach is
what are you going to do with a hundred
times more compute and sometimes that's
a really hard question for them there's
a lot of head-scratching
so both in terms of what can we do with
a supercomputer that's a hundred times
more powerful and what can you do with
something on your desk or in your pocket
where do you see us going in this
direction yeah well I have an insatiable
appetite for flops and so I would have
no trouble using 100 or even 1,000 or
even 10,000 times more compute you know
a lot of what I do is designing
computers and a lot of that involves
prototyping in simulation new computer
designs and I'm always frustrated by how
slow those simulations run and so if I
could run you know RTL simulations of a
new computer a hundred times faster it
would enable me to be much more
productive in trying out new ideas for
computer design same for circuit
simulations I spend a lot of time
waiting for a circuit simulation to
converge and if I could run it a hundred
times faster I could not just run one
simulation run whole parameter sweeps at
once and do optimizations at the same
time I'm simulating another thing is
also you look at sort of the computers
in your car I mean our our Tegra
processors are actually designed into
lots of different automobiles including
the the Tesla Model S the Motor Trend
Car of the Year but also you know Audi's
and via and BMWs and all sorts of Ford's
have Tegra is in them and the
applications people are starting to use
for these mobile processors and cars
involve having lots of computer vision
to look at what people inside the car
doing with people outside the car are
doing and in many ways it makes your car
is much safer by having the car aware of
what's going on around it many ways
compensate for the driver kind of not
being completely alert or perhaps
texting or doing something they
shouldn't be doing and in mobile devices
I think there a lot of compelling
applications in both computational
photography and augmented reality if
your mobile device is constantly aware
of what's around you it can be informing
you oh you know I think you're hungry
here's a place that has you know gear
O's that I know you like because I have
your profile of your likes and dislikes
maybe you should stop for lunch and or
you know a block a walk away is this guy
who you really don't like maybe you
should turn right at this corner
white avoid running into him and in many
ways I think it sort of evolves to
having your computing devices become
your personal assistant I always like
Jeeves in in the Iron Man movies I would
like to have you know a device I can
kind of talk to like that and is aware
of the environment around me and can you
know basically a brain amplifier for me
can sort of you know you know remember
things that I forget and tell me about
things in my environment and basically
assist me in going through my day both
on professional and personal basis so
one of the goals of the supercomputer
industry is to get up to the term they
use as exascale that they'd like to do
10 to the 18th flops per second and so
certainly NVIDIA is going to be
interested in being in those computers
what are we going to use that for well I
think first of all there's nothing
magical about an exascale it's like you
know we when we first made petascale
machines which is just a few years ago
it wasn't like breaking the sound
barrier or anything you know really
qualitatively change but it enabled
better science and and there's always
you look at sort of the fidelity of
simulations were able to do today you
know say to simulate a more efficient
engine for automobiles to improve gas
mileage and we're making lots of
approximations to fit them on the
supercomputers we have today as we can
get to higher fidelity by resolving
grids finer and modeling a bunch of
effects like turbulence more directly
rather than using macro models to model
them we'll get more accurate simulations
and that will enable better
understanding of you know combustion in
some of the biotech applications of how
proteins fold
you know how the various other you know
climate climate modeling sure how
climate evolves and and basically as we
as we get better computing capacity and
it's not not you're reaching a magic
exascale and wonderful things happen but
at every step along the way we get
better science we are able to design
better products and computing is a big
driver of you know both scientific
understanding and economic progress
across across the board I think it's
very important we maintain that steady
march forward an exascale is just one
milestone along that March and my
understanding is that power is really an
enormous ly crucial thing for them to be
get to get right to be able to enable
the exascale but we don't want machines
that are going to cost two million
a month just to plug in right it's
really an economic argument I mean if
you really wanted an exascale machine
today you could build one you just have
to write a really big check and locate
it right next to the nuclear power plant
the entire output of which it will
consume but I think if there's some if
there was some application that was so
compelling they were willing to really
you know you write the multi-billion
dollar check required to do that you
would you would do it I think what the
real question of exascale is is an
economical exascale and because on total
code on total cost of ownership the
power bill is a tremendous fraction so
it's not actually an economical exascale
machine unless you can do it for a
reasonable power level and then the
number that's been thrown out is 20
megawatts and and so that's 20 million
dollars a year yeah 20 million dollars a
year power bill if you're paying roughly
10 cents a kilowatt hour and in fact the
bill actually winds up usually being a
little bit higher than that because the
cost of provisioning energy amortized
over say a 30-year lifetime of the
facility usually is about equal to the
annual bill for the energy there's also
something called the the PUA which is
basically the efficiency of providing
the energy even for a very good
installation today maybe you know on the
order of one point one to one point two
so you pay another say 20 percent to run
the air conditioners and fans and things
like that in the facility and it's
basically energy or consuming it isn't
being consumed by the computer but it's
a big challenge for us to get from you
know say Sandy Bridge today that's 1.5
nano joules per per instruction to if
you wanted to do an exit instructions
per second and to do an exaflop you may
have to do more than an exit
instructions per second but even if you
take that as a thing at 20 megawatts
that's 20 Pico joules per instruction
and that's not just the processor that's
everything that's the memory system
that's the network that's the you know
IO storage system it's the the whole
ball of wax has to do that you may only
get 10 pica joules per instruction to
actually use in the processor so that's
and so even in videos not not quite
close enough to that yeah well compared
to Sandy Bridge that's a factor of 150
down and that's why and process isn't
going to help you much so that's why you
know conventional CPUs are not going to
get there it's going to require a hybrid
multi-core approach with most of the
work being done in a GPU like throughput
processor to get there but even we have
a ways to go you know or probably close
to an order of magnitude and we might
get a factor of three from process so we
need to be very clever to come up with
the other factor of three or four that
we need now Titan does have CPUs in it
yes that's correct so is there a vision
where that won't even be the case now I
think that there are always pieces of
the code where you have a critical path
you have a piece of single thread code
that you need to run very quickly and so
you always need a latency optimized
processor around to do that but most of
the work it's one of these things it's
kind of like a cache memory where most
of your accesses are to this little
memory that runs really fast but you
still need the capacity of the big
memory sitting behind it right and so
it's the same thing on throughput versus
latency most of your work is done on the
throughput processors but when you do
have a latency critical thing you wrote
it on the latency optimized processors
and so you wind up getting the critical
path performance of the CPU with the
bulk of the energy consumption of the
GPU and the bulk of the flops and Titan
is certainly going to write the bulk of
the flops will be on the GPS</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>