<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Identification Trees - Georgia Tech - KBAI: Part 4 | Coder Coacher - Coaching Coders</title><meta content="Identification Trees - Georgia Tech - KBAI: Part 4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Identification Trees - Georgia Tech - KBAI: Part 4</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/c5HJT1H8a2c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it is one of the method we can use to
process the kind of the data that we
just saw is sometimes called decision
tree learning recall that when we were
discussing case based reasoning we
talked about discrimination tree
learning there we learn the
discrimination tree incremental a case
would come one at a time and we would
ask the question what feature would
discriminate between the existing cases
and the new case in a replica feature
discrimination Kree learning provides no
guarantee of the optimality of this tree
that is to say at retrieval time when a
new problem comes along travels in this
tree might take a long time because this
tree is not the most optimal tree for
storing these cases we'll discuss an
alternative method called decision tree
learning which will give us more optimal
trees however at a cost the cost will be
that all the examples will need to be
given right at the picnic let us return
to a restaurant example we want to learn
a decision tree that will classify this
five examples so that as the new problem
comes along we can quickly find which is
the closest example to the new problem
to do this we need to pick one of the
four features restaurant meal gay or
cost that will separate these allergic
reactions so that one category contains
either only false instances or only true
instances as an example supposing we
think of restaurant as being a decisive
feature so we have picked restaurant as
the decisive feature now there are three
kinds of restaurants Kim's Bob's and
Sam's whenever it's Kim's restaurant
Bob's restaurant there is no allergic
reaction whenever it is Sam's restaurant
they can be allergic reaction shown in
green here or no allergic reaction shown
in red so the good thing about this
particular feature restaurant is that it
has separated all the five examples into
two classes and do the class Sam's and
to the class not Sam's you're not Sam
class consists of only negative
reactions which is good because we know
that we have not been able to classify
all of these five examples into two sets
one of which contains only negative
examples now if
these three examples we must pick
another feature that will separate them
into positive and negative instances in
this case we might consider costs to be
that feature when the cost is cheap then
we get positive examples when the cost
is expensive then we get negative
examples this is the classification tree
and if it is a very efficient
classification tree when a new problem
comes along for example visit six Sam's
lunch Friday cost is expensive and we
want to decide what the allergic
reaction might be we simply have to
travel through the scree to find out the
closest neighbor of that particular new
example this is called a decision tree
and this technique that we just discuss
is called decision tree learning this
method of inductive decision tree
learning work much more efficiently and
apparently more easily then earlier
method we had discussed but the crate
office if we needed to know all the five
examples right in the beginning of
course this technique simply appears to
be efficient and easy and that is
because we had only five examples and
only four features that were describing
all five examples but the number of
examples was very large or the number of
features describing each examples were
very large then it's very hard to decide
what exactly should be the feature that
we should use to discriminate on</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>