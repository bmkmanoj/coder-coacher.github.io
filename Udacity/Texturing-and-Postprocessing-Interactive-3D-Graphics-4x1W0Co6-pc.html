<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Texturing and Postprocessing - Interactive 3D Graphics | Coder Coacher - Coaching Coders</title><meta content="Texturing and Postprocessing - Interactive 3D Graphics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Texturing and Postprocessing - Interactive 3D Graphics</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4x1W0Co6-pc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I haven't talked about texture access
and fragment shaders the short answer is
you can access textures and fragment
shaders the theory of sampling and
filtering is the same as you've already
learned in previous lessons most of the
rest is just the syntax of setting up
the texture axis the key bit is that in
the shader you use the texture 2d
function this gives back a color from
the texture which you then use as you
wish search the 3 j's code base for this
keyword and you'll find more than 40
shaders that use texture axis the main
file for material shading is WebGL
shaders jas and it's worth your time to
give it a look if you want to become
better with shaders the other function
to look for is texture cube for cube
maps which takes a 3d direction as an
input many of the rest of the shaders
perform image processing where the
pixels of the image are used to form
another image let's take a concrete
example you want to convert a color
image to grayscale the formula is
luminance equals this much red this much
green and this much blue this formulas
for linearized colors and luminance is
intensity the grayscale there's also
another formula for luma for when the
inputs are not gamma corrected it's
surprising to me that in both formulas
how important green is and how little
blue matters whichever formula you use
you might think you could simply add it
as a final step in a fragment shader
however transparency again is a problem
you want to apply this formula as a post
process that is you want to convert to
greyscale after the whole scene is
rendered but by then it's too late the
image has already been sent to the
screen well in fact you can send the
image off-screen and have it become a
texture this is called simply an
off-screen texture pixel buffer or
render target this texture is not
typically a powers of 2 texture it's not
normally 512 by 512 or anything that
you'd use to make a MIT map chain our
goal is to perform image processing on
the so called texture we want to read a
pixel and convert it to gray you think
there'd be some mode that could just
take one texel and spit it out to a new
pixel but the GPU is optimized for
drawing triangles and accessing textures
the way we use this texture is by
drawing a single rectangle with UV
coordinates that exactly fill the screen
you'll hear this called a screen fill in
quad the UV values are then used in the
fragment shader to precisely grab the
single texel that corresponds to our
final output pixel on the screen 141
this sounds inefficient and in a certain
sense it is but this process is fast
enough
but often a considerable number of
post-processing passes can be done in
each frame in three Jas the effect
composer class lets you create and chain
different passes together with just a
few lines of code for our grayscale post
process the vertex shader is along these
lines this is almost as simple as a
vertex shader can get it copies over the
UV value and projects the screen filling
quadrilateral to clip coordinates the
whole point of rendering the rectangle
is to force the fragment shader to be
evaluated every pixel the fragment
shader code is also quite simple the
texture is accessed by the screen
location essentially so each texel will
be associated with its corresponding
output pixel we use the color of this
texel to compute the grayscale color in
this case using the LUMO equation this
color is then saved to the fragments
output color and we're done but we don't
have to stop there multiple post process
passes can be done and it's often
necessary or even more efficient for
example a blur can be done in two passes
a horizontal blur and then a vertical
blur doing so results in fewer texture
lookups than a single pass multiple
passes can be quite memory efficient as
the input texture from one pass can
become the output texture for the next
and vice versa this process is called
ping ponging as the flow of data goes
back and forth here the horizontal blur
uses the left image as input the right
for output the vertical blur uses the
right as input left as output say we now
want to convert to greyscale we add
another pass and reverse the direction
again here's an example of greyscale in
action the critical idea here is that we
can do all sorts of things in this
fragment shader we can sample nearby
texels and blend them together to blur
the image detect edges or a hundred
other operations we can chain together
each post process to feed the next this
demo by Felix Turner shows some of the
many effects you can achieve three j/s
in fact has lots of post processing
operations in its library and it's easy
to add your own I highly recommend
looking at the additional course
materials for links to Felix's tutorial
and other worthwhile resources</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>