<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Issues to be handled by the Runtime - Georgia Tech - Advanced Operating Systems | Coder Coacher - Coaching Coders</title><meta content="Issues to be handled by the Runtime - Georgia Tech - Advanced Operating Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Issues to be handled by the Runtime - Georgia Tech - Advanced Operating Systems</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/279iQAnQTgM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">lots of work to be done by the runtime
system to manage a MapReduce computation
the master data structures include the
location of files created by the
completed mappers remember that each
mapper is working on some node of the
computational cluster producing its
output as files on its local disk so the
master has to have a knowledge of where
those files reside created by those
mappers and the namespace of the files
that have been created by the mappers
and it also has to keep a scoreboard of
the mappers and reducers that are
currently assigned to work on different
splits because the number of machines
that may be available may be less than
the total number of machines that will
be needed if I wanted to do all of the
input M splits in parallel and all of
the are output splits in parallel and
therefore the scoreboard is seeing at
any point of time who are all the
workers scurrying out map of functions
who are all the workers scurrying out
the reducer functions when are they done
and when they are done how should I
reassign that worker to a new task so
these are the kinds of things that the
master data structures facilitate the
master to do then the big thing is fault
tolerance for a variety of reason the
master may find that an instance of a
map function that it started is not
responding in a timely manner maybe that
node is down for some reason maybe the
link is down for some reason or maybe
that processor is taking a little bit
more time than what the master expects
it can happen very easily because in a
data center environment where you have
thousands of machines there could be
some machines that are slower than other
machines there could be generational
differences between the machines that
populate a data center even though there
may be homogeneous in terms of the
capabilities programming environments
and even the machine architecture they
may have speeds that are different
because they correspond to different
generations of processes in any event
what might happen is that a master may
notice that there is no timely response
from a particular instance let's say of
a mapper in that case it might say well
I'm going to go ahead assume that that
mapper is dead I'm going to restart that
mapping function on a different note of
the cluster now when that happens it is
possible that the original mapper is
actually dead or it could be that it was
just slow in that case you could get
completion message from more than one
mapper for the same split so when you
get multiple completion messages from
redundant stragglers the master has to
be able to filter the mod and say ah
this is something that is a redundant
work I don't have to care about that so
that's part of fault tolerance that the
master has to worry about locality
management is another important thing in
the memory hierarchy making sure the
working set of computations fit in the
closest level of the memory hierarchy of
a process is very important and this is
another thing that has to be managed
very carefully so that the computation
can make good forward progress in
completing the MapReduce function there
is an inherent assumption in the fault
tolerance model of the MapReduce
framework and that is idempotent see of
the mapper that is even though the same
input data split is being worked on by
multiple mappers it doesn't affect the
semantics of the computation as a whole
and that is the reason why the master
can simply ignore the redundant
stragglers message if in fact it was a
slow computational engine that was
working on a particular map function and
if it finishes later then when it was
supposed to and the master has already
started another redundant computation to
take care of that particular split
ignoring that redundant straggler
message is okay because of the item
the assumption about the mapping
operation in a similar manner the master
may assign a new node the carryout
reduced function corresponding to a
particular split if there is no timely
response from one of the reduced workers
and here again the output file
generation that is associated with a
particular reducer split depends on the
atomicity of the rename system call that
is used to finally say that oh this is
the output file generated and the master
says okay I'm going to commit this as
the real output file of the computation
each reducer is writing a local file and
finally when the master gets a
notification from the reducer that it
has completed its work at that point
master renames that local file as the
final output file and this is where it
can get rid of redundant stragglers who
come along later and say I produce the
same output file for the same split
master will say I've already got it I
don't need this and it can ignore the
completion message from that redundant
straggler the other thing that the
programming environment has to worry
about is locality management and this is
accomplished using the Google file
system that provides a way by which
efficiently data can be migrated from
the mappers to the reducers task
granularity is another important issue
as I mentioned the number of nodes
available in the computation cluster may
be less than the sum M plus R where m is
the number of input splits and r is a
number of reducer splits and it is a
responsibility of the programming
framework to come up with the right task
granularity so that there can be good
load balance of the computational
resources and the programming framework
also offers several refinements to the
basic model the way the partitioning of
the input data space is done is by using
a hash function that is built into the
programming environment but the user can
override that partitioning function
with his or her own partitioning
function if they think that that will
result in a better way of organizing the
data and in the MapReduce framework
there is no interaction between the
mappers but if there is some ordering
guarantees that are needed in terms of
ordering the keys and so on that is
something that the user may have to take
care of the other thing that the user
may also do is combining a partial
merging to increase the granularity of
the tasks that executes his mapping
function remember that when we looked at
the simple example of looking for
specific names in an input corpus of
data I mentioned that the mapper can be
as simple as emitting a 1 for a value
every time it encounters the name
Kishore for instance in an input file or
it could take an input file and count
all the occurrences of kishore in their
input file and finally emit the total
value as the output of the mapper that
kind of combining function is something
that a user may choose to incorporate in
writing his mapping and reduced
functions it is very important to
recognize that in order for the fault
tolerance model of the programming
environment to work correctly map and
reduce functions have to be idempotent
that's a fundamental assumption that the
fault tolerance model of the programming
framework is based on and there are also
other bells and whistles in the
programming framework for getting status
information and logs and so on and so
forth but the basic idea I want to leave
you with is the fact that the
programming framework is a very simple
one it has two operations map and reduce
and using those two operations you can
specify a complex application that you
want to code up to run on a data center
using the computational resources it's
available in the data center</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>