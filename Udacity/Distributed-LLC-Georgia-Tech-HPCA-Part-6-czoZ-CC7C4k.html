<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Distributed LLC - Georgia Tech - HPCA: Part 6 | Coder Coacher - Coaching Coders</title><meta content="Distributed LLC - Georgia Tech - HPCA: Part 6 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Distributed LLC - Georgia Tech - HPCA: Part 6</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/czoZ-CC7C4k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so a distributed last level cache is
logically a single cache in that a data
block will not be replicated like it
would be in private caches where if two
or three or four cores for example read
a block each of their caches would have
that block and thus really the total
capacity of the caches is not how much
memory we are covering because some
memory appears many times possibly in
these caches a last level cache that is
distributed is logically still one cache
meaning if its capacities let's say four
megabytes then we really cover four
megabytes of memory without any
replication but this distributed cache
is sliced up so that each tile which
contains a core and possibly local
caches now also contains a part of this
cache so now what we have is in our mesh
we have a tile that contains a core a
level one cache a level two cache and a
slice of the l3 cache so if this slice
here that we use per core is let's say
one megabyte it's really N times one
mega bytes where n is the number of
course so now as you can see if we use
four cores we get four megabytes with 16
cores we have 16 megabytes so we get
what we want the big cash that is there
to prevent memory accesses is growing
with the number of course but it doesn't
have a single entry point in fact each
slice has its own entry point so if we
want the data that is in this slice we
have to route our message to that slice
if we want the data that resides in
another slice we send a message there if
the data is spread among the slices so
that all of them get equal demands for
the data then the network traffic would
be nicely distributed across our chip so
that none of the links get over utilized
but if we have a level-two miss in a
particular core how do we know which
slice of the level three cache to ask
for the data one simple solution is to
spread the cache around robbing among
slices by cash index so if we have our
level three cache with let's say 1,024
sets slice zero gets set zero slice 1
gets set 1 etc and then let's say that
we have 8 cores then slice 7 get set 7
slice 0 get set 8 set 9 is in slice 1
again and so on so now we can relatively
easily after we break down the address
to access the cache we know the set
number and the least significant 3 bits
in this case tell us which slice to ask
if we have even more cores then the
number of sets in the cache will grow
and as a result the number of bits that
we need to tell us which slice we have
is growing and that means that the
number of bits in the index are growing
and we will need additional bits to tell
us in which set to look note that if we
sequentially access data then we will be
really looking at you know one set and
then the next set and then the next set
and this nicely spreads the load among
the slices of the level 3 cache because
sequential accesses are basically going
to be spread across the entire chip
however the spreading of blocks
round-robin across the entire chip may
not be good for locality because a core
is just as likely to access something
that is in the opposite corner of the
chip as it is to access its own slice in
which case there is no on chip network
traffic whatsoever so another way that
can help with that is that we spread the
data around but this time we spread it
by page number so all of the blocks that
belong to the same page would end up in
the same slice of the level 3 that helps
because now the operating system can map
pages so that it makes the access is 2 L
3 more local for example here this score
is running a thread that has a stack the
pages that belong to that stack should
be those that end up in this slice so
that if you have a level 2 mess we are
very likely to access our own local
slice of the l3 cache of course some of
the shared data will be us elsewhere but
this dramatical
improves the locality in terms of how
far do we need to go to get to the
correct slice of l3 any data that tends
to be accessed by one core can be now
mapped by the operating system so that
it's usually found in the local slice of
the last level cache</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>