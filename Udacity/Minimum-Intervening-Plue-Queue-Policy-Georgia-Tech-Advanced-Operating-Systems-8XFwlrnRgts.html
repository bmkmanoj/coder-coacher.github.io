<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Minimum Intervening Plue Queue Policy - Georgia Tech - Advanced Operating Systems | Coder Coacher - Coaching Coders</title><meta content="Minimum Intervening Plue Queue Policy - Georgia Tech - Advanced Operating Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Minimum Intervening Plue Queue Policy - Georgia Tech - Advanced Operating Systems</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8XFwlrnRgts" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so that's your minimum intervening
scheduling policy that is ensuring that
the processor that is picked for TI to
run on has the highest affinity for TI
that's the minimum intervening and
there's a variant of minimum intervening
which is called limited minimum
intervening which is essentially saying
that if I have let's say thousand
processors in the multi processor then
the amount of information that I want to
keep for every one of these threads is
huge right for every processor that is
available in the multi processor I need
to keep this affinity index for the
thread that may be too much metadata
that the scheduler has to maintain on
behalf of every thread and therefore the
me there's a variant of minimum
intervening which is called limited
minimum intervening which is saying
don't keep this affinity index for all
the processors just keep it for the top
few processors so the affinity index if
it is two or three those are the ones
that I care about
if the affinity index is 20 or 30 I'm
not gonna pick that so why bother
keeping all of the affinity index for a
particular thread just keep the top
candidates that's the idea behind
limited minimum intervening scheduling
policy the last policy I'm going to
introduce you to it's called minimum
intervening plus queuing
the idea is still the same that I want
to look at were the intervening threads
that ran on a particular processor with
respect to this thread that I'm trying
to schedule at this point of time but
when I make a scheduling decision that
Tia is going to run on a particular
processor it may be that this particular
processor PJ may already have some other
threads that are going to run on it and
that's the idea behind minimum
intervening plus Q again I want to
explain this a little bit more detail so
in minimum intervening scheduling plus
queuing what we are saying is it's not
only the affinity index of Ti with
respect to a particular processor that
I'm going to look at but I'm also going
to look at the queue for this particular
processor why do we need to do that well
if Ti is going to be scheduled on on
this particular processor PJ maybe there
is a schedule in curacao
with PG which already has some number of
threads to be run and therefore even
though I'm picking the process of PJ
based on cash affinity by the time TI
gets to actually run to other threads
are gonna run before it
so this was when TI ran last and i might
find that the affinity for TI with
respect to pj is to just like in this
previous example that i gave you the
affinity is two so it looks like a good
choice to put TI on on pj if p if this
turns out to be the minimum but when i
make the decision what i'm gonna do is
i'm gonna stick this thread TI in the
scheduling queue of PG and if the
scheduling queue of PJ has TM + TN
already populated then what's gonna
happen time is now but by the time TI
gets to run on the processor PJ TM and
TN would also have run on the processor
right so even though the affinity index
that I computed at the point of the
scheduling decision this is a scheduling
decision at the scheduling decision I
made a decision to put TI on PJ based on
its affinity with respect to processor
PG but unfortunately the reality is that
Ti is not gonna run immediately but it
was gonna run much later in time and by
the time it gets to run two other
threads that are already sitting in the
queue of PJ they're gonna run and
therefore the cache will be more
polluted than what we thought it was
going to be at this point of time so
that's the reason that this scheduling
policy is called minimum intervening
plus Q saying that not only should you
take into account the affinity index of
a thread with respect to a particular
processor but you should also look at
the queue of the processor and ask the
question is the queue already populated
in that case the the processor that I
want to pick TI to run on is the men of
AI + Q where AI is the affinity index
and Q is the size of the scheduling
queue associated with this petty
processor PJ so that's the last
scheduling policy so we basically have
introduced five different scheduling
policies first-come first-serve
fixed processor last processor minimum
intervening and minimum intervening plus
queuing and as I mentioned these two
scheduling policies will really not be
having the information for at thread
with respect to all the processes in the
system because in a large-scale
processes may be infeasible to do that
so what you do is you limit the amount
of information that you keep for every
one of these threads remember one of the
attributes of a good operating system is
to make a decision very quickly and get
out of the way and from that point of
view the less information it has to sift
through in order to make a scheduling
decision the faster it can do its work</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>