<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Host-GPU Interaction - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Host-GPU Interaction - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Host-GPU Interaction - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/m9eGhIBJRUg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">finally let's talk about optimizations
at the whole system level including the
interactions that happen between the
host and the GPU so on most systems the
CPU and the GPU are on different chips
and they communicate through something
called a pci express bus or PCIe for
short today for example most systems are
PCI Express gen 2 which can in practice
get about 6 gigabytes per second maximum
in either direction now PC I can
transfer memory that has been paged
locked or pinned and it keeps a special
chunk of pinned host memory set aside
for this purpose so when you have a
chunk of memory that you want to copy
over to the device memory on the GPU
CUDA first has to copy it into the
staging area before it can then transfer
it over the PCI Express bus onto the GPU
this extra copy here increases the total
time taken by the memory transfer
instead you can use the cuda host malloc
function to allocate pinned host memory
in the first place such that the memory
you've got sitting on the host is
already ready to copy directly over
without this additional staging step or
you can use the cuda host register
command to take some data you've already
allocated and pin it again avoiding the
extra copy to take it into GPU memory so
that's why you care memory transfers
from the hosted device can go faster if
you pin the memory first and if you're
transferring pinned memory you can use
the asynchronous memory transfer CUDA
min copy async which lets the CPU keep
working while the memory transfer
completes how does that work well with
khuddam in copy which you've been using
until now you make a call to khuddam in
copy you pass it some information like
the pointers and the size and bytes and
whether this is a transfer from device
to host or device or hosted device and
then there's a semicolon at the end of
that statement and with CUDA min copy
the CPU blocks until the transfer
completes with khuddam MKA sync when it
hits the semicolon it just keeps going
this kicks off an asynchronous memory
transfer that continues to go on while
control returns to the CPU and the
program content the CUDA program
continues executing in other words the
CPU can keep getting work done while
this memory transfers so to control that
asynchronous interaction we have to
introduce the next topic an host GPU
interaction
and that streams</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>