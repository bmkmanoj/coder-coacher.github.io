<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>APOD Part2 - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="APOD Part2 - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>APOD Part2 - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lo2pKyVfDX8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so the analyze stage is really all about
profiling the whole application looking
not just at the kernels that you intend
to parallelize but looking at the whole
thing and trying to figure out where can
this application benefit from
parallelization right and how much can
you expect to benefit so once you've
decided that there's a region of the
code that you need two parallel eyes of
course there's different approaches to
doing this certainly no code is better
than the code you don't have to write it
all so if you can find that there's a
parallel library for the GPU that
already does exactly what you want then
great you're done you can simply call
out to that library sometimes you have a
lot of code and you want to be able to
instrument it you want to do a minimal
amount of work to get a little bit of
parallelization there's an approach for
this called directives the most
well-known one on the CPU is called open
MP there's another cross-platform
standard called open ACC which has
emerged which ACC stands for accelerator
this is sort of an extension of OpenMP
to encompass the ideas of accelerators
like the GPU and so if you're looking at
GPU programming open ACC is a really
lightweight way to experiment with it
but of course sometimes what you want to
do is actually go in and write a
parallel routine and naturally that's
what we've been focusing on throughout
this course using CUDA C++ so of course
we're gonna we're gonna focus here so
assuming that you're going to be coding
at something up from scratch for this
purpose the next choice is how to pick
an algorithm and this is a huge deal
this is your real chance to make a huge
improvement pick the right algorithm so
all the bit twiddling optimization in
the world won't gain gain you nearly as
much as choosing the right sort of
fundamentally parallel friendly
algorithm I'll give a couple of simple
examples in this unit and you'll see
more examples in unit 6 there's no
recipe for picking the right algorithm
what you need to do is sort of think
deeply about what is the parallelism in
your problem but will try to give you a
few examples of that so that you have a
little practice so once you've decided
how to parallelize your algorithm then
you want to optimize the code and there
will be sort of a cycle between these as
you'll see in the example you try a
parallelization study how well it does
you know suggests some changes that
might suggest a way that you approach
the parallelization differently so we're
really talking about profile driven
optimization by which I mean measure it
measure measure measure measure how fast
things are going
and use that to base your decisions
don't just sort of take a guess at
what's going to work well and what
doesn't and finally the deploy step so
you know look in this class we do these
little homeworks and they're fairly
self-contained so that you can get them
done in a reasonable amount of time so
the the process of actually deploying a
GPU accelerated code into real use is
not going to come up a lot in this class
so so consider this just sort of free
software engineering advice you know
when you're working on a real code it's
a really really bad idea to optimize in
a vacuum and what I mean by this is that
you can really you can easily spend tons
of time adding tons of unnecessary
complexity to your code speeding up a
kernel way past the point where it's no
longer a bottleneck and it's just
fundamentally a good idea to push any
improvements through to the end code
you're making it real by doing that and
making it real as soon as possible
ensures that you're running and
profiling and paralyzing and optimizing
real workloads and the other thing to
remember is that you know even small
improvements are useful if your code is
if you make your code 50 percent faster
or two times faster or four times faster
that's useful and you can push it out to
the users of your code you can start
employing it and making it real even if
you think that there's a factor of 20
times speed-up in the wings you know
really the the advice here again is is
be disciplined
you know analyze what you're doing you
know decide how you're going to parallel
why's it decide how you're gonna
optimize it by studying that code you
know and measuring it using using
profile driven optimization and finally
you know be sure to deploy frequently
okay so so I deploy early and often
remember that this whole thing is
intended to be a cycle</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>