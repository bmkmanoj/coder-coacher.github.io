<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Generic Gesture Recognition | Coder Coacher - Coaching Coders</title><meta content="Generic Gesture Recognition - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Generic Gesture Recognition</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/a2FjfUWdhFA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I actually pulled out an older piece of
work focusing just on the gesture this
is by Nam and one of recognising hand
gestures using some hmm just because it
was very partic of how people would do
things what was kind of cool about their
system was they had a bunch of different
gestures that they wanted to indicate
like nouns
you know chairs vaz lamp ball because of
course that's a natural vocabulary I
have no idea and then you want to do
things like put it down or bring it or
put or discard or jump I don't don't
even know why that was a particular verb
that they wanted to use but the idea was
that there was a fixed vocabulary the
inputs that they were going to use and
they were gonna control with the hand
was a couple of different kinds right
they had something to do about hand
configuration or posture something to do
with how your fingers were shaped okay
they also had how you were holding your
palm and then they had a sequence of
hand position a motion okay and they
wanted to use all of this information to
make a decision about what gesture you
were indicating so the first thing you
should ask is how are they getting this
information how are they getting this
information boy Megan woke up well they
were using something called a dated
glove here's a picture so a dated glove
is this thing that you could wear on
your hand that had both accelerometer
gyro information about how it was being
globally manipulated and also knew
something about how you were moving your
fingers so they built this kind of
interesting system and the reason I
liked it is they actually are using
these three sensors the the angles the
orientation the position right and
what's interesting is they used the hmm
just to get information about that
motion trajectory right they had other
methods of putting into their system how
your orientation was changing and what
the angles were right so the idea is
that you might have some basic overall
probabilistic integration system and in
order to make use of that you needed
things that would output
the probability or the likelihood of
getting a particular movement for a
given gesture and hmms were exactly the
kind of thing to use for that
in fact discriminative methods might
have been harder to use for that because
they need to combine these probabilities
so here was something very simple that
they did they took the I should say very
simple here's what they did it required
some engineering you take your raw data
which was a trajectory that you would
move an X Y Z the first thing they did
was they said well you know your gesture
is pretty much planar right the plane
could be this way it could be this way
but the idea is that a single gesture
didn't move in more than a plane I might
even go like this but you'll notice even
this figure eight is in this plane
alright so they find the plane that the
gesture fit best to project it down and
then they did a what's called a chain
code we didn't actually talk about chain
codes if you did some machine vision you
would learn about chain codes it was a
way of encoding a contour as being you
know maybe you could only take one of
eight steps right so you go up you get
you go you take a direction north you go
northeast you go east east east south
south east south west and then
eventually call around and you could
think of the entire contour as a
sequence of discrete steps right so
north east south right so sequence of
discrete symbols aha hmm so they trained
a very simple left-to-right hmm
left-to-right meaning that you go
through every state and you don't skip
states you have these loopback things
because you may stay in a state for a
while where essentially you're going
kind of let's suppose you were going
north northeast but you didn't have that
as direction well north northeast that
state you might sometimes put out north
sometimes put out north east etc
whatever but you'd stay in that state
for a while it would output there'd be
two symbols that it could output it with
high probability but that state for
example would never output south ok so
that would be you'd stay in a state for
a while so they trained up these HMMs
and they did one hmm four sort of each
Jess
okay they also did some stuff that had
to do with what they call junctures
doing transitions between gestures so
that it could parse them I don't think
I'll talk about that here I just will
say that people hook up multiple HMMs
together to form sort of an hmm that can
deal with a sequence of gestures and
it's it's not too much more complicated
than the original hmm so they do that
and then they test it and because
they're testing it on a very controlled
vocabulary using features defined to
work because they want their paper to be
accepted okay
you see results that look like this okay
so here they're hits this is the
percentage of the hits are the
percentage of the actual targets that
were correctly labeled misses are when
you don't label a thing correctly and as
you can see they're doing tests of over
a hundred of each of these examples and
almost all of their gestures are
recognized with a relatively high
accuracy you can see there were one or
two that was that were not so high and
what and showing a table like this is
one thing a slightly more interesting
table might be a confusion matrix this
is like we showed for the SVM's for the
bag of words where if you go back and
take a look at the slides you'll see a
table that says how often is an airplane
confused as a face or that kind of thing
normally if you're gonna report results
about doing classification don't just
provide hits and misses also provide a
confusion matrix because sometimes the
actual source of the performance is that
some of the categories were much more
confusable than the others you have no
way of knowing that if you just report
sort of performance rate overall but you
need to be able to see the the confusion
with which which elements or which
categories were confused with which
categories</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>