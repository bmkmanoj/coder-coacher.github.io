<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Merrills Linear-Complexity BFS on GPUs Part1 - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Merrills Linear-Complexity BFS on GPUs Part1 - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Merrills Linear-Complexity BFS on GPUs Part1 - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Dq0ImVxQsRo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so when the discussion on graphs I made
the following statement let me quote
myself if we had a graph that was just a
linear chain the last node would be node
n minus 1 the linear chain is very hard
to paralyze if we're doing a BFS here
it's going to take us order of n steps
to get to the end of the graph end quote
let me state this problem another way I
have n nodes in a linear chain and each
node knows the ID of the next node in
the chain this is just a simple linked
list what is the algorithm for each node
every node finding the end of the list
and so of course we can solve this and
in steps let's say that each node has a
next pointer and I've shown those in
blue that points to the next node in the
chain and the last node has next equals
null now we don't want to change the
next pointers at all or else we'll lose
the structure of our list so we're going
to assume they're read-only so we're
also going to store a second pointer per
node that we can change for historical
purposes we'll call this pointer Chum
and we're going to designate it in red
and at the end of the algorithm we want
each nodes Chum a pointer to point to
the last node in the chain so the
straightforward algorithm is on each
iteration on each node set Chum to Chum
to next until we reach a node where next
is null so we'll start off by making all
Chum pointers point to their own nodes
that's how we're going to initialize
them and again on each iteration we will
set Chum to the next pointer so in the
first iteration it's going to look like
this so now we're going to do another
iteration so for any particular node we
look for Chum and then next so on the
second iteration it's going to look like
this and so on and so on so on each
iteration the length of the Chum pointer
is going to be one more than it was on
the iteration before so the question is
the important question is can we do
better and it turns out the answer is
yes and this algorithm described by
Danny Hillis and guy Steele in 1986 not
discovered by them but described very
nicely is so cool that it's one of the
reasons that I decided to do parallel
computing in the first place so let's
analyze the complexity of the algorithm
that we just described clearly the
serial processor can do this computation
and in steps in order of n work how
about the parallel processor we know
it takes n steps how much work your
choices are order of n in log in n
square root of n or n squared</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>