<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Minimum Description Length - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Minimum Description Length - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Minimum Description Length - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bw9O7FlsL0g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right Michael so I all I've written
up here for you is our maximum
a-posteriori equation right so the best
hypothesis is the one that maximizes
this expression nothing new right so I
want to do a little trick the same trick
that you did before so you notice that
when we had e to the something that we
could use the natural log on e to get
rid of everything so I'm going to try to
do the same thing here and then that why
did the natural log work again well it's
the inverse of the e but it also let us
turn products into sums right and the
other reason it worked is because it's a
oh it's monotonic right it's a monotonic
function and so it doesn't change the
arc max so I'm going to do the log of
both sides here but this time I'm going
to do log base two for no particular
reason other than it'll turn out the
help later so I'm just going to take the
log of this of this entire expression
which because it turns products into
sums gives me this and by the way for
those of you haven't noticed I threw in
a little bit of notation here when you
write just LG it's just log base two
okay so we agree that the answer to this
equation and the answer to this equation
is the same and now I'm going to do one
other little trick exactly the trick
that you used before I'm going to change
my max into a min by simply multiplying
everything by minus one okay don't quite
see where you're going here but you
agree that we haven't changed the answer
I agree that we haven't chance answer to
a log in there to a minus sign in there
that took us from a max to a min but I
haven't changed the answer now do you
recognize anything about these
expressions I'll give you a hint
information theory
okay so information theory is usually
entropy which is like sum of P log P
stuff right I'm not seeing that well
there you there's your log and there's
your P sure it's not be times that
though that's true but we know from
information theory based exactly on this
notion of entropy that the optimal code
for some event with probability P has
length minus log base 2 of P so that
just comes straight out of information
theory that's where all the entropy
stuff comes from okay so if we have some
event that has some particular
probability P of happening the best code
for it has this structure minus log of P
okay so if we take this fact that we
know and we apply it to here what is
this actually saying this is saying that
in order to find the maximum
a-posteriori hypothesis we want to
somehow minimize two terms that can be
described as links okay see that so my
question to you is given that this
definition over here that individual
probability P has some length minus log
P what is this the length of so that
would be the length of the probability
the data given the hypothesis mm-hmm and
the length of the hypothesis or the
probability of the hypothesis well no
it's just a link to that pause oh
because the event is what has the length
oh I see so it's the length of the data
given the hypothesis and the length of
the hypothesis right so let's write that
out but I was just doing like pattern
matching there it's not clear to me what
a length of a hypothesis is hypotheses
or functions I don't know how to take a
tape measure to a function that's fair
so this is the length of the hypothesis
right yep
so you said you don't know what that
means but let's think about that out
loud for a moment what does it mean to
have a length of hypothesis that's
really sort of the the number of bits
you need to describe a particular
hypothesis right okay okay in fact
that's exactly what it means it's why we
use log base two so if we want to
minimize the length of hypotheses what
does it mean the number of bits that we
need to represent the hypothesis number
of bits we need to represent the
hypothesis is I guess in some
representation there's actually in this
case I guess would be some optimal
representation we are taking all the
different hypotheses and writing them
out the ones that are more likely have a
higher P of H because that's the prior
and those are going to have smaller
lengths in the optimal code and the ones
that are less common are going to have
longer codes well let's make it more
concrete</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>