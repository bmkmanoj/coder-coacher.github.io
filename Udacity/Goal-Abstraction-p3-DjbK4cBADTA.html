<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Goal Abstraction p3 | Coder Coacher - Coaching Coders</title><meta content="Goal Abstraction p3 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Goal Abstraction p3</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/DjbK4cBADTA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so as I know the last slide right once
we start thinking about goal abstraction
and sort of all of these functions or
modules or procedures running at the
same time which really have done is turn
this into a problem of arbitration by
the way this does have a name I really
like the name it's called modular
reinforcement learning and that just
sort of captures the idea that we've
divided the world into a bunch of
modules or what we might call options or
what we might call temporally extended
actions and these things always have
associated with them goals they're
always trying to do something or to
accomplish something they are different
modules and we're the operating system
and we need to decide which program
we're going to let run next and there
are lots of ways you might imagine doing
this here are three of the more popular
ones each of which has strengths and
drawbacks and they're kind of the things
that you would come up with if you were
given five minutes on a test to come up
with something so here are the various
arbitration techniques so the simplest
one is greatest mask you learning which
well Michael what do you think that
means it means greatest mask you
learning ah so we have Q functions maybe
for each of the individual subtasks and
we say well whoever's got the highest Q
value gets to take the next action
that's close so the first thing you said
is right since each of these things are
their own little goals running around
they're like their own little RL BOTS
for agents then each of them has a Q
function and what greatest mass Q
function does is it adds up all of the Q
functions so for the state that we
happen to be in add up the Q value for
every state action pair and whichever
one is the largest that's the one that
we execute wait hang suits I was saying
whichever Q function has the largest
value you're actually saying which
action after combining the Q functions
has the largest right so it's sort of
like they're voting that's exactly right
it's exactly like they're voting so I
say that the Q value of taking a
particular action in any state is
actually the sum of all the Q values for
each of the agents indexed here by I and
then these papers will go greedy yeah I
picked the action that has the most mass
across all the agents okay so then why
is it keulen why isn't just greatest
action mass or something well the reason
you have it is q-learning is because you
assume there was key learning going on
and you're using the Q function to
determine how to vote so that's exactly
why it's called q-learning because
there's a queue function involved so
this is adding everything up and it does
sort of exactly what you would expect
basically everyone votes and whichever
wins as the biggest vote wins so I want
to say that the the modules are voting
but they're voting on different actions
in whichever action has the largest
number of votes wins right I'm sorry is
what i meant to say what did i say okay
well it sounded like well it was
interpreted balazs the whichever q
module gets the most votes gets to
decide oh I'm sorry yeah so that's
actually closer to what you were just
yeah I know but yeah so here all you're
doing is you're voting for each action
that's the greatest mask you learning
and you just go from there and that's
neat and kind of makes sense if you
assume sort of their all care about some
ultimate goal together but people have
observed that that could be bad because
it might not be good for any particular
agent right so imagine that I have a
couple of you know I have ten agents
there are ten actions and each one
strongly believes in a subset of those
actions but they're different ones so
each one billions of a different action
and so or better yet there are five Act
there are ten actions and there's five
agents and there's an action that is the
fifth choice of every one of those
agents but because it's the fifth choice
of every one of those agents it's the
one that ends up getting the most mass
and so you haven't really satisfied any
of the sub goals yeah i mean i could see
that as being a bad thing or I could see
that as being a good thing right because
it's it's choosing that action not just
because it's bad it's choosing that
action because it makes everybody a
little happy instead of making some
people really unhappy right but you can
construct examples where sort of
everyone's least favorite choice will
still end up being the one with the most
votes if nobody agrees on anything else
but that's okay I mean it's still as you
say it's a reasonable thing to do under
lots of circumstances it just happen to
be cases where it doesn't always work
which would you know there's no free
lunch so it's not
surprising that that's the case</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>