<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Linear Value Function Approximation | Coder Coacher - Coaching Coders</title><meta content="Linear Value Function Approximation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Linear Value Function Approximation</b></h2><h5 class="post__date">2015-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/h5eEzgQI_SE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the particular case I'd like us to talk
about in more detail is linear value
function approximation so that is in
particular the case where our Q function
is represented as a weighted linear
combination of the features that
represent the state and and maybe the
state in action but we're gonna keep the
action separate for now okay so this is
how the Q function can be represented if
it's if we're doing things linearly so
we have this this set of weights W a sub
I and we have a set of features or at
least this function f that map's States
to two particular feature values and
let's say we've got n different features
so if we're representing things linearly
what we're doing is we're saying let's
sum over all the features for the
current state the value of that feature
times the weight that is being used to
represent the the Q function for this
action and just yes some of the some of
the I'll take essentially take the dot
product between this feature vector and
the weight vector and it's these
parameters these W Super A's that are
actually providing us the generalization
the ability to make a prediction to new
states because there's parameters that
are shared between all the different
states sure that makes sense so it's
like a neural network with nothing
nonlinear going on yeah in this
particular case it is exactly a linear
function which you can think of as being
a neural net without any nonlinear and
with a single layer yeah so in fact you
have a whole set of them you have a
whole set of neural networks all kind of
happening in parallel I suppose you
could claim that there that there one
neural network with the non-linearity
which is kind of some kind of max
function or something that figures out
which action you should take based upon
each of the Q s of A's and so you really
are kind of learning in neural network
yeah I can agree with that
I mean we're gonna we're gonna talk a
little bit more about using more general
neural network structures in this
setting instead of just just linear
weights but the linear weight case is
kind of easier for us to think about and
there's actually been a tremendous
amount of research on this particular
case because the hope has been that it's
been it's more well behaved than what we
get with with nonlinear function
approximation usually is let's think a
little bit about what these weights are
actually representing okay one way you
can think about the weight for a feature
is that it gives a kind of sense of
importance for each of the features in
how much they're contributing to the
actions value sure so if the weights
soup a sub I is zero then it doesn't
matter what the feature is it doesn't
contribute at all that's right it said
then it completely ignores the feature
for that prediction and if the weight is
the billion then it means a lot probably
and if it's negative ability and it also
means a lot just in the different
direction right sort of anti importance
well not necessarily I mean the future
depends upon how you want to interpret
it the the F sub I produces a negative
number and you're actually the weight is
also negative you're saying that that
feature is really important right and
the negativeness just it's kind of a
function of the fact that you want Q
values to be higher if you're gonna use
them okay all right I I think that's a
good way to think about it alright so
just kind of make sense here you feel
like you you appreciate the notion of a
linear value function approximator yeah
I think so it's a yeah that makes sense
you just add up all your features and
weight them appropriately cool all right
so let's let's kind of make sure that we
understand this okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>