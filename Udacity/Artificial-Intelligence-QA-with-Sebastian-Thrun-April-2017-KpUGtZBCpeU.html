<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Artificial Intelligence - Q&amp;A with Sebastian Thrun: April 2017 | Coder Coacher - Coaching Coders</title><meta content="Artificial Intelligence - Q&amp;A with Sebastian Thrun: April 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Artificial Intelligence - Q&amp;A with Sebastian Thrun: April 2017</b></h2><h5 class="post__date">2017-04-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KpUGtZBCpeU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome back we're back again
with Sebastian for a Q&amp;amp;A session how you
doing good all right excellent good
seeing you
I'll start with a question on general
artificial intelligence so DARPA shared
a recent video on their perspective on
artificial intelligence where they talk
about the three waves of AI can you
comment on building tools and techniques
that will come in handy for designing
context to where AI first of all I'm
after embarrassing say I was actually
part of the second wave it's hopefully
you guys are just part of the third wave
which is much much better but yeah so
there's been a discussion about what
tools to use and for a long time yeah it
was very rule-based the idea was to go
to an expert and solicit information and
talk to them and write down even as
rules and they looked like the most
scalable approach this came out of the
1980s at Feigenbaum invented expert
systems and I think the first successful
commercial application of the eye were
these rule-based expert systems people
try to scale this up to something of you
in intelligence there's a project called
the psych project see why I see that
spend more than a two deck is actually
trying to really put large rules to
there than what people found is these
rules have all loose ends that they
can't really connect them you have an
entity over here it's called a car and
do vehicle to vehicle and the car is not
exactly a vehicle because the vehicle to
be a bicycle but maybe in this contest
is meant to be vehicle and it was very
hard to make these rules of work
together and then of course came the
most recent super exciting machine
learning era where I am and with that we
tossed everything else overboard there's
no search no planning no rules no logic
the I can read books anymore and stuff
like that so it's very fair to say that
the future is probably somewhere in
between and the nice thing about
research is it comes in like a pendulum
it swings like it goes from rules to
learning to rules to learning and as we
do we make progress so my suspicion is
in the next ten years you will find ways
for example the bid general purpose AI
they can do multiple domains and then
use more maybe a logic based or a
rule-based
information to feed these systems not
just data points right to the future
lies and bringing together the best of
both worlds then I believe I mean the
the proof is of course in the pudding we
have to see how father and it carries us
I would argue humans vastly learned from
data we spend the first couple of years
like babbling and falling over but
eventually we learn by rules like if you
go as a college student to be will give
your rules but it takes a lot of prior
learning to make these rules process and
then the words aren't very good so in
the for example look at self-driving
cars the rules defining how to behavior
and behave in streets have
inconsistencies there they would lead to
complete traffic shut down it followed
verbatim in many many cases and then
people have to improvise so I don't
think we understand how to represent
these kind of soft rules powerfully in
an e-learning context yet ok cool our
next question is from Mario he asks how
do I go from training an agent on my
local machine to actually having
something deployed in production or in a
mobile app well you take the mobile app
Udacity nano degree we have an Android
and iOS and what you find is that the
training is much more complex and
time-consuming than the use so if you
train a neural network it might take
weeks to train and then running it might
take milliseconds and the reason is for
training you have to iterate many many
many times data points over and over
again we're than running it you just
take a single sweep
so in principle is not very hard for
androids Google has made its software
available you can do deep learning on or
deep one deep learning that works on
Android very easily and I just recommend
download it and play with it cool let's
move on to some questions from logic and
planning here's one from Morgan can you
give us some examples of companies that
are using planning systems for instance
maybe healthcare or other industries
that are using planning systems if it
depends on how we define planning I mean
there's this entire domain of job from
scheduling where you have a facility
that men fix or something
and you bring things in like for example
a car factory and you find all my
supplier bags has a problem the product
number why isn't good enough
there was a truck accident and a truck
shuttle full of these things over here
are delayed this machine just broke down
and then you have to take a schedule
which is a plan and adjust it and these
things are very commonly used in
industry has no question if you go even
further if you look for example in to
the chip design the type methods are
being used to test complex chips are
very similar and came out of our
intelligence to constraint satisfaction
systems which are regulated to a
planning system here again you have this
complicated problem that you might have
a really complicated chips with like
billions of transistors you can't test
every state but it won't have an
effective way to find defects in your
chip so if you take planning to be this
broad view I think it's very successful
if you take plane to be the narrow view
that is that they have to write on their
clauses in logic and the new logical
inference I think that's a more of an
academic sir sighs and hasn't really
made it as big an industry hmm that's
interesting here's an here's a question
related to that so verna asks nowadays
there is a lot of hype about chat bots
and virtual assistants can we use a
large knowledge base with efficient
logic and planning algorithms to create
a sound chat bot or is it better to use
a more statistical approach for such
applications there's none of those
questions I don't know the answer and
you can go and figure it out for me and
tell me because research is nonlinear
and sometimes things surprise a lot
however if you look for example in the
way Watson was designed and many chapels
are designed I would say large
sophistica techniques have a leg up and
their business language is not quite as
logic as Chomsky originally anticipated
it while it feels that there's very
clear grammatical rules that we use
those tend not to be sufficient to
understand what a coach at borders
especially comes to meaning of voice and
use of words and humor always one of the
things as the world is full of data so
if I were to build one I just find
myself a big database and just run
statistics over it face in the
statistics but having said this it is
quite feasible in the future someone
comes up with a very good rule-based
system that system is to be robust
very very robust can be very static
their baby with systems almost today
cool so in term two of a IND we'll be
teaching them some more statistical
approaches but with the fundamentals of
natural language yeah and there's an
interesting history to it there was a
German Peter Brown and at IBM at the
time about 20 or so years ago
who really looked into machine
translation which is not chatbots so we
have a Canadian text and English text
you want to translate those and back to
in the day all the linguists in the
world believed that you had to write a
rule-based system and they were writing
this rubra system and a test synonym for
accuracy and the basic hadn't over and
this IBM group under friend endlich
decided to instead statistically pars
text that is available in English and
French and they found in the Canadian
debates because Kenneth do lingo the the
elementary debates were meticulous
translated by high quality human
translators and it is huge corpus of
data we're almost were per board that
the French in English and by just
training a very simple statistical
background model on this text they were
able to surpass anything possible at the
time which led fragile an echo as the
head of the team proclaim at a time
every time a fire linguist the
performance goes up by five percent
that's that could be a good exercise for
our students to try out to replicate
those results
yeah and was interesting to us this
entire speech group eventually left IBM
and became Renaissance Capital you can
read up on it it's the very secretive
investment rule that often bring seventy
percent or so on annual returns which is
crazy and they're using similar very
advanced statistical techniques no one
else exactly what but they were built on
this idea of statistical as opposed to
rule-based
wow that's cool Morgan has another
question what is the current state of
the art and using neural nets to perform
planning or to provide heuristics for it
there has been a lot of work in the past
on using neural networks in the process
of things like game playing and so on
and it comes in basically in two
fashions
one is the evaluation function when you
when you do a search in games at some
point you're gonna say this board is
this good
there was done early on but Tia gammon
by Tercero and has been
a big component of the most recent
Navigo system and events egg- is the oil
and witches search if you get into alpha
beta search you find out that the oil
and which you expand is massively
impassive computation and ever since I
was a grad student people who are thesis
on this that is these learning
components play important roles if you
look into specific game playing like
two-way rule based game playing like
chess and so on there is a very deep
planning engine behind all of these
systems no matter how complex they are
but the learning part is about a mixed
scale here's one from Ho Chi and Chi if
you've heard of the recent upcoming Robo
race think like f1 racing for
self-driving cars planning and speed are
both going to be very important in there
so the question is should driverless
racing cars plan ahead of time to obtain
an optimal route or should they train
while navigating the course and slowly
increase the speed over time again this
Crescent doesn't have a binary answer
because in the end of the day of
infinite compute power say then he might
be just fine off planning on the spot
however at Google our cars when I ran
the team had a pre-planned route and the
people wrong was not as planned it was
also optimized so we would have
algorithms they would like at the the
terrain infrastructure the roads and so
on and find a good way to do a turn for
example the intersection and
occasionally arguments a fitters say
this video art can a piece bigger
outside and then humans will go on and
move these things a little bit around
not optimal but scalable then for the
Google car the evasion maneuvers are
very small like you might pass a car you
might imagine bicyclists and those tend
to basically result in lateral shifts
along your vote way so they're not very
complex however if you really want to go
to convex world you might actually try
to plan from scratch and rewrite on the
first principles of physics just be
aware this is gonna be a lot of work
especially in real time the real time
part is hard because as you plan and
you're going to race car you know 3040
meters per second and you spend a second
planning you will be surprised what your
car will do with you that's very good
advice
alright we'll wrap up with some
questions from probabilistic models
probably one of your favorite areas so a
Tula asks in Bayes nets and HMMs we
define a model by specifying states and
transitions between them how do we come
up with these states do I always need to
handcraft these states for my model yeah
but are you in these states of an hmm of
our common fate of every call it is kind
of the most difficult thing to do the
faders themselves are based on an
assumption
it's called conditional independence or
you could also call it the noise is
independent right so when the robot
drives on the corridor it might slip to
one side and the next moment it moves it
might slip to the other side completely
independently but the reality is they're
never independent so in carpet in
particular turns out if you driver over
on a carpet most common sense like this
and has a falling direction so it falls
in this direction which means if the
carpet falls in this direction the what
will always drift in this direction no
matter what so there is state the state
is now how did the carpet installer
install the carpet right it's the
falling direction this direction or this
or this North Oz believe you could
estimate this and before you realize you
have this like 10,000 dimensional state
vector and then is someone maybe your
grad student has to write on all the
rules or the state behaves very hard the
physics of the carpet so what we doing
in robotics is we take the most
important states and the reality is the
biggest challenge in designing these
filters and hmm so similar is to come a
good safe representation where these
assumptions are met in physical systems
like rockets or planes or self-driving
cars at least you have a semantics of
those states you know exactly what for
example velocity is what an acceleration
is for the driver drift phase if you
like but if you go to natural language
processing then often these things are
kind of propria to begin with you don't
even know what the state is of a human
brain there's no physical thing that
governs how for example Sebastian
mispronounced us every second words in
this video and but it certainly is there
there's a sebastian state that has
effect on my ability to speak proper
English which is not very good right so
so then things becomes even more fuzzy
and then to some extent you learn
learning algorithms can mask
with us if there's hidden dependencies
and some of my choices they adapt to it
but again I think the choice of state is
the single most demanding thing in the
design without us interesting so in
addition to the choice of states another
factor is for instance the choice of
features or observations that you want
to observe in order to model your you
know hmm for instance so how do you go
about deciding what features to use
there's been a big debate in the field
between features so sophistical ii
historically no more than five because
six dimensions began the hot approve
staff and the most recent wave is the
opposite take fifty thousand features
and then pepper the thing with data so
then let the data figure out what
features make sense it's an open debate
it's a very passionately conducted
debate in the field when people use very
large feature spaces they often add in
regular Rises they try to cram down on
those and arrive at a few of those to
avoid what's generally called the
bias-variance dilemma but all the data
in deep learning today contradicts
almost everything we know about
statistics so people are not willing to
take very large feature sets like
high-res images and still learn
interesting functions okay that brings
us to our last question today
Ivanov asks could you provide some
insights into one hmmm perform better
compared to recurrent neural networks so
HMMs work generally better when what you
model is close to how the world really
works if you for example do a gameplay
where you flip coins and you know
exactly that the coin you flip is random
and the next cone you pick up is
conditioned on the point you saw before
or whatever then and you can write on
these kind of laws of physics so to
speak it was of a game the nation is
doing really well hmm is do badly if you
have amorphous unspecified data and
that's exactly where the difficulty
comes in a speech recognition and the
reason advances so hmm have never done
well in my opinion on complex video
processing because video art is so so so
complicated are you can't really write
on the physics of all the rendering in
the world and all the cats in the world
and how they behave to really have a
good model
hands gonna do next unfortunately can't
and as we know Ken videos are the most
popular visible of of L videos ever
taken on YouTube so the recurrent
networks I think fit better in the other
category now they have waited in a
parameter so if you're very sparse of
parameters in data if you have really
very sparse on data then be careful with
recurrent neural networks they might
just get stuck and they can learn
strange strange crazy things
my very first conference paper about
what was called inversion and time and
it trained in okar neural network to do
digit recognition and then it looked
what other stuff is being recognized as
a five or the six and it turns out if
you do grain descending the input space
you find crazy do these networks
recognize as it perfectly formed five
and that is probably the weakness of
recurrent networks that there might be
some crazy input constellations that to
you me looked like noise but for some
whatever reason this train no network
recognizes something it knows that's
amazing that that's a good thought to
end on thank you so much for joining us
it's total pleasure and I see you guys
in classroom
keep it up great questions thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>