<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Relationship Between Image and Scene Brightness | Coder Coacher - Coaching Coders</title><meta content="Relationship Between Image and Scene Brightness - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Relationship Between Image and Scene Brightness</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_HV-IihAi2M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now let's look at the image acquisition
pipeline this is something again we've
discussed differently when we talked
about cameras but now let's talk about
it in detail in this context of course
we start off with a 3d scene and of
course this scene is being captured and
the basically the captioning Inferno
information is called the scene radians
referred to as L and basically what the
unit's here described is watts per
steradian meters squared stearate in is
a measure of the solid angle and because
these are 3d scenes and the light is
coming out in form of a cone from
everywhere the basic idea we want to do
is use the cone information to capture
the light so in essence what that
basically means is if I have a scene
what I will be doing basically is using
a cone and the STA radian is basically
kind of counting for all of the
information that's in this cone from any
point and thats basically allows us to
kind of have an area from that point
onwards so just to reiterate seen
radians and refer to as L is basically
watts which is energy per stay Radian
meter square stadium is the measure of
the solid angle primarily because again
this is a 3d scene and the light is
coming out in form of a cone from
everywhere of course when we have a 3d
scene to capture an image from it what
do we need force optics so here
basically now we use the Outlands and
objects and that converts all of this 3d
light information that's why we have the
solid angle and the cone basically
coming in and now of course we have a 2d
sensor so we'd of course do not have the
information from stair radians but we do
have watts per meter square and we know
that was something we refer to as sensor
a radiance and it's something they've
been labeling as e this is a linear
mapping once I know this and if I have
this information when it hits the screen
I can actually now or a sensor I know
what this measure would be next stage in
the pipeline of course of the shutter
because shutter is the amount of time
light is allowed into my sensor and we
know that basically e times delta T
gives us the information towards getting
the sensor exposure and you may
recall of course that we refer to the
exposure as H which was equal to the
sensor a radiant and amount of time the
shutter was open and this is something
again we've looked at before so in
essence what we going from 3d scene and
now we're getting sensor information in
the exposure values continuing on we
basically now will have a sensor which
would be a CCD again we covered the
details of our CCD our works light comes
into a CCD and would we basically get is
electrons collecting and depletion layer
kind of collects it in essence will be
doing is computing the voltages at
different types of capacitors within
secd next step of course is an analog to
digital converter basically takes these
voltages and converts them into digital
values to give you a raw image and of
course then we want to do some sort of
remapping from the raw image again if
you were doing Camera Raw you would just
use this information but sometimes you
basically get compressed pixel
information of intensities and that's
what we get the intensities out of it we
have covered each and every aspect of
this earlier and you can refer back to
the previous lectures on this one but
the bottom line is from 3d scene once we
have the senior radiance there is a
linear mapping to get sensory radians
there's another linear mapping based on
again the time opening to get the
exposures and then there is a bunch of
different operations that happen at the
sensor level so here is one thing we
want to note here is this whole process
of the pipeline is linear there are lots
of linear wrappings going on this part
could all be nonlinear right i mean
there now direct direct linear equations
that would actually let us predict this
analysis here and there also sometimes
depends on the kinds of sensors and
stuff but this is linear and now we need
to kind of understand how we can use
this to understand again information
from what's in the scene to what we want
on the sensor in terms of an exposure so
far we have studied the image
acquisition pipeline now let's look at
some of the mathematics associated with
it so of course this whole pipeline
starts off with L which is the scene
radians a linear mapping to e linear
mapping to exposure and then of course
all the way down here to give me
intensity values of course we're
interested in this pipeline but we are
also interested in the inverse of this
pipeline which lets me compute the
inverse
now we're basically what I'm interested
in is I have an image can I actually now
predict the model of the whole scene
intensities here in terms of scene
radians so I'm interested in both of
those and that's the kind of stuff now
let's think about to be able to model</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>