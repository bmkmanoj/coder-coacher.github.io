<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Estimating Q From Transitions - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Estimating Q From Transitions - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Estimating Q From Transitions - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Xr2U3BTkifQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so what we're gonna do to
figure out how cute learning works is
we're gonna think about what it means to
estimate this cue function from
transitions so let's just remember this
is the form of the cue equation that
we've been talking about and we can't do
this we can't solve this because we
don't have access to R and T all we have
access to are transitions so this is a
really I guess I mean I guess you said
this before but when you when you write
out this equation it really jumps out at
me this is the difference between what I
was talking about solving MVPs and
reinforcement learning in solving MVPs
we had R and we had T and now we don't
have them so we have to come up with
some other way to solve these kinds of
equations that's right okay so if we did
have R T then we could solve this yeah
this is I mean the same things that you
talked about value duration and policy
duration that can be formulated in terms
of Q so it's there's yeah there's this
is easy to do well P it's polynomial to
do if we have access to TNR but but
again in the learning scenario we don't
have the model what we have our
transitions okay okay so here's how
we're gonna use transitions this is what
a transition is we we observed that we
were in some state s of the MDP and then
action a was chosen somehow and then a
transition happens we land in a state we
get the reward for landing in that state
and we find out what state were in so
that's that's the transition and what
are we going to do with it what we're
gonna do is imagine that we've got an
estimate of the Q function Q hat and
we're gonna update it as follows here's
how we're going to use all these
quantities from the transition we're
gonna take the the state and action that
we just experienced and we're gonna
change it we're gonna update it we're
gonna move a little bit alpha this is
alpha this is called a learning rate
we're gonna move a little bit in the
direction of the immediate reward plus
the discounted estimated value of the
next state so we're gonna take our
estimate Q hat we're going to take the
state that we end up in as prime we're
gonna look at all the different actions
we could take from there and take the
maximum so this together is kind of an
estimate of the utility right mm-hm and
this is the utility of the state that
we're going to this all together is the
utility of this
date that we were in at the state s so
this is kind of the utility of the state
that we're landing in s prime and this
all together is is related to the
utility of the state right you can see
that it's related in that we've got the
immediate reward which kind of matches
to this we've got the discounting we
don't have the sum over transitions but
we do have the max a and the look up in
the next in the queue function alright
so this this is the Q learning equation
alright let me just say a little bit
more about this this alpha arrow
notation which I really like but is not
all that standard so if you when I write
you know something like V gets with an
alpha X what we mean is we're moving
alpha of the way from the current value
of V towards X which can be written this
way that V gets 1 minus alpha of V plus
alpha of X and so in particular if you
think about this as so if alpha 0 that's
sort of a learning rate of 0 which
shouldn't learn at all and in fact if
you set alpha to 0 here it's gonna zero
out X and it's going to only assign V to
V so nothing's going to change so a
learning rate of zero corresponds to no
learning and if we set alpha to 1 that's
like full learning so we forget
everything that we knew and we just jump
to the new value and that's what happens
here that 1 minus alpha is 0 so the V
goes away and we just get X assigned to
V does that make sense
that does make sense and and if alpha
were in between 0 and 1 like 1/2 you're
basically making V the average of the
old value of V and the new value X that
you see good</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>