<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dimensionality Reduction | Coder Coacher - Coaching Coders</title><meta content="Dimensionality Reduction - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dimensionality Reduction</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3uxOyk-SczU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let's talk about dimensionality
reduction so here I've got a bunch of
points okay and these points are in 2d
all right
it's called kind of green in red but
that's sort of a joke we're not gonna
worry too much about why it was done
that what you should notice is that in
the middle here are these oranges
yellowish points to see why it's orangey
red plus green makes sort of yellowish
or so it's all along that diagonal
they'd be kind of yellow I don't know
who did this originally but it's kind of
cool all right if you think about these
orange points let's think about how
they're distributed okay so they have a
mean somewhere and they've got a set of
eigenvectors right they've got a
covariance matrix that describes them
they have a axis of least inertia and
then the next axis so here you're seeing
the points the orange points are X X bar
here is supposed to be their their mean
and then we've got the big eigenvector
v1 and then the smaller one v2 and the
idea is we can represent those orange
points by only their v1 coordinates plus
the mean and what that would mean is
haha
essentially that we're gonna think of
all the orange points is just being on
that line and all I'm gonna tell you is
we're on the line they are and we're
gonna essentially ignore the amount that
they're off that line so we've just
reduced the dimensions from how many to
two how many one okay that doesn't sound
like that big a deal nor is it but in
higher dimensions this could be a huge
deal imagine you've got something in
10,000 dimensional space and yes and if
just a minute we're gonna do a 10,000
dimensional space if you said well I'm
gonna represent them by one number or
even 30 that would be a huge reduction
so if I said well what direction does it
vary the most in and I just give you
that value if that's good enough for
what we want to do you've reduced the
description from being a lot of numbers
to being a much smaller number in fact
we can sort of express that here
algebraically in terms of just thinking
about it whatever dimension X happens to
be in so if I've got a whole bunch of
data points in some end of
in space what I want to know is the
direction of projection and wuzza Said's
V alright that if I projected those
points after subtracting out the mean
that I'd have the greatest amount right
the greatest variation and that's what
that says here right so take X subtract
out the mean dotted with the B summed
over all the X's take the norm take the
square well that can be written as
expression like this of just V transpose
AV where a is just this outer product
okay that's the covariance matrix that
were familiar with before and as we said
before the eigenvector with the largest
eigenvalue lambda is going to be the one
that captures that greatest variation in
a minute I'll give you a little argument
about why it's the eigenvector with the
largest eigenvalue or you can just take
my word for it and the fact the smallest
eigenvalue would be the least amount of
dimension so basically what we're gonna
have to do at some point is take the
eigenvectors of this covariance matrix</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>