<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Left Turn Policy Solution - Artificial Intelligence for Robotics | Coder Coacher - Coaching Coders</title><meta content="Left Turn Policy Solution - Artificial Intelligence for Robotics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Left Turn Policy Solution - Artificial Intelligence for Robotics</b></h2><h5 class="post__date">2012-05-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rH5DKpwYQLY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and here's my solution I have the value
function is utilized 3-dimensional as
lots of 999 the policy is a similar
function in 3d and then I have a
function called policy 2d which is a
vinyl a tag on a print and it's the same
in 2d scrolling down my update function
is exactly the same as before for
dynamic programming
why changed exists go through all XYZ
and all orientations of which they are
for so it's now a deeper loop if you
found the goal location then update the
value and if there is an actual update
set change to true and also mark it as
the goal location otherwise if a grid
cell is navigable at all let's go
through the three different actions and
here's a tricky part how to make the
action work but it works beautifully we
go through three different actions when
we take the ice action we add the
corresponding orientation change to
orientation module o4 it's a circular
buffer so this might subtract one keep
it the same or add one to orientation
and then we apply the corresponding new
motion model to X&amp;amp;Y to obtain x2 and y2
that over here is our model of a car
that steers first and then moves
scrolling down further if we arrived at
a valid grid cell in that it's still
inside the grid and it's not an obstacle
then like before we add to the value the
value of this new grid cell plus the
cost of the corresponding action and
this is non uniform depending on what
action we pick now and if this improves
over the existing value we set this
value to be the new value and we mark
changes true and we also memorize the
action name as before this is all
effectively the same code as we had
before when we do dynamic programming in
a two dimensional world it gets us the
value function and it gets us the policy
action however I printed out a two
dimensional table not a three
dimensional table to get to the
two-dimensional table I now need to be
sensitive of my initial state otherwise
it's actually turns out to be undefined
so let me set the initial State
to be XY and orientation and all I do
now is run the policy so with the very
first state I copy over the policy from
the freedom engine table into the
two-dimensional mind which would be this
hash mark over here in what I haven't
reached the goal state quite yet as
indicated by checking for the star in my
policy table now my policy table has a
hash mark R and L but otherwise is the
same as before
it was hash mark I just keep orientation
the way it is it was our I turned to the
right if L is turn to the left I apply
my forward motion and I then update my
new X&amp;amp;Y coordinates to be the
corresponding after the motion in an
update my orientation to be o to finally
I copy the three-dimensional symbol for
my policy straight into the national
array and this is the array that I
finally print the key inside here is to
go from the three-dimensional full
policy to the two-dimensional array I
had to run the policy and that's
something you would have done to get
back this table over here that's
somewhat non-trivial I didn't tell you
this but I hope you figured it out but
everything else is the same dynamic
programming loop that you've seen before</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>