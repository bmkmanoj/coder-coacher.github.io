<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Reducing Kernel Preemption Latency - Georgia Tech - Advanced Operating Systems | Coder Coacher - Coaching Coders</title><meta content="Reducing Kernel Preemption Latency - Georgia Tech - Advanced Operating Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Reducing Kernel Preemption Latency - Georgia Tech - Advanced Operating Systems</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Whse_Lcd4ec" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the second source of latency as I
mentioned is the kernel preemption
latency now how do we reduce the kernel
preemption latency timer goes off where
the kernel is in the middle of something
and so we have to wait for the kernel to
be ready to take that interrupt the
first approach is to explicitly insert
preemption points in the kernel so that
it can actually look for events that may
have gone off and take action so that is
the first approach the second approach
is to allow preemption of the kernel
anytime the kernel is not manipulating
shared data structures now the reason
why you don't want the kernel to be
preempted is because it was manipulating
some shared data structures and if you
preempt that that can result in some
race conditions in the kernel bad news
so what we want to do is we want to make
sure that the kernel is not preempted
while it is manipulating shared data
structures but if it is not then we want
allow preemption so these are two
different approaches that can be
combined in order to reduce the latency
associated with kernel preemption a
technique due to Robert love called the
lock breaking preemptable kernel
combines these two ideas and by
combining these two ideas it reduces the
spin lock holding time in the kernel the
idea is the following so there may be a
long critical section in the kernel
wherein it is manipulating some shared
data structures but it is also doing
other things within this critical
section so what we're going to do is
apply these two principles and break
this long critical section as follows so
we're going to change this critical
section code into two sections you
acquire the lock you manipulate the
shared data structures and you release a
lock and the reason you're releasing the
lock is because you're done with
manipulating the shared data structures
and then we will reacquire the lock and
finally release it so essentially we
replace this long critical section by
two shorter critical sections one
manipulating shared data
and the rest of the code here what is
the advantage of doing this what we can
do is at this point once we have done
with manipulating shared data we release
the lock and at this point we can
preempt the kernel safely and since we
can priam the kernel at this point it's
a great opportunity to check for expired
timers at this point if there are
expired timers dispatch them reprogram
one-shot timers if need be all of that
stuff can be done at this point and then
you can come back reacquire the lock and
continue with the critical section so
that's the idea in the lock breaking
preemptable kernel that combines these
two ideas of explicit insertion of
preemption points and allowing
preemption anytime the kernel is not
manipulating shared data structures the
third source of timer latency I
mentioned is the scheduling latency that
is the timer event goes off and we want
to schedule the app that is going to
deal with the time of event
as quickly as possible but the scheduler
is in the way how do we quickly make
sure that that app gets scheduled firm
timer implementation and TS Linux uses a
combination of two principles one is
called proportional period scheduling
and in proportional period scheduling
what is being done is that when a task
so these things represent tasks t1 and
t2 when a task starts up it is going to
say that it needs a certain proportion
of the CPU time to be allocated to it in
every time quantum so there are two
parameters associated with proportional
period scheduling Q and T T is a time
window at a time quantum and this is the
time quantum that is exposed to an
application and the application can say
within the time quantum T I need a
certain proportion of that time for my
task so t1 might say that in any time T
I need 2/3 of the time to be devoted to
my task and if another task
- says in any time period t I need one
third of the CPU to be devoted to my
task then these two requests can be
obviously satisfied by TS Linux because
the to add to the periodicity of
scheduling T and this is the idea behind
proportional period scheduling in which
what the scheduler does is admission
control at the time that a process
starts up if it asks for a certain
proportion of time it sees whether it is
possible to satisfy that request so for
example if already the scheduler has
promised t1 2/3 of the time and t2 comes
along and says I also need 2/3 of the
time and every period t TS when X is
gonna say AHA no can I do that because
it doesn't have the capacity to
accommodate both these requests
simultaneously so that's the idea behind
proportional period scheduling so it
provides temporal protection by
allocating each task a fixed proportion
of the CPU during each task period t and
both these Q and T parameters are
adjustable parameters using a feedback
control mechanism and so this in essence
improves the accuracy of scheduling
analysis that you can do on behalf of
processes that are time sensitive the
second technique that is used in TS
Linux for reducing scheduling latency is
to use priority scheduling and let me
motivate that by introducing a problem
that plagues real-time tasks and that is
what is called priority inversion so
here is a high priority task C 1 and it
needs some service and it gets that
service by calling a server and this
call is a blocking call to the server
and the server itself may be a low
priority server for example this client
may contact a window manager to say I
need a portion of the window and this is
what I want you to do in
the painting that portion of the window
that might be a call that a high
priority task is making to a low
priority server and this is a blocking
call and until the server is done with
its work the high priority task cannot
continue execution so if you look at the
timeline c1 is running and it makes a
blocking call at this point and the
server takes over and this is the
service time for the server to execute
the blocking call made by c1 so at the
end of this service time c1 is ready to
run again but not so fast it could be
that during the service time of this low
priority server on behalf of c1 some of
the higher priority task c2 which
perhaps was waiting for some IO
completion becomes runnable again if it
becomes runnable again then this higher
priority task compared to this server is
going to preempt the server and take
over the cpu so what happens at this
point is that this medium priority task
because it is higher than the server's
priority it's going to take over
pre-empting the server and that is
essentially a priority inversion so far
a c1 is concerned because c1 is higher
in priority than c2 but unfortunately at
this point of time the server is the one
that is scheduled and that is lower
priority than either of these two guys
and therefore c2 happily preempts the
server and takes over the cpu but from
the point of view of c1 that's a
priority inversion and it is a
time-sensitive task that affects the
sensitivity of the time-sensitive tasks
this is where the priority-based
scheduling of TSL saves the day for us
basically the idea is that when c1 makes
a request to the server the server is
going to assume the priority of c1
even though normally it has a static
priority which is lower than the
priority of c1 because see one is making
this call
the server's priority is going to be
boosted to be the priority of c1 itself
so for the duration of the service time
of the server the priority of the server
task is going to be the same as the
priority of c1 which is higher now c2
when it becomes runnable it cannot priam
the server because the server is now
running at the priority of C 1 and
therefore we avoid the priority
inversion that would have normally
happened because of the priority based
scheduling in TS Linux so the upshot is
that there will be no priority inversion
with this priority-based scheduling
mechanism that is there in TS Linux
so to recap TS Linux avoids scheduling
latency to shrink the distance between
the event happening and event activation
by doing this admission control through
the proportional period scheduling and
also it avoids priority inversion by
using this priority-based scheduling so
these two mechanisms allow shrinking
that distance as well the other
advantage of the proportion period
scheduling is that TS Linux can have a
control over how much of the CPU time is
devoted to time-sensitive tasks so that
it can reserve a portion of the time for
throughput oriented tasks so for
instance it could say well within any
period T I am going to reserve a third
of the time for throughput oriented
tasks so that even if there are time
sensitive tasks running throughput
oriented tasks are going to get their
dips for running on the cpu and that way
we can make sure that while supporting
the timeliness of time-sensitive tasks
TS Linux can also ensure that throughput
oriented tasks are able to make forward
progress so the three ideas that are
enshrined in TS Linux for dealing with
time-sensitive tasks are first of all
coming up with the firm timer design
that increases the accuracy of the timer
without exorbitant overhead in dealing
with one shot timer interrupts second
using a preemptable kernel to reduce the
kernel preemption latency and third
using priority-based scheduling to avoid
priority inversion and guaranteeing a
portion of the CPU time to be allowed
for time-sensitive tasks those are the
ways by which the distance between event
happening and even activation can be
reduced and we can get good performance
for time-sensitive applications even
though the operating system is a
commodity operating system like Linux</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>