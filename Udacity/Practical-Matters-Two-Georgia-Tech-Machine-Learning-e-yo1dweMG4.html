<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Practical Matters Two - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Practical Matters Two - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Practical Matters Two - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/e-yo1dweMG4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">here let me put it to you this way
Michael what is mimic giving you for all
of that work that it's doing in building
dependency trees and and you know
running prims algorithm and finding
maximum spanning trees I'm gonna say
structure because that's the word that
you've been using repeatedly you get
structure and another way of thinking
about structure in this case is you're
getting information you get a lot more
information because you get structure
you get a lot more information for
iteration as well so that's the price
you're paying you're getting more
information every single time you do an
iteration at the cost of building these
maximum spanning trees or whatever it is
you're doing in estimating a probability
distribution so why would it be worth it
to do that what's the other source of
expense well so all right so there's all
this computation within an iteration but
what it's what it's doing what is trying
to do is trying to find inputs that have
high scores and so you do have to
compute the scores for all those inputs
so the the Fitness calculation is really
important right so mimic tends to work
really well when the cost of evaluating
your fitness function is high so it's
really important that I only have to
take a hundred iterations if every
single time I look at a fitness function
and try to figure compute it for some
particular X I pay some huge cost in
time well have you told us how many
function evaluations there are in an
iteration because it seems like it could
be a lot in mimic well you get one
basically for every sample you generate
yeah and and so but so I guess there's
you can compare iterations but you can
also compare samples right so that would
depend upon how many samples you feel
like you need to generate and of course
you can be very clever because remember
theta will generate a bunch of samples
for theta plus one so if you keep track
of the ones that you values you've seen
before you don't have to recompute them
so it's actually pretty hard to know
exactly what that's going to be but
let's imagine that at every iteration
you generate a hundred samples so at
most you're going to have to evaluate f
of X one hundred times
so mimic is still a win over something
else if the number of iterations that it
takes is one hundred or more than a
hundred times fewer Wow
right yeah so can you think of functions
Fitness functions
real fitness functions that might
actually be expensive to compute well
yeah sure I mean a lot of the stuff that
is important is like that so if you're
trying to design a rocket ship or
something like that that Fitness
evaluation is is doing a detailed
simulation of how it performs and that
could be a very costly thing right
actually that's a good example because
mimic has been used for things like
antenna design it's been used for things
like designing exactly where you would
put a rock in order to minimize fuel
costs sending it to the moon these sorts
of things where the the cost really is
in evaluating some particular
configuration where you have to run a
simulation where you have to compute a
huge number of values of equations and
so on and so forth in order to figure
out the answer another case where it
comes up a lot is where your evaluation
function your Fitness function involves
human beings Oh interesting
yeah where you generate something and
you ask a human how does this look or
does this do what you want it to do
because humans it turns out are really
slow they're not measured in mega flops
that's right so you end up with cases
where fitness functions are expensive
something like this becomes a big win
and that's a general point to make
though that when you're looking at all
of these different algorithms is
different models for everything that
we've been doing both for unsupervised
learning and earlier for supervised
learning a lot of times your trade-off
is not just in terms of whether you're
going to overfit or not it's whether
it's worth the price you need to pay in
terms of either space or time complexity
to go with one model versus the other
we've been talking about in terms of
sample complexity but there's still time
complexity and space complexity to worry
about cool okay okay cool so normally
what we would do next we would say what
what have we learned but I actually kind
of think we just did that
indeed so in fact let me do something
about that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>