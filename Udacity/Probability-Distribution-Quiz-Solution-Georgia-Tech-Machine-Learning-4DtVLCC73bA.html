<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Probability Distribution Quiz Solution - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Probability Distribution Quiz Solution - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Probability Distribution Quiz Solution - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4DtVLCC73bA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay Michael okay so problem one where
you're maximizing the number of ones to
represent the Optima here or the
influence of any given bit on the
fitness value they're all independent
they all just contribute whatever they
contribute and so I don't see any reason
to capture other dependencies or you
know local information is enough is that
is that enough to say that the answer
that the one goes in the last box for
independence that's correct
but it's I guess I guess what I don't
quite understand is in in the case of
the so we want to know what's the
probability yeah it's a funny thing
we're representing right so so if we
that like the third position we're
saying well what's the probability that
if this is a one that we're going to be
above a certain value and what's the
probability if if it's a zero we're
gonna be above a certain value
mm-hm and that doesn't really exactly
capture the way the fitness function
works but I guess oh I guess because
we're drawing from we're drawing the
rest of the things at random the rest of
the values at random mm-hmm yeah so
there's is that where the meaning comes
from then yeah I think about it this way
remember the probability distribution
that we care about pea-soup theta is
basically uniform for all X's such that
the fitness value is greater than or
equal to theta so imagine we start out
with theta equal to zero let's say which
is the lowest value that you could get
well then what's the probability of bit
one being a one okay for all values we
can think about it's one half okay
because every single value is okay and
so in order to get a uniform
distribution across n bits I can sample
each bit independently uniformly and
that'll give me an overall uniform
distribution agreed I do agree with that
yeah okay now at the very very end when
I have all ones as the maximum value
that's also easy to represent because
the probability probability of bit one
being one for the optimal value one yes
the probability bit 2 is 1 and the
probability to be 3 point note 1 exactly
and they're all can be independently
represented so we can definitely
represent the minimum Thetas are aimes
yeah yeah so we can represent the
maximum the question here is or at least
in terms of you know you're likely to
finding the answer the question here is
can this distribution
represent values of theta in between so
imagine theta was let's say I had four
bits here we were doing here and let's
imagine theta was too good now notice
that when theta is 2 it's not just the
number of points that will give you
exactly - it's the ones that will give
you at least 2 - right and 3 &amp;amp; 4 so how
many different ways are there to get 4
well there's only one way to get a value
of 4 and that is all ones how many
different ways can you do 3 well there's
four ways to get 3 you basically have to
choose the one that you give it a 0
right and each one of those bits each
one of these values will be a one
three-quarters of the time and how many
different ways can you get - well it's n
choose 2 which is something 6 6 so you
can actually write all of those out and
count the number of times that each one
is a 1 and those are all your samples
and you just simply estimate it and
you'll end up with a uniform
distribution which will be consistent
with the examples that I just sampled
from but we'll probably not exactly
capture pea-soup theta because it will
sometimes be able to generate with
probability not greater than 0 say a
value of all 0 all zeroes yes
ok good that was what I was concerned
about and so this is it's just an
approximation even in a simple case
right and so and that's actually pretty
interesting right so yeah we know that
the extreme values can be represented by
an independent distribution but it's not
clear that all the values in between can
be represented by such a simple
distribution but that's always going to
be the case what you want is a
distribution that will definitely
capture the optimum and or Optima and
gives you a good chance of generating
samples that get you closer to the
optimum along the way so even though in
the case before where theta is 2 we
might still generate examples where you
get a fitness of 0 or 1 you have a high
probability if you generate enough
samples of actually getting values of
theta greater than 2 3 or 4 either got
it ok all right so I so given that I
think I can do the next two with
to much more difficulty so for number
two problem two it maximizes the number
of alternations we pointed out that it's
really important to know who your name
you know what your neighbor is because
you want to be a different value than
your neighbor mm-hmm and the chain gives
you exactly that information without
anything extra right I would put the two
in the first box
yep and finally well there's only one
box left so I put the three in the
middle box but I guess the interesting
thing to to look at here is that it is
surprisingly appropriate right so that
the coloring problem it is specifically
saying well the my value depends on you
know what's a good value for me depends
on I guess several of my neighbors not
just one right but I feel like it could
you could capture a lot of the necessary
information by finding a good dependency
tree right that's and it turns out that
in practice as our readers and listeners
will see from one of the resources that
we're making available to them that in
practice mimic does very well on
problems like this even where you have
really complicated graph structure it
tends to do much better than a lot of
the other randomizer randomizing as a
ssin problems and that's because what
we've got here in this graph is
structure and what mimic is trying to
represent is in fact structure in fact
in all of these cases well except for
the the first case there's not a single
answer often there are possible mini
answers but the answers all have in
common their relationship to one and to
some underlying structure so in the
maximizing alternations case you have 0
1 0 1 0 1 or 1 0 1 0 1 0 these are two
completely different values in fact as
you pointed out when I asked you this
earlier they're complimentary but each
one has a very simple structure which is
every bit is different from its neighbor
to the actually both of its neighbor
every bit is different from its
neighbors and that doesn't matter what
their values are given the value of one
of them it actually completely
determines the value of everything else
right and so mimic doesn't get lost
trying to bounce back and forth between
this possible maximum and this possible
maximum instead it represents both of
them at the same time because the only
thing that matters is the relationships
so in fact that gets us to the last bit
of things I wanted to talk about
witcher's are practical features of
mimic and what we kind of learned by
think
this way</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>