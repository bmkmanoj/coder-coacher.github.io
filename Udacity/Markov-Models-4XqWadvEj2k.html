<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Markov Models | Coder Coacher - Coaching Coders</title><meta content="Markov Models - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Markov Models</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4XqWadvEj2k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so now let's talk about Markov models
and my apologies if you already know
what Markov models are because we're
going to go through this a little bit
then look at the HMMs and maybe that'll
be new for you and if it's not you can
just write in a postcard telling me that
you're unhappy send it to Megan alright
we're going to pretend for the moment
that weather as in the weather outside
is a Markov mall and if it were we're
also going to pretend that there's only
three types of weather you could have
you could have a sunny day a rainy day
or a snowy day it's kind of like a
little kids book and a Markov model says
we have to specify for any given one of
these what's the likely next day going
to be so for example suppose I tell you
that if it's sunny today there's an 80%
chance that it'll be sunny tomorrow 15
that it'll be rainy five percent that
it'll be snowy likewise if it's rainy I
may tell you well there's a 60 percent
chance that it'll rain tomorrow if it's
raining today there's only a two percent
chance that it'll be snowy so it's a
place that gets very cold so so once
it's rainy when it's raining it's not
going to snow and vice versa maybe and
38 percent it'll be sunny and likewise
if it's snowing there's a 20 percent
chance that'll keep snowing 75 percent
chance will be sunny and for the same
reason before very unlikely that all
rain this is referred to as a Markovian
system and in particular if the only
thing you need to know to make a
prediction about what the weather
tomorrow will be is what the weather
today is that's referred to as a
first-order Markovian system so I don't
look at today and yesterday and the day
before I'm just looking at today
in order to make a prediction about
tomorrow if I was looking at today and
yesterday that would be a second-order
mark okay all right so the probability
of moving of being in a particular state
of getting to state depends only on the
state on currently in order to specify
our markovia model we need a couple of
things right so we need a set of states
and these are labeled here as s12
through SN and those the s is those are
there's state one stay Tuesday that's
not a particular time or particular day
there's three different states so in
this example n would be three we also
need
transition probabilities and that's
written as a IJ so that is the
probability that if you're in some state
I that the next time you would be in
state J and then finally to kick things
off we need a initial distribution
that's just the probability that q1 and
a talk about Q a little bit more in a
minute that q1 is equal to si so Q sub T
is whatever state on that at time T so Q
sub 1 is the tot is the state at the
first day or time 1 so for this
particular example as I showed you here
you've got three states sunny rainy and
snowy we've got these state transition
probabilities so this matrix a that's
the encoding of all of these links of
all of these transition values and then
I have an initial distribution which
just says well to start off with maybe
70% chance that it's sunny 25% chance
that's rainy and if my math is Right 5%
chance that it starts out as being
snowing so given this Markovian model
you can ask certain questions for
example you could say if I give you this
series so that's sunny rainy rainy rainy
snowy snowy you could say what's the
probability of getting that series okay
well you have all the information you
need in fact it's written down here
below I've got a and PI right it's just
the probability that I start out sunny
that's here times the probability that
it becomes rainy given that it's sunny
so that would be here times the
probability of rainy given rainy which
is there all the way through I just have
to chain it through right and when I
multiply all those numbers together
point 7 times 0.15 times 0.8 boda I get
some number point zero zero zero one
five one two okay they tend to be small
numbers by the way probabilities and
hmms or in Markov models because
whenever I multiply a lot of numbers
that are probabilities together since
all numbers that are probabilities are
less than or equal to one when I
multiply a lot of them I get small
numbers and when you implement these
things you sometimes have to be careful
and do things like take the log but
that's all I'm going to say about that
all right so that's a Markov model</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>