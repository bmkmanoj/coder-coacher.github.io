<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Write Update Optimization - Georgia Tech - HPCA: Part 5 | Coder Coacher - Coaching Coders</title><meta content="Write Update Optimization - Georgia Tech - HPCA: Part 5 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Write Update Optimization - Georgia Tech - HPCA: Part 5</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/62TPpmxWyfE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now we will look at two possible
optimizations of a write-update protocol
the first optimization will look at is
about avoiding memory rights remember
that in a write-update protocol every
write in any of the processors needs to
be broadcast on the bus and needs to
update the memory because memory is big
and slow it cannot keep up with all the
rights and that means that the memory
throughput becomes a bottleneck for this
system pretty much it's not about how
much traffic can the bus take it's about
how much traffic and the memory take so
we want to avoid unnecessary memory
writes these caches previously behaved
as right through caches every write was
going through the cache to memory and we
have seen already that right through is
bad for memory traffic even with a
single core now we're adding more than
one core so it's going to be even a
bigger problem so the solution to
reducing memory traffic here will be the
same we will add a dirty bit to each
block in each of the caches and this
dirty bit will allow us to delay a
memory right until we actually replace a
dirty block from our cache so now let us
see how this work and how it avoids
memory writes suppose that this cache
reads a it gets this value from memory
let's say it's 6 the tag will be a it's
valid and it's not dirty
now this cache writes a at this point it
will broadcast the write with the
address of a and the value that it
writes let's say 17 so this cache here
would update the value now without a
dirty bit the memory would also be
updated with a equals 17 we want to
avoid that why well because there could
be a lot of writes here until we finally
replace it in a write back cache so what
we will do is we will write 17 tag it
this way and mark this as dirty dirty
means two things here one is that the
memory is not up-to-date and we need to
update it this is exactly the same
as in a normal unit processor write-back
cache if we replace something dirty we
have to send a write back to memory in a
write-update protocol dirty has another
meaning that we will now illustrate
suppose that this cache replaces this
block and then wants to read it again so
it issues a request to read on the bus
and now normally the memory would
respond with the value but the memory
still has the old value of equals 6 this
cache here has the only up-to-date copy
that's what the dirty bit also stands
for so now this cache needs to stop read
as well notice that we are reading the
same block that it has in a dirty state
so instead of the memory being allowed
to respond we respond first the cache is
faster than the memory so it will
respond quicker and say that a is 17 so
now here we get a becomes 17 in this
cache and it's not dirty now after this
let's say that we write a new value here
of let's say 20 we put the new value
here we broadcast the new value on the
bus the snooping here gets that 20 but
the memory again doesn't get updated if
this block however gets replaced from
this cache then an update is sent to
memory another interesting situation
here is what happens if we have the
block dirty in this cache and now this
cache writes let's say 32 a in that case
this cache broadcasts the right this
cache snoops the right puts 30 in its
cache now this cache is no longer
responsible for writing back to memory
because the new writer takes that
responsibility and the memory still
doesn't get updated so as you can see we
can now do many writes without updating
the memory we can even move the
responsibility for updating memory to
another cache and keep writing there
without the updates to memory only when
the last writer replaces the block that
is still dirty will we
a single right to memory so the benefits
of having the dirty bit are that we can
now write to the memory only when the
block is replaced so we can do many
writes without updating the memory does
saving a lot of the writes to memory and
also we avoid memory reads because now
we allow reads from memory only when
nobody has the block in a dirty state if
the block is dirty for example here then
whoever asks for this block this is the
cache that will provide the value and
the memory doesn't need to do that so we
are also saving reads from memory this
way</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>