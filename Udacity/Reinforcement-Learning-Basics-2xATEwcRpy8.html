<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Reinforcement Learning Basics | Coder Coacher - Coaching Coders</title><meta content="Reinforcement Learning Basics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Reinforcement Learning Basics</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2xATEwcRpy8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey Charles this is when we get to talk
about reinforcement learning hi Michael
this is what I get to hear about
reinforcement learning Wow I'm glad
we're on the same page so are we on the
same page is this all of reinforcement
learning or is it just the reinforcement
learning basics we're going to start
with the basics okay I can't we do your
that is so the first concept to try to
understand when you're doing
reinforcement learning is that a lot of
it takes place as a conversation between
an agent and an environment okay so like
right now you're the agent and I'm the
environment uh I think I'm gonna have
you be the agent okay and we'll just
imagine some kind of I don't know like a
videogame environment seems reasonable
by the way you notice that lost weight
oh good job have you how did you do that
well I got drawn as a stick figure
that's fair so here we are the agent and
the environment and the conversation
basically talks about what is going back
and forth between the agent in the
environment so the eight the environment
is going to reveal itself to you to the
agent in the form of States s you then
get to have some influence on the
environment by taking actions a and then
you also receive back before the next
state some kind of reward for the most
recent state action combination okay
fair enough so this is the same kind of
elements that we have in an MDP but the
important thing is that instead of just
being given an MDP is some kind of a
graph structure and then we get to
compute on it really that the
computation is happening inside the head
of the agent and the information about
the environment is really only available
through the course of this interaction
so does that make some sense it doesn't
make some sense but I guess how is that
any different from the NDP well it is
it's the same story as how a policy
interacts with an MDP right where this
is this is playing the role of the MVP
and this is playing the role of the
policy PI but now again we the the
computational aspect of the of the
system here the agent doesn't know the
environment it's not living inside the
agents head instead the agent is just
experiencing the environment by
interacting with it it can then you know
if it's if it's so chose build some kind
of a model of the environment in its
head and then think about that but the
what's in the agent's head and what's in
the environment are two
four things in this setup okay fair
enough I get that so maybe maybe I can
make this a little bit clearer
so let's actually put you in this
environment what do you say okay
metaphorically no let's just do it I'm
sure</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>