<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Interview with Juergen Fritsch - Georgia Tech - Health Informatics in the Cloud | Coder Coacher - Coaching Coders</title><meta content="Interview with Juergen Fritsch - Georgia Tech - Health Informatics in the Cloud - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Interview with Juergen Fritsch - Georgia Tech - Health Informatics in the Cloud</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SPXzxvn8j7s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">next we'll talk with dr. Jurgen Frisch
after earning a PhD degree at Carnegie
Mellon University he was a co-founder of
M modal today he's the company's chief
scientist Jurgen thank you very much for
being with us today thanks for having me
the student you are the chief technology
officer of a modal I believe a chief
scientists actually and the company
which as you know I've been interested
in for years was founded in 2001 but it
was quite a number of years before the
technology was built into electronic
medical records systems for direct use
by physicians could you explain why why
that happened that way and more
specifically how you went about training
the system yes so this was actually very
intentional on our part when we founded
the company we were looking for an
application of speech technologies that
would tolerate the error rate you know
that's still present in in today's
technology if you're familiar with like
telephony systems and other you know
speech enabled dialogue systems you're
familiar with how annoying it can be to
an end-user to have to deal with with
misinterpretations and errors by the
technology so instead of doing that and
going straight to the end-users we
decided to go a different path and we
use the technology in on the back end
first and we did this by enabling an
existing workflow based on dictation and
transcription so in the US you know
there's billions of lines of
documentation created in healthcare
every day or every year through
dictation and transcription workflows
and we enabled those dictation
transcription workflows
specifically the transcriptionists that
were doing that to be much more
productive in that that we produced a
draft document that they can review and
correct and then thereby be twice as
fast as if they had to type it all from
scratch so that was an immediate use
case for the technology you know there
was an ROI attached to it and it allowed
us to build up a business and at the
same time collect huge amounts of data
we collected you know billions of audio
recordings and got them transcribed it
corrected if you will by these
transcriptionist
the process so it was a fairly ingenious
way to basically collect the data
including corrected transcripts to then
train the system to get better and
better and after doing this for you know
five six seven years we got it to the
point where it was so accurate that we
could enable end-users to actually use
it and on the front end and use it for
for immediate speech recognition so when
I first became aware of a model and
traveled to your office in Pittsburgh to
see it one of the most striking aspects
of the system to me was its ability to
go into the text that it had created
from the verbal transcriptions fine
clinical concepts and encode them into
sno-med now the students are familiar
with sno-med as we we have this
interview they know how complicated it
is or at least they have an idea of that
so how hard was it to actually do that
how technically challenging it was
fairly challenging you know it's apart
from the usual challenges with any
natural language processing system we
had to deal with the complexities of the
ontology of the sno-med ontology and
with the medical terminology to begin
with so in addition to dealing with
things like syntax semantics pragmatics
and just the context of the entire
dialogue happening we had to also deal
with just just you know similar words
words that have different meanings or
can have different meanings in different
contexts things like that in healthcare
you know that just a simple term like
cold you can have like three different
meanings it can be abbreviated to yo LD
and it's a disease it could be the
common cold it could just be feeling
cold so there's all sorts of
disambiguation that needed to happen and
need to be accurate in order to codify
these terms correctly to their sno-med
codes so how accurate is it at this
point that's a tough question to answer
because it really depends a lot on the
use case we are not attempting to codify
to the entirety of sno-med you know to
the hundreds of thousands or 300,000
concepts in sno-med but we're focusing
on specific subsets based on a use case
so one of the use cases we're pursuing
is chronic
conditions you know things like diabetes
or heart diseases and and in in that
realm you know if you focus on a
particular subset of diseases and and
we're modeling those with a data model
that's not just including the disease
but also the temporality and the
specificity and the you know who is
concerned with that disease you can be
extremely accurate you can be up in the
high 90s in discovering and detecting
these things in all sorts of contexts
but if you would attempt to codify each
and every you know concept in the
sno-med corpus in the sno-med ontology
you know you would be ending up in a
much minimal but much lower accuracy
rate and and just you know it's just not
happening today that people would
automatically codify it to the entirety
of sno-med I have not seen anybody doing
that accurately and I think you really
don't need to because at the end you're
always pursuing a particular use case
you're always trying to solve a
particular problem and for that you
really only need a subset of that corpus
so what can you tell us about the the
technology that's under the service what
what languages and databases and
approaches are you using so let's start
on the speech side you know we've as
your students might know all the speech
recognition speech understanding systems
that are out there today are based on
statistical algorithms or based on
machine learning statistical
statistically trained machine learning
algorithms and there's no difference
here in our company we do use those a
variety of those you know starting with
hidden Markov models neural networks
regression models even the more complex
machine learning algorithms that are
that are on the market today or that
have been used but we combine them in a
fairly unique way and that we're not
just seeing it as a pattern matching
problem as most speech recognition
systems do but we combine speech
technologies with natural language
processing technologies the the theory
is that if you get a little bit of an
understanding of what you're trying to
recognize you can do better at the
acoustic identification of the sounds
and vice-versa right so you can do it's
a constraint satisfaction problem that
you're solving and the more knowledge
sources you bring in the more accurate
you can be so we do combine you know
syntactic parsers
and annotators and pause attackers with
the actual hidden Markov models neural
networks that do the speech recognition
and not and altogether by combining them
achieve better results that way when it
comes to identifying you know concepts
and tagging them in a medical corpus
such as sno-med we use a lot of
classifiers you know we use anything
from from a statistical classifier such
as a hidden mark even the hidden Markov
model all the way to maximum entropy
models and things like that yeah I know
you've begun to incorporate a modal into
commercially Amar's I believe Greenway
here locally is was the first how's that
going it's going really well you know
initially there was a little bit of a
reluctance by the EMR community I would
say to even incorporate speech
technologies into their systems there
was this perception that physicians will
eventually converge on structured data
entry and will accept the drop-down
menus and the choice lists that they
have in their systems but the opposite
did happen the physicians were pushing
back harder and harder and saying we
need to preserve the narrative not just
from a Productivity perspective they
don't just want to be more productive
and faster in entering the data but they
also want to tell a story they want to
be able to explain you know what they
thought about what the thought process
was in the diagnosis why they tried
certain things and why they worked or
didn't work and that you just simply
cannot do with by picking from a choice
list you have to be able to narrate a
paragraph or two and so this need for
not just speech technologies but just a
narrative a way to enter a narrative
whether it's typing you know speech
recognition or other ways what was was
really something that they pushed hard
for and EMR community has come around
we're not aware of a sim a single big
vendor you know that's epic
Cerner Greenway Athena or all scripts
all these companies have come around and
are now heavily investing into
preserving a narrative part of the chart
of the physicians there of the
physicians documentation and so as part
of that they are all including some sort
of a speech technology for authoring
these things but also there are more and
more incorporating natural language
processing technologies in order to
the narrative and find the relevant
information and combine it with the
structured data that they have where
when you look forward beyond where we
are today at the future of healthcare
and the potential role and future of
voice recognition technology such as
yours what do you see I wouldn't limit
it to just the speech technologies I
think for me again it's a it's a
narrative and what I find exciting in
healthcare is that there is this
Renaissance almost of of the narrative
in physician documentation you know it
started out with that since 100 years
ago physicians have been writing and
scribbling and really telling a story
about their patients and then it was
kind of a you know on the verge of being
abandoned
with all these initial EMR systems and
by you know using drop-down menus and
choiceless pick lists and now you see
the opposite happening again physicians
are creating much much richer and
storyline and a narrative around their
patients and the more these technologies
mature the more the better the speech
recognition gets the better the natural
language processing taggers and identify
us get the more use cases you see you
know appearing and to me the exciting
thing is that we can get to real
evidence-based minute medicine in the
next few years where you can use these
millions and millions of you know
clinical documents that the physicians
are creating in any given Hospital that
we can use those that we can scan those
that we can find trends that we can tell
exactly you know for this patient of
that gender that age with that disease
and that outcome this medication worked
or this medication didn't work and in
what context and we can use that
information to derive better treatments
and more accurate diagnosis for it for
other patients and I think that's when
you know when you haven't you really
have reached at the evidence-based
medicine
realm that we're all talking about and
and really haven't achieved yet yeah I
think there's a very exciting landscape
that you portray I hope the students
remember these comments when in lesson
10 we we look at some of the
contemporary research efforts in things
like clinical decision support so thank
you very much
I'm thrilled to see how far you guys
have come since I first visited you I
don't remember how many years ago and
perhaps we can do this interview again
in two or three years and see what
you've done then any time in my pleasure
thank you
thank you Mark</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>