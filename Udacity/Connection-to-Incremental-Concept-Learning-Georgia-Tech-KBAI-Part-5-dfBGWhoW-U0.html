<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Connection to Incremental Concept Learning - Georgia Tech - KBAI: Part 5 | Coder Coacher - Coaching Coders</title><meta content="Connection to Incremental Concept Learning - Georgia Tech - KBAI: Part 5 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Connection to Incremental Concept Learning - Georgia Tech - KBAI: Part 5</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dfBGWhoW-U0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">there is one more important point to be
noted here this again is the
illustration from incremental concept
learning when we were talking about
incremental concept learning we talked
about techniques for learning we did not
talk about how this concept we're going
to be used however in learning by
correcting mistakes we're talking about
how the agent actually uses the
knowledge it learns this point to the
center to knowledge-based AI for several
reasons your first reason is that
knowledge based AI looks at reasoning
looks at action decides how knowledge is
going to be used and then determines
what knowledge is to be learned it sets
the target for learning secondly you may
recall this particular figure for the
cognitive architecture that we had drawn
earlier you may see that reasoning
learning and memory are closely
connected and all of that is occurring
in the surface of action selection this
figure suggests that we not only learn
so that we can do action selection but
additionally as we do action selection
and we get feedback from the world it
informs the learning as this figure
suggests intelligent agents cognitive
systems not only learn so that they can
take actions of the world but further
that the word gives them feedback and
that feedback informs the learning once
again failure a great opportunities for
learning one additional point to be made
here learning by correcting mistakes
views learning as a problem-solving
activity an agent meets failure it needs
to learn from the failure it converts
this learning task into a
problem-solving task that is first
identify what knowledge error led to the
failure then let us build an explanation
for this then we will repair it this
learning is closely intertwined with
memory reasoning action and feedback
from the world notice also there's
reasoning learning and memory here in
the deliberation module a closely
connected rheumatic ignition module here
the reasoning memorial learning may be
about action selection of the world but
a metacognition module may have its own
reasoning learning and memory capacities
and some of the learning of the
metacognition is about fixing the errors
in the deliberative reasoner so
metacognition is thinking about thinking
the agent used certain knowledge to
think about the action selection and it
conducted those actions in the world
metacognition is thinking about what
went wrong in his original thinking what
was the knowledge error will turn to
metacognition in the lesson on meta
reasoning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>