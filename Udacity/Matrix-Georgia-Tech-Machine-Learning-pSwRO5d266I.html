<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Matrix - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Matrix - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Matrix - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pSwRO5d266I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay Michael so let's try to be a little
bit more detailed about kind of the
mechanics of how you how you would make
this work the algorithms for finding
independent component analysis are in
all the reading but I do think it's
pretty easy to kind of get lost if you
don't sort of turn these matrices into
actual numbers so let me just sort of
give you a quick example of how we would
do this specific thing here and see if
that helps okay okay so how would you go
about turning this into a problem that
something like you know an actual
algorithm that uses numbers could do
well it turns out it's fairly
straightforward and let's just take this
this particular example here with people
talking to a microphone basically you
create a matrix which are samples of all
of the sounds so in our original space
we have you know this handsome person
here we have this other let's say
similarly handsome but in a different
way person here and we have this other
person with my poor attempt to draw hair
over here and they're talking well what
we end up doing is we basically take
this sound wave and we sample it and
what does it mean to sample it well you
know you represent sound in a computer
as a sequence of numbers just like you
represent pictures as a sequence of
numbers and in fact you represent words
as a sequence of numbers and so we
basically turned these sound waves into
a matrix full of values so as I
described before Michael each one of
these microphones is actually getting a
linear combination of speech from each
of these three individuals so if we
think of microphone one it is seeing
some kind of sound wave which is again a
linear combination from each of these
people generating the sound wave the
same is true for microphone two and
similarly for microphone three now of
course we're talking about recording
these and we're thinking about computer
programs which means we take this
continuous sound wave and we sample it
at a very fast rate and what we end up
with is a sequence of numbers that
represent the particular pressure that
we're getting in these sound waves so
these sound waves get converted into a
sequence of numbers and I'm just going
to make up some numbers for this and now
what we have is a matrix where each row
represents a feature in our original
feature space and by original here I
mean the feature space that we see each
of our microphones
and every column represents a sample say
at time zero time 1 time 2 and so on
does that make sense yes and so since
each of these is a linear combination of
these voices we get here our goal is to
find a projection like we did before in
the original definition of the problem
such that if we projected this onto here
we would end up with the new feature
space that corresponds individually to
each of these people and you could do
this with anything it doesn't have to be
sounds if we think about the ad hoc
query problem that we went through
earlier each of these would be words and
say their presence of words would be
your features and each of these columns
would be documents say and the goal
would be to find a projection given a
set of documents that allowed us to
recover some underlying structure that
was useful for classification or for
information retrieval does that make
sense yeah and can you say what does it
mean for that sequence to have mutual
information ah so as you recall because
I know that you listen to push cars a
discussion about mutual information and
entropy and so forth all mutual
information is is a measure of how much
one variable tells you about another
variable and the assumption here is that
each of these people talking has no
mutual information that is they're
talking independently of one another or
the sounds that are coming out of their
mouths don't allow us to predict the
sounds that are going to come out of
another person's mouth so it may me that
these people are actually talking to one
another as we often do Charles might be
talking to Michael who's talking to push
cars talking back to Michael is talking
to Charles but the exact sound waves
that we see are actually independent of
one another so that turns out to be true
what independent components analysis is
trying to do is trying to recover
features in this case it turns out to
corresponding to individual speakers
such that their sound waves are the
values that you see are statistically
independent of one another okay and
that's what this does but since we could
always come up with arbitrary
projections that are statistically
independent it's important that whatever
our new transformation gives us
it actually has some relationship with
the original values that we saw so
somehow we want to be able to transform
this into this in a way that we don't
lose any information in much the same
way that PCA was trying to minimize the
loss of information and so we not only
want each of the individual new features
in this case people to be statistically
independent we want the amount of data
that we get from these people compared
to the amount of data that we got
originally from the microphones to
actually strongly predict one another
and if the mutual information between
the microphones and our candidates for
the people's voices have high mutual
information then it means we haven't
lost anything and so those two things
together those two constraints forced us
into a situation where if this model is
true we construct the original voices</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>