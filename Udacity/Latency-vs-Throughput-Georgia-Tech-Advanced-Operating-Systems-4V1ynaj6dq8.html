<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Latency vs Throughput - Georgia Tech - Advanced Operating Systems | Coder Coacher - Coaching Coders</title><meta content="Latency vs Throughput - Georgia Tech - Advanced Operating Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Latency vs Throughput - Georgia Tech - Advanced Operating Systems</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4V1ynaj6dq8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so it's important to understand these
two concepts of latency and throughput
latency is the elapsed time for an event
if it takes me one minute to walk from
my office to the classroom
that's the latency that I'm going to
experience for that event of walking
from my office to the classroom let's
say lapse time throughput is the number
of events that can be executed per unit
time bandwidth is a measure of
throughput so once again with this
analogy of walking to the classroom from
my office
if the hallway is wide enough to allow
five ten of us to walk in parallel
side-by-side to the classroom increases
the throughput but it does nothing to
the latency the latency is going to be
determined by how fast I can walk from
my office to the classroom so the
difference between latency and
throughput is very important to
understand in in other words I can
increase the bandwidth and that will
improve the throughput but it is not
going to do anything to the latency
itself so in other words higher
bandwidth does not necessarily imply
lower latency your work hard to lower
the latency our PC is the basis for
client server based distributed systems
and performance of our PC is crucial
specifically in the context of this
lesson latency refers to the time it
takes for an application generated
message to reach its destination so for
instance if you're doing an RPC call
from a client to the server then the RPC
call entails sending the arguments from
the client to the server and there is
work to be done here work to be done and
sending the message work to be done here
before the server can actually execute
the server procedure so there's a
latency that we are concerned about and
what we will see is all the software
components that comprise the latency for
RPC based communication and performance
of RPC is very crucial in building
client-server systems there are two
components to the latency that is
observed for message communication in a
distributed system the first component
is a hardware overhead
it and the second component is the
software overhead the hardware overhead
is really dependent on how the network
is interfaced to the computer so
typically in any computer what you have
is a network controller that interfaces
the network to the CPU and typically the
network controller operates by moving
the bits of the message from the system
memory of the node into its private
buffer which is inside the network
controller and this part of it moving
the bits from the memory of the node
into the internal buffer of the network
controller is accomplished using what is
called direct memory access meaning the
Network Controller is smart enough to
move the bits directly using the bus
that connects the memory to the network
controller without the intervention of
the CPU and this is what is called
direct memory access and that's how the
bits are moved from the memory of the
system into the buffer of the network
controller and once it comes here the
network controller can then put the bits
out on the wire and this is where the
bandwidth that you have connecting your
node to the network comes into play but
there are also other types of network
controllers where the CPU may actually
be involved in the data movement and in
that case the CPU does programmed i/o to
move the bits from the memory into the
buffer of the network controller from
which the network controller will then
put it out on the network but modern
network controllers tend to be built
using DMA technique meaning that the
network controller once the CPU tells
the network controller were in memory
the messages to be sent on the wire
network controller does the rest in
terms of moving the bits into its
internal buffer and then from the buffer
putting it out on the network the
software overhead is what the operating
system tacks on to the hardware overhead
of moving the bits out onto the network
so the latency if you think about the
latency as a whole for doing a network
transmission there is the software
overhead incurred in the layers of the
operating system to make the message
available in the memory of the processor
ready for transmission once it is ready
for transmission the hardware overhead
kicks in and the hardware the network
controller in particular moves the bits
from the memory into its buffer and then
out on the wire the focus of course
being an operating system designers work
is to reduce the software overhead and
take what the hardware gives you and
think about how you can reduce the
software overhead so that we can overall
reduce the latency involved in
transmission which is the sum of the
hardware overhead and the software
overhead</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>