<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Piecewise Linear and Convex 3 Part two | Coder Coacher - Coaching Coders</title><meta content="Piecewise Linear and Convex 3 Part two - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Piecewise Linear and Convex 3 Part two</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/q-VlOcLGrAs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so what's the last one so what we're
gonna do in the last step and I probably
shouldn't go through all the grungy
details though all the all the pieces
that you need for this have been in
stuff that I've said but what we're
trying to do now is represent this value
function v AZ of T applied to the belief
state B and we said that was going to be
basically a dot product of the belief
state with some kind of reward vector
for the current action plus a weighted
version of the value function for the
previous time step so it's going to be
helpful to actually take the value
function at the previous time step and
and write it out more explicitly so this
is basically just expanding on the
definition of the state estimator that
we did in the previous slide mm-hmm
we're gonna say that the value according
to the t minus 1 time step value
function for the belief state that we
get from taking action a and making
observations Z from belief state B we
can write this out as the maximum over
all vectors in that set of the dot
product of that vector with the
resulting belief state which we had
previously derived to have this form
okay the observation function times the
transition function times the beliefs
date and then normalized and this
normalization factor is the probability
of making the observation Z given that
we're in belief state B and action a
this is a highly nonlinear function but
this is the awesome part ready since
we're going to ultimately multiply this
value function times the probability
that Z is the actual observation in
other words probability of Z given B
comma a this and this end up canceling
and what we're left with is an actual
linear transformation so this this weird
divided by thing that actually makes
things really yucky cancels itself out
so convenient just like life not usually
but math sometimes does this for us and
so at the end of the day we end up with
a quantity that that is a dot product
with the belief state and another
quantity that is a dot product with the
belief state we can factor out the
belief state and what it leaves us with
is is a giant vector one for each
combination of observation action and
which gamma is going to be the maximum
at that observation so we actually have
to take the product of the number of
vectors that was in the t minus 1 set
raised to the number of observations
times the number of actions and that's
going to be the maximum size of the set
that we get for representing the T step
value function so like you said could
could blow up but still finite can't
blow up to be infinite if it started out
as finite nice so that feels like a
proof by induction to me great okay and
so you wouldn't want to actually do this
there is code in burlap for for doing a
lot of these processes there's also my
collaborator Tony Cassandra created a
program called Pompey Pisa that you can
download that actually lets that does
all these calculations carefully and and
you know on your behalf so I didn't
really want to get this to the point
where you could actually necessarily
code all this up just to believe that
it's code up a ball and you know you can
use an existing implementation if you
want to actually run it very
mathematical so there's one more step
before we can get something that I mean
you can't actually implement it this way
but this is guaranteed to be exponential
because you're actually combining all
these things together there's one step
that we can do that if it's the case
that the queue functions have a small
representation then the algorithm will
run quickly alright here it could be
that the queue functions are actually
very very big Oh in case it's not
obvious the queue functions I
represented right there oh yeah I called
it V a sub T but that's really the cue
function I like it I like it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>