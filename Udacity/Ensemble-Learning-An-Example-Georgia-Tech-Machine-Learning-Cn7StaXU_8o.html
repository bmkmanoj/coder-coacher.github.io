<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ensemble Learning An Example - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Ensemble Learning An Example - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ensemble Learning An Example - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Cn7StaXU_8o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right Michael so here's what you
have before you you have the same
housing data that we've looked at a
couple of times before I've for the sake
of readability I've drawn over some of
the data points so that they're easier
to see but this is exactly the data that
we've always had okay okay
now you'll notice that I marked one of
them as green because here's what we're
going to do I'm going to take the
housing data you've got I'm going to do
some ensemble learning on it and I'm
going to hold out the green data point
okay so of the nine data points you're
only going to learn on eight of them and
I'm going to have that Dean green data
point is my test example and see how it
does okay okay so that sounds like
cross-validation it does it's a
cross-validation or you could just say
I've just put my training set and my
test set in the same on the same slot
okay okay Michael so the first thing I'm
going to do is I'm going to pick a
random subset of these points and just
for the sake of the example I'm going to
pick five points randomly and I'm going
to do that five times so I'm going to
have five subsets of five examples and
by the way I'm going to choose those
randomly and I'm going to choose them
with replacement so we're not going to
end up in the situation we ended up just
a couple of minutes ago where we never
got to see the same data point twice
okay yeah all right so five subsets of
five examples and then I'm going to
learn a third order polynomial I'm gonna
take those third order polynomials I'm
just going to learn on that subset and
then I'm going to combine them by
averaging I want to see what we get oh
yeah sure so here's what you get Michael
here I'm showing you a plot over those
same points with the five different
third order polynomials can you see them
yeah that right there's like a bunch of
wispy hairs just like most third order
polynomials and as you can see they're
kind of you stare at them you can see
they're kind of similar but some they
sort of veer off a little bit because
they're looking at different data points
one of them actually very hard to see
because it's the only one like this
actually veers off like this because
just purely randomly it never got to see
the two final points I see but they all
but they all seem to be pretty much an
agreement like between points three and
four there's a lot of consistency there
right because just
five of the subsets you seem to be able
to either get things on the end or you
get things in the middle and maybe one
or two things on the in it sort of works
out even the one that doesn't see the
the last two points still got to see a
bunch of the first ones and gets this
part of the space fairly right cool okay
so the question now becomes how good is
the average of these compared to
something we might have learned over the
entire data set and here's what we get
when we do that so what you're looking
at now Michael is the red line is the
average of all of those five third order
polynomials and the blue line is the
fourth order polynomial that we learned
when we did this with a simple
regression a couple of lessons back and
you actually see they're pretty close
why is one of them a fourth order and
one a third order well what I wanted to
do is try a simpler set of hypotheses
than we were doing when we were doing
full blown regression so third order
simpler than fourth order so I thought
we would combine a bunch of simpler
rules than the one that we'd used before
and see how well it does you wanted our
well it does I would well it turns out
that on this data set and I did this
many many many times just to see what
would happen with many different random
subsets it typically is the case that
the blue line always does better on the
training set the red points then the red
line does but the red line almost always
does better on the Green Point on the
test set or the validation set
interesting that is kind of interesting
so wait so let me get this straight it
seems sort of magical so so it learns an
average of third degree polynomials
third order polynomials which is itself
a third order polynomial but you're
saying it does better by doing this kind
of trick than just learning a third
order polynomial
directly yeah why might you think that
would be I have a guess you tell me what
you think Wow so well I mean you know
the danger is often overfitting
overfitting is like the the scary
possibility and so maybe by but kind of
mixing the data up in this way and
focusing on different subsets of it I
don't know somehow manages to find the
important structure as opposed to
getting misled by anything too
visual data points yeah that's the basic
idea it's kind of the same thing at
least that's what I I think that's a
good answer it's basically the same kind
of argument you make for cross
validation and you take a bunch of
random subsets you don't get trapped by
one or two points that happen to be
wrong because they happen to be wrong
because of noise or whatever and you
sort of average out all of the variance
and the differences and oftentimes it
works and in fact in practice this
particular technique of ensemble
learning does quite well in getting rid
of overfitting and what is this called
so this particular version where you
take a random subset and you combine by
the mean it's called bagging and I guess
the bags are the random subsets sure
that's how I'm going to think of it
that's how I'm going to think of it it
also has another name which is called
bootstrap aggregation so I guess the
different subsets are the boots
no no bootstrap usually refers to or
pulling yourself up by your bootstraps
yeah I like my I like my answer better
so each of the subsets are the boots and
the averaging is the strap and there you
go so regardless of whether you call it
bootstrap aggregation or you call it
bagging you'll notice it's not what I
said we were going to talk about during
today's discussion I said we were going
to talk about boosting so we're talking
about bagging but we're going to talk
about boosting the reason I wanted to
talk about bagging is because it's
really the simplest thing you can think
of and it actually works remarkably well
but there are a couple of things that
are wrong with it or a couple of things
you might imagine you might do better
that might address some of the issues
and we're going to see all of those when
we talk about boosting right now</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>