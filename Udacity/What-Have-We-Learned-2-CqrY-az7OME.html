<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What Have We Learned? - 2 | Coder Coacher - Coaching Coders</title><meta content="What Have We Learned? - 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What Have We Learned? - 2</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CqrY-az7OME" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so i think that was almost it was
there anything else yes we then made a
leap to Monte Carlo tree search I
wouldn't say it was a leap we climbed a
Monte Carlo tree yes and did some search
and what do we learn about Monte Carlo
tree search so it's really important to
help with scaling because it lets you
have computation that's independent of
the size of the state space even though
it depends very possibly badly on the
length of the horizon right so it's got
a low Oh on the state space practice
independent but it has a big o on the
horizon which I'll just call each year
and it's exponential Annette yeah in
fact it's exponentially it looks like
hydrogen now so uh does MCTS and
abstraction fit together in any way we
could make it if we were abstract enough
uh-huh see what I did there if you pop
back up far enough you can sort of think
of it as a kind of abstraction over
actions and policies so no I was
thinking in particular that the idea
that in MCTS the way we talked about it
it was talking about specific States
ground-level states like if we have a
good way of abstracting states can we
use those abstract estates in MCTS
context oh sure Beck what I was about to
say is that all of the stuff that we
learned about generalization up here can
apply to MCTS some more easily than
others doing the function approximation
is sometimes quite hard but not really
because of the way that we're sort of
thinking about the queue functions but
the temple abstraction works very well
because I can use options instead of
actions to to do my my MCTS all right
you said that yeah even so that the and
as a result the state abstraction and
the gold abstraction can also follow
through there if you think about each of
the individual modules is doing their
own version of MCTS but MCTS is a very
general notion so if I were trying to
decide between different modules that I
might take it will look exactly like
trying to do the sequential decision
making and MCTS will work either way but
the big temporal abstraction is a huge
win for MCTS because again all of its
difficulty lies in the site the link
horizon right so if I'm able to search
far ahead in the future that lowers my
effective horizon nice right so okay so
if these ideas are so important for
scaling up to you do you feel like
they've contributed to I don't know the
ability of reinforcement learning to
solve some real problems oh yeah
absolutely no these things actually come
up quite a bit they've been used in a
lot of games MCTS has been used well
it's all in the papers that the students
were MCTS has been being used to solve a
bunch of game problems in just my own
work as well as in a variety of other
things you probably know a few more of
the top of your head but really any time
you have a huge state space or
potentially huge state space these kinds
of abstractions turn out to be extremely
useful some of them are easier to think
about than others function approximation
is very nice but does have its own
problem with picking the right features
particularly are going to be done linear
about it temple abstraction is often
quite useful because people can help you
come up with things like options or
constraints gold abstraction has a kind
of similar flavor to it and because of
those things the state abstraction helps
basically anything that lets you lower
the number of states or the effective
horizon has to make the reinforcement
learning problem easier nice right so
their scalability these things actually
work they actually are helpful and this
is a huge wide-open field in
reinforcement learning in fact to your
point I'll just sort of end it with this
that I think that reinforcement learning
has gotten so good at solving kind of
well-thought-out grid-like problems that
the field is really interested in
increasingly more interested in figuring
out how to make it work in the real
world and these kind of techniques these
abstraction techniques these scaling
techniques become increasingly important
as we try to move it out into the real
world this is a good thing Wow glad you
told me about it I'm about helping
others so I think we're good so uh I
guess goodbye Michael until next time
alright yes he then</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>