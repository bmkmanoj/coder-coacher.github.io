<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Bellman Equations - 1 | Coder Coacher - Coaching Coders</title><meta content="The Bellman Equations - 1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Bellman Equations - 1</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/b1GvQcjDwBU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this is the bellman equation that
we're just talking about right so the
value of a state is the max over all the
actions the reward that you get for
taking that X from the state plus the
discounted value of the state you end up
in weighted by the probability that you
end up there so this should look
familiar right no it does look familiar
at all I mean there's a V there's a Max
on the outside there are more
parentheses it's a reward of si instead
of it what you're making this up uh okay
so first of all parentheses shouldn't be
an issue right parenthesis just let you
group things but yeah I think you did
actually explain this a different way in
the other lecture so I use V for value
instead of U for utility okay and I I
think of rewards as being issued as a
function of taking a state in an action
so start taking an action in the state
which is to say that you're in some
state of the MDP so in particular for
win some state s and we take some action
a we get some reward for having done
that RSA and then we land in some new
state s Prime I guess that is different
how you didn't how you were talking
about it before yeah but you know when
we went over the the definition of an
NDP I did point out that you could think
of reward as a function of state or as a
function of state in action or as a
function of state action in next state
and they were kind of all mathematically
equivalent so so this is what we're
going to be doing for for the rest of
this class we're going to be talking
about it this way yeah I'm used to
thinking about V as being the value
function so it'd be I think I'm going to
slip into it no matter what we might as
well just switch to it okay so we're
going to do these we're going to our
essays but everything that we learned
before in our Scooby Doo flashback still
holds now yeah yeah this is it's just a
it's notational difference and otherwise
it really leads you to the same stuff
okay we shall see so what the bellman
equation is supposed to represent is the
sequence of rewards received by an agent
the topping around in the world it
starts off in state s1 it takes action
a1 it gets reward rs.1 a1 for that then
it lands in state s2 and from there it
takes action a 2 and receives reward rs2
a 2 and lends up in s3 and this whole
process just continues at infinitum okay
so you're seeing a bunch of SAR SAR SAR
SAR SAR s exactly right you can think of
history is just being SARS ours ours are
are oh so it's like a pirate with a
reverse Lisp yeah I guess that's one way
to think about it so so when we talk
about the value of this sequence it's
almost as if what we're talking about is
the value given that we start off in
some state s and we notice that
eventually that we're going to get to
some new state s and that value can also
be represented by this value function
and so that's what gives us this
recursive form that the the value of the
next state can be plugged in to
represent the infinite rest of the
sequence sure that's that sort of the
whole point okay how about that cool all
right so we're going to now try to mess
this up a little bit by thinking about
infinity a slightly different way as
bigger or smaller just starting it in a
different place okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>