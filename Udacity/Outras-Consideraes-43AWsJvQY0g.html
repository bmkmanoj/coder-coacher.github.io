<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Outras Considerações | Coder Coacher - Coaching Coders</title><meta content="Outras Considerações - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Outras Considerações</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/43AWsJvQY0g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what we've covered so far in this class
is a very simplistic and very partial
coverage of linear regression with
gradient descent if you were ever to try
and use linear regression to solve a
real-world problem there are a lot of
additional considerations that you would
want to think about in order to
seriously implement linear regression
with or without gradient descent first
of all gradient descent is only one
implementation of linear regression
there are a bunch of other ones and in
some sense they may be better ordinary
least squares for example is always
guaranteed to find the optimal solution
when performing linear regression
whereas gradient descent is not
additionally we haven't really talked
about parameter estimation and putting
confidence intervals on those parameters
in the models that we've built we've
given exact values for all of our Thetas
but as you can imagine there's some
confidence that we have in those values
you can imagine doing more thorough
statistical analysis in saying what are
the confidence intervals on these
parameters and we could answer questions
like what is the likelihood that I would
get this value for this parameter if
this parameter actually had no effect on
our output variable we also might worry
about issues like over or under fitting
this isn't so much a problem with linear
regression but with more complicated
models you might expect our model to
overfit say we had some data like these
red points that was approximately linear
if we had a model with many different
parameters we might be able to fit the
data points exactly where as the actual
underlying model is this black line one
way to deal with this is usually to
split our data into a training set and a
test set then we can train a model on
the training data and then test it on
the test data just as the name would
imply this is called cross-validation we
might also see under fitting where we
have data that's clearly nonlinear but
we only try and fit a linear model to it
this is also a problem that you might
encounter another issue worth mentioning
again is that our cost function may have
numerous local minima that means that
when using gradient descent our
algorithm can become trapped in a local
minimum that isn't actually the global
minimum of the cost function this isn't
a problem with other implementations of
linear regression but when using
gradient descent this means that maybe
we
perform gradient descent numerous times
randomizing our initial values of theta
with different random values every time
you may also already know this but when
using a random number generator to
generate random values it's important to
seed your random values and to store
that seed that way you have a result
that's replicable and other researchers
can look at your findings and also
produce them on their own machines when
they run the same script this has been a
whirlwind tour of a bunch of additional
considerations that we didn't really
touch in this lesson these are all
really important in machine learning
statistics using linear regression in
the real world I really wanted to focus
here on just implementing gradient
descent and the basics of how it works
but if you really wanted to use any of
these things to solve a real-life
problem you'd want to think about local
minima you know other implementations of
linear regression the confidence
intervals on your parameters and if
you're using a statistical modeling
package in our or Python or Stata
they'll usually give you these
confidence intervals and use a reliable
implementation of linear regression</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>