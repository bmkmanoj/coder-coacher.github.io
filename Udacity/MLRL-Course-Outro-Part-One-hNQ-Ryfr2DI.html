<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MLRL Course Outro - Part One | Coder Coacher - Coaching Coders</title><meta content="MLRL Course Outro - Part One - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MLRL Course Outro - Part One</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/hNQ-Ryfr2DI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi Michael hey Charles well that was fun
that was fun we should do it again I
don't think we need to do it again I
think we've now covered everything we
wanted to say about reinforcement
learning and I'm completely sure that we
haven't well what haven't we covered
well what happened we haven't recovered
well we haven't we haven't we covered TD
lambda sure so we talked about TD lamb
that we talked about a few our rhythms
who are there but we haven't really
touched on the big questions we haven't
covered everything that we should like
burlap we have definitely covered burlap
ok sure there was a tutorial and you
know there were assignments about it but
you haven't answered the big question of
Berlin which is what why burlap why do
we need anything like burlap why don't
you just use the UCI database and Weka
we're done right so the UCI data set or
the repository and Weka are really great
for supervised learning but they're not
actually well situated for reinforcement
learning Weka doesn't include
reinforcement learning algorithms in it
the UCI repository doesn't include
reinforcement learning problems in it
you really need a different setup for
dealing with ree importantly any
difference ok i don't i don't understand
that so we have algorithms we've talked
about many of them in class that's right
so algorithms are algorithms are
algorithms are algorithms and this is
all machine learning and so all we need
is data and that's what repositories are
for data so well yes a burlap is trying
to answer both of those issues one of
the things that burlap is trying to be
as a collection of those algorithms or
algorithms or algorithms or algorithms
mm-hmm and it's also providing kind of a
replacement for data so data in the
reinforcement learning setting is really
hard to work with instead what burlap
has is a set of simulators the ability
to act like the environment so that the
learning algorithm can interact with it
and learn from that oh I see so the key
word there is interact so the notion and
supervised learning is you've just got
data you've got input and output pairs
and put in output pairs but as we
pointed out multiple times the
reinforcement learning is not just about
em put it out put you in back get to see
states and rewards you take actions
those are the kinds of things that you
do and that requires interaction right
and the data that you actually see
depends on how you're exploring the
environment so just capturing a big
static set of data and presenting that
to the learner isn't really the
reinforcement learning okay so I like
that so I her tooth
there one thing i like and one thing I
don't like the thing that I like is that
you've distinguished reinforcement
learning from supervised learning you've
talked about the need for interaction
and how that's sort of crucial and you
said your solution was having simulators
right so I agree that that's not a
that's not a great thing so so
simulators are good in the sense that
you can actually interact with them and
so it's a way of transferring an
environment or a test problem from one
research group to another research group
sounds good but on the bad side they're
not really data it's not actual data
coming from a problem its just faked oh
so then you're suggesting this is the
second thing that I didn't think I like
you're suggesting that we don't have any
way to make reinforcement learning work
in the real world it is more challenging
but it is not the case that
reinforcement learning hasn't been used
to solve some real problems like what so
it's worth probably mentioning a few of
them we talked about backgammon as part
of the class the TD gammon algorithm
that actually learn to play back em and
at a level comparable to if not better
than human beings there's other sorts of
problems that are probably worth talking
about as well elevator control is an
interesting problem to think about from
a reinforcement learning perspective how
so that was an elevator controller
reinforcement learning from elevator
control if you think about the elevators
in the building they're trying to work
together to move people to where they
want to go and so we have actions we
have states and we have rewards the
actions are where the elevators are
trying to go whether or not they're
going to open their doors at a given
floor the states are what is the
arrangement of all the different
elevators at the moment which floors
have elevators on them which don't which
buttons of them press which buttons have
impressed so who's waiting on on which
floors and from the reward perspective
you can try to get the system to try to
minimize wait time for people right so
that's something that you can measure
how long is somebody waiting on the
third floor for the elevator to come and
then eventually getting to the
destination floor and at some that's
something you can measure in something
that you can try to find ways of
behaving to improve ok cool so that's a
reinforcement learning problem I like
that anything else yeah so that one
actually was done in simulation oh okay
but there has been a some some good work
in reinforcement learning in robotics so
one that's maybe worth mentioning is the
the helicopter work</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>