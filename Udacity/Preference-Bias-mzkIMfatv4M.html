<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Preference Bias | Coder Coacher - Coaching Coders</title><meta content="Preference Bias - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Preference Bias</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/mzkIMfatv4M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right another issue that we want to
make sure that we think about each time
we introduce a new kind of supervised
learning representation is to ask what
it's preference biases so Charles can
you remind us what preference bias is
like restriction bias tells you what it
is you are able to represent preference
bias tells you something about the
algorithm that you're using to learn
that tells you given two representations
why it would prefer one over the other
so perhaps if we think back what we
talked about with decision trees
we preferred trees where nodes near the
top had high information gain we
preferred correct trees we preferred
trees that were shorter to ones that
were longer and necessarily and so on
and so forth so that actually brings up
a point here which is we haven't
actually chosen an algorithm you talked
about how derivatives work how
backpropagation works but you miss
telling me one very important thing
which is how do we start you tell me how
to update the weights but how do I start
out with the weight so they all start
out at zero do they are start out at one
how do you usually set the way to the
beginning yes indeed we did not talk
about that that's it's really important
you can't run this algorithm without
initializing the weights to something
right we don't talk about how you update
the weights but they don't just you know
start undefined and you you can't just
update something that's undefined so we
have to set the initial weight to
something so a pretty typical thing for
people to do is small random values so
why do you suppose we want random values
because we have no particular reason to
pick one set of values over another so
we start somewhere in the space probably
helps us to avoid local minima yeah kind
of I mean there's also the issue of well
if we run the algorithm multiple times
if it gets stuck we'd like it to not get
stuck exactly there again if we do if we
run it again so it gives some
variability which is a helpful thing in
avoiding local minima and why do you
suppose it's important to start with
small values well you just said in our
discussion before that if the weights
get really big that can sometimes lead
to overfitting because it lets you
represent arbitrarily complex functions
good and so and what does that tell us
about what the preference bias is that
well if we start out with small random
values that means we're starting out
with low complexity so that means that
we prefer simpler explanations to more
complex explanations and of course the
usual stuff like we prefer correct
answers to incorrect answers and so on
and so forth
so you'd say that neural nets implement
or maybe we should say that neural
networks implement a kind of bias that
says prefer correct over incorrect but
all things being equal the simpler
explanation is preferred well if you
have the right algorithm if the
algorithm starts with small random
values and tries to stop and when you
start overfitting then yeah because
you're gonna start out with the simpler
explanations first before you allow your
weights to grow so yeah I buy that so
this is reminiscent of a principle
that's known as Occam's razor which is
often stated as entities should not be
multiplied unnecessarily and given that
we're working with neural networks
there's a lot of unnecessary
multiplication that happens but in fact
this actually is referring to exactly
what we've been talking about so this
unnecessarily is we're one
interpretation of this is that well when
is it necessary it's necessary if you're
getting better explanatory power you're
fitting your data better so
unnecessarily would mean well we're not
doing any better at fitting the data if
we're not doing any better at fitting
the data then we should not multiply
entities and multiplied here means make
more complex so don't make something
more complex unless you're getting
better error or if two things have
similar error choose the simpler one use
the one that's less complex that has
been shown to if you mathematize this
and you use it in the context of
supervised learning that we're gonna get
better generalization error with simpler
hypotheses</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>