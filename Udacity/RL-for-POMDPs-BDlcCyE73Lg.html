<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>RL for POMDPs | Coder Coacher - Coaching Coders</title><meta content="RL for POMDPs - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>RL for POMDPs</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BDlcCyE73Lg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so now that we have an idea of what Palm
DPS are about maybe we should talk a
little bit about what it might mean to
do reinforcement learning in them
because we basically talked about
planning if we have a model of the pond
DP we can run some calculations we can
run value iteration to get a way of
deciding what to do actually did it did
I say that I think I did not say that I
think what i said is how you get a value
function is it clear how you would use a
value function to get a policy in the
same way you would for an NDP right yes
no that's not true yeah yeah that's
right if you have the model then you can
use one step look ahead with the value
function to figure out what the optimal
action is in any given belief state once
we've run value duration and gotten a
approximation of the optimal value
function oh and what about that
valuation doesn't actually necessarily
converge it doesn't you didn't tell me
that I did actually when we were doing
in Lesson triple a lesson triple a yeah
the advanced algorithm analysis what we
said there is that value iteration
converges in the limit to the right
value function but and after any finite
number of steps that need not have the
optimal value function but it will after
some finite number of steps have the
optimal policy that's not going to be
true in the palm DP case because there's
an infinite number of states oh but it
is going to be the case that we get an
arbitrarily good approximation after
some finite number of iterations wait
arbitrarily good approximation of what
of the optimal value function wait but
not necessarily optimal policy yeah if
you do one step back ups we're one step
look ahead with a near optimal value
function you'll get a near optimal
policy ok so that's nearly good now that
we've talked about planning in Palm DPS
we should talk about reinforcement
learning in palm bp's Charles what's the
difference between planning and
reinforcement learning well I'm planning
you know everything in a reinforcement
learning you don't know everything and
you have to explore and exploit and do
all that other stuff in order to find
things out like you don't know the model
necessarily and that makes the problem
harder so what you're telling me is
reinforcement learning is harder than
planning in the way you're using the
words and palm DPS are more difficult to
deal with MDPs so reinforcement learning
and palm DPS should be like is that
additive multiplicative so reinforcement
learning in pocket piece is hard mmm
like super hard actually planning in
palm dps is formally undecidable in the
sense that undecidable yeah if i give
you a pom DP and ask is this
optoma first action to take from this
belief state if you could solve that
problem you could solve the halting
problem holy cow wait wait a minute wait
a minute wait a minute wait a minute
that has profound implications no it
doesn't yes it does because we're human
beings running around in the world we're
living in a pom DP because we can't know
everything so you're telling me that
even if I could relive life an infinite
number of times I still don't know what
the right thing to do is you're saying
that life is unknowable it's undecidable
you can never know what to do that's
profound wow I need a moment</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>