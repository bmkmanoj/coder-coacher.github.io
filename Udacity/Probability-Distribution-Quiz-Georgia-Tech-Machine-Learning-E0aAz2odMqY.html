<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Probability Distribution Quiz - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Probability Distribution Quiz - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Probability Distribution Quiz - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/E0aAz2odMqY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so we're gonna have a quick quiz
Michael insists on having one because
Michael likes that sort of thing and I
like Michael so I'm gonna go with him
and give you a quick quiz to see if you
follow along with what we talked about
now this quiz is less about the details
of mimic itself than it is about the
probability distribution so I've been
harping on this idea that mimic doesn't
care about your probability distribution
you should just pick the best one so we
want to make certain that you get that
by giving you three problems and three
probability distributions you might use
and see if you can tell us which one
goes with which okay so here are the
three problems the first problem is your
fitness function is to maximize the
number of won so the first thing you
need to to see is that we're going to
assume in all of these cases that our
input values X our binary strings of
length in okay so 0 0 0 0 0 0 1 0 0 1 0
1 1 1 1 1 0 0 1 1 1 whatever there's
gonna be a string of ones or 0 so
they're binary digits and the first
problem we want to maximize the number
of ones that appear in that sample do
you get that Michael yeah I mean that's
I mean that's gonna be maximized by just
making everything of one right that's
right that's okay but we want we want to
think about mimic finding that right
because you don't know that that's the
true underlying fitness function that
just happens to be what it is I see ok
so in the second problem we want you to
maximize the number of alternations
between bits so 0 1 0 1 0 1 0 1 is
better than all ones much better than
all ones in fact because the Fitness you
would get for maximized alternations
between 0 1 0 1 0 1 is in fact n minus 1
which is the largest that could be but
if you had all the digits being the same
your fitness would be 0 see that Michael
oh I see n minus 1 because it switched
every time it switches right got it so
what would maximize the number of
alterations and say a 5 digit string
like 0 1 0 1 0 or the complement of that
1 0 1 0 or 1 right so two values both
act as Maxima here ok the third problem
is you want to minimize two color errors
in a graph now that one's a little bit
harder to describe so I'm gonna draw a
little graph for you
so the to color problem you might
remember is given a graph with some
edges like say this graph here you want
to assign a color to each node such that
every node has a different color than
its neighbor okay so we assume there's
only two colors here one is zero so
let's say I assign this the color value
of one this is the color value of zero
this the color value of zero this the
color value of one and this the color
value of one so how many errors are
there Michael wait which oh we should be
trying to maximize but okay so I guess
not so minimize to clear so an error
would in this case would be an edge that
has the same color on both ends and I
see one of those the bottom sort of
reddish right so here these do not match
so that's good these do not match the
did another match but these two match
even though that one doesn't so there's
exactly one error so in these first two
examples we're trying to maximize a
fitness here we're trying to minimize a
cost just to make things slightly more
difficult for you if we removed this
edge here then you'll notice that this
has no mismatches whatsoever and this
would be an optimal yeah okay so we need
to figure this out okay so there we go
we want you to maximize the number of
ones in your string or maximize the
alternations by adjacent bits or to
minimize the number of two color errors
in a graph all right those are the three
problems now here are the three
distributions the first distribution
these are in alphabetical order is a
chain so a chain would be in kind of
Bayesian network speak a chain would be
a graph like this where basically every
feature depends upon its previous
neighbor so in a 4-bit string I'm saying
that the first bit depends on nothing
the second bit depends on the value of
the first bit the third bit depends on
the value of the second bit and the
fourth bit depends on the value of the
third bit so the way you would generate
samples is you would generate a sample
from here and then generate a sample on
here depending upon this value giving
that value you generate a sample here
given that value and you generate a
sample here given that value got it
Michael I think so so and we're
imagining that the ordering is given so
that so we know which ones depend on
which right so in fact it's not just a
chain it's a specific chain and is it
the same chain as say the ordering of
the bits yes in this particular case
it's the same change the ordering of the
bits so I'm going to call this that
chain all right okay the second one is
what we've been talking about all along
it's a dependency tree unlike in the
case with this chain here where I'm
giving you a specific chain this is the
first bit the second bit the third bit
the fourth bit and so on to the nth bit
I don't know which dependency tree is
here you'd have to find it but there's
some dependency tree I want you to
represent and the third one is the
easiest one to think about and that's
where everything is independent of
everything else so if I were to draw
that it would be a bunch of nodes with
no edges between them directed or
otherwise and so the joint probability
across all your features is just the
product of the unconditional
probabilities sort of the simplest
probability distribution you can have
okay you got that Michael yeah so and
okay if I'm understanding correctly each
of these is actually representable by a
dependency tree yeah each one is
actually so then why is why would anyone
be better than any other one I don't
know Michael you tell me I guess in the
case of well could be you could think of
it maybe in terms of the number of
parameters that need to be estimated so
in the independent case since we know
that it's independent or at least we're
imagining its independent we just have
to estimate one probability per node
which is like n yep in the chain case we
have a conditional probability per node
so it's like two n parameters yep and in
the dependency trait case it's I think
what you were saying is that we're
estimating kind of N squared parameters
and then then pulling the tree out of
that exactly now of course like you
point out Michael each of the chain is a
dependency tree independence are our
dependency tree and a dependency tree is
surprisingly enough a dependency tree
but these numbers of parameters do
matter because although a dependency
tree can represent an independent set of
variables the way you're going to
discover that they're independent is
you're going to need a lot of data to
estimate those N squared parameters in
order to realize that the conditional
probability tables effectively don't
mean
think so it would be very easy for a
dependency tree to overfit in the case
where all the variables or all the
features are actually independent okay
okay all right so you got it all right
no one more question yes well other than
what I need to fill the boxes in with
the numbers one two or three right yeah
for the products are the best form
got it and each one is used exactly once
yes
okay and then finally just to kind of
make sure that I've wrapped my head
around why we're doing probability
distributions at all so in the context
of mimic we need some way of capturing
the I guess the space of answers that do
at least a certain level they do at
least this well in terms of the fitness
so I guess I guess I I feel a little
thrown off because we're not trying to
represent the fitness functions right
you're not telling me which dependency
structure should I be using to represent
this Fitness function right instead I'm
asking you to figure out which
distribution will represent the Optima
the structure between the optimal values
okay all right I'm not sure hundred
percent get it but I think I get it
enough to answer this Chris excellent
okay so go</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>