<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Pipelined Caches - Georgia Tech - HPCA: Part 4 | Coder Coacher - Coaching Coders</title><meta content="Pipelined Caches - Georgia Tech - HPCA: Part 4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Pipelined Caches - Georgia Tech - HPCA: Part 4</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dNnhmnIQjVA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so one way of speeding up hit times is
to overlap one hit with another and we
can achieve this for example through
pipelining the cache if the cache takes
multiple cycles to access we can have a
situation where an access come in cycle
N and it's a hit and now if another
access comes in cycle n plus one and it
would be a hit though in a non pipeline
cache
the second access has to wait until the
first axis is done using the cache and
it takes multiple cycles to do that so
in this situation the hit time as seen
by each access is the actual hit time of
a cache plus the wait time that the
access suffers because it cannot access
the cache until the previous one is done
and in that situation pipelining the
cache so that we can send in accesses
one after the other will improve the
overall hit time now it may sound
straightforward how to pipeline the
cache you just divide it in let's say
three stages but how do you split what
amounts to basically a read from a large
array because that's really what the
cache is remember that the cache access
consists of using the index part of the
address to find the set reading out the
tags and valid bits that correspond to
the blocks in that set comparing the
tags and checking the valid bits for
each of these to see whether it has a
hit combining these so that we know
whether we have an overall hit and we're
in our set once we know where we read
out the data and use the offset to
choose the right part of the large cache
block at which point we have the data
that the processor wants and our cache
access is done so one example of a cache
pipeline would be to have this part
reading out the tags and so on from the
cache array B stage one determining the
hits and beginning the data rate would
be stage two and finishing the actual
data read all the way to getting the
data would be stage three so as you can
see we can pipeline the cache access
even if we don't know how to actually
break down
the reading from the cache array
especially if the tags and the valid
bits are read before we determine the
hit and we only read the data part of
the cache after we determine the hit in
that case just those two can be separate
stages usually the actual cache hit time
for level 1 caches will be one two or
three cycles one cycle caches don't need
pipelining and two and three cycle
caches can be relatively easily
pipelined into two or three stages
so usually level 1 caches will be
pipelined</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>