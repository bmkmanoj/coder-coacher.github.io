<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Measuring Performance | Coder Coacher - Coaching Coders</title><meta content="Measuring Performance - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Measuring Performance</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/--E5qo_XnXo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now that you have trained your first
model there is something very important
I want to discuss you might have seen in
the assignment that we had a training
set as well as a validation set and a
test set what is that all about don't
skip that part it has to do with
measuring how well you're doing without
accidentally shooting yourself in the
foot and it is a lot more subtle than
you might initially think it's also very
important because as we will discover
later once you know how to measure your
performance on a problem you've already
solved half of it let me explain why
measuring performance is subtle let's go
back to our classification task you've
got a whole lot of images with labels
you could say okay I'm going to run my
classifier on those images and see how
many I got right that's my error measure
and then you go out and use your
classifier on new images images that
you've never seen in the past and you
measure how many you get right and your
performance gets worse the classifier
doesn't do as well so what happened
well imagine I construct a classifier
that simply compares the new image to
any of the other images that I've
already seen in my training set and just
returns the label by the measure we
defined earlier it's a great classifier
it would get a hundred percent accuracy
on the training set but as soon as it
sees a new image it's lost it has no
idea what to do it's not a great
classifier the problem is that your
classifier as memorize the training set
and it fails to generalize to new
examples it's not just a theoretical
problem every classifier that you will
build will tend to try and memorize the
training set and it will usually do that
very very well your job though is to
help you generalize to new data instead
so how do we measure the generalization
instead of measuring how well the
classifier memorize the data the
simplest way is to take a small subset
of the training set not use it in
training and measure the error on that
test data problem solved now your
classifier can not cheat because it
never sees the test data so we can't
memorize it but there is still a problem
because training a classifier is usually
a process of trial and error you try a
classifier you measure its performance
and then you try another one and you
juergen and another and another you
tweak the model you explore the
parameters you measure and finally you
have what you think is the perfect
classifier and then after all these
scare you've taken to separate your test
data from your training data and only
measuring your performance on the test
data now you deploy your system in a
real production environment and you get
more data and you score your performance
on that new data and it doesn't do
nearly as well what can possibly have
happened what happened is that your
classifier has seen you test data
indirectly through your own eyes every
time you made a decision about which
classifier to use which parameter to
tune you actually gave information to
your classifier about the test sets just
a tiny bit but it adds up so over time
as you are on many and many experiments
your test data bleeds into your training
data so what can you do there are many
ways to deal with this I'll give you the
simplest one take another chunk of your
training sets and hide it under a rock
never look at it until you've made your
final decision you can use your
validation sets to measure your actual
error and maybe the validation set will
bleed into their training sets but
that's okay because you always have
these test sets that you can rely on to
actually measure your real performance</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>