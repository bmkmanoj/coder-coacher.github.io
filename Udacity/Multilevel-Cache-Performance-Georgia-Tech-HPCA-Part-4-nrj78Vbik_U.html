<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Multilevel Cache Performance - Georgia Tech - HPCA: Part 4 | Coder Coacher - Coaching Coders</title><meta content="Multilevel Cache Performance - Georgia Tech - HPCA: Part 4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Multilevel Cache Performance - Georgia Tech - HPCA: Part 4</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/nrj78Vbik_U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let's look at a single cache that is 16
kilobytes in size
let's look also at a single cache that
is a hundred twenty eight kilobytes in
size let's look at no cache simply we
will just access the main memory and
let's look at a hierarchy that has this
kind of cache is the first level cache
and this kind of cache is the second
level cache we will look at the hit time
for this the hit rate for all of these
and the overall aim at so 16 kilobyte
cache might have a hit time of two
cycles a hit rate of 90% so it gives us
an overall a mat of two plus 10% of the
time we have the memory latency let's
say the memory latency is a hundred
cycles in that case we end up with an
overall amount of 12 to from the hit
time and 10 on average from the Miss
penalties now let's look at a larger
cache this cache might have a hit time
of 10 cycles but a hit rate of maybe
97.5%
this is a bit high for such a cache but
let's say it is the a mat when this is
used alone would be 10 plus the miss
rate times the Miss penalty and we end
up with 12.5 which is a little bit worse
than with a smaller cache so having a
larger cache alone increases the hit
time improves the hit rate so it may or
may not improve the a mat but either way
the a mat is not going to improve a lot
of course having a cache is still lots
better than not having a cache not
having a cache means that our memory has
a hit time of 100 cycles basically the
memory latency it hits a hundred percent
of the time so aim at ends up being 100
plus 0 times the penalty because it
never misses but we still end up with a
hundred cycles per access which is way
too big so obviously having a cache is
better than not having it so now let's
look at the cache hierarchy the hit time
is different
pending on which of the levels we hit in
the hit time is still going to be two
cycles for a level one hit for a level
two hit however we first check in level
one so we paid two cycles to check then
we access l2 and have a hit
so overall now it's going to be 12
cycles for a level to hit the hit rate
is going to be 90 percent for l1 it's
still the same cache as if it was alone
and of all the accesses that go from
level 1 to level 2 we will have some
hits because the l2 cache has this hit
rate when working alone of all the
processor accesses it would have a hit
on this many but of all the processor
accesses those that hit in l1 probably
would also have been hits in l2
so this cache really has a 75% hit rate
of all the things that go into it it
would have this hit rate if it was alone
but the l1 cache is filtering all of the
easy to hit accesses so the l2 only get
75% basically it only gets to see kind
of the worst ten percent of the accesses
and for those it's only having a 3/4 hit
rate but the a matte is now going to be
2 for l1 hits plus 10% of the time we
have an l1 miss when we do we have ten
cycles to access l2 plus 25% of those
also end up accessing memory so when we
compute what this is it's 10 plus 25 so
the overall miss penalty for a level one
miss is just 35 cycles it's much better
than what it used to be when the l1 was
working alone and we finally end up with
two plus three point five which gives us
an overall aim at of five point five
cycles this is much better than either
of the two
she's working alone and it's much better
because really we're having most of the
accesses hit using the hit latency of
the fast cache some accesses have a
higher hit latency in the second cache
and fewer of them pay this huge memory
latency so this is why cache hierarchies
work better than individual caches and
why we have them it is not enough to
simply have a large cache if it's also
slow in that case you can combine their
good properties so that most of the time
we get this hit time but overall as far
as the memory access is concerned we
really have this hit rate in the
combined cache</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>