<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MapReduce - Georgia Tech - Advanced Operating Systems | Coder Coacher - Coaching Coders</title><meta content="MapReduce - Georgia Tech - Advanced Operating Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MapReduce - Georgia Tech - Advanced Operating Systems</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7nFBDFaiJxE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">in this lesson we're going to look at
one specific example of a programming
environment for dealing with big data
applications running on large
computational clusters and this
programming environment is called
MapReduce programming environment and in
this programming environment the input
to the application is considered as a
set of records identified by a key value
pair so the big data app developer
supplies the runtime environment with
two functions called map and reduce and
these are the only two functions that
the app developer has to supply to the
programming environment and both map and
reduce take user-defined key value pairs
as inputs and produce user-defined key
value pairs as output so both the input
and the output to each of these map and
reduce functions written by the domain
expert are key value pairs once again
these are key value pairs defined by the
app developer specific to the particular
application that he or she is coding
let's consider a fun example in this
example I'm going to say that we are
looking to find specific names of
individuals in a corpus of documents
maybe the names are Kishore a run drew
and so on these are the specific names
that I want to find in a whole corpus of
documents so the input to the
application is a whole corpus of
documents and we are looking for
specific names and the number of times
those names occur in those documents so
that's what this application is going to
do so the input key space for the
application is the file name and the
value part of the key value pair is the
content of the file so if you have n
files in the corpus of documents that we
want to analyze in this fashion then you
have n key value pairs corresponding to
each of the different files
the respective contents so this is going
to be the input to the whole application
and we are going to structure this
application using this programming
paradigm of MapReduce and we will see
how the app developer will use the
MapReduce framework to accomplish the
goal that we set out which is to find
the number of occurrences of unique
names in this corpus of documents in
this example the user defined map
function is looking for each of the
unique names that we are interested in
the corpus of documents so the map
function will take as an input a
specific file and the contents of the
file has a key value pair and emit a
value that corresponds to the number of
times each one of these names occur in
the input file now a simple version of
the map function may emit a one every
time it encounters the name Kishore in
the input file or the name alone in the
input file or the name drew in the input
file the output of the map function is a
key value pair where the key is the
unique name that we are looking for one
of the unique names if you're looking
for and the value is the number that
says how many times it found that
particular name as I said earlier a
simple version of the map function could
emit the value of one every time it
finds one of the specified names that it
is looking for in the file or a slightly
more elaborate mapper may actually
combine the number of occurrences of a
particular name in the input file and
then emit that as a sum of all the times
a particular name occurred in this key
value pair in either case the output of
the map function is itself a key value
pair note that it is different from the
input key value pair the output key
value pair that the mapper is emitting
is a unique name and a value that is
associated with the unique name and from
this example it should also be evident
that we can spawn as many instances
of the map function as the number of
unique files that we have in the input
document corpus further since each of
the map function is working on a
different key value pair as an input
they're all independent of one another
and there is no need for coordination
among them and that's the feature of an
embarrassingly parallel application the
output of the mappers are the input to
the reducers in other words the output
keyvaluepair from the mapper is the same
as the input key value pair for each of
the reducers that you see here again
this reduced function is something that
is written by the user and you notice
that what the mapper is doing is when it
it takes a particular name in this
example that it is looking for like you
sure then this mapper is going to send
the value associated with Kishore to
this reducer similarly this mapper is
going to send the value corresponding to
Kishore to the same reducer and all the
mappers in the same fashion are going to
send the respective values that they
found for this unique name Kishore to
this producer similarly the values found
for the name Arun is going to be sent to
this reducer by all the mappers and so
on so the number of reducers that we
will have is the same as a number of
unique names that we are looking for in
the corpus of documents this is where
work needs to be done by the programming
environment to plumb the output of the
mappers to the inputs of the reducers
potentially the mappers could be
executing on different nodes of the
cluster reducers can be executing on
different nodes of the cluster and the
work that is involved in this plumbing
is really making sure that the outputs
of the mappers are fed to the
corresponding correct reducers in the
entire distributed system for example
the output that is coming out of the
mapper corresponding to Kishore has to
be sent to
reducer from all the mappers the outputs
corresponding to Arun coming from all
these mappers have to be sent to this
reducer and so on that's what we mean by
the plumbing that needs to be done by
the programming environment to
facilitate the communication that needs
to happen between instances of the
mapper and the instances of the reducers
the work performed by each one of these
reduces is going to be aggregation of
the values that is got for each of the
unique names that we are looking for in
the input document corpus so this
reduces job is to aggregate all the
instances of kishore that it got from
all the mappers so it is receiving the
key value pair corresponding to the name
Kishore and the number of instances that
they found in the input key value pair
that they processed and the reducer is
going to aggregate that and the output
of the reducers all the reduces is once
again going to be a key value pair it is
exactly the same as the input key value
pair that the reducers got namely the
key is the unique name that they've been
assigned to aggregate and the value is
the total number of the occurrence of
this unique name in the corpus of
documents we started with so this is the
roadmap for creating a MapReduce
application for a chosen application
that works on big data so in this case
the chosen application was looking for
unique names in a corpus of documents
and all that the domain expert had to
worry about is deciding what is the
format of the key value pair which is
the input to the whole application in
particular the map phase of the
application and also what is the format
of the intermediate key value pair that
is going to be generated by the map of
function and what is the work that needs
to be done in each of the mapper and the
reducer to carry out the work that needs
to be done for this particular
application beyond that the app
developer does not have to worry about
any of the other details such as how
many instances of mappers do you need
eight how do we create the number of
instances of reducers corresponding to
what this application is wanting to do
and also worrying about the plumbing
from the output of the mappers to the
input of the reducers all of those are
things that the app developer does not
have to worry about</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>