<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>K Means Clustering - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="K Means Clustering - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>K Means Clustering - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/f4jvifS41M4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so we're going to talk about a different
clustering algorithm that that at least
doesn't have that weird property and it
has some other nice positive properties
but it's there's trade-offs there's
always trade-offs in clustering so
k-means clustering is what we're going
to talk about next and the basic flow of
the algorithm is like this we're going
to first pick a k k is going to be the
number of clusters that we're going to
try to produce and the way it's going to
do it is by picking K of the points at
random to be Centers and then we're
going to repeat the following process
each Center is going to claim its
closest points so we're going to cluster
all the points based on how close they
are to the K centers that we've defined
then we're going to recompute based on
that clustering that we just did
recompute the center's and the center
will be the average of the points in its
cluster and then we're going to tick
talk back and forth we're going to go
back and repeat till convergence for the
new center's claiming their closest
points the new groups of points
computing their average and back and
forth like that so let's step through an
example and then and then we'll try to
analyze what this actually does ok that
makes sense all right I'm going to do K
equals 2 in this example the same set of
points that I used in the previous
example and I'll just you know kind of
randomly choose two of them to be the
two clusters the red cluster and the
green cluster all right
ok that's that's this first step done
now what we're going to do is each of
these centers is going to claim their
closest points so we're going to take
all the points in the space and assign
them to one or the other of these two
clusters and it ends up looking like
this all right so this is now the points
that are closest to the Green Center
have all been put into a green blob the
ones that were closest to the red Center
all get put into the red blob okay okay
so that's that step two now what we do
is recompute the center's so the center
of the red blob is still pretty close to
where it was before but if you look at
the green blob the center the green blob
ought to be a little bit more to the
right
you see that I do I do in fact should be
a lot more to the right because there's
a whole lot of points on the right yeah
though I did this sort of by eye so it
doesn't quit you're right it should be
it should be closer to the clump on the
right but I
I didn't quite do it that way okay so I
moved it just a little bit more to the
right you see that mm-hmm but now we can
repeat this process we could say okay
now everybody join the group that you're
closest to and one nice thing that
happened now is that the group of points
on the left all joined together in red
and this sort of weird hammering thing
on the right became green and now we're
going to recompute our centers again
we're going to say well where's the
center of the clusters given the way
that they've been painted and that again
moved things a little bit to the right
in both cases we asked every point to
join the team that they're closest to
and we get that and that actually turns
out to be exactly the same clustering
that we had a moment ago so when we
recompute the center's it there they
remain unchanged and so we've converged
so it seems to have clustered things
reasonably given that I didn't actually
run this I just did it by hand okay can
I ask a question you seem to do please
okay you seem to drawn this in such a
way that the center's are always one of
the points but that's not really what
you meant to do is it or rather no it
was definitely not no no it's definitely
not what I meant to do it's it really is
just it doesn't the center is not
necessarily a point that's in the
collection of objects right yeah thanks
for pointing that out okay so this makes
sense and that looked better than what
single linkage clustering or single link
clustering or single linkage or whatever
it is called clustering did at least for
this kind of example yet it produced
kind of more compact clusters without
giant holes in them mm-hmm so so do you
have any questions about this about what
what it does yes so so I I think I might
have some questions Michael I'm and they
may even be questions you like for like
to hear so I asked one question about
what the center's you look like so I
have a couple questions one is does this
always converge does it always come up
with a good answer yeah those are good
questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>