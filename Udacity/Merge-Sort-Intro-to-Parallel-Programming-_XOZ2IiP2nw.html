<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Merge Sort - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Merge Sort - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Merge Sort - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_XOZ2IiP2nw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">more interesting from the GPU context is
a merge sort and it's really interesting
to discuss how to map this efficiently
to a GPU because it's a great instance
of a divide and conquer approach to the
problem so here's a tree that represents
our merge sort and what's particularly
interesting about mapping this to a GPU
is that the problem starts off with tons
of little tiny parallel problems and
then as the algorithm proceeds we
eventually end up with only one very
large problem to solve and that's the
final merge this is more challenging
than many of the algorithms we've
discussed where we have the luxury of
being able to solve lots of little
parallel problems independently
throughout the whole computation so what
we do at each stage of this tree is the
same the only operation that we need is
merging two sorted lists together into
one sorted list we begin with n items
which we treat as n sorted one element
lists then we run n over two merges to
create n over two sorted two element
lists then we run in over four merges to
create n over four sorted four element
lists and so on over all this is log n
stages and in each stage we merge a
total of n elements so the overall
number of operations the work complexity
is order of n log n this algorithm
exposes a lot of parallelism within each
step each individual merge this merge
this merge this merge this merge and so
on can proceed in parallel now the hard
part about mapping this to the GPU is
that the number and size of merge as we
do on each step differs greatly between
the first step and the last so I'm going
to talk about a GPU implementation that
has three stages the first stage this
blue stage here is merging a very large
number of very short sequences because
we have many many tasks and each is very
small we might choose to assign one
merge to one thread which can perform
each individual merge using a serial
algorithm on that thread we might get
better memory coalescing performance if
we use shared memory as a staging area
to read many input elements or store
many output elements at the same time
I'd say it's more common though at the
start of a large merge sort to just sort
a block of elements say a thousand 24
within shared memory and then stay
at the merge sort with sorted chunks of
size 1024 in other words if we're
actually doing this in practice we're
probably going to use a different
algorithm to do this blue stage here
with lots of little tiny tasks and then
use merge sort to do the last two stages
here and we're going to see a good
algorithm for an in block sort after we
finish the discussion on merge sort now
we move on to stage 2 now we have lots
of small sorted blocks and we need to
merge these small sorted blocks together
on the GPU for these intermediate merges
we would usually assign one merge to one
thread block now the obvious way to
merge two sorted sequences is a serial
algorithm so let's take a little bit of
a closer look at the algorithm that we
choose to use here and we'll come back
to this diagram a little bit later the
obvious way to merge two sorted
sequences is a serial algorithm and
here's our little serial processor here
the input to this algorithm is two
sorted sequences and the output is one
sorted sequence and so the algorithm is
that the serial processor looks at the
head of each one of the sorted sequences
chooses whichever element is smaller
outputs it onto the tail of the output
sequence and then advances the input
sequence from which you took the
previous element however this would be a
poor match for the GPU because this is a
serial algorithm and it wouldn't keep
all of our Hardware busy so it's
instructive to look at another way a
better way a more parallel way to merge
two sorted sequences</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>