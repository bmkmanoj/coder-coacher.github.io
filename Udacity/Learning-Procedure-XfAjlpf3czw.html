<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learning Procedure | Coder Coacher - Coaching Coders</title><meta content="Learning Procedure - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learning Procedure</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XfAjlpf3czw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">here's the big picture at a high level
of how we train a Q learner we have our
data here and we select which data we
want to train on of course this data in
the case of stock market is time series
and so it's arranged from oldest to
newest vertically here so we select the
day we want to train on and then we
iterate over this data over time so we
evaluate the situation there and for a
particular stock that gives us s our
state we consult our policy and that
gives us an action so we take that
action plug it into our system here
evaluate the next state and we get our s
Prime and our reward so after one
iteration here we've got an S an action
an S Prime and an AR or an experience
tuple and we use that experience to 'pl
to update our Q table once we get all
the way through the training data we
test our policy and we see how well it
performs in a backtest
if it's converged or it's not getting
any better
than we say we're done if not we repeat
this whole process all the way through
the training data so what do we mean by
converge
well each time we cycle through the data
training our Q table and then testing
back across that same data we get some
performance and we expect that each time
we complete an iteration here our
performance is going to get better and
better but after a point it finally
stops getting better and it converges so
overall the charts going to look
something like this eventually we reach
this regime where more iterations
doesn't make it better and we call it
converged at that point let's consider
now in more detail what happens here
when we're iterating over the data so
here are the details as we iterate over
our training data
we start by setting our start time which
is right here at the beginning and we
initialize our cue table the usual way
to initialize a cute table is with small
random numbers but variations of that
are fine now we're here in time and we
observe the features of our stock or
stocks and from those build up together
our state s we consult our policy or in
other words we consult Q to find the
best action in the current state that
gives us a then we step forward and we
see what reward we get and what's our
new state we now have a complete
experience tuple that we can use to
update our q table so we take this
information that we just learned and we
improve Q based on that information then
we step to the next point in time and
the next point in time and the next next
point time and so on
so these are all the details of what
happens in this step of the big picture</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>