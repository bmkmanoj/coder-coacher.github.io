<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Actually Doing the Matrix Multiplication - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Actually Doing the Matrix Multiplication - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Actually Doing the Matrix Multiplication - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bOmAllndo-4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so now we're going to start actually
doing the matrix multiplication and so
we're going to show the first three
steps of this the first thing we're
going to do is take the value vector and
the row pointer vector and together
we're going to create a segmented
representation of the value vector
note that each segment in this resulting
vector represents one row of the sparse
matrix and the row pointer shows where
each segment head begins the next thing
that we're going to do is gather these
vector values using these column indices
to create a corresponding list from
which we can multiply each of these
individual matrix entries so we see that
value a is located in column zero which
means it needs to be multiplied by the
vector element in row 0 so what we're
going to do is use these column indices
to gather from this vector and that's
going to give us the following array
okay now we actually need to do the
pairwise multiplications so we simply
use a map operation to multiply this
vector not caring about the segmentation
by this vector here and it's going to
give us yet another vector of the same
size and the final step is that we need
to add up the partial products within
each segment to be able to get the final
output vector and that's where we can
use segmented scan but now we have to
add up the partial products on each row
to get the output vector specifically we
need to add the partial products within
each segment and that's where our
segmented scan comes in we need to do an
exclusive segmented sum scan to sum up
each segment of partial products it's
actually a little bit more convenient to
do a backwards exclusive segmented sum
scan so while the sums instead end up at
the head of each segment since then the
row pointer array can be used to gather
those per row sums into a dense vector
now here we're actually using a
segmented scan to perform what's really
a segmented reduce and if you want a
good challenge think about how you might
want to build a segmented reduce that's
a little bit more efficient than a
segmented scan just to go back to our
original matrix to make sure we're
actually going to get the same answers
so here's our original matrix here and
our original vector and we note that we
dot product this vector with this vector
get this answer this vector dotted with
this vector to get this answer and then
this vector dotted with this vector to
get this answer and you'll see if you
look at each one of these rows they're
going to correspond to the sums within
each one of these segments but the nice
part about multiplying using the sparse
matrix representation is that we're
never multiplying by any zeros at all so
here we've actually had the x zeros and
then we just throw away the answers
because they're going to be 0 on the
other hand when we're actually
implementing this using a true sparse
matrix representation we're not going to
have any zeros present at all so this is
going to be substantially more efficient
for any real matrix that has a
significant amount of zeros</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>