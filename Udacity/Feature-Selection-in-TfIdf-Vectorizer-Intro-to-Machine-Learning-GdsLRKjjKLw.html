<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Feature Selection in TfIdf Vectorizer - Intro to Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Feature Selection in TfIdf Vectorizer - Intro to Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Feature Selection in TfIdf Vectorizer - Intro to Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GdsLRKjjKLw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so in order to make this a little more
concrete which might help you understand
what I mean I'm going to show you some
actual example from some code that
you've actually been running already in
this lesson maybe without even knowing
it so think back to the first couple of
lessons where we were learning about
supervised classification algorithms and
we were trying to identify emails by
their authors now what I wanted you to
do was to focus on the naive Bayes
classifier or the SVM or whatever and
just leave the pre-processing to me I
would take care of of reading in the
emails and getting them into a format
that was good for you now what I'm doing
is I'm taking you in to the code where I
actually did that pre-processing step so
that you can see that there's there's
really no black magic there and that you
would be able to do this completely on
your own in the future let me take you
into that code and show you what I'm
doing so I load in the data I put it in
my tf-idf vectorizer which you're very
familiar with by now and then there's
another step right here select
percentile I make a selector and I
select a percentile and what this step
actually does is it gets rid of a lot of
the features I know that this is text
data and that it's going to have
thousands or perhaps tens of thousands
of features because of just the large
vocabularies that we have and I also
know that a lot of those words are going
to be irrelevant so stop words is one
example of irrelevant words but there's
probably a lot of words in there that
aren't stop words but still just don't
have a lot of information in them
they're not going to help me figure out
who the author is very well and so what
I've done here in this step where I
select a percentile is I actually say
get rid of a bunch of the features you
go in and figure out for each feature
individually how good of a job that
feature does at telling you the two
people's emails apart from each other
and only accept the best ten percent of
the features for me to then use in my
classifier so what I've done here is
I've kind of sliced off that very top
layer the features that seem to have the
most information and I'm focusing on
those when I make my classifier now
there's one other place where I did some
feature reduction as well and you might
not always want to mix these two
together but I want to send you on a
little bit of a treasure hunt to find it
so I've told you about select percentile
this is something that's available to me
in the SK learn feature selection module
but there's also some feature selection
that I can
when I'm performing the tf-idf
vectorization of my data when I'm
actually taking the words in my corpus
and putting them into my tf-idf matrix
so what I want you to do is to look up
the documentation for this function the
tf-idf vectorizer and take a look at the
arguments that i'm passing to it one of
these arguments does something kind of
interesting it says that if there's a
word that's quite frequent that's
something that we want to ignore as well
by quite frequent what I mean is that it
occurs in many of the documents so for
example if you have a word that occurs
in every single document there's an
argument in here that will actually
remove it while you're making your
tf-idf so this is a little bit of a
tricky quiz because I haven't told you
exactly which argument is doing this
although a quick Google search and the
SK learn documentation should make it
pretty clear but the question that I'll
ask you in the quiz is what this
threshold is for this particular tf-idf
to ignore the word so does a word get
tossed out if it occurs in 10% of the
documents 50% or 90%</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>