<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Update Rule | Coder Coacher - Coaching Coders</title><meta content="Update Rule - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Update Rule</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Cgx6l19y7q0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">consider our robot here that's
interacting with the world the first
thing that sees is some state and as
we've talked about already the thing to
do now is to take that state go look in
the cue table and find the action that
corresponds to the maximum Q value and
then take that action once that action
is taken that results in two new things
one is a new state we call that s Prime
and a reward all that information comes
into the robot and it needs to use that
information to update its cue table so
as a consequence of this interaction
with the world it's got an S an a an S
Prime and an R how does it take that
information to improve this Q table
there are two main parts to the update
rule the first is what is the old value
that we used to have and that's Q si
and what is our improved estimate and we
want to blend them together and to
combine them we introduced this new
variable alpha alpha is the learning
rate alpha can take on any value from
zero to one
usually we use about zero point two and
what that means is in our new improved
version of Q which I indicate over here
is Q prime it's a blend of alpha times
the improved estimate plus one minus
alpha of the old value so larger values
of alpha caused us to learn more quickly
lower values of alpha caused the
learning to be more slow so a low value
of alpha for instance means that in this
update rule the previous value for Q of
Si is more strongly preserved so
stretching it out a little bit more
detail again we have here our current
value for the Q at si plus alpha times
the immediate reward plus gamma times
later rewards now we're introducing
gamaheer so promise there's only two new
parameters here that you have to worry
about what gamma is is the discount rate
and similar to alpha gamma usually
ranges from zero to one a low value of
gamma means that we value later rewards
less remember the discount rate when we
were talking about bonds same thing a
low value of gamma equates to
essentially a high discount rate a high
value of gamma in other words a gamma
near one means that we value later
rewards very significantly if we were to
use 1.0 that means a reward 20 steps in
the future is worth just as much as a
reward right now now we have to expand
this component here in a little bit more
detail this next part here is a little
bit tricky but don't worry we're gonna
step through it step by step
this component represents our future
discounted rewards in other words we end
up in state s Prime and from then on out
we're going to act optimally or at least
the best that we know how to and the
question is what is the value of those
future rewards if we reach state s prime
and we act appropriately well it is
simply that Q value but we have to find
out what the action is that we would
have taken so that we can reference the
cue table properly so if we're in state
s prime the action that we would take
that would maximize our future reward is
art max a prime so a prime is that next
action that we're going to take with
regard to Q s prime a prime so we're
going to find that best a prime that
best action that maximizes the value
when we're in that state so this
collapses just to a prime and then we
look up the Q table value for Q s prime
a prime
so that allows us to bring it all
together now so our update rule is the
following our new Q value in state s
action a is that old value multiplied by
1 minus alpha so depending on how large
alpha is we valued that old value more
or less plus alpha times our new best
estimate and our new best estimate is
again our immediate reward plus the
discounted reward for all of our future
actions and that's it this is the
equation you need to know to implement Q
learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>