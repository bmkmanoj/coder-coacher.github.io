<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Buffer Sizing for a TCP Sender - Georgia Tech - Network Implementation | Coder Coacher - Coaching Coders</title><meta content="Buffer Sizing for a TCP Sender - Georgia Tech - Network Implementation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Buffer Sizing for a TCP Sender - Georgia Tech - Network Implementation</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1K_DVt1XSQo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let's suppose that we have a TCP sender
that's sending packets where the sending
rate is controlled by the window W and
it's receiving X now at any time if the
window is W only W unacknowledged
packets may be outstanding so the sender
sending rate R is simply the TCP window
W divided by the round-trip time of the
path so the rate is W over RT T now
remember that TCP uses additive increase
multiplicative decrease or aimd
congestion control so for every W acts
received we send W plus 1 packets and
our TCP sawtooth will look something
like this
will start at a rate W max over to
increase the window to W max and then
when we see a drop we will apply
multiplicative decrease and reduce the
sender sending rate to W Max over to
again so here right at the point of a
packet drop this represents the maximum
number of packets that can be in flight
so again the required buffer is the
maximum number of packets that can be in
flight or simply the height of this TCP
sawtooth now we know the rate is W over
RT T and we'd like the sender to send at
a common rate R and if we'd like the
sender to be sending at the same rate
before and after it experiences a loss
then we know that the rate before the
drop must equal the rate after the drop
so then we can set these two rates equal
we know that the RTT is part
transmission delay T and part queuing
delay which is the maximum buffer size
of the bottleneck link divided by the
capacity the bottleneck link we also
know that after reducing the window the
queuing delay is zero so we can replace
the term on the left with W old over 2t
plus B over C and we can replace the
term on the right with W old over 2
because the congestion window has been
reduced by half divided by 2 T simply
the propagation delay with no queuing
delay now if we solve this equation we
find that the required buffering is
simply 2 T times C now the rule of thumb
makes sense for a single flow but a
router and a typical backbone network
has more than 20000 flows and it turns
out that this rule of thumb only really
holds if all of those 20,000 flows are
perfectly synchronized if the flow
those are desynchronized then it turns
out that this router can get away with
much less buffering</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>