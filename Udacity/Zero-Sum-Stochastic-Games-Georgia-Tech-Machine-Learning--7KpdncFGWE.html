<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Zero Sum Stochastic Games - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Zero Sum Stochastic Games - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Zero Sum Stochastic Games - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-7KpdncFGWE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now what makes stochastic games more
interesting perhaps than repeated games
is the idea that the actions that the
players take impact not just the rewards
but also future states right and so this
is the same issue that comes up when
we're talking about Markov decision
processes and the way we dealt with it
in that setting was by defining a value
function so it seems pretty reasonable
to try to go after that same idea again
so what I've got here is actually the
bellman equation and let's look at this
together and see if we can fix it
because it's not quite right okay we're
dealing with the idea of zero-sum
stochastic games so okay so you remember
the bellman equation we've got Qi star
mm-hmm so there was no AI before but Q
star is the state it's defined over
state action so here we're going to
define it over action joint actions for
the two players action pairs the
immediate reward to player I for take
for that joint action in that state plus
the discounted expected value of the
next state so we need to factor in the
transition probabilities so the
transition of actually going to some
next state s prime is s sorry T of s a
be s prime right so now we're imagining
what happens when we land in s prime so
what I've written here it says well
we're going to basically look at the Q
values in the state that we landed in
and kind of summarize them summarize
that value back up so that we can use it
to define the value of the state that we
left you with me I am with you all right
so if we put this in if we say the way
we're going to summarize the value for
this new state that we land in is we
think of it as actually a matrix game
right that there's payoffs for each
action choices of a prime and B prime
and over all of those we need to kind of
summarize well which which of those
actions in this table of values that we
get for s prime which of those values
are we going to propagate forward and
call the value of that state so what we
did in regular mdps is we said we'll
just take a max over all the actions or
in this case all the joint actions
mm-hmm so what do you think that
translates to um well you wrote down max
but that doesn't make sense it doesn't
there can't be well it translates it
means something it just doesn't mean
what we mean that's true that's fair so
what does it mean and then and
and how can we fix it so let's start off
with what does it mean it means that you
kind of always assume that the joint
actions that are going to be taken will
benefit you the most so know everyone
everyone is trying to make you happy so
this makes you optimistic yeah it's sort
of optimistic to the point of delusion
yes very good right it just basically
says whenever we're in a state the whole
world is going to choose their actions
to benefit me and this is not what we'd
get into say is zero-sum stochastic game
and a zero-sum stochastic game we should
be you know like fighting it out at this
point so that would work out of
everybody's rewards were the same or
everybody's rewards were the sum of
everyone's rewards or something like
that that's right if it was some kind of
team-based game or if everybody you know
was going to sacrifice their own
happiness for the benefit of Qi or I I
mean hmm so it's it's not reasonable to
assume that in fact what we what was it
that we were assuming when we had a
zero-sum game that was just a single
stage right just just a single game and
then we were done
oh that people were doing minimax right
and maximin so what if we change the
equation to look like that so what I
mean by this is when we when we evaluate
the value of a state we actually solve
the zero-sum game in the Q values and
take that value and use it in the
context of this equation that seems
closer to right yeah I mean it's not an
unreasonable thing to do it's just today
I'm gonna summarize the future by
imagining that we're gonna play that
game that represents you know all the
future sure and I'm gonna act in such a
ways to try to maximize that assuming
that you're trying to minimize it which
makes perfect sense if it's a zero-sum
game right I was yeah and we're still
we're still acting as if they're only
two people here yeah yeah that's right
it turns out that when you're talking
about zero-sum it really implies that
there's only two players because if you
have a zero-sum three player game it
really is just a general sum game that
that you can imagine that the third
player is just an extra factor that's
just messing with the numbers to make
things sum up to zero so yeah so zero
sum really does kind of focus on this
two-player setting that make sense so
we've got this modified bellman equation
and we can even translate it into a form
that's like q-learning hmm so the analog
of
bellman equation and and the q-learning
update in this setting would be that we
if we're in some state there's some
joint action that's taken there's some
pair of rewards that comes in some next
state that's visited that the Q value
for that state joint action pair is
going to be updated to be closer to the
reward for player I plus the discounted
expected value or started the discounted
summarized value or V value of the the
new state s prime and will again use
well we use minimax to summarize what
the values are in that new state I like
it and that equation is sometimes
referred to as minimax Q because it's
like the Q learning update but just with
the minimax operator instead of a max
didn't make sense</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>