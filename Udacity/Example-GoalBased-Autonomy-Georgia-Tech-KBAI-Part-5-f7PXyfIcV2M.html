<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Example: Goal-Based Autonomy - Georgia Tech - KBAI: Part 5 | Coder Coacher - Coaching Coders</title><meta content="Example: Goal-Based Autonomy - Georgia Tech - KBAI: Part 5 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Example: Goal-Based Autonomy - Georgia Tech - KBAI: Part 5</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/f7PXyfIcV2M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so meta reasoning can be very difficult
to talk about because it's circular so
it's often unclear what exactly we're
talking about at a given time so to try
to make this process more explicit let's
take an example let's imagine a robot
whose task is to assemble a camera and
all day every day the robots it's
they're assembling camera after camera
then one day the boss walks in and says
instead of assembling that camera
disassemble this camera that's already
been put together so what does the robot
do it wasn't programmed to disassemble
cameras so how does it figure out how to
do this task well the robot might have a
rule that says given a new goal or
giving a new problem choose the method
for which I have the most knowledge the
robot might then look at its memory and
say well the only thing I have is a
bunch of cases of assembling camera
after camera after camera so this is
metacognition the robot has now thought
about it what it knows it's thought
about its new goal and it's decided on a
method to use to approach this new
problem but now that the robot has
selected a method it de needs to reason
further its chosen case based reasoning
as its reasoning method but how will it
do the adaptation well the robot might
then select a rule out of its memory
that says to reverse a process do the
steps in reverse so now we've done not
only strategy selection when we select a
case based reasoning but we've done
strategy integration it is now using a
rule based approach to take care of the
case adaptation so the robot uses that
rule reverses the steps and disassembles
the camera now the boss comes back by
and says well yeah you disassemble the
camera but why did it take so long you
could have done it so much faster but
the boss doesn't give any feedback as to
how the robot could have done it faster
then later the boss brings back another
camera and says here disassemble this
camera but do it faster this time so now
the robot needs to select a method again
it thinks last time I used case based
reasoning to select my method for
disassembling the camera but case based
reasoning didn't give me an optimal
solution the boss complained that it
took me too long so instead the robot
chunks a rule that says given a new task
of disassembling a camera suggest
strategies other than case based
reasoning so now it's used a form of
meta meta cognition it's thought about
it's metacognition it's looked at the
way it selected a strategy in the past
and decided the way I selected the
strategy in the past must not have
worked because the strategy i selected
wasn't ideal so next time selected
energy so here we've seen everything
we've talked about the day in action
first we saw using metacognition to
resolve a gap the agent didn't have any
way of disassembling a camera so use it
to select a strategy for resolving that
gap that's also strategy selection a use
case based reasoning to decide what
method it should use to resolve this gap
we then saw strategy integration where
it used a rule based approach to adapt
its prior cases we then saw correcting
mistakes where the boss told the robot
that it didn't do it fast enough so its
reasoning method must have been
suboptimal so next time you should try
something different that last part is
also an example of meta meta cognition
or metacognition about metacognition it
looked at its strategy selection method
and decided next time I should select a
strategy differently David's example of
a robot that knows how to assemble
cameras but then it's given the goal of
disassembling a camera is a good example
of gold base autonomy earlier we had
looked at how an agent can go about
repairing its knowledge of reasoning or
learning where it makes a mistake or
reaches of failure but sometimes it is
not so much that the agent reaches a
failure as much as it is that the agent
is given a new goal when the agent is
given a new goal we do not want the
agent to just fall apart we do not want
brittle agents we want agents that can
then adapt their reasoning methods and
their learning methods to try to achieve
the new goal even if they were not
necessarily programmed to achieve that
goal for predicting we know that human
cognition is very robust and flexible
you and I address a very large number of
task a very large number of problems had
a key were very large number of goals if
we had to design human level human-like
AI agents then those AI agents will have
to be equally robust and flexible
metacognition provides a powerful way of
achieving that robustness and
flexibility it does so by flexibly
dynamically selecting among competing
strategies it does so by flexibly and
dynamically integrating multiple
strategies as the problem-solving
evolves it does so by using riesling
strategies and knowledge that were
programmed into it to achieve new goals</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>