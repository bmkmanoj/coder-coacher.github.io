<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Transpose Code Recap - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Transpose Code Recap - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Transpose Code Recap - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/RdFrnh5fhKc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so let's quickly recap we had a
serial version of the code that did
everything in a single in a single
thread trivial to write that code zero
parallelism and pretty terrible
performance then we had a parallel per
row version of the code that was also
pretty simple to write and assigned one
thread per row and a single thread block
again did not get great performance
although a huge improvement factor of
about a hundred then in the third
version we extracted pretty much all the
parallelism that the problem has to
offer and assigned one thread per
element of the matrix so we did this
transpose operation now in sort of
massive parallel and now we got you know
quite a bit better performance remember
that all of this is happening in the
context of a pod analyzed parallel wise
optimized and deploy and this is
actually might be fast enough that
you're ready to deploy it right so we
started by looking at analyzing the code
and deciding that this function of
transposing matrix need to be sped up we
started exploring ways to parallelize it
and this might be fast enough this is
already a place where you ought to look
at this and say is this the bottleneck
anymore if speeding this up gonna make a
big difference to my application if not
then deploy if so then we can start
thinking about optimizing it and that
was the next thing we did we looked at
the performance here we saw that we were
getting pretty poor DRAM utilization and
we diagnosed that the problem must be
that our global stores were getting bad
coalescing in other words when we were
writing the output matrix we were
getting bad coalescing and those
accesses to global memory so to fix that
we came up with a tiled version of our
code where each thread block is
responsible for reading a tile of the
input matrix transposing it and writing
that transpose matrix to its location in
the output matrix and it can perform
these reads and writes in a coalesced
fashion we did this in blocks of 32 by
32 tiles and got excellent coalescing
this improved our speed a little bit but
we're still not getting great DRAM
utilization so we looked into why so
only thought a little bit more about why
we wouldn't have taken a great
improvement in bandwidth we concluded we
probably had too many thread
waiting at barriers so we improved that
by shrinking the tile size experimenting
with different tile sizes led us to
conclude that a sixteen by sixteen
thread block writing into sixteen by
sixteen tile and shared memory struck a
good balance between achieving coalesced
writes reads and writes to memory and
not spending too much time waiting in
barriers</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>