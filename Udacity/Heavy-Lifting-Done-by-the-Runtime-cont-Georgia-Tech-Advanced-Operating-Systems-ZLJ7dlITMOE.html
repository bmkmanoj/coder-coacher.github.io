<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Heavy Lifting Done by the Runtime (cont) - Georgia Tech - Advanced Operating Systems | Coder Coacher - Coaching Coders</title><meta content="Heavy Lifting Done by the Runtime (cont) - Georgia Tech - Advanced Operating Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Heavy Lifting Done by the Runtime (cont) - Georgia Tech - Advanced Operating Systems</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZLJ7dlITMOE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">in the reduce phase there is more work
to be done and pulling the data that is
needed for each one of these reduces
because we know that the mappers have
been executing on different nodes of the
computational cluster and they produced
the intermediate results as files on the
local disk and this worker that is
carrying out a particular split of the
reduced operation has to reach out and
pull the data from all of the M mappers
that have stored that intermediate
results on the respective local disks so
there is remotely that is involved as
the first thing in the reduced phase is
to pull the data this is part of what i
mean by the plumbing that the runtime
system provides is to recognize that for
this reduce operation to work it needs
the mapping results from all the m nodes
that carried out the map function and so
it is going to do or pc in order to get
all this data from all the local disks
of the nodes on which the map is
executed and once it has all the data it
can sort it and then call the reduce
function reduce function is the one that
has been written by the domain expert
and this is the point at which the
domain expertise comes in in saying well
I've got the data now let me do the
processing that I want to do for the
reduce operation the sorting that is
being done as part of the programming
framework maybe to sort the input that
is coming in from all of these different
mappers so that all the same keys are
together in the input data set that is
going to be given to the reduce function
and one such sorting has been done the
programming framework will call the
user-supplied reduce function for each
key with the set of intermediate values
so that the reduce function can do its
thing which is domain-specific each
reduce function will then write to the
final output file specific to the
partition that it
is dealing with so if you think about
the original example that we started
with if let's say this guy is
accumulating all the instances of the
name Kishore then it will write the
output file that says oh I found so many
instances of the name Kishore in the
input corpus of data and similarly this
guy may be doing it for another name
like Drew or Arun and so on and once
each worker has completed its work by
writing its final output file for this
petition that it is responsible for then
it informs the master that yes i'm done
with the work that is assigned to me the
user program can be woken up when all
the reducers have indicated to the
master that they have done their work
and at that point the MapReduce
computation that is initiated by the
user program is complete we said that
there could be M splits of the input
data set meaning the input key values
pairs and there could be our splits of
the output that has to be generated by
the application as a whole now the
computational resources that are
available in the data center n may be
less than the sum n plus R so they may
not be a unique machine to assign for
each one of the M splits that have been
made it is a responsibility of the
master to manage the machines and assign
the machines that are available to
handling the M input datasets as well as
the all reduced plates that need to be
generated so this is part of the heavy
lifting that has to be done by the
runtime so for instance let's say that I
have only 100 worker nodes available as
mappers and I have an input split of a
thousand then what I'm going to do is
I'm going to assign one split to this
worker and when the guy says I'm done
with it then I'd say oh you're done okay
take the next plate and work on it take
the next plitt and work on it so that's
how we're going to manage the available
resources for carrying out the work that
needs to be done so remember that this
is all
done as part of the heavy lifting by the
runtime the user doesn't have to worry
about it all that the user did was right
the map function and write the reduce
function and the rest of it is Magic so
far as the MapReduce framework is
concerned and similarly the number of or
splits specified by the user may be more
than the number of workers that are
available to carry that out and in that
case again the master is going to assign
a particular split to this worker so
that he can compute and generate the
output file corresponding to that split
once he's done with that and notifies
the master then the master will say ok
now that you're done with that work on
the next split and to do all the work
that is associated with plumbing meaning
bringing the data for the split that a
particular worker is working on right
now sorting it to put all the
corresponding keys together and then
finally calling the reduce function that
has been written by the user that's the
kind of work that goes on under the
covers in the programming framework of
MapReduce</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>