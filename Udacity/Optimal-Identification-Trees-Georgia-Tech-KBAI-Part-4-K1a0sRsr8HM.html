<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Optimal Identification Trees - Georgia Tech - KBAI: Part 4 | Coder Coacher - Coaching Coders</title><meta content="Optimal Identification Trees - Georgia Tech - KBAI: Part 4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Optimal Identification Trees - Georgia Tech - KBAI: Part 4</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/K1a0sRsr8HM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let us look at another example of
decision tree learning here is a data
set of people who go to the beach and
some of them get sunburned and others
don't in this data set there are nine
examples and each example is
characterized by for features here
height age and lotion once again how can
we construct an optimal decision tree
that will classify all of these examples
one possibility is to discriminate first
on hair color hair color classifies all
these 9 examples into three categories
round red and blonde the interesting
thing about a choice of hair color is
that in case of brown all these sunburn
cases are negative people were Brown
here apparently don't get sunburned in
case of all the red haired people there
is sunburned so hair color is a good
choice for picking as the feature to
discriminate on because it classifies
things in such a way that some of the
categories have only negative instances
and no positive instances and some of
the categories have only positive
instances and no negative instances of
course that still leaves blonde haired
people in this case there are both some
positive instances and some negative
instances and therefore we lead another
feature to discriminate between the
positive in the negative instances here
lotion might be the second feature that
we pick lotion not classify the
remaining examples into two categories
some people use lotion other people did
not those who use lotion did not get
sunburned those who did not use lotion
did get sunburn once again these are all
negative instances these are consisting
of only positive instances does in this
decision tree simply by using two
features we were able to classify all of
these 90 examples this is a different
decision tree for the same data set but
because we use a different order
therefore now we have to do more work
this decision tree is less optimal than
the previous one we could have chosen a
different set of features in a different
order perhaps we could first described
it on height then on hair color and H in
this case we get a much bushier tree
clearly this tree is less optimal than
this one note the trade-off between
decision tree learning and
discrimination tree learning that we
covered in k space
reasoning decision tree learning leads
to more optimal classification trees but
there is a requirement you need all the
examples right up front discrimination
tree learning mainly to sub-optimal
trees but you can learn incrementally</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>