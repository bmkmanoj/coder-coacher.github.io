<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Intro | Coder Coacher - Coaching Coders</title><meta content="Intro - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Intro</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JTg5Y7zNd1g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">All right.
Welcome back to Computer Vision.
Today what we're going to do is having
just started talking about Video.
We're going to start talking about,
Action Recognition or
Activity Recognition in Video.
That's the processing of video.
For generating,
generating some sort of label or, or
descriptor that tells
you what's going on.
So, there's a bit of a challenge in
activity recognition in
terms of terminology.
And there's no sort of universally
accepted terminology, and
I'll say some of this goes
back to the 70s, Hans Nagel,
first started talking about events and
actions in history and things like that.
So, loosely, we're going to use
the definitions that I have here.
So, we talk about Events.
And the one thing about an event
is it's a single moment in time.
Right?
So
the moment a door closes or something
changes right, right in the imagery.
A typically we refer
to that as an event.
A little bit higher up perhaps thinking
is this basic idea of movements or
sometimes referred to as actions.
And these are I'm going to describe a,
sort of atomic movement patterns.
So you know, sitting down.
Or you know, waving or
something like that.
We've got a gesture-like, it's a,
you could describe it as
a trajectory in some feature space.
Whether it's the feature space of the
joints of the body or some appearance.
It is it's a, it's a single thing.
And then at the higher level there's
this notion called Activity.
By the way the only reason it
says adopted from Venu and, and
myself not together I did the original
paper on movement activity and
action and it was wrong.
I mean wrong in the sense of in,
in hindsight had activity followed
by actions because I was thinking
of actions being a big scale thing.
And the field which like the paper for
a little while has sort of moved on and
we have this notion of, of movements.
And then actions and
then relay activity.
And activity is being sort of
composed of a series of actions or
a bunch of actions
happening at the same time.
Typically if you're looking
at some interactions
among the group of people that
we thought of as an activity.
So one example.
Here's a thing taken from
some surveillance, work.
Some of this was shown at
the PETS conference lets see.
Performance Evaluation of Tracking and
Surveillance,
I think is what PETS stands for.
There's been a lot of work lately on
just you know finding the person in
the image here and
have extracted them there.
And maybe looking at some interactions
between people in a train station.
The idea of basically being able to
watch an environment sometimes to be
able to inform authorities if
there's possible problem going on,
sometimes to do things forensically.
Right?
So something happened and
I'd like to look back over
the last eight hours of video and
find different kinds of things.</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>