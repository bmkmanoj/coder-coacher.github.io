<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Caching Spinlock - Georgia Tech - Advanced Operating Systems | Coder Coacher - Coaching Coders</title><meta content="Caching Spinlock - Georgia Tech - Advanced Operating Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Caching Spinlock - Georgia Tech - Advanced Operating Systems</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Lo2Lneqd27k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now let's look at how we can exploit the
caches available now it is a fact that a
test is an instruction has to
necessarily go to memory when we want to
acquire the lock we have to execute a
test and set instruction so that we can
atomically make sure that exactly one
processor gets the lock but on the other
hand the guys that don't have the lock
could in fact exploit the caches in
order to wait for the lock and that's
why this particular algorithm that I'm
gonna describe to you is what is called
spin on read and the assumption here is
that you have a shared memory machine in
which the architecture is providing
cache coherence or in other words
through the system bus all the
interconnection network the hardware is
ensuring that the caches are kept
coherent well that gives us an idea as
to how we can exploit the caches the
waiter is instead of executing a test
and set instruction that has to go to
memory they can spin locally on the
cached value of the lock because when
you are spinning on the local cached
value of the lock if that value changes
in memory these guys are gonna notice
that that's the principle behind the
cache coherence that is implemented in
hardware and so we can exploit that fact
in implementing a more efficient way of
spinning which is called spin on read
the idea is that the lock algorithm the
first thing it's going to do is go and
do a check on the memory location to see
wheels locked so this is a normal atomic
read operation that is being done not a
custom set operation so if it is not in
the cache you're gonna go to memory and
bring it in and once you bring it in so
long as this value doesn't change we go
to basically looking at the value that
is in my cache in order to do the
checking and I'm not going to go to the
bus and therefore I'm not producing any
any contention on the network and there
could be any number of processors
waiting on the lock simultaneously no
problem with that because all of them
are going to be spinning on the local
value of L in the respective caches and
so if there is one processor that's
actually doing useful work and it has to
go to memory it's not going to find that
to be a problem no contention on the
network from the waiting processors
because of this now if the one processor
that was having the lock
eventually releases it they go
everybody's gonna notice that and so if
I'm waiting for the lock and I've been
spinning here locally in my cache when
the lock is released I'll notice that
through the cache coherence mechanism as
I'll break out of the spin loop but
immediately I want to check I want to
check if the lock is available by doing
this test and set and get it uniquely
for myself so multiple processors are
trying to execute this test and set
simultaneously it's possible that
somebody else is going to beat me to the
punch
and if that happens I plea go back and
and and do the looping on my private
copy of L and wait for the guy who beat
me to the punch to release the lock
eventually so that I can get it so
that's the idea the idea is you spin
locally when you notice that the lock
has been released you try to do a test
and set if you get lucky you win if you
lose you go back and spin again locally
so that's the idea behind spinning on
read the unlock operation of course is
pretty straightforward the guy that
wants to unlock is simply going to
change the memory location to indicate
that L is no longer locked said that's
all it has to do and then and then the
other processors can observe it through
the cache coherence mechanism and be
able to acquire the lock but note what
happens when the lock is released when
the lock is released all the processes
that are stuck here in the spin loop
they're going to go and try to do this
test and set operation at the same time
and we know that testing said has to
bypass the cache and everybody's hitting
on the bus right everybody is hitting on
the bus trying to go to memory in order
to do this test and set operation and so
that essentially means that in a write
invalidate based cache coherence
mechanism it's going to result an order
of n square bus transactions for all of
these guys to stop chattering on the bus
because every one of these
testing set instruction is going to
result in invalidating
the caches and and as a result you have
an order of n square operation that is
going to result when a lock is released
where n is the number of processors that
are simultaneously trying to get the
lock and obviously this is impeding that
one guy that got the lock and can
actually get some useful work done and
this is clear disruptive and earlier one
of the things that we said is that we
want to avoid or limit the amount of
disruption to useful work that can be
done by the processor that acquired the
lock</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>