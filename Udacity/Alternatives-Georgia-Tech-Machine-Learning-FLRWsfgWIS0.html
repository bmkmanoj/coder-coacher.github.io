<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Alternatives - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Alternatives - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Alternatives - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FLRWsfgWIS0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay Michael so we've talked about PCA
and I see a and they both work
remarkably well in the specific domains
that they're designed for and they've
been applied for decades on a wide
variety of problems for doing this sort
of feature transformation but I'm going
to just very briefly describe two other
alternatives to sort of give you a
notion of the space okay sure okay the
first one is kind of irritating but I
feel obligated to share with you and
it's called well it's got many different
names but i'm going to call it RCA just
because i like the the symmetry and RCA
stands for random components analysis so
what do you think random components
analysis does this is also called random
projection I'm going to guess instead of
finding dimensions with say hi variants
it's just going to pick any direction
that's exactly right what r CA does is
it generates random directions then I
guess it projects the data out into
those directions that's exactly right
it's like saying it picks a random p to
random matrix to project your data on to
this matrix is in some sense just any
random linear combination and you want
to know something it works it works
remarkably well at what though in terms
of it like reconstruction at
reconstruction well not particularly
well at reconstruction but you know what
it works really well it works really
well if the next thing you're going to
do is some kind of classification now
why is it you think that it actually
works can you imagine why just picking a
bunch of random directions and
projecting onto those random directions
might work well it does mix things
together differently I don't know why
the original data wouldn't work then
this would work better unless the
original data somehow is purposely made
to not work well remember what we're
doing it right we're starting with in
dimensions and we're projecting down to
M dimensions where m is significantly
lower than in so I've started with a
bunch of dimensions now remember the
real problem here is not that I can't
gather the data from the n dimensions
it's that there's a whole bunch of them
curse of dimensionality so I need to
have a lot of data so if I don't have a
lot of data at least certainly not an
exponential amount of data so to speak
and I projected lower dimension why
would random projection still give me
something that helps with
of classification so it's as if it's
it's maintaining some of the information
from these other dimensions even though
there's fewer of them now they're all
kind of mixed together but the signal
might still be there that's exactly
right and because you projected into a
lower dimension you end up dealing with
the curse of dimensionality problem
which is sort of the whole point of this
or one of the whole points of this in
the first place and really a way I think
of summarizing what you're saying is
that this manages to still pick up some
correlations so if I take random linear
combinations of all of my features then
there's still information from all of my
features there so in practice at least
in my experience Michael it turns out
that M the number of lower dimensions
you project into for randomized
components analysis or randomized
projections tends to be bigger than the
M that you would get by doing something
like PCA so you don't end up rejecting
down to sort of the lowest possible
dimensional space but you still project
down to a lower dimensional space that
happens to capture your correlations or
at least capture some of the
correlations which often ends up working
very well for a learner or classifier
down the road you can actually see how
in this case you might even project into
another set of dimensions em where those
number of dimensions are actually bigger
than the number of dimensions you
started out with this in some sense is
almost exactly what we did with
perceptrons in solving x or basically
you're projecting into higher
dimensional spaces by doing this does
that all make sense yeah I think so I
mean it makes sense to me that it would
be not as efficient in some sense as PCA
because it sort of reminds me of you
know if I want to if I want to paint my
wall I can very carefully paint all the
little pieces of it or I could just
splatter stuff at it and it generally
takes more when you splatter because
you're not being as systematic but it
does ultimately cover your wall yeah I
think that's a an interesting analogy
and I'm going to go with an abdomen ok
so this sort of thing works what other
advantage what advantages does it
actually have over pc and i see i can
you imagine one there's one in
particular which i think sort of jumps
out at you RCA well I don't know is that
is that a good quiz question may be sure
let's make it a quick quiz</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>