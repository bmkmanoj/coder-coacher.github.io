<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Housing Example Revisited | Coder Coacher - Coaching Coders</title><meta content="Housing Example Revisited - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Housing Example Revisited</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lvJzg6SJXbw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so here's how we're going to
look at this so as you may recall in
this housing example if we look at
different degrees of polynomials and how
well they fit the data let's look at the
training error the per example training
error so how far off is it for each of
the data points and as we increase the
degree of the polynomial from constant
to linear to quadratic and all the way
up to in this case order six the error
is always falling as you go up you have
more ability to fit the data closer and
closer and closer right because each of
these models is nested inside the other
we can always go back if the zero fits
best and I give you six degrees of
freedom you can still fit the zero so
that's what happens with the training
error but now let's use this idea of
cross-validation to say what if we split
the data up into chunks and have each
chunk being predicted by the the rest of
the data train on the rest of the data
predict on the chunk repeat that for all
the different chunks and averaged
together so so I actually did that and
this is what I got with the
cross-validation error so there's a I
don't know there's a couple interesting
things to note about this plot so we see
I have this red plot that is constantly
falling and the blue plot which is the
cross-validation at her starts out a
little bit higher than the the red plot
that's got higher error so why do you
think that is Charles well that makes
sense right because we're actually
training to minimize or we're actually
trying to minimize the error on the
training set so the parts we aren't
looking at you're more likely to have
some error with so it makes sense that
you'd have a little bit more error on
the data you haven't seen right so good
so in the on this red curve
we're actually predicting predicting all
the different data points using all of
those same data points so it is using
all the data to predict that data this
blue point which is really only a little
bit higher in this case is using in this
particular case I used all but one of
the examples to predict the remaining
example but it doesn't have that example
when it's when it's doing its fitting so
it's really predicting on a new example
that it hasn't seen and so of course
you'd expect it to be a little bit worse
in this particular case the averages are
all pretty much the same so there's not
a big difference but now let's look what
happens as we start to increase the
degree we've got the ability to fit this
data better and better and better and in
fact down
on at you know say three and four
they're actually pretty close in terms
of their ability to to fit these
examples and then what's great what's
really interesting is what happens is
now we start to give it more the ability
to fit the data closer and closer and by
the time we get up to two order six
polynomial even though the error on the
training set is really low the error on
this on this cross-validation error the
error that you're that you're measuring
by predicting the examples that you
haven't seen is really high and this is
beautiful this this inverted U is is
exactly what you tend to see in these
kinds of cases that the error decreases
as you have more power and then it
starts to increase as you use too much
of that power does that make sense to
you it does make sense so the the
problem is that as we give it more and
more power we're able to fit the data
but as it gets more and more and more
power it tends to over fit the training
data at the expense of future
generalization right so that's exactly
how we refer to this is this sort of
idea that if you don't give yourself
enough degrees of freedom you don't give
yourself a model class that's powerful
enough you will under fit the data you
won't be able to model what's actually
going on and there'll be a lot of error
but if you give yourself too much you
can over fit the data you can actually
start to model the error and it
generalizes very poorly to unseen
examples and somewhere in between is
kind of the Goldilocks zone where we're
not under fitting and we're not
overfitting we're fitting just right and
that's the point that we really want to
find we want to find the model that fits
the data without overfitting and not
under fit so what was the answer on the
housing example well so it seems pretty
clear in this in this plot that it's
somewhere it's either three or four it
turns out if you look at the actual
numbers three and four are really close
but three is a little bit lower so three
is actually the thing that fits it the
best and in fact if you look at what
four does it fits the data by more or
less zeroing out the quartic term right
it doesn't really use the this power oh
but that's interesting so that means it
barely uses the extra degree of freedom
you give it but even using it a little
bit it still does worse in
generalization just a tiny bit worse yep
exact
so it's actually kind of cool</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>