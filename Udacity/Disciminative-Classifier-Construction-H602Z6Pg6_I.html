<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Disciminative Classifier Construction | Coder Coacher - Coaching Coders</title><meta content="Disciminative Classifier Construction - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Disciminative Classifier Construction</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/H602Z6Pg6_I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">we're going to talk a little bit more
about this but basically what I just
talked about for example whether you're
doing the whole histogram the histogram
of the whole image which doesn't work
very well but you could do it or if you
build like these orientations of
gradients in each of the quadrants
you're building a model a description of
that instance by the way you take for
each of those for those histograms
before and just string them into one
great big feature vector that's your
description so now what you have to do
is you have to train or sometimes prefer
to as learn a classifier given a bunch
of those feature vectors describing
koalas and given a bunch of them
describing pandas figure out how to
discriminate one from the other so
here's the basic description all right
so let's suppose we're trying to learn
cars versus not cars so how many classes
is that sorry how many classes are that
how many is that it is six there are six
classes but the number of classes is six
actually number of classes is too I
don't know it's called a binary
classifier because there are two classes
so for example suppose I have a little
picture here of a car and I have to
decide is it a car and what do you think
you think that's a car yeah good she got
it right yes it's a car okay now here's
another picture okay it taken some merch
and I think I don't know remember we're
sorry so is that a car not a car no very
good what we need are methods of doing
that now there's been a huge effort in
machine learning and applied to computer
vision over the last really 15 20 years
of methods of doing discriminative
classification what did you see listed
here are a whole bunch of methods a
couple of references below them of how
to go about doing that we're going to
talk about three of them I've just
highlighted them here nearest neighbor
SVM's boosting there are others as well
the general approach and there's a huge
literature on this now especially with
these large-scale object recognition
competitions of what's the best feature
vector you can use learning different
feature vectors sparse representations a
bunch of other things and then given
those representations what are the
methods that you should use
to make the classification here the
three that we're going to talk about if
you take more machine learning just
remember later you could apply those
methods to those other representations
our fundamental assumption is going to
be someone and hopefully that somebody
you don't have to pay but somebody is
going to give you a database of lots of
examples of the things you want to find
and lots of examples of the things you
don't want to find and then you're going
to train the classifier now once you do
that you have to come up with some way
of tests given some new image how do you
test it so you remember we talked about
you have to generate these new
candidates and you have to score them so
here's the basic idea you start off with
a window and then in kristin is really
good at this animation right and you
might take that window of a particular
size and you scan it all over and what
you do is you apply your car non-car
classifier to every one of those windows
you say do I see any cars by Sandy cars
with sander cars not very clever but it
just works very well right because the
classifiers are quick and they're
accurate so as opposed to having a
different way of trying to do detection
versus labeling I basically do detection
by labeling there is a problem of course
though I picked a window well suppose
I'm nearer to a car does the picture get
of the car get bigger or smaller that
one's an easy one Megan if I get car
bigger does closers it look bigger or
smaller bigger bigger very good so what
do I have to do well I just have to try
bigger windows and I slide those all
over the place and if this feels kind of
data intensive you're right and with
their various tricks to doing it but
that's the general idea is that you take
these different sized windows and you
apply them to different places in the
image</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>