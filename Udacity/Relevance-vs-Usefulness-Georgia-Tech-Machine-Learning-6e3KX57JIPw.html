<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Relevance vs Usefulness - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Relevance vs Usefulness - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Relevance vs Usefulness - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6e3KX57JIPw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so let's see if we can be a bit more
formal about this notion of usefulness
okay so I erased all the stuff that I
had before but basically you'd summarize
that last slide is saying that relevance
measures the effect on the Bayes optimal
classifier right so a variable is
relevant if it can make the Bayes
optimal classifiers performance better
or worse so really relevance is about
information so when you were talking
earlier about things that you might use
for filtering you said well I like
things that have variance or things that
have entropy or things that give me
information gain those are all measures
of the information that is present in a
particular variable or a particular
feature right yeah so really from the
Bayes optimal classifiers point of view
the only thing that matters is how much
information a particular variable
provides you know condition on some
label or just in general how much
information and provide so a variable
like see here which doesn't change has
zero entropy provides no information
independent of the value of the label
and therefore cannot be relevant to the
Bayes optimal classifier that makes
sense it does now and and that this this
notion of help usefulness not
helpfulness but usefulness is when we
conditioned on particular predictor and
that's why we can have C being useful in
the context of a perceptron right so
usefulness is exactly about effect on
error given a particular classifier or
some specific model so usefulness is
exactly about minimizing error given
some particular model or some particular
learning algorithm right so in this case
although c is clearly not relevant it is
in fact useful at least for something
like w transpose x now this is not
useful for a decision tree nor is it
relevant it is not relevant to this
particular problem but it is however
useful for some algorithms now just to
clarify so so it seems like the Bayes
optimal classifier has a privileged
position in this definition right so
couldn't we define relevant as measuring
the effect on a perceptron relevance no
no I'm saying but it you just you
plugged in a kind of classifier there
why can't we plug in some other kind of
classifier
ladies optimal classifier yeah why is
that one special because the Bayes
optimal classifier captures this notion
of the optimal thing that you could do
it's not a specific algorithm I mean you
could write down an algorithm that would
compute the Bayes optimal classifier
except that it requires you're looking
at all possibly infinite number of
hypotheses right but it is the the Bayes
optimal classifier computes the best
label given all the probabilities that
you could ostensibly compute overall the
hypothesis space it doesn't have to
actually require specific algorithm to
do so it truly is a measure of
information of variables so any other
algorithm you have has a bias and a
particular inductive bias okay I feel it
okay okay that's a fine answer so at the
very beginning of our discussion Michael
you actually asked me this question of
what the criteria was when I said that
feature selection was about maximizing
some criteria removing features
according to some criteria and I told
you that eventually we kind of get to
the point of what the criteria is the
notion of relevance versus usefulness
gives us an idea of thinking about what
that criteria is ultimately we've been
talking about unsupervised learning
mostly in a kind of vacuum but
presumably you know whether some
particular description compact or
otherwise some particular label is in
fact a good one based on how it's used
later on so one way of thinking about
this is the labels that I come up with
for a set of data are exactly good ones
insofar as they help me to do something
else like classification later all that
clustering that we did before like with
k-means andy-em you could think of those
as a kind of feature transformation
algorithm which is what we'll be talking
about next where you've taken a bunch of
features and you've converted them into
something simple like a label and
whether that label is a good label or
bad label depends entirely upon whether
you can then do some kind of
classification or regression problem
layer the label in this case meaning the
cluster name right got it okay it's
interesting so you'll actually find if
you go through the literature and you
look at some algorithms that people have
predicted that a lot of the measures
like information gain or entropy or
whatever often end up being couched in
terms of relevance but ultimately what
we really care about is usefulness or at
least one could argue
cool okay so that's pretty much what I
wanted to talk about for a feature
selection there's a lot of algorithms
and if you go and you look at the
material that we've made available to
everyone you'll be able to see some of
these algorithms discussed in more
detail but at a high level these are the
key issues that I wanted you to see so
with that Michael let's wrap up</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>