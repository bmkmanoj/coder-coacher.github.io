<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Minimize Time Spent On Memory - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Minimize Time Spent On Memory - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Minimize Time Spent On Memory - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/v-gSOY9-RgI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let's talk about ways to minimize time
spent on memory accesses so the first
strategy to think about is move
frequently accessed data to fast memory
we've talked about the memory spaces
available to the GPU there's local
memory which represents the given
threads private variables local
variables parameters things like that
they're shared memory shared by a thread
block and there's global memory shared
by all the threads and more or less it's
true to say that local memory is faster
than shared memory which in turn is
faster than global memory in fact shared
memory and local memory are usually much
faster than global memory I should
mention that there are subtleties here
for those of you who know something
about computer organization the reason
why I'm labeling local memory is so fast
is that it tends to live either in
registers or in l1 cache and those are
both those are both quite fast this
isn't a hard and fast rule there's some
subtleties here but in general data that
is kept local to a thread is going to be
about as fast as possible and data that
is shared in a threads thread blocks
shared memory is going to be very fast
and data that is way out in global
memory is going to be a lot slower
although this is still much faster than
CPU memory also known as host memory so
let's see an example of using local
shared and global memory so here's a
kernel I know that it's a kernel because
it starts with either device or global
it's called Lee use local memory GPU it
has one parameter called N and it's got
one local variable called F because this
is a local variable it's in local memory
it's private to this thread every thread
will have its own copy of a variable
named F and parameters are also local
memory so every thread will have its own
copy of a parameter called in and you
know real code would presumably do
something with these variables but since
this is just an example of how to use
local memory I don't need to do that how
would you call the kernel that shows
using local memory well you would call
the kernel you would have to launch it
meaning tell-tell the GPU how many
thread blocks to run with how many
threads and you'd pass in any parameters
so in this case 2.0 pretty simple</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>