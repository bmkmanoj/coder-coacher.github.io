<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Problems With 1 Bit Predictions - Georgia Tech - HPCA: Part 1 | Coder Coacher - Coaching Coders</title><meta content="Problems With 1 Bit Predictions - Georgia Tech - HPCA: Part 1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Problems With 1 Bit Predictions - Georgia Tech - HPCA: Part 1</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/malQIOtaAuU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so we have seen in the latest quiz that
the one bit predictor works reasonably
well for loops that have a lot of
iterations so what are the problems with
one bit prediction that have led to
better predictors the one bit predictor
predicts well branches that are always
taken it might make a mistake the first
time it sees the branch but after that
it's going to start predicting taken and
because the branch is always taking it
always works well similarly always not
taken is predicted well because the very
first time it might miss predict but
after that it learns the behavior and it
stays the same so we just have to always
not taken it also predicts well the
branch is where the number of taken
outcomes is vastly more than the number
of not taken outcomes here it's gonna
learn after the first taken outcome that
the next outcome should be predicted
taken and very very rarely it's gonna be
wrong because of a not taken outcome
similarly the one bit predictor predicts
well when the number of not taken
outcomes is vastly more than the number
of taken outcomes for the same reason
basically we will see not they can not
take and not taking many many times the
first time we see one of those we're
gonna learn it and then the taken
outcome will be miss predicted so what's
wrong with the one one bit predictor
what's wrong with it can be glimpsed
from these let's look at the branch it
is for example more taken than not so
it's been taken many times and then
there is a non taken outcome and then
it's going to be taken many more times
let's now look at whether the one bit
predictor will be right on this it's
been taken many times so it's gonna
predict a can and then because it's been
taken it's gonna predict the next one
let's take an the next one is going to
be predicted taken taken again when we
reach the not taken out come the last
outcome was taken so we will have a
misprediction this would not be much of
a problem if not taking occurs very
rarely because we're basically miss
predicting just the very rare
occurrences however there is an
interesting problem here which is now
that we are back to our taken behavior
which is the vast the dominant behavior
in this case the last outcome was now
not taken so we are gonna
predict this branch - now we're
predicting not taken and the branch will
be taken after this the previous outcome
was taken so we predict taken and we
continue predicting taken so the problem
really is that each anomaly such as we
have a branch it is almost always taken
but sometimes it's not taken results in
two mispredictions one for the anomalous
behavior and then once more for the
normal behavior that follows the anomaly
so the one bit predictor will not do so
well when the branch is biased towards
let's see doing more taken branches but
the number of not taken branches is
still significant or when there is more
not taken branches but the number of
taken branches is significant because
for each of the less dominant behavior
it's going to do two mispredictions not
just one typically also a branch
director like this will not do well on
short loops why because in a short loop
we have a branch that for example exits
the loop then we have a sum loop
behavior and then a branch it loops back
the branch that exits the loop will be
predicted correctly as long as we stay
in the loop by this predictor the exit
from the loop will be mispredicted the
branch vector will now be trained to
take this path here when we come back to
this short loop it's gonna miss predict
the very first iteration for this branch
because now it's gonna think that it
should be this way but in fact now we're
staying in the loop so if you have for
example an eight iteration loop we will
have two mispredictions every eight
iterations one at the end of the loop
and one at the beginning of the loop
because the previous ending of the loop
trained the predictor that way and then
of course the one bit predictor will be
pretty bad when the number of taken and
not taken outcomes is similar yet
predictable we will talk about this more
later but now let's first devise a
predictor that will fix this so can we
devise a predictor that behaves
similarly well here but does not miss
predict twice whenever there is an
anomaly</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>