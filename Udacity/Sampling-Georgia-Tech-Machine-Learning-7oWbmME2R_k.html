<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sampling - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Sampling - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sampling - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7oWbmME2R_k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">earlier I mentioned sampling and I asked
you whether that sounded useful and you
said it was so let's do a little
exercise
why why why is that a useful thing why
is it good idea to be able to sample
from a distribution
well because it's one of the two things
that distributions are for what does
that mean well so why do you have a
distribution a distribution is so that
given some value you can you can tell me
what's the probability of me seeing that
value which is kind of what it looks
like when you have the probability
function but also if you have a nice
distribution you can generate values
according to that distribution okay
that's a little bit circular in the
sense that it didn't tell me why it was
useful to generate them other than it's
one of the things you can do well you
didn't ask me to actually make sense but
I mean this is the the thing that you
use distributions for now why would you
want to do that yeah so if a
distribution represents kind of a
process it would be nice if I could
duplicate that process right so I would
have to be able to generate values in
the right way consistent with the
distribution in order to generate that
process so it's like flipping a coin I I
want to flip a coin and find out whether
I'm gonna get heads or tails it would be
nice if I could do that in a way that's
consistent with whatever the underlying
bias of the coin is okay so yeah so if
this distribution represented something
complex we might you know for whatever
reason need to simulate that world and
act according to those probabilities so
yeah that's a reasonable one what else
what if what if I showed you this if I
took the distribution that we used for
the lightning and thunder example mm-hmm
and what if you wanted to get a handle
on it how could we use sampling from the
distribution to give you some insight
into how the storms work okay so let's
see so I've got this representation of
the Joint Distribution but it's just a
representation of the Joint Distribution
if I want to ask a question like well
what's the chance that it's oh let's say
storming outside if I've heard thunder I
could go through and and you know back
compute the reverse of the conditional
probability tables and I can do things
like or I could just generate a bunch of
samples where I had thunder and I could
just see how often
was also true does that make sense it
does though I'm not gonna use the words
that you just used to write that down
okay I'm gonna call that approximate
inference so the basic idea is that you
would like to do some inference you'd
like to figure out what might be true of
the world in different situations and
instead of doing some complex
probability calculation you're just
going to imagine a bunch of possible
worlds and see how often is it the case
that whatever it is that you want to
figure out is true so yeah that that
turns out to be a really good way to do
it in fact sometimes I think that's a
lot of what people are doing when we're
making judgments in the world we're just
really really good at this kind of
sampling from past realities that are
relevant and we can make judgments based
on that so how would you do that how
would I do what how would you do this
approximate inference we're gonna get to
that but I wanted to oh but there's one
or two other things about sampling that
I wanted to mention okay another thing
that I could imagine using this for is
this notion of visualization which maybe
is I mean this in a broader way than it
sounds not necessarily to actually see
what the distribution is like but to
kind of get a feel for it so I bet if I
was to run that if I was to draw a bunch
of samples from the lightning thunder
set you would have a better feel for how
likely different things are just you as
a person might get a sense of how these
things work so you could imagine in a
medical domain a doctor who is who's
thinking about prescribing a particular
kind of drug for a particular kind of
person if the information about drug
interactions and so forth was
represented as a big belief net it might
be hard to look at it and know anything
but if it if you use that to generate a
bunch of artificial patients you might
start to get to feel for oh you know
what these kinds of people tend to react
badly in these kinds of circumstances
that's still a kind of approximate
inference right but yeah but it's right
that's right so this is this is kind of
in the machine sense and this is kind of
in the human sense okay I like that so
let's see let's see if I understand it
so the the nice thing about the storm
the Thunder and the lightning example is
it has pedagogical value because it's
easy for a student to look at that and
go okay I understand what's going on
here one because there's only three
nodes and two arrows and the other is
because we think we understand how
storms
under enlightening work right most
people do so that makes a lot of sense
of course the downside of it is we think
we understand it and so it's hard to see
why you would need to do samples I mean
there's just a couple of probability
distributions and we kind of know what
it means but in the real world there are
perhaps hundreds and hundreds of
variables with complicated relationships
and conditional independencies that that
aren't necessarily intuitive just by
looking at the graph and so picking one
conditional probability table and
looking at it isn't going to tell you
much but by sampling I get real examples
that are concrete that as a human being
I can understand without having to you
know really crock all the 25 different
conditional probability tables that
sound right is that yeah that's exactly
right thanks okay I want to draw your
attention to this this word here for a
moment this notion of approximate
inference now generally we don't like
approximations when we can do things
things exactly so why are why are we not
doing things exactly because it's hard
it's hard that's exactly right
so or it or even if it weren't hard it
might it may it may be in some cases
faster so I would be I'm not going to do
it now but I'd be happy if I guess if
there's a groundswell of support amongst
the students to I can go through the
argument as to why this inference is
hard there's a nice little reduction to
problems and MP complete problems like
satisfiability but it turns out roughly
that if you could do inference exactly
on any belief net that you want then you
could solve very very hard problems
efficiently using that idea so it's it's
it's cute but it kind of takes us a
little bit off our path so I'm not gonna
get into that
okay so sampling is useful Michael which
I always suspected in my heart and now
we've got some good arguments for why it
actually is</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>