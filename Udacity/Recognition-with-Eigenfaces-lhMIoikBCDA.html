<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Recognition with Eigenfaces | Coder Coacher - Coaching Coders</title><meta content="Recognition with Eigenfaces - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Recognition with Eigenfaces</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lhMIoikBCDA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so how do we do recognition well
actually it's pretty straightforward I
have some new novel X comes in some new
novel face image alright all I do is I
project it into the subspace what does
that mean just like before
I subtract off the means and I compute
the dot product the coefficients W 1
through wk by the way I can then do
something it's optional put here suppose
I'm not really sure that what you gave
me was a face image well what I can do
is I could reconstruct using those
coefficients and now here's the thing if
you gave me some other 10,000
dimensional vector right you know three
guys on a bicycle and I try to make that
image by just summing up a hundred I
ghen vectors from the face space how
well do you think I can reconstruct that
image not so well the only images I can
reconstruct well our faces so I could do
the reconstruction and compare them and
say aha bad choice this is not a face
image it also means by the way if I'm
looking for faces in a picture I might
do that in fact in the original Turk and
pennilyn they actually did detection
that way there are now better ways to
just detect ball faces but the ability
to reconstruct is a way of knowing that
yep I actually have what I was looking
for I'm gonna use to see if I can
restart to do some tracking but hang on
that's for that's for the next lecture
but for the recognition part it's
optional let's assume it really is a
face well then all we can do is we can
say all right you gave me these double
use right 1 through K let me find in my
list the one that's closest in the those
K numbers I might use a Euclidean
distance some other distance metric but
basically I have a description of a new
face coming in and I just see which of
the descriptions in my database is
closest and that's why you can think of
this somewhat as a generative model
there's actually more detail to use it
in a more probabilistic way we'll
actually talked a little bit about that
in the tracking but the idea is that
each one of these descriptions
gives me a probability if you will or a
likelihood of what this person's face
might look like because it assumes that
this is captured most of the variation
and that the other stuff doesn't matter
too much and if I new one comes in I can
just compare them and if I get closer
that's more likely and that's why it's a
generative model</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>