<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>RL for POMDPS Part Two | Coder Coacher - Coaching Coders</title><meta content="RL for POMDPS Part Two - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>RL for POMDPS Part Two</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0u6uXZuLXNA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so basically planning is hard so i
assume reinforcement learning is also
hard so the results that we have for
reinforcement learning in Palm DPS are
more empirical and algorithmic results
they're not really formal results but
still something that people try to do
sometimes right if you have some kind of
robotic system or or agent system that's
trying to figure out what to do and the
world is the word that it's in is
partially observable then you have to do
something like this yes all the halting
problem well no no getting the exact
optimal answer is undecidable well there
is it decidable as you can get near
optimal yes okay well then I feel better
why don't you stop depressing me and
like tell me what to do so that I can
sort of feel better about this whole
approach sure no problem I'm gonna ask
you what to do so okay so in particular
to remember we had kind of two main
flavors of reinforcement learning
algorithms for MDPs do you remember what
those where there's value duration and
policy iteration right yeah those are
planning algorithms but for
reinforcement learning in an MDP the two
main branches model-based RL and model
free RL oh yeah sure right well that was
obvious uh-huh and do you remember you
remember the distinction between it well
one used the model and one didn't when
learned a model and when did it okay
well the same thing you can't use a
model if you don't learn it if you
didn't know it that's true that's very
well said so you learn a model and then
you use it versus don't bother to learn
a model and just do it I think the
little quip was the world is your model
whose quip is at probably rod Brooks
alright so we can actually use this same
kind of distinction this model based RL
and model free based RL or model free RL
in the palm DP setting where in
model-based RL you actually try to learn
the palm BP and then you plan in it and
in model free RL we try to map
observations to actions and we do that
iteratively over time so we don't
actually build the model but we do try
to figure out okay when I see this this
is a good thing to do what can I ask you
a question well we're here before you
jump in so one of the things that you
know we learned in AI class 150 years
ago is that if you don't know what's
going on you can often to figure out
what's going on by taking specific
actions that guarantee you end up in
some state that you actually know sure
so like even if you're blind and you're
trying to get to a particular place in
the room you could do stuff like well
I'm just going to go
left for 15 minutes and then I know no
matter what happens I'm gonna be against
the left wall then I know where I am yes
then I can do things do either of these
methods do the equivalent of that or an
analog of that either could in fact okay
well that's good again the guarantees on
whether things actually work in this
space are non-existent so it's not the
case that we can always say oh yeah it's
always going to do the right thing it's
going to figure out the the simplest way
of getting to a known stayed and then
behave from there but yeah I mean I've
seen both these kinds of algorithms do
that kind of thing okay good good well
that's promising</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>