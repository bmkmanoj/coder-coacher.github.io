<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Stochastic Games and Multiagent RL - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Stochastic Games and Multiagent RL - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Stochastic Games and Multiagent RL - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZdwT6YHZOt0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so what I'd like to tell you about is a
generalization of both MDPs and repeated
games that is that goes by the name
stochastic games also sometimes Markoff
games mmm I like the name Markov game
better but I used to caste games because
that's what other people call it and
sometimes it's good to use words that
other people use and what what
stochastic games give us is a formal
model for multi agent reinforcement
learning in fact I like to think of this
in terms of an analogy which is
something like MVP is two RL as
stochastic game is 2 multi agent RL it's
a formal model that lets us express the
sorts of problems that take place in
this formalized problem setting hmm it
sounds very promising cool all right so
let me let me give you a start off by
explaining it in terms of an example and
then I'll give a more formal definition
because you know I can't not so so this
is a little game played between a and B
oh I should have it between smooth and
curly but at the traditionally it is
played between a and B mmm
and sometimes it's good to use the words
that other people use I wouldn't say
quite that way so it's this is a three
by three grid each of the players can go
north south east and west and can stay
put if that's helpful and determine the
transitions are deterministic except for
through these these walls here which are
called semi walls so these thick lines
represent walls that you can't go
through the thin wallet the thin lines
just represent cell boundaries but this
kind of dashed line here is a semi wall
and that means if you try to go through
that say by going north from if a goes
north from this position then 50%
probability a will actually go to the
next state and 50% probability a will
stay where a is so the goal is to get to
the dollar sign and if you get to the
dollar sign you get 100 dollars so if we
ignore a for a second what should be do
to minimize the number of steps
necessary to get the reward go left and
then go up and go up or I'm sorry go
west and then go north and then go north
yeah now what should I do ignoring B go
east and then go north in the north yeah
unfortunately these guys live in the
world together and what happens is they
can't they can't occupy the same square
and as soon as somebody reaches the
dollar sign the game ends and the other
player if it the other player hasn't
reached the dollar sign gets nothing
I see so now there's a little bit of
contention so what happens if a and B
both try to go to the same square at the
same time let's say that we flip a coin
and one of them gets to go first and
then the other one will bounce off of
the first one but that's not a problem
when it comes to reaching the money but
it's not a problem
yes right so the money is kind of like a
money pit what a money pit is but okay
and so they can dive in and they both
get the money because they're in the
money pit I like it so what do you do if
you're a how do you play this game
oh let's think of another thing is can
you think of what what it might mean to
have a Nash equilibrium in a game like
this oh that's an interesting question
it would mean well it would mean what do
you mean what would mean it would mean
that neither one of them would want to
deviate it would mean a pair of
strategies for the two players now the
strategies are now multi-step things
that say they're like policies right so
like it's a pair of policies such that
neither would prefer to switch so can
you think of a pair of policies that
would have that property well no I'm not
sure I was trying to think about that so
I was I was thinking that kind of if I
were a nice guy what I'd want to do is
I'd want to as both to try to go through
the semi walls and if we both go through
the semi walls we just go up again and
then we we hit the dollar sign at the
same time and that's very nice so okay
good so that that seems like a
cooperative kind of strategy right where
they're both you know 50 percent sorry
25 percent of the time both will get
through both will go to the goal
together hooray
by 25 percent of the time neither one
will get through and then we're in the
same place we were before so that's okay
that problem is the other 50% where one
of them gets through and the other
doesn't right so what do you do if you
make it through and the other one
doesn't what do I do if I get through
the other one doesn't well if I'm only
gonna do this the one time then I just
keep going and get the dollar and the
other person loses yeah all right so
what and so what this works out to be is
that a is going to get to the goal
all two-thirds of the time and B is
going to get to the goal two-thirds of
the time mm-hmm so all right so if
that's the case if I say okay a that's
what you should do B that's what you
should do then is there a way that
either A or B can switch strategies and
do better
well if be for example decides to go
west and then go up what happens yes
that's a good question B will now make
it to the goal a hundred percent of the
time and a will only make it to the goal
fifty percent of the time so B has an
incentive to switch to that to the
strategy if we tell them to both go
through the semi wall right so that
wasn't a Nash equilibrium B would want
to switch this new policy mm-hm
is this a Nash equilibrium no wait is it
no because why doesn't a just choose to
go west east well what would a do better
on average by switching to this strategy
well let's see no actually oh no no you
said half the time they go through yeah
so half the time you flip the coin so
half the time I don't make it right but
half the time I do so actually it looks
the same it looks the same that's right
and B would go from 1 to 1/2 yeah that's
true so it a doesn't have an incentive
to do it but B is hoping very much that
it doesn't do that right so so yeah so
that so there's one Nash equilibrium
where B takes the center another one
where a takes the center I guess if they
do if we do this coin flip thing it
works out this way if it's the case that
if they both if we change the rules here
so that if they collide neither of them
gets to go then
both trying to go to the center is not a
Nash equilibrium anymore because you can
do better by actually going up the semi
law right and so if we if if collision
means nobody goes through then suddenly
you would want to do the other thing
where one of you goes through the semi
wall and one goes the direct way right
so we can see that there's a bunch of
different Nash equilibrium here sorry
that's equilibria here and that it's not
so obvious how you'd find them but it is
at least clear that they exist and they
have a different form than what we had
before because now they're again their
policies instead of these otherwise
simplified just you know choose this
row of the matrix mm-hmm cool all right
so let's think about how we might learn
in these kinds of environments oh okay I
like that already</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>