<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Raven's Progressive Matrices - Georgia Tech - KBAI: Part 5 | Coder Coacher - Coaching Coders</title><meta content="Raven's Progressive Matrices - Georgia Tech - KBAI: Part 5 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Raven's Progressive Matrices - Georgia Tech - KBAI: Part 5</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sVyY2A0oSj8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it may interest you to note that the
projects you have been doing in this
class are based on cutting-edge research
under just a few years back
all computational models of solving
problems on the Ravens test first
extracted propositional representations
from the figures and then ran
prepositional engines on this
propositional representations thus they
may extract the transformation from A to
B in the form of a semantic Network
shown here and similarly they may
extract a transformation from C to five
through the semantic Network shown here
they would then compare these two
semantic networks and decide whether or
not a is 2 B is similar disease to file
you may have done something similar in
your early projects but in 2012 math
leaked under here at Georgia Tech was
able to write a computer program that
used all the analogical representations
without extracting any propositional
representations and yet were able to
solve problems from the Ravens
progressive matrices test it used only a
fine and set transformations over the
analogical representations so as an
example it would compare a and B by
saying that it is a set transformation
this particular dot is no longer there
and it is a fine transformation in fact
to affine transformations first that
make this square bigger and second the
translates the position of the square
from inside the circle to outside the
circle
it would find similar affine and set
transformations that will relate c and v
that will compare the affine and set
confirmations again without extracting
any proposed representations little
surprisingly mexican - program called as
t for a st i was able to do quite well
in the ribbons test it solved 50 ordered
60 problems correctly then in 2013 keith
mcgregor again here at georgia tech
wrote another computer program that used
a different kind of analogical
representation called the fractal
representation and he was able to show
the diffracted representation also
enables addressing problems on the
Ravens test with a good degree of
accuracy we provide references what math
Lee's work and Keith's work in denotes</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>