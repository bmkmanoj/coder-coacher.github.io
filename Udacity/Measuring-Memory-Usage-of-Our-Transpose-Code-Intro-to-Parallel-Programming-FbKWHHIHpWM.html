<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Measuring Memory Usage of Our Transpose Code - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Measuring Memory Usage of Our Transpose Code - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Measuring Memory Usage of Our Transpose Code - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FbKWHHIHpWM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so if we go through this analysis for
all of these kernels we'll see that our
parallel per element version of the code
achieves 12.5 gigabytes per second our
parallel per row version of the code
gets about 1.8 giga bytes per second and
our serial version of the code gets an
abysmal 0.01 eight gigabytes per second
this is roughly the speed of a carrier
pigeon and a better way to think about
this perhaps is not in absolute numbers
but as a percentage of what the
particular GPU we're using can achieve
so if we were to work out the
percentages we're achieving it's
something like thirty one percent of
theoretical peak bandwidth with our
highest performing colonel
four-point-five percent peak bandwidth
with our per row kernel and less than a
tenth of percent with our serial colonel
so back to the question why is this
number so low we can take a pretty
shrewd guess that a whenever you see
really load DRAM utilization really low
percentage bandwidth your first guess is
always coalescing the way to think about
coalescing is that the GPU is always
accessing global memory accessing the
DRAM and pretty large chunks 32 or 128
bytes at a time and this means that
we're going to need the fewest total
memory transactions when the threads in
a warp access contiguous adjacent memory
locations so this is an example of good
coalescing every thread is either
reading or writing an adjacent memory
location and clearly if the threads in a
warp are reading and writing completely
random locations in memory then you're
going to get poor coalescing right so if
these accesses are spread out all over
the memory then the total number of
chunks of memory that we have to read
could be as large as the number of
threads in the warp so a random access
pattern clearly leads to bad coalescing
so much more common access pattern is
what's called stride 'add and this is
where threads access a location memory
that's a function of their threadid
times some some stride so for example
thread 0 might access location 0 thread
one location to thread to location for
thread three location six and so on in
that case that be a stride
too because there's two elements between
thread accesses and stride it accesses
range from okay like in this case we're
with the stride of of two elements I'm
really only doubling the number of
memory transactions so I'm sort of
having the quality of my my coalescing
all the way to really really bad right
so you can imagine that if the stride
between elements is large enough then
every thread in the warp is accessing a
completely different 32 or 128 bite
chunk of memory and then you're you're
guaranteed to get bad behavior
guaranteed to be maximizing the number
of memory transactions that you have to
do so let's look at the code for our
Colonels here's where we're reading from
the input matrix and this actually works
out pretty well every thread is reading
a value in memory which is equal to some
large offset J times n plus I and if you
look at I I is really the thread index
plus some offset so adjacent threads you
know threads with adjacent thread
indices and X are reading adjacent
values of the input matrix that's
exactly what we want so this is good
coalescing on the other hand when we
write the output matrix adjacent threads
threads with adjacent values of I are
writing to places separated in memory by
n right and n was like a thousand 24 so
adjacent threads are running a memory
locations that are a thousand twenty
four elements away from each other this
is clearly really bad this is bad
coalescing bad bad bad bad bad bad bad
this is in fact the root of our problem</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>