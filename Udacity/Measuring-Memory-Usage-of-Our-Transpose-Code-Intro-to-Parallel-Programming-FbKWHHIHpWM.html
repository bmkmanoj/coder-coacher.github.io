<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Measuring Memory Usage of Our Transpose Code - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Measuring Memory Usage of Our Transpose Code - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Measuring Memory Usage of Our Transpose Code - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FbKWHHIHpWM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so if we go through this analysis for
all of these kernels will see that our
parallel per element version of the code
achieves 12.5 gigabytes per second our
parallel per row version of the code
gets about 1.8 gigabytes per second and
our serial version of the code gets an
abysmal 0.01 8 gigabytes per second this
is roughly the speed of a carrier pigeon
and a better way to think about this
perhaps is not in absolute numbers but
as a percentage of what the particular
GPU we're using can achieve so if we
were to work out the percentages we're
achieving it's something like 31 percent
of theoretical peak bandwidth with our
highest performing kernel 4.5% peak
bandwidth with our per row kernel and
less than 1/10 of percent with our
serial kernel so back to the question
why is this number so low well we can
take a pretty shrewd guess that a
whenever you see really load DRAM
utilization really low percentage
bandwidth your first guess is always
coalescing the way to think about
coalescing is that the GPU is always
accessing global memory accessing the
DRAM and pretty large chunks 32 or 128
bytes at a time and this means that
we're going to need the fewest total
memory transactions when the threads in
a warp access contiguous adjacent memory
locations so this is an example of good
coalescing every thread is either
reading or writing an adjacent memory
location and clearly if the threads in a
warp are reading and writing completely
random locations in memory then you're
gonna get poor coalescing right so if
these accesses are spread out all over
the memory then the total number of
chunks of memory that we have to read
could be as large as the number of
threads in the warp so a random access
pattern clearly leads to bad coalescing
so much more common access pattern is
what's called strided and this is where
threads access a location memory that's
a function of their thread ID times some
some stride so for example thread 0
might access location 0 thread 1
location 2 thread 2 location 4 thread 3
location 6 and so on in that case that'd
be a stride
- because there's two elements between
thread accesses and strided accesses
range from okay like in this case we're
with the stride of of two elements I'm
really only doubling the number of
memory transactions so I'm sort of
having the quality of my mic coalescing
all the way to really really bad right
so you can imagine that if the stride
between elements is large enough then
every thread in the warp is accessing a
completely different 32 or 128 byte
chunk of memory and then you're you're
guaranteed to get bad behavior
guaranteed to be maximizing the number
of memory transactions that you have to
do so let's look at the code for our
kernels here's where we're reading from
the input matrix and this actually works
out pretty well every thread is reading
a value in memory which is equal to some
large offset J times n plus I and if you
look at I I is really the thread index
plus some offset so adjacent threads
you know threads with adjacent thread
indices and X are reading adjacent
values of the input matrix that's
exactly what we want so this is good
coalescing on the other hand when we
write the output matrix adjacent threads
threads with adjacent values of I are
writing two places separated in memory
by n right and in was like a thousand
twenty-four so adjacent threads are
running in memory locations that are a
thousand twenty-four elements away from
each other this is clearly really bad
this is bad coalescing bad bad bad bad
bad bad bad this is in fact the root of
our problem</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>