<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The RL problem | Coder Coacher - Coaching Coders</title><meta content="The RL problem - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The RL problem</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JlhH6YVfneg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's important to point out that when we
say reinforcement learning we're really
describing a problem not a solution in
the same way that linear regression is
one solution to the supervised
regression problem
there are many algorithms that solve the
RL problem because I started out as a
roboticist I'm going to first explain
this in terms of a problem for a robot
so here's our robot here and our robot
is going to interact with the
environment so we represent the
environment as this sort of cloud up
here so the robots going to take actions
that'll change the environment it will
sense the environment reason over what
it sees and take another action in
robotics we call this the sense think
act cycle and you don't have to
implement it only using reinforcement
learning there's many ways that you can
implement since think act but we're
going to focus on how to do that
with reinforcement learning okay so our
robot observes the environment and some
form of description of the environment
comes in let's call that the state s so
s is our letter that represents what we
see in the environment now the robot has
to process that state somehow to
determine what to do and we call this PI
or policy so the robot takes in the
state s and then outputs an action we'll
call that action a and it affects the
environment in some way and changes it
now this is a sort of circular process
the action a is taken into the
environment and the environment then
transitions to a new state so T is this
transition function that takes in what
its previous state was and the action
and moves to a new state and that new
state comes out boom back into the robot
robot looks at its policy action comes
out now this is a question how do we
arrive at this policy how do we find pi
well that's what we're gonna spend a
couple lessons on but this whole puzzle
is missing a piece and that's the thing
that helps us find pie and part of that
piece is well there's this other part
called R which is the reward so every
time the robot is in a particular state
and it takes an action there's a
particular reward associated with taking
that action in that state and that
reward comes in to the robot and you can
think of the robot as having a little
pocket where it keeps cash and that's
what that reward is and the robots
objective is over time to take actions
that maximize this reward and somewhere
within the robot there's an algorithm
that takes all this information over
time to figure out what that policy
ought to be so let me recap a little bit
S is the state of our environment and
that's what the robot senses in order to
decide what to do it uses its policy PI
to figure out what that action should be
and by the way PI can be a simple lookup
table over time each time the robot
takes an action it gets a reward and
it's trying to find a PI that'll
maximize its reward over time now in
terms of trading our environment really
is the market and our actions our
actions we can take in the market like
buying and selling or holding s are
factors about our stocks that we might
observe and know about and R is the
return we get for making the proper
trades</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>