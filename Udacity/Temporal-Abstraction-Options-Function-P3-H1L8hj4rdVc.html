<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Temporal Abstraction Options Function P3 | Coder Coacher - Coaching Coders</title><meta content="Temporal Abstraction Options Function P3 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Temporal Abstraction Options Function P3</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/H1L8hj4rdVc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay Michael so here's the definition of
the reward function Eskimo oh it's an
expectation over the set of rewards that
I'm going to see discounted at each step
by gamma so the first reward that I see
are one at step one is going to be our
at step two it's going to be our to
discounted by gamma at step three it's
going to be our three discounted by
gamma squared and so on and so forth
until the option ends after K steps and
that final reward will be discounted by
gamma to the K minus 1 so this is in
some sense the average in fact in a very
particular sense this is the average
discounted reward that I will see by
executing this option in this particular
state does that make sense yes I mean
it's it's I guess it's weird because
it's kind of immediate reward in the
sense that it's the reward that comes
from that executing that one option but
it's also clearly not immediate reward
it's a sum of rewards right so one way
of thinking about this is remember all
an option is is a policy that I'm going
to execute that policy will be realized
in specific actions which means it will
be realized in particular States and
rewards that I will see a bunch of Sarge
Sarge Sarge Sarge Sarge Sarge so even
though from the outside I start here in
this particular state some time passes
that I end up in this state what's
actually happening along the way is I'm
visiting every single one of these
states and picking up reward along the
way but we need to be able to discount
that reward and so the discount factor
is hidden inside of the reward function
so this is as if rather than executing
the option I had actually just executed
all the atomic actions that the option
itself will impact execute and then you
call that sort of one bolus of reward
all right because all that's really
happening right is that whenever you
have this kind of summation over you
taking you've seeing a bunch of states
and taking a bunch of actions all you're
doing is adding up all the rewards
you're going to see remember we got the
bellman equation by just writing out
that we're going to visit these we're
going to visit a whole bunch of rewards
that the definition of the value of
being in the state is the expected
discounted reward so and we're keeping
that consistent here in this in this
abstracted
temperley abstract actions setting by
virtue of the fact that still the
immediate rewards are discounted
according to the true time steps of the
underlying process even though we I
guess as the agent get to think at a
higher level we get to think about an
action taking multiple steps right
exactly and so we do something very
similar for F and we end up with this
nice equation</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>