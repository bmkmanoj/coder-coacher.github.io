<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Virtually Accessed Cache - Georgia Tech - HPCA: Part 4 | Coder Coacher - Coaching Coders</title><meta content="Virtually Accessed Cache - Georgia Tech - HPCA: Part 4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Virtually Accessed Cache - Georgia Tech - HPCA: Part 4</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YWKPtJJtbUs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">we can improve the overall hit latency
of the cache using a virtually accessed
cache in that case the virtual address
is what we use to access the cache and
get the data on a cache miss we would
use the virtual address to tell us what
the physical address is so that we can
bring data into our cache but on cache
hits we can get the data without doing
the TLB access at all so the advantages
of this virtually accessed cache over
the physically accessed one are that the
overall hit time is just the cache hit
time with no TLB latency added to it
that's nice and we don't need the TLB
access on cache hit so we can save
energy
we like that tool so we have seen that a
virtually accessed cache has the hit
time that is just the cache hit time
because we use the virtual address to
access the cache and because of that we
get the data
even without address translation on a
cache hit so we can only access the TLB
on a Miss which saves us TLB misses and
saves energy which is also nice so it
looks like the virtual access cache
would win every time so why are we even
considering physically access caches
well first of all the TLB in addition to
containing the translation for the
physical address also contains
permissions that we need to tell us
whether we are allowed to read or write
or execute certain pages so even though
we don't need a physical address from
the TLB in order to get our data we
still need to access that he will be
even on cache hits just to get the
permissions that tell us whether we are
allowed to read write or execute that
location so this advantage really
doesn't exist in real processors a
bigger problem is that the virtual
address is specific to a particular
process so if we were running one
process and filled the cache with its
data once we begin running another
process that other process will have
virtual addresses that might overlap
with the addresses from the previous
process but they should be going to
different data pretty much in the TLB
there would be different translation
for that other process and we should be
accessing different actual memory
locations because our cache only knows
about virtual addresses in this case we
now need to flush our cache meaning
remove all the data from it every time
we do a context switch once we are
switching to another process we know
that virtual addresses are going to map
to different locations so what we have
to do is get rid of everything we have
in the cache this means that we have a
burst of cache misses every time we
switch processes processes are switched
once every millisecond or so so it
doesn't sound like a big deal but keep
in mind that the cache can be large so
it takes a lot of misses to bring in the
data into it so this is a disadvantage</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>