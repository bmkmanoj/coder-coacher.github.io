<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Explore or Exploit Lemma | Coder Coacher - Coaching Coders</title><meta content="Explore or Exploit Lemma - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Explore or Exploit Lemma</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qKB3BQ_KotY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so the last little piece to talk about
is the Explorer or exploit lemma so the
idea of the Explorer exploit lemma is it
gives us the piece of the argument that
we did when we were doing deterministic
R max which basically said if we are in
some kind of a loop going around and
around and around that we're getting
optimal reward if not then we're gonna
quickly reach an unknown state and we're
gonna learn something and so the the
corresponding version of this in a
stochastic domain is okay so let's say
we're running R max and all the
transitions are either accurately
estimated or we mark them as unknown and
we have an you know an R Max transition
for those state action pairs mm-hm
then if we take that MVP and optimize it
that optimal policy is either near
optimal in other words the the that
we're not making any mistakes the reward
that we're getting as we travel along
this optimum policy is essentially
optimal or we're actually going to make
it to some unknown state some R max
marked state relatively quickly in
polynomial number of steps we're gonna
reach this new state and we're gonna
learn something from that and so this
property ends up being true throughout
the execution of R max I'm sorry
literally that property or that property
like with high probability right with
high probability right so things can
always fail we set up our Union bound in
such a way to make sure that that the
probability of failure is sufficiently
small given that it hasn't failed then
this would actually this relax would be
true and if it's true then what's gonna
be happening is we're either going to be
doing the right thing or we're gonna
quickly bump into a new state learn
something new and continue and the
number of times that we can learn
something new is going to be bounded by
the number of states times the number of
actions mm-hmm and the number of steps
before we learn something new is bounded
by a polynomial in the various
quantities and that's I think all we
need right so we can't actually run for
a very long time without either learning
something new or being neurotic huh I
feel like there's some metaphor for life
here hmm how would that go I'm not sure
something about grad school yeah you
can't always just go there oh I'm pretty
sure you can and I proved it for many
years all right well so I don't know if
this is related to grad school but it is
sort of a key property of these
algorithms that's just basically
trying to handle the case that says by
virtue of the fact that we make the
unknown stuff optimistic we do the right
thing right so we're either learning
quickly or we're being near optimal and
so what would be bad is if there was
some kind of hole in between these two
cases right that says well we're kind of
stuck doing something suboptimal for a
long time but we don't know it and we
don't learn that we are doing something
wrong that's the bad case and and what
the what this lemma is about is showing
that in fact the bad case doesn't happen
either we're learning something or we're
doing very well right and that could
only not happen if we were incredibly
and extremely unlucky but if we were
incredibly and extremely unlucky then
you couldn't learn anything anyway yeah
right that's 12 then and that's back to
this sort of pact notion that it's
probably going to work and we can
actually put at least approximately yeah
that's right and working is here related
to approximately so that was really all
I wanted to get at with exploring
exploration so this idea that even in
general mdps
we have a way of organizing our learning
so that we can make guarantees on how
close to optimum we are and how quickly
we get there but wait a minute you
didn't tell me what C was C just quickly
oh this C is correct no I meant the
original C that was a parameter oh well
I did not write down a formula for that
but it it follows the same analysis as
what we did when we wrote down the value
of C for bandits okay so good enough we
could make that a homework problem sure
I mean that's what we usually do know
what I write something down okay all
right done</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>