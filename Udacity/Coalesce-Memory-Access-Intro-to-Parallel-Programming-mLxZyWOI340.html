<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Coalesce Memory Access - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Coalesce Memory Access - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Coalesce Memory Access - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/mLxZyWOI340" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the other major thing that you can do to
minimize the time that your program
spins in its memory accesses is what's
called coalescing we want to coalesce
your accesses to global memory let me
explain what that means whenever a
thread on the GPU reads or writes global
memory
it always accesses a large chunk of
memory at once even if that thread only
needs to read or write a small subset of
the data in that large chunk but if
other threads are making similar
accesses at the same time then the GPU
can exploit that and reuse this larger
chunk for all of the threads that are
trying to access that memory this means
the GPU is at its most efficient when
threads read or write contiguous global
memory locations we say such an access
pattern is coalesced in this example
every thread is reading a writing from a
chunk of memory that's basically given
by the index of the thread plus some
offset and so this is a coalesced access
this is good you'll get very high
performance on a memory read or memory
write in this setting in this example
every adjacent thread is accessing every
other memory location and so this is not
coalesced we would call this strided
because there's a stride between every
threads access and this pattern is not
so good if you think about it the way
that I drew this dotted line here sort
of implied that the GPU in this case was
accessing memory and chunks of five
memory locations so if I were to just
draw out the next five memory locations
you could see that here to service the
needs of four threads making a request
each to an adjacent memory location I
was able to service that with a single
memory transaction this dotted line
whereas in this case the same four
threads are accessing a broader striding
across memory and I actually need to
pull in two memory transactions to two
of these chunks of memory in order to
service that so I'm going to get half of
the speed out of my global memory here
you can probably see that the larger the
stride between my threads the more total
memory transactions I'm going to have to
do and the lower my performance will get
at the limit you can get to a place
where each thread is accessing spots so
far in memory are so unrelated to each
other in memory that every single thread
gets its own memory transaction and this
as you can imagine will lead to pretty
bad performance from the memory system
so we'll talk more about memory
optimizations later so for now just know
that global memory is going to be
fastest when successive threads read or
write adjacent locations in a contiguous
stretch of memory</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>