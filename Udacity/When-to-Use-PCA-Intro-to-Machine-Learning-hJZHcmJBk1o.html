<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>When to Use PCA - Intro to Machine Learning | Coder Coacher - Coaching Coders</title><meta content="When to Use PCA - Intro to Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>When to Use PCA - Intro to Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/hJZHcmJBk1o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">So now you should have a good intuition for what PCA is, and how to use it.
The last example I'm going to give you, starting very soon,
is one of the coolest examples of where PCA is actually used in the wild.
But before we get into that, let me just pause and, and
talk about when you want to use PCA.
When is it an appropriate approach?
The first one is if you want access to latent features that you think might be
showing up in the patterns in your data.
Maybe the entire point of what you're trying to do is figure out if
there's a latent feature.
In other words you just want to know the size of the first principal component.
An example of this might be something like,
can you measure who the big shots are at Enron.
The second one of course is dimensionality reduction.
There's a number of things that PCA can do to help you out on this front.
The first is that it can help you visualize high-dimensional data.
So, of course when you're drawing a scatterplot you only have two dimensions
that are available to you, but many times you'll have more than two features.
So there's kind a struggle of how to represent three or four or many
numbers about a data point if you only have two dimensions in which to draw it.
And so what you can do, is you can project it down to the first two
principal components and just plot that, and just draw that scatter point.
And then things like, k-means clustering might be a lot easier for
you to visualize.
You're still capturing most of the information in the data but
now you can draw it with those, with those two dimensions.
Another thing the PCA can help with is if you
suspect that there's noise in your data.
And, in almost all data there will be noise.
The hope is that the first or the second, your strongest principal components,
are capturing the actual patterns in the data.
And the smaller principle components are just representing
noisy variations about those patterns.
So by throwing away the less important principle components,
you're getting rid of that noise.
The last one, and what we'll use as our example for the rest of this lesson,
is using PCA as pre-processing before you use another algorithm, so
a regression or a classification task.
As you know if you have very high dimensionality, and
if you have a complex, say, classification algorithm.
The algorithm can be very high variance,
it can end up fitting to noise in the data.
It can end up running really slow.
There are lots of things that can happen when you have very high input
dimensionality with some of these algorithms.
But, of course, the algorithm might work really well for the problem at hand.
So one of the things you can do is use PCA to reduce the dimensionality of
your input features.
So that then your, say, classification algorithm works better.
And this is the example that we'll do next.
It's something called eigenfaces, and
it's a method of applying PCA to pictures of people.
So this is very high dimensionality space, you have many,
many pixels in the picture.
But say, you want to identify who is pictured in the image.
You're running some kind of facial identification, or what have you.
So with PCA you can reduce the very high input dimensionality,
into something that's maybe a factor of ten lower.
And feed this into an SVM, which can then do the actual classification of
trying to figure out who's pictured.
So now the inputs, instead of being the original pixels or
the images, are the principal components.
So let me show you this example and you'll see what I mean.</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>