<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Artificial Intelligence - Q&amp;A with Sebastian Thrun: June 2017 | Coder Coacher - Coaching Coders</title><meta content="Artificial Intelligence - Q&amp;A with Sebastian Thrun: June 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Artificial Intelligence - Q&amp;A with Sebastian Thrun: June 2017</b></h2><h5 class="post__date">2017-06-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gyEyBZdUjCo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone we are back here with
Sebastian for another Q&amp;amp;A session hi
Sebastian how are you doing good see you
good to see you too
all right our first question here is
something that comes up pretty often so
I'm going to ask you in a different way
so I'll name these different topics one
by one and you tell me the first word
that comes to your mind ready
absolutely okay data science great jobs
AI sampled overhype sometimes ml love it
did a lot of work in it
how about deep learning kind of the same
thing these days okay so this first
question was from Ratna who was asking
what is the difference between data
science AI ml and DL do you have
anything to add to that it's evolving
and it's a strong overlap these days if
you ask someone at AI butts over lipid
data science ten years ago I would have
said nothing and now it's strongly
overlapping saving machine learning and
deep learning and the reason is data has
become so much more important and data
is not the core of AI of all these
disciplines now there are differences
for example epidural games or search is
something you would not find in data
science in science is pure descriptive
it looks at data as it is whereas AI
goes a step further and looks into the
decision-making cool a related question
from autism is why isn't there a
universally accepted definition of AI
there's never ever universally accepted
definition of anything try to find out
what a is so what the present oriented
state says AI is a very subjective
matter and people sometimes have very
strong emotions about the word
intelligence yet they can't even agree
with intelligences in biology so I
wouldn't spend much time worrying about
it there's a good about AI which is we
are really asking the question can be
human level intelligence and then
there's a bad which would scares people
off to call artificial intelligence
because call it data science P will be
much less scared that's an interesting
take on it
Thanks so our next couple of questions
are from Attila when we've seen them
before you might remember the name so
the first question is very interesting
how does Sebastian keep himself updated
on the latest developments in deep
learning hi adalah in many ways I have
still a lot of students here at Udacity
in stem
that helped me with us sometimes the
evil violent paper are there too on deep
learning so we can contribute but also
scientific literature nips is a great
conference
ICML is a great conference and these
days a lot is in the news so we just
follow up what's happening there now
that's my main source cool another
question from outliers how much of
neuroscience research is related to deep
learning
that's a phenomenally good question
because the link right now is week
series neuroscientists would look at
back propagation say it's simplistic
serious deep learning people would say
be much better than the human brain in
many ways but what I see is a
convergence I see you convergence in the
sense that there's a very simple
architecture on the line and forgive me
my neuroscience friend you might debate
this but I think if it fits on to a
small thumb drive if the human DNA it
can't be they're complicated and
secondly data plays it phenomenally
important more than filling it up and I
see this as a convergence between human
loan and computer learning because in
the past to instruct a computer a
software engineer to sit and spell out
all the rules over the computer storage
contingency and now we train a computer
not dissimilar from a human being with
lots of data right that's very and
that's very important because now like
the actual hand coding is less important
but structuring the training for
computers has become more yea important
it's is in the exciting time great so
what what problems in deep learning do
you think we'll keep researchers busy in
the next decade or so I think we've kind
of scratched the surface so far we do in
some sense simple understanding like we
can understand whether a more on your
skin is skin cancer or we can understand
whether certain centers is a good
response to customer inquiry but they
haven't yet gotten to really complicated
multi-domain reasoning like our go
program by Google that beats the world's
best go players can't play chess and our
work here at Udacity and voyage on
surviving cars can fly a plane so I
think getting this kind of cross
learning in place where an AI is as
multiple competencies it's something
we're going to be working on great do
you think this is that if I
some people call artificial narrow
intelligence versus artificial general
intelligence I would say so yes so right
now every a Isis machine can only do one
task very very well and nothing else
cool all right our next question from
retina is what are some interesting use
cases or products in the market for deep
learning
I think deep learning will have having a
massive impact on any repetitive human
work so if you're an accountant and you
fill spreadsheets if you are a doctor
and you diagnose or your radiologists
and look at x-rays
whether you are lawyer maybe a litigator
and you try to find this Gregg
accommodating emails and will discover
your document our scopes documents these
are on areas where we now pay people
often even hundreds of dollars or where
I think the data or the work is so
repetitive that if it is training I we
can basically make people a hundred
times as effective so if I were to start
a company today in AI I would do one
pick a highly paid job like for example
a dermatologist and give them a powerful
system at the hand that make them a ten
or hundred times as efficient cool so
you're giving them some ideas yeah
absolutely it's a this is going to be a
killer area to big companies in the
future awesome another question related
to deep learning
Nikita asks are there any successful
approaches that combine deep learning
and classical AI for example in computer
vision way too few so what has happened
is for many many years the more
rule-based day I kind of was the winning
this mini horse and companies would spin
it around the idea the Dakotan expert
and you elicit the experts decision
rules and you put them into a system and
you build what's called an expert system
and that was actually intellectually as
well a big part of AI for many years and
I was a student people who talk about
logic and inference and the frame
problem was actually the hardest problem
the eye when I was a kid which today no
one has a clue what that is in fact I
never understood it either to be fun but
then the machine learning took off it
was just so powerful they left most of
AI behind
and I can see a situation where rules
would come in but maybe not the the
classical wave in expert writes them
down but more in the way that any I
would read other books and books are
kind of rules because they kind of give
you language descriptions but not as
syntactically correct as the classical
AI rule and if that happens if even I
could read all the books and prime
itself of eating all the books they
would be even stronger interesting right
going back to the talk about
neuroscience here's an interesting
question from Anton he is asking are you
interested in doing a project on neuron
segmentation and leading up to basically
the idea of trying to use advanced deep
learning and AI to analyze neural
structures and then once you understand
those structures maybe reflecting back
and improving our deep learning
algorithms themselves is anyone trying
to do that is that something you've
thought of but I would argue the way I
understand it it fits into the area of
image segmentation and it's a
non-trivial segmentation task so we have
to understand what a boundary is you're
in a three dimensional situation but you
get a two-dimensional slice so you might
miss certain structures and as every
image segmentation problem it's it's
massively interesting right so you can
do amazingly good work you can write a
PhD and that's to be honest the question
is whom do your help like whom to go to
and and whose life do you make better if
you have a good result this is going to
be a clinician a pathologist research
and then I have a medical person and I
bet there's people who greatly care
about this I want to point out there's
actually phenomenally great work on 3d
microscopy
out of Stanford mark Navarro and others
who really understand how are they image
and entire tissue in 3d in a single shot
and I would assume as many more
interesting to go to 3d segmentation
yeah and it sounds like something like
that will let us understand much better
how our own neural structures work look
when you look at the human brain with
it's ten to the over eleven Iran and ten
to fourteen connections it's it's it's a
miracle how it works but there's many
different levels at which you might look
at this if you look at the neural level
you almost certainly at this point won't
be able to image the entire
brain so you'd rather go to two smaller
animals like insects that often have a
much more repeatable neural structure
but you can reflect individual neurons
across different individuals and even
those I had to understand so people who
do and your science work often go more
macroscopic they might use an MRI
machine for example to look at act
activity at a global level and it's it's
been a miracle it's been really amiracle
to understand the human brain yeah cool
and George's has a question around
transfer learning so our students use
transfer learning in one of the projects
but nanodegree and their concern is
about accuracy
so we claim that when we use transfer
learning we're not sacrificing much of
accuracy but what happens if we train
the same neural network from scratch on
the new problem is the result more
accurate or better in some sense than
the transfer money approach that's a
great question I would usually toss a
question back at the student body else
but you guys think if you ask me I think
it's a matter of how much data you have
if you have infinite data for the new
task in infinite training time I would
not exactly see a reason why transfer
learning helps you but given that in
most deep learning networks the number
of parameters could vastly outnumber the
number of data points I would think that
starting from scratch could be negative
and here's a complete example in fairway
this year my students and I published a
paper in Nature on skin cancer detection
using deep learning and we trained a
neural network to distinguish between
cancerous and lung cancer was patches of
skin and by an low behold from that we
can actually match the performance of
the best doctors and hidden in this
paper his transfer learning which is we
started out with an empty network and we
turn to fleet riedel and network that
was pre tain by Google to recognize
things like cats and dogs and the letter
one did better so we have an example the
trans one really helped us in fact this
paper would not exist without friends
for learning
cool that's an interesting case for for
transfer learning it's not just
improving
but actual results yeah it's all to do
with the bias-variance dilemma sososo
view if you have a small data set and
lots of parameters you tend to overfit
and what the prior data gives you is
control structure it says in computer
vision whether you recognize cancer dogs
or whether they recognize skin cancer
there's some commonality there's some
understanding of similar features it's
actually beautiful because you might
wonder why babies bubble-like for the
first year and do something that looks
doesn't look very interesting but
they're learning like crazy you could
now argue maybe what they learn visually
in early life hates them later on when
they come specialists and you don't have
to read and write in all the other
things cool right Daniel has a question
on product so what are opportunities for
AI or opportunities in AI for product
managers they they seem to be only in
big companies like Facebook Google and
Amazon but are there any you know
smaller companies where product managers
and I would be useful oh my god there
and every single company gonna hire you
Daniel there's lots of startups right
now we may be my student group with the
skin cancer is finding out a company
another student group is spinning or the
company and trying to to organize
repetitive work the customer service
acquisition domain and all of these need
product managers my recommendation for
every product manager is be technically
really strong so you understand the
technology don't become a product
manager just be abstractly familiar with
a field because you need the technical
understanding it was a product manager
if you don't call yourself the technique
understand what's going on to be a great
product manager that's a good suggestion
so Aaron had an interesting question on
slack I asked them to posted here is
there such a thing as a neural network
designed to train other neural networks
to solve a problem oh my god I have not
come across this yet so meta learning
done by a neural network there's been
work on the probably the worst work I've
ever seen was really catastrophic be
poorly done but used a neural network to
guide the training of
other neural network and transfer
learning by extracting derivative
information and imposing it
did happen to be on PhD thesis called
explanation based on network learning
and we got some positive results okay
but it was at a time when weapons are
very very small so don't read it but
yeah I think there's an opportunity I
think for me that the field of transfer
learning is very very large and you
might apply transfer learning on the
weight level you might apply it at a
meta level of like meta parameters okay
interesting
some people were pointing out an
approach called Auto ml or genetic
algorithms are they viable options for
this yeah they are and you get it to
this religious battle off of whether
genetic or a lot as is correct which
which at least when I was a student was
widely crazy battle because P when I
made conviction and without much data
but genetic algorithms are search
algorithms they help your search
parameters and if you believe that
parameters that can be extracted from
one domain might be applicable to
different domain then you should try it
should we try it out and see how well it
works okay great
so my last set of questions is from Phil
Oh near they have a bunch of questions
but let's see how many we can get
through one of them is is there any
topic you would have wanted to cover in
the AI and D curriculum but weren't able
to include it but firstly I'm saying
that robotics doesn't find find enough
space in there but I mean there's always
too much of AI to be done game playing
I'd say a field that I find more more
interesting is this notion of Internet
of Things distribute there I we have a
system that's very distributed but I
think what you do get is you get the
foundation you get the ability to pick
up a new topic on your own as you move
on AI if you if you get on Peter Norvig
since to Russell's book it's over a
thousand pages it's kind of crazy long
any of that is from scratching the
surface
so there's many other things even like
inside machine learning a deep
reinforcement which would love to cover
but happened right and we are working to
bring these topics into either the AI
curriculum the ML curriculum or as
separate nanodegrees like the robotics
nano degree
so yeah we're we're definitely working
towards that another question was other
than choosing a good metric as you've
mentioned in
in a previous Q&amp;amp;A what is your advice in
how to approach original research like
how do you keep yourself on track the
research for me is is a conjunction of
solving a problem and discovering the
problem you're trying to solve when I go
to say Stanford and students are
admitted into the PhD from the bachelors
program and they asked me whether
there's to a PhD and what it means I'd
say look in your bachelor's program and
to some extent here at Udacity someone
gives you a problem and you have to
solve it right and some really smart
person like yourself fought really hard
what's a good problem to challenge the
student in a ph.d program in research
you're going to go to office and no one
gives you a problem
professor shows up smiles at you and and
says do something interesting and if you
as you start working on something
complete which you always have to do
otherwise you'll fail you'll find that
the solution the end so you found might
not be quite the answer to the problem
that you posed so give an example my own
life recently so I'm involved in a
company called Kittyhawk
we build electric flying vehicles we
just spent public a few weeks ago and
our belief was what we're really
building is a vehicle that is very quiet
and it's electrically actuated and
therefore can be operated near people in
cities it's not very noisy but as we
were working on this we found the most
intriguing feedback we got from our
customers was wow this is super easy to
fly and we realize the VVD inventing is
a way to democratize flight so that
everybody can learn to fly in five
minutes
we only know electric is a component but
it's not the core attitude I would say
every piece of research I have done we
started out building something we
started making something and we didn't
quite know what questions were answering
and it took a servile Mona Hardison's
lecture pod and researchers to
understand what question are you really
asked an answering that's that's very
important
so what would you say is your process
when you have an AI idea an idea for an
intelligent system from going from just
that idea to a working prototype I think
the most important aspects are first of
all drop everything you know never be
arrogant that your methods are the right
methods question that secondly build the
simplest system you could imagine and
and you might from the very beginning
say no it's not it's not complicated
enough most students I work with have a
bias to build something complicated
first and I worked really hard to change
the DNA to be semi simple first the
simple thing might fail it might succeed
if it succeeds it's kind of amazing
it saves you're building something
complicated and possibly publishing a
stupid paper to be quite frank because
someone else comes along with a simpler
solution and then your paper will not be
read by anybody if it doesn't succeed
you gain a much deeper understanding of
the problem at hand you can investigate
why doesn't succeed and really
understand the problem much better and
then when you take a next step and make
it more complicated you take the right
step and that is completely different
from the vast majority of better
students I've seen in my academic life
at Stanford and Carnegie Mellon
University where the bias tends to be
alert this amazing SuperDuper graphic
and network higher higher hyper
parameter of deep learning thingy and I
want to apply that right I really think
don't do this just take something really
simple and see how far you get and then
understand why you fail like Thad
Starner says try the stupid thing first
and then when it fails and yeah
something coffee and if you write a
research paper in your research results
paper you go in and say at first glance
might might be tempted to go do this
stupid idea and here's the result
and if you give those negative results
along with your positives your chances
of getting new paper accept it go up
astronomically because now the reviewer
will understand why it's a hard problem
that's very interesting cool last couple
of questions one is that as these
students are graduating from the
nanodegree they'll be competing with
people who have masters and PhDs so
felonio
asks how do they stand out from the
crowd I would argue be very very
confident and you should be confident
because what you learn here at Udacity
in in almost every case this more
bleeding edge than what you can find at
pretty much any University I don't wanna
be negative in universities but if you
for exactly look at deep learning
Udacity teaches more students deep
learning right now
then all universities combined and our
curriculum is directly derived from what
is arguably the leaders in the field
such as a school building and to some
extent ourselves and in deep learning
the the reason is we are so much faster
and building curriculum then then the
professor can be because the professor
kind of tends to teach the same stuff
for 20 or 30 years and so you should
take the confidence what you've done
here if you graduate from yesterday it's
no easy fees you've done something
amazing now many of students are use our
career services I highly recommend it
part of winning a job is not just being
technically good and having done good
work yet audacity or Ellesmere it's also
winning the interview so understand
building an interview and writing a good
CV is actually not that easy but we
offer model services our job is to find
you a table honestly this is our our
intimate goal we are we are really
developing everything we do around the
idea of getting a job and you might come
from behind because you don't have a PhD
from Stanford or MIT but I hope you can
get a hit through the city yeah a lot of
our students are interested in getting
jobs in the I field but some of them are
interested in continuing further
research in that domain so a follow-up
question was have you considered
organizing moonshot projects like
Udacity X where students can work on
advanced research projects guided by
Udacity staff it's funny I I've actually
really playing with the idea we had some
amazing success in the self-driving car
field maybe gave students like yourself
what I consider to be extremely harsh
challenging problems and I get dissolved
and some of you were able to solve them
in 48 hours blow my mind now that
specific project went on and spun out
into a company called voyage so they're
not part of us anymore so we have to be
staff or self-driving car team but I'm
tempted to do something
because I think I mean honestly if I
look at the quality of our good students
it's it's anywhere as strong as strong
as Stanford students I've advice and
this is not meant to be negative on
Stanford I just think among all the
great people the world's temper only
admits a small sliver of those and
there's so many more more that exist
yeah so there's a good chance in the
next few months I spin something up
yeah if someone out here is a really
strong product detail once the one
something like this please send us an
application well I personally am very
much for the idea I've been toying with
the idea of maybe either expanding into
the education domain or picking another
sort of MIDI problem that's out there
and there's so many great probably that
know and seeing what our students can do
yeah great on that note let's conclude
thank you a thank you any us
let's see your class thank you everyone
for joining us today we'll be back with
another Q&amp;amp;A session later on</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>