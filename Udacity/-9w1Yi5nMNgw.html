<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>准确率与训练集大小 | Coder Coacher - Coaching Coders</title><meta content="准确率与训练集大小 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>准确率与训练集大小</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9w1Yi5nMNgw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">there's a very important thing that I
was keeping an eye on as always drawing
up my training set of all the persons of
interest and that is basically the size
of that training set the reason that the
size of your training set is so
important is that it usually has a big
effect on the accuracy that you're able
to achieve with your classifier let me
show you an example of what I mean I
once had a problem that I was trying to
solve in physics I was using a naive
Bayes classifier to try to identify
certain types of particles and I had a
thousand events of each class in my
training set and my question was
basically is this enough events to
capture all the trends in the data so
here's what I did to answer that
question
I took my thousand events of data and I
put about 800 into a training set and
about 200 into a test set then I took
these 800 and I split them again into
four times 200 so then by recombining
different numbers of these slices I
could come up with a training set that
had 200 events 400 600 and 800 and then
I would always be testing it on the same
200 event testing set and what I found
was something that looked like this
the maximum accuracy that you can ever
get will be 100% and usually in practice
the maximum accuracy that's even
hypothetically possible will be some
number less than 100% and if you don't
have enough statistics in your training
set if your training set isn't big
enough
you'll get an accuracy that's even lower
than that so for 200 events maybe I
would get an accuracy that was around
55% however when I go up to 400 events
my accuracy jumps to let's say 70% so I
got another 15 percentage points just by
adding more training data I didn't do
anything else then I go up to 600 events
again my accuracy improves but probably
not as much as before so let's say this
is 80% now and then when I add in my
last slice of 200 events I might be at
about 82% and what this told me was that
there was a trend in the data maybe
something like this that when I looked
at it described to me whether I could
expect the accuracy could
get very much better as I increased the
size of my training set
obviously 200 wasn't ideal if I only had
a training set that had 200 events in it
I couldn't expect to get a very good
accuracy by the time I got out to 800
I'm all the way up to 82% and moreover
by looking at this trend I can see that
it started a plateau and then even if I
went out to let's say a thousand events
I might only get up to 83% so there
wasn't as much of an advantage to add in
another 200 events at the end then this
first 200 events at the beginning and so
one of my concerns when trying to
identify persons of interest is whether
we'd be all the way down here that we
would have so few examples of persons of
interest especially relative to how many
completely innocent people are in our
data set that it's very hard to
distinguish the patterns that set apart
the persons of interest now in a perfect
world I could maybe try to make a graph
like this and if I found out I was down
in this corner I could go out and try to
find more data in this particular
example that's not really possible right
we only have as many persons of interest
as we have it's not like more of them
are just going to appear because I want
to make a better classifier but this is
something that's very foremost in my
head when I first tackle this problem is
how many examples can we get of persons
of interest so when I look at this list
that I've compiled of the names of the
persons of interest and I see that we
have about 30 people do I think that's
enough to proceed with the project and
the honest answer is I don't really know
especially when I first started and
there's no good way to know except to
try it out but ideally if you're working
in a situation say the self-driving car
where you have the option of asking a
question like this how does the accuracy
change with the number of training
events and especially if you have the
power to go out and collect more data if
you need it this can be an extremely
useful series of questions to ask and in
general more data is going to give you a
better result than a super fine-tuned
algorithm this is something that
surprised a lot of machine learning
researchers when they first started to
discover it many years ago but it's
become a truism of machine learning
right now that being able to use more
data will almost always help out
the performance of your algorithm</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>