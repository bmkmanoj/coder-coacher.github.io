<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CUDA Program Diagram - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="CUDA Program Diagram - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CUDA Program Diagram - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lQVV5JCd74I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the computers were using in this class
are termed heterogeneous they have two
different processors in them the CPU and
the GPU now if you write a plain C
program your code will only allow you to
use the CPU to run your program so how
do we write code that will run on the
GPU
that's where CUDA comes in the CUDA
programming model allows us to program
both processors with one program so that
we can use the power of the GPU in our
programs CUDA supports numerous
languages but in this class we're using
C now part of your CUDA program is plain
C and it will run on your CPU CUDA calls
this the host the other part of your
problem will run on the GPU in parallel
it's also written in C but with some
extensions that we use to express
parallelism the CUDA term for your GPU
is the device then the CUDA compiler
will compile your program split it into
pieces that will run on the CPU and the
GPU and generate code for each CUDA
assumes that the device the GPU is a
coprocessor to the host the CPU it also
assumes that both the host and the
device have their own separate memories
where they store data and the systems we
use in this class both the CPU and the
GPU have their own physical dedicated
memory in the form of DRAM with the GPUs
memory typically being a very
high-performance block of memory now in
this relationship between CPU and GPU
the CPU is in charge
it runs the main program and it sends
directions to the GPU to tell it what to
do it's the part of the system that's
responsible for the following one moving
data from the CPUs memory to the GPUs
memory to moving data from the GPU back
to the CPU now in the C programming
language moving data from one place to
another is called mem copy so it makes
sense that in CUDA this command either
moving data from the CPU to the GPU or
moving data from the GPU to the CPU is
called kutiman copy 3 allocating memory
on the GPU and see this command is
malloc so in CUDA its CUDA malloc and
for invoking programs on the GPU that
compute things in parallel these
programs are called kernels and here's
a lot of jargon in one phrase we say
that the host launches kernels on the
device</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>