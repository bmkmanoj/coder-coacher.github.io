<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MLRL Course Outro Part Two | Coder Coacher - Coaching Coders</title><meta content="MLRL Course Outro Part Two - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MLRL Course Outro Part Two</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oZInk0TYs6A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">there's a work out of Stanford and UC
Berkeley on using reinforcement learning
to actually fly model helicopter tricks
like what so it turns out that if you're
flying a model helicopter I've tried to
do this turns out to be really hard to
do part of it is you have to coordinate
the blades and the blades and the blaze
yeah and part of it is that you can do
crazy things with helicopters if you
know how to do it you can make them fly
upside down you can make them swing back
and forth you can make them kind of roll
over and over and over you can do all
sorts of really well I know you can do
all sorts of amazing things but
professional stunt flying helicopter
people can do amazing things what the
reinforcement learning work was about is
trying to get a system to learn to do
those same kinds of tricks huh and they
were able to do this with real
helicopters or real model helicopters a
real model helicopter not a simulator
but in actual you know mini helicopter
okay so that's cool so you sort of
convinced me that burlap and repository
that's sort of a good okay i buy that
but I do want to point out something
that you said that I thought was
interesting you talked about simulators
and that may be what we really want to
do is work in the real world but it
occurs to me that at least one of those
examples the simulator is the real world
so games right so if you have games like
backgammon if you have simulations that
people actually interact with then that
is actually the real problem itself that
is the real world if I'm playing pacman
and I've got a simulator for pac-man
that's the same thing as having pac-man
and if I can learn to play pac-man I've
learned to play pac-man there's not
really a similar involved I would make a
distinction between grid world type
simulators where they were developed
specifically for reinforcement learning
researchers to work with versus as you
say the kinds of simulators that people
actually interact with when they're
doing things like playing video games
and so video games actually is a really
great intermediate step between real
physical world stuff and things that can
be run in simulation and I'm actually
there's been some terrific work in that
space really like what well one of the
things that I'm very excited about
recently is a group called deep mind
which you know they're very good at
naming things have a system for actually
doing what they call deep reinforcement
learning DQ learning where they are
actually trying to learn
in Atari video games video games from
the 80s where they actually are using
you know Atari emulator the actual games
as people actually played them taking
the information that's available on the
screen as input and sending joystick
commands as output and learning to play
actually at the level of human players
wait there's good as human players they
are as good on averages human players
and some of the games are actually much
better than people games like breakout
where you have to bounce a ball around
okay and then there's other games where
they're actually much much worse than
people games like frostbite where you
have to jump around on a bunch of ice
floes it seems very difficult for the
system to actually learn what to do in
that game okay so their heads in an oven
their feet is in ice water but on
average they're comfortable I see what
you're saying so your point is that it's
not playing just like a person it's
playing better and worse than people so
on an average you can say that it's kind
of playing like people mm-hmm but still
that's kind of cool I think it's really
amazing and i think it's it's that
particular data set is itself really
interesting because there's 40 some-odd
atari video games that are all built in
the same system you can use the same
inputs in the same outputs and the same
learning algorithm but you can put in
different games to see what it will do
ok so it is just like Weka and it's just
like you see I accept here Weka is the
burlap algorithms or whatever
reinforcement learning algorithms and
you see I instead of being input-output
pairs are sort of the real world yeah
and there's there some work that's being
done in collecting data from the real
world for example medical diagnosis or
online education I like that we should
do something with that for trying to
figure out what the the right way of
interacting with people online is people
have collected some of that data and
there's reinforcement learning
algorithms that are being run of that
data it's not the full reinforcement
learning problem because you don't
actually the learning system doesn't
actually have to decide how to collect
the data it's already been collected for
it but it is really using real data and
making decisions based on that and I
think that's a really promising
direction for reinforcement learning to
go in the future ok I like that so I got
two things out of that the first thing
is reinforcement learning really can be
used in the real world it has been it
can be and there's a nice bright future
for that's good and the second thing is
I was right there was a bunch of stuff
we hadn't talked about
okay all right that's it that's a valid
point okay was there anything else you
want to wrap up with anything well I
feel like we should say maybe a little
bit about the current directions in the
future of reinforcement learning so one
of the things I think is really neat is
that it's having an impact not just on
engineering and computer science but
also on the behavioral sciences and the
neurosciences house oh well so the sorts
of things that we think about
reinforcement learning being good for
are an agent that's interacting with
some environment it's making decisions
it's trying to figure out what to do
it's trying to be happy and so you could
argue that animals and people are trying
to do exactly those sorts of things that
that we we are reinforcements learners
sure animals do it people do it yeah
birds do it educated fleas have been
known to do reinforcement learning right
okay and so the interesting thing about
that is the neuroscientist when they're
trying to think about okay well how can
we understand the algorithms essentially
that people are running they're turning
to the reinforcement learning field as a
source of inspiration for the structure
of the algorithms how they can be set up
what sorts of things have you know
seemed to work and not work and they're
actually looking for evidence of these
in real brains oh I like that I like
that a lot and you know what I really
like about that is it takes us back to
the beginning of the machine learning
class it takes us back to beginning of
the reinforcement learning class well we
try to emphasize the point that
reinforcement learning is not just a set
of algorithms it's not just an approach
it's actually a way of thinking about
problems and so really this whole class
has been about solving problems and I
feel like we have solved some problems
hey I think that's a wonderful note to
end things on what are ya know I think I
think this is really valuable thanks so
much alright well thank you very much
Michael I appreciate it and I will see
you in the next class bye</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>