<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Decision Tree Expressiveness - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Decision Tree Expressiveness - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Decision Tree Expressiveness - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KwMaBd3UitA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so we saw before when we looked at and
an or versus X or that in the case of an
Leonor we only needed two nodes but in
the case of X or we needed three the
difference between two and three is not
that big but it actually does turn out
to be big if you start thinking about
having more than simply two attributes
so let's look at generalized versions of
or and generalized versions of X or and
see if we can see how the size of the
decision tree grows differently so in
the case of an inversion of or that is
we have in attributes as opposed to just
two we might call that the any function
that is a function where if any of the
variables are true then the output is
true we can see that the decision tree
for that has a very particular and kind
of interesting form any ideas Michael
about what that decision tree looks like
so well so going off of the way you
described or in the two case we can
start with that and use you pick a pick
one of the variables and if it's true
then yeah any of them is true so the
leaf is true what happens if it's false
well then we have to check what
everything that's left so then we move
on to one of the other attributes like a
2 and again if it's true it's true and
if it's false and we don't know we'll
look at a 3 good idea
mmm this could take some time yes oh
there's actually an interesting point
let's say if there were only 3 we would
be done right right but wait what if
there were 5 then we need one more node
what if they were in then we need n
minus 4 more nodes right so what you end
up with in this case is a nice little
structure around the decision tree and
how many nodes do we need looks like one
free tatra beaut so that would be n n
nodes exactly right so we have a term
for this sort of thing the size of the
decision tree is in fact linear
and in and that's for any now what about
an inversion of XOR so XOR is if one is
true but the other one is not true then
it's true and if they're both true yeah
I don't it's not clear how to generalize
that so why not so well the usual
general version of this we like to think
of is parity all parity is is a way of
counting so there's usually two forms of
parity that we worry about either even
parity or odd parity so let's pick one
it doesn't matter
I'd say odd
I like that we'll do odd parity and all
that works out to be in this case is if
the number of attributes that are true
is an odd number then the output of the
function is true otherwise it's false
got it got it
okay so how would we make that decision
tree work well we got to split on
something and they're all the same so
let's split on a1 again okay so what do
we do if a1 is true vs. being false we
don't know much if a1 is true we have to
look at everybody else right oh let's
look at a 2 what if a 2 is true versus
false of a 1 and a 2 or true then the
output is going to be whatever the
parity of all the remaining variables
are so we still have to do that yep and
I'm already running out of room so let's
pretend there's only three variables
what's the output all right so the far
left is there's three truths which is
odd so the output is true yep the next
leaf over only two trues a1 is true a2
is true but a3 is false so that's two
trues which is even so the answer is
false
mm-hm and is this going to pattern
continuing then we've got no so then
it's false again because we've got two
trues in a false to get to the next leaf
mm-hm
and we've got one true to get to the
next leaf so that's true
oh that looks like XOR it looks just
like XOR in fact each one of these sub
trees is kind of a version of XOR isn't
it now what we have is
have to do the same thing on the right
so we got to redo a two and we're going
to be in the same situation before we're
going to start drawing on top of each
other because there's just not enough
room hmm so what's the answer to the one
on the very right where all of them is
false
all of them are false so that's an even
number of true zero is even so that's
false okay so in the case where only a
three is true just true and we just keep
going on and on and on again now imagine
what would happen in fact let me ask you
Michael what would happen if we had and
four attributes instead of three then
we'd be really tired of this game
yes and I'm already tired of this game
so the question is can get a whole
another whole other level of this tree
yep we have to uh just goes on and on
and on and nobody wants to think about
anymore so how many nodes do you think
there are well for three there was one
two three four five six seven
which seems suspiciously like one less
than a power of two mm-hmm and that is
exactly right you need more or less to
the UH notes or to the end maybe minus
one yeah but let's just say Big O of two
to the end everyone watching this is a
computer scientist so they know what
people mean okay so you need an
exponential therefore as opposed to
linear number of nodes dad yeah so you
very very quickly run out of room here
you very very quickly have a really
really big tree because it's growing
exponentially so XOR is an exponential
problem and is also known as hard
where as or at least in terms of space
that you need is a relatively easy one
because it's linear we have another name
for exponential and that is evil evil
evil and it's evil because it's a very
difficult problem there is no clever way
to pick the right attributes in order to
give you an answer you have to look at
every single thing that's what makes
this kind of problem difficult so just
as a general point Michael I want to
make is that we hope that in our machine
learning problems we're looking at
things that are more like any than we
are looking at things that are more like
because otherwise we're going to need to
ask a lot of questions in order to
answer the parody questions and we can't
be particularly clever about how we do
it though if we were kind of clever and
added another attribute which is like
the sum of all the other attribute
values that would make it not so bad
again so maybe it's just a just a kind
of bad way of writing the problem down
well you know they say about AI is that
the hardest problem is coming up with a
good representation so what you just did
is you came up with a better
representation where you created some
new pairs a new variable let's call it B
which is just the sum of all of the a s
where we pretend that I don't know true
is 1 and false is 0 this is actually
really good idea it's also called
cheating because you've got to solve the
problem by picking the best
representation in the first place
but you know what it's a good point that
in order for a machine learning to work
you either need an easy problem or you
need to find a clever way of cheating so
let's come back and think about that
throughout all the rest of the lessons
what's the best way to cheat</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>