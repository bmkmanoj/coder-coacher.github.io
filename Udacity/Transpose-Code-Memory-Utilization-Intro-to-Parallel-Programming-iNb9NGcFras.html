<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Transpose Code Memory Utilization - Intro to Parallel Programming | Coder Coacher - Coaching Coders</title><meta content="Transpose Code Memory Utilization - Intro to Parallel Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Transpose Code Memory Utilization - Intro to Parallel Programming</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iNb9NGcFras" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so before we proceed I want to fill
in these numbers again and rerun this
program to get values that correspond to
what you'll see on the Udacity IDE until
now as I've mentioned I've been using my
laptop but I want to we're gonna let you
play around with this transpose code and
I want you to see on the screen numbers
that are a little bit more comparable to
what you'll get on the much bigger GPUs
that Udacity is using versus the one
that's in my laptop okay so here's the
code we've looked at before this time
it's running in the Udacity IDE and what
I want to do now is do a test run and
here's the results we get so you can see
that now transpose cereal took eighty
two point six milliseconds all the way
down to transpose parallel per element
tiled which took about 0.1 three
milliseconds so here I've written those
results down again and now we can go
through and fill in the DRAM utilization
so you can see that we've got the same
pattern the serial version of the code
which runs in a single thread takes 82.7
milliseconds as we get more parallel we
start moving into single milliseconds
and then sub millisecond and by the time
we get here we're running quite well at
0.35 milliseconds and sure enough by
tiling that code we improve on this a
little bit but now we're still spending
a lot of time waiting at barriers and by
going to a smaller tile size we can get
that all the way down to 0.1 3
milliseconds and at this point we're
getting about 43 and a half percent of
the theoretical peak limit of our
bandwidth and that's actually doing
pretty good
there's one last optimization effect
that we're not going to talk about at
this lecture but you're welcome in fact
encouraged to go look it up any CUDA C
best practices guide or in many
presentations that you can find online
if you're motivated and curious I
decided that it's a fairly subtle effect
and not too important and that's shared
memory bank conflicts essentially what
this says is that shared memory is
organized into banks and depending on
how you line up your thread accesses
that the array of threads is making to
the memory that's actually stored in a
tile you can end up spending a lot of
times
of replaying over and over you saw that
shared memory replays statistic much
earlier when we were looking at the NV
VP output and that's what this is about
the fix is relatively simple and as I
said we're not going to go into it here
but there's a version of this code that
you can download and play with on the
wiki the fix is actually simply to
reserve a slightly larger chunk of
shared memory then you're actually going
to use and this has the effect of
padding the shared memory and striping
it across the bank's which can actually
improve our run time even slightly more</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>