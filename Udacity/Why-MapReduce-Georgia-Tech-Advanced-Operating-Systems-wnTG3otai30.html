<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Why MapReduce - Georgia Tech - Advanced Operating Systems | Coder Coacher - Coaching Coders</title><meta content="Why MapReduce - Georgia Tech - Advanced Operating Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Why MapReduce - Georgia Tech - Advanced Operating Systems</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wnTG3otai30" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the question is why MapReduce is a
programming framework for big data
applications it turns out that several
processing steps in giant scale services
are expressible as MapReduce for example
let's say that you're looking for seed
availability for selected dates to
selected destinations on different
airlines that can be expressed as a
MapReduce computation let's say you want
to access frequency of the URLs on a
website that you've designed that can be
coded up as a MapReduce application
let's say you want to create word
indexes to facilitate document searches
on the web that can be coded up as a
MapReduce application or let's say that
you want to do ranking of pages when a
user is doing a search how to present
the search results may depend on the
popularity of pages and that is what is
often referred to as page ranking so if
page ranking has to be done for all the
documents that is another application
that can be coded up as a MapReduce
application the list goes on all such
examples that I mentioned share some
common property there embarrassingly
parallel and they're common in giant
scale services and all of them tend to
work on big data sets therefore there is
plenty of opportunity for taking
advantage of the computational resources
that are available in a data center and
all such applications need domain
expertise in terms of what to do with
the data which is expressible as a map
function and a reduced function and this
is the only thing that is required of
the domain expert to provide to the
programming system because that is
domain expertise that lives with the app
developer so here is another example of
how an application may be structured as
a MapReduce application and in this case
I'm showing you a page ranking
application that is I'm interested in
knowing what is the popularity of
different URLs that occur in a document
corpus so the key space that
input to this application is a set of
URLs and the key value pair that is
coming into each of the mapper is a
source URL and the contents of that web
page that corresponds to this particular
URL so what this mapper is doing is in
the given page defined by this URL the
contents of which is the input to the
snapper it is looking for different
targets maybe it is looking for a
particular URL target one another URL
target 2 and so on target n and that's
what each of these mappers are doing so
the key space that is output from the
mapper is unique target names so the key
space that is output from the mapper is
unique target URLs and the value is the
URL in which it was actually found so
the corpus of input URLs it is taking
and saying well in this particular URL I
found this target if it did it is
emitting that this target was found in a
particular URL and this reducer is going
to get all the hits for a particular
target that was found in the input
corpus of URLs so all the mappers
they're going to send their results to
this reducer if they found in the input
s URL the target target one if they did
they're going to send the result to this
reducer similarly if they found target n
each of these mappers are going to send
to this reducer that in the input URL
they found this target n and the job as
a reducer is once again aggregation and
you have as many reducers as the number
of unique targets you're trying to
identify in the input data set very
similar to the previous application that
we went over so the output of the
reducer is going to be the specific
target that this guy has been asked to
accumulate and a source list meaning all
the source pages in which this
particular target was found so each of
these reduces is going to find the
number of
a particular URL as found in the input
corpus of webpages that came into the
system as a whole for instance if I
wanted to find out how many times my web
page appears in the universe of web
pages all over the world we can take the
entire corpus of web page available in
the universe as input and the mappers
are going to look for occurrence of my
web page in each one of those input web
pages and if they find that they're
going to send it to this reducer and if
target one corresponds to my web page
then this reducer is going to say okay
shores web page was found in this list
of source web pages all over the
universe that in a sense gives a rank
for that particular web page that we are
looking at so we are able to rank the
target web pages one through n based on
the number of source web pages that
contain that particular target and
that's what page ranking is all about so
I'm giving you yet another example of
how this MapReduce functionality can be
applied for an application such as page
ranking all the heavy lifting that needs
to be done in terms of instantiating the
number of mappers instantiating the
number of reducers the data movement
between the mappers and reducers all of
those chores are taken care of by the
programming environment all that the
domain expert had to do was to write the
map and reduce function that is unique
to particular specifics of his
application rest of the heavy lifting is
all done by the programming framework</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>