<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Monte Carlo Tree Search p1 | Coder Coacher - Coaching Coders</title><meta content="Monte Carlo Tree Search p1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Monte Carlo Tree Search p1</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/onBYsen2_eA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay Michael so you know if you go all
the way back to the very first slide
when we started this conversation slide
said something about generalizing
generalizing but one of the words that
was written on there was scalability so
one of the things that we've been
talking about sometimes explicitly
sometimes implicitly is this notion of
getting scale to actually happen so just
because I think it's important to think
about scale more than in terms of
abstraction I just want to take a moment
to talk about a kind of algorithmic
approach to getting scaling to work
that's different from just doing
abstraction of the sort that we've done
before although it's going to turn out
that all the things that we've done with
our abstraction will actually work in
this new kind of algorithmic view of
scalability that seemed interesting yeah
that would be really helpful cool let's
do that all right so here's a particular
algorithm that I want to introduce it's
called Monte Carlo tree search and there
are four words there and there's kind of
two different parts so for the beginning
I just want to concentrate on the tree
search part and then tell you what I
mean by the Monte Carlo part so I want
to use this picture on the right this
sort of little tree all I'm trying to
get you to think about with this tree is
sort of what we've done in the past say
in an AI course where you've got nodes
representing States there are actions
that you might take that would get you
to other states and then more actions to
get to other states and kind of so on
and so forth but this particular tree
has a nice little form that's kind of
hidden by the edges in the nodes and I
want to sort of harp on that for a
little bit and I think it would help if
you understand the algorithm that I'm
trying to get through on this data
structure okay so the algorithm is
written on the left and it's a big loop
loop loop loop loop loop loop and it
works like this they're four steps the
first step is selection and I'm define
what all these things mean in but a
moment but I just sort of want to go
through at a high level what each one is
so the first one is selection and
selection is basically the way in which
you're going to decide what actions to
take from a particular State what's
going to happen is you're going to take
a bunch of actions and eventually going
to get to some point in this sort of
tree here of possible States and actions
you might see where you don't know
enough to know how to make a selection
once you're at a place where you don't
exactly
know how you should make a selection the
idea is that you're going to expand the
tree there and then do simulation to
figure out what it is you ought to be
doing to make selections and the way
that's going to happen is you're going
to estimate from that expanded set of
nodes the true value of taking actions
in those states and then in a very kind
of on a very kind of bellman equation
sort of way you're going to back up what
you learn through your simulation and
then that will allow you to select what
to do next and you'll just keep doing
that over and over and over again making
selections where you know what to do
expanding simulating the world for a
little while so that you learn what to
do and then make those decisions and so
on and so forth so as I make sense at a
very high level so what I'm trying to
accomplish her yeah I think so okay I
mean it reminds me a lot of other kinds
of tree search that I've seen in AI
classes like what a star is a kind of
tree search game tree search is a kind
of tree search they have similar kind of
pictures where you repeatedly expand
nodes and and you know get estimates of
values right and in fact I like the game
tree through game search one this is not
game search because we're living in an
MDP and it's just us and so we're not
playing against an opponent but
something very nice about that
particular one is the way it works in
that world often is you have a
particular way of figuring out what
action to take or you sort of expand and
do a search among a bunch of
possibilities and then eventually you
run out of time and so you have to
decide what the value is whatever leaf
nodes you've gotten to and the way you
do that is use something like an
evaluation function which tells you how
good we think this node is and that's
just what you what you've got to work on
and you use that and you back up the
values and that helps you to make a
decision about what to do and then you
make a decision then your opponent makes
a decision you end up in a state and you
do it all over again
basically you search out as far as you
have time to search out for when you run
out of time you use some estimate that
you got from somewhere of how good the
node is and then you back that up and
that's basically what we're going to be
doing here except we have another
wrinkle and the wrinkle here is where
the monte carlo part comes in so the
tree search is very standard the monte
carlo part is well we've got randomness
we've got still cash
city in our transition model and so
we're going to have to come up with some
way to do this estimation that takes
that into account and that's where the
simulation is going to come from okay
all right so let's sort of beat that up
in the little parts I actually that's a
lot of words but I think kind of walking
through this picture might might help a
little bit</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>