<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Print Path Solution - Artificial Intelligence for Robotics | Coder Coacher - Coaching Coders</title><meta content="Print Path Solution - Artificial Intelligence for Robotics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Print Path Solution - Artificial Intelligence for Robotics</b></h2><h5 class="post__date">2012-05-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CyQ2gl-9W4o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so here's my solution I make a field
called action of the same size as the
grid where memorize for each cell what
action it took to get there so for
example if in the gold cell over here it
took an action of go down to get there
from the previous cell then this cell
over here would have the action index
for the action down that's a little bit
tricky but it turns out to be really
easy to program in my node expansion
routine where I go from X to X 2 which
we talked about before I now add just a
single command for the successor state X
2 and Y 2 I memorize the action it took
to get there notice I don't associate it
with x and y the from state and the
reason is in the from state I'm trying
out many different actions and I don't
get know which one succeeds but when I
hit the 2 state and expanded for the
first time then this is going to be the
expansion that's part of the optimal
path so I associate the action with the
successor state not with the originating
state over here very subtle very
important if you got this right you know
exactly what I'm talking about
now I have a field that memorizes for
all these states over here the action it
took to get in there but I don't have
this wonderful representation as I have
over here this will be compiled into a
field called policy or plan which I
initialize with blanks but it was the
same size as grid this is the field over
here which I eventually print out down
here in that field I said the location
of the goal explicitly to be the star
we're setting over here and then I go
from the goal backwards I iterate from
the goal location x and y now in
backwards order all the way to the start
and do this as long as X and white
haven't become my initial location yet
and I apply the inverse action so I find
the originating state but taking my
current state and subtracting the action
exactly the same way I added it before
using my action field as finding out
what action was actually being used in
doing so the first time it
X&amp;amp;Y was the goal state and x2y2 become
the state before I happen to know in the
gold state that the action was a down
action if I apply the negative of it I
go up and find myself over here I then
mark the policy field for the
originating state to be the special
symbol associated with the specific
action over here and then i recurse i
set x and y to the state x2 y2 and I
then go a step for them in doing so I
will reverse the path step by step print
the associate action and get exactly the
state over here very tricky but look
this is an advanced artificial
intelligence class you might as well
program something very tricky took me a
while to program it myself but I finally
got it right too</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>