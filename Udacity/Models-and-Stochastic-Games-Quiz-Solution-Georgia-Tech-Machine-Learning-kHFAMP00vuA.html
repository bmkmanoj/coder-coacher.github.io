<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Models and Stochastic Games Quiz Solution - Georgia Tech - Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Models and Stochastic Games Quiz Solution - Georgia Tech - Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Models and Stochastic Games Quiz Solution - Georgia Tech - Machine Learning</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kHFAMP00vuA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right talk me through it okay so I'm
going to say that I think I know the
answers for this one and let's start
with the first one so r1 equals minus r2
which you'll notice they are equal and
opposite and in fact if you add them up
that is you sum them you end up with
zero so I'm gonna say that's a zero sum
stochastic game nice for two basically
you're saying that for all intents and
purposes there's only one agent which
just makes it a regular Markov decision
process yeah so isn't that interesting
that just by making the other player
irrelevant then that's what an MVP is
it's like a game where the other players
are irrelevant
yeah which both of my children are like
that but okay I think that's pretty cool
and in fact I'd be right in saying that
r2 doesn't have to equal to zero as long
as it just equals to some constant yes
that's I mean constant actually
depending on how you think about it it
could be we could just ignore the whole
r2 thing and just say that as far as the
first player is concerned since the
second player really has no impact on
anything it doesn't matter but the
reason I put that in is I got kind of
scared that like I feel like if I lived
my life and knew that my actions
affected the state and my rewards but
they were also affecting the rewards of
somebody who didn't matter like I feel
like that would actually still have an
influence on me sure but then the way
you'd get around that is you would say
well your r1 is actually equal to your
r200
so if I had gone like that wouldn't it
be the case then that we're saying oh
yeah I see that the second player is
irrelevant but the reward but the first
player may be relevant to both yeah okay
I like that a little bit better yeah I
mean once again it all boils down to
changing the rewards okay and so given a
and B I know the answer to three must be
C unless you're tricking me and it could
be a or b again which I suppose you
could have done you didn't say they were
mutually exclusive so let me actually
argue why it would be C well there's
only one state and since you're in a
stochastic game and you're going to be
continually doing this it means that
you're basically doing the same game
over and over and again so it's a
repeating game yeah yeah so in
particular the actions impact the
rewards but they're not going to impact
the transitions because you're always
just going to go back to where you were
the discount factor plays the role of
deciding when the game is going to end
Casta Klee and so yeah it's exactly a
repeated game and this is the one I feel
most comfortable about because this
really does recover that same model that
we've been talking about how I get cool
now given that we actually are now in a
model that generalizes mdps it would be
nice if we could generalize some of the
things that we did with MVPs like queue
learning and value iteration to this
this more general setting so that's what
we're gonna try next cool</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>