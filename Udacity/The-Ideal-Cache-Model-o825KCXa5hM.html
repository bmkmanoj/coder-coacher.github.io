<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Ideal Cache Model | Coder Coacher - Coaching Coders</title><meta content="The Ideal Cache Model - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Ideal Cache Model</b></h2><h5 class="post__date">2015-07-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/o825KCXa5hM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">to analyze a cache-oblivious algorithm
we're gonna need a model of how a cache
works here's the model I want you to
assume which we sometimes call the ideal
cache model start by assuming that slow
and fast memory are divided into blocks
of size L words this L is the same as
the transfer size will refer to one of
these blocks and fast memory or cache as
a cache line so you have a machine in
which fast memory is being managed
automatically consider your algorithm or
program as it runs the issues sequences
of load and store operations these loads
and stores reference addresses in slow
memory for this lesson let's assume that
the algorithm issues these operations
sequentially now consider some load
operation suppose it reads from an
address
call it a and wants to load the value
into a register call it are the hardware
will check to see if a copy of a is
already in fast memory if it's there
then it returns the value and completes
the store operation which writes to
register R let's refer to this case as a
cache hit because the value that we want
is in cache if the value we want is not
in cache then it's a cache miss in this
case the hardware grabs the value from
slow memory but also stashes a copy in
the cache keep in mind that the hardware
has to transfer an entire cache line now
which L consecutive words around the
address a get transferred depends on how
a is aligned so what about a store from
say a register s to a memory address B
you will behave kind of like a load
operation there's a copy of B in cache
then it's a cache hit and we update the
cached value otherwise there is no copy
of B in the cache and it's a cache miss
the hardware would load the block from
slow memory into cache in other words a
store miss like a load miss causes a
memory transfer ok so those were the
basics of load and store operations
here's the next assumption in the ideal
cache model the cache is fully
associative ok so what does that mean
remember that a cache consists of a set
of cache lines or cache blocks now
suppose you load a new block from slow
memory full associativity means that
this block is allowed to go into any
block or line of the cache now you may
know about set associative caches and
direct map
cassia's if you do then you know that
real caches typically don't implement
full associativity rather they implement
one of these schemes which has the
effect of restricting the possible cache
lines that a given memory address can go
into full associativity says you can
ignore this restriction
it's a simplifying assumption that will
make our ideal cache model more powerful
than real caches now at some point the
cache will be full of previously used
values to make room for new values the
hardware will need to choose some line
to kick out or to evict if the value
being evicted hasn't been written to
main memory yet because say it was a
store hit previously then that will
cause another memory transfer I'll refer
to those transfers as store evictions so
if we have to kick something out what do
we kick out that leads us to the next
assumption of the ideal cache model
optimal replacement optimal replacement
means that the hardware managing the
cache actually knows the future in
particular the hardware knows all future
accesses it looks at all the blocks
currently in the cache and then evict
the one that will be accessed most
distantly in the future at first glance
this might strike you as being extremely
idealistic or optimistic but in fact
we'll do an analysis of just how
powerful this assumption really is in a
moment okay let's do a quick summary of
all the assumptions of the ideal cache
model will model the program is issuing
a sequence of load and store operations
to slow memory the hardware manages the
Z words of cache which is divided into
lines of size L words each these Z over
L cache lines will sometimes call cache
blocks as in the conventional IO model
slow memory to cash transfers will
happen in lines or blocks of size L if
the value for some slow memory address
is already in cache it's a cache hit and
otherwise it's a cache miss a cache will
assume is fully associative lastly when
we need to evict a cache line we'll
assume an optimal replacement policy
this policy sees the future one final
point remember that in the conventional
IO model we counted memory transfers in
the ideal cache model we do the same
thing the number of transfers is really
equal to
number of misses plus the number of
store evictions okay now I think is a
good time to see if you really
understand how an ideal cash might work</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>