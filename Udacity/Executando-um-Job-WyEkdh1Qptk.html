<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Executando um Job | Coder Coacher - Coaching Coders</title><meta content="Executando um Job - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Executando um Job</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WyEkdh1Qptk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's often the case the MapReduce code
is written in Java however to make
things a little easier for us we've
actually written our mapper and reducer
in Python instead and we can do that
thanks to a feature called Hadoop
streaming which allows you to write your
code in pretty much any language you'd
like
first of all let's double check that we
have our input data in HDFS so if I
Hadoop FS minus LS then there's my input
directory and if I look at that
directory then yes there's purchases txt
in there and in my local directory I
have mapper dot P Y and reducer dot py
that's the code for the mapper and
reducer written in Python we'll look at
the actual code in the next lesson okay
to submit the job we have to give this
rather cumbersome command we say Hadoop
jar a path to a jar then I specify the
mapper I specify the reducer I need to
say - file for both the mapper and the
reducer code I specify the input
directory in HDFS and I specify the
output directory to which the reducers
will write their output data and we're
calling that job output I hit enter and
off we go
Hadoop is pretty verbose as you can see
as the job runs you'll see a bunch of
output which shows us how far along the
job is it turns out that for this job
Hadoop will be running for mappers and
our virtual machine here can only run
two at a time so the job is going to
take longer than it would on a larger
cluster actually that's worth mentioning
here with the size of the data we have
for this example which is only 200 Meg's
realistically we could probably have
solved this problem faster by just
importing the data into a relational
database and querying it from there and
that's often the case when we're
developing and testing code because the
test datasets are pretty small Hadoop
isn't necessarily the optimal tool for
the job but when we're done testing and
we need to process our full production
data
that's when hadoo really comes into its
own so as you can see the job is now
nearly complete and when the job has
finished we'll get a set more output and
you'll see that the last line tells me
that the output directory is called job
output let's take a look
what we've got in there Hadoop FS minus
LS shows me that yes I now have a job
output directory and if we look at the
job output directory you'll see that it
contains three things it contains a file
called underscore success which just
tells me that the job has successfully
completed it contains a directory called
underscore logs which contains some log
information about what happened during
the jobs run and then it contains a file
called part - zero zero zero zero zero
that file is the output from the one
reducer that we had for this job
let's take a look at that by saying
Hadoop FS - cat part zero zero zero zero
zero and we'll pipe that two less on our
local machine that's the contents of
that file which is the output from our
reducer it's the sum total sales broken
down by store exactly as we want it
incidentally if you want to retrieve
data from HDFS and put it onto your
local disk you can do that with Hadoop
FS - get Hadoop FS - get is the opposite
of Hadoop FS - put it just pulls data
from HDFS and puts it on the local disk
so as you can see now I have my local
file txt on my local disk and I can
manipulate that however I'd like</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>