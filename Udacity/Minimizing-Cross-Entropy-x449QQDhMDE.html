<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Minimizing Cross Entropy | Coder Coacher - Coaching Coders</title><meta content="Minimizing Cross Entropy - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Minimizing Cross Entropy</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/x449QQDhMDE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so now we have all the pieces of a
puzzle the question of course is how
we're going to find those weights W and
those biases B that will get our
classifier to do what we want it to do
that is have a low distance for the
correct class but have a high distance
for the incorrect class one thing you
can do is measure that distance averaged
over the entire training set for all the
inputs and all the labels that you have
available that's called the training
loss this loss which is the average
cross entropy over your entire training
set is one humongous function every
example in your training set gets
multiplied by this one big matrix W and
then they get all added up in one big
sum we want all the distances to be
small which would mean we're doing a
good job at classifying every example in
the training data so we want the loss to
be small the loss is a function of the
weights and the biases so we're simply
going to try and minimize that function
imagine that the loss is a function of
two weights weight one and weight 2 just
for the sake of argument it's going to
be a function which will be large in
some areas and small in others we're
going to try to find the weights which
caused this loss to be the smallest
we've just turned the machine learning
problem into one of numerical
optimization and there is lots of ways
to solve a numerical optimization
problem the simplest way is when you've
probably encountered before gradient
descent take the derivative of your loss
with respect to your parameters and
follow that derivative by taking a step
backwards then repeat until you get to
the bottom gradient descent is
relatively simple
especially when you have powerful
numerical tools that compute the
derivatives for you remember I'm showing
you the derivative for a function of
just two parameters here but for a
typical problem it could be a function
of thousands millions or even billions
of parameters</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>