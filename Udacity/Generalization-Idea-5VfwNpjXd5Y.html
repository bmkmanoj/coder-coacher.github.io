<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Generalization Idea | Coder Coacher - Coaching Coders</title><meta content="Generalization Idea - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Generalization Idea</b></h2><h5 class="post__date">2015-07-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5VfwNpjXd5Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now that I've given some kind of
motivation for this notion of
generalization it might be worth talking
about what exactly we are trying to
generalize between different learning
opportunities okay so what are the
functions that we're actually making use
of when we're doing reinforcement
learning what do you mean when we're
learning we're actually generally
learning some mapping right so this is
true in reinforcement learning in
general there's some mapping from input
to output oh I see what you mean so well
the whole goal of course is to learn a
policy which is a mapping from States to
action great ok that seems like a really
good place to start so policy map states
to actions but that's usually hard so we
usually learn some kind of intermediate
thing like a value function well let's
just stick with policy here for a second
so in terms of the policy generalization
would mean that to the extent that
similar states have similar actions then
we could learn what the right action is
for some states and then guess what the
right action is for other states using
some kind of I don't know function
approximations I'm kind of supervised
learning right so if you're in a state
where an anvil is about to hit you on
the head you should probably jump out of
the way that's probably true for every
state where an anvil is about to hit you
in the head even if you've never seen
the specific details of that state
before yeah I mean it could matter
whether or not there also is a shark
tank right in front of you so when you
jump out of the way of the anvil you
actually jump into the shark tank but
yeah I think that's exactly right that
we want to be able to say across lots
and lots and lots of related states that
we could be using the same kind of
action right but I think what you're
pointing out is that we don't know how
to learn the policy directly anyway when
we're talking about these kinds of
reinforcement learning algorithms so we
usually learn a kind of a stand-in for
it and my favorite one is the value
function which is where you're now
mapping States to some number to our
right so we can map for example states
and actions to the estimated return
that's that's what the Q function does
and that's another function that we
could be trying to learn and this is
another function where generalization
might be an option right so to the
extent that similar state action pairs
have similar returns again because if a
pimple is about to hit you on the head
probably that's a bad state you're in a
bad situation
across all the different kinds of states
where an animal is about to hit you in
the head there you go that's you you
should draw a picture of me standing off
to the side to your left
yeah I have the world's tallest Nick
yeah so let's say I'm in a state where
an anvil is about to hit me head there's
lots of other details that are sort of
not that important in predicting what
the estimated returns going to be so you
even look kind of concerned though
that's supposed to be me
yeah you're tall mm okay enough so this
is another place where we could be doing
function approximation is in the actual
cue function itself and there's a third
one that I think is actually really
important and interesting and that is
the model to the extent that you can
actually do a good job of predicting
next States transitions for related
states then you could actually be doing
function approximation or generalization
in the model as well right in fact
that's probably very very important
often yeah it's not only is it important
but it's actually often a really natural
place to do it because when you're
learning a model right so that what's
what is it about learning a model you're
in some state you take some action and
you observe what next teacher in these
are actually supervised examples of
transitions so unlike learning the
policy or learning the value function
when you're trying to learn the model
you're actually getting standard
supervised examples Thanks so that being
said the using function approximation
models it has been done in the field but
it's it's not that well understood in
particular you need models that can
actually predict many many steps ahead
to be able to be used effectively for
planning and decision making mostly what
what researchers have focused on is
function approximation in the value
function so generalization in the value
function so that's what we're gonna look
at in the rest of this lesson
look forward to it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>