<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Stochastic Motion - Artificial Intelligence for Robotics | Coder Coacher - Coaching Coders</title><meta content="Stochastic Motion - Artificial Intelligence for Robotics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Stochastic Motion - Artificial Intelligence for Robotics</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NqIlWVeMIvg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so let me talk about dynamic programming
with stochastic actions and at the end
of this assignment you'll be able to
program this the motivation to study
this is as follows suppose we have a
robot and we have an obstacle and a gold
state then this or what might be tempted
to scratch the wall over here in the
head towards the goal and practices is a
bad idea because robots that get really
close to obstacles are frightening and
in fact if the actions aren't quite
perfect they might actually hit the
obstacle which is no good so in practice
what we tend to do is we go more like
this we maintain a certain clearance to
obstacles and now we're going to modify
our dynamic programming planner to do
just that to find paths that are a
little bit safer and little bit away
from obstacles the way we will do this
is even modern actions as stochastic and
we have not done this before but you
learn how to do it take the action of
going north from the cell over here in a
deterministic action it always succeeds
unless of course you run into a wall in
the stochastic case it succeeds with a
certain probability say 50 percent
whereas with 25 percent chance it might
accidentally go left or right
even though we commanded it to go up
this is a stochastic action and it's
exactly the type action I want you to
program later on if for example there
was a wall over here and there all would
decided to go up maybe 25 percent chance
it would hit the wall which is not good
so staying away from of all is a good
idea in a stochastic situation I will
now show you how the backup works
without asking your quizzes suppose we
study the action of going up over here
and we have a 50 percent chance of
success and suppose at the time we do
the backup the value over here is 10 20
over here and 40 on the right and the
value of the state for the action go up
would be obtained as follows it's 50
percent chance times 10 25 percent
chance times 20 and 25 percent chance
times 40 plus 1 which is our motion cost
which together gives me 5 plus 5 plus 10
plus 1 equals
21 that is the backed up value over here
for the action go up and you can do the
same with go right go left go down the
interesting case in your implementation
is the one for an action that either
runs off the grid or into a wall so
let's study the case of going north from
this cell over here where there's a 25%
chance of falling off the grid then the
value for the cell and the action of
going north is 50% times 20 which is 10
25% chance
times 40 which is also 10 and then we
have this case where you fall off the
wall and let's define the penalty for
falling off the grid or for hitting an
obstacle 100 so we add 25% chance times
100 plus 1 hence the new value is 10
plus 10 plus 25 plus 1 which is 46 so I
want your update to produce for the cell
over a year 46 for this specific action
of going up of course the value might be
smaller because there might be a better
action like the action of going right
but for the specific calculation should
receive 46 so your program the
assignment looks as follows I will give
you a grid in this case it's a grid
that's entirely unoccupied and as before
I give you a gold state and a set of
actions and I want you to program
dynamic programming all the way to the
end so when I run it the values I get a
zero for the gold state
37 for the two adjacent in 4460 and 63
so if I go right to the goal there's a
50% chance of hitting the goal in which
case MCOs is just 1 which is the cost of
motion there's a 25% chance of running
into the wall which cost me 100 plus of
course one for the word motion in
there's a 25% chance
I find myself down here was cost us 44
so we put this into mathematics we get
50% chance for it's in the goal 25% for
hitting of all which cost me hundred
twenty five percent of going south and a
value here is forty four point seven
seven plus the cost of motion is one and
if you add this all up you get exactly
bit
7.19 three let this value over here
constitutes so after convergence for
this quit I want the value function to
look just like this and he is the
corresponding policy if I modify the
grid to insert an obstacle over here
then I get a value function like this
1000 is my initial value for each cell
it I modified for the obstacle still and
these are the values I received 94 86 73
44 you can check what these values are
correct let me take a slightly bigger
grid with the goal position in the top
right corner and two obstacles down here
size 4 before and here's my output for
the value function you can read those
values they happen to be a thousand for
the two obstacles and what's remarkable
is the policy when I'm close to the wall
you can see they're being pulled away
from those Evolvin of all elements to
stay in free space I will eventually
reach the goal but I never I'm willing
to drive in a way that crashes me into a
wall if it's not avoidable what you have
to do with the code we provide is to
modify the dynamic program routine that
assumes a deterministic action with the
one for stochastic action and
specifically what this routine should do
it should incorporate the probability of
successful action and the collision cost
so for example if I modify the
probability of success into a
deterministic function then my value
function looks as follows it's just the
number of steps in the usual way one two
or three as before in the policy drives
me straight to the goal as shown over
here in a final submission please
exclude any printouts so we can modify
the grid and these values for success
probability and collision costs and we
can see what their code generates in the
initial value function please initialize
the value function with 1000</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>