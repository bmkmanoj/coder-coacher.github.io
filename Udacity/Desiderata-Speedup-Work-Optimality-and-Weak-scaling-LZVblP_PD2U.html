<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Desiderata  Speedup, Work Optimality, and Weak scaling | Coder Coacher - Coaching Coders</title><meta content="Desiderata  Speedup, Work Optimality, and Weak scaling - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Desiderata  Speedup, Work Optimality, and Weak scaling</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LZVblP_PD2U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now given a dag and a way to estimate
its execution time how can I tell if the
dag is good or bad let's derive an
answer first we'll identify a metric of
goodness and then we will optimize the
metric let's use speed up as our metric
speed up is defined as the best
sequential time / the parallel time in
terms of symbols I'll use T star to
denote the best sequential time and of
course we'll use TP of n to denote the
parallel time as before now quick
comment about the numerator and the
denominator of speed up the denominator
will in general depend on the work the
span the problem size and the number of
processors the numerator will depend
essentially on the work done by the best
sequential algorithm so for notational
consistency since I'm using work in the
case of a parallel algorithm I'll use
another work symbol for the sequential
algorithm the best sequential time will
essentially always be equal to the best
sequential work now you might be
wondering why am I saying best
sequential time what's special about
best the answer is I'm a good professor
and I want to make it hard to cheat
after all you can always make speed up
artificially large by choosing a
terrible baseline if any of you are into
marketing you know what I'm talking
about now if I give you a peer am with P
processors then ideally you'd like the
parallel algorithm to be P times faster
than the best sequential algorithm this
condition is called ideal speed up or
sometimes linear speed-up linear scaling
or ideal scaling but basically they all
say you want the speed up to be linear
in P here I'm using big theta notation
because you usually won't care about the
constant factors at least not at this
pencil and paper or algorithm design
stage now essentially what this says is
if P doubles then you want sp2 also
double of course that's an ideal we
might not always achieve it let's write
speed up in terms of best sequential
work and parallel time now in the
general case we can use brent's theorem
to get an upper bound on time and
therefore a lower bound on
up so let's go ahead and plug in brent's
theorem for notational ease I've dropped
this / n of n in the right-hand side
just remember that there's a dependence
on end there let's do a little bit of
algebra on the right-hand side to get it
into a form that we can analyze more
easily okay written in this form you can
now immediately see what has to be true
in order to get ideal scaling first
notice the numerator which has the
number of processors in it so relative
to this goal I will pay a penalty which
is determined by the denominator in
other words if I want to get linear
scaling I need the denominator to be a
constant so what would it take for this
to be true of the denominator let's look
at each term in turn for this term to be
constant the work of the parallel
algorithm has to match the work of the
best sequential algorithm this principle
is something we call work optimality
it's a necessary condition to ensure
ideal scaling intuitively it prevents
another form of cheating it says that if
you get a very parallel algorithm by
dramatically increasing the work
relative to the best sequential
algorithm then that's actually bad for
speed up now let's look at the other
term in the denominator for this term to
be constant it essentially says that P
should be proportional to W star over D
so this is similar to the idea of the
average available parallelism and the
main difference is that we have a W star
here instead of just W now there's
another way to write this this other way
to right it is to say that W star
divided by P has to be big Omega of D
let's think about this for a second w
star over P is basically the work per
processor this expression says that the
work per processor has to grow and in
particular it has to grow proportional
to the span and the span remember
depends on the problem size n so in
other words this says that the work per
processor has to grow as some function
of n in the parallel computing
literature this is called week
scalability so basically what it says is
as you increase the concurrency of the
machine then if you want to get good
scaling you might need to increase the
problem
okay that was a little messy let's try
to recap the algorithm design goals you
just arrived so starting from speed up
we set linear scaling as our goal now to
achieve linear scaling you derived two
fundamental principles of good parallel
algorithm design the first is work
optimality which says that the work of
the parallel algorithm should match the
work of the best sequential algorithm
and the second principle is weak
scalability in one interpretation it
basically says that the work per
processor should grow as a function of N
and that function is determined by the
span</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>