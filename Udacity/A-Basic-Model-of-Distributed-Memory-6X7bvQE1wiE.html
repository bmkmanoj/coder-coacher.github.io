<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Basic Model of Distributed Memory | Coder Coacher - Coaching Coders</title><meta content="A Basic Model of Distributed Memory - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Basic Model of Distributed Memory</b></h2><h5 class="post__date">2015-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6X7bvQE1wiE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">to start designing algorithms for a
cluster or a supercomputer you're going
to need a machine model how about this
one in this model a machine is a
collection of nodes connected by some
kind of network each node consists of a
processor connected to a private memory
by private I mean that the node can only
directly read or write its own memory
you can't directly access the memory of
other nodes I'll refer to this type of
machine as a distributed memory machine
now this abstraction of private memories
is critical it implies that to share
data nodes will have to send messages to
one another so for example suppose this
node wants to send data to this node the
only way to do that is the sender or
source has to package up a message and
then put it on the network so this
message will have to find some path
through the network to get from the
source node to the destination node in
contrast to shared memory where we read
and write shared variables this style of
parallel communication is called message
passing now this machine model has a few
simple rules the zeroth rule of the
model is you never talk about the model
by that I mean you need to master and
internalize these rules okay so what are
the real rules the first rule is that
you should assume the network is fully
connected that means there's always a
path from any node to any other node in
the network the second rule is that the
network links are bi-directional what
does that mean well suppose I have two
nodes in the machine and they're
connected by a linked bi-directional
means that the link can carry a message
in both directions at the same time so
while one message is going this way
another message can be going this way
the third rule is that you will allow a
node two concurrently perform at most
one sin and one receive at a time
this rule is important because it
affects the cost of communication so for
example suppose this node wants to send
a message on each of its outgoing links
in order for this node to send four
message it's going to have to send them
one at a time by contrast it could do
one send and one receive simultaneously
the four
rule is about the cost of a simultaneous
send and receive of n words so suppose
this is our computer and let's further
suppose that this node wants to send a
message to this node there are several
different paths here's one path and
here's another regardless of which path
the message takes rule number four says
the following the time to send this
message if it contains n words is a
constant alpha plus another constant
beta times the size of the message in
other words the cost of sending the
message is linear in the message size
now it may seem strange that this cost
somehow is independent of the path
that's taken that's not entirely true
and I'll clarify a little bit later in
the lesson for the time being let's
accept the formula as stated now the
formula has two terms the first term is
called the latency and it has units of
time it's a fixed cost that you pay no
matter how large the message is the
second term has a parameter beta beta
has a name we'll call it the inverse
bandwidth it has units of time per word
you will think a little bit more about
where this cost model really comes from
momentarily so just sit tight
one subtlety is that this fourth rule
really only applies when there are no
messages competing for links so we have
a fifth rule which tells us what to do
when messages are trying to go over the
same link at the same time this
situation is called congestion this rule
says if there are K messages
simultaneously competing for a link then
in terms of the cost of the message will
change only the beta term and in
particular will multiply it by K for
instance let's consider this link that
connects these two nodes the last rule
governs what happens if two messages try
to go over the same link simultaneously
so suppose there's a red message going
this way and a blue message going this
way last rule says that the effective
cost of this operation is the same as if
the data transmission part which is the
beta term was serialized over the link
so these two messages are being
transmitted in parallel instead of
observing
parallel execution time of alpha plus
beta n supposing that the messages are
the same size n what you'll see instead
is a cost of alpha plus beta times n
times 2 okay so take a second to look at
these rules and commit them to memory</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>