<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Temporal Abstraction P1 | Coder Coacher - Coaching Coders</title><meta content="Temporal Abstraction P1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udacity/">Udacity</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Temporal Abstraction P1</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NJhFnaUBypQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay Michael so to demonstrate this idea
or demonstrate some of these ideas I'm
going to look at grid world's one a very
simple grid world to try to get across a
pretty straightforward idea at least
what I hope so pretty straightforward
idea and then slightly more complicated
in prettier grid world in but a moment
but first let's look at kind of a basic
grid world so this is like our famous 4
by 3 grid world except I've added a
couple of details I haven't drawn all
the little squares and all the little
tiny grids because really I just sort of
want to pop up a level here but you
start somewhere in this world it almost
doesn't matter where and you have to try
to get here to a little plus one that's
where all the reward in the world is and
you have the normal actions you can move
up down left right and you know it's
slippery so every once in a while when
you try to move up you end up moving in
a perpendicular direction and and
there's usual sort of thing that we
normally do now other than that what's
different about this world is that I've
got walls like we had before except
these walls actually happen to
coincidentally create little rooms so
let's imagine that you're starting over
here somewhere and your goal is to
eventually learn in this world how to
get to well let's go so I think we know
how to do this I think we've done this
before many many times we certainly did
it in the the four by three grid world
but I want to ask you a slightly
different question I want you to think
about this in a slightly different way
if you were a trying to tell a person
how you should get from this point to
this point what would you tell them I'm
going to say Google Maps this is not
Google Maps there's this isn't a GPS
dead zone oh I know I know it's a mouse
I guess that's that's one of the real
benefits of reinforcement learning is it
can work even even in a GPS dead zone so
so the question is how is this how would
you tell them to go well so you know we
talked to agents via policies so I could
try to give a policy but you didn't
really get so that's a mapping from
States to actions but you didn't really
give me a lot of details about what the
states were so probably if I was talking
to a person I would say something kind
of high-level like well pass through the
doorway
to the east then you enter a room and
there's a doorway to the south go
through that and then a little bit
inside the doorway you'll find a great
reward or at least a reward plus one is
the greatest reward than anyone can
receive Michael you know that so right
and and I like this because what you did
is I gave you the actions up down left
right and you could have said okay so
move right right right right right down
right right and then go I don't know
right right down down down down down
down down down down down right or
something but instead you said well go
to the doorway and then go to the door
another doorway and then once you're
past that doorway you know you'll just
take a couple of steps and you'll you'll
end up where you want to be where the
great reward is and that's perfectly
reasonable in fact it's more than
perfectly reasonable it's a kind of
abstraction I'm in the same way that
function approximation is a sort of
abstraction over the states what you
just described is what we call temporal
abstraction I see and you know that has
a specific meaning but I think to really
kind of grasp what it is the right way
to think about it is you came up with
new actions hmm that's making the action
space bigger making the action space
bigger which is a problem you would
think but each of these actions actually
covers an enormous amount of ground so
in fact if you had said write write
write write write write write write
write down write write write write write
write write write write down down down
down down down down down down down down
down down down down down down write or
something like that that's a lot of
actions to have to reason over over a
long period of time but what you
actually said was take one action take
another action and then I don't know
take one or two action so we managed to
do with your new actions in I don't know
about five steps what would have
otherwise taken I don't know a hundred
steps or maybe he's cool idea maybe six
right and that is where the abstraction
comes from and where the temple nation
nature comes from because again the the
one of the things that makes
reinforcement learning hard is this
delay to reward and what's implicit in
that is that you have to reason over
time that you have to take many many
steps and because all the options there
are several options at every state
you're actually getting an exponential
blow-up over all the paths you might
take
and here what you've done is you've
traded off the price and adding new
actions with being able to skip over
having to make a bunch of decisions
along the way and so now I can do in
five steps would have taken 100 steps
and that's going to be a gigantic
exponential savings</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>