<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Live Stream #98: Starting Series on Neural Networks | Coder Coacher - Coaching Coders</title><meta content="Live Stream #98: Starting Series on Neural Networks - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Coding-Train/">The Coding Train</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Live Stream #98: Starting Series on Neural Networks</b></h2><h5 class="post__date">2017-06-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cmffV5rMSEU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">whoa hello welcome Good Friday to you
afternoon here it is in New York City my
name is Dan Shipman this is the coding
train a YouTube thing that happens every
once in a while where I come and talk
about programming topics and various
other types of things and often
embarrass myself in a variety of other
ways all while live streaming from Tisch
School of the Arts here at new New York
University here in New York City it's a
very hot day outside it is a cool breezy
72 degrees Fahrenheit here in this room
I hope that the microphone is working
fine you can hear me okay that this
music the levels with me and the music
are quite reasonable because I had a few
technical things and change some things
around so welcome I have a few quick
announcements to make to happen that's
what's I just said that without thinking
it through
I should plant I've got a plan for these
things actually hold on hold on
where where where is it oh it's over
here oh there is a discord server
somebody made one uh Sasha I made some
notes I made some notes for today
because a topic that I want to cover
today is linear algebra as it relates to
programming and matrices and code here's
another book these are really just props
these are actual linear algebra
textbooks that I used at one point in my
life but we're talking about okay let me
do the math here divided by 12 carry the
four
well 25 years ago something like that so
in any case uh but I'm going to return
to that topic today now okay that stuff
is going over there so what it what oh
it's a couple things I am taking a look
at the YouTube chat over there in a
screen and I see people saying has he
already started hey you're doing linear
algebra after calculus love how do you
say lolz la la la la la la la anyway
lols lols anyway uh yes I am I don't I'm
not unfortunately nothing on this
channel has a particular is particularly
thought out her plan any like reasonable
logic whatsoever I'm all about trying to
figure stuff out pull from here pull
from here piece this together piece this
together make something creative see if
we can get some code up and running
compiling and running and doing
something interesting so that's kind of
my goal here so I am seeing the YouTube
chat over there I am looking also at a
slack channel which if you would like to
join the coding trade patron program
making it sound like it's a thing you
can go to patreon.com/scishow do that is
a way of crowdfunding the work that I'm
doing here on YouTube and some benefits
in namely a slack channel that I look at
also during the during the live sessions
okay so um bonjour to gaming with Izzy
and the chat so it's summertime but do
we have any summertime music
this summer music I don't know come on a
little break from my usual schedule and
it's actually been a bit more difficult
to schedule these live sessions than I
had imagined good news is I am here in
town in New York City for a stretch of
time from now until July 14th I will
then be away for a couple weeks just
because you're planning your summer
around my schedule which you really
should not that's what's happening right
now so I am hoping now to take this time
from now until July 14th and really
cover with some depth how to program a
neural network from scratch in
JavaScript and perhaps also in Java
using processing most of my inspiration
is coming from almost hey I won't be
doing this almost all my inspiration is
coming from this wonderful book that I
purchased earlier this year called make
your own neural network by tarik Rashid
I think believe who's based in London
this is a step by step with no prior
knowledge needed of any mass or a
programming actually to build a neural
network program in Python because
reasonable people who live reasonable
lives program their machine learning
stuff in Python but I am NOT a
reasonable person living a reasonable
life and I'll be doing this at least for
now starting to do this in JavaScript
and I have to say that the ultimate goal
here I know I'm going to end up just
repeating myself again in a second is
that I oh look it's already even open
here I have actually already done this I
have there's a github repository neural
network p5 which is a my watch is
beeping at me I'm going to press this
this is a JavaScript library with code
based on the code from that book and it
actually has a few demos associated with
it already I'm going to click on this
one this is kind of a classic classic
machine learning scenario of learning to
recognize
digits and I have a little p5 example
where I can draw the letter 3 there
which it thinks is the letter a letter
that number 3 the character 3 the number
3 thinks it's a 5 maybe after some more
training eventually it will determine
that it's 3 we'll see so I have this
example I also have another example
which is a using the same neural network
code oh it's broken
I knew it I changed something I got to
fix this so I'll fix that so anyway I've
done this already I did this for a
course that I taught here at NYU at ITP
earlier this spring and now what I would
want to do is unpack this process unpack
the process that I undertook to make
this library and do it over a series of
many videos so on the one hand you
should probably just go and enjoy your
summer vacation go to the beach read a
book and come back when I'm finished
with this and then kind of get your
hands into like the using the neural
network library making some creative
projects but as an exercise to help
myself
learn more background and more depth
about this topic and for those of you
might be interested I'm going to build
all this stuff over the course of a
bunch of videos which I will start today
ok so that is my main spiel now now it's
about 2:30 schedule-wise
oh yeah I'm going next week O'Reilly ai
conference next week I will have a
limited schedule is this am i off right
here because I will be attending this
O'Reilly artificial intelligence
conference where hopefully I might learn
something that I can take with me and
then bring to this YouTube channel but
so if you if anybody watching will be at
this conference please tweet me at
Schiffman so maybe I can say hello give
you a sticker coding train sticker or
processing sticker or p5 sticker
I can try to remember to bring those
with me and say hello to you at this
conference I'm particularly excited I'm
going to a session on deep reinforcement
learning which is really the the kind of
machine learning algorithm that I'm most
interested in in terms of how it applies
to creative animations and interactive
systems so okay uh truly the chat is
asking about the Chrome extension
tutorial so unfortunately I did say I
okay let me let me answer this for a
second look I'm actually whoa that's
weird
my web browser is on the webpage that I
was just going to go to but it wasn't
before how did it get there
anyway I must have clicked on it
subconsciously so this is a syllabus for
a course which is kind of MIS named
because it's not a beginner course at
all but programming from A to Z it was a
course from last fall and I made a lot
of video tutorials actually if I go to
Schiffman net slash teaching slash a to
Z that's not the right page oh whoa
where is my a to z page if I go to here
oh just slash a to Z just if I just go
to shift Minette slash a to Z you will
find the whole set of pages each with
videos and notes on a variety of topics
and if I go down here to Chrome
extensions here are the examples in a
few notes but I didn't actually make any
of the videos yet so this was a topic
last fall I made videos for this course
all fall along that's an expression to
say and I never got to the Chrome
extension videos I kept saying I was
going to get to it and then it became
kind of like a running joke
so I almost feel like I can't ever do it
because then we won't have the running
joke anymore but I really do need to do
it at some point this will happen for
sure in the fall because I'll be
teaching this course again and want to
fill out stuff and actually I'm going to
add some machine learning stuff to this
course I'm going to
word to Veck I want to look at recurrent
neural networks and text generation
there's something else in chat bot stuff
so that's coming as well in the fall
okay so now I'm looking at the chat see
if anyone's got any questions for me
okay so because of this conference next
week I will not be live again until next
Friday I mean that's what I usually do
anyway so today's a little bit of like
getting back into the swing of things
because I was kind of been laying last
livestream was a week and a half ago and
then I'll be back next Friday and then
I've got two weeks in July that I'm here
in town with a stretch of a pretty
flexible schedule and I hope to get a
whole bunch of live streams in them I go
with that for per month and so because
I'm gonna be away the last two weeks of
July them I might do two per week those
two weeks that's my kind of goal and so
I'm hoping that by July 14th I will have
rebuilt everything about this particular
neural network library in a video on
live talking about it figuring it out
and taking hopefully your helpful
suggestions so let me yeah the problems
I'm going to repeat a lot of this stuff
in a second because I got to do sort of
introduce one of the things that I do it
for those of you haven't watched live
before is the live stream gets edited
into a bunch of tutorial videos that
then get put in a whole bunch of
different playlists depending on what
course they go with so a lot of
introductory stuff I might end up
repeating again I apologize for that
but now I even forgot what I was going
to say so let's see here so I think I
just want to get started mmm okay so a
couple good suggestions from the slack
chat patreon group binge crowd writes
you should make a calendar with all the
conference's you attend that's a good
idea except to be honest with you I go
to very very few conferences I would
love to travel and go to more things but
I just have a lot of work commitments
and family commitments so generally I'm
just kind of here in New York City but I
bet that's a good idea we'll try to kind
of keep that up to date or and
so if I'm doing any other workshops or
things outs conferences outside of stuff
that I usually do here code coder /
surly asks will there be a separate math
video for this topic so this is a good
question
and I've been struggling with this and
this is where I have arrived at at the
moment so I am going to do I'm going to
build a neural network code and I'm
going to use a matrix math to do the
weighted sums of all the connections and
I will get into the details of what that
means so I am going to do some separate
videos that cover the matrix math
required so there's all I'm going to
pick and choose little nuggets from
linear algebra and cover those and also
write the code to implement those things
then at some point and I'd probably not
today
I'm going to get to the part of the
neural network thing where you're
training it and adjusting the weights
with a process called back propagation
we're going to talk about what that
process is write all the code for it but
I don't think that I'm going to derive
the calculus math that's required for
the formulas that are used I'm just
going to use those formulas and point
people to other references or maybe come
later do a follow-up video to unpack
some of that math in a bit more detail
so that's my plan and I kind of had a
similar plan point of view with the
linear regression stuff I mean it's
actually the same math so a lot of that
will apply but where I try to just sort
of like make a video and use the
formulas and then come back and make a
follow-up video for those who would be
interested in that so that's my plan is
this going to be posted later
oh yeah and Karl's so let me make some
notes here I forgot so I also the issue
is as much as I want to okay so hold on
a linear regression batch Grady got some
things that I forgot to do are and Carla
so a couple somebody asked in the chat
will this be posted later yes everything
is posted later it'll even be edited
versions of this later if you don't want
to watch all the long-winded stuff batch
gradient descent is something that
I forgot to mention and covers part of
the linear regression tutorials and then
there were some other additional things
to the perceptron example that I wanted
to do and I'm tempted to come back to
the everyone's asking for the fit I did
this to myself I wanted to do the
fidgets better and code and I never did
that and when I first mentioned that
everybody had the what you know the
reaction that one might expect which was
like groan major groan really could do a
fidget sputter simulation video but then
I got kind of excited about and I talked
about it and then some other people got
excited about it than I never did it so
and yes I'm definitely going to be doing
neuro evolution is my happy place so one
of the things we'll see as we build a
neural network is that the whole point
of one of the one of the one of the key
pieces of working with neural networks
is figuring out how to get the optimal
weights of all these connections that
are in that network and so there are
these methodologies for doing that
there's the standard methodology which
involves this gradient descent like back
propagation algorithm tweaking according
to an error to minimize the error
changing weights to minimize the error
but there is another method which
involves an evolutionary approach to
evolve the optimal weights and that's
the method I love because it's just very
more it's very intuitive and it's can
understand it or relate to my genetic
algorithm tutorials it doesn't involve
all that sort of like calculus stuff so
I'm definitely planning to get to that
yes I could so at least I'm getting some
negative feedback about the fidgets
spinner which will keep me from doing
that oh yeah I've no III will sell out
as soon as I possibly can right
if baking fidgets spinner video will
suddenly get me you know 100 million
subscribers which you won't obviously
then I'll just do it but you know I have
no qualms selling my soul yeah
unfortunately if you're watching this
live you cannot watch it a to 2x speed
you have to watch it to Expedia but I go
to try to pretend that it's going to XP
because I go really fast them to talk
about that that's actually more like 4x
speed what about polynomial regression
oh my goodness ohyeah ohyeah there's too
many things I didn't get to that either
can I in one youtube channel cover the
entire known universe of knowledge no I
cannot to be honest
Allah I mean my my goal with the channel
is to create friendly and accessible
tutorials for people who want to be
creative and experiment with code in an
informal way and so on the one hand you
know I just don't it's not the goal of
my channel to cover every sort of
statistics mathematics computer science
algorithm from scratch in some sense
that I'm going to show to you so you can
memorize it and and redo it again later
I mean I'm not saying that doesn't have
value there are other channels that have
that approach but my approach is quite
informal and loose and so polynomial
regression I don't know that I need that
so much for where we're going because
ultimately I think the creative examples
will come from using neural networks to
to experiment with user interaction and
other types of interactive and animated
possibilities okay
all right I'm reading this chat and it's
just lovely to read all these nice
messages and people are having a
discussion and I can't keep up with it
at all
I forgot the momentum so many things I
forgot I can't do it all
I can't trigonometry yes
two more gesh I will be oh yeah oh
whoops I hit the bell by accident I
could do a fidget spinner with
quaternions if you're new here you know
that if I ever say the word quaternion
I have to run away instantly it's
terrifying or terrifying
all right I think what I'm going to do
because I feel like I'm want to get some
momentum here and start the neural
network stuff I'm just walking over here
to reset this camera um I think maybe I
should hold off should I do
opening requests I'm trying to decide
I'll do the straw poll thing that's
usually how it works best I kind of know
the answer to this but let me just
confirm here pick one finish off some
details and things for perceptron
actually just get started on a neural
network so this is the multi-layered
perceptron you guys probably can't see
this but I will so here we go
create poll so here is the straw poll
address wr6
said 3e
should I finish off some of these things
that we didn't get to and like visualize
and add some other stuff or let's just
get started it's going to be a long
process it won't finish won't be
finished today we get started building
this javascript neural network library
this is why people can watch the engine
searched or the archive cuz you can just
skip over this part where I wait for the
straw poll results
oh wait just this link not working Oh
what happened what happened I was such a
fail all right did let's try this again
everybody is are people able to get the
straw poll it's working okay what's
funny is somebody in the chat said I you
know clicks link arrives at livestream
sees guy dancing leaves so this is good
because if somebody just joined this by
accident sort of sees the dancing is it
interested in probably good it's not
gonna like the rest of the video all
right
I think I know what this is going to be
all right so what we're going to do
today is just get started
and we are going to build a neural
network library in JavaScript and we
should just all be aware good I'm not
really an expert in this and I'm just
doing this to learn it myself and give
it a try
and you're gonna encourage me or not or
whatever but that but I but I feel you
out there I feel you watching how many
people are watching 747 people that's
terrifying absolutely terrifying okay
alright so let's get started really
these different few thing okay so how to
begin so I need a code editor
okay I think I am ready now oh wait
actually I want to there's something I
want to do
okay so I should map this out a little
bit okay so let's think I'm aware where
will these videos live this is a little
tricky because there are two places
right now I am here basically in a week
four of the intelligence and learning
class but this these videos actually go
along with chapter 10 of the nature of
code book and there goes the camera so
that music that I'm playing is by Adam
Blau who is a film and television
composer based in Los Angeles he has a
podcast that I'd love to plug called
rarefied air which is really terrific
and I believe that is called Tori the
dog so to me is their stuff like extra
extra spare music that I could use and
Adam is the composer of the
soon-to-be-released coding train theme
so I know you can't wait for that okay
so I think this is not a coding
challenge I will do some coding
challenges with neural networks but I
think this and it would be interesting
to try to do like a hey just program
internal network in 20 minutes kind of
thing but I want to spend some time
doing stuff step-by-step in a series of
videos about building this neural
network library so the thing that I want
to start with is yeah okay I have these
slides from the perceptron
boy I really could have thought about
this in a different way let me do an
introduction video
I'm really trying to completely try to
figure this out I you know what I am NOT
going to worry about it I am going to I
am going to consider this to be a I got
it I got it everybody we're good I
figured it out this is a new playlist
ten number ten in a nature of code it is
going to look if I go to my channel and
go to here so basically you can see here
what this is going to be is ten neural
networks ten neural networks and what
I'm going to do now is make an intro
video that sets the stage for what's
coming and the perceptron videos will
actually follow that intro video and
then the neural network I mean the
multi-layered perceptron library
building will follow that so I'm God
making videos out of order so first I'm
just going to do probably just like a
couple minute introduction to the idea
okay yeah all right so I'm looking at
the chat I'm seeing lots of stuff oh no
you did not miss the train whistle oh
there's the train whistle okay all right
here we go
I need a moment to meditate the shoulder
seams go over to stretch ah I think
there's an issue where the web is set up
the camera is actually right there but
I'm kind of like standing over here so I
have this like awkward neck craning
thing to look at the camera but we're
just gonna go all right so what time is
it down oh my god 30 minutes in and I
haven't really started doing anything
yet but I was thinking this through and
talking to you you are watching barely
let's go let's get a move on
hello welcome to a video that at this
present time doesn't exist but when you
are watching this video right there to
the right of 9 genetic algorithms will
be the number 10 and will stay next to
that neural networks so I am embarking
on a journey to learn about neural
networks what they are how you program
them what are the what's kind of like
math and stuff you need to know to make
them work and then what kinds of
creative and experimental outcomes can
you have now it should be said that uh
there are lots and lots of machine
learning libraries out there there are
lots of examples and resources for doing
this well I want to hold on I'm still
talking I don't know where did I put
that book act over here I want to
reference this book make your own neural
network by Tariq Rasheed which I used to
develop a lot of the materials that I
will be presenting to you and developing
during this series of videos and I
should also say that you know in this
book this book has all sorts as how to
program your own neural network from
scratch and without even knowing
anything about programming in Python
because as I might have said earlier
today any reasonable person would start
and make a video tutorial series about
programming a neural network from
scratch in Python but I don't really I'm
not very reasonable or logical and I do
we'll make just constantly make mistakes
with everything and here's a mistake
that I'm going to make I'm going to do
all this in JavaScript and the reason
for doing that is to have everything run
in the browser on the web and also
really for me to learn about how to do
this stuff so I am going to build a set
I'm going to building a simple neural
network library in JavaScript not to
make something efficient not to make
something robust but to learn about the
mechanics of how all this stuff works
because ultimately and you might want to
just enjoy your summer or maybe you're
watching this during the winter and get
outside and do something else
and not watch these videos and just skip
ahead to like later because I'm going to
do a bunch of coding challenges and
projects that involve that neural
network library and also other neural
network libraries namely something
called tensor flow in future videos but
these first videos of building the
neural network library which I will do
over a series really just for me to
learn how to do this stuff and if you
want to watch and sort of give me some
good feedback and see if you can follow
along and improve on what I'm doing and
help me with it that would be great so
ok what what hello am i just rambling
here I am but why are we here so I'm
going to go so the nature of code
materials in this video sits in the
nature of code playlist is all about
looking at things in nature in our
physical world and trying to unpack
those things and understand the
algorithms behind those things and see
if we can convert those things those
algorithms into code up this is like
going it's like so auto-playing how do I
stop that and turn those things into
software to make animations and creative
projects why not look at something
really interesting in nature the brain
so this is kind of a loose diagram of
this idea of an actual biological neural
network apparently I have one here
struggling quite a bit these days where
there are
entities called neurons and they're
connected to other neurons and there's a
lot of you know mystery to this and a
lot of recent research to be
neuroscience what I am focused on in
this series of videos is what kinds of
computational systems can be built
inspired by the actual biological neural
net dural Network biological brain and
made into something called an artificial
neural network and what kinds of
applications and outcomes can we can we
create so what is the analog what is the
neuron and by in our code how does it
receive inputs how does it generate
outputs so my brain does this it
receives all these inputs you know from
light in the room that travels through
my retina and into the brain and the
signals that produce outputs and allow
me to catch something or read some words
what how can that how get that process
be simulated in software and what types
of outcomes can be generated and the
very first thing that I'm going to do is
look at the simplest possible neural
network a next not even a network at all
it has one neuron a processor neuron
that receives two inputs and generates
an output and that's called a perceptron
so if you look at the next videos in
this playlist I am going to build in
processing a perceptron example just to
show the mechanics of how this works and
to produce a sort of trivial example
that doesn't necessarily have a very
powerful outcome but gives us because if
we can build and understand how this
single neuron receives inputs processes
those and generates an output then we
can start to connect those together to
create more sophisticated systems that
can begin to generate outputs based on
more complex outputs based on more
complex inputs and this is kind of a fun
fits it's right there in the world of
machine learning this idea of I have
some data that I want to make sense of
that data is an input to a machine
learning algorithm that algorithm is
going to generate it an output so maybe
the data is an
the machine learning algorithm is going
to guess is it a cat or a dog or maybe
that input is the specs of a house you
know square footage a number of bedrooms
etc etc and that's machine learning
system is going to generate an output a
predicted price so there are lots of
other machine learning algorithms
besides just neural network based ones
and I do have another video series that
covers some of those but ultimately I
want to learn how a neural network works
so I can place it right there and start
to make sense of data generate outputs
from it so if you want to continue along
the way this video series will work
first will be a perceptron which is a
this thing then I'm going to talk after
the perceptron is done I'm going to talk
about what the limitations of the
perceptrons are and why it is that if we
can create a multi-layered perceptron
meaning many of these perceptrons all
connected to each other what we can
start to build and create afterwards so
that's my rambling introduction that
apparently you just watched because I
mean maybe I'm then no one will ever
watch this but but but probably somebody
will and I'll see you follow along I
look forward to your feedback I hope
this goes ok that's mine it's a pretty
good goal just ok it's fine and I'll see
you in these future videos as I keep
going thanks for watching
did alright you know that's me that's
this is my style
ok so looking at the chat so now
fortunately so fortunately for all of
you you don't have to now sit through me
doing the perceptron because that is
already oops
that out my channel that is already done
and that is here well that's the
follow-up but if I keep going this way
we can see here it is the perceptron so
there are two videos about the
perceptron at some point I might come
back and fit some little pieces in there
um people are giving me great
suggestions like yeah in the chat but
now I code please everybody is very very
focused on me getting to the point of
things I would tend to agree okay so the
next thing that I want to do now is I
want to talk about all right this is
very hard this is difficult here alright
so I want to talk about first hold on
try to see the thing that I need to
reference I probably should have
followed this along more closely I'm
sorry I'm looking at my notes here yeah
okay
okay so there's this and there's also
have these notes okay okay okay so the
next thing is to discuss why the
perceptron okay all right let's see how
this marker does so first of all um such
a good marker that makes me so happy can
you read that I'm gonna go walk over to
my monitor and see if I can even read
that looks like the focus is kind of
reasonable it's a little bit small
Yasu are yah sis to everybody from
Greece in the chat I guess I just need
to write bigger but that's good okay
people are saying it's okay so where's
my eraser all right okay here we are
I'm going to be in now a little bit
large would be fine okay who font size
+3 okay okay uh here we go
hi again so maybe you just watched my
previous videos about coding a
perceptron and now I want to ask the
question why not just stop here so okay
so we had this like very simple scenario
right where we have a canvas and it has
a whole bunch of points in that canvas
or a Cartesian plane whatever we want to
call it and we drew a line in between
and we were trying to classify some
points that are on one side of the line
and some other points that are on
another side of the line so that was a
scenario where we had the single
perceptron the sort of like processing
unit we can call it the neuron or the
processor and it received inputs it had
like x0 and x1
we're like the x and y coordinates of
the points it also had this thing called
a bias and then it generated an output
each one of these inputs was connected
to the processor with a weight you know
weight one weight to or never wait wait
wait and the processor creates a
weighted sum of all the inputs
multiplied by the weights that weighted
sum is passed through an activation
function to generate the output so why
isn't this good enough now let's first
think about what what's what's the limit
here so the idea is that what if I want
any
number of inputs to generate any number
of outputs that's the essence of what I
want to do in a lot of different machine
learning applications let's take a very
classic classification algorithm which
is to say okay well what if I have a
handwritten digit like the number eight
and I have all of the pixels of this
digit and I want those to be the inputs
to this perceptron and I want the output
to tell me a set of probabilities as to
which digit it is so the output should
look something like you know there's a
point one chance it's a zero there's a
point two chance it's a one there's a
point one chance into two zero three
four five six seven oh and it's like a
point 99 chance it's an eight and a
point oh five chance it's a ten and I
don't think I got those to add up to one
but you get the idea so the idea here is
that we want to be able to have some
type of processing unit that can take it
arbitrary amount of inputs like maybe
this is a 28 by 28 pixel image so
there's 784 grayscale values and instead
those are coming in to the processor
which was weighted and sudden and all
this stuff when we get an output that
has some arbitrary amounts of
probabilities to mitla help us guess
eight not that this is an eight this
bottle why couldn't I just have a whole
bunch more inputs and then a whole bunch
more outputs but still have one single
processing unit and the reason why I
can't is a stems from an article I don't
know sorry a book that was published in
1969 by Marvin Minsky and Seymour Papert
paper called perceptrons you know AI
luminaries here I don't know if I click
on this link where it goes to Amazon
maybe Oh a mighty press so in this book
Minsky and Papert top edit time out for
a second how do you pronounce seymour
papert's last name is it PayPal
paper paper paper paper do I pronounce
the T can somebody help me with this
somebody said dirty Tory the doc
well I wait for somebody help me with
pronunciation paper with a TR no team
paper with this pronounce gif ha ha o is
a good one oh come on I don't want daily
hacks I'm not interested in your deal I
want to know how to pronounce paper
nobody will tell nobody will tell I'm
gonna just mispronounce it oh I'm
looking for Lisa slack channel I can
rely on you patrons somebody must know
look at this I really got the chat going
crazy here Pay Pal yeah my paypal is
Daniel at shipment net OOP that's also a
email
my Bitcoin address is nobody has any
idea that's fine
I will just suffer through the comments
that I will get in the video at a later
time check this video oh my god well I
like the chat is going crazy I've never
seen anything like it
the tea is pronounced thank you ADA ADA
you have come through for me thank you
very much I are totally forgot what I
was talking about okay in the book
perceptron Marvin Minsky and Seymour
Papert point out that a simple
perceptron the thing that I built in the
previous two videos can only solve
linearly separable problems so what does
that mean anyway and why should you care
about that so let's think about this
this over here is a linearly separable
problem meaning I need to classify this
stuff and if I were to visualize all
that stuff I can draw a line in between
this part of the day that this stuff
fits to this class and this stuff that's
with this class the stuff itself is
separable by a line in three dimensions
I could put a plane and that would be
literally separable because I can kind
of divide the space in half and and and
understand it that way the problem is
most interesting problems are not
linearly separable you know there might
be some data which clusters all here in
the center that is of one class but
anything outside of it is of another
class and I can't draw one line to
separate that stuff and you might be
even thinking but that's you know still
so much you could do so much with
linearly separable stuff well here I'm
going to show you right
now a particular problem I'm looking for
an eraser I'm walking around like a
crazy person I'm going to show you a
particular problem called X or let's
erase all this and making the case for
why we need to go a step further and
start to whoops I'm making the case for
why we need to go a step further I just
had an idea I'll go back to later I'm
thinking the case for why we need to go
to is close go a step further and make
something called a multi-layered
perceptron and I'm going to lay out that
case for you right now so you might be
familiar you might remember me from my
videos on conditional statements and
boolean expressions well in those videos
I talked about operations like and and
or which in computer programming syntax
are often written you know double
ampersand or two pipes the idea being
that if I were to make a truth table
true true false false so what I'm doing
now is I'm showing you a truth table I
have two elements I'm saying what if I
say A and a B so if a is true well this
makes no sense what I've drawn here
because I'm losing my brain cells slowly
over time with every passing a it's very
sad true false true false true and true
yields true if I am hungry and I am
thirsty I shall go and have lunch right
true and true yields true true and false
is false false and true is false false
and false is false right if I have a
boolean expression
and B I need both of those things to be
true in order for me to get true
interestingly enough this is a linearly
separable problem I can draw a line
right here and true is on one side and
false is on the other side this means I
could train a perceptron to receive two
inputs true and false you know that are
true or false oh I'm like way off the
screen here that's not a screen that's a
hold on how's that let's let me go
backwards for a second and read you this
part this means Scott this is gonna
fetch me I'm gonna get to the coding I
swear not know if we get to it today -
perfectly honest with you but I've got
all this stuff that I want to talk
through I don't know if it's a good idea
giving it a try this means is this is a
linearly separable problem which means I
could create a perceptron that
perceptron is going to have two inputs
they're going to be boolean values true
or false true or false
and I could train this perceptron to
give me an output which if two truths
come in I should get it true if one
false set of true comes in I should get
a false - false is coming I should get a
false great or I could do the same thing
what is or change in two if I'm going to
do or let me erase this dotted line and
or now all of these become true because
with an or operation A or B I only need
one of these to be true in order to get
true but if both are false I get false
and guess what
still a linearly separable problem and
is literally separable or is literally
separable we could have a perceptron
learn to do both of those things now
hold on a second there is another
boolean operator which you may you might
not have heard of until this video which
would be really kind of exciting for me
I would make
very happy if somebody watching this
never heard of this before it is called
x4 can you see what I'm writing in your
X or the X stands for exclusive
exclusive it's exclusive or which means
it's only true if one is true and what
is false it's not your both are false
this or that if both those things are
false I'm still false but if both are
true it's also false so this is
exclusive or let me erase all this
exclusive or means if one is one is true
and one is false it's true if one is
true is one is false is true if both are
true it's false if both are false it's
false this is exclusive or a very simple
boolean operation however I triple dog
dare with the cherry on top you to draw
a single line through here to divide the
falses in the truth I cannot I can draw
if this is not a linearly separable
problem this is the point of all this
like rambling I could draw two lines one
here and now I have all the truths in
here and the false is outside of there
this means a single perceptron the
simplest cannot solve cannot solve the a
simple operation like this so this is
what Minsky and Papert
talked about in the book perceptrons
well this is like an interesting idea
conceptually it kind of seems very
exciting but if it can't solve X or what
are we supposed to do with this the
answer to this is and you might I've
already thought of this yourself it's
not two but really I I kind of missed a
little piece of my diagram here right
let's say this is a perceptron that
knows how to solve and and this is a
perceptron that knows how to solve or
what if I took those same inputs and
sent them into both
and then I got the output here so this
output would give me the result of and
and this output would give me the result
of or well what is XOR really XOR is
actually or but not and right so if I
can solve something and is linearly
separable not and is also linearly
separable so what I want then is for
both of these outputs actually to go
into another perceptron that would then
be and so if this project run can solve
not and and this perceptron could solve
or and those output can come into here
then this would be the result of both or
is true and not and is true which is
actually this these are the only two
things where or is true but not in but
not and and so the idea here is that
more complex problems that are not
linearly separable can be solved by
linking multiple perceptron together and
this is the idea of a multi-layered
perceptron we have multiple layers and
this is still a very simple diagram you
could think of this almost as like if
you were designing a circuit right if
you decide whether electricity should
flow this were like a these were
switches you know how could you get a
bunch of how could you have an LED turn
on with exclusive or you would actually
wire this circuit basically in exactly
this way
so this is the idea here so what I am
would like to do in the next so at some
point I would like to make a video where
I actually just kind of build take that
previous perceptron example and just
take it a few steps farther to do
exactly this but what I'm going to do
actually in the next videos is diagram
out this structure of a multi-layer
perceptron how the inputs how the
outputs work how the feed-forward
algorithm works where the inputs come in
get multiplied by weights get some
together and
right an output and build a simple
JavaScript library that has all the
pieces of that neural network system in
it okay so I hope that this video kind
of gives you a nice follow-up from the
perceptron in a sense of why this is
important and I'm not sure if I'm done
yet I'm gonna go check the live chat any
questions are important things that I've
missed and then this video will be over
time okay all right what did I do
okay I'm oh I gotta turn this camera on
okay so now is a brief moment where you
can pull out things that I got horribly
wrong that I should make sure I correct
or ask some follow-up questions that
might be important I see there's some
chat going on here but I think that has
nothing to do with what I are we good
we're good does that make sense did I
get that about right I don't know if k
week Mon is watching I don't think so
that's my sanity check yeah I didn't
mention hidden I probably should have
mentioned that like this is technically
the this is technically the hidden layer
these are the inputs this diagram is
terrible because it should be down here
so maybe what I'm going to do is I'm
going to connect you know that's what
I'm actually going to do is maybe I'll
do a quick redrawing of this so that it
matches what people are used to doing
great
oh thank you got to know doing great
place circuit scrambled explains this
thing perfectly that's interesting Tom
this is a coding train t-shirt that you
can get at coding trade
or envy calm proof or EXOR is not and
and or that's right right when I said it
is both or and not and that's correct
okay so I think I'm good I'm not seeing
anyone telling me something that I've
done I'm not seeing anything that I've
done that's sort of like horribly out of
my watch not the shirt this is a Fitbit
I don't know it's the Fitbit whichever
one looks like this okay so let me do
let me get a couple things I would like
to show so for those of you are
interested by the way this is a viewer k
week mon github is k week Mon who
created a learning XOR with a neural net
example and it is it kind of visualizes
the connections and that sort of thing
so I'm going to show this I'm going to
read fix the diagram here and mention
hidden and then that's not a Wikipedia
page by the way this is this page here
is part of my course syllabus and has a
bunch of references here Daniel would be
nice to know if a non-linearity of the
problem affects the number of neurons to
use in the hidden layer so yeah so I
will get to this I mean yes yes and no
it'd be really nice if I could just like
open a door over here and like an actual
machine learning expert come out answer
some of these harder questions but let's
let me get a little further and let's
sort of come back to that I mean the
complexity of the number of hidden
layers affects the number of parameters
that you get to tweak which is the level
of complexity that you can kind of apply
to a problem
so certainly okay so
oh yeah back so there was one question
which is important like Oh what I heard
somebody in the chat asks what about the
hidden layer and so this is jumping
ahead a little bit because I'm going to
get to this in more detail in the next
video there's a way that I drew this
diagram is pretty awkward let me try to
fix this up for a second imagine there
were two inputs and I actually drew
those as if they were neurons and I know
I'm out of the frame but I'm still here
and these inputs were connected to each
of these perceptrons each was connected
and each was weighted so this is
actually what's now known as a 3 layer
Network
there is the input layer this is the
hidden layer and the reason why it's ok
well actually this is the output layer
right that's obvious right this is the
input those are the inputs the druze and
the falses this is the output layer that
should give us a result are we still
true or we false and then the hidden
layer are the neurons that sit in
between the inputs and the outputs and
they're called hidden because as a kind
of user of the system we don't
necessarily see them a user of the
system is feeding in data and looking at
the output the hidden layer in a sense
is where the magic happens the hidden
layer is what allows one to get around
this sort of linearly separable question
so the more hidden layers the more
neurons the more amount of complexity in
a way that the system the more waits the
more parameters that need to be tweaked
and we'll see that as they start to
build a neural network library the way
that I want that's library to be set up
I want to say I want to make a network
with 10 inputs 3 outputs one hidden
layer with 15 like hidden neurons
something like that but there could be
multiple hidden layers and eventually as
I get further and further down this road
if I keep going we'll see that there are
all sorts of other styles of how the
network can be configured and set up and
whether the output feeds back to the
input that's something called recurrent
Network convolutional network is if some
this kind of like set of image
processing operations almost happens
early on before as part of the layers so
there's a lot of stuff in the grand
scheme of things to get to
but this is the fundamental building
blocks so okay so I'm in the next video
I'm gonna start building the library and
to be honest I think what I need to do
no no no yeah I'm the next video I'm
going to setup the basic skeleton of the
neural network library and look at all
the pieces that we need and then I'm
gonna have to keep going and look at
some matrix math that's going to be fun
okay see you soon good bye ever walk
over here
alright okay it is now 3:30 and I've
been streaming for an hour I'm checking
out the chat which is nice to see okay
so I think it's time to write some
actual code okay so what I want to do is
oh I forgot to show this yeah I'll come
back to it because maybe I maybe I maybe
there'll be a time to come back to it
but I do want to build I want to do this
kind of as a coding challenge but it'll
make more sense to do it once I have the
library I think actually in a way okay
so what I want to do now is go to here
okay I can close this I can close this
is there anything yeah okay um and here
oops let's get rid of this
this okay so I think now I'm ready to
start writing the code and and let me
just look I'm going to look at how I set
it up here to do it the same way so I
want to create this is how I'm going to
set it up I want to create a network
that has a certain number of inputs so
I'm going to have the library only
create a 3 layer Network and so it's
made with a certain number of inputs a
certain number of outputs and certain
numbers hidden neurons okay and the
viewers are dropping I'm not surprised
you know this I'm kind of you know I
feel like what I'm doing here is getting
away from is moving a bit ask you or ask
ants aside adjacent to the sort of core
mission and kind of stuff that I like to
do on my channel but trying to take this
two-week period of the summer to see if
I can blast through this material and
hopefully get a sense of it and begin to
do some more interesting applying it
later
I like bandar writes maybe you should
have an outline for every live code
session that would allow for a more
smoother presentation duly noted
duly noted there's nothing smooth about
this whatsoever okay let me keep going I
have a mental outline but I'm just a
scatterbrained okay um so this is what
we're gonna do I'm not going to get very
far with this but that's okay all right
so let me see here okay
all right so here we go I'm going to
move on now
welcome back I'm going to actually write
some code in this video not that much so
what I'm doing now
welcome I made a few introductory videos
covered some background about neural
networks and why they exist and where
I'm trying to go with this and in this
video I'm going to actually begin to
write the code for a simple JavaScript
neural network library now I've actually
already done this it exists here at this
repository github Schiffman slash drone
- network - p5 I've designed this
library to be used with a set of p5.js
examples with a library and JavaScript
library called p5 although ultimately
this library stands alone on itself by
itself you don't have to use it with
just p5 so before I can write the code
let me come over here to the white board
and this is where I last left off
talking about how this general structure
of a neural network library works neural
network system works and so what I need
to do here is when in the code I create
a neural network I want to create three
things I want to create an input layer I
want to create a hidden layer and I want
to create an output layer so when I
create a new the way I want to design
this library is I want to say new neural
network and I want to give it can you
see this I think you can I want to give
it three arguments the number of input
neurons let's just use the word Deron's
the number of hidden neurons and the
number of output neurons so I'm doing
something which I typically don't do
which is usually I'd like to have a
specific problem code tried to solve and
like write the code for that problem and
in here the problem that I want to solve
is I want to make a generic kind of
useful library that can be used in a
bunch of different contexts so I don't
know what those numbers are going to be
I don't know what the data is
I'm just kind of working on the skeleton
the structure of the library before I
start to apply it to things so let's
just make up some numbers let's say
there's going to be three input neurons
four hidden neurons and two output
neurons what this means now is in a
feed-forward neural network there are
three inputs we could imagine again I'm
using the kind of classic example of
guessing the price of a house this could
be number of bedrooms number of
bathrooms square footage so those are
like three parameters of a house
these will connect to one two three four
hidden neurons so this is the input
layer this is the hidden layer and then
I'm kind of running out of space here
there will be two outputs and then this
is the output layer so this is the
configuration the idea of a and so what
I'm building here is what's known as
this is a multi-layered perceptron these
are individual perceptron units
essentially that are have multiple
layers and it also is another important
term that I want to add here is I want
to create a fully connected Network and
now there are variations to this that we
might see in future examples but the
idea of a fully connected network is
that every input is connected to every
hidden every hidden is connected to
every output when I so I can draw all
those connections and it's not so many
that I you know if I were doing some
kind of
post-production I would speed this up
but I'm going to just draw this web of
all these connections so every input is
connected to every hidden and every
hidden is connected to every output whoo
whoops ah I messed this up but how can
it eventually there we go
right so you can see that every every
node is connected to every node in the
next layer so the idea is that those
three inputs come in the data feeds
forward and those two outputs come out
so this is the structure now we have to
get into a lot of details here well how
do I keep track of all of these
connections how do I actually do the
loops to like do all the sums of
everything and how do I read the outputs
I'm going to get to all that but this is
the overall structure so let's go back
to the code and now let's actually try
to like write a little bit of this
library very very little so where am I
going here okay so this is my code
there's nothing yet I'm going to create
a new file and I'm going to call this n
nsj so this is now going to be with MUP
so here's the thing ultimately I want
this to be like a proper JavaScript
library but ultimately what is a
JavaScript library but a file with some
JavaScript in it so I'm like later as
this gets more sophisticated optimize it
and do some sort of like builds process
or break it up into multiple profiles
but right now I just want to kind of get
the pieces going so I am going to you
I'm also going to use es5 syntax this is
the trajectory that I've been on soon in
future videos I will start adopting some
es6 syntax but ultimately maybe this
library will follow up and come back and
kind of I'm going to do a lot of things
maybe not in the most optimal or
efficient way but hopefully in the most
easy to understand and follow away so I
want to create a constructor function
called neural network okay and I should
also mention again while we're here that
I built this library already and when I
built it I based just about
everything out of this book called make
your own neural network by tariq Rashid
and so while I'm doing this now kind of
a bit more on the fly I'm sure
everything that's in my brain ultimately
came from here and probably some other
sources too okay so what do I want to do
the core thing that I want to do is I
want to create the net neural network
with a certain number of input nodes a
number hidden a number of output so I'm
going to add those as arguments here I'm
going to say number of input number of
hidden number of output I'm going to
create a neural network with three
arguments and then I'm going to say
input nodes I think I'm gonna be
long-winded about this equals number of
input and so I'm going to create three
hidden nodes is this argument and output
nodes is this argument is that and oh
yes it is okay so this is we've actually
written some code the idea being that
what I want to do is say things like var
brain and brain is a new neural network
that has three inputs with three hidden
and one output right this is the idea so
I need to figure out what shape and
Chevys in the word shape very
specifically does the data come in
that's how many input nodes I want what
shape is the output that I want am I
looking for a single output am i trying
to look for a range of outputs that's
how many outputs I want then how many
hidden neurons so I want well that's
kind of an open question well maybe I
want as many as I could possibly fit in
with the program running reasonably fast
but it sort of depends on the complexity
of the problem and we'll come back to
that later and I should also note that I
this is a simp oversimplification of how
neural network architectures can be this
is by definition a 3 layer Network and
this library is only going to allow for
a 3 layer Network an input
single hitting and sink than output but
that's something you might think about
for the future how would you write the
code to have multiple hidden layers
because a lot of neural network based
learning systems need multiple hidden
layers to be able to perform optimally
but for now I'm going to keep things
very simple okay I'm going to pause for
a second because I'm kind of thinking
I'm seeing some interesting questions on
and so there's an interesting discussion
going on is what's the relation a number
of input hitted and output so it's not
that the hidden is arbitrary but it can
be kind of any number but you know if
you're just going to have one it's not
going to just kind of work very well and
so you know one thing that you might do
is just kind of like well however many
inputs let's just make the hidden layer
the same number that could be like a
good starting point I would say okay so
the thing that we're going to need very
quickly and I need to refill my water
here is we're going to need the linear
algebra stuff yeah um so I'm trying to I
think I think I'll take this video a
little bit further
and then I have to stop and explain so
here's the thing let me talk this
through without this being part of the
official tutorials ultimately what I'm
going to do with each one of the exes
why do i why do I even bother saying
like let me talk let me just talk this
through and this will be part of the
video I don't know where I came over
here I don't know where I was
Oh linear algebra yeah I don't even want
to use that word but it's it's what
we're gonna do is actually quite it's
not so hard to figure out okay what is
the next step
written right we did write some code
thankfully roads of good now we've got
to stop again the next step is the
feed-forward process
oh the feed-forward process the way that
the feed-forward process works is that
we receive these inputs so much to to so
many pieces of this puzzle I'm excited
to get through it all though so let's
just say for example we're looking at
this hidden neuron do you remember from
the perceptron videos maybe didn't watch
those so let's talk about it the idea is
that we need to do something called a
weighted sum so let's pretend this is
the house prediction thing and this was
the number of bedrooms three this is the
number of bathrooms you know this is the
number of the square feet so each one of
these connections right the data is
going to flow in the data comes in here
the number three comes in here and then
look at this there's four outgoing
connections each one of those
connections has a weight to it now
ultimately the whole point of doing this
learning neural network based learning
system is we want to
week those weights we want to train the
brain train the neural network to have
optimal weights to get good results
results that makes sense and that
training processes I think that I'm
going to get to I don't have any videos
down the road from now but not too far
away these weights will typically just
start one way of thinking about them is
they're going to just have random values
between negative 1 and 1 and there's a
wide variety of techniques and
strategies for initializing random
weights or not just random
- a neural network but for right now a
good way for us to get started they're
all have random weights so even though
I'm looking at each one of these flowing
out slightly better way for me to look
at this with you is actually just look
at all the connections flowing in so
this particular hidden neuron has three
connections flowing in a three and the
input values are 3 2 and 1000 each one
of those has a weight so let's pretend
this is like 0.5 let's say this is like
a negative 0.5 and this particular
weight is 1 so I'm making using very
very simple numbers the idea is that
each hidden neuron does something called
a weighted sum so it takes the input
multiplied by the weight and adds that
to the other input multiplied by the
weight and adds that to the other input
multiplied by the weight so we could
actually do this 3 times 0.5 is 1.5 plus
2 times negative 0.5 is negative 1 plus
a thousand times 1 is plus a thousand so
this value now is a thousand point 5 now
we can see there's a huge flaw here
which is that the fact that square
footage is kind of a big number and
number of bedrooms number of bathrooms
our small numbers means this kind of way
of summing is going to produce some like
odd results this the square footage is
going to be weighted so heavily just by
the fact that it's bigger numbers so a
lot of time in working
the machine learning or neural network
based system we need to do some type of
cleaning or normalizing of the data and
we might do something where we you know
we sample this down so they you know we
actually do the number of bedrooms
between 0 &amp;amp; 5 as a value between 0 1 and
number of bathrooms always as a value
between 0 1 square footage this would
actually turn into 0.1 like because the
range between 0 and 10 thousand square
feet or something so we would do some
kind of normalization of these values
but this is again further down the road
when we start to apply the library in an
actual project once this weighted sum is
complete the result of that weighted sum
gets sent out through the outgoing
connections but it gets passed through
an activation function so I'm going to
come back to the activation function
this is something we did with a
perceptron and that's going to be a
separate video where we look at
different activation functions and how
they work right now I want to focus on
this weighted sum so I could keep going
here I could create some type of array
of I could create an object that's like
each one of these nodes or neurons is an
object then I could iterate over I could
have connection objects so there's a
bunch of different approaches I could
take but the classic and standard
approach is actually to look at storing
all of these weighted connections in
something called a matrix which is
really just like a spreadsheet a grid of
numbers looking at the inputs as an
array and doing some type of math that
basically takes take that array of
inputs multiply it by that matrix of
weights and generate the outputs of this
hidden layer so this is the so give me a
second here I'm going to erase I'm going
to I'm going to I'm going to make the
case for this with a simpler scenario
okay so so I'm gonna erase this
this can get edited out and let's see
here
you know a lot of times writing used to
do these videos I would do the videos at
the end of the day after I taught the
material with a classroom earlier in the
day and I would sort of figure out in my
head how to condense things I think
through the magic of editing things will
get condensed down but okay so I'm gonna
let's see let me just let's go back to
this simpler diagram
okay
okay okay I'm back I erased what I had I
drew I'm drawing a simpler diagram here
now so let's look at this diagram which
just has fewer connections can be easier
for us to unpack so we could think of
these inputs as x0 and x1 let's not even
worry about the output right now these
are the inputs this is the hidden layer
right hidden layer so let's think about
this and actually let me change these
numbers to X 1 and X 2 you know
sometimes I like to count from 0 seems
like to count from 1 I don't know why
but I feel like in this case let's let's
call it 1 &amp;amp; 2 so this is really like
hidden one hidden two so each one of
these connections right each one of
these weights you could say here this is
a weight that goes from 1 to 1 this is a
weight that goes from 1 to 2 this is a
weight that goes from 2 to 1 and this is
a weight right here that goes from 2 to
2 so notice how there are two inputs two
hidden neurons four weights in other
words the weights I'm going to draw I'm
going to kind of use start to use matrix
notation a little bit the weights can be
expressed like this 1 1 1 2 2 1 2 2 row
I want those to be row column holes let
me think about this for a second time
out time out time out this would take
maybe like numbering should actually be
row row yeah row row I did it right I
did it right never mind
okay okay so this is a way of expressing
the weights and a way of expressing the
inputs I could write it like this X 1 X
2 okay so
making the case that I have two inputs
and I have four weights and I could
write it out like a matrix of numbers a
two-by-two matrix and this is
essentially a 2 by 1 matrix whenever I'm
going to get more into matrices in the
next video or my in that video already I
don't even remember I don't know where I
am but typically when we talk about a
matrix a grid of numbers we reference it
rows by columns 2 by 2 2 by 1 okay so
let me just show you something
remember this we need a weighted sum
here this weighted sum is X 1 times
weight 1 1 plus X 2 times weight 2 1 ok
that's the weighted sum for this neuron
or node the weighted sum for this neuron
or node is X 1 times the weight from 1
to 2 and X 2 times the weight of 2 to 2
plus X 2 times the weight of 2 to 2 it
so happens I could take these two
results I could call this like h1 and
call this h2 and I could say let me
actually say I could I could basically
say this times this equals h1 h2 so this
is the actual math the way that we
described it look at both inputs coming
in multiplied by their weights and sons
look at both inputs coming in multiplied
by their weights and summed these are
the
it written out but it so just happens
that this exact math writing it like
this and producing this outcome is
exactly the math that is part of a field
of study called linear algebra linear
algebra involves manipulating vectors
and matrices of vector being a
one-dimensional list of values a matrix
being a two-dimensional list of values
the inputs are always one-dimensional
the outputs for always one-dimensional
the weights are always can always be
expressed as two-dimensional zitz every
input connected to every pin you can
think of it very much like pixels every
row and every column so this is where I
need to stop and what I want to do is do
a few videos that cover this notation
and math with a bit more detail writing
a little JavaScript simple JavaScript
matrix library and ultimately once we've
done that we can come back here and see
how if we have that library written we
can then use it to do the math between
the inputs and the hidden and the
hiddens to the output and ultimately
later just going to go backwards through
the network to tweak values and and
train it and that's we're also going to
use the same matrix math so this is why
we need or why we don't need because it
could kind of do it without it but while
it's useful to work with this idea of
linear algebra and I should note once
again that if we were doing this in
something like Python using a library
like something called numpy we would get
all this stuff for free and there are
JavaScript matrix libraries and might
but I'm going to kind of unpack some of
this and write a lot of the code from
scratch just to have a sense of how it's
working because why not okay I'll see
you in the next video where I look at
this a bit more in a book more detail
thanks very much okay uh how we do in
here what did I get wrong oh I'm wrong
looks like I got something wrong shoot X
1 times W 1 1 X 2 times W 2 1 X 1 times
this Plus this X 2 times this Plus this
I don't see it being wrong let me go
back and look at the chat I'm pretty
sure I got it right oh whoops sorry I
didn't change the camera I'm pretty sure
I got it right the way that I mean I'm
going to cover this in the next video
but the way that you do this is
essentially these two on sorry I lost my
train of thought I basically take I do
the dot product of like this vector in
this vector so that would be W 1 1 times
X 1 plus W 1 2 times X 2 W 1 times X 1 W
2 1 times X 2 and then I would do that
for this and this w 2 oh this is wrong
maybe we were we looked at it a second
goes right oh maybe I've just did I
write this in the wrong way and this
should have been two one up here ah
shoot yeah this should be shoot I miss
wrote I wrote this wrong I knew this
would happen
and then this should be one two
I have to go back we have to go back we
have to go back we have to go back
well we check the chat uh no did I have
it right the first time matrix is
correct okay hold on I I did it to
myself
hold on was it correct oh why
look at the chat here formulas wrong
it's a problem is you guys are behind me
so you guys are kept apart below does
not match the matrix book so here's the
thing this is correct the way that up
let me go in let me look at a let me
look at the way I mean I these
definitely don't match these match and
the way I thought of it writing in this
matches but I'm pretty sure that this
should actually be down here so let me
look at how it's the notation is used in
in this book yeah yeah yeah yeah yeah I
just shoot I messed up so I know if you
guys can see this but Tariq in this book
the author similar notation and so I
have to item trying to decide whether so
I just want to make this one - in this -
one whether I want to hate the fact that
it's going to be wrong throughout the
whole video and then I'm going to
correct it at the end but I think if I
go back I don't I don't want to like
redo this whole section I wish I could
watch this back right now actually I can
sort of by stopping because like where
where could where could I erase the
board from
yeah yeah I just mentioned that it's
wrong and I'll fix it in the next video
it wasn't so long in the video lost is
right no nothing that this um I just
ended up notating it in is what I was
actually asking myself this question I
decided that I was right and then I
realized I was wrong because I'm
thinking of this row column row column
really all row column row um this should
alright so just trying to side if I want
to like we record this tutorial with the
correct values there or just issue a
correction at the end of the video right
I need to do another straw poll I had a
sense of where where I was where cuz I
think I'll just issue a correction um oh
yeah okay good idea
so um topher and the chat is just
suggesting you know what I can do is
when we make the edited version of this
we can also I mean this is more work for
my tube but I know this is technically
possible we can maybe just put actual
annotation in the video like an overlay
so I'm just going to issue a correction
right now okay so hopefully as you were
watching the video you saw a little
annotation this is actually incorrect I
mean everything about this math is
correct this matches this right the
weighted sum is x1 times weight 1 from 1
to 1 x2 times weight from 2 to 1 but
actually the notation that the way I
wrote this matrix as we go as I go into
the next video where I actually look at
how the matrix math works this really
should be written as 1 2 and this should
really be written as 2 1 the reason why
that is is this should be x1 times w1 1
x2 times w2 1 which is written right
here so that matrix math but I'm going
to go in more detail in the next video
we take this row and multiply it by this
column and this row and multiply it by
this column and you can see that's what
these two things are okay so thanks for
bearing with me I there's a lot of
little pieces but I am going to get back
into the code so in the next thing I'm
not very confident about the order I'm
doing all this in but it's just the way
that I'm going to choose to build it and
so in the neck again I'm saying this
again the next video I'm going to look
at the matrix math again and then write
a generic library that does that math
and then come back and put it back into
the neural network itself
okay so see you in the next video thanks
okay so I think I got it the correction
good put some thumbs up the notation on
the matrix is always because there's so
much going so much other going on I
can't tell what people are referring to
what time is it an hour and 40 minutes
formula is wrong not the matrix can we
agree that what I have here right now is
correct before I move on I want to make
sure there's nothing else that's wrong
here to me I feel I'm going to look at
the Tariq's book again
good job everything is good some people
say no I forgot
your notation is bad no it's correct all
right let me look here boy I'm getting a
lot of mixed signals here let me look
and see how Tariq notates it so I'm
going to look I'm looking at this input
1 times wait 1 1 plus input 2 times wait
to one input 1 times wait 1 2 plus input
2 times wait 2 - okay
and then the matrices are 1 1 2 1 1 2 2
2 1 2 so I now have just confirmed that
my notation matches exactly this
notation the one thing that I've done
that's kind of incorrect is swapping the
order of these I really should be saying
wait 1 times x1 plus 0.1 1 times x1 wait
2 1 times x2 I kind of wrote it out this
way but that's a minor detail because
it's equipment the math is equivalent
but maybe the standard would be to write
this multiplied by this so I'm feeling
based on the fact that I have now looked
at this particular book and see that
what I did matches I'm feeling more
confident about it
Oh somebody is say matrix notation is
different for Europe and America oh whoa
oh no don't tell me I got to use the
metric matrix system this is so
interesting is that really true let's
Google this matrix notation Europe
versus America
two dimensions are read by two by three
that's how I do it two rows and three
columns 1 1 1 2 1 3 ah so yeah so the
awkward thing here is so this is the
unfortunate awkward thing
these are mapped to this but you
wouldn't normally I think notate that's
why I wrote it the other way the first
time around you wouldn't normally notate
it that way because you would sort of do
in this notation you would say X by Y or
column by row but these aren't actual
these aren't actually the column and row
numbers they're the weight mapping so I
think a little bit off in the weeds here
I'm going to leave this as is and when I
do the generic linear algebra videos
I'll try to use this the more Stanton
won't be tied to the neural network
stuff I can kind of think about it in a
different way I'm gonna go read the chat
again one more time
yeah the T don't differ so far classic
rat someone is fooling with me on that
also could be possible that people are
troubling me because huh yeah it's the
transpose all right okay I'm seeing some
very interesting discussion but I am
going to move on and I guess I could add
a little addendum there and maybe I'll
just for the sake of argument I'm going
to just record that saying that in one
sentence to tack it on could be edited
in I guess somehow if necessary
let me one more thing I should point out
about now that I fixed this notation
that's a bit
awkward here is that there are different
styles for notating matrix you know and
again I'm going to use the convention of
rows by columns so this is a two-by-two
row column but you would notice here
that typically these would then be row
column row column so this would be 1 1 1
1 2 that's why I had it reversed before
the first place but because I'm taking
it from these weights these aren't
actually the row column numbers all my
head hurts already but it's all going to
work out it's all going to be fine just
bear with me in this sort of notation
snafu okay the important thing is that
this actually matches the way I want to
describe the weights and those weighted
sums and I will we're going to double
back and everything hopefully as I get
through more explanation stuff will
start to make more sense okay I don't
think that should be added today I don't
think yes that should not be added let's
just leave it as is people in the
comments will complain but I had
whatever let me keep going oh yes I know
about transpose egregious knees use
please use square brackets um okay oh my
god the chat is going crazy oh my god
good job all right all right all right
okay okay I'm on let me just say for the
sake of argument I'm sorry I'm gonna
move on
[Laughter]
this is now going to be erased
all right now now we come to the point
where I actually took some notes you
might be shocked to hear this okay do I
have the stamina and energy to keep
going uh hold on Jed I was writing
something in the chat I can't you guys
are right the hidden nodes are the rows
and the input nodes are the columns
exactly everyone knows how to troll me
now I'm going to keep going oh the fact
that I wasn't using square brackets
don't you or I'll use square brackets
now so I should use I should use square
brackets okay hello Here I am who so I'm
trying I'm moving along here through
this journey of trying to program this
neural network library again I might
suggest skip ahead find some videos
where I'm just using the library but I'm
doing this I'm exposing this process of
a person struggling to make sense of the
world but for this video I did actually
make some notes and I want to reference
actually uh there's a nice medium post
about kind of what linear algebra you
need to know for deep learning that I
will show you on my laptop in a second
and link to it in the video where I read
that post this morning it helped me kind
of gather my thoughts for this
particular set of video so what I've
done so far is I've established that we
need this idea of linear algebra in
order to perform some of the math in the
neural network library that I'm building
so what I want to do is take a break
let me start over
let me not start over that's fine it's
fine so what I want to do is take a
break from the neural network stuff
itself and look at the linear algebra
stuff in a vacuum and yes finally
actually hopefully write some code
because I want to talk through the math
and implement the math in code in a
generic way and then apply that to the
neural network whoo
we're gonna get through this everybody
okay so what are the core so I have I
have some drops wait time how so
necessary because I brought these up
here I found my old linear algebra
textbooks from 20 some plus 25 some
amount of years ago so I brought these
as props did I was reading them this
morning but here's the thing hi this is
not a course in linear algebra there's
actually some great linear algebra
videos on Khan Academy on probably
there's some other ones out there I will
link to additional resources in the
description of this video I want to do
is cover the aspects of linear algebra
that are necessary or relevant to the
neural network stuff and kind of leave
out the rest so I'm going to give that
an attempt and see how it goes and write
code along with it and you'll let me
know how that goes okay so here's the
thing there are two key concepts in
linear algebra there's the idea of a
vector and there's the idea of a matrix
now a vector is actually something that
I've spent a lot of time in previous
videos in this nature of code playlist
talking about the idea of a
two-dimensional vector an entity with
magnitude and direction in a
two-dimensional space we use this vector
for forces and velocity and all sorts of
physics simulation all sorts of stuff
but ultimately this vector is just an x
and a y that two-dimensional vector from
of course could be a z4
dimensional vector for all the computer
graphics and animation physics emulation
stuff I've done in previous videos we
could think though about it we can we
can consider a vector as just an
n-dimensional list of values and I could
make the notation like this and I could
say X 0 X 1 X 2 X 3 X 4 X 5 so this is a
five dimensional vector there you go so
this is the idea of a vector now one
thing I should note is that you will see
a variety of different kinds of notation
you might see them I still might see
things written like this X Y you might
see it written like this X Y different
textbooks different styles I'm going to
use this square bracket notation for the
algorithms and examples I'm going to
demonstrate in this video and in future
videos okay so that's the idea of a
vector now if you also recall we can do
math with vectors and there are a few
different kinds of operations there's
the idea of a scalar operation like
let's say I have the vector to come 2 3
and I multiply that by the number 2 I
could take this scalar value the single
value and multiply it by each component
of the vector and I would now have 4 6
there also are operations that are
referred to as element wise this is the
kind of operation that I did over and
over again if I had a velocity vector at
a position vector so if I had a position
vector that was something like you know
2 3 and then I had a velocity vector
that was you know negative 1 5 I could
add element wise add these together so
the first element add to the the first
elements get added together so 2 plus
negative 1 is 1 the second two elements
get added together three plus five is
eight so these are element wise
operations now in addition
to that there is also something
reference referred to as vector
multiplication and there's like a dot
product and the cross product there's
like the hog how do you say that hot
Naru well anyway there's so I don't so
I'm kind of reminding you of some things
and I have a bunch of videos on the dot
product the dot product I use in a
videos to look at the angle between two
vectors there's a path finding example
we really needed the dot product to
figure out how to get a moving agent to
follow a path and the way the dot
product works is we take two vectors and
get a single scalar value so you can see
these scalar operations a vector by a
times a single number we get a vector
these element-wise operations a vector
plus a vector we get a vector the dot
product and the reason why I'm going
through this is I'm going to use this
again once I get to matrix matrix is
where the new stuff is the dot product
if I have two three
I just use these same values negative 1
5 the way that we do this is we take the
first value we like time out for a
second I'm so used to looking at this in
without actual numbers we take X like
let me just look at the formula I like
oh I'm going off this I'm going off the
window so let me correct this you try to
oops so just take a break for a second
if I had a B and C D the dot product
would be a times D plus B times C is
that right don't see my mind here
is that right it's like been such a long
day and I'm doing so many things
I know I got it wrong hold on it's
wait I wrote this down a 100 no no no
it's the X's plus the Y's a times C plus
B times I over complicated this in my
head of course I'm such a sorry about
that I know I got like confused for a
second it's simpler than I think yeah I
don't know why I was thinking about how
I do it
like here's all my excuses row I had
that wrong but really I just gonna get
confused a lot okay cuz this is none of
this is fresh in my mind I'm like just
pulling this out of a old body of
knowledge I guess and it's usually
easier just look stuff up okay
okay let's so the way that the dot
product works is we actually take the if
these were x and y values we take the
x's and multiply them together and the
Y's multiply together and add them
together it's kind of like that weighted
sum thing that I was doing earlier in
the sort of neural network in the
perceptron stuff so I would take 2 times
negative 1 which is negative 2 plus 3
times 5 which is 15 and I would get 13
so that is the dot product so this is
linear algebra now if I wanted to
implement all this stuff in code
I could actually come back over here
oops
look don't see that I have the dot
product Wikipedia page up for anything
so let me actually let me go to where I
want to go I want to go to the github
com
I'm going to do is go to source math p5
vector and you know
oh my god what a just want to find the
dot product function of this dot X yeah
yeah sorry sir okay uh uh sorry for up
switch the camera Here I am okay look so
I could take the next step and I could
start to write code for all these
operations for vectors but I'm not going
to bother with that because ultimately
what I need for the neural network
library is the matrix stuff but i
starting with the vector stuff because
it's all going to translate it's all
good it's going to be analogous but i
should point out that this is all in if
you're in p5.js for example there's p5
dot vector j is the source for the p5 is
all on github and you can actually find
all of these operations here's the dot
product function you know if I look for
the add function here's you know adding
two vectors together so you can start to
actually go and unpack for these 2d and
3d vectors how that math works in the
source code but now what I want to do is
redo this but not for vectors but for
matrices so the idea here is what I want
to now do is I want to understand well
what if I'm storing numbers in a matrix
and why would I do that well there are
so many reasons pixels live in a matrix
but data in a spreadsheet is in a matrix
the weights of connections in a neural
networks can be in a neural network can
be stored into matrix so there are so
many scenarios in programming where the
numbers that we're working with are
stored in a matrix and we can think of
that like a two dimensional array that
we want to perform these kind of
mathematical operations very very often
so what is a matrix a mate
instead of a linear list of values is a
two-dimensional grid of values and I
could think of it like this a b c d e f
and this would be a 2 by 3 matrix
typically we refer to matrix by the
number of rows and the number of
colleagues two rows three columns so in
that sense we can redo all of these
mathematical operations with a matrix so
let's do these one at a time and then
also write the code actually build up
anybody have a sense of like how long
this particular video starting from the
linear algebra stuff has been anybody
note the time where I started trying to
decide like maybe do I want to keep
going into the code also in this video
or maybe I should just described
describe actually describe these and
maybe I should come back and do this one
in a separate video
yeah yeah let me see if anybody in the
chat told me about how long they think
we got six hours ah it's no no not the
whole livestream just since I started
writing linear algebra up here so not
all the other stuff I did one by two
okay week - here - correct everything
shouldn't be a one by two a vector is a
vector as a 1 by is a 2 by 1 typically
it's usually half this one off um 15
minutes around 30 minutes ok that's
reasonable I'm gonna keep going then
okay
okay I lost my train of thought so so
let's look at these kinds of
mathematical operations now with a
matrix so I could do a scaler this
should be an a scaler operation so let's
say I have the matrix 2 a 3 negative 4 9
and if I were to multiply that by the
number 2 a scaler operation will just
double all these values so this would
give me then the matrix 4 6 negative 8
18 okay so let's actually let's pause
for a second I'm not really going to
pause and let's before we get to these
other operations let's start to write
some code okay so what I want to do is
have a library that allows me to create
a matrix of values and then perform a
scalar operation let's go write the code
for that now I should point out that
what I'm doing the nature where I'm
doing is kind of ridiculous because
there is a math KS this is an extensive
math library that includes an entire
matrix implementation there is also GPU
rocks which is a GPU accelerated
JavaScript library for doing matrix
operations and you know talk about GPU
stuff in a little while later but
there's also I think matrix J as there's
p5 as a matrix implementation but I am
going to write my own just to kind of
understand how it works and then later
as part of this library probably wanna
swap it out to have something more
efficient that's going to actually you
know opt to do these matrix operations
optimally but so let's create a new file
I'm going to call it matrix Jas and I'm
going to write a constructor function
and I'm going to call that matrix and
the constructor should get a not a
certain amount of rows and
and I should say this dot rows equals
rows and so long since I typed this dot
feels good
this dot calls equals columns okay so
the idea being that I want to be able to
say var M is a new matrix three by two
something like that right that's the
idea here
I want to be able to just generate a
matrix okay so for example I can do this
just here in the console now
oh let's actually go to index.html and
add in the neural network library and
the matrix library now and I should be
able to say var M equals a new matrix 3
comma 2 and I can see there we go I have
a matrix object with three rows and two
columns okay now we got to come up with
a way of at least initializing the
values and this is this is 2 by 3 and I
said 3 by 2 but whatever so let's
initialize all the values as 0 so how do
I do that well ultimately I need to have
a variable and maybe I'll just actually
call it matrix you call it values I
don't know what to call I'm going to
call it matrix equals an array now there
are all sorts of sophisticated
JavaScript ways you don't only ever
going to put floating-point numbers in
these I can have fixed size to allocate
the memory it's an optimal way but I'm
just going to live in the breeze code
this in the most easiest loosest
friendliest way and then we're going to
come back and optimize to use some more
efficient and optimal data structures
later so what do I want to do I first
want to have a certain amount of columns
time out for a second
I want to see how did I do this I'm just
curious in the library that I made here
I just want to look at my implementation
no I did rose yeah because I did it Rose
so interesting because we typically this
is that back to that is rose first or
columns first I like the bane of my
existence I got to just go back to like
generative art coding challenges I is
row we are triggered yeah no kidding
don't worry I'm now correcting that okay
so what I first want to do again the
traditional way to think about a matrix
is rows by columns so I'm going to start
with a loop through the number of rows
and I'm going to say every single row is
also an array and then I'm going to loop
through all of the columns and I have a
J here an I here by accident and say
then every single row column location is
a value and let's just initialize them
all at 0 whoops so this is me now making
a matrix of values everything with 0 so
let's go back to the browser
oops we might do a little I don't point
there because I want it to be on this
page let's go back to the browser
and let's refresh the page and create
that matrix again and I should now see
matrix has three rows and two columns
and then it has an array each one of
these rows
has two values zero zero zero zero zero
zero so this is now we can see the data
is actually stored in there so I've got
the beginnings of a matrix library
nothing about this is optimal or
efficient but I have a librarian object
that stores the number of rows in the
number of columns and creates a
two-dimensional array filled with zeros
ok so now what I'm going to do so we
kind of now we have the ability of a
library to create this matrix the next
thing that I want to do is add a
function that performs a scalar
operation so for example let's add a
function that's called multiply which is
the warning of this is a little bit
tricky because ultimately vector matrix
multiplication can mean a lot of
different things but just for right now
I'm going to write a function matrix dot
prototype that's part of the matrix
object all matrix objects I'm going to
call it I guess I could call it scale
let's just call it scale for right now
equals a function that's going to
receive a single value N and what do I
want to do I want to I'm going to do
this a lot loop through every single row
loop through every single column and say
this dot matrix i j x equals that value
let's call i'm going to call this
multiply and then I'm going to add
quickly add another one for another
scalar operation called add and I'm
going to say plus equals so again this
is this I have written two functions
these are scalar functions I just want
to take a single value and multiply
every a value the matrix by that value
or I want to take a single value and add
it to every single value in the matrix
that's what these two functions can do
so let's now come back here once again
up I've got a syntax error I guess I
have an extra
close curly bracket so I'm going to
create that three by two matrix again
I'm going to say add five now let's look
at it and I should see the values in it
should be all fives right now again
we're not really seeing the nuance of
this because there's not different
values but it started to zeros and then
I added fives to it and now I could say
M multiplied negative three
oops oh I call it multiplied and if I
look at em again now and I start to look
at those values we can see all the
values are negative fifteen so what do I
have so far I have a simple matrix
implementation that allows me to
initialize a grid of numbers by rows and
columns and perform scalar operations I
can multiply or I can add so I'm going
to pause here and in the next video I'm
going to do element wise operations and
then we're going to start to look at
other vector multiplication which is
really no longer the dot product but
where I'll talk about sorry matrix
multiplication so I'm going to kind of
break these out into separate videos and
I'm going to show you some interesting
things about building a JavaScript
library where I can actually determine
what's coming in I could reuse the
multiply an add function to determine am
i adding a scalar on my adding a whole
other matrix so I'm going to get to that
in the next video okay thanks whoo I'm
running out of steam here
oh boy this is how I feel right now huh
where am i time wise Oh
- ours in 15 minutes toxic desire ass
I'm sorry how long are we going to be
here I wanted to at least get to the end
of this but can I pull yeah I'm but is
it really worth the stress rebuilding
existing libraries from scratch I don't
know I feel like people are interested
in learning this stuff and seeing the
process of making it but it's a good
question I am more generally of the
sufferer from the what I do video
tutorials that I have kind of the
theoretical infinite time and so I just
like well I might as well fill in as
many details as I can whereas if I were
doing teaching a course and it just
meets like a couple hours each week and
I want to get to applications I would
kind of talk through the stuff in more
generalities and show the library and
that kind of thing so but but
fortunately a lot of people in the chat
are enjoying this so much coffee shot
coffee shot for me yeah okay well it's
not just a matter of me running out of
steam I have a end-of-year school picnic
to attend I have no idea to raise
anybody you know if it's raining outside
in New York City right now I'm at picnic
might not be actual actually look at my
let's see I can try to look at the I
mean that basically like a room with no
windows I could try to look at the
weather on my phone it doesn't say that
it's raining right now just as a 50%
chance so I think that picnic is on yeah
this is going to be a series I wanted to
I feel like I wanted to make it to a
good end point today which was all the
way through element wise and matrix
multiplication let me at least let but i
but i but i don't know if that's
realistic
wait wait you can use table array to
visualize in console this is a really
good tip so are you saying if I do table
M matrix how do I do that I guess I
don't know so I would if anybody has a
tip for me there okay oh I forgot about
the what does it call that had a Monde
or Patamon had a mard why is it called
that
sure product Oh French Mac
mathematicians jacques hadamard or
German mathematician Esai sure okay
these are really easy to do
okay a console table thank you console
table Oh tonight
oh look at that oh my god my whole life
has changed
Wow my whole life has just changed in
this moment I did not know you could do
that that is amazing
I don't know huh
I feel so happy that's like the greatest
thing to happen to be in a long time I'm
so tired it takes a lot of energy to do
these you know it's something also doing
this stuff like Friday afternoon after a
long busy week okay let me try to get
let me try to get a little bit further
along I'm gonna actually open this video
with that who suggested that first I
want to like thank the person I don't
know who it was yet karma points ah okay
okay let's keep going
Julito was it Julito okay I think it was
jelly toe hopefully I got that right hi
this yeah you don't know what you're
about to watch this is ostensibly just
like a random video in the middle of a
very long series of building and neural
network and I'm kind of now doing
matrices and I already started in this
is really just a video about doing
element wise operations with a matrix
and adding that to the matrix little
matrix library that I'm building but
guess what opening of this video is
something really exciting that I just
learned that I never knew Thank You
Julito from the YouTube chat for
pointing this out but what let let me
set the stage of where I am we're
building this matrix library the idea is
to be able to store numbers in a grid
and perform different mathematical
operations with them and we're going to
ultimately use this library
to do weighted sums in a neural network
and right now I'm about to add an
element wise operation but I just did
the basics of creating the matrix and
the basics of creating the matrix and
multiplying or adding a value to it okay
so now let's review I could say var M is
a new matrix and it's 3 by 2 and then I
previously was looking at it like this
and kind of going like this and trying
to like look at the values in it but I
learned that I can say console dot table
and then pass in an array look at this
console table pass in an array
my whole life has changed in an instant
realizing that now I can have this nice
little tabular view and so I can just
say uh multiply adieu add five and then
I can look at it again and I can see
that there's fives in there and I could
try to do other stuff and there's so
many things I'm going to need to do to
like check if it's working this is going
to make it so much better I had to fake
my reaction right now because I when I
really the first learned and I was
genuinely else I'm still genuinely
excited about it okay but for everybody
watching live had to watch me get
excited about it twice apologies for
that okay so you watching this video
right now let's add the next piece so
what's interesting here is one of the
things I wanted to do right it's just
saying let me for example add this I
multiply that add the number two to each
one of these values but what if I had
another matrix you know three one four
negative three and what if I wanted to
add this matrix to this matrix element
wise what element wise means is if I
have two matrices a b c d and i have e f
g h i get a resulting matrix that has a
plus e b plus f c+ g d plus h i just
take these two values and add them
together at these two values add them
together these two values added together
these two values and the other now this
will only work the way that I've
described it to you if these matrix
matrices have the same dimensions the
same number of rows in the same number
of columns now there is there something
in Python the numpy library which is the
core you know matrix math library and
Python has I forgot what it's called
what's that thing called were like time
out for a second I'm going to edit this
video right here come back with the
answer this what is that what's that
thing in Python
what's that thing in Python where it it
like can can actually do element-wise
with slightly different dimensions where
was I reading this it was actually on
the that blog post deep learning linear
algebra I really should be thanking this
blog post so this is I got to remember
to linear algebra cheat sheet for deep
learning by Brendan Fortuner thank you
so much this has really helped me
somewhere down towards the bottom here
am I losing my mind here broadcasting I
don't know are relaxed via a mechanism
called broadcasting yeah yeah yeah okay
thank you okay where was I back here
okay I'm back it's called broadcasting
in numpy so but we're going to live in a
simpler world where we for this we have
to have the dimensions match exactly so
what I want to do now is I want to keep
those multiply and add functions I want
them to be the same function but I want
those functions to be able to receive a
single number and add that single number
to all of the values or receive another
matrix and add all those that add the
values of of add those knives
element-wise so let's go back in adness
now there's some things that I need to
do for example I first why don't I at
least write a function called randomize
and what this function will do and
you're going to see this and everything
is just give each value a random value
so I am going to this I'm going to do
something rather silly right now we're
just say math.floor math.random times 10
so I'm not using the p5.js random and
floor functions writing this library
because I want this library to be able
to be used outside of the p5.js library
so I have to actually
use the native JavaScript random and
floor functions so I should be able to
now whoops syntax error line 16 oh this
should say equals function I should be
able to say here's a new matrix m dot
randomized and then let's look at its
values and you can see there we go one
one eight three eight one four those are
random values so now if I were to say m
dot multiplied by two and look at it
again we can see there we go 216 616 to
eight great so now at least we can
experiment and use different values now
here's the thing look at this function
matrix prototype ad equals function n
the argument coming in is n a single
value but what if n isn't a single value
what if it was actually a matrix
actually what I can do here is say if n
is an instance of matrix let's see is
that right instance of what does that
mean I'm trying to determine what the
type of n is so I can look at that here
write n an instance of matrix true M
instance of what's another JavaScript
object array false right so it's and if
what I'm basically saying is here the
add function receives an argument that
argument might be a matrix it might be
something else if it is a matrix what I
want to do is add all the values element
wise otherwise now I should probably
check like is it actually just a single
number but I'm kind of going to assume
here that there's only two possible ways
any reasonable purposes would call this
function either with a matrix or a
single number so if it's a matrix add
the values element wise every IJ should
get added to the corresponding IJ
otherwise
otherwise just add the single value to
every single value so let's now see if
this element-wise works it gives myself
some more space here so I'm going to
make a matrix that is I'm going to call
it m1 and I'm going to say m2 is also a
three by two matrix I'm going to
randomize m1 I'm going to randomize m2
then I'm going to say console I'm going
to look at them both table m1 oh whoops
sorry let me clear this console table m1
dot the actual array in there console
table m2 so we can see here these are my
two matrices six three seven two zero
seven zero four three one seven three
let's double the values in m2 just to
see that that works or let's add to the
value sorry what I did this with ad
right so I'm going to say m2 dot add one
let's add one to every value at n 2 and
let me I'm gonna make this font little
smaller hopefully you can still see it
let's look at m1 and m2 so we can see
yep every value of M 2 increased by 1
now if I add m1 to m2 I should get a
matrix that has 7 8 right 6 + 1 3 + 5 7
+ 4 2 + 2 let's say m1 dot add M - let's
do that
oh ah hmm cannot read property 0 of
undefined what did I get wrong matrix
say s 29 what's wrong here and oh you
know what I forgot probably a lot of you
in the chat notice this or if you watch
this you know is this the matrix object
has inside of itself a variable that
actually stores the values called matrix
and maybe I should call that something
else I'm not so sure about this this has
to be n dot matrix right if this is an
instance of the matrix object I want to
add this matrix values to the n matrix
values so unfortunately I'm going to
have to redo all this I have one matrix
I have two matrices now I'm going to add
one to the second one and then I'm going
to add m2 to m1 Oh didn't get an error
now let's look
oh wait I didn't randomize that and they
won't have the same values it's going to
be zero lilies okay give me a second
here
Oh No m CH is gonna have one in it so
let's uh let's just let's randomize em
one let's randomize em - let's add one
to em - Wow takes a long time just to
like get back to my test sure I just
write this code into like a code example
you'd be much nicer that way I'll do
that in the next video now let me look
at all of them console table m 1 matrix
console table and 2 dot matrix ok 1 plus
5 is 6 6 plus 5 is 11 so let's see what
we get
mm1 add em to okay
console table m1 I don't know no dot
matrix I think that's right if I scroll
back up I cleared it I can't scroll back
up someone will have to confirm the math
but I think we have successfully now
written a function into our library that
can do either scalar operation or an
element operation element-wise operation
and it's the same function and if I go
back to the library I could do this same
thing with multiply however I'm going to
leave that I'm going to just do that on
my own time I'm gonna leave that as an
exercise for you so if you're following
along and building this library with me
now go and write the same code to make
multiply work both scalar and element
wise and we're yes there is install so
to speak the thing that's the most
important thing that I haven't gotten to
is actual matrix multiplication that
isn't element wise and this by the way
this element wise matrix multiplication
is referred to is commonly known as the
hard
meru no no that's that's on Twitter
heart through on Twitter does amazing
work but what's that product had
Hadamard product let's go to the
Wikipedia page so that's what this is
called Hadamard also it's the sure
product that's the element wise
multiplication but matrix multiplication
itself is actually going to work in a
completely different way and just be
going to become the fundamental piece of
how we look at inputs and weights
between layers in a neural network and
multiply and add all those things
together
like that again it's going to be the
fundamental piece of how we look at
inputs and weights and how we multiply
those things that add them all together
in a neural network so so this is where
we're building up to so in the next
video
I am going to look at matrix
multiplication the sort of core piece
and we're going to put that into our
library there's some other things we got
to look at transposing a matrix is
something we'll need and a few other
things too and then we'll be back into
the neural network it's starting to put
those pieces together
oof there's a lot of a lot of elements
to this a lot of videos but thanks for
staying with me in this journey process
thing hopefully I'm doing ok see you
soon oh ok uh Hadamard thank you forgot
your randomize ok um boy everybody is
talking about Julito in the chat is that
there's an actual person named Julito or
did I make that up I'm in the wrong
camera
alright everybody I'm very sorry that
this is as far as I got today
um I don't even remember where I started
I got to look at my phone I apologize
for doing that middle of a live stream
but I got to get to this picnic oh um
see okay hold on offense of text
messages here
hold up lay this dots on as always I
always forget the diss stop it stop it
stop just stop
I'm eating this stop this stop
underneath this this stop this stop this
done this
this stock this stock this stock and
they're using this stock to stop this
this stock is stock is done and using
this knots are like actually Doug Lizzie
does stop it stop it stop it stop I
don't to break okay I'm gonna make a
stock I'm gonna make a prediction I
remember distinctly when I looked at my
live dashboard a while ago at the
beginning there were 747 people watching
because I remember 747 like but it's
like the airplane so gone off the deep
end here it should never never land of
matrices and linear algebra and all this
stuff I've left the core I think the
core audience of this YouTube channel
behind and I get a guess that there are
300 people watching right now
oh look 685 that's kind of amazing
okay go back and we check the slack
channel all right so everybody I'm sorry
that this is where I have to wrap up I
this has been a 2 hour and 36 minute
livestream let me mention to you so
what's what's coming what's coming is
next Friday I will be back to continue
this so I'm just going to keep going I'm
going to do the matrix multiplication I
think things will pick up speed at some
point that I'm going to put that matrix
multiplication into the neural network
code I've got to do the training and the
back
application and all this stuff la veille
but that's going to come next week next
week I will be at the O'Reilly AI
conference here in New York so if
anybody happens to be watching is going
to this conference send me a tweet at
shipment so I can say hell I say hell I
which is coding train for hello say
hello and give you a sticker if you so
that's that I will take a short few
minutes to answer a few questions is so
hot in here and I'll be back next Friday
the Julito stuff is really kind of
unbelievable I wish I could follow the
chow if someone could like summarize
that for me like what what happened what
went wrong and Julito by google Julito
what do I get I really should not that
is a thing okay I don't want to go any
further I don't want to go any further
with this what I'm doing okay
um oh I'm not giving a talk at the
conference
I'm just VIP I'm just trying to absorb
and go to some sessions and going to
some tutorials and stuff so okay so let
me see um oh boy there's no way I'm
going to be a look at that right s
multiply and s add e multiply that would
be right okay so Julito is a real
YouTube user I would thought that maybe
I was just like told a fake name and
there was some kind of joke so it isn't
so so I'm fine you guys have your own
thing I have my thing which was actually
thanking a real person whose YouTube
name is Jill Ito got it okay okay um
lets me see if um I'm going to put on
this goodbye it's on
and I will take a few questions I'm
looking at the slack chat that's kind of
if you are want to support what I'm
doing patreon.com slash coding train is
a crowdfunding thing that I'm using for
making YouTube content and you'll get a
conditional slack channel what did I go
to school for learning I studied as an
undergraduate mathematics and philosophy
I spent almost all my time though doing
musical theatre not well terribly mind
you and then many years later I ended up
at a program called ITP which is where I
teach right now and I learned about
creative coding and lots of other
interactive media stuff there at this
program
can I make a first-person 3d style
first-person game that's not something
that could close on my radar right now
they'll be interesting to kind of look
at systems like that but I do I would
like to do more 3d stuff and
particularly get more guests for 3d
stuff where in my front I grew up in
Baltimore Maryland you plan on making
searching sorting algorithm
visualizations interesting uh yeah that
would be a great topic boy that would be
a really nice topic to do and I could
actually do those in like quick short
videos
where's my coding train hat
it's me your friendly neighborhood train
conductor
either microphone still be
all aboard they really shouldn't have
the math digest in the background for
this over to choose using my mind
can I bounce this on my hat on my chin
oh good so um yeah
yes my engineer costume all right uh yes
the renaming the functions I did see
that I think I think I don't think
there's any questions left cuz people
are just talking about cholita so I
think I'm gonna be saying goodbye I see
some people are typing in the a what
life yeah having subtraction as its own
function hold on so okay so okay there's
been a discussion actually in the in the
slack channel in the slack live chat
about what operations I have left to do
so I need to do the element wise for
multiply to add that in I need to
rethink the naming because what should I
actually call the matrix multiplication
function and you know versus
element-wise function so I think they
need about name it need to do the matrix
multiplication I need to do the
transpose we could actually you can
actually see all this stuff is in the
because I did this a month ago or so
already so I can actually just look at
that here and I'm kind of doing it from
scratch again now so transpose copy add
multiply what did I do
I guess I called it a map is something
we're going to need but I'll add that
dot is what I called it is that
technically a good thing to call it I'm
not so sure so that's what I called it
okay so that's yeah so that's pretty
much what I have left to do and so one
person in the chat asked about well I
could have two different functions like
s add and E add like four scalar add or
element wise add but I like the I mean
so that would be a reasonable way but I
do kind of like this solution of reusing
the same function having the function
kind of auto detect what's coming in and
so the other question was added was
asked well should I have a subtract
function and you could make the argument
yes to have a subtract function but you
also just use add
the negative value and would have the
same result but I gonna have some
utility especially for the element wise
subtraction otherwise you have to like
multiple you know to first take a matrix
and multiply by negative one and then
add it that sort of thing
alright thank you everybody for tuning
in today thank you for bearing with me I
hope to get back to kind of just more
creative examples and different
generative algorithms and quick quick
games and that kind of stuff I'm or
guess so but I want to try to see if I
can get through this neural network
stuff and this may go for people who are
interested and your feedback and your
thoughts are highly appreciated and
encouraged uh
criticism and everything as well okay so
thank you guys I'm going to turn this
button off I will be back next Friday
and most likely the same sort of timing
or a little bit later probably in the 3
p.m. eastern time which is I guess like
7 or 8 p.m. Greenwich Mean Time okay so
see you all I don't have a break I don't
do a great job of having a fixed
schedule oh this is this computer is
about to die it's not plugged in this is
actually those of you want a little
inside baseball here this computer has
reaching green paper on it so that you
don't see it but you can see I'm kind of
like cut off by it if I walk over this
way alright um so um see you all next
Friday
unless something magical happens I have
time to do a layer but hopefully in
between July 3rd and July 14th I'm going
to have twice a week live stream so I'll
update you about those schedule times
and get through all this internal
network learning stuff ok thanks very
much and I will see you next Friday
goodbye</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>