<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>11.4: Introduction to Computer Vision - Processing Tutorial | Coder Coacher - Coaching Coders</title><meta content="11.4: Introduction to Computer Vision - Processing Tutorial - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Coding-Train/">The Coding Train</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>11.4: Introduction to Computer Vision - Processing Tutorial</b></h2><h5 class="post__date">2015-07-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/h8tk0hmWB44" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so this is the last video in this
section of videos about images and
pixels and what I want to talk about in
this video is computer vision creating
using using an image as something other
than a thing we draw on the screen or a
thing we look up colors from to draw
other things on the screen what does it
mean to try to have our program our
thing we're making it processing see the
world in some capacity maybe to
determine if there's a user present
maybe to determine if the user is
waiving his or her hand maybe to
determine what color clothes the user is
wearing there are lots of things we
might be able to figure out from a scene
if we have a camera looking at that
scene or an image that was taken from
somewhere okay so this is a huge topic
and somebody who actually knows what
they're talking about could probably
make a long series of videos going quite
in-depth about topics and examples in
computer vision what I'm going to do in
this short 10 to 20 minutes here is
simply kind of look at some of the
basics where some the key fundamental
pieces that we need to know about or
figure out in order to build our own
computer vision application and then
what are some pathways to doing more
stuff with that so let's let's let's
kind of like start with a basic kind of
classic scenario let's say we have a
scene there is a camera from our
computer pointed into a room and in that
room there is a very bright light and as
a this sort of weird looking light bulb
thing that I've drew here and maybe
there is a person like I can't draw it
all holding on to that light bulb and
they're moving it around could we have a
camera over here looking at this scene
track that light bulb how would we do
that well conceptually we might say aha
let's find the brightest pixel in this
image how could we find the brightest
pixel in this image well we might start
with this pixel and see that this pixel
is very dark it's as a color a
brightness value of you know zero and
then we look at the next one and see it
has a brightness value of zero and the
next one is break to tell you three and
the next web radius family of four and
then zero again and
we might get around be like oh look
there's a pixel over here with a
brightness value of 255 that's really
bright let's remember where this XY
location is and as we get to the end of
looking at all the pixels could which
one had the the highest brightest value
this is searching through the pixels to
find to try to see where the brightest
pixel is so let's look at it kind of
variation on this for a second over here
I have an example which I'm going to run
for you that's hopefully going to pull
up an image I have a camera right here
looking at me
and you can see there I am above over
here and I'm going to take this blue
marker and I'm going to click on it and
you can see oh I'm kind of drawing a dot
following this blue marker I'm tracking
the blue color in this image that's
coming from a camera how is this done
now you can see there's a lot of
problems there it wasn't so perfectly
accurate and this is not there's a lot
of issues here that I want to take a
minute to discuss too but let's just say
for the sake of argument that is the
be-all end-all of computer vision how do
we write a program that does that that
recognizes the color in an image and
continuously follows that color as it
moves over time very similar we talked
about here the difference is maybe we're
looking for the cult the pixel that's
the most blue not the pixel that's the
most bright so one key thing we need to
figure out here is how do we determine
if a color is similar to another color
so let's think about these two colors
here zero comma 100 comma 255 are G B
and now let's take another this is sub
color it's kind of bluish greenish now
let's take another color 250
you know 255 so how similar are these
colors well one thing we could say is
like ah the red values are 200 units
apart the green values are 50 units
apart and the blue values are 0 units
apart so I could kind of give it a
similarity score of 250 where 0 would be
the most similar right if all of these
values were equal and 255 times 3
would be the largest difference if all
of these if you know values were only 0
to 255 so we can see here like taking
the difference subtracting one color
from another and you'll notice I'm using
the absolute value meaning 200 minus 0
is 250 minus 100 is actually negative 50
but I don't care whether this one's
greater this one's greater I just want
to know how far apart are they so this
is kind of a way conceptually we can see
how different are these colors it turns
out that an accurate way that we can get
this all into one line of code let's say
I have these two colors as in variables
R 1 G 1 B 1 and R 2 G 2 B 2 I can say
float the difference between two colors
is the distance between those colors R 1
G 1 B 1 and R 2 G 2 B 2 this line of
code right here using Processing's
distance function will actually give me
a rating of value a numeric value that
indicates how similar these two colors
are how does that work well distance
probably make sense you if I have a
three-dimensional space which is where I
am right now
my hands are a certain distance apart
now they're getting closer and closer
and closer well what are there's that
there's three-dimensional space there's
like an x axis a y axis and a z axis and
things in this room that are closer to
each other have a lower distance well we
could think of these axes instead of
being XY and Z as being the red axis the
green axis the blue axis what if we
filled this 3-dimensional space with
every possible color colors that are
nearer to each other would be more
similar than colors that are further
apart from each other and this use of
euclidean distance the distance formula
even though conceptually we think of it
as something that has to do with
physical space or even two-dimensional
space in the case of two-dimensional
distance we can use that with color as
well now why am i spending all this time
talking about this just this distance
formula this is what we need to do if
we're trying to find the color that is
the most blue what if I look at this
pixel and find its distance from blue
then the next pixel and find its
distance from blue then the next pixel
and finds distance to blue one of those
pixels will hold the world record for
smallest distance to blue and if I keep
track of that record does this pixel
break the record no throw it away just
this pixel and break the record no throw
it away
does this pixel break the record yes it
does keep its XY now keep going and if I
ever find anything else that's greater
than that then keep those XY when I
after I finished looping through all the
pixels I'm going to find the XY location
of the pixel that is most blue so the
two things that we need are one we are
the things we already have is we know
how to look through all the pixels the
things that we don't have necessarily
from before is how to find the
similarity between two pixels this
distance function is a great way of
doing it and also how to keep track of
which pixel is the one I want to
remember later after I finished looping
through everything so let's go back and
look at this example again and I need to
run it so there's a few things I guess
I'll point out in the code but let's
just make this example run again I'm
going to hold up this blue marker I'm
gonna click on it you can see yeah you
know it's tracking it it's continually
finding this blue marker now a couple
things that are going to fail here let's
see if I want to track the green green
you know I'm clicking on it and you know
there's this whole background it's green
so tracking something green isn't going
to do very good what if I click on my
nose to try to track the color of my
nose you know the color of my nose
similar to my forehead is similar in my
hands so there's a lot of flaws in this
scenario of just looking for a single
pixel you know how much this is jumping
around
we could add easing or interpolation
that might help that there's a lot of
flaws in this and honestly if we really
want to track a color an object that has
a specific color you know in a you know
image we probably makes more sense to
look for an area of pixels that are very
similar we're just looking for a single
pixel so but this you know while this
might not be the most useful application
in a kind of real interactive scenario
this demonstrates a lot of the basic
principles of computer
so let's go let's look at a couple
things one is in the code here one thing
I want to point out is this is exactly
what I'm talking about
we have a current color from the video
and I need to get its red green and blue
values and then I have a color that I'm
tracking that's the color I'm searching
for so I want to know how what's the
distance between the current pixel I'm
looking at and the color that I'm
tracking so this here's the distance
function being used inside of this
nested pixel loop the other thing that
I'll point out is we're starting before
we go through the loop we keep track of
there's what's the world record
the world record some big number that
that's obviously the first pixel is
going to beat and then we need to keep
track of that X&amp;amp;Y point so at any moment
if we find a pixel with a distance
that's less than the world record then
the new world record is that pixel and
that X&amp;amp;Y we should save so this is that
second piece the first piece of
something new here so we need to figure
out how our two images our two colors
different or similar using the distance
function and another piece is how do we
while we're looping through how do we
keep track of which is our favorite
pixel essentially is this our new
favorite it is save it and we'll save it
again if we find so it doesn't actually
matter how what order we look through
the pixels we're going to hold on to
that quote-unquote best pixel all the
way through that loop okay so this is
giving you some of the basics again you
can see there's a lot of flaws here if I
were to give you an exercise I might add
try to add some easing so that even
let's look them so even if I'm oh this
is a black pen let's go back to the blue
so even if it's you we could probably
get this to be at least somewhat smooth
the other thing I should point out here
is there's no need to display the video
look at this whoa I'm magically
controlling the circle above me so so
one thing more they recognized here is
the camera is really acting as a sensor
there's nothing about it that we're
using for display purposes we're just
reading the image and getting some
analyzing for some piece of information
so just recently at the winter show here
at ITP students built a spray paint an
interactive paint application where you
would hold a spray can
the wall and inside of that spray can
was a very bright green LED and there
was a camera on the wall so the camera
was able to track where that spray can't
was simply by tracking a very bright LED
so there's a lot of cases where you
might want to track something find it
with simply with color I should point
out that another going to just jump to
this another scenario where you might
like to look at the difference between
pixels is for looking for motion so I'm
gonna stand here try to stand very very
still and you can see when I stand very
very still except for my mouth moving
there you're not seeing any black pixels
but if I move around a lot you're seeing
a lot of black pixels so one thing that
you can do is you can find motion by
saying I have one frame of video and I
have the next frame of video let me
compare each pixel a pixel that changes
is likely where there's motion right
because if my hand is never moving the
pixel color here is not changing but as
soon as I move my hand the pixel colors
are changing now notice that you know
just with subtle movements we're getting
it's in a way we're all we're finding
the edges of my hand because if you
think about it the pixel even as I move
my hand the pixel colors in the center
of my hand aren't really changing it's
only changing along the edge where this
white part where this width as part of
my skin meets the green part of this
green screen that you can't speak as you
see a computer screen so this is another
scenario on all these examples are in
the learning process and github
repository child connect this one is
example 16 point 13 so this is a little
bit about a computer vision here I guess
I'll just show you one more here there's
another example which we can look at
just how many pixels have changed per
frame so if very few pixels have changed
for frame you see this small dot in the
center and as I move around a lot a lot
of pixels are changing the dot is
getting bigger so this is a scenario
where we can use
maybe an exercise might be could you
find where the motion is so you could
create an application where as I'm
waving my hand I mean something is able
to follow the thing that is moving so
there's a lot of possibilities here in
how you use what the computer can see
can you find the edges we looked at edge
detection in image processing finding a
specific color finding the brightest
pixel finding the darkest pixel finding
pixels that are moving these are the
types of things you can do writing your
own code in processing however this is
not a new idea I didn't invent any of
this in fact I know very little about
this compared to a lot of people in this
world and in fact if you want to work on
a computer vision application it's quite
likely that am i recording yes and how
long 30 minutes were fine so it's quite
likely that what you want to end up
doing is using a library that has a lot
of computer vision functionality built
into it so one library that I would
recommend you look at is a I'm going to
have to just sort of Google search this
here really quickly github is open CV
for processing so this is a library by
Greg Bornstein open CV is an open source
computer vision library originally
developed by Intel now maintained by
open source collectives this is being
printed and you can see here that
there's a lot of functionality it can
find your face it can do all sorts of
image processing it can look for blobs
and contours so a lot of the stuff that
we might spend hours or weeks or days or
months trying to program from scratch
our features that are built into a
library and you can even see as I get
down here there's lots of kind of really
interesting features like like I don't
know recognizing a card for example okay
so or yeah recognizing different markers
and an image so anyway okay so well let
me show you one one thing that this is
kind of classically used for is for face
detection so let me run this one we
close these out and back to processing
and run this so one of the things that
open CV will do for you
as it will find faces in an image so you
can see here as soon as I turn to the
side by the way it does not it's not
recognizing my profile only if I'm
looking dead on so what OpenCV will do
for you is it will give you a rectangle
now this is quite different than face
recognition right it's this is just face
detection oh there's a face there it is
that's how big it is but you can imagine
some applications you might do here is
some how many people are there are
somebody looking straight versus looking
to the side there was a project just
here in the ITP winter show where two
people are standing in scene and their
faces are swapped so there's a lot of
creative possibilities here you know if
you use if you use Google hangout you
can see that you know you can add
there's all these features we've got a
hat or a mustache on somebody you could
do this but with the opencv library as
well so this is something that I might
encourage you to take a look look into
as a possibility and one thing that
OpenCV has also its blob detection so
finding areas of brightness or areas of
darkness which is very useful in a
tracking sense as well so the last piece
that I want to just kind of demo for you
here and I'm going to have to plug it in
is that there is a thing called the
Microsoft Kinect I'm afraid to pick this
up can you see this this is the
Microsoft Kinect this thing has a camera
in it and a regular RGB camera it has an
infrared camera and has an infrared
projector so what what this sensor is
going to do this camera this depth
sensor and let me see if I can open this
example up and oops hello this is what
this is what happened there we go okay
so you can see that this is showing us a
couple different things one is here's
another image of me in this room you can
see that I have a little TV over here
where I can watch myself this is all
very strange
and there's just a camera coming out of
this Kinect but then there's also this
image over here this image is a depth
map now it's very the way that the
screen captures work it's very hard to
see what's going on here but you can see
that my hand is a little bit brighter
and now it's
quite a bit darker and now and you can
see as I put it in here we can't see it
anymore so what the the Microsoft Kinect
and this is the old Kinect of 14 4 this
is the original model from a few years
ago 14 14 is the model number what it
does is it's able to not just say like
here's a pixel and here's its red green
and blue value what it says is here's a
pixel and here's how far it is from the
Kinect from the camera from the sensor
in millimeters so you can know what's
close what's far away and another way of
looking at this I think UPS oops so
sorry I had a technical malfunction so
what you can see here in this scenario
is that I'm drawing each pixel as a
point in three-dimensional space and
it's a little hard to see probably where
we are do based on this like orientation
I'm like looking in 12 different places
but you can see that this is essentially
the data visualized in three dimensions
so some really basic 3d scanning of
terms of a scene what I'm not using here
is there's a library called open and I
simple open night which is actually now
open and I was purchased by Apple okay
here's the thing I don't want to like
ramble for like the next 20 minutes
about all the different versions that
connects and which ones work with which
operating system in which library but
what you have right now at this very
moment there's the original Kinect that
came out a few years ago that you could
use there's a library for PC and
processing that you can use there's two
libraries for the Mac and processing one
which is open Kinect which is a library
that I built on top of some open-source
drivers for the Kinect and there's also
called something called simple open and
I which uses open and I which has since
been purchased by Apple and has been
shut down so while all of this works if
you're interested in the Kinect you
probably want to go and look for Kinect
version - that's the newer Kinect it's a
bit higher resolution a lot of the
skeleton tracking which I haven't really
mentioned yet is a bit more accurate I
think however there there aren't open
source drivers as easily available for
the new Kinect and so there is an
official Microsoft developers kit and
you can use that with processing however
it's only for Windows and at the moment
there are a lot of people here at ITP
in probably other places in the world
working on ways to pass the information
from the Kinect and a PC over the
network what you have to realize is the
Kinect itself is just sending this raw
data what is the distance for each pixel
from the Kinect what you can do with
that information is incredibly powerful
and if we looked at any demo of the
version to connect or the old Kinect you
would see it can recognize the form of
my body very quickly and track where my
arms are my hand is my head is my knees
are all sorts of stuff you can do with
that we don't have time or I don't
really get into all of that here and
perhaps someday there'll be more videos
or more examples that I can do and help
prepare in that direction however let's
just I just want to jump back for a
second and just show you what you can at
least do something that the Kinect makes
possible with just even just the raw
depth information so one thing I want to
do is do this okay so one thing you can
see here is this is where I'm standing
as I walk closer to the Kinect I start
to turn red as I walk further away I
stopped being red as I put my hand here
my hand is red so what with depth one
thing that you could do rather easily is
say where are the where is the thing
that's closest to the camera and in the
sense of a hand pointing straight out
that's pretty easy to track no notice I
put my other hand out now that dot is in
between them take this one away switch
so this isn't doing any sophisticated
hand tracking I could like put my head
here it's just looking for like a blob
of stuff that's close to the camera I
could take this marker and point it out
like this and you can see it's sort of
tracking that I think this marker is
actual a little bit reflective so
there's a lot more to this and how it
works and infrared light and the depth
versus the skeleton and blah blah blah
and I'm just kind of doing a terrible
job here but what I what hopefully
you've got a sense in this video if
you're still watching is that that for
loop right of looking through all the
pixels you need that you need that for
for the image processing stuff you're
doing and be that for some computers and
stuff and in fact you need it for this
because instead of looking for the color
that's the most closest to whatever I'm
looking for the pixel that's the closest
to the to the Kinect itself so that for
loop is pretty crew
and there's a lot of things you can do
with computer vision however there are
also its you could do from scratch on
your own but they're also a tremendous
set of libraries and resources and other
devices like a depth sensor that you
might consider as well very last thing
is I'll I'll try to include a link also
there are third-party applications open
source ones like computer community
computer the community core vision open
tsps these are applications that you can
run behind the scenes on your computer
and have them pass messages about what
they're tracking to processing and that
that's also a way that you might think
about in developing computer vision
application involves computer vision
okay so some day I will kind of revisit
some of the stuff in a hopefully more
organized or useful way but for now I'm
just going to say goodbye and I have no
idea this is probably way too long okay
but I didn't manage to get the connect
work in this video just got it
interested okay see you later</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>