<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>6.1: Intro to Session 6: Markov Chains - Programming with Text | Coder Coacher - Coaching Coders</title><meta content="6.1: Intro to Session 6: Markov Chains - Programming with Text - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Coding-Train/">The Coding Train</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>6.1: Intro to Session 6: Markov Chains - Programming with Text</b></h2><h5 class="post__date">2016-10-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/v4kL0OHuxXs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello welcome to session six or week six
I don't know you doing this every day
every week every month this could be
year six for you if you wanted it to be
but this is programming from A to Z it's
a set of tutorials a kind of online
course you could follow all about
programming and algorithms with text
text language text words letters all
that sort of stuff so today in this
week's session the focus will be about
the focus that I want to have is Markov
chains well what's a Markov chain what
smart what's the deal what's going on so
in the last session I focused on
something the sort of topic of text
analysis so in last week the idea was
really exclusively about reading text in
and analyze it analyzing it counting how
many times different words appear trying
to think about how you might do
sentiment analysis what happens when a
computer program reads in text I want to
turn now towards what happens when a
computer program writes its own text and
there of course are many many ways that
you could do this in next week's session
I'm gonna look at something called a
context-free grammar in other sessions I
hope to look at some machine learning
techniques for generating text as well
as other just kind of creative ideas for
ways to mix and match and have a program
put together text as if it's writing it
now one thing I should say about this
week's topic of Markov chains is it by
definition requires a source text from
which to generate text so this is
something you'll see in a lot of these
algorithms for generating text they also
include a reading text component so now
a Markov chain is not something
exclusive to the idea of text and in
fact a Markov chain really just
describes a sequence or a chain of
states like I am happy I am sad I am
running and I'm like typically on any
given day be sad and then I start
running and then I feel happy and that's
kind of my sequence so what with a
Markov chain looking at how certain
states are sequence and the probability
of a given state following another state
we can use we can evaluate sort of
existing data right I can look at
like you know what's the weather like
today what's the weather like tomorrow
it's a leather-like the next day over a
year and try to use that to either
predict the new weather or to recreate a
simulation of weather based on the
sequence of states so this is something
I'll look at more in more detail in the
next video but there's a piece of that
which is if I want to apply this idea of
a Markov chain to text what I want is
for the characters are words of a piece
of text to be States for example the
state is I the next state is M the next
state is feeling the next is like
dancing so those are states and the you
know whenever I say m i usually say
feeling and then whenever you say
feeling I usually say like you know but
I might say the other day I I'm feeling
like eating some kale salad or something
like that too so this is this is like
quite possibly the worst explanation of
our cupcakes ever the Internet but you
skip to the next video where I'm sure it
will make a lot of sense but a piece of
evaluating this fiscal properties of
characters and words how they appear
next to each other is this idea of an
Engram so this will also be a piece of
the example that I built today of how do
we look at a body of text and look at
this idea of engrams now Google has this
massive treasure trove repository of
text corpuses of text from you know 1800
all the way up until present day and you
can search for the frequency of certain
engrams so these are what it might be
called by grams meaning to computer
science creative code creative writing
we could think of other ones like I am
and I could search for any of these
diagrams and their frequency in text and
we can see that computer you can see
first of all computer science started to
appear more and more frequently and
starting the 1960s you can see a sort of
more consistent amount of i.m you can
see creative writing creative code down
here so this is a way of looking at how
and we can look at trigrams engrams with
an order write an order of for the order
referring to the number and you can do
creative projects with
so here's a great project by Chris
Harrison called web trigrams visualizing
Google's trigram data and we can see
here if we just look at this PDF and I'm
going to zoom into it so you can see you
can see here that that in this project
the Chris is visualizing all the words
that tend to follow he and then from
there all the words that tend to follow
that so another I think this is these
are some nice examples to look at and
you can kind of hear imagine now I have
a I am not I was not I do not I can a so
you can sort of see the frequencies of
these sequences and if you can evaluate
those frequencies you can use those
frequencies as probabilities from which
to generate new text so here's an
example of a project made by Alison
parish the interactive
telecommunications program is a program
at ITP it's called is a program at IUP
it is it's where I teach and we have
courses every spring and what Allison
did is read all of the courses into a
program look at all the statistical
properties of all the characters and
words and how they appear next to each
other and use that to generate new new
courses so I'm gonna let's let's find
one that that looks good
the Anthropology is a virtual design
workshop MIDI and cinematic objects this
course constraints of weekly sessions
beyond exercises and inspire the
possible so this sounds great I think
I'll take that course this is another
example of a project called King James
programming and these are post generated
by a Markov chain that has mixed several
different input texts the King James
Bible structure and interpretation of
computer programs and some of Eric s
Raymond writings run by Michael Walker
so you can see here these are different
things that are generated from that
exercise 3.67 addresses why we want a
local variable rather than a simple map
as in the days of Herod the king okay so
there's a lot of possibilities for how
you might use Markov chains to for a
creative output and on the one hand this
is nothing new this has been done and
done and done and done again this idea
of reading in a source text evaluate the
probabilities on a character or word
based level I'll talk about that as I
implement the code in the next video and
then text generating out of that you
could make a Twitter bot that generates
text based on a Markov chain so I I
think there's value and hopefully you
might enjoy exploring the idea and you
might even just take the examples that I
provide and find your own source text in
but I think for you to think about what
is the reason why you might do this
where might it fit into an existing
project hero walkie-talkie and and come
up with some creative possibilities so
in the next video I'm going to focus on
the code how to write the code to
implement a Markov generator I'm gonna
go through it entirely from scratch and
then I'm gonna show you a few additional
examples and then come back with some
exercise ideas for things that you might
want to try doing yourself after
watching these videos and then I hope
you'll share them with me on Twitter at
Schiffman or you can subscribe to the
patreon too to post the post your work
in slack as well okay so I will see you
guys in the next video</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>