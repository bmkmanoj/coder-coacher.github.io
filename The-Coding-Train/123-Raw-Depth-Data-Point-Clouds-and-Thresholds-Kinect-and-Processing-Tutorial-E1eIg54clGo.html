<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>12.3: Raw Depth Data - Point Clouds and Thresholds - Kinect and Processing Tutorial | Coder Coacher - Coaching Coders</title><meta content="12.3: Raw Depth Data - Point Clouds and Thresholds - Kinect and Processing Tutorial - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Coding-Train/">The Coding Train</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>12.3: Raw Depth Data - Point Clouds and Thresholds - Kinect and Processing Tutorial</b></h2><h5 class="post__date">2015-11-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/E1eIg54clGo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello in this video I plan and hope and
I'm excited to look at the raw depth
data meaning not the depth image not the
depth values converted to a grayscale
image but actually the raw depth data
that's coming out of the Kinect itself
so again with the version to connect
you're getting numbers between 0 and
4500 with the version 1 Kinect you're
getting numbers between 0 and 2048 and
to demonstrate this what I have over
here is a simple processing sketch
that's drawing a whole lot of dots on a
plane in 3-dimensional space and that
plane is rotating rather slowly so what
I want to do is and this is what's known
as a point cloud I want to take every
point on this plane and give it its
actual physical real space no anyway
let's it up again ok the Kinect is
seeing all these points I am all of
these points in a room and the Kinect is
seeing me and I want to move these
points around but this is like the
weirdest thing I've ever had to explain
and it's like the city it's like totally
simple it'll just make sense if I just
showed it to you yet I insist on trying
to explain it in this weird way but I
want to take all the points of the
Kinect are seeing in this physical
3-dimensional space where I am and I
want to move these virtual dots which
are on the screen in this virtual 3d
space and that's known as a point cloud
this is how you might start to build a
3d model of what the Kinect is seeing in
the space so the key difference here so
one thing that I had before in the
previous video is we were looking at
this pixel based image right this idea
of each image each pixel of a depth
image has a value between 0 and 255 and
it's a brightness value based on how far
or close it is now the information is
stored in exactly the same way inside of
this big array but instead the numbers
are between 0 and 4500 so how do we work
with these numbers so let's come over
here and do a couple things in this
video but this first point cloud example
I mostly have the code already so you
can see here that what I'm doing is
looping
through the connects width and height
again I'm skipping because I don't need
to do every single point I don't need to
do all the points just to visually get
this effect and then I'm finding the off
set it off set into that array so X plus
y times connect to two not width so
that's how I'm going to look up into
that big array of all those depth values
now what is that array that array is
called is I get that array by saying
connect to dot get raw depth so when I
said get depth image that gives me a P
image object with pixel values all in it
now I just get a big integer array I
guess those integers are between 0 and
4500 so they're in that array and I can
say the depth is I already use the depth
is the offset into that array now
there's something else going on now in
this function what it's doing is there's
a function here called depth to point
cloud position X Y D X is the pixel X Y
is the pixel Y D is the depth that the
Kinect is see they're sort of there's a
strange thing that's happening which is
that the pixel we look at all these
these pixels in a grid and we get this
raw depth value but the Kinect itself
there's some math involved in how that
can actually convert it to real
measurements in physical space like
where is the actual X where's the actual
Y based on like how the camera is seeing
it so in order to do that this
particular example has just this
function which essentially you want to
download these examples and copy this
verbatim but this function is using all
of these kind of parameters that are
built into the hardware itself so these
are like a whole set of numbers and
values that are just part of the
connects calibration and you kind of
multiply and divide by these numbers and
you get the actual value of where it is
in space sort of an interesting problem
I would love to let go through it at
some point but right now I'm sort of
inclined to sort of skip it and say the
interesting thing is what you're getting
is if you give the raw depth value the
pixel X and the pixel Y and use that
function you're going to get the X Y and
depth values in
leaders back of where those things are
in physical space so I don't want to in
fact draw the this is what you're seeing
in this particular visualization right
now is just all of these pixels at their
exact XY and XY value with a zero depth
so what I want to do is change this
program to say this actual physical
point this P vector the P vector is an
object that is an X Y and a Z I want to
draw the vertex at point X point dot y
and now point point Z and in order to
make this a little bit better I'm going
to skip fewer pixels I'm going to skip
only four and I'm going to run this
again and now you'll see here I am this
is the point cloud this is me in
three-dimensional space so if i zoom in
on this you can start to see like what's
going on this over here by the way is
the wall tell me how I can like put my
hands on the wall almost as if I'm
distorting the wall but really what I'm
doing is I'm casting a shadow on so it's
a little bit strange to see this view of
me and my Kinect I can like no I give
myself a hug that's a little bit weird -
I was like punching this weird hugging
anything that you do I don't know just
scratch all that but you can see here
this is now a visualization in
three-dimensional space you connect
these points with lines you could color
them there's a way of actually getting
the RGB values and so you could see like
the colors that are on my shirt on these
points as well this is a road you could
go down and I find this road to be
particularly interesting but what and
you can see that I'm using just a simple
Y rotation so now I'm kind of like
spinning around this image which has now
gone off-screen but if i zoom back in
you can sort of see it's over there so
this is kind of the start of sort of
thinking of like what can you do with
these raw depth values I think what
would be a useful demonstration now is
to look at how might I actually pick out
just me so you can visually see just me
but there's a sort of nest there's like
all this stuff over here there's this
over here there's actually like this
pole over here that's being picked up by
the Kinect so what I what if I just
wanted to like even only get my hand
right here what I want to do is try to
calibrate a threshold so what if I want
the Kinect only to see the connects over
here remember so
it's to the left of me I don't know what
what hi that is your viewing but what if
I want to say look at the pixels in
between here and here and now would
conceivably get my hand right how would
I do that how to look only look at the
pixels between a certain minimum and a
certain maximum let's look at that so
one thing I'm going to do is I'm going
to save this as I don't to call this min
max threshold and I'm going to get rid
of all this 3d stuff for right now
because I'm not going to do this with
you could do this with visualizing the
point cloud still but I'm going to do
this with jest and I'm going to look at
all the pixels so I want to do X plus
plus + y plus plus and somebody remind
me what's the size for 512 for 84 set
right I don't know if that's right
and so hopefully that's right and then
what I want to do is I don't need any
shape I don't need I don't need begin
shape I don't need any of this stuff
what I want to do again and I don't need
this depth to point cloud thing taking
all of that out because what I want to
do right now is just go through this
double nested loop and look at every
depth value 0 and 4500 but I only want
to like count the ones that are between
200 and 400 or between 500 and 800 what
is that what's that minimum and what's
that maximum threshold okay let's make
this happen so the first thing that I
should do probably is I would like to
make myself just to be able to see this
I'm going to make myself an image and
I'm going to create a blank image which
is the same as the width and height of
the connects and it's an RGB image so
this is a function in processing create
image that just makes a blank image and
then whoops and then what I'm going to
do right now is I am going to in here
I'm going to right here I'm going to say
image dot load pixels because I want to
operate I need to operate on the pixels
of that
I'm going to set pixels in that image
based on the raw depth and at the end
I'm going to need to say image update
pixels and I'm also then going to want
to draw that image so just to make sure
that things are working what I'm going
to do is right here inside sorry this is
where all of the important code needs to
happen right now it needs to happen
right here inside this double loop right
for every X for every Y I want to set a
pixel on the image image dot pixels
index offset equals and I'm just going
to set it to be you know some color
right now some purplish color and run
this and we should see that that's
working okay so you can see this
purplish color I clearly cut the size of
the window run let me just let me just
get that for you guys really quick so if
I go back and look at my RGB depth test
ah this isn't telling me Oh actually you
know what let's just be smart about this
I want to just know what those values
are I'm going to print out I'm going to
print out the the the depth width and
the depth height really quickly we can
look in the console 512 424 I knew I had
some post close so let me just get that
right now and I don't need this much of
the console here and I can get back to
the important part of the code we could
run this we can see okay purple so I
have now filled every pixel on the
screen with purple but what I want to do
is fill every pixel on the screen based
on the depth so for example what if I
were to just say if D is greater than
300 and D is less than 1500 image pixels
offset is that otherwise image pixels
offset is black so what I'm doing is I'm
saying only if the only if the distance
is between 300 and 1500 let me see a
purple color otherwise let me see a
black color and when I run this we
should see oh my god I can't believe
what I guessed and like a genius here
it somehow guessed a pretty reasonable
threshold so you can see
here that now what I've done and now you
see like all computer vision problems
melt away in a way like what I could do
now is like it's so easy to find that
I'm not easy but it's much easier now to
find the contours that I have this
problem of this wall over here so how do
I get rid of this wall well first of all
the way that I get rid of that wall is
by not doing my connect stuff right next
to a wall so unfortunately this is like
a bad a better setup I think for doing
these videos which someday maybe I will
find but what I wouldn't they let's at
least see if I can get the hands so one
thing you'll notice here is that the
hands go away once you're about a foot
and a half from the Kinect so what I
really want is between about I don't
know between zero and maybe like five
hundred so there's probably a better way
for me to calibrate this than just
randomly picking numbers but let's give
this a try you could see nothing nothing
nothing nothing nothing nothing nothing
nothing nothing that didn't do it so
good so so it's a so I you know I whoops
that's not going to do me any good
either
let's do between like two hundred and a
thousand nothing you can see up like
right but if I come in a bit so you can
see here how like I'm able to pick out
only my hand again I've got this problem
with the wall so I'm gonna do something
about that in a second then maybe try to
like just like not look at the pixels on
this side of the window I guess but you
can see how you I'm starting to find
this idea of a minimum and a maximum
threshold and really I should make these
variables so I'm going to say a min
Thresh is 200 and Max thrush is 1000 and
you know I might as well make these
floats because what could be also useful
I think the way to I could calibrate
this right here's a great way I could
calibrate this so in between the minimum
threshold and the maximum threshold what
I might do is up here I might say min
threshold equals map the mouse's x-value
which goes between zero and width to
between zero and 4500 and the maximum
threshold I'm going to do whi which
between zero and height zero and 4500
and then I'm just going to print out
those values I could draw them on the
screen which we probably let's draw them
on the screen
so then down here I'm going to just fill
255 text size 32 text min Thresh plus Oh
Mac gotta use double quotes max Thresh
you know 10 comma 64 so here we should
see on the screen these values so now
what I need to do is figure out like
what's a good whoops wait X is going
between I'm doing I have lost what I've
to do something is wrong here
Mouse X between oh this is max Thresh
yeah that's a problem okay so now you
can see I'm able to like calibrate the
minimum threshold and let's calibrate
the maximum threshold like how far back
am I seeing but the minimum needs to be
higher and then I don't want to see too
far back so there we go so this I feel
like is good if I'm getting my hand
right now it's between about 480 and 827
so let's like only if I'm standing right
here of course but you know you could
design an interactive exhibit where you
put some footprints on the floor and the
person has to stand there so I'm now
going to keep my hand boy this is a long
video I'm at 15 minutes I'm going to
keep my hand around here I'm going to
make the minimum maximum 480 and 8:30 so
now I could comment these lines of code
out and I'm going to say 480 and 8:30
and I'm going to run this again and we
can see I'm kind of getting my hand like
really I'm getting a pretty good
tracking of my hand so one thing that
I'm going to do now of course which I
think would be useful is try to get rid
of this wall over here so you know the
wall is a bit of a problem but I can
kind of do a little bit of a cheat here
I think which is also to say if and and
X is greater than I don't know what how
many pixels do you think that was that
was probably about 75 pixels so maybe
it's a little bit more so I'm just like
not allowing me to measure anything
that's like a hundred pixels over so you
can see I kind of got rid of that wall
and now I have my hand so this is great
you can see like this really nice clean
outline of my hand because this is my
other hand
coming in it's not inside until it gets
there right it's outside of that maximum
threshold and now it's inside of that
minimum threshold it's funny how it like
oh no my arm is coming in so of course
my whole body comes in now you can see
my whole body is here which is another
thing that I want to look at so um you
can see how this minimum and maximum
threshold is working pretty well so I
think this is this wraps up this video
I'm going to continue this exact example
you could try this on your own as an
exercise before you get to the next
video how would I actually just find the
center of my hand so I could control a
processing sketch now by moving my hand
around or moving this hand around or
what if I do both hands so how would I
do that this is I feel like I'm like I'm
some sort of like magic person here um
so that's what I'm going to look at in
the next video how do I find the center
of my hand and control something else
like a little like snake that's moving
around the screen or make a particle
system come out of my hand we'll look at
that in the next video and another thing
I want to look at is how would I find
the top of my head so if I'm the human
being here how do I know if I'm bending
down or standing up okay so we'll look
at that in the next video thanks for
sticking with me here I think this is
actually starting to come together okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>