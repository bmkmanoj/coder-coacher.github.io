<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Python Web Crawler Tutorial - 8 - Creating the Spider | Coder Coacher - Coaching Coders</title><meta content="Python Web Crawler Tutorial - 8 - Creating the Spider - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/thenewboston/">thenewboston</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Python Web Crawler Tutorial - 8 - Creating the Spider</b></h2><h5 class="post__date">2016-02-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/MpazNSqP4uo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so the first thing I'm going to do is
import everything we need so URL Lib
request imports URL open art so this is
just a module that allows us to connect
to web pages from Python you probably
use it before now another thing that we
need to do is just import link finder so
our spider can actually use it so from
link finder import link finder and also
remember this file that we made earlier
it just had a bunch of like simple
housekeeping methods in it we're just
going to import that so from general
imports all are right - looking good so
of course later on we're going to go
ahead and need an is this initialization
method it's kind of a tongue-twister
so inside here is where we typically
write all of our instance variables in
other words when if we were just making
a normal class and each instance of that
class had its own set of variables you
know we would just type in there if we
made a people class every person would
have their own name their own hair color
tomato tomahto but again these spiders
as we saw they need a special type of
variable they need a variable that they
can all share right there so what we're
going to do is we're going to actually
make a class variable now a class
variable is a special type of variable
like I said that shared among all
instances so whenever we make this all
we can make like 100 spiders in there
all looking at the same variable and let
me write that so class variables say a
shared among all can you spell instances
Bucky holy sweet moly art so there you
go and the first thing I'm going to do
is I just want to make a variable called
project name so that way whenever the
spiders start crawling the links they
just know what folder to start putting
them in and again this is just going to
be equal to something like the New
Boston most of the time but we're going
to let the user pass that in now another
thing I
to do is get the base URL because
remember we need the base URL and that
is just typically going to be just a
homepage URL and we already explained
why we need that so you can pretty much
if a link is only um relative you can
make it a full properly formatted link
now the other thing that you need is
domain name now later on I'm going to
show you guys why you need the domain
name basically for the same reason you
need this and there's actually a bunch
of cool Python modules to help us out
with some of that stuff but we want to
make sure that we're connecting to a
valid domain without any issues so
there's that now I'm also going to make
variables for those crawled and queue
files and that's just because I just
don't want to be like um project name
plus crawled dot text I just don't want
to pull off this all over every time I
want to access the file so I'm just
going to make a variable right here and
I'll name it um queue file in croud file
now again the reason I'm making these
blank is I'm just going ahead and
declaring them up here so whenever I
make them up here I'm just saying hey
these are class variables they're just
going to be shared among all instances
we don't have to set their value yet um
we just make them class variables right
here and we can actually just set their
value later on any spider actually you
can set the value of these which is
pretty cool and I actually want to make
two more things two really important
things and that is the queue and can
name this queue set if you want but I'm
going to be using this a lot so I'm just
going to set this equal to an empty set
and also crawled now again if you're
like alright so the queue is the waiting
list in the crowd are all the pages that
you crawled so isn't that what this is
right here well remember this is going
to be the text file so whenever we're
shutting down our computer and we want
to save that information long term we
actually need to save it to a file so
these are actually going to have the
same data in it but the reason that we
make these sets right here is
because we just don't want to write to a
file every single time you come across
our link that's really slow it's not
efficient at all so we're going to use
variables and again files are stored on
your hard drive and these variables are
stored on your RAM they're a lot faster
even with the new you know solid-state
hard drives whatever all right so we got
a bunch of variables and again these are
the ones that are shared among all
instances or all spiders now anytime you
want to use a class variable actually
let me go ahead and pause this video and
I'll talk to you guys about this in the
next one it's getting kind of long</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>