<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Python Website Scanner Tutorial - 7 - Running the Final Program | Coder Coacher - Coaching Coders</title><meta content="Python Website Scanner Tutorial - 7 - Running the Final Program - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/thenewboston/">thenewboston</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Python Website Scanner Tutorial - 7 - Running the Final Program</b></h2><h5 class="post__date">2015-10-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LqIkt78qBSk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright guys welcome back and the last
thing that we need to do for this
program is now that we have all of these
individual tools created to find the
domain name IP address and map
robots.txt who is we got all these
individual tools I'm just gonna make a
single function to run all of them at
once
so then all the user has to do is pretty
much give a URL and hit run and it
gathers all of those automatically now
I'm actually just gonna stick all of the
results in a separate directory
I can't just Oroville store them in the
same directory as this but then I got
all my results you know jumbled up with
all my source code so instead I'm just
gonna make actually let me make this a
constant so root underscore directory
and what am I gonna name this I'll just
name it like companies so you can name
this companies targets projects whatever
but this is just gonna be a separate
folder inside here and then every
website I scan is gonna be stored in a
folder inside here like the new Boston
it's gonna have its own folder read it's
gonna have its own folder and that way
everything is nice and all nice and
organized so I'm just starting to write
great der root directory and again
remember what this does we did this in
the first video is it just checks if
that directory is created or not and if
it's not created then it creates it so
that way we can run this the first time
and it's gonna work and then we can run
it another time and it's not gonna like
freak out and overwrite it and delete
everything you're just gonna work
perfectly every time so let me take this
a bit actually let me get myself a
tidbit more space to work with like
being able to scroll for some reason
alright so this is gonna be the main
function that the users are gonna call
and we'll just call it gather info so
all they're gonna do here is they're
gonna pass in the name of the company
and this is it's gonna be like the new
Boston or eBay or whatever and then the
URL of the website now we're passing in
the name because when
we make these folders to organize
everything each of the folders just
gonna have a new name and will let the
user decide whatever they want to you
know name their folder so basically all
we're gonna do from here is we're gonna
go through each one of these tools and
remember these tools all they do is they
run a skin and they return the results
so what we're gonna do is we're just
going to call them and essentially just
save the results and then save it to a
file pretty simple
cool uh I like weird phlegm in my throat
okay so the first one I'll just do them
in order of how I imported them so the
domain name in order to get this we just
call get domain name and this just takes
the URL easy and actually let me show
you what this ending gather info is
going to look like right here
so this gather info is gonna take two
parameters the first one is gonna be the
new boss then and this is just going to
be what my project folder is gonna be
named and the second one is just going
to be the full URL HTTP let's just write
new boston.com
and we can add that ending forward slash
if we want or we can exclude it remember
it doesn't matter because we wrote a
check and balance for that so what this
is going to do is whenever we pass in
the URL is just going to return the
top-level domain the New Boston com
simple enough now from here we can let
me just do this we can get the IP
address and the IP address we need to
pass in the URL as well so the next
thing we have to do is we need to get
the results of the nmap scan and that is
getting map and you see this takes two
parameters the any optional parameters
that we want and also the IP so by
default just have a minus F which just
means a fast scan
and this just runs a little bit quicker
it doesn't scan that many ports and
remember this doesn't take a URL it
takes the IP address and since we got
that in the previous line we can now
pass that in look how neat that is and
now robots the text what we can do is we
can get this and the robots that text
this takes the URL so if we just write
could probably type that faster than
copy in but whatever
and now the who is destroy who is equal
get who is now this also takes the it
says URL but it's actually the domain
name because remember it can't use arm
like this right here it has to use the
top-level domain name which is the new
Boston com
so that's why we need to pass in the
domain name right here and now what we
did up to this point is you pretty much
just ran all those tools and we now have
all of the data from all those tools in
variables right here so now we can make
one more function and all this function
is going to do is it's going to save
this text and write them to a text file
so we're gonna write which is called
like creates reports and we're gonna
pass in all of the information so name
which was you know whatever the
company's name is the URL the domain
name what else we got the end map robust
the text and the Whois alright so now we
actually have to create this so again
all this gather info function does is it
runs all these tools and gets the
results and now this great report is
just gonna save them to a text file and
we can actually just use this if you
want to be really lazy about it since
we'll just keep all the same parameters
now remember that each new website you
scan which is essentially a new project
you want to save it inside a new
directory so what we can do is we can
actually just say project underscore dur
so this websites directory is the root
directory which is this going to be
companies and then we'll just add a
little forward slash for the path and
then the name so again if we scam the
new Boston this is gonna be in a
directory called companies the new
Boston you scan eBay is going to be
inside a company's directory inside
another folder called eBay and then all
of our text files are gonna go in there
it's gonna be nice and organized alright
so from there all we need to do is we
need to create that directory and it was
called projects directory and now we
pretty much just need to write to every
file so write file and let me run that
again so you guys can see so write file
and this takes two parameters the path
in other words what's the file name
where do you want to save it and then
the data itself what do you want to
write to the file and of course all of
those are just whatever we got from
right there so right file and the path
is always going to be the project's
directory since we're we're saving it is
depending on what website we're scanning
simple enough and then we'll just do
these one by one so I'll just write like
a full URL text and let me do this
all right so that way we know that the
URL we pass in this one is actually the
full URL and I just want to rename it so
we don't get it confused with the
top-level domain which is the new Boston
calm so you know I can actually copy
this whoa see one two three four one two
three four all right so let's do this
really easy so domain name and map
robots.txt
and who is notice the text and who is so
again whatever the tools name we'll just
name the file the same thing and all
right mate that looks good now I have to
clear out these lines or else probably
gonna yell at me and I think that is its
full domain and man boom roasted all
right so now let me go ahead and run
this and if I didn't mess anything up
then what we should see is a four-door
being created right here and then
another folder inside it called the New
Boston calm and all of these results at
once so cross your fingers and let's see
if this works and it takes a little bit
of time and what you may want to do is
inside each of those tools right when
the function starts you may want to
write like just print out something to
the command line so people can see that
you know it didn't freeze on them like
scanning for the Whois or doing an nmap
scan or whatever but check this out
alright so it looked like you created
that company's folder and inside the New
Boston we now got all actually we messed
up because all right we didn't we need
to add this right here so I'm actually
going to delete this
and I run that bad boy again
done don't-don't-don't scanning my
website and this is gonna work alright
so company's the new Boston and check
this out so we now have all the
information in one big shebang the
domain name the full URL the results of
an nmap scan robots.txt who is boom
roasted and if we ever want skin a new
website instead of going through the
command line the terminal and typing all
that which is gonna take us forever all
you have to do is give it a new project
name give it a new URL hit run and boom
roasted so we now are saving ourselves a
bunch of time and by the way one last
thing I'm gonna leave you with is this
I'm gonna post this on github but I'm
gonna tell you guys right now there's a
98% chance that I'm not going to
maintain this tool and that's just
because you know I'm lazy essentially
but if you guys want to add your own
modules and you know you want to run
your own skins then go ahead and fork it
or um you know add one to mine and I'll
accept it so yeah if you guys want to
help me build this then there you go but
I'm not like gonna be updating it so you
know don't write me messages but hey add
some more modules that this said that
but uh yeah if you guys want to help out
I'll definitely accept this so thank you
guys for watching and well that's all I
got for you so uh I'll see you guys in
the next series</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>