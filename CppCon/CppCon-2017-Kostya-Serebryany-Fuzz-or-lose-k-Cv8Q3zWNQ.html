<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: Kostya Serebryany “Fuzz or lose...” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: Kostya Serebryany “Fuzz or lose...” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: Kostya Serebryany “Fuzz or lose...”</b></h2><h5 class="post__date">2017-10-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/k-Cv8Q3zWNQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">- Good afternoon and thank you
for coming for the last afternoon session.
I appreciate that you are tired.
But I hope to wake you up a little bit.
My name is Kostya, I work at Google,
and I'm going to talk about fuzzing today.
So I hope to explain you why
we should be doing fuzzing.
We'll have several case
studies related to fuzzing.
I will discuss continuous and automated
fuzzing, which is a kind of magic,
and I will cover some of the challenges
that we face with the
adoption of the fuzzing.
I will not cover any deep
technical details today,
this is just half an hour talk,
but your questions after the talk
about any kind of detail are very welcome.
So what is fuzzing?
Lets first discuss what is testing.
In most cases testing
you API means that you
feed a fixed number of fixed inputs
into your API and observe the behavior.
On the contrary, fuzzing
is a process where you
are feeding and infinite amount
of generated inputs into your API.
That's, that's it.
And there are lots of
different strategies,
for doing the fuzzing or in other ways
for generating the test inputs
automatically for your
API, I'm mostly working on
so called coverage-guided fuzzing,
but this is all irrelevant
for the today's talk,
today's talk covers fuzzing in general.
So why would you fuzz C++ code?
And please, wake up.
So one of the reasons why you
want to fuzz your C++ code
is that because hackers love C and C++.
The problem with this is that the hackers
love C++ and C for different reasons.
Not for the same reasons as you love C++.
This animated GIF shows you how fuzzing
can find Heartbleed Bug in five seconds.
And for those of you who don't remember,
Heartbleed is a bug that
shocked the industry
the internet about three years ago.
And I've presented this thing
at CPPCon two years ago.
So did I hear any &quot;Boo,&quot; in the audience?
(laughs)
No?
Did I really say C/C++
on the C++ conference?
Boo, anyone?
Yes I did say C/C++ because C++
unfortunately inherited a bunch
of problems from the C language.
The major one you might put in my view
is the set of memory safety bugs,
such as buffer-overflows, use-after-frees,
use of uninitialized memory and so on.
Every time I say something like this,
C++ inherited blah, blah, blah,
I hear, &quot;Boo,&quot; anyone?
I hear that, &quot;Come on, modern C++
doesn't have those things.&quot;
I've heard this when C++ 11 appeared,
when C++ 14 appeared and
I keep hearing it now.
So I have a few things
to say about modern C++
but let me say just one thing,
so this is a modern C++, the class called
&quot;std string view&quot; has
just appeared in C++ 17,
who can spot the bug in this code snippet?
Raise your hand.
Okay so quite a few of
you can spot the bug
but quite a few of you
cannot or are sleeping.
Anyone else?
Okay.
So that's a heap buffer overflow.
We're creating a temporary object
which is result of
continuating two strings
we take the reference to that
temporary object in the string view
then the object is destroyed and then
we use the reference to
the destroyed object.
Oops.
Any kind of sane memory error detection
tool for C++ will report this bug
if you execute this code while
testing with this memory safety tool.
Things get a little bit more sophisticated
if you just remove a few
characters from this example.
If instead of using hello with many Os,
you use hello with just a few Os
it will become a different bug,
at least as it is implemented in lib C++.
Because this is now
short string optimization
no heap memories involved,
this is still a bug
but slightly different.
So modern C++ you said, lets
fuzz some really modern C++.
I don't have anything written in C++ 17
because the standard is, today is old.
But I have something
written in proper C++ 11
this is a relatively small
library called, &quot;woff2&quot;
which handles VAP phones.
I would say that 50 percent of you
have woff2 in your pocket, in your phone.
So it is a C++ 11 library,
the team follows a strick
coding style for C++ 11
the team uses code review,
the team has unit tests
the unit tests are running
on continuous integration
the code use STL containers, iterators,
namespaces and even bells and whistles.
It didn't help.
When we started fuzzing this code,
we almost immediately
found a buffer overflow
which has a write of 12
kilobytes outside of the buffer.
And just imagine this thing is running
on your mobile phone
and is processing data
that you receive from internet
from untrusted sources
so you probably care about fuzzing.
Do you agree?
Okay.
So you are not asleep, good.
And now let me show you how much effort
did we spend to find those
memory issues in woff2?
This was not the only
memory issue in woff2.
So this snippet of code and
we call it the fuzz target
is the single function that
consumes an array of bytes
and that uses this array of bytes
to feed them into the
API you want to fuzz.
I want to emphasize,
this is all the effort
required to fuzz that library
and to find bugs in it.
And we found it with libFuzzer,
you can find it with many
other fuzzing engines
the same way, let me just show you
how easy it is to do
things with libFuzzer.
So suppose you have this fuzz target
in a separate file
fuzz.cc, this is fuzz.cc
and you have all other
files of your library
of your API somewhere else.
All we need to do is get fresh clang
this is all pretty new development
compile all your code
including the fuzz target
with a couple special switches.
Fsanitize address gives
your memory safety checking.
And fuzzer gives you
instrumentation required for
coverage guided fuzzing and it also
adds some library at link time.
Then you want to create a directory
where you will put some samples
for the inputs of the API.
And then you just run the resulting
binary on this directory, this is it.
So I hope I convinced you
that fuzzing is pretty simple.
A few words about the concept of
fuzz target as we understand it.
So again a fuzz target in
our occurring definition
is a function with a fixed signature
that consumes an array of bytes.
And inside that function,
you use the array of bytes
with your API in whatever way you want to.
The fuzz target should be tolerable
to any kind of data and any kind of
crash or abort or searching
failure or time out
or out of memory should
be considered a bug.
If not, I would say that your
code is not really an API.
This fuzz target should be single process,
it should be ideally deterministic,
if you need randomness, get
the random bits from the input.
Preferably it should
not modify global state
although we can tolerate this.
And the smaller the target is,
the more efficient will be the fuzzing.
Although we can fuzz
arbitrarily large targets
if we have enough CPU power.
So far we discussed
mostly memory safety bugs
but stability and security
of an application,
not necessarily of C++ application,
is much more than just memory safety.
Let me give you another example
which I hope is suitable
for C++ conference.
Eight months ago my
colleague Dmitry Vyukov
has submitted a single ticket
against boost regex library.
And this is literally the ticket
so in just half an hour, Dmitry had found
memory safety issues of different kinds,
assertion failures, segmentation faults,
infinite loops, bunch of leaks and so on.
And this is the effort he needed to spend
to fuzz boost regex and find
those couple dozen libraries.
Again these are just half a dozen lines
that have no complicated logic in them.
All you do is you take the data
provided by the fuzzing engine
and you feed it into your API.
And this is what you get, those many bugs.
I am very grateful to the boost developers
for fixing all of those
bugs very promptly.
This is great, like not all of, not all of
the developers who get reports
from us fix their bugs.
Boost did.
But the problem was
that continuous fuzzing
was never set up and I want to emphasize
that continuous fuzzing is much
stronger that just fuzzing.
For reasons that I hope you understand.
These are the same reasons why
testing is not enough and
continuous testing is much better.
So I have added boost regex to the
continuous fuzzing service which I am
going to talk about on the next slide.
And it happens, happened
last Thursday evening,
because I was preparing my slides
and I realized that something
is missing on these slides.
Yes on Saturday five bugs appeared
on the continuous fuzzing service in Boost
and some even last
night, two more popped up
and one of them was
actually memory safety bug
in Boost, stack buffer overflow.
If anyone here is from Boost, I will try
to catch you tomorrow at the Boost dinner
so that we can fuzz more of Boost.
(laughs)
So a few words about the continuous
fuzzing service I have mentioned,
the service is called OSS-Fuzz
we have launched it December last year.
And the project is a collaboration
between quite a few teams at Google.
The project provides continuous
and automated fuzzing
of open source projects
on Google hardware.
It uses two different
fuzzing engines right now.
libFuzzer and AFL, more fuzzing
engines are in pipeline.
And the service also uses the sanitizers
ASan, MSan and UBSan, to
actually find bugs at run time.
This project is available to what we call
important open source projects
and we don't, it's provided for free.
We haven't built this thing from scratch,
instead we reused the same infrastructure
that we're using for the last two years
to fuzz the components
of the Chromium browser.
And this slide shows some of our trophies.
So in less than a year, the service have
reported 2000 bugs to more than 60
different open source projects.
And this is the slide from months ago
now the numbers are even better.
As you can see there is
a usual set of suspects
memory safety bugs, buffer
overflows and use-after-free.
Now there is lots of other types of bugs
like out of memories, time outs, leaks,
the largest sections, the largest section
comes from the tool called UBSan
and define behavior sanitizer,
these are basically
assigned integer overflows
and shifts by large numbers like
you're shifting left by 1000.
Someone at this conference
have already asked me,
so what if I don't have
an open source project?
What if my project is closed source?
In the current form, the service is only
provided for the open source projects.
And we also don't accept toy projects.
The project has to be significant.
But all the tools used by the service
are open sourced and most of them
are part of the clang LLVM tool chain.
They are fully supported on Linux and Mac
and I want to thank the apple developers
for helping me to port these tools to Mac.
On Windows they kind of work
but your mileage may vary.
But if you are on a Windows active system
there is a service provided by Microsoft,
take a look at that one.
So back to fuzzing.
The examples I've shown so far are
open SSL, VAP phones and Boost Regex
those consume pretty simple data formats.
To some extent these are bags of bytes.
Not just bags if bytes
but not very complex.
And not every API written in
C++ consumes simple data type.
So in many cases fuzzing
complex data types
is very inefficient because the fuzzer
creates invalid inputs very frequently.
And nothing interesting happens.
So lets do another case study,
lets fuzz something that consumes
a very very complicated input.
Do you know anything that is
more complicated than C++?
I don't.
So if we can fuzz a C++ compiler,
I am pretty sure we can fuzz everything.
Lets take a look.
So a compiler is typically
a series of building blocks.
And roughly speaking it consists of
a lexer, a parser, an
optimizer and code generator.
So we first started fuzzing clang
as a thing that consumes a bag of bytes.
And we found enormous amount
of interesting things.
For example if you put,
if you give the compiler these four bytes,
it will do a heap buffer
overflow somewhere.
And there are quite a few of those,
I have shown only the ones
that fit on the slide.
So we've got use-after-frees,
we've got infinite CPU and RAM consumption
and all of those
don't really look like C++ code.
Would you agree?
Well the first one maybe but
the second and third one.
Maybe this is C++ 12, eh no, 20.
But not C++ 17.
So this was annoying because yes we were
finding bugs in the compiler but we were
not going anywhere deep in the compiler.
We wanted to get into the code gen.
So we started fuzzing the C++ compiler
in a structure aware manner, such that
we know that we are fuzzing
C++ or a subset of C++.
And this is what we've got.
So we have implemented the
toy prototype for fuzzing
where we know that we fuzz,
that the input is a C++.
And now this input that triggers
an infinite loop in LLVM
it actually looks like C++ or
actually it's a subset of C but
this is my toy prototype.
And all of the bugs we found this way,
and we found a few, they trigger something
inside the deepest levels of the compiler
namely optimizer and code generator.
So how do we do this?
We need to provide a little
bit of help to the fuzzer
by implementing what we
call a custom mutator.
So most of the fuzzing engines
typically mutate the
data they consume in some
serial way like byte
flipping or bit flipping.
And instead we need to
provide the function
that takes the bag of
bytes, parses it into
abstract synthex tree
or some other structure
implements one single
mutation on that tree
and feeds it back to the
target that you want to fuzz.
And also have a support
library that does all of the
all of the above on the protobuffers.
A protobuffer is a library that provides
AST sterilization, desterilization.
And we then hooked this library into clang
so that we can fuzz C++ not protobuffers.
I won't go into more details now
but this was really simple and all of
this code is an LLVM trunk now
so you can have a look.
By the way fuzzing also
finds logical bugs.
This is mostly important for things like
cryptography, compression,
rendering of any kinds.
And it is very easy when you have
two implementations of the same thing.
Suppose you have a
reference implementation
of some code, crypto primitive
and an optimizer implementation
and you want to verify
that on every inputs
they produce the same results.
All you need to do is
implement a fuzz target
that would call both versions
of the provided input
and verify that the, that
the output is correct.
We have found quite a few bugs this way
in cryptographic code
and here is one example.
So raise your hand if you
think that fuzzing is useful.
Thank you.
(laughs)
Now raise your hand if
you think it's simple.
Come on.
(laughs)
Okay so I haven't convinced
you that this is simple.
But even if it were simple,
simple plus useful is not
necessarily widely used.
And this is my pinpoint, I want fuzzing
to be widely used because
it helps get rid of bugs.
And at Google we have reached
quite good adoption of fuzzing.
Not good enough, we're still working on it
but we have several
thousands of fuzz targets
across our server-side code and Chromium
and open source projects
developed by Google.
And this number is growing.
We keep this because
there are several things
about Google infrastructure
that are critical here,
first of all we control the build system
and so building all those
things is trivial, its one flag.
We have built automated bug finding,
automated reporting, automated tracking.
We have held several
events, Fuzzits, Fuzzathons
Fuzzing weeks et cetera, most importantly
we advertised fuzzing on our toilets
worldwide, three times
and I'm not kidding.
What about adoption outside of Google?
Here
it varies between the
teams, I've just heard
from one of the large C++ companies
here on CPPCon today
there are using libFuzzer.
Thank you guys but I want everyone here
to use libFuzzer if it's
applicable to your code.
I started my career as a
C++ developer 19 years ago.
And one of my first manager told me
no question, test are for students,
students have plenty of time for tests,
we are serious developers,
we are developing
a production thing, we
don't have time for tests.
It was before Kent Beck had declared
his test driven development.
And even now I see many many projects
and products that don't really use tests.
However this has changed dramatically.
How many of you actually
write tests for C++ code?
Yeah.
If I had asked this 15 years ago,
most of the audience
wouldn't raise their hands.
But we need to go further,
testing is not enough,
in our experience, testing
finds roughly 10 percent
of the bugs and 80 more
percent of the bugs
are found by fuzzing
and then the remaining
10 percent also not found
by fuzzing or testing
they are found in production by users.
So I want to proclaim
fuzz driven development
this is where all your tests
are essentially fuzz targets.
And the continuous integration system
does continuous fuzzing.
And by the way this is not
specific to C++ in any way,
the people in the rust community
are already doing it very successfully.
And despite the fact that rust
is a memory safe language,
they do find loads of interesting bugs
and most of them are not
memory safety issues.
We need to make fuzzing simpler
to make it more widely adopted.
And we'll probably have to change
the language, the IDEs, the
compilers, the build system
and whatever it takes
to make it super easy.
We need to make fuzzing as easy
as putting one word in
one place in your program.
And here is my proposal that is not tested
and not implemented but I want
something like this to happen.
Suppose somewhere in your application
you have an API function
that consumes data.
Want to slap an attribute on that function
and have it fuzzed automatically by the
build system IDE, CI or whatever you have.
Now data and size is
not really C++ language,
you will probably agree.
And so we may want something more C++
maybe allow strings as parameters
or maybe I'll allow vectors
of simple types as parameters.
Or maybe I'll allow any kind of types.
But for any kind of types it
becomes a little bit tricky
the fuzzer actually need
to know how to serialize
and deserialize this data and optionally
how to mutate this data and then
we'll have to provide more stuff there.
Now I've mostly talked about
memory safety and fuzzing,
unfortunately C++ memory
safety is more than fuzzing,
you will never solve all
the memory safety bugs
in your application with fuzzing.
So we need to do something else
and I can see two most important
areas other than fuzzing.
First of all do we need to have support
from hardware vendors and I call this idea
hardware assisted memory safety.
Good news is that one vendor has
implemented and shipped hardware
with very useful memory safety feature.
Unfortunately I guess almost nobody here
uses SPARC, does anyone?
Yes, okay.
So if you are using SPARC, you have a
very very useful memory safety feature.
But I don't have SPARC.
And all other vendors
have tried to implement
something useful for memory safety
and have failed so far.
So we as a C++ community need to
put pressure on hardware vendors here.
And the second large areas of improvement,
we need to have something that would
be a statically verifiable subset of C++.
That would provide some
guarantees of memory safety.
I don't know if this
is C++ core guidelines,
that Bjarndis talked this morning
or if this is something else.
But we have to come up with it.
Of course it will help
only newly developed code,
for the old code we'll have to do
fuzzing, hardware assistance
and bells and whistles.
So to summarize my talk today,
fuzzing C++ code is very useful
because it prevents bugs
and you agreed with me.
And it's also simple, I hope
you will agree once you try.
But also must make it even more simple
and we must make it widely adopted,
otherwise, it won't be useful
for the entire C++ community.
This is all of my talk and if you
have questions, please use the mic.
(applause)
(laughs)
- [Man] Hi, so as a programmer
that's also developed
tools that's being used to test
some code for Google fix it
would it be even more awesome
to have a tool that gives you
simple testing so that
simple testing has shown
to be complicated and
you're talking about a bug.
Do you have something
like to simplify the test
case as much as possible
before you generate them
while still showing some bug?
- Can we simplify the
cases generated by fuzzing?
Yes most of the fuzzing engines provide
some way to minimize the test input.
And both libFuzzer and AFL
have some such switches.
The examples for the naive clang
of fuzzing are minimized, you cannot,
you cannot remove any byte from them.
And the examples for structure where
fuzzing for clang can also minimized.
Like the tools are not able to
remove anything from them
while keeping the bug.
- [Man] Hi, are you guys fuzzing the
Chromium embedded framework
as well as Chrome itself or?
- Do we fuzz the Chromium
embedded framework?
I frankly don't know.
My team provides the tools and the service
and the Chromium team
fuzzes their own code
so I don't know the answer.
I know that Chromium project has
several hundred fuzz targets
across the code base.
- [Man] Okay. Thanks.
- [Man] So just, just, so that I
verify that I actually understand this,
your whole argument here is about
generating a test data to exercise
the functions, as far as detecting
the actual problems, the dereference of
null pointers and overflows, is that all
handled by the analyzers that go with
the compilers or does your set up
also include things
like analytic detection.
- Thanks for the question,
so the question is
who actually finds the bugs?
The, the fuzzing provides
inputs that trigger
interesting parts of code and hopefully
trigger the bugs but we need to somehow
detect them.
In our setting we use the sanitizers
tools like address sanitizer, ASan
Memory sanitizer UBSan, these are the
dynamic bug detection tools that work
together with fuzzing
tools in the same process.
You can use other tools available
on your platform like on Microsoft
you will probably use app verifier
or page heap or other things.
- [Man] So with for example your set
of analyzers presents in the UI
the sequence of events which show
what kind of problems the have.
How difficult would it be to have a fuzzer
presents the same kind of sequence
that you guys that shows set errors?
- How does fuzzing results compare to
static analysis results?
So fuzzing results are much better,
because with fuzzing you can have
a reproducer that triggers the bug.
You can rerun it, you can replay it
you can collect the trace from debugging,
you can step by step it,
this is what static analysis tools
either don't provide at all or
provide in a less usable way so
in this sense fuzzing is
superior to static analysis,
I believe so.
We're out of time, thanks
a lot for your attention
but I'm here if you have any questions.
(applause)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>