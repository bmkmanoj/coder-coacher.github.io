<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: Matthew Bentley “Colonies, performance and why you should care&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: Matthew Bentley “Colonies, performance and why you should care&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: Matthew Bentley “Colonies, performance and why you should care&quot;</b></h2><h5 class="post__date">2016-09-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wBER1R8YyGY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi I'm Matt obviously so I always like
to start with this quote because it's
something that's sort of you know jeong
bandied around a lot nowadays on
stackoverflow and various forums and
what-have-you and it's generally sort of
used as a way of essentially you know
hammering on UVs for thinking about
optimization and it's usually used in
the context of saying micro optimization
is bad and this sort of thing you
shouldn't be thinking about optimization
at all you should let the compiler do it
whereas in its original full quality
ssin what it's actually saying is yes
you should optimize you should think
about optimization you should think
about micro optimization as well but you
should be wise about how you optimize
and where you're optimizing you should
optimize the three-percent
but you should do that after you're
identified where it is so about 12 years
ago or so I couldn't walk for about ten
minutes without having to lie down for a
couple of hours afterwards so the
concept of efficiency and performance
has a slightly more real-world perhaps
personal quality for me than it does for
maybe a lot of you and I tend to see it
more externally than solely within
Computer Applications and whatnot for
example Google Maps for example is a
good example of sort of computers and
real world efficiency coming together
you've got all sorts of things like
image compression network compression
browser efficiency JavaScript efficiency
all these different sort of things
coming together to increase this
real-world efficiency if you think about
the millions maybe billions of litres of
petrol that the app has saved since its
inception
not to mention driving time you know use
of frustration wear and tear all that
sort of thing now the only reason I'm
saying that is just to illustrate that
what we do as computer programmers does
make a difference in the real world and
sometimes that's not very visible
that's why conferences like this are
quite good because they bring all of us
to
in a way that we can see each other's
efforts and that sort of thing
so a little bit of background about
myself
yeah a programmer jokes alright so yeah
started programming quite really got my
BSC when I was 21 programmed in some
legal publishing firms and then quit out
of that to have a long term illness
instead and then about three or so years
ago I decided wanted to get back into
programming specifically I wanted to
make some games and I decided I wanted
to write my own game engine because why
not
you should only take a couple of months
so one year later the game engine is
finished and obviously I've lost learned
a lot in the meantime because it had
been about you know 10 years or so since
I touched C++ and obviously a lot has
changed and the first thing I did was I
went through all the open source game
engines that were available and kind of
looked through what they were doing and
I kept on it coming across this thing
called Victor now you've got to remember
that when I completed university the
standard library was kind of a thing but
nobody was really using it it wasn't
that much of a thing so we learned how
to make linked lists not how to use them
so this thing Victor kind of went all
this kind of looks like an extendable
array of some description looks like it
could be very useful for games no
actually kind of not really why is that
and any game programmer here will know
sort of some of the workarounds that we
have for dealing with Victor but just
for the sake of argument I'll go over
what are the problems with Victor and
its default state so crappy erasure
performance for large amounts of data
even if you using arrays if then you get
per frame jitter or if you even if
you've got small amounts of large data
so large elements poor insertion
performance if you're inserting on the
fly is singly insert invalidates all
your pointers and iterators it doesn't
invalidate indexes array
is invalidates pointers miss erasers and
indexes to all elements after the erased
element and it requires a single
continuous memory block which can be
problematic depending on RAM limitations
in your system and that sort of thing
juda fragmentation so why are all these
things problematic for games well to go
into that we first have to analyze what
is game data in general because it's not
quite the same as other domains so this
is stuff that I've garnered a from my
own experience B from talking to other
developers C from talking to the SG 14
group and it seems to be relatively
consistent the first thing is that
elements within containers team to
utilize elements within other containers
doesn't matter whether you're talking
about a flat C style array or you know a
victor or whatever the things are going
to refer to other things so if you're a
game programmer you already know if
you're not then with most games nowadays
there's some sort of entity component
system usually combined with a little
bit of i/o and so you might have your
base level object an entity and it
refers to say a sprite and then sound
and so on and such forth and you're
going to have multiple instances of
various different kinds of things like
walls or enemies or whatever so you're
not going to want to have those
resources within the object itself
you're going to want to refer to them
otherwise your waste memory etc so any
container or use of a container which
invalidates kind of your linkages
between containers is not going to fly
by the way throughout this talk I'm
gonna be going to be using the term
lengths just as a shorthand way of
saying iterators slash pointers slash
indexes basically whatever you're using
to get one thing to refer to another
order is unimportant for the most part
so generally would just got data iterate
over a transformer this refers to that
would bring in this stuff goes out to
the screen and magic happens we have a
game small to medium sized classes and
structs are the norm not scalar types
obviously if you're using a struct
for a configuration that's the exception
by the way obviously this is an all game
data this is just kind of the bulk
majority of stuff can't generalize too
much erasing or otherwise deactivating
objects in real time is common you kill
an enemy you destroy a wall that thing
no longer needs to get kind of iterated
over and creating new objects and adding
them into a game in real time is also
common
so spawning things for example if you
have a more good then you know player
pops into an area and you have to add
stuff in there so basically having some
kind of extensible container is useful
more stuff we don't always know in
advance how many elements there will be
in a container pre development or
necessarily during play again for during
play the Mamaw Pagar example is good
because you don't know how many players
are going to be in a particular area and
that effects the number of creatures and
what-have-you pre development that's
pretty obvious
I mean math you work on a game you're
refining things you're taking stuff out
you're putting stuff in etc the number
of objects that we tend to have in games
is not what you tend to see on online
benchmarks so a million integers or
whatever so for a typical indie game you
could be looking at maybe a hundred to a
thousand objects per level if you're
talking triple-a then I think Mike Acton
said sunset overdrive used about
eighty-four thousand objects per game
level for performance reasons memory
storage which is more or less contagious
is preferred I think everybody's gone
over this enough in previous CP pecans
that I don't need to go into great
detail but you know the usual story ram
speeds have gone like that CPU speeds
have gone like that and we've got this
slightly ever widening gap between the
two which means that we can get
approximately 200 instructions done in
the same time as it takes to fetch one
integer from main memory so the name of
the game is to get everything into the
cache and the best way of ensuring that
everything is in the cache is to have it
contagious in memory speaking of which
memory usage and
constraints are often critical
considerations so if you're on a closed
platform that's obvious but even if
you're on PC you don't know how much
memory the end user is going to have and
you don't necessarily yeah necessarily
know how much RAM they've got left
whatever applications they've got open
etc and the last point is that we
generally don't want containers which
allocate upon initialization we want
them to allocate upon first insertion so
an example of how this could be
problematic
would be something like a quadtree using
that for collision detection and for
those of you who don't know a quadtree
tends to be made up of nodes sub nodes
sub sub nodes etc etc and each of those
nodes can contain collision blocks or it
might not so it may just contain sub
nodes so if you're using something like
Lib standard C++ as dear complementation
which allocates upon initialization then
every time you allocate a node it's also
going to allocate another chunk of
memory for the dick regardless of
whether or not that memory gets used so
you lose memory but you also lose
performance because allocating memory is
problematic so what are some of the more
common victor workarounds there's a
whole bunch of them but I just thought
I'd go into a couple I think Chandler
Carruth is going to be going into a few
of them during his talks so you might
have to eat my hat after that one anyway
first one using a boolean flag or
something similar to indicate that
something's being raised for both of
these will basically have to use indexes
to refer to elements within the
container because pointers will get
invalidated upon insertion but using a
boolean flag to indicator Asia the good
thing about this is that it's really
fast to raise the bad thing about this
is that it's actually quite slow to
iterate over the data and I'll go into
why that is and second what just up my
lapel malloc
second one using a victor of indexes
referring to a victor of elements so
you've got your elements ten of them and
then you've got your vector of indexes 0
1 2 3 4 5 6 7 8 9 so when you raise your
raise from the victor of indexes not the
victor of elements and then when you
iterate you iterate over the victor of
indexes to access the elements so say
you want to arrays element 4 so you get
rid of that and the victor of indexes so
it's 0 1 2 3 5 6 7 8 9 and then when you
iterate over the data it just skips
element 4 so the good thing about that
is that it's relatively fast for
iteration the bad thing about it is that
it's pretty slow for AirAsia's because
you still get that reallocation cost
whenever you do the erasure and the
vector of indexes neither solution frees
up memory to the OS so if you keep on
inserting into and erasing from on the
fly then you're going to get a gradually
increasing container size and both of
them of course have relatively slow
singular insertion on-the-fly speeds so
the alternative that i've been working
on for the past couple years an
alternative of many definitely not
saying it's the only alternative
it's an unordered container sumter a
permissive zealand license which
basically means you can use it for
whatever you can modify it blah blah
blah so long as you don't pretend that
you wrote up it never invalidates
pointers to non erased elements it
reuses memory from erased elements and
frees them to the OS performance is
geared towards small to large classes
and structs rather than scalar types and
in the context of all those game data
requirements as faster than any
unmodified standard library container
and I'll go over what its performances
like compared to the modifications and a
little bit so what is it sort of
abstract design uses multiple memory
blocks which prevents element pointer
invalidation upon insertion
the blocks are free to the OS if they
become empty the blocks must be
removable with low performance cost and
without pointers to elements being
invalidated so for example we couldn't
use one one way of implementing a dick
for example is to have a victor of
memory box and we couldn't do that
because when you got rid of one of the
memory blocks all of the other memory
blocks would reallocate so you get
reallocation cost and also you get those
pointers being invalidated it also
records all the erased elements in a
skip field and the skip field design
itself must have allow for rather zero
one time complexity plus plus and minus
most operations so my specific
implementation of this at the moment
uses what I call a chain group
allocation pattern but you could also
call it a doubly-linked intrusive list
of nodes I prefer not to use the ten
nodes or linked lists because when I
think about that I think about singular
elements rather than collections but it
doesn't actually matter it's all just
nomenclature these contain memory blocks
block metadata and skip fields I use
peel if stack which is my own stack
implementation for recording and reusing
a raised element locations and I've
developed a basically a generic numeric
pattern called a jump counting skip
field which enables zero one time
complexity iterator operations so go
into each of those very briefly so the
good thing about having a sort of linked
list kind of format for memory blocks as
opposed to something like a vector of
pointers or whatever is that it makes
releasing the memory blocks very quick
you don't get that reallocation cost and
you don't give any pointer problems for
example if you're doing a vector of
memory blocks rather than pointers to
memory blocks there's a growth factor of
two but you could use anything typically
and the minimum and maximum group sizes
are customizable so for example if you
use the size of your keishon you need
the size of your elements then you could
set your minimum and maximum sizes to
the same amount and have them fit onto
the case a little bit better or whatever
peel if stack it's basically just a
faster stack implementation so faster
than any standard library container in
set context for non scalar types and for
large numbers of scalar types regardless
of Kampala and that includes vector and
Dec of course the performance advantage
over the standard library components
increases with the size of the element
being stored also uses that chain group
allocation pattern minimum and maximum
group sizes are also customizable so so
for all of the benchmarks that I'm going
to be presenting today vertical scale is
duration in microseconds less is better
horizontal scale is number of elements
in the container so here we're comparing
PLF stack versus standard vector there's
a standard stack under GCC this is total
time so this time to push all of the
elements into the container and then pop
them all off and read each of them also
for all of the tests that I'm doing
today
I'm just using small struts if you want
to seed results for scalar types or
large structs go to the website although
I need to update the benchmarks on there
because there in that day should be from
the beginning of the year
this is GCC 5 on the same platform same
OS this is M SVC 2015 so PL if stack
performance doesn't change match the
other ones
quite a bit so for the rest of the test
I'm going to be using GCC so how does it
get used in colony basically when
something gets are raised the memory
location for that element gets pushed
onto the stack the next time the colony
has an insertion happen the chicks that
stack if the stack is empty then it just
inserts to the back of the
if it's not empty then it pops a
location off the stack and it reuses it
hence the container is unordered because
you don't know where in the container
that element that you insert it's going
to end up so now I'm just going to go
into jump counting skip filled pattern
but before I do that I have to describe
why I can't use a boolean skip filled
instead of something else because
boolean skip fields are kind of
convenient and simple
the main problem in terms of the
standard is that if you're using a
boolean skip field then it makes your
iteration time complexity Oh random so
if you imagine you've got your skip
field 0 0 1 1 1 0 0 1 1 1 1 1 whatever
between any two non raised elements you
don't actually know in advance how many
raised elements there's going to be in
between them and that means that when
you go plus plus it might have 50 skip
filled nodes that it needs to check
before it finds the next non raised
element or it might have one or it might
have 0 etc so the standard says we can't
have them have to have 0 1 operations on
our iterators so can't do that but the
actual real problem with it
is that each of those checks on each of
those boolean nodes is a branching op so
depending on how many ages you have you
can have very good performance or you
can have really really bad performance
and it makes your code entirely
dependent on CPU branch prediction and
the other thing of course is that
generally when we're doing a boolean
skip field unless we're getting really
specialized we don't tend to do a bit
field because that fields are slower
than byte level addressing so we end up
wasting memory as well so jump counting
skip field pattern Council jumps ie the
number of consecutive arrays elements
the updating of the field in terms of
the mathematics and the programming is
very efficient
there's no branching code for the
iteration
so the iteration code becomes a lot
simpler the erasure and insertion code
becomes a little bit more complex so
this allows for time complexity oh one
operations on your iterator we're going
to go into it a little bit but you know
we don't have a couple of hours for me
to totally boy you so if you want to
know like the entire algorithms and the
whole thing there's a seven thousand
word paper on my website you can go
there and read through it and I promise
you by the end of it you will be
thoroughly bored so just a little bit of
benchmarking so this is comparing PLF
colony using a jump counting skip field
versus their victor work around with the
boolean skip field that we talked about
earlier versus a colony using a boolean
skip field so this is prior to any
Erasers happening in the container and
you can see that victor is doing a
little better the boolean colony is
doing a little bit worse so let's erase
25% of all of the elements and the
container randomly and see what happens
to the iteration speed so suddenly kill
colony is doing a little bit better and
the tool to boolean implementations are
doing much worse so let's jump that up
to 50% of all elements in the container
are erased at random unsurprisingly the
other two get worse again now let's go
up to 75% somewhat surprisingly the
other two do better in this context than
they did at 50% would anybody like to
hazard a guess why yeah exactly so if we
go back a little bit 0% erasures all of
these skip fields are just a bunch of
zeros so the cpu branch prediction works
perfectly and the boolean
implementations can actually do pretty
darn well
once you get up to 25% erasures then
basically you've got a one in four
chance of acacia mass at 50% basically
the branch prediction can't work at all
because it's just getting a completely
random stream of zeros and ones and at
75
since you go back to having one in four
chunk chance of vacation us again so
that's basically why boolean Schofield
suck so so comparison between jump
carrying Schofield the format and
boolean Schofield so basically the
equivalent jump counting skip field is
on the right the first thing you'll
notice is that no singular erasers are
exactly the same this day as ones once
you've got a couple in the road that
become - - once you get more than that
you get this sort of increment by one
notation where the first number
describes how many consecutive erasers
there are so does the last number and in
between you get a two three or two three
four or what-have-you depending on the
size of the Schofield block so I'm just
using the term Schofield block to refer
to any number of consecutive roast
elements how is this useful okay so for
a boolean Schofield has to check every
single field for the jump counting skip
field goes zero zero three jump three
zero zero four jump four etc obviously
if you're going in Reverse then you're
doing exactly the same thing and you
might be asking well that's fine but
what about you know the two three in the
middle there what's that useful for that
comes into play when you're reinserting
back into the colony later on earlier I
talked about you push the location to
the stack and pop it back off and reuse
it that's what that's for
but I'll get into that in a bit so
comparison of iteration code so in this
context we're looking at the Skip field
being separate to the memory block for
the elements which may not be all may
not be implemented that way in all cases
but just for the sake of argument we're
doing it that way in this case so you
have your pointer to your element and
your pointer to the Skip field node
associated with that element and if
you're doing a boolean skip field then
you just increment both of those check
the Skip field node and if it's one then
you loop it again a loop again until
such point as you reach a non raised
element for jump counting skip field
you did the same thing you add one to
the element point in the skip field
pointer and then you just add the value
at the skip field node to both the
element pointer and the skip field
pointer so there's no branching so
arisia from the jump counting skip field
in this case where the arrow is is
basically to denote the Skip field node
associated with the element which we
want to erase so the first thing that we
have to do is check the nodes to the
left and the right of the skip field
node and basically there's four cases
which resolve down to a single switch
statement if both of them both of the
left hand and the right hand node are
zero then that means there's no
consecutive erased elements we just set
the field node to one second example if
only the left hand node is nonzero that
means that we're at the end of a skip
field block and we update the block on
that basis similarly if for the third
one if only the right hand node is
nonzero that means that we're at the
beginning of skip field block we update
the block on that basis and if both are
nonzero
that means we're in between to skip
field blocks and we basically join the
two blocks and update them on that basis
similarly for reinsertion so this is
where we're popping a memory location
off the stack and reusing it upon
insertion so in this case the arrow
corresponds to the skip field node
associated with the memory location
which we want to reuse so if both left
and right are 0
it's just a single raised element no
consecutive raises set it to 0 if only
the left hand node is nonzero we're at
the end of the block we update the block
on that basis if the right one is
nonzero we're at the beginning of the
block updated on that basis if both left
and right are nonzero this is where that
increment by one notation comes into
play so in the bottom example there the
3 indicates how far we are away
to the left from the first non raised
element and with that information we can
find the start of the skip field block
and when we know the start of the skip
field block we also know how many
numbers sorry how many elements are in
the skip field block and we can split
the Schofield block on that basis and
update into two blocks again if you want
to see all the boring mouths look at the
paper so that's all very useful when now
you vaguely know how a colony works and
all that jazz
how does it perform so we're going to
have a deaf match gonna start with just
raw performance comparing against just
standard library containers and we're
not going to worry about all those pesky
game requirements like keeping all our
links valid and that sort of jazz so I
haven't included some of the C++ 11 long
ones like unordered map because the
performance difference wasn't that great
so I'm gonna start with just inserting
singly a whole bunch of times into each
of the containers measuring that and
that's just to measure sort of on the
fly insertion performance then going to
arrays from each of the containers 25%
of all elements at random and then we're
going to iterate over the data so not
terribly real world but just ok so
insertion performance map multi suit
most not doing so great Victor doing ok
colony and dick doing pretty well
yeah Lib standard C++ as dick
implementation is pretty good so
logarithmic scale we see a little bit of
a crunch there between 100 and 1000
elements victor starts to look alright
but for the rest of it it's more or less
dick and colony doing very well
so erasure performance linear scale
obviously this isn't terribly useful the
two standing out there dick and victor
without using the remover formulation so
we'll go to the logarithmic scale so
dick and victor without using remove
in this particular context not very good
would remove F more or less on a power
of colony map and Maltese it don't do
too well analyst does pretty well
iteration performance here we see more
CC at map and list sucking wildly the
others doing pretty well so if we go to
the logarithmic scale colony is doing
well but not as well as dick or Victor
and we see a pretty weird thing
happening with list and I in quiet
around on the GCC forums and the general
consensus was and this was basically
validated by further testing because
list iteration is essentially very
simple it's just follow this point of
follow this pointer as long as all of
your list data is in the cache then that
iteration speed can actually be very
fast but unfortunately once you get
competition for the cache or once your
data no longer entirely fits within the
cache then your performance starts to
get quite bad so the other tests I did
we're just increasing and decreasing the
size of the element being stored and
that sort of lip goes up and down
accordingly so who won that round Colony
had good insertion excellent erasure
speed reasonable iteration speed victor
had poor insertion speed poor Asia
without remover for good with removeth
an excellent iteration speed dick pretty
much the same as Victor it sipped
not quite as good for iteration and it
has a good insertion speed so whoops
skips one so next round we're going to
start worrying about those pesky game
requirements so here we're using those
two victor workarounds that we talked
about earlier a victor with the boolean
scope field and a index victor of index
is referring to a victor of elements
we're going to do sort of a similar
thing with dick we're going to have a
dick with a boolean skip field and
basically a dick of pointers referring
to a dick of elements and the reason we
can do that with dick
whereas we can't with Victor is because
dick doesn't and Val
date pointers upon insertion so same
tests insertion speed obviously the
victor ones not doing as well colony and
pointer dick more or less Nick Nick and
the boolean dick is doing quite a bit
better because essentially it's got less
to insert it's a lot simpler erasure
speed logarithmic scale
so again without remover fraught so
great with remover dick the index Victor
and pointer dick approach more or less
on a power of colony depending on how
many elements there are and the boolean
dick and the boolean vector approach
both are the best simply because you're
just flicking about so much faster
iteration speed no surprises there the
boolean approaches don't do so well
after you have arrays 25% of all the
elements colony doing pretty well but
again not as good as index vector or
pointer deck so we pretty much had the
same winners for the second round but
we've just disqualified the boolean
workarounds essentially so up until this
point all of the tests have been you
know relatively non real-world fairly
what you'd see on online benchmarks and
that sort of thing so we're going to try
doing slightly more real-world tests so
we're going to take each of these
containers and we're going to vaguely
simulate simulate thirty minutes of game
time so one hundred and eight thousand
frames assuming 60 frames a second which
is somewhere halfway in between average
gaming time for mobile NPC we're going
to basically iterate over the data in
each of the containers for every frame
and at random during each minute so each
3,600 frames
we're going to arrays and insert at
random one percent of all the elements
in each of the containers and then we're
increase that 5% and then we're going to
increase that timber see now this may
not match all use cases obviously some
games have much less things coming into
play and being raised or whatever some
of them have more but it really depends
on the karmic tot that type of game that
you've got so so this is just the total
time taken so the total duration time to
simulate that half an hour of game time
so we see here with one percent
modification Colony not really doing so
well it's got a little bit of a bump
there in the middle which I haven't
quite worked out yet but I am going to
we can also see that the remover
variants aren't doing so well which is
fairly obvious because basically with
either got 1 or 0 Eurasia's happening
per frame generally speaking let's see
what's happening with memory so we can
see that colony is doing a bit better
than the vector approach but not by that
much but it's more or less on a par with
point a deck in terms of memory usage so
at 1% modification per minute probably
not going to look at colony at least not
for a half an hour of gameplay
so let's bump it up to 5% modification
so suddenly we see beyond a certain
number of elements the other
implementations of container workarounds
start to suffer a little bit this colony
stays pretty much consistent and what's
happening in memory is at this point
because the vector and deck
implementations can't actually arrays
from their containers with or free up
their data without invalidating pointers
or indexes so they've just got
insertions happening raisers happening
and the containers are just gradually
growing so at 5%
both of those implementations are using
twice as much memory as colony and
that's consistent what's the logarithmic
scale that's consistent all the way back
regardless of however many elements
you've got in your container after half
an hour colony's going to be using half
as much memory just because of that
element location we
cycling in the freeing up of blocks so
jumping up to 10% you can see that the
other containers start getting even more
wildly out of scope in terms of
performance and you can anticipate that
the longer you run the simulation for
that sort of lip that you get there will
go further and further back down the
number of elements memory so at 10%
modification the other tui basically
using four times as much memory so
that's kind of vaguely interesting so it
looks like Colony seems to be better for
hire modification scenarios and it seems
to be doing better and better based on
the amount of modification that you've
got at least compared to those two
vector and dick modifications so let's
do an even more extreme example let's
arrays and insert a certain number of
elements per frame instead of per minute
which sounds I don't know a little bit
extreme but when you think about
something like bullets you know you can
have 100 or maybe even 500 for a more
eager bullets flying out per second and
then one minute or no not one minute one
second or two seconds later most of them
have disappeared or lodged into
something or gone off the game map or
whatever also quadtree opt read nodes
you get a lot of modification to a frame
and outside of games you can look like
heavy model modification cells like
cellular or atomic simulation that sort
of thing so starting off with 1% and
we're going to use a much shorter term
frame just a one minute of game time so
3,600 frames so this is logarithmic
scale because the linear scale kind of
looks like that we're colonies at the
bottom and the other ones are up like
that so with this really high
modification rate colony is basically
around about a factor of 10 faster than
the other ones and we can see here that
because obviously we've got a lot more
erasers happening per frame the removeth
variants are doing quite a bit better as
well I'm put up to 5% colony does better
again and 10% better again
in terms of memory usage at that point
so for 1% modification per frame colony
is using 34 times less than the other
two 5% it's using 172 times less after
one minute and at 10% it's using 340
times less memory after one minute of
simulation which is why I can't run this
simulation for more than a minute
because if I run it for half an hour it
uses more memory than my computer hat so
bottom line what is kala mean vaguely
useful for basically high modification
scenarios so if you've got a scenario
where you haven't got too much
modification going on maybe you've got
one or two the rages and insertions here
and there over the course of half an
hour you probably wouldn't be reaching
for colony but if you've got more than
one percent raises or insertions
happening per 3,600 iterations over your
data that's when you would use it so
medium to high modification scenarios if
you've got less than that if you've got
less than two percent of your elements
being inserted or arrays maybe you want
to look at one of these dear core victor
approaches but whatever you do you
probably don't want to be using boolean
scope fields in general so generally
speaking the higher the ratio of
modification to iteration the greater
the performance and memory saving you
get out of using colony and that's
pretty much it for coding more or less
that the title of the talk was colonies
performance and why you should care I've
gone into colonies have gone into
performance I haven't really gone into
why you should care and this is just a
generalized statement about thinking
about performance in computing going
back to what I was saying at the start
and I think it's fairly it's possible
that over the next 10 to 20 years we're
going to see a fairly strong performance
crunch in computing on the software side
there's a couple of reasons for that
some of them are internal to computers
some of them
or external the internal reasons we're
kind of scraping the bottom of the
barrel a lot of the time in terms of
what we can get out of our hardware now
how much we can increase the performance
if you look at the 90s or whatever we
were more or less doubling CPU speeds
every year or every couple of years but
that low-hanging fruit is gone and now
it's all down to you know more efficient
pipelining cache all that sort of jazz
and paralyzing parallelizing not
paralyzing where we can but of course
parallelizing has a fairly limited scope
to an extent so we have to kind of look
at things in a kind of context where
this is sort of what we got and we are
going to get gradual performance
increases but short of a major sort of
computing technology revolution we're
not going to get the kind of 200%
performance increases that we were
getting in the 90s so we can't rely on
hardware now to sort out all our
performance problems for us at the same
time externally in the real world people
are obviously using computers more and
more they're demanding more from them
and they're doing more with them if you
look at the 90s again everybody was
doing everything still on paper so on
faxes whatever now everything's
transitions to digital documents media
communication why because it's
essentially more efficient and the other
thing that's going to drive that
efficiency I think economically is
basically sheer sort of population
numbers that sort of thing we've got
roughly double the number of people on
the planet they were when I was born at
the same time we have some diminishing
natural resources that sort of jazz I
mentioned Google Maps earlier that's a
good example of using computing
technology to greatly increase our
real-world efficiency and use of
resources and I think we're going to
need a lot more of that over the coming
years and I think at the front of that
performance crunch is probably going to
be C++ in terms of programming because
we don't really have anything else that
accesses that high level of our
distraction and the low level
distraction at the same time and that
low level is really important for being
able to modify for different Hardware
scenarios getting access to registers
all that sort of jazz but we're going to
have to look at a lot of change in the
language and in the way that we do
computing and some of that change is
going to be hard one because now I
imagine whoever wrote this quote was
kind of pissed off at academics but at
more or less applies to any scenario
we've got a knowledge field which has
got a great level of complexity in it
and I don't think anybody would argue
against the fact that C++ at this point
has a great level of complexity and the
problem of that is that the kinds of
minds that come towards programming tend
to be very intelligent and we tend to
get very wrapped up in ourselves in
terms of thinking of ourselves as
knowing a lot the sort of jurors and I'm
not disputing myself from that at all
I'm just as bad the only problem with
that is that once you know a lot then
when what you know changes there tends
to be some resistance to change and
we're already seeing a bit of that with
SD 14 and various other movements that
are happening so my last point with that
is simply to say that I think it
behooves us all including myself to look
at the ways that we are holding
ourselves back in terms of the computer
industry and in terms of C++ and the way
we program and that sort of thing and
that's all I've got
any questions
yeah questions yep sorry eventually yeah
I want to get it into boost first if I
can
the main problem for that is basically
finding the time to work on the
documentation and get it into the boost
format I think once it's gone through
that process then I'll be in a bit of a
sort of position to write something up
in terms of a proposal I think the
biggest problem with that is really
going to be separating out what makes a
colony a colony from an abstract point
of view versus an implementation point
of view so yeah but eventually at the
moment it's just sort of freeform for
whoever wants to use it and modify it
and whatnot so yeah yeah yeah so the
question was when you modify the Skip
field structure in rare instances you
might have to update the Skip field for
the entire block for example if I mean
basically if all of the elements and the
Skip field so if all of the elements in
that particular block have been erased
but one or two depending on where the
elements that you're raising are then
you could be updating a whole lot of the
block I thought this would be
problematic but in terms of actual
implementation it turns out that it's
not and the reason for that is again
there's no real branching happening but
the other thing is that like I said
earlier when you have these blocks and
they become empty they get freed to the
OS so that takes out a lot of those sort
of big long strings of erased elements
and the other thing in terms of my
implementation of colony basically I've
got a 16-bit unsigned int skip field and
so the block sizes
Limited at max to 65535 elements and
that just limits the amount of that kind
of skip field update factor so you know
you could imagine if you had unlimited
block size if it went up to a 64-bit
size or whatever then you could end up
having to update huge amounts of skip
field nodes for a given erasure but
keeping those block sizes smaller but
still not too small because remember
we're talking about games we're not
talking about a huge number of objects
it just cuts down on what the
performance cost of that is and in terms
of the benchmarking that I've done at
least I haven't found that to be a
significantly you know detrimental
factor yeah yes so the question was are
there any other problem domains that
would benefit from this these techniques
I think any problem domain where you're
using for whatever reason a boolean
scope field binary scope field or an
equivalent you definitely benefit from
at least looking into the job counting
scope field pattern and seeing whether
that would fit into that scenario taking
into account that kind of block size
thing that I talked about earlier in
terms of the other stuff I'm not so
familiar with other domains but
basically any domain which has unordered
data which is modified significantly and
where the ratio skews towards you know
reasonable amount of mod iteration and a
reasonable amount of modification then
you're going to get some performance
benefit from using a colony yeah anybody
else yes
sorry could you say that again what are
in the skip field yeah 16 but for my
implementation but actually I eat each
element so it adds 16 but and for
unsilent for each element basically yeah
ideally and so the general question was
how much I mean basically how much
memory wastage do you get from having
that jump counting skip field there and
in terms of my implementation 16-bit but
actually I just remembered you can it's
part of the template you can change the
size of the skip field which also sorry
the skip field and signed it enter type
which also changes
the maximum size of each of the memory
blocks so for example if you only had
you know you were only thinking about
having maybe 200 to 400 elements then
you might want to change it to a you int
8 type instead of a youant 16 and then
you only get you know a byte wastage per
element yes so ideally in terms of in
terms of what you're storing you're
going to be better off having storing
something that's larger than 16 but
integer but yeah it just depends what
you're doing again for the gaming
scenario we're looking at structs in
classes so pretty much everything is
larger than 1/16 I don't so almost
things yeah anybody else yep
totally couldn't hear that sorry I do
not know the question is how does colony
behave in a concurrent environment I
would really like to know that I would
really like somebody to step up and kind
of go hey I'm gonna take colony I'm
gonna make a multi-threaded version of
it at the current point in time the
thread-safe guarantees are basically the
same as the standard library so you know
concurrent reads the fine concurrent
writes not so much I'm not sure what the
performance differences would be in a
concurrent environment but I would be
very interested to know yeah anybody
else know looks like we're done thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>