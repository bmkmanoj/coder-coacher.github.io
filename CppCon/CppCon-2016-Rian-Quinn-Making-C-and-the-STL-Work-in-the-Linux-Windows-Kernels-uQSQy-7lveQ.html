<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: Rian Quinn “Making C++ and the STL Work in the Linux / Windows Kernels&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: Rian Quinn “Making C++ and the STL Work in the Linux / Windows Kernels&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: Rian Quinn “Making C++ and the STL Work in the Linux / Windows Kernels&quot;</b></h2><h5 class="post__date">2016-10-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uQSQy-7lveQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right thank you for coming today I
will be presenting how we got C++ to
work inside the windows and linux kernel
including the standard library and full
exception support we use this for our
open source lightweight hypervisor that
leverages C++ 1114 and it's designed to
facilitate hypervisor research so I'll
go into the hypervisor just real quick
so there's some background as to why we
did this the a lot of people think that
hypervisors are specifically meant to
virtualized servers or run Windows on a
Mac it's usually the use case most
people are familiar with but there's
actually a whole field of research
dedicated towards the use of hypervisors
when in a lot of cases guest supports
not even needed a good example is
reverse engineering and here are some
projects online that we have done in the
past or at least the first one we've
done and then the other three are from
various other people I myself have
actually done this four times so using
hypervisors like Xen KVM and VirtualBox
can be extremely painful for doing
research with hypervisors especially
when you don't need guest support
specifically because they are so focused
on guest virtual machines so there's a
lot of code in there that you don't want
and they also have a lot of legacy
support which also gets in the way of
kind of doing your research so you end
up with a lot of people who start
writing hypervisors from the ground up
to overcome a lot of the limitations but
these existing open source projects and
like I said I've done this a couple
times the first one that did was in
assembly which was quite the experience
and then I wrote to others and see and
so when it came time to having to do
this again I said enough was enough and
I wanted a language that would provide
me much better high-level abstractions
but also still provide me raw access to
the hardware because I need that when
you're doing something like a hypervisor
so that I mean the obvious choice was
C++
to do that with and I wanted to make the
hypervisor generic so that I wouldn't
have to do this again so it needed to be
able to support type 1 type 2 models it
needed to be able to support multiple
operating systems like Linux and Windows
and OS X and EFI so it really had to be
this very generic type structure so the
first question that came in my mind at
least when I started the project was
alright how am I again where do I start
how am I gonna do this because I need to
be able to get C++ to run inside the
actual kernel and especially on
operating systems like Linux that is
pretty much strictly prohibited so
what's the starting point so I took a
simple application like this where it's
really doing absolutely nothing and
compiled it to do this compilation we
can't compile it with the GCC that's
sitting on your box because that
compiler is specific towards the machine
you're running it on so whether it's
Linux or cygwin or if you happen to be
using W for Windows there's a lot of
stuff in there that is specific to that
operating system so you really do need a
cross compiler well unlike cross
composite you may have used in the past
for say like developing arm applications
on a different machine this cross
compiler doesn't actually target an
operating system so you really don't see
this happening very often unless you
happen to troll the OS dead website very
often so but the advantage of using a
cross compiler like this is that when
you're done compiling the code there's
really nothing there besides that C++
code that you wanted to compile what you
get when you're done
linking in a shared library is what you
see here these are the basically the
symbols from this very very simple
example there's really nothing there so
the beauty is is that after I'm done
compiling this piece of source code with
Ag plus plus cross compiler and linking
it as a shared library and then running
read elf is I now have an elf binary
that has some C++ code that I can start
working on the trying and run inside my
kernel
so we're gonna need no floater
I've got no finery and I've got a
somehow run it so let's go let's build
an elf loader when we're looking at elf
there's two different ways that we can
view it we can either view it from the
linking point of view or the loading
point of view unfortunately if you go to
OS devs website right now and you look
up elf loader you're gonna see the
linking part and then the loading part
which is the part that they're supposed
to be describing is totally missing so
hopefully someday we can maybe as a
group go in there and clean that up the
linking side is really the part that
most of us are most familiar with when
we think of a binary executable we're
always thinking what that dot text
section that everybody's always talking
about or dot data or dot BSS for the
purposes of this presentation there's
also dot C tours and detours and then
the eh frame which I'll get to and once
again if I take that example and I run
read elf on it I can see all the various
different sections that are in my elf
binary and so this is all of them that
are in this one there'll be more as we
progress this example it's just kind of
useful information to some degree some
of it even I have too haven't done this
I have no idea what it is from the
loading point of view basically all your
various different sections need to be
loaded into memory so you can't just
take an elf file and copy in the memory
and say executed you actually have to
copy in the memory based on what this
information is telling you to do because
there are some interesting caveat so for
example if you look to go to this site
here if you look to the far right
there's some alignment information that
tells you exactly how the segments will
actually get loaded into memory and so
even though this elf file only has a
couple kilobytes and it maybe there's
how much memory it's going to take up
from a virtual memory perspective is
actually several megabytes and that's
because it's going to put the
read execute sections at the very top
then that's gonna wait until the
alignment hits two megabytes so that you
get good page alignment and then it's
going to put the read right after that
and so you need to pay attention to
these instructions and the segment's and
the way this kind of works if we go back
to this slide is like once again like I
said if you if you look at my picture
here all the sections kind of get
grouped up into segments and so what the
segments are doing is saying take these
sections and put them here take these
sections put them there and now you're
ready to run the only additional thing
that's missing is we need to do some
relocations so because we are taking our
elf file and putting it randomly
somewhere in kernel memory we have to
use position independent code which
requires that we have to actually go
through and do relocations unfortunately
don't have enough time in this
presentation to go through the intricate
intricacies of doing that but all of our
code is online and you're more than
welcome to go there and and look at it
and tell me all the things I did wrong
but in there is all that the relocation
code so we are going to do in this
example we're going to do a really
really simple one so now that we have a
better understanding of elf and we have
our little example C++ program we're
ready to execute C++ inside the Linux
kernel so we're going to do is we're
going to start by creating a Linux
kernel driver just go and download your
favorite skeleton driver off online
somewhere there's a lot of them and
allocate some read/write/execute memory
and for the purposes of this discussion
we're going to ignore the obvious
security reasons why you'd never want to
do that then we're going to copy our c++
executable into memory that memory we
just allocated and we're going to get
the address of that entry function
inside the elf binary our dynamic symbol
table will tell us where that is that's
actually a pretty simple thing to do and
we're going to add the location of the
starting address of that memory that we
allocated to that entry because the
dynamic symbol table is going to give
you the location of that symbol as an
offset to the elf binary because it's
an independent code so it basically says
I've got my binary here my symbol is
located here but because I located that
somewhere in the kernel I got to know
where that first buffer started so you
take that address you add it to your
symbol and now you've got an address
that you can actually execute so in this
example here I do that very simple math
and I run that function which if you
recall just adds 10 to the argument and
returns the result so I should see 20 as
my answer and sure enough after we got
this working properly that's exactly
what we saw we were able to actually run
C++ inside the Linux kernel which was
extremely entertaining of course if it
doesn't work the results pretty obvious
all right so that's basically it for the
elf lower side of things once again if
you have any other questions on how that
works feel free to contact me or ask me
questions afterwards be more than happy
to to help out but let's get to the more
interesting stuff that's specific to C++
all right so let's work on making the
example a little bit more complicated
now actually what's interesting is when
we first started this project just
having that much code we were able to
get almost the entire hypervisor up and
running almost and I'll explain one
problem we ran into that required this
example right here but you can actually
go and create classes you can create
inheritance you can do all that stuff
even lambda functions all that stuff
work great by just having nothing more
than an elf loader and doing some
relocation code where we ran into
problems to start was global
construction destruction now once again
if you go to like the OS dev website
they'll claim that it's optional it's
not an all explain why since we took
their word for it we ran into some
problems so global construction
destructions so if you ever wondered if
you create a class and then create an
instance of that class globally how is
it that your constructor is getting
executed and what happens to the
destructor
well it just so happens if you write
that code your compiler is going to
stick to more sections inside your elf
binary called the C tours and detours
this is a list of functions that take no
arguments and return no result that must
be executed so it's if you look at the
table it's actually gonna alignment of
eight bytes cuz I'm on 64-bit and so
it's it's literally just a table of
functions that you need to run through
and execute so this is where the C
runtime library comes into play if you
so your compilers would provide this and
I'll explain some more information on
that as we go but for us we're going to
need to create our own since we don't
have an operating system to do this for
us so we're gonna create a local init
and a local Feeny function that's going
to run through this for us now if you
were to take like GCC and look at the
Lib GCC source code you're gonna see a
CRT stuff dot C which is where this code
actually exists since we're not using
that like I said we got to create our
own and the function for it is once
again really simple the elf loader
provides the struct to the beginning of
this function and all it does is it says
here is the section that has your C
tours go to that section and executed
for each function in it and then there's
this basically the Feenie function looks
identical and then I'll get to the eh
frame stuff later also you might notice
that this code is not very a c++ core
guideline compliant that's due to the
fact that we have a circular dependency
at the moment with respect to the C
runtime and the lip C++ which we
actually can remove and so we hope to do
that in a future in which case we'll be
able to port this code so it's a little
bit more modern and more compliant one
thing I did find really interesting is
and I know now why but at the time I did
exactly what this guy is doing when I
when I had this example I said okay well
what we kind of interesting is why don't
I create a bunch of
classes that have a whole bunch of
different instantiations of constructors
and destructors and I should say this
list grow as I add more and more to them
and to my surprise that was absolutely
not the case the size of that list
stayed exactly the same and instead
what's happening is is this function
global sub I test out CPP is the
function that's actually inside that
list and then that function calls the
static initialization and destruction
and this is consistent between GCC and
clang and so what's actually happening
is is that as you add more and more
instantiations of your global
constructors destructors the size of
that function that static initialization
and destruction function is what's
actually growing what's really
interesting was what was at the bottom
of that function so this takes me back
to my example where I had a problem with
not being able to completely get the
hypervisor up and running because we did
have a couple instances of this example
right here where we had a base class and
a derived class and the derived class
had a function we then had a global
instantiation of the derived class we
didn't have global constructor
destructor support but that was ok
because we didn't do anything in our
constructors and destructors so it
didn't matter we would take a reference
to the globally defined class or
instantiated class rather and then
dereference it trying to call that
function and we would get a segfault I
was able to verify that this code is
perfectly legit I put it in a normal you
know Ubuntu as a user space app and when
you run it nothing no problems but it
would always say float with an LD
reference in our code until I got global
construction destruction working not
only was the code just easier to work
with but then in addition this started
working without a problem come to find
out at the bottom of that fancy function
it's doing relocations for you so if you
think that global construction
destruction is optional you're wrong
because there are certain instances
where that code is that function is
being leveraged to kind of finish the
relocation work and that was the same
for clang ng cc
another interesting problem that we ran
into was the red zone so once we fixed
that problem boom we had the hypervisor
up and running that happened around
November December last year didn't
really do much still doesn't do much but
at least at minimum we were able to get
a successful launch and we all had beers
and celebrated and then I decided ok why
don't we start and stop the hypervisor
over and over and over and kind of
stress test this to see if this is going
to work and sure enough after like five
or six iterations we would get a seg
fault and then you wouldn't see for a
while and you get a seg fault again so
it was very racing and it was driving me
insane
I couldn't it took forever to try and
figure this one out and so eventually
working with the Linux kernel it has a
really good OOP system so I was able to
actually diagnose this in a sane way
thanks to that I took the address of
where we were getting the seg fault it
was a null dereference and reverse
calculated the location inside the elf
file where was actually dying and was
able to attribute the seg fault to the
string length function
I had actually written the string length
function because at this time we didn't
have a standard library so we didn't
have a need for new Lib
so I we only had a couple functions we
needed so I wrote a custom string length
and being paranoid like I am i wrote the
string length function with a null check
so you literally you had this string
length function where i checked to make
sure that the argument passed to it was
not null and then I would dereference it
right after that and that code where ID
referenced it seg faulted saying all
dereference how the heck is that
possible I just checked and I said it
wasn't null so immediately in my head
I'm thinking well the only time I've
ever seen something like this is I'm
getting some sort of corruption from
sort of some outside thing you mean so
like if you're in user space do you
think multi-threaded problem right but
I'm not in user space I don't have
multiple threads but I am in the kernel
and kernels have to deal with interrupts
all the time so immediately after I
thought about that I said okay maybe
there's an interruptus firing that's
correct
the stack somehow so I typed in that
into Google and surprisingly oh and then
of course I added OS dev that always
helps and surprise him there happened to
be an article that talked about the red
zone and a whole bunch of other people
who have suffered the same pain I just
did so the red zone is an optimization
to System V so if you're and if you're
on any system other than Microsoft
you're using system V and what it does
is it basically says if you're a leaf
function so they give it like a you know
a tree a leaf function would be the the
last function being called in the stack
until it starts unraveling so a string
length function is a good example of
this because it doesn't call another
function therefore it must be a lead
function all leaf functions within
system V do not need to advance the
stack pointer so it's an optimization
that the compiler can put in to save
some instructions and since there's a
lot of leaf functions inside your code
that's a pretty decent optimization the
problem is is not compatible at the
kernel because if an interrupt fires the
interrupt on x86 uses the current
existing stack pointer as the location
for its stack and therefore since you
didn't advance the stack pointer inside
your code when interrupt fires it starts
corrupting the stack for the code that
was running there and so anybody writing
kernel code has to turn this off so if
you look at like the Linux kernel flags
this is the first like flag they have in
there because I'm sure for the same
reason some kernel developers like
what's going on so the really annoying
part here though for me was that I went
to my command line and it looked at you
know my flight so that was passing into
GCC to say okay please stop compiling
with the no red zone by adding this flag
and so then I read compiled on my code
and it's still crashed and I'm like how
is this possible I know it's got to be
the red zone so a couple hours later I
said okay I what if I turn the string
length function into a non leaf function
so it's an interesting but very simple
test I basically created a do-nothing
function and I called it from within
string length therefore the compiler
couldn't assume
that it was a leaf function unless it
optimized it out which thankfully didn't
and therefore it would have to advance
the stack pointers inside a string
length because it was calling a
do-nothing function that function its
stack and get corrupted all day long
because it's not doing anything with the
stack so it just whatever and I ran that
and sure enough it stopped crashing on
string length of course I started
crashing on the next leaf function in
the code and since there's hundreds of
thousands of them in it you know well
probably the hundreds of thousands of my
example but there were a lot of them so
but at least it proved to me that the
redzone had to be the problem so a
couple more hours of banging my head
across a table
I realized since I'm coding in C++ and I
had put the know red zone flag in GCC I
was using the wrong compiler and I just
had to change it to G plus plus and that
was good to cap off oops
alright so I've got a working hypervisor
and now I've got a reliable one so what
about the standard library I'd really
like to be able to do this code up here
like do a standard C out and have the
output dump out to the serial port I'd
really like to be able to use standard
vector now I'm standard vector big no
big deal I can create arrays and C all
day long but a map that's a different
story that's not fun to do yourself or
hash table or a lot of other things so
I'd really like to have the standard
library the two biggest ones out there
Lib C++ and Lib standard C++ there's a
lot of other ones more esoteric in
nature but most of them made there have
either been abandoned at this point or
they don't support C++ 11 / C++ 14 and I
really wanted to be up to date the last
thing I want to do is start a project
that's already in the past so those are
the only two I get basically I start
since I was using GCC at the time I said
well let's stick with GCC and that was a
total nightmare Lib standard C++ and C++
are very tied to GCC but more
importantly they're very tied to the
operating system
your choice and they don't like
compiling against cross compilers that
don't have the middle of the target
defined right so I'm doing x86 - elf and
normally you would say x86 - Linux - elf
because I'm missing that that Center
argh
really gets mad and there are a lot of
other people who have shared my
experience so Lib C++ it was it's
actually pretty easy to compile to some
degree I'll explain some complications
we ran into once again it supports when
I wrote the slides C++ 17 wasn't his
support is is now so it goes all the way
up there it can be compiled without
threading support or exception support
which at the time for us was extremely
helpful
now we support both sort of and it works
well with both GCC and clang which was a
must since at the time I was using GCC
and it works well with new Lib which was
important because it really didn't want
to write my own C just to get this in
there there are some disadvantages to
start there are some functions in Lib
C++ that are kind of stack heavy and in
the kernel especially in the Linux
kernel which is insane with an 8k stack
some of this stuff can cause a problem
we do have a workaround for it it's an
ugly one but it works there is also some
annoying things inside the code for
example I tried to use an unordered map
so like I'm all excited I get to use a
hash table inside my code I don't have
to write it myself except when I tried
to use it
I found an undefined symbol and it was
because I'm not linking in the math
library since that we really shouldn't
be using floating-point and divide
module inside the kernel so this the
unordered map wouldn't work and looking
at the source code this is why if you
look at the source code here they're
trying to do some integer division and
normally integer division would round
down and in this particular case they
wanted to round up so first they convert
to a float then they take the result and
seal it well there's actually a better
way to do this that doesn't require you
to do the floating conversions so I'd
really like hopefully they'll accept the
PR for me but changes this because I'd
really like to get this in there
there also is an annoying issue with new
Lib new Lib like GCC really wants you to
define that operating system so since we
don't it won't spit out a shared library
which leaves me in a very uncomfortable
position because if I am compiling Lib
C++ and live C++ comes with this other
library called Lib C++ ABI which you
also have to have in there I would end
up with potentially duplicate symbols
because if I have a static Lib C and I'm
statically linking those two Lib C++ for
two different libraries if they share
similar symbols then you get duplicates
and it might work like nah I don't know
I don't want to try so the alternative
was to compile Lib C++ ABI as a static
library and take all the static
libraries and statically linked them to
Lib C++ that actually works it's not
supported by the Lib C++ developers but
it does actually work in the end the
reason why they don't support it is that
during the linking phase it might
optimize out symbols that aren't used
and we actually found one of them it was
for the for exception specifically so we
do have to add symbols back if they're
optimized out by the compiler so I'll
talk for a future work we do plan to fix
this by implementing our own Lib C
specifically for Lib C++ and I think it
actually could benefit more than just
our project because I've actually talked
about this with several people and they
all share the same pain another issue
with live C++ was how to compile it and
so once again like I said it could be
compiled but it wasn't necessarily the
most pleasant experience my colleague
and I both actually attempted to do this
simultaneously he tried to get it to
work with C make and since I like to
brute force everything in life I just
basically started hand compiling each
source file by hand and actually got to
work in a couple hours so I knew it
could be compiled of course my
colleagues approach was far better so we
continued to work on trying to get C
make to actually work to do this you
need to use C makes cross compilation
tool chain where you basically
say what platform you're trying to
compile for and of course it says you
can provide you an eric or none or
something like that but that never
worked i actually had to say linux to
get it to do what i wanted to and then
you provided some other things once the
the two most important things to notice
from this slide is where i'm defining
the c compiler and c XX compiler
everything else is kind of you know you
can look at it it's not that big a deal
so when we tried to actually get c make
to do this when we gave it that cross
compiler the problem that we ran into
was c make would come back and say I
can't find lib sup C++ or Lib standard
C++ whatever the the GCC C++ library
couldn't find it I'm like well I'm
across compiler number one so I don't
have that number two
I never compiled that so of course you
can't find it why are you even asking
for that library you're being
cross-compiled well there's this nasty
thing that I I learned and it's like one
of those like feelings where as you're
learning more and more you're like oh my
god oh my god I can't believe this so if
I don't know how many know this but if
you compile a simple hello world program
normally you're gonna give it a dash C
that tells it to create an object file
and then you're gonna take that object
file you're gonna give it back to your
compiler and without the dash scene it's
gonna link them all together and spit
out a fancy executable so even if your
executables as simple as that one
example I had before
what spits out is gonna be pretty big
and the reason why is that just to run
that little tiny application your linker
has to go and add a whole bunch of stuff
to get it to execute on that operating
system so that includes all your
standard libraries like Lib math and Lib
C and Lib C++ there's usually a bunch of
header files that the compiler itself is
trying to sneak in there and there's
also your C runtime which should bunch
of static libraries that it's also
adding as well as your Lib GC Lib GCC
which has a bunch of other fancy stuff
in it so when you look under the hood as
to what to the
making face your compilers going through
that's what it's doing all those extra
Ari's is exactly what I just said so for
us because we're essentially creating
our own operating seven really not but
it we're playing like that we have to
essentially
do this on our own so once again I went
to OS dev I said okay what does OS to
say about this well the first thing they
say is you need to create a OS specific
tool chain and what they do is they say
ok here's this in GCC
here is this giant string that lists out
all the stuff that you just saw in that
command line so when you go to compile
GCC itself has this nasty thing that
basically somebody filled in and what
they're telling you is you need to take
GCC and patch it with your own set of
arguments to that list I mean nobody in
their right mind would ever do that
first off why would you want to patch
GCC for every version of GCC that you
have alright I want to patch my cross
compiler and second off I mean can you
guys read that question excuse me
doesn't work oh yes thank you so the
question was why is it when you ask - no
sed lib why doesn't that work I don't
know it just basically ignores your
command I tried and I would add that
flag and the standard Lib would still
show up in there so the question was
where the reference is the operator new
and operator delete in this particular
case we were trying to compile see make
and it's running through the
configuration scripts so it's basically
trying to take your compiler and verify
it what features are supported which
features aren't and so I don't have
control over that it's it's going
through the list of you-know-what
features can I do and what can I do and
as soon as it can't find a standard
library cuke slow over itself so another
option I have is to manually link
everything myself that's actually what
we had been doing up to this point right
we had been manually running LD if you
noticed I wasn't linking with my own
compiler was linking with LD
specifically the problem with this is
that C make doesn't allow you to do that
they give you these nice two little
flags to set which compilers you want
but they don't have the equivalent for
LD and if you go to that link that I
just provided you'll see a whole bunch
of people complaining about the same
problem and C make basically says well
why on earth would you ever try to link
manually it means you would have to know
what all of those crazy args are to get
it to work on your platform so you
shouldn't be doing that you should
always link with your compiler that's
the rule right and so you know that
meant that we couldn't do that so the
winning option for us was to create a
custom bash script because some bash
script basically acts just like that
giant chunk of string stuff that you saw
right it takes if you give it a dash C
it takes all your arguments and passes
it right off to GCC or G+ plus if you
don't give it a dash C it filters all
those arguments just like G plus plus
will then combines all of the shared
objects that we have or sorry static
libraries that we have and we need like
the C runtime that we just created and
compile or sort and passes that to LD
for you so it's literally doing the
exact same thing that GCC is doing but
it's doing it without a patch to GCC
which is important right so what this
means that I can now use any version of
GCC I want and I can also support clang
it's a much cleaner solution and and all
the dirty hacks that we had to go
through to make this environment work
are now self-contained in one nice
simple bash script that I can comment
that's really nice and simple to use so
I know it's it's ugly to script your way
out of these problems but in this
particular case I love this solution
all right so dynamic cast at some point
we wanted to try and get dynamic cast
working and I figured dynamic cast was
built into C++ it's not it's part of the
standard library so I will miss them the
hard way
if you go back to our original example
when we created that test app you might
have noticed that some of those symbols
are labeled weak and some are labeled
global so what is a weak variable well
if you happen to be compiling in such a
way where you've got a whole bunch of or
you've got one symbol is to find a whole
bunch of different times as long as you
have one that's labeled global then the
elf loader knows when it's doing its
relocations and such the the global
symbol is the one that it needs to
choose that's the address that it needs
to give to everybody else this is how
new and delete work you can globally
define new and delete operators yourself
and that's how it's that's how this
works in your standard or in the
standard C++ library operator new and
delete are defined as weak that way in
your code you can define them yourself
and since you're not defining them weak
it's gonna replace the code for you what
happens if every single symbol that you
have is defined weak and your areas no
global one well this code here that you
see for dynamic casts will fail in my
particular case in the normal case no
because I did something wrong so I
figured well I this code here is from
Lib C++ ABI so I figured okay this code
here is failing that's on my code let me
go file a bug so the Lib C++ developers
were extremely patient with me very
helpful and they basically said no no
that codes been there for a long time
we're pretty sure that works really well
like I don't know I'm seeing this
problem blah blah blah and so he turns
on goes well have you taken a look at
section blah blah blah blah in the
Itanium spec no and so there's this
one-liner in the spec that says if all
week variable
our week then you need to pick one and
across all shared libraries that same
address needs to be used across all of
them specifically for this problem so
that way pointer comparison can be used
when you're doing things like checking
type info probably for other reasons too
but that's the reason it bit me all
right
so onto exceptions this was the really
fun part so we've got a hypervisor we've
got all this crazy stuff working but in
the back of my mind there's two things
that are always haunting me the first
one is the fact that I'm using floating
point and division inside the kernel
which I'm sure a kernel developer will
want to do very bad things to me for the
second thing is that the STL is designed
to use exceptions
now I understand you can pass the no
exceptions flag and then supposed to
blue exceptions are turned off but in a
lot of cases yester turned off but you
don't get the error because the API
wasn't designed to alternatively give
you an error code so it just fails it'll
call standard terminate and bad things
happen so you're really just putting
your head in the sand if you use this
flag you better know that there's
certain things in the STL that are not
going to go well for you since we're
running a hypervisor I really didn't
want that situation so I said well why
don't we try and get exception support
to work we've already got C++ on the
kernel why not add exceptions so let's
look at how unwinding works all right so
if you're writing code
traditionally without exception support
the way this normally works is you're
gonna call a bunch of functions and when
you get down to the bottom an error
might happen and so what you're supposed
to do is return the error and the person
who called you supposed to check Oh an
error happened he's gonna take that he's
gonna return the error and the person
who called him is gonna check that and
say oh an error happened he's gonna
return there and eventually it'll get
somewhere where it can handle that error
and it'll do something with it
exceptions are doing the exact same
thing for you they're bubbling that
error up they encapsulate an exception
and then eventually get to a catch block
and it deals with it
exceptions can be broken up into three
separate layers you have layer 1 layer 2
layer 3 the first layer is what
everybody is used to so you say throw
did runtime error the answer should have
been 42 the second layer is what the
compiler is generating so when you see
that throw command it actually creates
these symbols so if you were to do a
disassembly you would actually see this
right here and you can actually see the
spec for this or the code right at that
link I provided since layer 2 is
supposed to be architecture independent
it needs to call 2 layer 3 which is
really defined by the attain iam spec
and in part by the system D spec to say
this or basically which ends up calling
is unwind raise exception which goes and
does the dirty work of actually
unwinding the SEC there are already
stack and winders out there you have one
in Lib GCC which I think include OS is
using you have Lib unwind from Google
and you have Liv unwind from apple it's
an unfortunate case where they have the
exact same name so actually and I
believe the live unwind that Apple had
was donated to LLVM so it's there if you
want to see it the problem is they all
share something in common and that is
they were all expecting to be run in
user space so they're not necessarily
written in a kernel safe fashion they're
also they use certain functions that
would normally only be exposed in user
space no the reality is is someday we
want to kind of go in a similar
direction but we were able to write one
without need for that so our current
unwinder that we have right now has no
dependencies it's it can be compiled
without having to link any libraries to
it or include any libraries to do it we
needed four different specs the dwarf
spec the LSB spec which is for Linux and
really all the LSB spec is doing is
adding a couple things to dwarf to
support exceptions because dwarf was
really meant for debugging the Itanium
spec and the system of e spec all right
so a member in the
very beginning of this presentation I
talked about this eh frame part so
that's where this comes into play
the elf loader in or your elf binary has
a section called eh frame and your elf
loader is gonna need to basically record
the location of that and it in our case
it provides it in that same struct and
this function call is providing it to
the unwinder because the unwinder needs
to know where are these eh frame
sections in each shared library that you
have this section is where all of your
unwinding information is located so if
you ever wondered why when you turn
exceptions on and C++ the executable
gets so big it's because every single
function you write needs in addition to
the dot text section to describe the
actual function and assembly it also
needs an FTE located inside this section
that explains how to unravel the stack
so every single function has an
additional section in here so you can
imagine how the code would balloon
really quick now thankfully at least
these FTEs are compressed so that's why
the door spec does the door spec
basically describes how to compress all
the logic necessary to unwind the stack
so that those FTEs or at least as small
as I can get them but there are a lot of
them in there what you basically have to
do is when an exception is thrown you're
going to be given the instruction
pointer of where the exception was
thrown you're going to take that and
you're going to go search through that
entire list of all the FTEs and you're
gonna look for in this list of FTEs
where is the FTE - describes the
function that I'm currently located in
once you get that it'll tell you
somewhere inside that FTE or your
function how you need to unwind that
stack when you get to the top of the
function in the FTE
what you're going to get is a return
address that return address is the
address that would normally be used to
return to the function that called you
so you're going to then repeat this
process so you start with instruction
pointer that instruction pointer
he says you know you look up the FTE you
decompress the dwarf code and that tells
you where your return address is from
there you look up the next fde with that
return address and that points you
somewhere in here and then you unwind
the stack again with the dwarf code and
then you take that return address you
find the next fde and you keep doing
this so this is why exceptions can be
generally slow because if you were to
not use exceptions you just return an
error code and there's no searching that
has to be done with exceptions because
it's doing all this work for you it has
to go through a list of all these FTEs
every single function call to find the
FD associated with what needs to happen
now there are optimizations for this for
example normally in Noora code there's
actually a hash table that's used and
there are other ways to minimize the
size of the table but in general the the
difference is because it's doing all
this work for you it's got to do
additional work under the hood to try
and figure out how do I get how do i
backtrack that stack now the the the the
next hardest part about this function is
just that at some point you have to know
when to stop alright so some point you
got to know okay I've searched when do I
actually stop and the personality
function is what's doing that now the
personality function is in part provided
by the ABI it's also provided by the
compiler or at least the information
that that function needs is compiled
provided by the compiler that basically
says every single time you get to a
certain spot you ask it have I found a
catch block yet have I found a catch
block yet how they found the catch block
yet it's actually a bit more complicated
because in addition to catch box it also
has to deal with ra íí- so what really
happens is that sometimes it'll say no
no pretend I found a catch block and
then it will go and handle the
destruction of our that all the ra íí-
objects and it'll Reath row the
exception so it can continue it until it
finally does get to a catch block so
that's how it's handling things like GSL
finally and basically that's exception
support now the only unfortunate part
about this is if you happen to know the
name of the function it's called phase 2
and that's because you have to do this
operation twice which was also crazy
when I first saw it but
there's an explanation on at least the
spec as to why but yes so not only does
it have to do all this work but every
single time you throw an exception it
does the work twice so that's how I got
a C++ to work inside the windows and
linux kernel now with respect to our
project because we are using C++ we are
able to better utilize a lot of the
newer technologies that are out there so
we actually have a hypervisor now that
currently utilizes Travis CI with a
complete set of unit tests we have at
Bayer support for Windows we leverage
coveralls as well as Coverity scan
client ID for our compliance and Google
sanitizers for our dynamic analysis and
the CII best practices we also use the
GSL and the core guidelines now this is
an area where I could definitely use
some health of anybody here who's better
with C++ than I am wants to contribute
this is one area we could definitely do
better in but we do have the GSL in our
code base and we are passing all the
client ID 3.8 checks
- reinterpret casts since I'm in
hypervisor in the kernel I dare you to
find a way to get rid of that and we do
have support for GCC 5 6 C++ 1114 Iong
3/8 or sorry 3 8 3 9 should be coming in
next couple of days I actually I've been
working on this laptop so for future
work we do plan to support OS X we have
Linux and Windows right now we also do
plan to support arm so that'll be kind
of just in getting c++ working in the
linux kernel on an arm device and I
think probably more interesting would be
the fact that since we want to support
type 1 we would like to be able to get
this environment working in UEFI which
means that if I combine it into a script
I can statically compiled of everything
you should be able to generate C++
applications for EFI generically what
should be I think an interesting project
for people who are doing stuff in UEFI
and don't want to be stuck with C we
will be adding extended API support and
hyper kernel extensions so because
everything's written in C++ we can
extend
the hypervisor using inheritance and
since we support shared libraries that
means that I can add more libraries to
the codebase so I can actually take the
bare minimum hypervisor and leave it in
one repo and then I can create another
repo that has the extent of API s and
another one that provides guest support
so that allows me to accomplish my
overall goal which is that I want a
hypervisor that can work for researchers
that doesn't provide a bunch of stuff
that gets in their way
but then if somebody does want to do say
guest support in the future we can still
support that without cluttering the base
hypervisor so it's a very modular
architecture which is nice we also do
plan to support include OS in the very
new future which I think will be
absolutely awesome because that means
we'll have a C++ hypervisor and a C++
you know kernel I mean it's a C++ that's
awesome and we also do likely plan to
provide a custom Lib C to get around the
new Lib issue which I think will likely
be a separate project because I do
envision other people benefiting from
this it would basically be a Lib C
specifically geared to support Lib C++
because Lib C++ only needs a couple
functions at a Lib C so I don't need to
implement all of it I just had to do
this small subset which I think other
people could benefit from - other than
that that's my presentation question so
the question was why didn't I create an
OS specific toolchain for the hypervisor
itself there's a couple answer to that
first off new Lib won't accept any
target other than Linux and I think one
other they could heard is the other one
so even if I created an OS specific
toolchain for the hypervisor to deal
with the not needing the bash script I
would not have solved the new Lib
compiling as a static library the
however being able to get rid of the
bash script sure if somebody wants to
tackle writing that disgusting string
thing for us I'd be more than happy to
accept that down the road I also
wouldn't mind you know putting that in
there but I'll be honest that we we do
have a really big hurdle in front of us
which is that if I was to say pitch
something to GCC to say please accept my
patch to your compiler to support this
hypervisor I'd have a whole bunch of
Linux developers asking me why are you
putting C++ in the Linux kernel so at
least right now being a separate project
and I'll have to deal with that too much
other than the fact that now that I
presented this
probably a whole bunch of people
spamming me but yeah that's that's
basically the short answer to that
question well it was actually a very
good question yeah okay so that's a good
that's another good question so um how
am I getting this to work on Windows so
Windows uses the MS 64 ABI all of this
code is compiled using my cross compiler
which spits out system v I don't change
that now the we do have an a user space
application in our repo for talking to
the hypervisor that's native C++ and so
that compiles in Windows just fine right
now we support cygwin but we will have
some support in the near future for
Visual Studio to compile at the driver
and that user space app so the question
though is that all the cross compiled
code that gets loaded into the kernel
how exactly do I execute that in Windows
and the answer is I have a very slick
piece of assembly that does all the API
conversions is I call in to my system v
code and back out and so I actually do
all that by hand that code doesn't that
code preserves all the registers
including all of the SSE in registers so
I can actually do oh three optimizations
inside the hypervisor which does work
and it handles all those API conversions
so that's I'm running in kernel space
and I'm running and the windows case I'm
running Linux applications essentially
using system v inside the Windows kernel
so once again I don't think they'd be
very happy about that either but it does
work question thank you it's a great
question how did the question is how did
I deal with only having a K stack in
Linux so at first I yelled and screamed
for a while because that definitely bit
us in the butt when we were having
problems with the hypervisor loading I'd
built one really big function that
printed out the entire DMC S which is
the fancy name for a hypervisor thing
and that would seg fault and I wasted
easily two days on this problem later
figuring out that I was corrupting the
stack because that was over running it
like mad and so I basically reduced the
size of the function got rid of the
problem until it bit me in the butt
again like a week later so finally I had
it and said we gotta solve a stack
problem so inside that fancy assembly I
also take a piece of dynamically
allocated memory and overwrite the stack
pointer so when I jump into my code I'm
actually running out of my own stack and
then when yeah I was I know they're not
gonna be happy about either and then
when we called back to the kernel I put
the stack pointer back in place now one
interesting thing is that Linux actually
has a flag that if you compiled when
external with when an interrupt fires
it'll actually check to see if the stack
pointer is off in the middle of nowhere
and since we are off in the middle of
nowhere it throws a warning message out
on your screen and the form of our
kernel oops it's really a benign error
message but it is detecting the fact
that I did that
so yeah you can't do that or at least
that's how we solved the problem but
you're really not supposed to do that so
the short answer is if you don't want to
have that ugly hack in there then you do
have to be gentle with the stack inside
the kernel or complain the Linux and
tell them to put a realistic kernel or
stack size in there because 8k is
obnoxious
actually be honest I haven't tried that
that's a great question I don't know
I'll have to give it a shot
let's go over here question don't forget
to your question for a couple reasons my
colleagues would say oh the question was
why didn't I
natively get the C++ code to compile
into the kernel instead of loading an
elf binary bringing it that way so my
colleagues would tell me it's because I
have absolutely no idea how to actually
work inside the Linux kernel but the
right answer is that I don't know if I
could do that in a cross-platform way so
I mean I might be able to get Linux to
do it I know people have tried but
getting it to do it also in Windows and
also in OS X which would be even harder
I probably could do it in UEFI probably
could do any a fine but OS X and Windows
that would be extremely difficult so and
then in addition trying to get the STL
on there so by loading my own modules
not only did it give me a modular
architecture which also was a huge
benefit to doing that but then it gave
me a really simple way of handling the
cross-platform aspects now there is one
big disadvantage to this and that is
that from a researchers perspective you
look at some of the projects they like
to call into kernel functions from their
code when they're doing research with
like say reverse engineering and because
I'm sitting in these modules you can
view the execution of my code as
independent I can't see back into the
operating system now the reality is
since I'm running in a hypervisor and
and ring- one a lot of times you really
can't call into the operating system
safely because you're at a really high
req but some people like to ignore that
and I'm not gonna complain because I
clearly like to ignore rules too
the question is have may have been in
touch with the Linux kernel community
and what was their response to our
project the answer is no I'm pretty sure
I know what the response to that
question is gonna be although I did find
it surprising we did advertise we
reached out to the author for Onix and
he was very nice to reblog what we were
doing and there actually was a
surprising number of people who were
very supportive of our approach and
people who were working the Linux kernel
who have all shared similar frustrations
with only having access to C so that
part was at least nice but I mean come
on honestly Linus is not gonna be happy
with what we did here correct we're
loading so the question was how do I
deal with the fact that C++ has a lot of
stuff that would potentially get paged
out in the kernel and the answer is yes
we load everything in on page memory so
right it's a hack I've been doing for
you it's not necessarily a great
solution of the problem but it works
really well it the the the issue with it
the reason why you wouldn't do that or
don't want to do that is on memory
constraint systems you have a lot of
wired memory because you can't get it
back
question surprisingly pretty simple the
I can show you here oh so the question
is how easy would it be for me to do
this on my own if I go to my website and
try to use this from here so
if you see here in our entry code right
here this would normally execute this
code which is our actual hypervisor or
the launching point of our hypervisor
but here I can add in any C++ I want and
I can run it and I can get my result so
that's standard out in the Linux kernel
so the answer is it is somewhat simple
in that aspects you basically just need
to use my existing entry module and a
couple others and then you could start
writing your own modules for this and if
you do have any problems just reach out
to me and I'll help you get started
question yeah you know you and me both
so the question was why did I have to
use the Itanium spec in so many
different instances and I don't know go
online and google it because there's a
lot of other people with the exact same
question but for whatever reason stuff
that we're using for system V is showing
up in Itanium 64 spec for C++ there's
actually a lot of Itanium stuff for a
C++ that shows up so I have no idea
other than the fact that they did it for
that architecture it worked for system
beam so they said why change it it was
mind-blowing to me to is like I can't
believe I need this I need four specs to
write an unwinder that's ridiculous
question so the question was what makes
getting all this stood up for a
hypervisor more complicated than an
embedded system so normally for I hope I
got your question right but for a
foreign bedded system creating all the
cross compilers normally you're going to
specify your operating system type when
you do it other than that you're
probably going to run into a lot of
these exactly
problems in fact that's like it Alfred
from the include OS has run into a lot
of these same problems and yeah you're
gonna have basically the same exact
issue you're gonna have to create a
cross compiler that can go and compile
your code and then from there you're
gonna have to have some sort of linker
they can then get your various different
shared libraries linked into your
application and executed so with whether
you're creating a unit kernel or whether
you're creating a standalone application
for embedded device it's the same
problem my best advice is that if you
can you know use I mean you're more than
welcome to use anything out of our repo
it's all there and you can statically
link it and run all this but there's
also you know other projects specific to
embedded devices and might may help make
this a little easier there's no
operating system there's no nothing so
there isn't I mean we're instantiating
that exact same environment inside the
kernel so you could use what we're using
here to make that work
so the I would say the steps to do that
are basically going to be very similar
to that of a unit kernels you know
kernels exactly the same thing right
view the unit kernel is I've got bare
metal it's really a virtual machine but
I got bare metal that I'm really trying
to talk to and I want to stand up a C++
environment and so how do I do that
it's the exact same problem we kind of
did the exact same thing here where we
had to try and stand up that C++
environment inside the kernel like it
we're running environmental so a lot of
the stuff that we did here would apply
to your problem space any more questions
question it doesn't it absolutely
doesn't so went and what's just seen in
next couple of months is when we go to
do this on UEFI that's that's exactly
what will happen so we'll stand up this
environment you get to work on UEFI
which is bare metal
excuse me correct
it's just a bootstrapper to get it going
that's exactly what it is in fact
actually that my title for this
originally was how to bootstrap C++ in
the window and they said well my people
aren't interested in that word so they
changed it to work just fine any other
questions I really appreciate you guys
coming thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>