<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: Tim Shen “Regular Expressions in C++, Present and Future&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: Tim Shen “Regular Expressions in C++, Present and Future&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: Tim Shen “Regular Expressions in C++, Present and Future&quot;</b></h2><h5 class="post__date">2016-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/N_rkHzhXueo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so how everyone will come to this if you
become my name is Tim Shane I'm from
Google LLVM T so I'm doing the compiler
work but I'm also maintaining live STV
C++ reactive dragons library as part of
my officers contribution so today I'm
going to talk about regular expression
implementations so before proceeding to
the actual talk let's look at the
several annotations so for to post we're
going to use parentheses for lists we're
going to use square brackets for sets
we're going to use curly braces and for
maps we may use arrows all right so a
while ago I saw this Stack Overflow
audit that is caused by a regular
expression so the regular expression
matches one more characters or or more
characters so it's a fine expression
write an expression even if it's a bit
redundant but Stack Overflow used a
backtracking rag exchanging and which is
problematic because it results in all of
N squared behavior and all of N squared
and square behavior is sufficient to
take down Stack Overflow for a while
alright so we'll come back later to see
why this happened in this talk I'm going
to introduce the data structure we use
for compiled read X and the four
different algorithms that drawn this
data structure after that we should be
able to understand why Stack Overflow is
taken down and after that I'm going to
talk about three regular expression
features that you should be aware of
because they slow down your program and
how it should you deal with them last
but not least I'm going to talk about
two changes I wish to make into the
standard so that we have faster and
easier to use regular expression library
all right
so why don't we look at the compiled
regex representation we call this
non-deterministic finite automata you
can find the formal definition from any
computer theory of computation books so
I'm not gonna repeat that here instead
I'm gonna show some code examples to
help you understand that so a nfa is a
directed graph and the nodes or the
states by the way I'm going to use state
in the node interchangeably here because
they are the same thing in the context
the state stores data including the type
of the state and optional data members
for each each individual type and of
course successors so the state types are
like except type match type the sorry
accept state match state out state
alternative state and repeat state each
of these type represents a regular
expression feature and there are a lot
more than these ones but we're focusing
on accept state and match state so why
don't we look at the example of the
simple regular expression a B so the
graph is dumped by Lieb STD C++ regular
expression debug info so it's the real
data's in generated by the library so
you may safely ignore speaking and SN
here those are just a different notes
for implementing capturing groups and
here our focus is state one and state
two those are blue because those are
matching states and they match a and B
respectively
so step 5 is the accept state which
indicates a successful match so the
second the second example I'm going to
give here is aid or B so the alternate
operator creates a diamond structure
that starts from 6 and Forks into state
1s state 3 and finally converge to
whatever comes up
that which happens to be state 7 which
is SN but it can be anything that's
after the sub-expression the third
example is repeat a it creates a loop
structure that starts from 2 &amp;amp; 4 0 or
more times it enters 1 and come back
comes back to 2 then it exits to state 4
similarly state forest just whatever
comes after the sub-expression all right
so this is an interesting example we
have a question mark repeated four three
times and a repeated four three times
notice that a question mark means the
optional a so we either match na or we
skip it so it creates a triangle
structure and we concatenate this
retrying of structures and three
matching states together this is
interesting because from zero to state
11 which is the accept state in total we
have eight different paths that means we
have two to the power of three different
paths because at state 1 3 5 we have to
make individual decisions and those
decisions combine to eight different
scenarios which is exponential and we
will come back to this later to see how
does it slow down or overdose and the
final example I'm going to give you is a
compound the example that shows how
different structures can compose so on
the top level we do a repeat structure
and the sub graph for the repeats graph
is a alternate operator which Forks into
state 2 which is matching a and stay for
me which much is B those two states come
back to 8 when eight it exits it exists
to state nine which matches C all right
so let's talk about regular expression
matching algorithm a regular expression
matching algorithm takes a red X and a
target string in our example the target
string is a BAC so the algorithm is
supposed to find a path from 0 to 12
which is the accept state such that all
the matching states in a path in the
path matches all the target characters
in the target string for example if we
have such a path from 0 to 12 we have
matching States to 4 to 9 they are in
order and they are matching a BAC and
that's what we are going to match in the
for the target string all right and how
do we find such a path there and the
first algorithm we I can come come up
with to find a path is depth-first
search
it's the textbook or within it traverses
the graph in a depth-first order
so why don't we just go through a
example so it's the same example we
start from 0 and we can proceed to eight
without consuming any characters our
current target character is a because we
start from the beginning of the Travis
trip and we proceed to seven not notice
that at eight we have a choice between
proceeding to seven and nine and we go
to seven first because we are using this
great greedy strat strategy for the
repeat state greedy strategy is defined
by many of the popular flavors of the
regular expression for example
JavaScript style or Perl style so we go
to seven first then we have another
choice between two and four and we go to
two first because we go to the left-hand
side of the alternate operator first
defined by the sum of the flavors so we
go to two now we are going to find a
match here because we expect an A and we
do have an a character in the target
string so we find a match and we proceed
to repeat state so we've got a seven
again and we go to two unfortunately
is a match for this time so we backtrack
and then we proceed to four which is a
match again so we go back to eight again
we go through seven you go to two
yes this time it's a mesh so we go back
to eat again we go to seven and we go to
two it is a match so we backtrack and we
would go to four and it still doesn't
match so we keep backtracking until we
exit the repeat state and we find state
in our line matches the final seeking
now we proceed to eleven and finally
twelve that's how we find a path that
consists of all the 30 characters so
that's the match that's a successful
match and why don't we just look at the
code it's not it's not hard so first we
check if our current state is accept
state if so we just return true because
that's more or less by definition then
we check if the current state is match
state if it is match state but the
target character doesn't match our
expectation then we should early return
false without proceeding the to the next
state if it is a match state and the
characters match we should increase the
target iterator the target pointer here
so either it's a match state and we with
our target pointer increased or it is
not match and we shouldn't increase our
target in order we can proceed to the
next step which is recurring on the
successors if any of those recursive dfx
DFS calls returns true ok say favor
attention otherwise we return false
all right so it's like a 5-line DFS
so let's look back to this pathological
example as I said before the number of
paths is 2 to the power of 3 which is 8
so imagine that instead of repeating the
separate parts for only 3 times we
repeat them
or enzymes and what will happen now we
have a lot more paths because 2 2 to the
power and which is pretty bad because
the FS are rhythm will have a very bad
time especially where n is large like 32
it takes like 1 and 1/2 minutes to run
with an eco stability so the time
complexity is exponential and if you are
running your application with a security
question then you're screwed so how do
we solve this problem there so a very
usual idea is that if you have a
exponential algorithm and you want to
make it polynomial you don't
memorization or dynamic programming so
if you have a function like this which
is pure thank God it's pure and we can
make a container for memorization out of
the signature where the container itself
is a map and the key is the
impulsiveness of the function and the
value is a return value of the function
all right so this is a conceptual map
from a pair to a pool but in C++ we can
implement that in various ways for
example can go out for the
straightforward way we use map and peer
and bool or if we are aware about the
performance we can use a two-dimensional
array where the first dimension is the
ID of the state so ID starts from 0 and
the second dimension is the position of
the string character so the because we
have a immutable string we can easily
use either pointer or a index to
represent the whole string content or
the suffix on the string
or we may have other different data
representations depending on our
optimization scenario so for
illustration I will just use the worst
choice
I will use this STD method from a fear
to bow here so we are going to write our
memorized aversion of DFS so first we
create the key then we check if the case
the key is already in the memorization
container if that's the case we don't
proceed to the actual computation and we
just return the value otherwise we
compute the value and store the value
back to the container the fsmo is
exactly the same as our previous DFS
version except that it doesn't
recursively call itself it recursively
call our memorized the DFS so that
during each recursion the memorization
logic is pick it up all right it turns
out the time capacity as we expect is
much better it's the number of target
characters times the number of states by
the way number of states is proportional
to the length of the regular expression
strings with one feature disabled we
will talk about the efficient later but
the space complexity is also increased
because we have to keep this
two-dimensional memorization container
in our memory and that could be bad
because what if we have a very long time
string say if the target string has 1
million characters then we are going to
have a bad time and run out of memory
and we are able to solve this problem so
look at this two-dimensional memoization
container for DFS so in during the DFS
we go back and forth in this
two-dimensional table where I'm saying
back and forth I mean the we may go down
or go back up so we don't always go
horizontally and that's a problem
because by using this access packing we
have to keep the whole dimension who
two-dimensional table in the memory and
what if we change the
order of the traversal instead of
keeping all the things in the memory and
going back and forth we keep only one
role in the memory in this case we keep
the second row in the memory and we are
during the process to generate the third
row and after completing generating the
third row we can safely discard the
second row and in this case the first
row is already discarded that means it's
not it's not we cannot feel free to
increase our target iterator because
that's gonna move our row down and
that's bad so our strategy is to
exhaustively search for the current that
sails in the current row and collect all
those potential cells that's able to
proceed to the next row then we perceive
all at once
alright so based on this idea we have to
create a helper function that's called
epsilon closure an epsilon closure is a
function that takes a set of states and
return another set of states the return
states are reachable from any input
States by at least one epsilon moves a
epsilon move is any move that doesn't
consume any target character or it
doesn't increase the target string
iterator
alright so I don't have code for this in
my slides because I think that's
straightforward enough to implement so
let's look back to this pathological
example so and we can just run through
the BFS over to see how it goes alright
so first we initialize our container
which is a set it contains one start
state and we call our epsilon closure so
it computes all the states that reach
all by at least one epsilon move which
means one through seven eight is not in
this result because from eight to from
say seven to eight we have to consume a
target character so after that now that
we have exhaustively searched the
control we find those
that is Abel that are able to proceed to
the next role which are the mashing
states and matching a because a is our
first target character all right so we
filtered all the epsilon closure states
by matching states and by a we find the
result to be two four six seven then we
assign back the results to the active
set and do the similar things for the
second character so we calculate the
epsilon closure in this case from two we
can reach through we can reach three
through seven from four we can reach
five through seven from six we can reach
seven from seven we can reach eight and
we finally merge all these results
together into three four five six seven
eight then we do our filtering and the
result is four six seven eight all right
and when we do the similar things for
the third character we calculate the
epsilon closure and we filter them by
the third character and we have such
States all right so now that we have run
out of target characters we have we can
do another epsilon closure because
epsilon closure itself doesn't consume
any target characters as you may see
eleven is in our final epsilon closure
that's a good thing because we actually
find a match because 11 is there it's
more or less by definition so if we do a
few equivalently if we do a final
theater by accept state we can get a non
empty set back that means we have fine
we have found the match and here's a
code is actually even shorter than the
DFS version with the help of the epsilon
closure helper so first we initialize
our container then for each character we
call epsilon closure and then filter the
result by the target character and
finally we do the our final absolutely
and check if except state is in the
absolute ocean right so the time
capacity actually does change because
conceptually we still need to traverse
to to filling each cells in this
two-dimensional
memoization table it's just we don't
have to keep the whole table in the
memory we just need to keep one row so
the space complexity reduces to all of
the number of states all right one
caveat is that though the worst case
time complexity is the same as the DFS
and memorization version it's actually
slower than that yes DFS on average by
saying on average I mean on the normal
non-malicious non-pathological inputs in
those cases DFS usually have a few just
a few back tracks or even no back tracks
at all and for it quickly finds the
answer and early Richard and but all our
DFS on with them we have to exhaustively
search the current row then proceed to
the next row so it's actually hitting
the worst case much more frequently how
do we solve that problem we do have a
way to speed up our BFS approach but
with the price of space complexity
that's called a deterministic finite
automaton approach or DFA approach so
the idea is quite simple we simply pre
compute this expression in our BFS code
so that we make it faster so we the
pre-computation generates such a
container that's from a pair of a set of
states and a character and it produces
another set of states so there's another
trick we can do here to normalize
different sets of states to unique IDs
where ID starts from 0 and ends at n
minus 1 where n is the total number of
sets of states we care about
and this is easy to implement in C++ or
just use a factor of a fixed length
array the column number is 128 here
because we are dealing with ASCII
characters here and Delino is unicode is
a slightly different question all right
so let's see how how can we generate
this DFA be aware that this is the pre
computation so no target string is
involved first we calculate the ID of
the given set so it may be a new idea
allocated or the existing ID it's
already seen so if the ID is in the DFA
we shouldn't do that again so we just
early return otherwise we create a new
DFA entry and we start to populate the
entry so we enumerate all the characters
in the ASCII and we calculate the
expression to get the result set back
then we calculate the ID of the result
set and assigned ID back to the crass
ponytail right
finally we recursively call on the
result set this is because we want to
lazily discover new sets so that we
don't have to exhaustively search for
all the setting and enumerate other sets
in our space because there are too many
with that said if you know if we do this
lazy discovery the space compute the
worst case space complexity is still bad
it's 2 to the power of number of states
which is the exponential and
unfortunately we do have at least one
malicious input to hit this worst case
so if you have you if you have a regular
expression to match arbitrary content
followed by an a or arbitrary literal
followed by a fixed length suffix then
you're hitting this worst case space
complexity but the upside is that we
have a much better matching time
capacity which it's just all of them
because if we go back to the EF a BFS
approach if the function body only takes
all one to run then the whole program
takes all enter oh we're range the
length of the target stream all right so
here's the matrix of all the algorithms
and the performance care straight their
characteristics so I have three
suggestions for this first don't use the
FS or DFA without a backup solution
because they have big special behaviors
and they they will cause the security
vulnerabilities of your application
secondly if you do want to choose a
backup solution you want to look at the
length of the tummy string first for
example if you are doing a code search
long lines go search in your code base
and you have a style guide that says
each line should be less than or equal
to 80 characters then the number of
target is number of catawba characters
is less than or equal to 80 characters
so in that case it's pretty safe to use
DFS and a memorization but if it's not
the case and you have a potentially lon
target extreme you should use BFS as a
backup solution and now let's see why
this deco flourish happened so it uses
it our DFS algorithm without
memorization and these results in two in
theory exponential behavior
it's only all of N squared because it
repeats the parts the part for only two
times if it repeats for K times then we
have our algorithm wrong on all of em to
the power of K which is exponential and
here's the implementation and algorithm
matrix so as you may notice most of the
implementations implement DFS because
many features they claim to support or
they wish to support is only
implementable in DFS mode or at least
efficiently
and some of the implementations for
example the best EDC fusses and pcre
they do support BFS but who is BS BFS
remote turned on by say custom Flags the
corresponding features will be turned
off so if we use both BFS feature and
those are BFS mode and those features
I guess the compilation will fail so for
our e2 which focuses on security it
takes a very different approach first it
tries to compile the recs to DFA if that
fails because it generates two men a DFA
States then it falls back to DFS and
memorization with a memory consumption
threshold I think the memory consumption
thoroughly is to is 32 kilobytes and
it's not customizable I wish is
customizable for example if I have 8
megabytes and it's dedicated for a one
important relics way why can't we just
use that because DFS is faster in a BFS
in on average right if DFS i memoization
threshold is hit it falls back to BFS
alright so let's talk about
personalization or the features that
slow down your application
the first one is capturing groups it's
actually very common so it serves as
these parentheses that keeps content of
the last match in so that you can
inspect the content after the regular
expression matching so usually we have a
global match which is put into the group
zero and we have indeed individual
contents put into individual cells based
on the capturing group parentheses so
before supporting this feature for each
algorithms we have such a nice container
which is affordable which are affordable
at least and we have to modify them to
support this new feature like this
so for DFS memorization that's actually
pretty cheap
it's almost free to support because we
can just maintain one list of strings as
capturing groups during the whole
regulates our expression matching that
is because we are doing the leasing a
DFS way right we can modify the
container to represent the next the
capturing group who want to use before
entering the recursion and after leaving
the recursion we can revert all the
modifications very cheaply by for PFS we
don't have such a lot because for we
don't have the current state thing and
we actually have different states with
their own capturing groups that those
are totally different that means for
each state that's currently on record I
have to add a overhead for that and the
overhead is has a factor of number of
capturing groups so if you have 1
million capturing groups you are pretty
much screwed but for the FS we don't
have this problem for TFA on the other
hand I don't have a solution that
doesn't customize the time and space
capacity so the best solution I can have
will decay the time complexity to the
BFS one so why don't we just use BFS so
I do have some premature ideas but it's
not I don't want to talk about that
right now so how do we prevent the
pessimist issues we should check if we
are using p FS first of all we should
check the number of capturing groups to
make sure they are a small one number by
looking at for example STD mark accounts
and for the FS we don't have to worry
about that the second feature I'm going
to talk about is back offices so sorry I
have a mistake here
so the back reference refers to a
specific capturing group by the number
in it for example we have backslash 1 so
it refers to the it matches the content
in the first caption group at that time
so for a B a a B the whole regular
expression matches matches it and the
first caption group matches the first a
B and the back reference matches the
second a a B it does not match aibee
aibee aibee because the first part and
the second part don't equal alright so
let's do this again before the
modification we have these nice
containers and after the modification we
have to put path into the consideration
because the contents of the matter start
to matter now but that actually defeats
the purpose of our memorization because
the whole purpose of memorization is to
reduce exponential taste to a polynomial
piece but with those power path
considered the memorization itself is
exponential so why do we even do this so
the solution is to if you really care
about the security is to forbid it
because it's actually proved it's only
supportable in a exponential it simply
np-complete so lib STD C++ provides this
library extension flag that is
underscores for polynomial which
switches to the BFS approach and throw
an exception if it sees a back reference
so the third feature and going to talk
is brace crime-fighters it uses braces
and in close being a number and it acts
actually like a macro that expands the
expression that it associates waste for
so many times for example a 3 expands to
80 and the interesting part
is when we nest those quantifiers so it
expands to nine times if we have such a
thing and it's sometimes you have like
parsers to check for this pattern and
you want to avoid this pattern but users
can always walk around that by putting
parentheses and extra characters so it's
not actually avoidable and what if the
user did this and this would be bad
because with a such short regular
expression input stream it generates so
many states and if because all all of
our algorithms rely on the number of
states so if the number of states is
huge then we can have a bad time while
the solution is easier we can simply
forbid it through the library flags or
the library should set up a state limit
for example some of the standard library
sets up the state limit so if the the
actual States exceeds the limit the
compilation will fail and the throw an
exception here it is aerospace alright
so as a conclusion and have a matrix
here for DFS it can supports everything
is free because it's already slow
for the FSM memorization it can freely
support capturing groups but for other
features and other algorithms those
features are either limited support or
not support it at all but for DFA a
memorization for DFA and the caption
goes I need to put more thoughts on you
where you Fanny one knows the answer
tell me I'd be grateful so let's talk
about the future I really want to change
this on the container sorry the standard
so that we can have better things for
example in the future I want static
compile-time reg X so I want this
component I'm Rex that carries no
runtime data and carries all its
characters in the template so that the
library authors can actually do template
generate code generation and the
compiler will pick up all the code
patterns in the Reg Xcode and optimize
all of them and the use case should be
like we can just construct a static
ragas and passed it into the normal
regular expression function call and
that that actually requires a language
change because currently we do not
support arrays as template parameters
and it also comes with an elaborate
change but that's true do it's trivial
to you and love your address and today
we can do similar things but not as
nicely we can use variadic templates and
that we have to sell separately read
each individual characters but with that
I actually have a a t1 line
proof-of-concept
it doesn't do parsing so that's why it's
so short and the runs much faster with
those are optimized library
implementation and I believe boost
expressive is doing some manual
optimization that can pick up these very
simple case which is just matching 1000
days with the a star
and why that's so fast because the
compiler cases the comparing the
relative expression library and to all
of the all kinds of optimizations loop
unrolling the prac transition cost and
propagation in learning and many other
cool things so if we don't have compile
time records another approach to take is
to write a JIT compiler so sorry right I
read it is anything that uses a JIT
compiler to compile to a machine code at
runtime but to standardize JIT compiler
it's a bit hard or even harder much
harder than my previous profiles so
that's just to give you a feel how this
proof of concept look like it's not
based on NFA it's using continuing GPS
style continuation passing style that's
why it's so short but I'm not going to
talk about the details here all right so
the second feature I want is to extend
the algorithms for non characters for
example I have such an event email that
models a machine repair case so we can
open case and close the case and during
the case we can swap parts and reboot
the machine I want to be able to match
such an event stream that is during a
case we rebooted the machine for three
times interval at some point so that I
don't have to reinvent the rhythm scene
in my project because those algorithms
are written and optimized I want to be
able to just user and that is the second
feature currently basic reg X requires
the element type to be car like it's
much stronger than a like equitable type
so yeah here's a brief recap we have our
four rhythms with the performance
characteristics and the suggestions of
when to use one and then have
about three different features how
should we deal with those features so
that they don't slow down our
application finally I have two wishes of
the changes to the standard so that we
have faster and easier to use regular
expression library and that's all about
it we have like 20 minutes for questions
yeah I know
so the comment is that instead of
supporting the car arrays in the static
Redax we can use a lightweight version
which is easier to support that is
making this user-defined literal support
very attic cars like this okay support
very big cars so so that we can just
write a string literal with the suffix
underscore re or something and it will
generate the revenue static graphics of
that for you
so that we don't have to separate
separately right each individual
characters the question is in the static
radix implementation do I use different
types for different input the answer is
yes I use things with similar things
like expression template so for each
individual compile time input I will
generate a unique type for that so if
you are interested since we have time we
can't go through work just to look at
the implementation because we do
time yes it's a guest actually well
let's just wait and whoa yeah well we
can still do questions while waiting for
that oh that's that must solve
everything I mean we started
I hope that it's hope these tell for
that cool slice support offline mode but
other questions the question is do I
support to remove the non ACMA script
styles that means POSIX style I'd
slightly because mainly because the
longest sorry leftmost longest matching
style and that's harder harder to
implement than the JavaScript style and
I do support detector freedom and just
don't use them and I don't I'm not happy
with pro-style either because it
supports like sorry
look look ahead which is actually
backtracking of head as opposed to a
static look head which retains actual
force and for once and nope no it's just
a complete to be one of a network but
anyways you can look at the code after
the talk it's I will send out the that
slides so you will be able to get the
link so any other questions here I am a
user projects which use everywhere which
PUC tamashii disease etc what's a great
library works but what scares me is that
it's maintained by one enough people
part-time ok yeah something like that
yeah
so it is suffering like from the open
SSL problem that nobody is actually
investing time in reading the code
checking that there are no weird
overflows in there and being sure all
the libraries that you showed before
I'm currently properly maintained or
I mean I can't speak for others because
I'm maintaining sorry the question is
it's more or less scary to use those
less meant the the libraries that are
not actively maintained or if banks are
in those libraries then if they are not
fixed on time then it's pretty scary
so that's your comment but so that's
also a comment so the comment is for
almost all these libraries are lists
they use depth-first search for as the
default regular expression engine so yes
so that's the common okay
yes then the form is the form is first
suggestion on these metrics is to not
use DFS or DFA without a backup and how
many engines without a backup show up
here like for right so question
okay wait just sorry yeah hey it works
so I don't want to teach all of details
about this code because it involves
template programming and like template
specializations and continuation passing
style I actually steal it from a SML
book it's it's just the first few sample
that let SML book games so it creates
different templates for different nodes
we are going to use some also call it
parser Combinator but I'm not sure of
that
and we just specialize on different
cases and handle different cases using
CPS we don't have to use CPS we if we
have 13 and as I said I didn't do the
parsing so in order to use the regular
expression I have to explicitly write
out the ast of the regular expression
all right any other questions the other
comment is it would be great to have
compile time parsing and so that we can
actually generate error messages at
compile time and I think we do have that
that's called cost expert and we can put
like static assertion it yes okay
I have to be a lot of back didn't cover
it probably done them a gradient sir but
given that each of these libraries have
used a specific algorithm that has some
killer red X if we're accepting Gregg
X's from the end-user we have to in some
way sanitize them resource limits on
them to prevent our program from which
these libraries like to control these
resource limits so the question is if we
are accepting the red X in the target
screen from the end-user or potentially
the malicious malicious user from the
internet which library should we use so
that it takes care of all the resource
management and other security
vulnerability concerns yes so the
comment is either it can takes care of
the resource management or it exposes
different like configurations for the
user to set threshold out so the answer
I guess is are you two so it doesn't
expose much configuration for you to set
threshold on but although it doesn't
explode so for the malicious inputs
that's what I'm saying are you - the
question is can explain more about are
you - are you - is not a standard
conforming implementation it's a third
party regular expression library
developed in Google it focuses on it
doesn't first for example it doesn't
support backed references at all because
it has security concerned so it focuses
on security and it uses DFA by default
the question is is by saying if DMA are
you - is the question is Ari - available
outside of go there as Radiesse is a
resourced with bsd license so the
question is is are you two different
from are you - see I don't know Ari -
see so somewhere sir yes it is different
now fastest one two three okay you are
dismissed</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>