<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: Peter Sommerlad “Mocking Frameworks considered harmful” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: Peter Sommerlad “Mocking Frameworks considered harmful” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: Peter Sommerlad “Mocking Frameworks considered harmful”</b></h2><h5 class="post__date">2017-10-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uhuHZXTRfH4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">- I'm Peter Sommerlad.
Talk topic today is mocking
frameworks considered harmful.
And even after I submitted the talk,
I figured out, well, you could read that
in a couple of senses.
And some of them I tried to list there.
Is it, mocking frameworks
considered, harmful?
Or, mocking frameworks
- considered harmful.
Or mocking and frameworks
- considered harmful.
By the way, for those that are
not in the ISO C++ Committee
what you see in the
background is our campus
and the beautiful town of
Rapperswil in Switzerland.
That's where next June's
WG21 meeting will take place.
So if you consider joining
the standardization committee,
that's actually one of
the places to go to.
The other is Kona in Hawaii,
where we had the meeting this spring.
Now, as a professor,
I always want to teach
something to people,
and &quot;considered harmful&quot;
is something that has an ancient meaning
in the programming era
when people start writing
about GOTO considered harmful.
And usually it's a tool
that you might over-use
or use too much.
We learned yesterday from Bjornar
that GOTO is no longer something we use
because it's so primitive.
With mocking frameworks,
I'm not really sure
if the primitive argument actually
is the right one.
I'd like to show you when they are useful,
or when the mocking themselves is useful,
and show you some means what's in there,
and what to look out for.
And that's the idea of my talk today.
And by the way, this hat,
if you come next year to
Rapperswil I might provide
another batch of these
hats for those who come.
I usually ask my students
questions about that.
So my question is, who is
using a mocking frameworks
for writing automated tests?
Who's refactoring their code often?
Okay, let's see if my,
let's say, my amusing
share with your experiences
and I'm happy to learn
otherwise in the end.
A lot has been written about
testing and other stuff
mainly targeting people from
the OO Java-ish community,
actually, are exposed to these things.
But the wisdom in these
books, especially these two
I'm referring to, is actually valuable
for C++ people as well.
So there's xUnit Test Patterns,
and xUnit stands for all these famous
unit testing frameworks, starting
with sUnit for Smalltalk,
back and back, and jUnit,
Re:Gamma and all the others.
We have plenty of those for C++ as well.
And the good thing about these patterns is
they are language agnostic, most of them,
and they tell you
something about the idea.
And if you read any kind of pattern,
always look for the fine print.
It's not always, this is a great solution.
A good pattern description gives you also
hints about the drawbacks
you have to pay for
if you apply it.
And some of the drawbacks
that are actually explained
in the xUnit Test Patterns,
in the very fine print,
I'd like to point out today.
Another very interesting
book that might also
be underappreciated is Working
Effectively with Legacy Code
by Michael Feathers.
And for him, Legacy Code is actually code
that doesn't have enough tests.
And code without tests is bad code.
And when he says &quot;tests&quot;,
he means automated tests.
And his book is actually about
how to get stuff under test,
and that's where you might actually need
and appreciate the mechanism of mocking.
And what that is, let's go to that.
I'm also referring to another article,
because that's where I stole
the example I'm using today.
It's by Martin Fowler, who's also writing
a lot of stuff about
Agile, Odesign, and so on.
And he has an article
about Mocks Aren't Stubs.
I'm stealing his example deliberately,
because I've seen talks
about mocking frameworks
that use this example, and I'm
trying to elaborate on that.
Anybody not knowing Martin Fowler by name?
Good.
So he has an interesting
example that's quite simple,
he wants to test an order class
that relies on a warehouse class
for fulfilling the order.
And if you consider that
it's completely unrealistic,
except for the example that
uses the Talisker whiskey
to get it from the
warehouse, or a whole batch
of Talisker whiskey bottles,
and it has some interesting
design deficiencies
that I don't want to show you right now,
and if you can't read the diagrams,
I'm not sure if it's really legible there,
doesn't matter.
The intended behavior
of the Order object is,
if you want to fill an order,
it asks the warehouse, do you
have enough stuff in there?
And if yes, remove it from the warehouse
and memorize that the order is filled.
And it's kind of a stateful thing.
If the inventory is not sufficient,
it will just fail to fill the order.
Now, if we just want
to test the order class
without a real warehouse
delivering the Talisker,
and if we run the test,
you don't want to ship
the 50 bottles of Talisker
that you want to test for,
so that's why you actually want to replace
that warehouse object with a fake object
that is actually doing nothing,
or pretending to be a real warehouse
without doing anything useful.
So you want to actually
check the order class,
if it behaves like that,
and you want to check if these
interactions happen as you planned them.
Now let's see what we can do about that.
That's the underlying example
that I stole from Martin.
If you look at the xUnit patterns,
there's a generic diagram that
happens over and over again,
and the basic idea is that,
when you write a test case,
you have something where
you set up the test,
you exercise the methods of functionality
that you want to check from
the system under test, SUT,
and then you verify if
the test was fulfilled,
that's where you actually
have a test failure,
and then you have the teardown phase
where you actually clean up.
In C++, that teardown
phase is usually trivial,
that's just a clearly closing phase,
because we have destructors.
And if you have to teardown something,
the destructor will take care of that.
For terminology, at least on my slides
and in the xUnit patterns,
SUT is a system under test,
and the DOC is the
dependent other component.
In an ideal world, you can
test this system under test
without external dependencies.
But if you come, like
Michael Feathers describes,
from Legacy code that doesn't
have sufficient tests,
you will actually end up with situations
you have other components
that you depend on.
And now, how do you test that?
You can test it on a system level,
but if the other component is slow
and, let's say, doing a database,
or communicating over a network,
your tests will run slow
and you will have very slow feedback,
so you need to do something about that.
And that gives you one of the situations
why you want to actually
do something about
replacing that dependent other component
by replacement, and
there are several words
used for that, test-up, test or mock,
or test double, and I might
use them interchangeably,
and I'll give a little bit differencing,
what a mock is and what a stub is.
So one thing is, the real
object that you're testing with,
which is the dependent other component,
not the system under test, has
non-deterministic behavior.
How do you test something that
relies on a random number?
Or relies on external input,
like a stock market quote?
The real object is difficult to set up.
It might require network
connections, database connections
or whatever.
The real object used in systems under test
depends on, it's hard to trigger behavior.
How do you test for,
let's say, false failures?
Or the log is full failures?
Real object is slow,
which is also something
that can be a problem,
especially if you write software
for real hardware, beyond just
the type it runs on.
And, like, automotive
or other control stuff.
Then you need to have
to do something about it
so that you'll be able to
test your software fast
and without extra hardware moving around.
If your software still has bugs,
you don't want to destroy
the hardware from that.
Real object has or is a user interface,
or it's a user itself, herself or himself.
And one thing, where
mocking is interesting,
is the test needs to
know if the real object
is actually used correctly.
For example, was a call-back triggered?
Or things like that.
Or it doesn't yet exist.
If you have a large system,
you might want to write
tests for a component
that has to rely on some other components
that are not yet implemented.
And how do you do that?
So the basic idea is actually
that you replace this
nonexistent or missing
or badly-behaving other component
by a so-called test double.
A replacement.
So you need the means
to actually perimeterize
the system under test
with a replacement component.
That's hard to do if this
one actually essentiates
this other component,
based on a concrete class.
Or uses it, like calling an
operating system function
that you need to replace
because that might do IO.
So we want to avoid slow
tests, and we want to be able
actually to test this system under test.
If we,
and only if we want to go to
check if this system under test
actually uses the other
component correctly, that's when
what Gerard calls &quot;mock-up&quot;,
and that's one of the aspects
of Martin Fellow's article
I was referring to.
You want to actually check
that the system on the test
uses this other component correctly,
and you verify that in the
end that it's used correctly.
And that's
where mocking comes in.
So the setup actually needs
to set up a replacement object,
and this replacement
object needs to verify
if it's used correctly.
Either while it's used, or in the end.
And the verification step
in our test case is actually
doing something useful for
the final verification.
That is what mocking is about.
For those of you who are
using mocking frameworks,
is that what you're actually doing?
Some hands are going down, some waving ...
Okay.
Now, many mocking frameworks
actually provide you
with something that Gerard calls
&quot;the configurable test double&quot;.
How do we tell a test double
what to return or expect?
And that, in my opinion, is an idea
that's quite often overused
in the mocking frameworks
that you encounter,
because a lot of the
mocking frameworks allow you
to actually set expectations
to return values
while configuring that
test double, or the mock,
and then, in the end of
the verification phase,
the test double or some
magic will actually check
if the expectations have been met.
And if you,
checking expectations, okay,
but everything's spelling
these things out,
that's actually where the
problems might come from,
and I will give you some examples later on
so you can appreciate my red block there.
What this means.
So what do we actually get
in a mocking framework?
One thing is, we need to provide something
that people actually have many names for,
one fancy name is &quot;dependency injection&quot;.
And when you see that,
you always think that
you get some kind of shot
for immunization or whatever.
It's not that, it's just
to provide a parameter
to your object so you can actually replace
what you pass in, instead of
having hard-coded dependencies
to concrete other stuff
that are hard to replace.
So what you actually
would need to do is what
Michael Feathers calls,
you introduce a seam
to make your system
under test more testable
by being able to replace the
dependent other component.
What a mocking Framework usually
then provides, very often,
the dependency injection is something
you have to do yourself,
or you might have tools for refactoring,
and I'll show you some of them
that we created for our IDE.
And then the next thing
is you actually have to
replace the dependent other component.
One example is just by
a fake object that gives
pre-defined, canned results,
so the system under test can be run
without the real thing, and
provide something useful
for the test case.
If there's an interesting
interface that you want
to actually check if
it's operated correctly
between the system under
test and the other component,
then you might want to trace the calls
that the system under test does against
the other component, the test double,
and then you want to match if
the calls and the arguments
made on the other
component that is replaced,
are correct, and these
are the core elements
that go into a mocking Framework,
and that's what many people actually use.
I've chosen three examples,
or three mocking frameworks.
One is GMock, because
it's the most popular one
and quite ancient one,
and another one that's
a little more modern, C++
14-ish by Bjorn Fahller.
And actually, his talk at, I believe, ACCU
or some other event, actually triggered
me giving this talk, because
Trompeloeil is a great framework,
but using mocking frameworks easily
makes code bad, and I'll show you that.
And the third one is, actually,
one of my former students
created in his Masters thesis,
it's called Mockator,
and it's integrated into RS Cevelop IDE,
you might hear me speaking
about it in several locations.
Now the first thing is,
Michael Feathers tells us,
introducing a seam.
So we have existing code,
and we want to make it
better-testable.
So we actually need to do something about,
where we can alter the behavior
of our system under test
without editing the system under test,
because we want to test the real thing.
There are several mechanisms
that Michael actually presents.
The classic OO-ish one is
the so-called Object Seam.
We extract an interface of
our dependent other components
and change our system under
test to just use that interface
instead of using a concrete component.
And that's the thing that all
mocking frameworks support,
but not actually the extract interface.
If you're using language like Java,
or you have a very good
refactoring infrastructure,
it's almost automatic,
so you don't have to do a lot editing.
In other languages, you
might need a little bit
more things, Cevelop
provides some refactorings
to get their extract
interface refactoring.
But again, you have to
introduce a dynamic polymorphism
to enable that, which is not
always a good idea in C++ code.
With C++, in contrast to
Java, we have something
that Michael Feathers
calls &quot;Compile Seam&quot;,
and we have corresponding
refactory in the Cevelop IDE,
but you can do that by hand as well.
You just make the other component's type
a template parameter, and
provide a default argument
for the template parameter, being
the concrete other component,
so you don't have to
change the codebase throughout.
But then you can actually
compile your system under test
with a different template argument
where you pass in the test double.
And there, Michael also
shows some more interesting
seam things in cases that
are more pathological,
where you have dependencies
on system libraries
or even more interesting
things that are very hard
to replace, and there are
things of last resort,
which you can actually use
a preprocessor to change
a function name to something else,
where you can replace it,
or you can use a Linker,
or LD Preload with a DLL
to exchange system library
functions to do so.
And I won't go into those details,
because that's beyond what
I want to show right now.
So what we actually do is
we want to use a zipper
to be able to replace
our warehouse object,
our warehouse class, so
what we actually need to do
is extract an interface class,
I called it &quot;iwarehouse&quot;,
write your unit, change the order,
that it's using the iwarehouse
instead of the concrete
warehouse class, the unit
test then will provide
a mock or stub warehouse
that is actually used
for a specific test only, instead of
the concrete warehouse
that might do the shipping
to test this to test the order class.
Anybody done things like
that for testability?
Okay, you're all experts,
why are you here!
Now, to show off a little bit,
if we have a warehouse
with some implementation
and our order using that warehouse
in the fill member function,
what you can actually do, you
can call the extract interface
refactoring, and it will actually extract
a warehouse interface with
pure virtual functions
and make the warehouse, just
implement that interface,
and it will also, in
the corresponding places
of the order class, change the warehouse
to the warehouse interface.
So these blue bars show
what's actually changed
or automatically generated
by the refactoring.
And you see, it's a toy example,
so in real world code you
might have, let's say,
slightly more interesting effects and
it might not work
completely automatically,
but that's the idea.
And you can do that by hand as well.
For things, if you want to
have a template extraction,
we provide an extract template
parameter refactoring,
I don't show yet.
And the interesting thing about templates,
if you look back,
here, all member functions
have to be given,
and they are generated as pure virtual,
because they might be used by order.
And if you have us do
a replacement for that,
you have to implement all of them.
Because if it's pure virtual,
you have to implement it.
So with templates, that's
a very nice feature,
only what is used needs
to actually be provided
by a template argument.
And the compile seam refactoring
actually will tell you,
okay, if you see the mock
warehouse is actually empty,
if you look closely, it's a screenshot,
and it will tell you,
okay, you didn't implement
all the required member functions yet.
And if you do that, it
will actually create
the missing member functions for you,
but only those that have
been actually called
by the test case.
So that's actually an analysis
of how order is implemented
to figure out what needs to be provided
by the mock warehouse.
That's a cool thing.
Even if you want to change
the code afterwards.
Now, remember, you want to actually check
if these calls are made
from our replacement warehouse,
and we want to test for that.
So we write our test down here
with an empty warehouse,
you can generate that class,
and, again, we will be helped by the IDE,
or doing it by hand, to add all
the missing member functions
that we need to implement,
and these are completely auto-generated
with default returns, so
that they will compile.
And the nice thing, because
the default return of a boule
is false, and our empty
warehouse, we expect the order
not to be filled from,
so our test case just runs.
That's a very quick thing
to go around our circle of
writing the test, writing the
code that fulfills the test,
refactor, and rewrite the test again.
That was the case that you would
apply if you do it by hand,
or with some support from your IDE.
What would it look like
with the mocking frameworks
that I prepared for this talk?
Most of the existings for
C++ and the two examples
I have chosen, GMock and Trompeloeil,
require you to use the extract interface
with the pure virtual functions, and then,
if you want to provide a mock,
you have to use interesting macros
to actually specify the
overwriters of the member function
and the macros will actually
generate magic code for you,
so that the rest of the
mocking frameworks can work
with your mock warehouse objects.
So for a const member
function taking one parameter,
you write MOCK_CONST_METHOD1 in GMock.
Or in Trompeloeil, it's MAKE_CONST_MOCK1.
So very close.
That is one thing some people like.
I hate it.
Because it changes the language syntax,
and as a tool-builder, it's
very hard to work with code
that actually employs macros.
If everything is fine, okay.
But if you make a typo in
one of the macro arguments,
and you might consider,
why do I need to write
one and two here?
Well, for the macro, it might not be able
to recognize all the
commas there correctly,
depending on what you're using there.
Like you might have a template type
with multiple template arguments,
and the macro will just
take the template comma
as something interesting.
Who has run into that with code?
Yeah.
THat's a cool thing to debug.
Especially the compiler
error messages might be
very interesting, and very confusing.
Especially if you don't know
that you have a macro there.
So I hate macros in C++ code.
But, a lot of mocking frameworks do that.
So one of the considered
harmful things that hurt.
Now, if you just want to fake,
and that means we want to provide
a default result for our functions,
replacement functions,
if you do it yourself, the
default for &quot;has inventory&quot;
for this case, with the empty warehouse,
it's returning &quot;false&quot;.
With the mocking frameworks,
we cannot just say
return false, no.
Many of those provide you
with a specific infrastructure
to actually specify how
a function should behave.
And in addition to that, they come with,
as a side effect, not only
specifying how it should behave,
but also specifying how
the system on the test
should actually call the object.
The Google Mock people provide
a macro called ON CALL,
providing the object and the
function and the arguments,
and then you can say, okay.
Will, by default, return false.
Which reads nicely if you read english,
but not that nicely if
you want to read C++ code.
Because it's not C++-ish.
Under the hood they will
build infrastructure
to actually create
an expression object that
will be evaluated at run-time
to provide the return of false,
but it's not that obvious,
and you have to learn the
language and the right spelling.
The interesting thing the
Google Mock documentation
actually tells us,
ON CALL is something that it underused.
Many people write EXPECT CALL.
And I figured out why.
ON CALL, if you run your test
cases and you use ON CALL
to just fake something,
generates you a warning.
It says, okay, you can just ignore it,
but it nevertheless generates a warning
so you have the mental
overhead of checking out,
is that a real problem?
Or is it just something that
happens because I used ON_CALL?
So if you really want to work
with a lot of tests and stuff,
any warning actually
triggers some bad feeling.
So you better write
your code and your tests
so they don't trigger warnings,
they just go green and pass.
And that might be one of the reasons
why ON_CALL is underused,
so many people overspecify saying, okay,
we expect that this has
inventories actually called,
and if the order object
fill member function doesn't call
has inventory with
exactly these parameters,
exactly these arguments,
the test will fail.
Trompeloeil, instead of expect call,
allows require call,
but it also allows allow call,
so it can actually specify,
like ON_CALL, the default behavior
without actually requiring
that the call is made,
so if you refactor your
fill member function
doing something else and figuring out if
the inventory is empty,
it's still possible to do so
without having the test fail.
Now, we see here, we
assert the order is filled
or in the other framework
that I'm using down here,
assert not order is filled.
Where does the testing
expectation actually happen,
is fulfilled happen?
Well, it happens when the
mock warehouse object,
the warehouse here,
is actually destroyed.
So it's under stack and unwinding.
Which is a little bit late, in my opinion,
and that's one of the other problems
many of these C++
mocking frameworks carry,
they test stuff at the structure.
If you have another problem
where an exception is prone,
you might end up with interesting things,
because the checks are coming very late.
So I already talked about
the behavior verification
by providing the expect call explanation.
Sometimes you have interesting APIs here
that you want to make
sure that they happen.
The problem is, if you specify
a lot what should happen here
you over-specify the in-turn behavior of
the system under test, so you might end up
with fragile tests when you refactor
your system under test
that you're just evolving.
And I have some better
visualization for that.
So if you want to fill
something from a full warehouse,
we actually can say, okay,
back to this,
you first have to ask for &quot;has inventory&quot;,
that's true, we actually
want to move the Talisker,
50 bottles, from the warehouse.
To do so, we, again,
employ our &quot;expect call&quot;
where these arguments will return true,
and then we expect another call
that it's actually removed.
To make sure that these two calls are made
in the correct order, first
checking and then removing,
we actually have to
introduce magic by this
in-sequence object in
GMock to check out, okay,
first, this call and then that call,
and it's by magic only because
this in-sequence object
happens to be there.
These &quot;expect call&quot;s are
actually checked in the sequence.
And it's again magic
on destruction of that
in-sequence object that
things like that happen.
Trompeloeil is a little bit more explicit.
You also have this sequence object here,
but you pass it into your &quot;required call&quot;,
so it's more obvious that the sequence
is required from these calls.
But both frameworks suffer
that the actual check
that the calls have been
made in that sequence
is done here, or here.
But you have the check that
the order is filled before.
So if you have a logic error
that the order is not filled,
even these calls are made,
you might actually fail here and have
multiple issues within a single test,
and that's also bad about test cases.
If a test case has
multiple reasons to fail,
it's very bad, because you never know
what went wrong immediately.
You have to start
debugging your test cases.
Who is using the debugger to figure out
if test cases are wrong?
Ahh, plenty!
Go home, look into the mirror and say,
I should write my test cases so that
I don't need a debugger to
figure out what's wrong.
That's one thing to take home.
No debugging!
Core dumps are fine.
We have a poster here that says
&quot;Core dumps are so retro.&quot;
Core dumps are fine.
Interactive debugging is
the biggest time-waster
for developers.
I get one thumb up.
More, okay. (laughs)
And the other issue is,
many of these mocking
frameworks provide you with
their own language for
specifying behavior.
Well, we are programming C++!
Why isn't C++ used for
specifying the behavior?
I'll give you some of the reasons later,
just to give you an overview,
Trompeloeil has a nice two-sheet
cheatsheet how it's to be used.
And I don't want to explain,
for details go to Bjorn Stock
or listen to one of his
video-recorded talks
where he explains how
great Trompeloeil works.
But just an interesting thing,
you write EQ, that's so Fortune-ish!
Who remembers Fortune?
It was dot-EQ-dot but nevertheless.
Well, we have equals.
And other things.
So interesting things, and
because of implementation
and language problems,
there are things, oh, I have
reference to local stuff,
I need to take care about that.
Well, it's because
magic happens in the destructor,
and your locals might be gone
while you're checking things.
That's a problem.
Now, when we perceive Mockator,
with the tooling and the framework,
I was thinking about Kent Beck,
remembering him saying,
&quot;Do the simplest thing
that could possibly work.&quot;
When in doubt.
I figured out, is that really true?
I remember Kent saying it.
But actually, it was Ward Cunningham,
working with Kent, saying, &quot;Kent!
&quot;Do the simplest thing
that could possible work,&quot;
when they were pair-programming.
Anybody not knowing
who Ward Cunningham is,
what he invented?
Some of them?
He's the inventor of The WikiWikiWeb.
Not Wikipedia or,
but the WikiWikiWeb
in 1992, I believe, or so,
can figure that out.
So, what were my constraints?
I hate macros.
And I want just regular C++ code,
and it was just after C++ 11 was available
in regular compilers,
so we provided, and we were
writing against an IDE.
So we have tools for
generating and analyzing code,
and that makes things
simpler, in my opinion.
And those of you who still use, let's say,
ancient IDEs or no IDEs at all,
an IDE called Emacs ...
I believe that's very retro.
Even more than core dumps.
So what we provide is
introduce seam refactorings
for all kinds of seams
Mike Feathers talks about.
We generate regular C++ code
that you can actually change
and the stuff will still work.
We generate regular C++
code for tracing calls
and that's where the simplest thing that
could possibly work,
we trace calls by just
generating strings,
or, a slightly fancier mechanism
for generating strings,
and the use of vector
with these call objects
with our strings, for tracing the calls,
and you can compare the
vector that is generated
with a vector that you preset
in the test-case to figure out
if there's a bug or not.
So you set your expectations
and it looks like that,
you have a call to the constructor,
you have a call to house inventory,
and you have a call to remove,
and these calls are actually
happening in that sequence
as you spell them out,
you just insert equal,
the trace object with
your expected calls, and if that's okay,
everything is fine.
If it's not, you get an
interesting error message,
and I show you in a second how that looks.
And if you have more interesting
stuff that should go on,
if you want to check
more interesting stuff,
you still have the power of C++ and regex
and, let's say, interesting STL algorithms
to figure out if the
expectations are actually matched
without learning any extra magic.
And if you learn more about the details,
there are nice screen-casts
made by my former student
on Mockator.com,
and everything is available in Cevelop.
And if you try it out and find bugs,
please tell us.
We need our user feedback to improve.
I just found a bug when
preparing the slides,
and it's already fixed by my assistant.
So it's,
most of the time,
bug fixes are small unless
you have a big design problem,
but that's also something
that might happen
from time to time.
Just to give an example,
all this blue bar stuff
is actually generated from
Cevelop, and then that's
the example you see already,
and if you have an
expectation that's not met,
because we have our inventory
actually returns false,
&quot;remove&quot; will not be called
and we see immediately
in the div view from
our running test cases
what's missing from the actual output.
And that's very obvious to
see that something is wrong.
Either our expectation's wrong,
which it isn't in that case,
or our implementation's wrong,
which we can figure out.
And the assertion that's
explicit in our test case,
so we actually know what
failed and where it failed,
not at some kind of curly
race happening magic
where things go wrong.
Now why is it as bad as I say,
and why did I invent,
together with Michael,
something different?
Well, if you look for the
history of mocking frameworks,
they stem from the time
of the mid-90s, late-90s Java code bases.
Where people started using jUnit,
and other people invented
jMock and EasyMock.
And, for example, Google
Mock actually stems
from these same designs, they even claim
they descend from jMock and EasyMock.
Java comes with built-in reflection,
it only has classes and objects,
always has dynamic polymorphism,
even if they tell us
something else, and it
didn't have any lambdas then.
So the only means to specify code pieces
in the method was
to invent some mechanism
to easily specify code
that is not code.
Because they didn't have lambdas,
or not easy lambdas.
Inner classes for everything,
also not that nice in Java.
So what happens, under the hood,
the mocking frameworks provide subclassing
with method implementation for reflection,
and the lack of lambdas
made them invent DSLs,
domain-specific language
to specify the behavior,
and not just plain code.
And the problem is, if
you inherit a design
because you think it's the
best thing since sliced bread
without having the same constraints,
you might end up with a design
that's not just filling.
So, if you follow Java
Design and C++ code,
(blows raspberry) bad.
We don't have use for
reflection yet in C++,
so you might need macros for some stuff
when you write Unit-testing frameworks,
but you might not need
that for defining steps,
but mocking frameworks do
so because they inherit
that feature from the Java frameworks.
Relying only on virtual member functions,
I remember an era when
Google Mock and Google Test
only work with virtual member
functions, nothing else.
Which is bad.
It's not C++-ish any more.
Other mocking frameworks, like Hippomocks,
do very low-level
machine-specific ABI tricks
like replacing virtual table entries.
Which is possible if you
know how your compiler
does your retable layout,
but it's also in the range
of undefined behavior
that is not really portable,
it might break with new
versions of compilers.
A lot of work goes into DSL to specify,
and also often employs MACRO magic,
with implicit matching behavior
instead of actual,
that into the destructor
of the magic objects
that are generated from that,
and it's very fragile,
especially with respect to refactoring,
because refactoring tools cannot
understand code like that.
And it turns out that
tests actually get bloated,
because let's say you have a
more interesting interaction,
like here, a turtle
object that's taken from
the Google Mock documentation,
you have quite a lot
of things to figure out
what's actually happening.
So the first call will
get Y will return 100,
then it will return 200, and
then it will stick at 300,
so what does that actually mean?
There's also the curse
of too much mocking.
Because when I employ a mocking framework,
when I check, actually,
the internal workings,
inter-working on the system
dependent on another component,
I write white box tests.
White box tests actually
make things frozen.
Remember, white, ice, snow, frozen.
Actually, ice is blue,
but think of snow.
It's hard to refactor
for tools and manually,
and a lot of design flexibility
where you want to actually
evolve your design and
change your code is lost.
It also fosters stateful APIs.
Who is a fan of stateful APIs?
Good.
Like, okay, set this,
set that, and then do it.
One curse of many of
the graphics frameworks,
inherent from turtle graphics,
which is inherently stateful.
Who loves Cairo?
GUI programmers or graphics programmers?
Okay.
That explains a lot.
- [Audience Member] What do they have--
- I think I
already told you that, just to make sure.
Remember, if you use a mocking framework
in a way like that,
you have a lot of elaborative setup code,
and you have that implicit
checking of expectations
actually after the verification call.
And what happens then,
you actually put superglue between
your test case and the system under test,
and between the system under test
and the dependent other components.
That's where the tide coupling,
if you over-use mocking
frameworks, comes from.
Because you do this as a white box test,
so you actually put the glue in,
and you can no longer
change what's happening
within your system under test.
Which is not good.
And it also means your test
cases are so elaborate and long
that you no longer
appreciate changing them
and simplifying them.
And frozen code is bad.
Because your requirements
will never be frozen.
I skip musing on the stateful APIs,
just, that's my Cairo example.
Who can see, on the first,
on one simple glimpse,
what's happening there?
It's very hard.
That's just example code
from the Cairo documentation.
Nothing fancy.
Stateful APIs are bad.
If you need sequencing, wrap things around
like nesting calls or nesting objects,
and then you have sequencing implicit.
When do I need, actually,
checking the sequence?
When you have an existing API
that your system under
test has to depend on,
and that API is frozen and stateful.
Then, it might make sense to
employ a mocking framework
to check if it's used correctly.
One bad example that we have to live with
is the classic C socket API.
Who has written a C socket, server socket?
Who was copying the code
from the manual pages
or some other source?
Why?
Because it's elaborate, multiple steps
that you have to do to
actually get the connection.
If you have another reason,
tell me afterwards on Twitter or whatever.
I think, if you don't
have an existing API,
then don't employ mocking.
You still might have to use faking,
but not mocking.
So, if you need to test legacy code,
introduce seams, stub your
dependent other components
and maybe mock it, but
don't do it everywhere.
Take the power of IDEs and C++,
not macros and C-ish
code or Java-ish code.
And only if
you have to test the code of APIs
that are fixed and stateful,
employ mocks that are good.
Be aware of the dangers and the
power of mocking frameworks,
they are like superglue,
fixing your design and code,
and I mean, not that is good,
but that it's unchangeable,
which is bad for code.
It's called software for a reason.
Do not use mocking frameworks liberally
when you mock non-existing code,
and keep it simple,
or keep it stupidly simple,
applies to test automation as well.
Questions?
(audience applause)
And by the way,
is anybody using Swift on a non-Mac OS?
We are working on a Swift
IDE for Linux called Tifik.
There's a question!
Please.
- So, Google Mock has
a nice feature, argument matchers.
Is there an equivalent in Mockator?
- If you want to do that,
what you actually would do,
let me show you a piece of code.
What you would actually do,
if you want to have a specific argument,
it's traced here.
So you can actually match
that down here in your call.
- [Audience Member 1]
Yes, but what if I want to
have a wildcard?
I don't care what are the
values of the argument --
- You just don't trace it here,
because it goes into a string,
you just don't put it in the string,
and you don't put it in
the string down there.
So it's very simple, it's just strings!
Or you put an underscore
there if you really want
to have the same look and feel.
And it's C++ code, it's
very obvious to see.
That is just string concatenation.
It's just a little bit of magic
so you don't have to do
it manually for yourself.
So it's very, very simple.
Even simpler than you might have thought.
Other questions, please!
- So I've been using this
stuff for a couple of years now,
and after you do it for awhile,
it becomes really apparent that
none of this stuff has
any first-class support
from C++, and--
- Sorry, I didn't get
the beginning of your,
can you say it again?
- So I've been using
this stuff for quite awhile--
- Which stuff?
- Mocking, unit testing,
all that kind of stuff.
And it becomes very obvious that there's
no real first-class
support in C++ to do this.
A good example is the need
to mark things &quot;virtual&quot;.
Although you bring up
the fact that Mockator
probably doesn't have that same problem,
but at least, a lot of other
frameworks definitely do.
- You can use templates.
- Is there any, since you're
on the committee, is
there any work being done
to actually provide decent support in C++
for unit testing and mocking?
Like, maybe actually part of the standard?
- There's a lot of work
going on, currently,
on having decent reflection
support at compile time
within the library and the language,
but it still takes a
couple of years to mature
to actually being able to standardize it.
But there are people working hard on that.
It's just not simple. (laughs)
- Yeah, 'cause a lot of other
languages have had this
kind of stuff for years.
- That's one of the reasons we did that
in the IDE, because it's
very hard to be able to
do it with the compiler only.
- Yeah, okay!
Just curious if there's anything going on.
- But there are people who
will actually tell you,
don't do reflection and C++,
because the code gets too big.
And that's true, because
you need all the stuff
around at run-time,
bad things might happen.
- Yeah, thank you.
- Jeff?
- I just wanted to
update the record on one point,
that Google Mock was
the only framework where
you didn't have a listed author.
The main author of Google Mock
is named Jian-Young Wan.
He actually works in the Kirkland office
a few miles from here.
- I'm sure that, I just
couldn't figure it out--
- Yeah, when I noticed that
I checked, our documentation
doesn't credit him
and it really should.
- It wasn't obvious, at least.
- [Jeff] Yeah, so I'll
see about fixing that.
But just for the record, I think it's
a really excellent piece of work.
- Yeah, sorry for that.
One more?
- Sure, so,
you mention the need for
reflections to be able to write
at least decent mocking framework--
- Unit-testing framework.
- Well, for mocking framework,
I mean, if I look at something
in substitute for C#,
which is fantastic,
of course they have compile
time and run time reflection,
and they can do all sort of crazy things.
I think with a static
reflection we'd be able to have
some templated class which can mock
any virtual function of the
template parameter class
that you give it, and then,
you don't blow up the code,
because it's static reflection,
it's not in the run-time,
and then you could have a
list of all the function
that you would want to
mock in such a framework.
So the question is, similar
to the previous question,
since we know that the committee's working
on static reflection, is
there anyone working on
a mocking framework based
on that proposal, currently?
And if not, why not,
because that would be my
first use case for it.
- It's also my use case
for reflection in C++.
The problem is, it's not fleshed out yet
exactly what should go in the standard.
And so they are slightly
competing strategies
how to achieve what you need
for a static reflection,
and the problem is, it's
a chicken and egg problem.
So you don't want to
commit with a mocking frame
or the testing framework, without having
the working implementation,
and so you wouldn't be
able to write tests,
and you wouldn't want to change too much
unless it's--
- Right, but it would be
a fantastic use case to help in the design
of the specification.
- There might be people
who actually work on
that, but I'm not aware,
it's not on the, let's say, the agenda of
the standards committee yet.
- I understand.
Quick other question,
so all those IDE tricks that you're using,
is that available in Eclipse as well?
- It's available in our
Eclipse-derived Cevelop,
and some of the stuff you might be able
to install directly--
- As a plug-in or something?
- With Eclipse, as a plug-in,
and if you're more interested,
I have some flyers here,
you can take them home
and you can ask me.
- Alright I'll do that,
thanks.
- And if you try it
and things fail, tell us, please tell us!
I'm not sure who was next?
- [Audience Member 4] I
really like you bringing
the vector recording of
calls to the forefront.
- Thank you.
- The reason being,
vectors are regular
if they're full of regular types.
Which means you can save the recording
and then compare to a
trusted component recording,
and so you don't have
to hardcode your calls.
So if you have a component
that works correctly,
you can actually record the trace
and then test an untrusted
component with that trace.
- Yes.
- And no other framework
actually allows you to do that (laughing)
because you can't just
copy the damn thing.
So yeah.
We should really have that
in every mocking framework.
- [Audience Member 5]
I would like to comment
on the topic you've,
the name of the presentation, which is,
mocking frameworks considered harmful.
From my personal experience,
I was doing mocking a long time
before I knew about mocking frameworks,
and I found that when I
actually started to use
mocking frameworks, they limit my ability,
because there's a
specific language you need
to know about, and only
certain things you can do,
it often limits the
capability of a programmer
to write as flexible
tests as he would like,
and sometimes it's much easier
just to go and spend
the time that it takes
to spin off an interface,
and write a state machine
within the implementation,
and then to do custom stuff
which maybe can't be expressed
so easily with a macro,
or with a framework.
Because there you only have specific tools
that you can actually use.
And what I've seen is that people write
very long, convoluted tests,
that don't really test much.
They test trivial things, like,
I put in a variable and
want to see what comes out.
And we all know that that works.
What's really important is
domain-specific behavior
that sometimes requires much more
than just a simple macro,
or providing a delegate or a lambda,
which are not stateful,
and they're very difficult
to emulate complex behavior.
I wanted to hear what
you think about that,
and do you think that's also an aspect
of harmful behaviors
in mocking frameworks?
- Let's say, if you do mocking by hand,
that's good.
Because then you actually
suffer from your bad design,
and you write real code that is easily,
where you can see what it does,
and you can refactor it.
As you have observed,
the mocking frameworks
give you some handcuffs
that look, first, very
nice and interesting,
but I hate it.
And you seem to hate it as well.
And that's why I made this talk!
And you should have spoken
up before I started,
so I have my complete
motivation in your contribution!
And I think we run out of time,
and I thank you very much.
If you want to know more about Cevelop
or whatever we are
doing at our university,
speak up to me,
I'll be around until Friday morning,
and take some flyers.
(audience applause)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>