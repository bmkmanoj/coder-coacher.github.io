<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2015: Lawrence Crowl “Comparison is not simple, but it can be simpler&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2015: Lawrence Crowl “Comparison is not simple, but it can be simpler&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2015: Lawrence Crowl “Comparison is not simple, but it can be simpler&quot;</b></h2><h5 class="post__date">2015-10-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fi0CQ7laiXE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">greetings everyone what I'd like to talk
to you about now is some relatively
unknown pitfalls when you're using
comparison and particularly in
comparisons with the utility algorithms
in the standard library so first off we
need to understand what comparison is as
much as fifty percent of all
instructions executed on a machine are
on behalf of a comparison or the
subsequent branches so that's a lot and
an ill-formed or incorrect comparison
can invalidate the entire program which
means that error rates of one in ten
trillion will cause a failure every day
on every machine so we need to pay
attention to this issue so even very
rare events can come out and get us but
to carry on we inevitably have to talk
about a little math so a comparison is a
query against an equivalence or an order
relation so it's a mathematical
operation and there are mathematical
properties associated with those we'll
start off with equality what we have is
an equivalence relation many operations
provide a weak equivalence it's
reflexive it's symmetric and it's
transitive most likely if you're going
to fail and delivering a weak
equivalence it's that you fail to
deliver transitivity and then the
stronger thing what we usually think of
when we see operator equals is that we
give an equality or a congruence it also
adds the principle of substitutability
if a is equal to B then every function
on a will produce the same result as
that same function on be so it's a very
strong relationship very strong
requirement and if you're going to fail
delivering equality it's probably in
this
property the next is what is an order
relation the standard talks about a
strict week order what it means by
strict is less than non-strict means
less than or equal to but the standard
only cares about strict so that's what
we're going to focus on but before we
get to what a strict week ordering is we
need to know what a partial order is and
it's irreflexive it's asymmetric and
it's transitive so the first two
requirements are different from an
equivalent they're the exact opposite
but it shares the property of being
transitive and if you're going to fail
on delivering a partial order it's
typically in the transitive clause so
the strict week order adds this strange
thing a less than B implies a less than
C or C less than B what this means is
that you have a set of ordered
partitions right so every element has a
relationship with every other element
unless it's in the same partition okay
so the best way to think of this is you
start with some total order and then you
partition it and say okay all of these
things that are sort of near each other
in the total order become an equivalence
class and they'll be considered
equivalent for our strict week order and
then we get to the total order which is
what we typically think of when we see
the operators less than equal to and
greater than we typically think we're
going to get a total order and that has
an additional strong requirement that it
be try Croatoan nomis what that means is
that for every two elements you have
exactly one of those three relationships
less than equal to or greater than your
most like
be failures in delivering what you need
are in creating the ordered partitions
or in creating the try Croatoan miss
property so what comparison orders are
needed probably the biggest one people
worry about is what sort needs and it
says it needs a strict week order and
there's various other optum in there
that need something a bit stronger or a
bit weaker but the one thing the
standard doesn't say anything about is
what you need for your domain of
computation what works best for your
domain for an operator less than it may
not be what the standard requires so
standard doesn't know and the standard
makes some assumptions so what can go
wrong well the thing you should be most
worried about is your bank balance may
suddenly disappear you never know what
might happen because if you go wrong
you're often in undefined behavior
territory and then you have no idea
what's going to happen I am going to use
some examples with floating point
numbers I'm going to use these examples
for a couple of reasons one is that it's
a built-in type it's kind of hard to
ignore the problems in floating point
because they're going to carry on but
the problems do apply to other types and
I'll get into that a little bit later
but the net result of this is that
contrary to what most people think the
standard does not support sorting
floating point numbers in general so
passing general floating point numbers
to STD sort is undefined behavior and
you may get an anchovy pizza within the
hour you just don't know so how is
sorting with nan
well we're going to look at the
standards requirement for a ordered
partition and if we compare one and
three one lesson three that's true but
nan doesn't compare less than to either
of those so it doesn't meet that
requirement so let's put some five
numbers into a sort a couple of those
are Nan's will sort it and with
different partitions on the input and we
get wildly of different results out of
the sort and what's happening here is
that then any man and the data tends to
partition the sort into independent
subsets which are then sorted right and
our partitions tend to be pretty small
so it looks pretty random but if you do
a binary search on something that's been
sorted with an an in it you're probably
not going to get a large chunk of your
data ever looked at so this kind of
behavior in sort is not only undefined
it's not very helpful okay so how is
sorting with sine 0 remember I Triple E
floating point has both a positive and a
negative zero this operator meets the if
you ignore nan and assume that man's
don't exist then the operator equals for
floating point does deliver a strict
week order but it does not deliver
substitutability because one divided by
negative zero is negative infinity and
one divided by positive zero is positive
infinity so it's not inequality but
that's okay because store doesn't
require a quality but if we have our set
of five numbers of with some positive
and negative zeros we sort them will get
an order that's not consistent they
given the input
all of these are correct the algorithm
is delivered is delivering what it
promises because all of the elements in
the partition are together they're just
not in a consistent or reliable order
it's correct but it may not be what
folks expect so but let's go a little
bit further for memorization so we've
determined that operator equal does not
provide substitute substitutability
therefore it's not inequality so if I do
a memoization over 1 over X and I give
it minus 0 plus or minus 0 what I should
get out is minus infinity plus infinity
and minus infinity what I do get out is
minus infinity minus infinity minus
infinity so we've got the wrong thing
there and if I reorder the input I might
get plus infinity plus infinity plus
infinity what's happening here is
because minus 0 + + 0 compare equal the
first one into that bucket defines the
result for everything in its partition
and that's probably not what we want if
we're doing memoization one over X is
not the only function that has this
behavior there are several trig
functions that have this behavior and so
forth so how is memoization with nan so
the sign zeros are easy case let's go to
nan nan equals nan is false in floating
in I Triple E floating point so operator
equal is not reflexive which means it's
not even equivalence it so far off the
map you don't even know what it is so
let's take four numbers run them into
our memoization algorithm with one over
X and we should expect nan nan plus
infinity and nan ok what we get out is
nan nan plus infinity and man really we
have an algorithm that's so
totally broken we don't know what it
means and we get the right results okay
so what's really happening here is that
Nan's never compare each equal to each
other so the hash table does a look up
it will never match against the prior
man so it allocates a new bucket fills
it in does the computation dutifully
records the answer and never looks at
that answer again every man you put in
the street allocates a new bucket and is
subsequently ignored so you have found a
rather excellent way to waste programmer
time CPU time and memory okay so we
don't want to do that so how do we make
things right the first thing we have to
remember is that an i triple e double
there's not a man there are eight
quadrillion of them yeah and this is
this is something most people don't
worry about but there you have it there
are some bits that in the man tell you
where that man came from implementations
can use those and I Triple E arithmetic
defines its operations such that it
preserves those things so every one of
those Nan's is distinct and should show
up in operation so we memo nan number
one plus zero nan number two we should
get nan 1 plus infinity nan to so with
the default comparison we're back to the
same problem we had earlier where none
of the buckets get reused if we use a
week order we somehow go in and decide
that all man's are equivalent what will
end up happening is will fill the first
bucket with the bucket with its first
element in the equivalent class and
never never get the other so we only get
the first one when we impose a total
order on the floating point numbers we
get the right out pit so we get the
right result once we imply apply the
total order the important point here is
that
for any value that might possibly be
distinguished from another in any
function on the type we need to provide
a total order that exposes those
difference in values only then will our
memoization be fully effective so we've
talked about floating point how that can
go wrong and is this the only problem
other primitive types like int are
usually but not necessarily ordered the
standard allows a ones complement
representation of int now I've never
actually worked on one of those machines
I doubt anybody in the room has done so
but the standard still allows it oh you
have okay so that's a rare case maybe
you could just write it in page 362 into
your of your documentation that that
doesn't work but this problems get a
little bit harder to shuffle under the
rug when we move to user-defined types
so anytime you have a type with more
than one field that's almost inherently
a multi-dimensional type and there's
usually not a good natural mapping on a
multi-dimensional type onto a total
order you have to think about what
you're doing there and make sure that
you actually do get a proper mapping and
it's hard to do this because you're
using some type that you got from some
library and you go look at the library
documentation and it dutifully gives you
a less than operator but it doesn't tell
you what properties it meets so you're
going to have to go on trust and most
people never think about that they
assume a total order but in fact in many
cases it's not a total order and we know
that for floating-point it's not a total
order fact
for floating-point we know it's not even
a week order and we don't necessarily
want to require that people give a
specific order because they wrote their
less than operator for use in their
application domain for the algorithms
that are central to their type right
they didn't do it to make the standards
job easy they made it to they did it to
make their job easy so what is the real
problem here the real problem is that
the standards utility algorithms use the
operator left stand by default but
operators may not meet those guarantees
and we should not have those guarantees
imposed upon certain types okay what
we've got here is one operator trying to
serve two masters and that will probably
not serve either well what we need to do
is separate out the comparisons we use
for utility algorithms from the
comparisons that we use for the
application domain can it get worse
actually yes it can um the standard
helpfully provide some facilities for us
to automatically generate operators okay
in fact what it defines is the
implementation on the left it lists this
in the standard that's it this is
exactly what it does but this fails when
when T is partially ordered it doesn't
give the right results that is it fails
when you give it a floating point type
so what you should do is the alternate
implementation where you do exactly what
the operator name says it's greater than
or it's equal to and then you get
expected behavior and this gives you the
same results even as the floating point
operators
do when you apply it to float so getting
clever in your definition of these
operators is counterproductive so the
important thing is what can you do about
this problem now so I've outlined a
couple of bugs you can go and hunt for
those bugs now that you know about them
explicitly check your data for Nan's
that's one way to avoid a lot of
problems with sorts you can go and look
at your code and prove that the
operators you have have the properties
you want and if they're not weekly
ordered or totally ordered you probably
need to say that in the documentation
but you can write new code to avoid the
problems and that's mostly what I'm
going to talk about now so what the
advice I'm going to give you is to not
use the operators with the user-defined
operators with utility algorithms
because you just can't trust them you
have no idea what's going on um which
implies that you can't use STD less with
the standard algorithms because that
typically just picks up operator less
right which just shuffles the problem
through one more layer of abstraction so
what do I suggest you do I suggest you
write well defined comparators that
match the properties that I've discussed
earlier and then pass them explicitly to
the utility algorithms they all have an
additional comparator argument people
usually default it but you can it pass
it explicitly
hello okay it was way behind on me so
what are the boolean comparator function
comparison functions we write well we
had three levels of relationship for
order and those actually imply two
levels of equivalence relation and then
a pairing two partial orders so we have
a partial order a week order and a total
order and with the less operator and
then we have the equivalent where it's
unordered in partial it's a that's got
an equivalence in week and it's equal in
total order okay so we just write these
functions and carry on if you use these
names then we'll build a community where
everybody expects the same thing but I
have to caution you that these names are
not in the standard and the standards
committee is known for renaming things
so don't get too distant a change in the
future the next thing you need to do is
be consistent so don't develop these
comparators in isolation you're do you
have a whole set of issues these
interrelate the first thing is you want
to make sure that the equivalence class
operations are written in terms of less
than or the less up the less comparators
or their cement or they're effectively
equivalent to the two that you want to
be consistent across levels so if there
is
an order imposed by a week order and
somebody then goes used to use the
stronger total order they're going to
expect it to be consistent so you want
to make these consistent as well you
want to be consistent with the operators
that you provide for that very same
reason people are going to use it one
way with the operators they're going to
expect these comparisons to at least be
consistent so do that and finally if
there's a standard out there that
applies you want to be consistent with
that for floating-point there is a
standard it's a total order function so
fine advice but how do we go about doing
that first operator less then already
implements a partial less so we can just
use that in our definition of partial
less we can write partial unordered with
partial less as I showed earlier now we
have to write total less respecting the
I Triple E total order then we can write
total equal with that and now we get to
the middle case which is often the one
that seems to be a little bit more work
we write week less and weak equivalence
with week less let's go into that a
little more detail the I Triple E total
order puts all of its values in this
order starting with positive quiet Nan's
to positive singling signaling man's all
the way down to negative quiet man's
every bit pattern is distinct because
there exists some operation that will
give different results on different bit
patterns okay now sadly that the order
up here is not the same as any integer
type you're likely to use so you can't
just cast to end and
compare I wish it were so now when we
moved to a week order remember a week
order is a total order among partitions
so what we want to do is take the total
order that we have for floating-point
and partition it up the partition that
makes most sense is to make all positive
Nan's equivalent then you have positive
infinity each of the positive reals make
the two zeros equivalent the negative
reals the negative infinity and all
negative Nan's are equivalent so this
gives you about as close to the
operators as you can rationally get now
both the strong order and the week order
have their uses it's perfectly fine to
have both of them in there then you need
to check your relationship with the
operators to see if you're consistent
I've done this the total equal weak
equivalence partial order it in
descending strength and then we get to
operator equal equal which is even
weaker than that okay on the left side
total is stronger week and then partial
less and operator less than have the
same strength there there event
essentially the same so we have a good
good consistency there when you move
into implementation though what you want
to do is make sure that you take care of
the common cases first right Nan's and
negative zeros are uncommon in most code
it'll be a small number of things that
you see small percentage of values that
you'll see those so we don't want them
to slow down the computation so we can
test regular doubles if it's less than
we know it's true if it's greater than
or equal we know that week less is false
and then we can go into the other cases
which takes a bit more time now
in case you're worried about me waving
my hands too much I'm providing my code
for all of these examples and the
implementations to the conference for
them to make available for anybody that
wants them but I do want to caution you
that if you compile on the ia32
architecture the ABI basically turns
signaling man's into quiet Nan's at the
first opportunity so it's hard to do any
testing on signaling Nan's okay we've
done floating-point now let's go into
another example and what I'm going to do
is look at zip codes and in particular
their relationship with zip plus 4 codes
for those of you that are unfamiliar
with US postal codes zip plus 4 is an
optional extension to the regular zip
postal codes the optional part
represents a challenge what we want to
do is figure out how to sort zip codes
when they might have five digits or they
might have nine digits one way to do
this is just to consider them all
strings and do a lexical sort this
provides a total order so it's good for
sorting but the problem is it sorts
123456789 as very different from one two
three four five and if we're trying to
look to see if it's the same address
written two different ways then we've
separated those in the sort and we're
not going to match up so you might think
okay well we'll just make a nine-digit
zip equivalent to its 5-digit zip so
that they'll compare equal okay the
problem is that if you look at the
relationships you can prove that they
don't meet the ordered partition
requirement so it's not a weak order and
it's not satisfactory to the sort
algorithm so we don't want to do that
but what else can we do well what we can
do is make every nine digit zip
equivalent to the same 5-digit zip right
so that all you basically ignore those
last four digits and only look at the
first five okay that gives us a week
total order or sorry a week order
because we partitioned the total order
into coherent chunks this is helpful
when you're doing a sort to look for
addresses that are the same and it's
useful in the context where you've got
other address information that's
strengthening the comparison on based on
the other fields okay the essential
point of this example is that both a
week order and a strong order have
reasonable use cases and we want to
enable both but before you go out and
write your own address application
actually the better approach to looking
for addresses that are the same is to
use various services that will normalize
addresses the post office will do that
for you so I don't want to give people
the impression they should run away and
code up this stuff right way so that's
another example but remember our primary
problem was composite types where we
have more than one field so let's look
at some comparison algorithms to see
where we get sort of the first one is it
every field says less well then
obviously the composite type compares
less this works but it will only ever
produce the partial order you can
demonstrate that it's not not not
transitive and so it's only a partial
order the next algorithm is ok I only
require that one field say it's
and as long as none of the others say
it's greater it's consistent it's
nobody's objecting and so I'll call that
less well you can pretty much proved
that that thing is only a partial order
but more importantly you can prove that
it isn't an order at all if any field is
partially ordered so for this algorithm
every field has to have a weak order for
it to succeed at all okay so both of
these algorithms produce a partial order
one might give you better results in
certain applications than another but
they're both still partial orders the
third algorithm is a lexicographical
this fails when any order in any field
is partially ordered you can demonstrate
that it doesn't give you a week order so
it's useful it's useless in sort
otherwise it produces the same order as
the weakest field so if you have any
field in your tight that has a weak
order the use of the lexicographical
algorithm will only deliver you a weak
order okay more importantly when you use
the lexicographical order the field
order defines the comparison order so
you have to thank very carefully about
which feels you want to compare first
because that's your major key right all
the next key is your second key and so
on down the line so you have to decide
which parts of your field are most
important to compare and there's there's
another technique in here that I
hesitate to mention so I didn't put on
the slide and that is to just use mem
compared over the type as it turns out
that this will dutifully compare your
gaps between fields and it will do two
ibly compare your pointers to string
rather than the strings themselves and
all of that so please don't use mem
compare
alright so now you have an approach of
what you can do but it's not exactly
nice so what can the standard do well
the first job the standard has to do is
maintain backwards compatibility we
simply cannot afford to break trillions
of lines of code but what we can do is
enable my creation to separating out
comparison on the application domain
with operators in comparison for the
utilities with comparators we can
provide a order and equivalents
functions for all the standard types
this gets a little bit tricky when the
standard type is a template and it takes
a user to find type so it will take a
little while to migrate the code because
if it's a template type it needs one one
of those less operators to have been
implemented on the types passed in so
that it can reconstruct it for the
following one out so if you do a basic
string of your favorite character type
it won't know what the ordering should
be there is more so we have a problem in
the standard library if I give you the
first code comparing a string we're
going to go look at every character in
the string twice okay the string
provides an operator that gives us the
result in one go and then we only have
to test an int to see which way to go in
our branches okay so we know the second
way is more efficient now let's repeat
that process for every field at every
layer of abstraction so we go down the
left side of our abstraction all the way
down opitz not
less than let's go back up the layers of
extraction now is it greater than let's
go back down the way over the
distraction so we're revisiting the leaf
nodes many many times and simplifying
the order analysis we basically double
the base of the exponent and even I can
figure out that two squared is much
smaller than four squared now the
problem we have is that the standard
library has no way to do the efficient
thing because they use operator less
they're stuck with migrating up and down
the abstraction tree so what do we do we
make sure that our standard algorithms
can can accept trinary comparators as
returned by like s compare okay but the
next question is is this a week
comparator or a strong comparator the
actual answer is it needs to be all
three of the comparators that we've had
this way when a algorithm like sort says
I need a strict week ordering it can say
I expect a function returning type week
ordering and it knows what to do with
that okay if you're doing memoization
you would say I need a function
returning a total ordering and then it
will pick up the appropriate function
carry on and act appropriately so in
addition to getting the trinary
comparators we also get a trinary
comparator that's very explicit about
the relationships we require to make the
algorithm work so rather than a small
sentence very deep within the language
standard we can actually get a compiler
error if we do something wrong
so the next question is can we make
coding easier well we can with some
defaults the first thing we can do is
think about providing an explicit
default for partial order the problem
here is that while unanimous always
works uncontained do we want to make the
default conditional on whether or not
there's a week order or do we want to
just say you're on your own if you want
to construct the partial order we could
probably get away with that because I
don't see a lot of people being
concerned about partial orders we can
provide an explicit default four-week
order and that's pretty straightforward
because only the lexicographical
algorithm works and it needs weekly
ordered fields so you could construct it
automatically by calling the the same
function on its fields and we can do the
same for total order it requires totally
ordered fields and to avoid having to
implement the same thing twice we can
apply implicit defaults so if you
provide a total order where you can
infer from that that you have a weak
order because all total orders are also
weak orders so with these kind of
defaults we can help with the production
of the comparators in many cases though
if you want a sort order that's
consistent with your operators you may
not want to use these defaults if you're
writing your own operators you might
want to do something more special so
given all that what is the path forward
for all of us to make things happen our
first task is to separate
responsibilities
okay you can solve the correctness
problem yourself but your life would be
much easier with standard help so let's
start off at the first sub bullet right
this is where you do all your booing
comparators so you can start solving the
problem the next thing that can happen
is the standard can provide booing
comparators to make your life easier you
don't have to rewrite those for the
standard types the next thing that can
happen is the standard can provide
trinary comparatives and algorithms
overloaded for them right so that we
will start shipping a new overload for
SCD sort that takes a trinary comparator
and does the right thing with it that's
a bit more work on this part of the
library implementers and then the next
thing that can happen is the standard
provides explicit defaults for
comparators and this will require a core
language change and now we can start
once we have all that in place now we
can start to push more strongly on this
notion that the operators belong to the
application domain and the comparators
belong to the standards utility domain
and we can start pushing the algorithm
defaults towards the trinary comparators
and away from the use of operators there
is a proposal in the works which is n
for 367 and any successors that will
come out of that in case you're
interested in details and given that we
move to questions
no questions in this is the ordering
fixed once and off for all by the you
know person writing the class or can
they take in SQL this relational
database they did with ordering all the
time essentially you know you to select
something you know and then you say
water by whatever things you want to
order why at that time so you know
column one column two maybe one that you
do that kind of query but the next time
you might do by column 3 comma column 4
and so here is it all fixed once and for
all at the very beginning you to decide
this is all you want to compare that I
think for not the question is does the
order have to be fixed at class
development time or can you defer it as
happens in relational databases for
couple sorting and all that I suspect
most people are going to want to fix it
once and for all that if you're and if
you're doing variable field stuff then
you want something a little more general
than this so you would construct your
own comparator perhaps using lambdas or
something like that and pass that in so
you would still do the comparators right
it's just that you might even
dynamically construct the comparator to
pass that into F into the to the sort
you wouldn't necessarily have sort by
default pick up a comparator associated
with the type you'd pass whatever you
want to do in explicitly you better that
the standard only currently only cares
about the less than or equal not the
same either less than or if something is
equal basically and then when right in
an application if I can express
everything in terms of less than instead
of like greater than or equal would that
have an impact in the speed of the four
months of the application okay so the
question is
f I could define everything in terms of
only less than equal to would that have
an impact on the performance of the
system and you can do that it will be
mostly as efficient but there are a
couple of cases where it might not be as
efficient the first case is that if you
do greater than that's simply a switch
in the parameter order okay so as long
as you've got that in line and have a
decent compiler you'll have no
performance okay for less than or equal
to if you do it properly you have an or
between less than an equal to and that
could implement that could introduce
overhead so if you can implement less
than or equal to directly you might be
able to avoid that overhead okay now if
you're lucky enough to have a totally
ordered type then you can do the trick
of not less than to get greater than or
equal okay and that might save you a
little bit for the most part the
performance difference is not going to
be huge there but you know like if
you're writing floating-point comparison
you really want to be efficient because
it's used everywhere so it depends on
your application if you've got a big
type rarely used probably doesn't matter
no more questions all right then thank
you very much and have a good conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>