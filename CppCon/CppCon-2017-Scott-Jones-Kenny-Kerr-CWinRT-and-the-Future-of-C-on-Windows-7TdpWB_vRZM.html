<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: Scott Jones &amp; Kenny Kerr  “C++/WinRT and the Future of C++ on Windows” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: Scott Jones &amp; Kenny Kerr  “C++/WinRT and the Future of C++ on Windows” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: Scott Jones &amp; Kenny Kerr  “C++/WinRT and the Future of C++ on Windows”</b></h2><h5 class="post__date">2017-11-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7TdpWB_vRZM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Well, thanks very much for coming.
This is C++/WinRT and the
Future of C++ on Windows.
My name is Kenny Kerr.
Scott Jones is down here.
He'll be helping me with some demos
and contributing in other ways,
and are from the Windows
team at Microsoft.
This talk is inspired a project
called C++/Windows T Now
it's started off as Modern
C++ for the Windows Runtime.
And it's all about
bringing modern, automatic
and standard C++ to the Windows platform.
So what's this talk about specifically?
So one of the things
that we're doing is we're
replacing proprietary extensions
with standard C++ code.
And we'll talk about what that means and
practically how you'll see that today.
Making Windows a great
place for C++ developers.
For a long time it seemed
as if Windows didn't really
care that much or that was the perception
and we wanna make sure that that changes.
Benefiting from advanced
C++ 17 and TS features.
So how we are internally
using features in C++ 17
to really make our library development far
simpler and far more efficient
and elegant and so on.
Even though the C++ library
is very straight forward,
there are no templates, there's nothing
like that you need to
deal with when you use it
as a customer, or developer
and certainly internally
we use a lot of these
techniques internally
to make it come alive.
And so we'll show you some of those.
Providing great tooling,
so Scott's gonna give us
a few demos of the tools
that we've produced and
how easy and elegant it is
to use them to really get a
lot of work done very simply.
And then we'll show, give you some idea
what's coming up next.
And looking into the future, what
we're working on in the longer term.
So what is WinRT and C++ WinRT?
So if you haven't really
been following along,
the Windows runtime is
really made up of these
three pillars.
Metadata language projections
and the Windows ABI.
So the metadata's essentially
the compile time information,
what is the Windows API look like,
what are the classes
and methods and so on.
And language projections
are the way that we project
that into a specific language
in a language specific way
so what is natural for C
sharp isn't natural for C++
developers or java script
developers as well.
A language projection is
free to take the metadata
and interpret it however
they wish and make it work
most elegantly and most
efficiently with various trade offs
for a different language.
The Windows ABI is often
overlooked, but it's really
essential because it's the
thing that binds them all
together at runtime.
At runtime we wanna make sure
that they can communicate
across language projections
and it's really the part
that the operating system
has the most influence
over and certainly the
contract the Windows runtime defines.
And so we'll talk more about that as well.
And C++ WinRT simply the
standard C++ language
projection for the Windows runtime.
It's a standard modern C++ library.
It's a header only library
so there's no runtime,
there's no DLL, there's
nothing you need to distribute.
You just hash include and off you go.
And it provides a classy type system
so this is not something like ATL of other
libraries you might have
seen from Microsoft before.
This is really gonna give
you first class support
for using the runtime classes
that the operating system
pro ports to provide and you can call them
in a standard way like
you'd call any standard C++
library such as SDL.
So who's using C++ WinRT today?
Obviously in Windows
we're starting to use it
quite a bit.
Office has started using it
and some of the applications,
Adobe Photoshop today lights
up on Windows 10 thanks
to C++ WinRT, Spotify
and many, many others.
It's a header only
library, we don't really
know who all's using it
but certainly based on all
the questions and the
feedback we are getting
a lot of people have started adopting it.
Which is great to see.
So from proprietary to standard,
this is one of the big sort
of themes of this library
and certainly our emphasis
in Windows in general.
So one example is C++ CX
from the visual C++ team,
we're replacing that with C++ WinRT.
You know a bunch of language
extensions in the compiler,
to something that's written
purely in C++ as a library.
Another example is decluspec and uuidof,
mainstays of common
development for decades now,
we're replacing those
with context per functions
such as guid of, which we'll talk about a
little bit more as well.
Another example is pre compiled hitters.
This is something that
VC projects, visual C++
projects have used for years,
but has really reached
the end of it's lifetime
in terms of what it can
support and scalability
rather inefficient
solution and we're really
moving all our emphasis and
all our investment to C++
modules.
IDL and MIDL, Microsoft
specific language and tools
and compilers,
that would love to move
away from and focus
more on standard C++ solutions, so how
could we take a proprietary
language and a proprietary
compiler and replace it with
standard C++ code as well.
And then whatever compiles,
if John Cates were here,
I don't know if he is,
he'd tell you about all the
scary extensions to the
compiler that we regret
having put in the compiler
in the first place but he
now has to maintain and
support those because so much
code is based on that.
But we're moving to a
world where we try to
compile everything with
permissive mindedness
which is a visual C++ flag,
that basically restricts
the things you can do
for the most part,
to conform in standard C++,
you also use Clang to
ensure that even further or
greater standard compliance
is reached by our libraries.
So what does it look like?
So here's a simple example.
Imagine your manager says to you,
go write a camera application on Windows,
you know, how on earth would you do that?
So the Windows runtime
makes that fairly straight
forward and C++ WinRT brings
it to you quite concisely.
So we start off using the
storage library a runtime class
to get the pictures folder.
It's a save folder method,
it's really a property called
save folder like return me the save folder
not save the folder, it's
a rather strange name
but let's go with that.
You could write a storage
folder object in which
you can then call the
create file a sync method on
to create the actual file in that folder,
so that gives you back
a storage file object,
then you can prepare the
webcam, you know, setting up
the drivers and whatever else is required,
and finally create,
actually capture the image
using that webcam and or
whatever camera's actually
associated with it and
storing it in that file.
So within one slide, thanks
to courtines and modern C++,
we can condense that
entire camera application
onto a single slide.
And it works really great.
So what does it mean
just beyond a library?
So in previous talks, James
McNeals and I we talked
a lot about the library
and the abstractions
how we project and surface
the run time in a way
that's elegant and efficient
for C++ developers on Windows
but we avoided talking
about the tooling 'cause
we weren't ready to really
reveal that and that's
what we're gonna do today.
So the way it works is
you have this tool called
cppwinrt dot exe and we
call compiler 'cause it
converts from one thing to another.
And you run it with a number of options,
one is in, local is one
of our short cuts and
Scott will be mentioning a few others.
And what that does is it
takes all the data in your
system, win metadata folder
and produces a set of
header files that represent
those API's in modern C++.
You can then simply hash
include that into your C++
project, and write your code
and send it to your favorite
compiler, clang, CL, whatever you prefer.
At this point the tooling
that we provided is
out of the way, you no longer
have to deal with it whatsoever.
And now Scott's gonna come
in here and give us a demo.
Can everyone see a console behind me?
- [Audience Member] Yes.
So far so good.
Okay, so the first question
you might have is where is
CPP WinRT?
Well it's in the STK, or it soon will be.
Next month when we ship
our first RS4SDK after
we ship RS3, we expect
to unveil the tools,
CPP WinRT the executable
as well as a projection
for the SDK.
So, it will be a first
class experience within the
console, this is a developer console.
Within visual studio, within
VS code, within any of the
tools that Microsoft supports.
Let's take a look at what
the options are for the tool.
Okay.
Just a handful really.
We're got, as Kenny
demonstrated on the slide,
we have a dash in option.
So, this is how I specify
the source metadata.
The WinMD files, it could be a file path,
it could be a single
WinMD file, we've got a
couple of pneumonic here,
down here for the SDK
I can say give me the current
SDK that's installed, and
optionally with the plus I
can say include any of the
extension SDK's.
Or I can say give me a specific
version of the Windows SDK
that's installed, if it can't
find it, it will error out.
Or I can say give me the local
Windows system 32 Win Metadata content.
Typically you wouldn't wanna do that,
usually if you're gonna
create a projection
you wanna control the
version that you're using.
But it really is, more or
less as simple as that.
We have references for WinMDs,
if we're building a
projection that's based upon
another projection,
then we need to specify
the reference to that other projection
upon which we depend.
And the reason for that
is just in the same way
that WinMD files can
reference other WinMD files,
well the projected headers
have a similar dependency.
And so that's how we would achieve that,
and then finally we have
an out parameter here
and this tells us where
we put the projection.
Okay.
So let's go ahead and build
a very simple projection.
And we'll just say give us
the local Windows system 32
Win metadata content and
create a projection for it
and put it in a folder called out.
And in the time that it takes
me to type that and run it
I now have a projection.
So if I take a look at
what's in that folder,
I have 280 some top
level name space headers.
Each one of these is a self
contained name space header
generated from the WinMD file,
and contains the runtime
classes and the machinery
needed to substantiate those
from a consuming perspective
as well as form a producing perspective.
So let's take a look at
how easy it is to create
a consuming application using
CPP WinRT using projection.
The first line I'm going
to type is not standard C++
but bear with me, this is just so I don't
have to create a project file.
Windows app is an umbrella
library that provides all the
Windows runtime free
functions, the entry points
and the functions upon which
the projection depends,
is implemented.
The next thing I'll do is I will include
a sample top level name space.
System, whoops sorry,
Windows system diagnostics.
What we're gonna do is diag nostics dot H.
We're going to consume the
system diagnostic info class
which the browser is
implemented in terms of.
So the F12 debugging, if
you've ever used that,
then we're going to reuse
that component, okay?
Using namespace WinRT that's
the top level namespace
for the Windows runtime, and
this provides entry points
like an apartment and make
template functions and that
sort of thing.
And then for the specific
namespace that we're going to consume,
diag nostics,
we'll type that in,
and then we just simply
init our apartment,
this is an extraction,
an exception friendly,
or exception enabled extraction
around the roman initial
has called.
And then we can just
substantiate the Windows system
diagnostics, system diagnostic info,
get for current system, there it is,
and in a very natural, intuitive way,
I've got access to the
static factory method get
for current system which
will instantiate the system
diagnostic info, alright?
Now, with that,
we will
access the
memory usage
property.
And then we'll go to trouble
with the intel sense today.
Upon which we will dot
in and access the report
property on that, and then final we will
access the total physical bytes.
I want all of that.
- [Kenny] Ripple teaching
the intelligent engine
to not think that we're the Windows AVI.
Yes, we're getting a
little bit of interference
but that's okay.
Alright, so.
On the info object, I've access
the memory usage property.
That's pulling back an object.
A temporary upon which I
am then invoking the get
report method.
And then from that I'm pulling
back the total physical size
and bytes, alright?
And then we'll simply just print that out.
Okay, now before I
compile this and run it,
I'd like to just call your
attention very quickly
to what would this code have
looked like if I would have
used the Windows resource?
The Windows runtime library, alright?
Which is the other
alternative that you had
up until C++ WinRT for
creating a native iso C++
client code for WinRT.
If you didn't wanna use CX,
then this is what you had
to deal with.
Well, as you see here, we
start off with some sort
of machinery, macro machinery
for dealing with H results.
Because those are front and center.
Everything, every property
access or every method
that you call, is returning an H result.
And so you see how that
begins to clutter and dominate
the code, the landscape.
I have to declare local
temporary for the system
diagnostic info statics, this
is just a construct a thing.
And then I have to
I have to supply a runtime string,
for the runtime plays,
where am I going to get that?
Well I simply scroll to line
2,789 I have a convenient
string definition for
the runtime class, okay?
I need to know where to find that.
And then I supply that to
the get activation factory,
that provides me a static
factory method upon which
I can call get for current
system, saving the result
into a local, a temporary.
Well I'd like it to be a
temporary but it's not.
It's a named, and then
returning out once again.
You see, you see how
ponderous and clumsy this is,
and how it really gets in
the way of a fluent chained
dotted style of programming,
which is really what I'd like.
I'd like to focus on the
domain and not on all this
other machinery, alright?
So that is what this natural,
modern C++ projection affords.
Okay, alright well let's
go ahead and build this.
I'm gonna build this with
clang, the latest distribution
of clang which supports
end to end compilation and
linking of a Windows executable.
As well as PDP file generation.
And the only reason I'm doing
this is just to demonstrate
that this is standard C++.
I can do it with clang, there's no tricks,
and to Kenny's point, I'm
not using all sorts of
compiler and extensions
that are Microsoft specific.
And then finally I'll go
ahead and run the program.
And there I have it.
So in just two lines of code, effectively,
two lines of user code,
I am able to hash include
create an instance, dot
in and there we have it.
Back to you Kenny?
Thank you Scott.
There we go.
Alright, so let's now talk about,
went backwards there for a moment.
Benefiting from C++ 17, there we go.
So this is CPPcon, you've
probably been here all weekend
seeing many ways where you
can benefit from C++ 17
in many different ways.
I wanna give you some concrete
examples of how we're doing
that within Windows, within this library,
we solve real problems if
you're curious, there's
some significant savings
we've seen over the last
years as we've picked up more
and more of those features.
Now one simple example is
nested namespace definition.
We picked this up early on.
It really turns rather of
a boast code into something
a lot more elegant.
We used a lot of namespaces
and types in Windows runtime,
and this makes our life a lot simpler.
It just makes the code a lot
more beautiful to look at
and use
and then when you get to
the offering experience
as well, the code that
you have to deal with or
are confronted with is also
a lot more concise.
Perhaps a more practical example
is this one from com array.
So the Windows runtime
inherited the allocator from com
which it was a, basically
an alec and a free function
similar to the C runtime.
And it's co task mem alec
and co task mem free,
and the Windows runtime
uses that to establish
and AVI portable array type.
Which is used in some cases, not all.
And the challenge is with C++ '03
you had to deal with this concept of well,
what kind of value type
or what kind of type
am I actually storing in this com array?
And so you might have this class template,
and before freeing it,
you actually naturally
wanna call the destructors on your types.
The challenge is what if T
doesn't have a destructor,
what if it's an integer?
Then this wouldn't compile.
And so you're forced to
use various less than ideal
solutions, you might have
complete specialization,
a partial specialization
for different types,
but it gets really uncomfortable
and awkward very quickly.
C++ 11 gave us a better solution,
so we can use type traits,
you can say well is
the value type attributed destructible?
In which case we don't have
to call this destructor
and we can simply do nothing.
So we can basically do type switching,
with these destroy overloads
and you can do that
if it's truly destructible,
or the destructor is, if it's not.
And this great because
the compiler sees that's
within a class template.
It'll not actually compile
that good or attempt
to compile that good,
in such specializations.
Now C++ 17 however does
much better and it says
well let me just take care
of all of that for you
and we can call std destroy
and it does all of the same
machinery behind the scenes
and again, compiles it
to nothing if T happens
to be some type which
is truly destructible.
And this actually avoids
a visual C++ compiler bug
or a cojan bug which I found
while preparing this slide,
so I'll save you the details there.
Another way we take advantage
of C++ 17 is with the
logical operator traits.
So this is an example
of an implementation.
So you can naturally
implement the I stringable
and the I closeable
interfaces for yourself,
your own implementation
and we'll take care of doing
all the machinery behind
the scenes that's also
required by the Windows runtime
in some cases.
And some examples include
implementing Iunknown,
reference counting in QI,
Iinspectable, Iagileobject
and Imarshal and others.
So how do we know when to implement these
interfaces and how do we implement them?
That's where the logical
operator traits comes in.
We wanna answer those kinds of questions.
For example, we wanna know is
this an agile implementation.
Should I be implementing
the iagile interface.
Absolutely always be agile,
but there are cases
where you might say no,
I need this to not be agile.
And so we have this non
agile opt out mechanism.
That's a marker type you
can just stick in there.
Or here or anywhere else.
In the vreadic primary pack to say
no, no, back away, don't
implement that for me, I'll
take care of this myself.
So we need a clever way
of saying well how do we
detect that at compile time.
And that's where the logical
operator traits comes in.
First off, we say well,
is I really non agile?
As in, it's not an interface?
And then we disjunction to say
are any of the interfaces,
are any of the types
here non agile?
And finally we use std
negation to say well
that's the result of
these agile type that we
actually care about.
And so we take a lot of complex reasoning
and we stick it in a type
A list that we can reuse.
A few more examples, is
factory is I inspectable,
and is weak reference
source, just more examples
we used inside the
implementation to make those
sort of deterministic
decisions at compile time
and to save you the work of
having to figure that out.
And we also do things like
doing, static assert on these,
so we make sure that cannot
actually produce an invalid
limitation without
getting a compiler error.
And that's just essentially
what we're expressing
there in that lost type alias.
Another example of how
we've really benefited form
C++ 17 is this example here.
So within a query
interface implementation,
this is a runtime method,
kind of like dynamic costs,
the caller would say well
given this squid representing
some interface, please
go ahead and give me your
implementation if you have one.
And so we need to first
figure out how do we implement
this based on our very
erratic parameter pack.
So one method is to say
use phiney, so we say
for this function template,
we'll only match this one or
allow it to be used by the
compiler's decision making
if first is an interface.
And if so, then we might compare the grid,
and possibly return the V pointer.
Otherwise we'll keep looking.
But now we need to go to somewhere else.
Some other function to
do the rest of the work.
So we have another overload,
another function tablet,
which does the reverse,
and it says if first is not an interface,
then we'll just keep looking.
So here we're essentially
just skipping over
that first type parameter.
And all of this code needs
to be written just to do
that simple skip over.
And finally we have the terminal pace.
We need to say well, we've
run out of type parameters,
let's go look elsewhere,
perhaps there's base type which
we get more functionality from.
Or we have this weird template
machine we have to deal with
which is awkward and
works but it's a pain.
Wouldn't it be nice to take
those three functions and stick
them into one.
And that's exactly what we
do with if quans text brook.
Here we can sit and
essentially say forget about
sphinay, and we start
at the top, you know,
is first an interface.
It's a compile time
expression so we can do that.
We then say well if it has
a matching guid then we
can return the V pointer.
Otherwise if there are
more type parameters,
we can keep looking.
'Cause it might even be that you know,
even though the first wasn't interface,
it might not have been the one you wanted.
And finally we can look
elsewhere if there's a need
for that in terms of a
composable hierarchy.
The point is we've taken all of that code,
which is supposed to get spread
out across a large header,
and stuck it in one place
that's easy to reason about
and certainly far simpler to write.
So another example of how the
Windows operating system is
made life difficult for C++
developers is with guids,
so we have these guids that
are associated with interfaces,
and we're added extensions
for years where you can
associate that guid with that
interface high stringable,
and then you can look it up
later on with UID off keyword.
And the way this works is
essential a cooler in the main
function might say I'm
looking for this interface,
it gets passed to the implementation,
which does the check
and possibly returns it
using that our parameter.
So, that works as well
as it does and you know,
we could probably live with that.
But then the Windows runtime
came along and made it
really, really complicated.
What is the quid for
the I vector interface?
Well the problem is it could
be one thing if it's an
I vector of int or it
could neither if it's
an I vector of a string.
It gets very, very
difficult and you have a
complicated of working that out.
They have to be unique.
So, before what we did
is this essentially.
We had a static and search
which would simply fail
and if this specialization wasn't found,
as in it wasn't in metadata
and we didn't admit
the specialization for you,
this is the bailout,
this is what you get.
And essential it boils
out to good luck trying
to figure out what the value should be.
We didn't include that
in the shipping version
but that's essentially
what we were saying.
So we replaced all of that
with a const text per function.
We literally have, all
those extensions are gone,
all the static assert is
gone, and we've baked it all
into the base hitter so you
can look at all the code,
and you can now simple
call the good of const text
per function and to get the
value out that you need.
And it works with whatever
crazy container of naps
and naps and naps of
containers you can imagine,
it does the work of figuring that out.
And how does that work?
Well I'm gonna spare you all
that code because it's non
trivial, but essentially
it boils down to this.
So we have these type traits,
so we have the full specialization
for the I stringable,
we know that good because it's in metadata
so we just roll it out,
but for generic interfaces like
ivector and imap and so on,
we have a partial specialization.
And in there we essentially
have a const text a function
which does what that
RFC says you should do,
we generate a string, given
the specialization that
you pass in so we actually
build that string dynamically.
At compile time, we create
a buffer with a certain
given starting guid and the
UTF eight representation
of that string that we just created,
and then we have to hash
it and grab the first
16 bytes of that hash we
then convert that to a guid,
that's those 16 bytes
essentially become the guid.
And then we have to turn
it back into little again
because where Windows and
do a bit more twiddling
and then finally you get the value out.
But you get the value out at compile time,
which is incredible, and all that pain,
really the biggest problem
we had with developers
using our projection
simply goes away thanks
to const pack per functions.
And there's many, many more
ways we're benefiting from it.
We used stood optional, stood variant.
My two favorites, we have string view,
and Scott James lighted
up for us diprocated,
so the Window's API is a
number of deprocated API's,
we now translate that
into using the standard
diproacted attributes so
that you'll get a compile
warning or error saying
hey, you should use this
other API instead.
For example, we have some
unique requirements around
code injections and and we
use has include in other
standard feature, this is
not a compiler extension.
Even though it looks like one.
And then coroutines, we
use coroutines heavily,
James and I chatted about
that a lot last year,
so I won't get too much into that.
There are things we haven't
started using because we're
waiting for the compiler,
so visual C++ will soon
give us fold expressions and
template argument deduction.
Which would make our
headers even simpler still,
so I'm looking forward to those as well.
So I know a lot of you have
asked me questions this
week about developing components.
And so we'll talk about that now.
So developing components is
largely the same in terms
of how our tooling works.
You simply call that same
CPP WinRT executable that
Scott demoed for us.
There's a dash component option
which lights up the component
authoring experience.
Now this is not a different
projection that it produces,
it's rather a super state of
the projection you would get
if you were otherwise
consuming those types.
But it includes a visual C++ project,
a module dot def file,
and the various scaffolding
you need to actually
alter your types.
Now again, this is not
visual C++ or visual studio
specific, but we do make it
very easy for you because
a lot of developers we know
wanna use visual studio
for their component authoring.
And that does give us
things like round tripping
when you're updating your metadata,
we update the scaffolding
underneath the covers for
you automatically, which
saves a lot of time.
And now Scott's gonna come
up and give us a demo.
Okay, so there are two sides to every AVI.
There's the consuming side
and the producing side.
We're already seen how easy
it is to create an application
that consume a WinRT component, the system
diagnostic info, let's see
how easy it is to actually
implement that same component.
So we're turning to our,
we call it a compiler, I don't know why,
we could call it a projector too.
It's a funny name, compiler,
we're always confusing
ourselves.
Let's take a look at the 3rd
demo here, the 3rd sample.
Which coincidentally is the
exactly the command line
I need for this demo.
So it's very handy.
So let's take a look at this.
We've got CPP dash WinRT dash
V using the single letter
abbreviations here for the options.
Dash V give me verbosout,
dash C generate that component
scaffolding that Kenny
just mentioned,
dash R reference WinMD
files from the current SDK
that's installed.
Dash N, use this as the
base name for the module
that I'm putting together.
This will in turn drive the
name of the output binder
in the yellow.
Dash F, filter all the fully
qualified type names that
I want included into my component
to those that begin with
this string, windows dot system
dot diagnostics dot system.
Okay?
And then finally out, create
the projection in a WSD folder.
I'm gonna go ahead and run
that and you can see 350
milliseconds I now have
my project scaffolding,
let's see what that looks like,
okay, we see the module
level, this module dot CPP
includes module walking
mechanisms, and activation
factory and that sort of
thing, we've got a pre compiled
header and then we've
got this trio of files
for each one of the top
level, the run time classes
that the component implements.
We've got as G dot H, this
is a template scaffolding
that provides the runtime
class, base class template.
As well as factory
implementation if you have that
for your runtime class.
Then we've got user defined header and CPP
and that's where we'll turn
our attention as we implement.
So let's go ahead and open
up that generated project.
Okay, so just from a
usability perspective,
we decided to throw all of
the generated scaffolding
into the generated filter
folder so we don't have to
be bothered with it most of the time.
Let's return our attention
to the consuming application
that we just created.
And we have four win runtime
functions that we're calling.
There's a static creation method.
Which gives us back the
system diagnostic info.
There's the memory
usage property access or
there's a get report
method and then there's
a total physical size and
bytes property access.
So four methods need to be implemented.
Alright,
so let's start at the top
and work our way down.
System diagnostic info, let's go in there.
Okay, right down at the
bottom here is where our
get for current system static method is.
Alright, so
I apologize for the scrolling but,
alright, now in order
to create one of these
I will use the make template
method and what this does
is will substantiate the
drive type and then it will
unroll the underlying ABI
pointer and create a smart
pointer that wraps that
and returns that out.
So, very, very simple to use there.
And then in turn we're going
to call the memory usage
property accessor and
generate for ourselves
a system memory usage so
I'll do the same thing there.
Now this is property generally
speaking we would probably
have this thing persisting
as a member but in this case
I'm just going to new one up.
And immediately I get a
red squiggly under make
and the reason for that
is because I just hopped
tracks to another name space
on there so I need to make
sure that I include that.
Okay.
Now I've implemented my
system diagnostic info class
and it's memory usage property accessor.
Let's move on to the memory usage class,
and we see the same pattern repeated.
In this case we're going
to implement get report.
And similarly I need to
hash include that header.
Alright and finally we'll
jump down into the report.
And just to make it clear,
we're implementing this
property while we're trying to fix value.
Okay?
And then the only other thing
I need to do at this point
is to address my constructors.
The compiler has been a
little careful on our behalf,
conservative and has deleted
all the default constructors.
Because activation which is
the WinRT word for construction
should be something that
we explicitly control.
So we'll just go ahead
and opt those back in.
Start with the system diagnostic info,
moving on to the memory usage.
And finally the report.
Okay, I'm gonna return back
to the report source and
drop a great point in
here before we move on.
We'll go ahead and build it.
First thing we see is that
there's a whole bunch of
spew here.
Or I see ref, ref, ref, ref, file SDK,
that's the CPP WinRT
projector component compiler
executing once again,
that's been baked into the
project scaffolding that we created.
And the reason for that is
because if I had started
with an itl file, or if I was
concerned at all about the
input Win metadata, having
changed I wanna make sure
there's a dependency because
that's what I've generated
my component scaffolding off of.
And so we've got that built
in as a custom builder.
Looks like everything built
so let's go ahead and copy.
The generated binary
into our Windows system, 64
and 32 well notification,
alright and then we can execute.
- [Kenny] You must be an Otis developer.
I must be.
Let's set for ourselves a
debugging application of
the application that we just
created.
CPP com, show them dot EXE.
Use that to drive, since
this is an improv component,
a DLL, we need an executable
to load the thing up.
So we'll just use the
program that we just created.
And we'll run and it hits our break point.
Let's take a look at the call stack,
I apologize for the font size but
we can see from the call
stack that we've got
two levels in show main
for our client application
and I'll just call your
attention again to the fact
that we're using PDB's
that are generated both
from clang and from visual C++.
And these are very neatly
stitched together in this
unified call stack, so that's kinda neat.
And then we've got two
frames as well from the
component itself, Windows
system diagnostics.
So let's pop back up here
and let's work our way out.
I just popped out of that top frame,
and we can see here that
we are now in the wrapper,
the shimming that shims
up right, in the component
itself, shimming up from the
ABI layer to the implementation
of the property or method accessor.
Okay, and let's keep going.
And very light weight as you can see here
very thin C++ wrapper that
compiles away to nothing.
And then we pop back out
and now we're back into the
consuming side and the
inverse, the cemetric inverse
to that which is the shimming
down to the ABI on the
consuming side.
That's all that you're seeing.
You've seen two functions
with three lines.
All of which are in line
and out we go and we print our output 42.
It's that easy to implement components now
with C++ WinRT.
Thank you Scott.
(applause)
That was a good demo.
Alright.
Okay, well what's coming
soon, what's coming next?
What can you expect?
So if you work Microsoft on
the Windows operating system,
you can look forward to the
Windows build being updated
with a compiler that supports
building, using this library.
We've had some trouble up til
now because the compiler is
slightly behind to have
publicly with visual C++
and it doesn't support
all the context for things
we need to actually make this work.
And so that will be
available fairly shortly,
I think in the next week or two.
Windows SDK for everyone
else in Microsoft and
around the world, that
you get to access this
through the Windows STK as Scott mentioned
pretty soon, I think
in the next few weeks.
Whenever the first RS4
STK comes around you'll
have access to those books and the hammers
and it will just work as you
have seen Scott demonstrate.
XAML compiler is something
a lot of people have
asked for or even if
they didn't ask for it
it's what they imply when they say we want
full XAML support.
It's something that sort
of straddles visual studios
and the Windows operating
system and it does
all the language specific
code gen within visual studio
and that team is now
actively working on doing the
code gen for C++ as we speak
so that will be working fairly soon.
And then what we need
finally is visual studio
to bring it all together
and give you that file
new project experience
that everybody enjoys.
So that's all coming,
finally sort of coming
together really well which
has been great to see.
Then looking into the
future I wanna talk a little
bit about what we're
planning to do in future
you know, what are the
ideas and things that we're
investing in because
certainly the work isn't done
yet, we have a lot more to do.
And you know, one of the
things Scott mentioned,
well is it a compiler or
is it something else, well,
I'd love for it to be nothing
and I'll tell you why.
But first I wanna mention
something that's really
important to me and
important to the success
of model C++ in general,
which is the optimizer,
making sure that we can
train the optimizer to really
do the best possible
job with model C++ code,
otherwise there's this
whole class of developers
we're leaving behind,
developers that really need the perf that
we need to give them.
So one of the big things for us and that
I've demonstrated already
and last year as well,
we talked about this is
using modern C++ techniques
even within our implementation
to reduce the complexity
of our internals and reduce the complexity
of our implementation, such
that with every version
of C++ WinRT, the projection
itself has actually
gotten smaller and simpler
and more concise and
more to the point.
And what that means also it
helps in a number of ways.
One of the things we've
done is moved a lot of our
code to const text bro.
Which actually has a great benefit for
binary size 'cause there's
so much more data that
can actually be stored
in a more efficient way
by the compiler.
We also reduced instruction count.
Brian, who's over there,
he's on our team and he did
a number of great optimizations
to reduce the size of
the instructions that are
actually laid out on disc
for the implementation of
certain very high traffic
codes such as sting input parameters.
And that's great to see how
those optimizations can be
tightly controlled and
make a big impact on large
scale components.
We have internal teams like
XAML that will be using
this now for the implementations
of their own DLLs and
at that scale when you
have a DLL that's 15 megs,
it's pretty big deal when
you can save a few bytes
on every instruction or on every API call.
In line all the things,
so when you get to modern
C++, you're talking about
constructors and what is
effectively a property
something that returns the value directly
rather than as a parameter.
Those things what we return, and we create
all the temporaries that
you saw in Scott's demo,
they're all tend to be
objects with non trivial
destructors.
And the trouble is the visual
C++ compiler has for decades
not been able to inline those things.
Those types of objects.
You have function returning
a non trivial destructor
or returning a type with
a non trivial distructor,
you cannot inline that function.
You have a function with a tri catch book,
it's not gonna get inlined.
Thankfully, that now was
enabled with a compiler switch
first and now it's on by
default in 15 dot three.
Which is immense for our
libraries and libraries
like us for SDL, things like that,
because the compiler finally has the
far greater ability to inline and optimize
and make good decisions
about how you wanna optimize
your code, whether its for
size or speed or somewhere
in the middle.
And really what that comes
down to is talking semantics
with the compiler, saying to
the compiler more about what
you, what you're trying to achieve.
You know, Scott's demo
showed two lines of code,
which really concisely
expressed what he was trying
to do, rather than how
he was trying to do it.
Where as the world code the ATL style,
age results and pointers,
it didn't really tell
the compiler anything.
Now thankfully, most C++ compilers today
are optimized for C code,
so that's great for that
code but what we wanna
do is make sure it's
C++ compilers today and
the optimizers they come
with are really geared
toward optimizing libraries
so we don't have to compromise our designs
in order to get the best
possible performance.
Context all the things, I've
already talked about that.
So much benefit there for
us to put more and more
work into the compiler and compile time.
And exceptions, exceptions, exceptions.
So much of the design we
have today with libraries
pre supposes that you are
using exception handling
or at least that you're
using exceptions as a way to
report errors.
Now you might write an
application using a library like
this and never have a catch block.
And that's perfectly fine.
But when something exceptional happens,
it's gonna get you out of
there and crash the application
you might even get a
crash dump from Microsoft
or from your own server
and you'll have the data
you need to really track that down.
The trouble comes when
you're the operating system
or you're a component
and you need to cross
and ABI boundary.
At some point, you hit an
ABI boundary, like you're
implementing one of those
methods that Scott implemented
in his demo and something
goes wrong and you need
throw in an exception.
At some point you hit that
ABI boundary and you need
to stop.
You cannot have an exception propagate,
that's not gonna work.
So you need to turn that
into an H result of something
that the ABI can convert
into something that another
language projection or another compiler,
another tool chain can
convert into their own
form of air handling.
And the problem is that catch
block is what's expensive.
That's where a lot of our
code book comes from today
in our compilers and so
we're working with a C++ team
to give them those kind
of repos, because we can
create a component with
thousands and thousands
of ABIs, of methods that might
catch and throw exceptions,
very quickly so we have the
ability to give the compiler
team these incredible repos
that they can then use
to optimize model C++ code.
And this something we're
actively pursuing today.
So that's a big deal
and I'm hopeful to see
even more, even as the
compiler's done immense work
to optimize for modern C++
over the last two years,
we're gonna see even
more in the coming years.
So, two more things I wanna talk about.
One is C++ modules.
Now C++ modules, I mentioned it briefly,
why does this matter?
So today, as we illustrated already,
we have this model where
we have this win metadata folder or some
other set of win MDs
and we post it to our CPP
WinRT compiler as an input.
And as an output it
produces these headers,
and you saw that live and
it works so that's great
you know, you get headers
and they're standard C++
and you can simply hash include them.
So what's wrong with headers?
Well there's lot of them,
there's over 1,000 headers.
Earlier versions of the
projection had even more,
close to 2,000.
So we've condensed them
down, but there's still
a lot of headers.
Roughly 1,032 at this point.
That amounts to about
40 megs worth of headers
of source code that the
the compiler needs to pars.
And that takes a long time,
and when you're building
a simple consult app
like that camera application,
that's not a big deal,
but when you're using come
of the larger name spaces
like XML name spaces, they're very big
and it can take 30 seconds
or a minute sometimes even
to just compile those headers up front.
So pre compiled headers
are not the solution.
They're huge, the problem
with pre compiled headers
is that they essentially
take the layout of that type
information in memory and
just write it out to disc.
So you can easily end up
with enormous PCH files,
which are unwieldy and
take a lot of space.
They're not efficient,
and of course there's
other troubles as well.
They're not reusable for one.
So you have a visual studio
solution with a number of
projects, you cannot share the PCH,
now there are some hacks
I've seen people do,
but it doesn't work well.
And they don't offer isolation,
so you have your header only library
and you've got macros in there perhaps,
hopefully not but perhaps.
You have some implementation,
name spaces where your
doing some internals and
you'd like to rev that
and change that from
one version to the next,
but all of that leaks out
so app developers can take
advantage of those things
and it really causes trouble
for you and for them,
because of that.
And finally, 40 megs of
headers, big compile time,
all that memory layout, that's
gonna hurt your machine.
You're gonna often have
to use the big object
flag with visual C++,
in many cases clang won't
even compile out headers.
If I include every single
header that we have,
the clang compiler will not compile it,
it runs out of memory.
And visual C++ handles it, they
know me well now, but
but you often have to
use the cross compiler,
which means you use a 64 bit compiler,
to compile 32 bit code,
'cause you have a bigger address space,
and that works great.
But some people can't use that,
the last time I checked,
last time I checked,
the Windows operating
system cannot be built with
a cross compiler because
they don't have enough memory
or it takes too long
or something like that,
someone could correct me
but that's what I heard.
So it doesn't scale.
As a more visual example,
here you have the includes up front there,
so that's how you do it today.
And that amounts to between
one and three gigabytes of PCH.
And it's very error prone as well.
So you've just done that but
those name spaces might
include declarations of types
but not their definitions,
and we do that because
we're trying to avoid
creating big PCH files.
But the problem is you'll get a link error
saying you've used some type
and there's no definition
and you get this cryptic link error that
says something about name spaces and stuff
that I don't recognize.
And so the solution is just you've missed
a name space, go and include it.
But I'd love for that
problem just to go away.
'Cause it's really weird.
And the final issue with this is that it's
rather redundant.
You know, you've named all
the name spaces at the top,
you name them again at
the bottom because those
are the ones you actually wanna use,
and it gets real tedious pretty
quick in a large application.
With C++ modules, all of that goes away
'cause you don't need PCH files.
You simply import WinRT,
because it's so concise
and so efficient, you don't
actually have to have a
WinRT module per name space,
you can just have it for
the entire Windows API.
Now perhaps XAML gets
enormous in the future
and we might might have a
WinRT dot XAML just for them.
Similar to the way the
standard libraries are creating
subsets of names, of modules.
But it eliminates all the linker errors.
There's no redundancy,
you just declare the
name spaces that you'd
like to actually use.
There's macro isolation,
so the way we define the
module for C++ WinRT
we can specifically say
this section of types
of functions within this
name space is gonna be exported.
And the rest won't be
exported so we can easily hide
all of our implementation details
and implementation name
spaces all internal to us.
And finally because the module
format is a binary format,
it dramatically improves
it's intellisense.
So intellisense works
reasonably well in visual studio
today, they've been
testing our library for
quite a while now.
A VS code as you see
doesn't work that well.
They haven't caught up yet and it's not a
great story there.
But with modules, we're simply
saying don't worry about
parsing my code, I mean
what visual studio does
is literally re parses all
your code with a different
compiler and then produces that
experience that we all love.
But's not a very efficient story.
With us it'll be much more efficient and
we get dramatically
bare both times as well.
Alright.
So, reflection, code
injection and meta classes.
So this is looking more into the future.
No doubt you've heard
about static reflection
and code injection this week.
And during Herb's talk on meta classes,
he mentioned a number of these things.
And this is something we're
pursuing and we've been
working with Herb Center
for quite some time now
to make sure that what will
eventually become a standard,
is rich enough and expressive
enough to deal with
what we're trying to do.
So halfway through Herb's talk,
this pops up on my phone.
So, when are we going to
see C++ WinRT implemented
as a constexpr WinMD parser
and a set of meta classes?
And this is James McNellis
and he was my co presenter
last year at CPPcon.
So it was quite surprising,
not that surprising,
but it was quite funny
because I didn't prompt this
I didn't pay money, this
was just a random comment.
Absolutely.
The interesting thing is this
actually what we're thinking
of doing.
So it's very interesting.
So to begin with, we know today
we have consuming metadata.
This is a basic scenario that we have.
You start off with meta
data files and WinMD files.
You stick them through our compiler
and you produce this set of
standards C++ source files.
The producing side is a
little bit more questionable.
Now we have good tooling
and Scott demonstrated this
so it does work.
But the question is you
know, starting with standard
C++ code, how do we get to
the results we really need?
We send our C++ codes
through a compiler, clang or
visual C++.
And we get that executable.
But how do we get the WinMD?
And that's the challenge.
So today we have a
slightly complicated story.
So you might start with
IDL a project dot IDL file
which is that proprietary
language that I've mentioned.
And we then stick that
through the middle compiler
to produce a WinMD.
And then we have to feed
that all the way around
back into our compiler to
produce the scaffolding
or update the scaffolding
that we used to then
actually compile the application with C++
or standard C++ today at that point.
Now this is obviously
not a great scenario,
you don't wanna see an
architectural diagram like this
that would be a really bad
idea if you were to come up
with this at a meeting
but this is actually
what we do, this is the steed in which
we've evolved our platform.
And we're working very hard to come up
with a better solution.
And one of the tools that
we're gonna use for solving
this problem is meta
classes and reflection
and all these things.
And what that essentially
allows us to do is
define everything, both
our consumption story
as well as our production
story inside C++.
So you can imagine that re
meta data and like meta data
are constexpr functions.
Now re meta data might
literally go and find
files at compile time, load up the file,
pars the meta data just
as James was saying.
And it might also define,
the project itself
might also define additional
types, runtime classes
and so on, APIs.
It might even use those
types that it imported
as part of its implementation.
And then finally it would
write down the meta data
to a file again.
Again, those are both constexpr functions
they're both having a compile time,
so it's really not, so
at the end of the day
you end up with an
executable and a WinMD file
but it's really not the
compiler that's producing
them like a WinMD file.
Like with C++ CX it was
literally visual C++ doing that.
But today's literally your
compile constexpr code
that does that for you.
Or now today, in the future,
if we manage to get this to work.
So this is where we're
going with that story.
This is a kind of thing we're thinking of.
There's a lot of hand waving here,
I mean the meta classes
work that Herb Centers
invested in and Andrew
Sutton, if you saw his talk
the code he's written in
the prototype compiler
actually works, and it's
incredible to see it.
You can see it on the compiler explorer,
there's even a page there
where you can try it out.
But it's still far in the
future, so this is what we're
planning to do, or at least
what we're investing in to
see how far we can take
this to make a great
experience for C++ on Windows.
Just as an example, here's
what we might imagine
to see a number of meta
classes for the Windows runtime
and as Herb was saying,
this is how we would define
the constraints or the
defaults for those types
to categorize them more
clearly in a way that we can
then use static reflection
to say this a property,
this is a method, these are all the things
we can unambiguously define and identify
in your source code
which we cannot do today
but in a way that we can
then clearly produce metadata
from those artifacts.
So what might an implementation look like?
Well here's a rectangle interface.
So WinRT has interfaces and classes,
this is just a class
but it's a meta class,
it's based on a meta
class and so we can use
the compiler to give us the
declaration for those things
and then we can go even further
and say well here's both
the declaration and a definition.
The compiler through meta
classes and static reflection,
can take this, fold it into
the number of projections
that we need.
So if you think of C++
WinRT as a projection,
that's true, but under the
covers we create a number
of things, we create an
ABI, and so a production
experience, we create
with a V table and all
those things that you
might program against.
Internally, we create
a production side and a
consuming side, those
are the shims that Scott
was mentioning in his demo.
All of those things
need to be, all of those
artifacts need to be created.
At some point and we can
use meta classes to produce
them with code injection
and static reflection
to figure out what to produce.
Now finally, I wanna just
mention if we have time
that it's not just about saying
C++ needs to improve
because we have this great
Windows platform and
we're just waiting for you
guys to catch up.
We're also trying to see
what we can do in the
platform itself to bring
the platform forward,
make a richer, more
programmable platform that we
can serve the needs of the
C++ compilers and tools
and especially the high
performance needs of certain
teams.
So one of the things that
we're imaging that we could
do for example, is look at the
ABI for the Windows runtime.
So today this is all hidden
inside the projection unit.
You don't see any of this.
But the reality is that the button class,
let's say you have a
button class and you have
this ibutton interface,
it starts off by the root
interface is obviously
iknow, and it has three methods
and then it's I inspectable
with three methods, and then
finally you tack on the end
whatever's specific to your interface.
So if you're button
implements I button and I
stringable, there's our
two different V tables
with all of those methods.
And then on the left you
see what's essentially
your instance,
your instance has two VF pointers,
and this is a runtime cost,
this impacts the size of your
object and memory.
Now you might, second version,
add a second interface.
You wanna add some more
functionality like a
color property.
And even a third, but
as you do this you see
that the instance size grows.
And so that's a problem for implementers,
certainly with large APIs,
this is gonna quickly become
a real problem in terms
of their implementation getting
more and more expensive,
over time.
Now the solution if you've
developed com applications
for years, might be obvious to you.
Interface inheritance.
We've had this for years,
it's been around forever,
button three, derived from my button two,
my button two, derives from my button.
This is not a shocking revelation here.
Every person I've talked
to about the problem
they immediately jump to the solution.
This is clear this is something that would
immensely help us from an
efficiency prospective.
So we're looking at how we can do that,
but it's not only an issue
for component authors.
Application,
yeah, sorry, there we go.
So this is essentially just another view
of the same thing.
So button three derives
from my button two,
which derives from my button.
What that means that
is that my button three
is a super state of my button two, which
is a super state of button.
So from an efficiency
perspective, this is ideal.
You've been able to
condense the VF pointers,
there's only one VF pointer
for the latest version.
There's a VF pointer for any
other polymorphic interfaces
that you might wanna implement.
And then all of the actual
interesting implementation
details for you component
or for your runtime class
are gonna be condensed
into a single flat list.
Now as I was trying to say,
this isn't only a benefit
to component authors, this is
a big deal for applications
as well.
Teams like office come to me and say well,
calling this WinRT APIs
is rather expensive,
what can we do about it?
Well why do they say that?
Well let's imagine you have a button class
you've just created that
object on the stack,
internally it holds an I
button interface pointer,
you wanna set the text property,
no problem, that's a virtual function call
to the put text virtual function.
Now you wanna set the
color property, sure.
C++ WinRT does it for you,
but it has an injector
called query interface to
get the appropriate V table
in order to make the
second call to put color.
'Cause that's a different interface.
Rotate as much the same,
and so is query interface.
The trouble here is obviously
all these additional
calls and let's not forget
about all the release calls
at the end.
All of that fills up your binary.
It's more code to execute,
if you were at the good ball
talk you would've seen
all that machine code,
you know nano seconds worse
than stuff he's mincing over,
this is dramatically more,
this is a lot of CPU cycles
doing all those virtual
functions as grows your binaries
this can be a big problem
depending on the scale of your
application.
With the streamline AVI,
this gets almost as straight
forward as you can imagine.
In this case we're holding
on to I button three,
this is the virtual function call,
so it does this and this.
There's no other overhead here whatsoever.
This one naturally's still
a polymorphic interface.
Which anyone can implement,
so we QI for that as before.
But we've reduced a lot
of the instructions in the
implementation and we've
done it in a dramatic way
which saves not only a component author,
and the application's address space,
we've also saved code
on disk, made your code
far more efficient.
So these are just some of
the things we're thinking
of doing, we're dreaming
about we're trying to see
how we can move the
platform forward as well
as the C++ compiler to
make this world where C++
developers really love using windows.
And thank you very much,
you can download it today.
You can learn more there
and you can follow me.
(applause)
So if you have any questions,
feel free and we'll be
here afterwards to take them as well.
Great, we answered all their questions.
- [Audience Member] Hi, I
got two of them actually.
Complicated related.
The first one is you've
shown that the arrows
are sent by exception in the competence,
but on the client side, I saw that you use
a lot of dot operators so
how do are arrows any of that code failed?
Sure that's a great questions, so
again, this all comes down to the ABI.
So within the implementation,
you use modern C++
and you throw exceptions of
what errors to propagate out,
but when they hit that
ABI, we essentially have a
catch dot, dot, dot, dot,
which takes that exception
and turns it into an
appropriate age result,
mostly as things for the
debugger to be able to light
up with stack information
a bunch of other things
that we need for error
origination in the platform,
and then it simply returns the age result,
which is the error code, that
represents that exception.
The language projection
on the consuming side
then resurrects that
exception and rethrows it,
so it takes the error
information and turns it
into an exception again
and just goes thrown that.
So it's as if you threw
from one side to the other
but it went through this ABI,
so it could be one
compiler and another and
still just works.
- [Audience Member] Yeah,
I can definitely see
the point.
I have a question, I really like the fact
that you try your first demo with clang,
that was very cool,
but my question is if we go from modules
since it's clearly not
stated if the binary
for the modules would be the same
between compilers, how
would it work between
VC and clang if it's
not specified anywhere.
Sure, that's a great
question for the compiler
teams.
We're just consumers like you,
we write libraries like you.
We're not specifically
involved in the generational
or even the definition of
the module specification.
My understanding today
is that it's compiler
specific so you get an OBJ
file, you get a binary,
but they may not work
across different compilers.
But it is great for a
scenario let's say you're
building Windows and you have thousands
and thousands of projects,
you don't wanna recompile all
those things you could have
within that contained environment,
one module that defines
those sets of things
that you're reusing.
And you can have 'em in
savings and even if you
have visual studio
project with a number of
projects in it, solution with
a number of projects in it,
again, you're gonna get big savings there.
But it doesn't necessarily
address the portability issue
in the way that you're saying.
- [Audience Member] Alright, thank you.
You're welcome.
- [Audience Member] So I was just curious,
can you actually also run
this on Linux so that you
can kinda do
continuous integration
and maybe deployment
from a Linux build system
to a Windows application?
Okay, so you're trying to
target Windows but you're
trying to build it on Linux.
Probably not, I don't know.
Just to clarify the continuous
integration being the
generation of the projection,
because the artifact, this
is just a header collection,
a header library, pure header library, so,
what is it that you're imagining would
be continuously integrated?
- [Audience Member]
Possibly the projection, the
kind of like the
Microsoft header codes and
just the both the consumer and the.
Sure, sure.
We do that already internally,
we've got a TFS project
that we have continuous
integration turned on and
it's constantly rebuilding
our compiler and then using
it to generate projections.
And so I could imagine
something if you were say,
Win 2 D or some component author
and you wanted to make
sure that every change
to your interface
definition would generate a
corresponding projection
without you having
to lift your hands to do it,
then you could do the same sort of thing.
So sure, yeah you could do that.
At the moment though,
the tools that we built
and the libraries we've written,
although it's standard C++,
it's obviously Windows specific
and we're focused on that
right now.
I do have some enthusiastic
volunteers at Microsoft though
who are very concerned
about cross platform
and so we have a guy
named Harry Pearson who's
obsessed about this
and he's taken our code
and our tools and he's
ported all of it to Android.
He has it running on a number
of different platforms.
So in that sense this
has been very successful.
But that isn't our primary
focus at this point.
- [Audience Member] Thank you.
You're welcome.
Alright, well if there's nothing else,
thanks very much for coming.
(applause)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>