<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2015: Detlef Vollmann “Executors for C++ - A Long Story ...&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2015: Detlef Vollmann “Executors for C++ - A Long Story ...&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2015: Detlef Vollmann “Executors for C++ - A Long Story ...&quot;</b></h2><h5 class="post__date">2015-10-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sAJGoHN6Xx8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is to talk about executors for C++
it's not how to use them it's what they
can do for you and how hard it actually
is to get executed right and it's called
a long story and that long story hasn't
ended yet so we don't have a final
executor interface yet in C++ so what's
the mission of an executor well some of
you may know the async problem so if you
look at the code and so with a set up
here is not very optimal um who of you
believes that this will put out hello
world okay who of you think it will put
out hello
who of you think it will put out just
college and or just a mix of those
letters and who of you think it's just
undefined
okay daiva actually very few of the
right answer because the right answer is
it will guarantee put out hello world
and that is not really known to a lot of
people you have absolutely no
concurrency here
and the reason for that and that is a
little bit the scientists the acing
problem and the a thing actually that
turns the future and normally these
structures of the futures don't block
except if the future comes from an
amazing
so in our code here well we don't
actually capture the return value so you
get a future out of the a think and well
you don't capture their future so the
destruct of their future is immediately
called and the destructor blocks for the
ending of the task and so you get
absolutely no concurrency here and that
is actually good because lifetime
control is very important for the class
class this is what makes c++ different
from all those managed languages like C
sharp or to our board or anything else
and the problems with the a thing is you
have absolutely no control about the
execution agent agent that actually once
your task and so you have no idea how
long it actually wants and if their task
actually uses references some of objects
that are also used otherwise but you
wouldn't need to know when it actually
finishes to use those objects and this
is why we have the blocking the blogging
is actually good the problem is that we
have
for a future different behavior under
destructor whether it comes from an
async or from some grounds and the
reason for that is well you simply have
nothing to control when the lifetime of
your async or of the task ends so that
is why the ocean a thing is not really
optimal another motivation motivation
pipelines we actually had a proposal for
that and well the example here comes
from an old oops lab work shop how to
pretend concurrency to students and so
the exercise is actually okay you have a
restaurant and you have number of orders
coming in and then you have some chefs
who could prepare the meals and then you
have some waiters who actually deliver
those meals and if there is nothing to
do anymore everything else and this can
easily be with using that pipeline
proposal so you say you have Swiss chefs
and for waiters and the orders
conveniently orders come in to some
communication mechanism to the chefs and
the meals prepared part by the chef's
comes with some communication mechanisms
to the waiters and then eventually it
ends and this can be won on a sweat pool
on something else so what actually are
the requirements for the executors well
to hunt ours and to give some control
about lifetime
well so we got a very simple kaposin
originally net came from Google that
there was yeah somehow a similar purpose
of Microsoft and eventually they just
joined the proposal and so the executor
interface well it wasn't a face class
and it had one function just to put a
new task to the executor and the execute
eventually execute their task and as
usual if you get some requirements to
programmers they will give you more than
you actually asked for maybe not exactly
what you asked for but they will give
you something so you also got the
Commission initiated task count net
turns ought to be pretty useful
sometimes so that was nice that is not
really the virtual interface but that is
what it boiled on to and then we had a
default executor and some mechanism to
set the default executors oh that sounds
nice and then the proposal also proposed
some concrete executors not only the
interface but also some real executors
that actually do some work of course at
that pool the last serial executor this
just one one task after the other on the
same threat but on a different thread
then the caller the inline executor well
that actually calls the function right
away on your calling thread and the loop
executor is something in between but
it's also serial and then you have this
great executor that just spawned of a
new task a new set for each two
allocated
and those are actually interesting
because they have completely different
semantics concurrency wise the set
executors which justice spawns a new
threat for each task well that is a
really concurrent the serial executor
isn't really concurrent because it does
one pass over the other nowadays we call
that it has parallel execution semantics
and that is a little bit
counterintuitive parallel means it can
actually be cereal while concurrent
means it has to be in parallel this is
how it is yeah the point is parallel
runs on as many calls as you have and if
you have only one core you don't get any
authority yeah
so with that proposes we can actually
solve the icing problem so we can either
define new launch policy say don't
execute and put one on the default
executors well maybe that's not such a
great idea baby because it sometimes
really makes a difference because you
have the set default executors you have
no idea what guarantees you actually get
from the executor is it a concurrent one
or just a parallel one and well but
anyway you could use that one and even
the normal standard async could use the
default executor but it still has to
block on the future destructor because
this is what people expect now and as I
said sometimes it's very important that
you know then the lifetime of your
thoughts has finish finished so you can
just clean up all the global objects it
might use and the most important
interface would be the last one you just
give it the specific executor you want
to run the task on so that's nice if you
look at the pipelines well this can
really be implemented on the proposal as
well so nice what result we have
executors and that is why the
concurrency study group decided to put
this proposal into the concurrency tiers
well we have used 15 minutes of the hour
so you know it's not the end of the
story because now the wheel discussion
started well some of that already
started before and one of the problems
is the original propose just used an
extract extract base class interface
that actually is very useful it's not a
template concept it's an actual base
class it's not part of the time which is
not really important for function but
for structures that can be very
important so we did that mistake I think
it was a mistake with the containers
that the allocate is actually part of
the type and so we got scoped allocators
in C++ 11 to work around that and so
that is one point the executor if it's
an extra base cause is not part of the
time and the second thing is it can
cause spinal interfaces so you can
actually provide a lively that takes an
executor
and they're like we can be by the way
only and it gets the executors it gets
to the exit based art it knows what
function it can call on that so
everything is fine however sometimes it
simply costs too much if you had it if
you have a lot of very small tasks you
don't want the overhead not only of one
virtual function call but actually of to
be because what you're at function
actually takes it's a state function and
that internally uses a virtual function
call as well so we actually have two
virtual function calls for each task
that you startin that executor and
sometimes that costs a lot and we got
more requirements so one of them is
stuck then so we have two then the ten
proposals so the future to attend which
is a continuation that the ones after
that future is finish is ready so if
your first house is has finished you
know what you want to run after that and
so you just startin anything with
something and you this time you actually
captured it you use that future that you
get from the racing and yet when you say
ok on this future you want to put
continuation and that continuation
should run on my specific executor okay
that's fine
that works with the old proposal the
problem is if you don't give it an
executor on which set should it
preferably one well in a lot of cases it
would be very useful if the continuation
runs on the same sweat
the original function the original task
however how does the dot then know that
if you don't control the whole library
but only your very small things then you
might have a problem to me to know that
so you have no mechanism right now to
transfer that information the previous
proposal
another thing is well I lives in the
embedded world I'm just curious how many
of you two embedded systems okay thanks
interesting that would definitely be
different in Switzerland for example
because in Switzerland
nearly all chief justices on embedded
systems and sometimes I just have to use
real-time and we talk priorities so we
have something like the pipeline in this
case it's just the data concentrator and
it has two producers who wheat from data
from two different devices and then we
have a consumer that takes all the data
does some calculations on those and
finally we act on that one or stores it
somewhere or whatever the main point
here is you have to put use of that week
from external devices and one of those
devices doesn't really have an internal
buffer so that really needs a very high
priority so that you don't miss any data
if it signals you okay
data is available you really have to go
for that data independent of all the
other things that your core is currently
doing so you need a very high priority
on that one you don't really need high
priority on the other ones so you want
to run
that concentrate concentrator well and
one of the tasks has a different
priority than the others
next example a CEO who of you has
already used boost a CEO oh so you know
what I'm talking about so this is about
asynchronous input output input output
is asynchronous piety form by definition
essentially and so this is really meant
to be high-performance input-output
library and so it generally wants to run
the continuations of your i/o on the
same set that the operating system
returns from your i/o call and often you
want to run concurrently but sometimes
you actually want to run cooperatively
on one single sweat so all your tasks
don't have to synchronize anything and
this is actually doable with a zero and
it definitely doesn't want the overhead
of the future because you just have to
synchronize and if you want if you know
you one of the singles Wed anyway well
you don't want the overhead of the
future and it wants well provides its
own executor but it should also be able
to run on user-defined executors which
has additional knowledge about the
system and maybe additional
functionality so system specific
asynchronous events like signaled
interrupts mailboxes that you have some
small embedded services and things like
that
well this is your live with actually
videos by now and so there's a lot of
experience with that one but of course
that is very specific very specific
requirements for asynchronous input on
so now we have new requirements so we
got new proposals so we were missing
here and so the first proposal was
actually by Chris Cole of based on Asia
so if you had internally executors so he
proposed just that and it has several
interesting things one of them is it
makes difference between the executors
that you use as your interface and the
execution context that actually holds
all your stain the sweat if you have a
thread pool you have to so that you have
the queue with all the tasks to be run
and so on there is a stage there is a
very heavy very thing you don't want to
copy that one you might want to move it
but even though it might be pretty heavy
but definitely not copier and the
executor there is only a very very
lightweight interface and handle to that
one and but that is what you use as
interface and he proposed several
concrete executors the system executor
which just start a new thread for each
task the strength which is like to see
you will execute or a thread pool of
course and loop executor I have to admit
I don't remember what this one exactly
is only like the loop executors from the
other proposal
and it had a number of customisation
points and that's interesting so one of
the customisation points where the
continuation tokens so you could
actually use that to one the
continuation of some IO
atomically on the spec which did you IO
so the continuation could be used
synchronization as synchronization
mechanism and yeah
I think a better name for that would
actually be synchronization - okay
because it can also be used to define
the concurrency mechanism that you use
so he actually has also a continuation
token that uses cooperative multitasking
and just you this yield to wait for
something right now to block for
something and that yield then returns to
your executor and that it can run
something else the second customization
point is she actually didn't have a
single egg function but actually Sui
functions this patch post and defer and
if you look back to the original
proposal they had an inline executor and
a serial and all the other executors so
the interesting thing of the inline
executors was that it once a function
the task right away so it actually locks
for finishing that function
and some people said well this might be
very surprising to some of the people
who use executors so that might not be a
good idea so actually they actually
dropped in line executors and said okay
the eighth function is never allowed to
block however sometimes it's actually
useful to have such an inline executor
so what Chris Colfer actually has
proposed is to have a dispatch function
which actually can do that it can run
the function right away so it can
actually block your caller until the
task is done it doesn't have to but it
can do that so that from the behavior
definitely the different interface then
the post function which is the newest
one to the edge function so post is just
okay here's a new task want it don't
look for it right now and one it
somewhere and then here's the third
function the defer function which just
says well they're tasks they give to you
here is actually some kind of
continuation of what I am currently
doing so it might be useful to one their
task may be on the same set that I'm
currently running just when I wait for
something or something else so it's it's
more hint it's not really a different
behavior it's just a hint to the
executor and but it's a very useful in
to get high-performance execution and
the third customization point is the
associated executor
so I told you the executor in this
propose is just a very lightweight thing
and the wheel thing underneath is the
execution context
so you can actually define your own
executor on top of an existing execution
context so you don't have to implement
your own thread pool just because you
want to give some additional information
or to use some additional information so
for example I implemented my real-time
executor just on top well in my case
just the scratch executors so I just
spawned a new thread for each thing
because then the operating system
priorities actually kick in and so that
lightweight executed on top of that that
actually contains the additional
information whether something is a high
priority task or low priority task so if
we come back to my proposal here what
you actually see is I have a different
object here and this is an object that
has just a different priority so I have
two different executors here those are
just like wait handles on the same
execution context and one has no
priority and one has a pretty high
priority so this interface with the
associated executor this in general
allows for providing any info from the
application point to the executor
without my data concentrator needs to
know anything about that
so that was Chris Cole Oscar poser
but we also got another proposal from
Google Chris Mason was at this time and
he actually started to work on the
original Google proposal but just did a
lot of work on that one and tried to fit
into the new requirements and address
the extra base class so what he actually
proposes is an executor just as and as a
concept so it's essentially a template
based so templates can just take in
executors as template argument and then
you can use that interface so our X
function which was renamed to spawn is
not a virtual function anymore but it's
again a template over the actual
function time so you don't have to use
the function so you don't get the
overhead of the function here's our so
we definitely addressed this one and the
other things that he also edit was
exactly something like The Associated
executor so he proposed the task
football and originally he made a
mistake there but after some discussion
now he actually does it the right way so
that is fine but that's the only
customization point he proposes
and then we got a third proposal by the
by Nvidia essentially because they've
implementing the parallel orgasm tears
and in that well originally in that
proposal for the parallel algorithms
we'll also execute the interface so you
give an executor and you all do them
we'll just one on that executor and well
we did get out to the parallel audio
isn't as a tears but not executors
anywhere else so that was get off from
the common tears but we still want to
have it at some time so they looked into
what do they actually need from an
executor to implement the parallel
algorithms on top of an executor
interface and they decided not to come
up with just another one another
executor interface but they said well
what we actually proposed is a trade
class and this just adapt to whatever
executor you have and that weight class
first gives you the semantics of the
actual executor so I talked before about
the concurrent executors which is always
more or less in parallel and the
parallel executor which might be CEO
will and then we also have weekly
parallel where you are not allowed to do
any synchronization at all at least no
blocking synchronization and well if you
implement something you typically want
to know what semantics you actually get
so they wanted to know this in the
trades
they wanted to know the future time that
you actually get for the return then a
tasket on that is something none of the
other proposals actually covered but
because they don't talk about futures
and although the ACO proposal talks
about that in some kind so one of those
continuation tokens actually put you to
the future but generally they say well
it's not the job of the executor to deal
with your results and to deal with any
exceptions or things like that that is
something else that has to deal with
that but the parallel orders and air
people they said well we need some kind
of future and they want to know what
type that actually is they said okay it
doesn't have to be the future it can be
some other future time but they need to
know what time it is
okay fine and of course they want to
know how they have to start a new task
and that ass has to return exactly the
future time and they also want to stop a
lot of tasks at the same time so they
say okay well that is in video so they
don't have one call or for course they
have several hundred calls so they want
to spawn off several hundred tasks and
if you are then executed it might be
much more efficient just to create 100
tasks at the same time than one after
the other so they came up with an
additional interface okay we want to
start so many times
the interesting thing about the executor
trade is the trades actually allow for
weapon
your executor and you can add all the
functionality that this specific way it
requires inside of the trade you don't
have to do it in the executor so for
example the future thing well as I said
the north opposes don't really talk
about futures well you can add that if
your underlying executed doesn't provide
such a bike interface well you just can
write in your trades class you for loop
and start all those carts so I think
that's a very useful approach but of
course this is again only one aspect one
specific domain for the parallel order
so what's the status quo what do we have
right now
well the suppose with several
modifications was accepted by the
concurrency of study cool into the
concurrency yes February last year and
Issaquah just just a few miles from here
well that wasn't apparel in June last
year people came back with school off
until then never came to a meeting he
just will proposes but he didn't come to
the meetings and he was in the post view
but Pete Marku actually presented that
to the concurrency group and after their
discussion well
nearly everybody said okay we have to
remove the original proposal from the
compound CTS we are not there yet
you cannot use that one as a TS and but
also and this means strongly in favor in
favor neutral again strongly against so
only two people weakly against removing
the original proposals from the tears
but no strong opposition on that one on
the other hand most people were not
really happy with the ACO proposal a
sixth and so they said well we need more
work on that one so when we finally
asked the question okay should we use
now the the ACO proposed as the new
executor model in our tears well the
group was pretty much split so
definitely no consensus on that one
so sg1 decided to have an additional
meeting between the La Paz middle
meeting and the open a champagne meeting
in October November last year so they
met 2014 over in Redmond and there Chris
Mason came with his new version of the
Google proposal and well a lot of max of
people there there were a lot of Google
people there that meeting and they were
all in favor of that proposal so when
they are the question okay should we
actually
we start with this proposal yeah most
people they're in favor of that and
those two who were strongly against they
are not even in Westmont they'd be on
the phone and one of them was me and one
of them was somebody from the UK maybe
because we said well yeah that's not
really what we need and the Nvidia
proposal that was discussed in May and
Lenexa but we didn't take vote we
thought well okay it's a very
interesting approach but we are not
ready to vote on that one yet
so that's the status quo so what do we
really need and maybe it's actually
useful to look a little bit at the
bigger picture
so the original C++ standard
standardized the Istana template library
and part of that standard template
library were the educators but
essentially nobody actually used ever
that allocated directly that was used by
the containers so the educators is a
very low level building block and you
put the interesting thing that's
actually used by your programs for you
applications
well that isn't a middle layer and for
the executors that middle layer might be
an azo couple oh just a sink to start
and you task well to do one a task on
that executor and get a future back and
two fiddling with all the future things
like exceptions and things like that
the pipeline couple that we have seen
the flow graphs as it was in TVB also
listen ptb be parallel algorithms
something like an event loop that's very
important in embedded systems but also
in other systems so the executor
actually isn't something that is used by
applications directly but it's something
that is used by the middle layer by some
additional components then actually some
of them might be standardized some of
them might not but they will use the
executor interface and there's a general
you cool if you have more info then you
can do a better job well what kind of
information might be useful for the
implementation of an executor well for
example what's the relationship of the
task 31 to your caller let my team Oh is
the task that you're actually giving to
the executor something gets long-running
or something that is very short running
just computed function and then you are
done or is it something like a server
which will live more or less forever
it's a function it's a task actually
contains it internal locking calls is it
actually a terms that should be run
again and again and again which is often
done in a better system do you have some
specific priority as we have already
seen and
how do you want to get the information
back of your TAS maybe maybe you are not
interested in that information at all if
you are running the server for example
its new spawning of a server you're not
interested in any return you don't
expect it to give you any return but all
that information is very specific to
some executors to some domains and only
nothing of that should be directly in
the interface of the executor but there
should be a mechanism for me as
application programmer to give this
information to my underlying executor
that I controlled as well if I start the
pipeline on an executor I possibly
created that executor
so I know what executor I have as an
application programmer but I don't
control the actually call to the
executor so I need some mechanism to
give this information from the
application to the underlying executor
and well this is exactly what the
Associated executors can do if you have
that very lightweight handle because
then you can just use that mechanism to
transfer that information Wow
yeah there's still a little bit more and
I'm equip pretty heavy that car is
sitting there pretty happy and well Kovu
teens very important for some types of a
synchronicity and a zero for example but
pretty well together with co-routines
but i believe i might be wrong but i
believe that the current proposal that
we have is the async with humor coach
doesn't really work together with
executors maybe we can do that do you
know okay good to know
I will definitely have to look okay so
he go actually when Caesar made proposed
awfully I think assume proposal he just
told me that you can probably do exactly
that by saying async and give that an
executor and I have to admit I fully
have to look at that part of the
proposal and we really need that
composability so I started quo is we
don't have an executor interface so what
do we need to do well executors are very
very important building block for
anything that is even remotely
concurrent asynchronous parallel but
they should be very low-level they
should provide you the interface for the
immediate layer they should not provide
you an interface for the application
program but what the interface will be
we still have no agreement America
and well we have some very specific
experience so we have a lot experience
from SEO we have experience now a little
bit from the parallel algorithm people
we also have the experience of all the
Google people and what they have done in
inside Google but I still believe that's
not the whole story and we probably need
a lot more use cases to see what we
actually need so yeah well one question
is what is a task so what information do
you need to give to an executor if you
give some higher level mechanism a task
to run is it really just a function or
is it the function plus some information
and if it is plus some information well
what information is it and how do you
get that so what we will need to look
into okay what interface do we need
between the executor and the middle
layer but in a way that the higher layer
the application actually can transport
all the fact all the information it
wishes to the underlying executor and as
I said we definitely shouldn't
standardize everything but we should
stand out as something that is open
enough so that other people can build on
that and to their own things outside of
the stand
so yeah I was actually one of those
people who said well I really want to go
forward to the ACO proposal not with the
quiz nation proposal on the other hand I
think the ACO proposal actually is very
very complex and I actually have
implemented my own executors on top of
the ACO proposal and it just has
something that I think you shouldn't
need to do but the ACO proposal actually
provides me those three customization
points that I think are very useful but
there might be more customization points
that might be useful but I simply don't
know them yet and Chris Mason's proposal
only provides one of those customisation
points the associated executor so it
actually has that in interface to
transport some information from the
application they are down to the
executor it's who the middle layer but
it doesn't have anything like
continuation tokens and it doesn't have
the suite function interface and
personally I don't really like the suite
function interface I'm not completely
sure that we only have those sweden's we
want to give from the middle layer down
to the executors so yeah you definitely
need to do more work
Thirteen's Gore just told me that they
are more cooperative than I thought
which is very very good thank you and
well that's it
any questions
well I'll just stay seated so in using
the executor that we have in the code
that I work on one of the issues that
comes up is you have a large number of
tasks that need to be run and those
tasks consume resources and you would
really like the executor to be aware of
the resource consumption so that it
could choose tasks to perhaps pause or
abandon or what have you and there are
other things as well but I'll just leave
the question out at that and I just
wondered whether you'd given
consideration to that kind of thing well
I think everybody has hard to the
question so I don't have to repeat it
well yeah this is something that
especially the ACO proposal has put a
lot of thought into the head one and the
point is there is a very interesting
thing PPP because part of that is
between my middle layer and the executor
and part of that is between the
application and the executor so it
actually two different things and if I
look back at those sweet customization
points
I have to admit I don't think that
swinney come up it's definitely good
input
any other question yeah it's related to
not necessarily just about the executor
have you guys talked about the
cancellations for the tasks in general
and something that the executor could
look at the task post consult before
it's wrong so yeah actually say you put
a tax on an executor and then you decide
well you don't need it anymore so we
cancel it and the executor shouldn't run
it
no we haven't thought about this use
case and I think none of the proposals
has any remove function so which says
okay remove their tasks from your queue
if it's not already started and then
again doesn't fit very well into my
middle layer and application they are
seeing because sometimes it's a middle
layer that they notice it's okay I don't
need it anymore and that could actually
do something but because that has a
direct interface to the executor the
applique about sometimes it's actually
the application layer that's well okay I
started here something use it whatever
using whatever and you tast and but I
don't need that anymore but it doesn't
actually have a download interface to
the executor so well and then executor
definitely could have an interface like
that I don't remember that it ever came
up in the discussion but well that's
definitely interesting input
I just want a second that we have a we
did I did a similar thing where we used
a token we called it a token that we
passed the tasks so that they know if
they need to keep doing work and
sometimes tasks would take longer to run
then maybe our framework expected and
and so we would kick off another task to
help it these things could be on course
they could be distributed it was it was
we didn't build the framework to know if
it was on that machine or distributed
but these tasks would be sent out and if
task for not coming back as fast as we
wanted then we would kick off more but
there was a plenty of opportunity for
the token to tell the task hey it's been
handled now stop your work or don't even
kick you we created ten more but you
don't need to send that out it was
there's cost and sending out yeah okay
but after that I actually think it might
be doable just using that lightweight
executor thing associated executable
because there you can add whatever
information you want and you can just
put in a boolean for example okay don't
run it anymore or yeah you still need to
run it something like that but there is
only if it really comes from the
application if it comes from the medium
layer well yeah
one more question I think I missed the
part at the beginning of your
presentation when you talk about when a
sync fires and it's lunch icing and you
said it's desirable to know that the
task will finish by the time the
instruction happens for that future
there I don't think it's desirable when
the lunch is pacing
I think it's desirable when it's
deferred but when it's async why
wouldn't I wait for the future
explicitly why no that's not the point
the point here is your task once it
whoever wants some objects
violet ones you must make sure that
those objects are still available
available then they toss exorcism and
that is why you need control over then
their task actually finishes sure wooden
I done wait on my main threat on that
future and then I know that hey it
completed
I can read exactly that is why they
actually give you the future from the
async because then you can bake on that
future and everything is fine the
problem is if you don't wait if you
don't take that future and don't wait
point then you have a problem
are there usages for that like who do
that well that is exactly the point when
we originally designed future and I
think we thought no there is no use for
that but it turned out that a lot of
people actually use it exactly that way
they have fire-and-forget time so they
are not interested in the future they
just want to start their task and the
point is we actually have two different
use cases but only one interface for
them and that is the problem I think we
have time for one last quick question
okay so in your slide about your real
time priorities and your non non real
time you gave the priority to the
executor handle and not to the task that
you fired off in my use case we actually
need something that knows that this task
takes a fifth of the memory that is
available and you can only run five but
you've got 32 cores so you need to sort
of you know but knapsack the the RAM and
it's doesn't work well the point here
was that executors handler is a very
very very light rating so you can
actually create a new executor for
single-task and this way you can just
put the information that you would want
to put to the task into that thing so
actually it is a little bit of misnomer
so it wasn't apparent to me but I looked
at the interface that I could use it
that way but after I actually work with
it I found out about this is exactly the
thing I need to put whatever information
I want into the task and give it to the
underlying execution context in this
case so you can actually use it that way
look okay I think time is over</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>