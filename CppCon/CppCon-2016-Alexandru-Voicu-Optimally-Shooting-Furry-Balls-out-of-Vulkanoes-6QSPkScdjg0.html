<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: Alexandru Voicu “Optimally Shooting Furry Balls out of Vulkanoes&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: Alexandru Voicu “Optimally Shooting Furry Balls out of Vulkanoes&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: Alexandru Voicu “Optimally Shooting Furry Balls out of Vulkanoes&quot;</b></h2><h5 class="post__date">2016-10-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6QSPkScdjg0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone I'm Alex thank you
for coming it's very heartwarming for me
to see that so many people decided to
come up at 9am it's also a bit scary
because as I was telling the gentleman
in front I was counting on roughly five
people maybe 10 so there's quite a bit
more pressure now with wide audience
you've also spread out so that I have my
work cut out and I'll go over there go
there but hopefully it will be fine I
used to be and I will be again software
engineer when the graphics business
working for an ITV my prior employer
used to be imagination technologies if
you know two dudes named do d IP for the
iphone ipod and so on and so forth and
as you can imagine it was pretty
important for them being in the handheld
world to to work on Vulcan therefore my
task for most of my time there was to
work on Vulcan now I must make you aware
of two things this is not intended to be
a talk in which someone comes with the
truth and impart it and it's not one of
those moments I mean I am Romanian I'm
not Andre Alexandra school so I'm just a
programmer like you if you feel like
asking questions throughout the talk do
I don't guarantee that always have
answers but I might know where to look
if I don't have an answer and having
said that let's look at the wonderful
discovery of the lack of zero in Roman
numerals this is what we sort of
aspiring to now given my experience with
prior talks that I've given in my pace I
don't know if we'll make it up to the
bottom but we have a fair chance to make
it up to the graphics point so the goal
is to come up from very high level with
an abstraction that sort of starts from
first principles of rendering and of
computation more than it starts from I
have an API have to wrap it into
something there are a bunch of other
tools that do do wrapping for you if you
want to use
they're great and very useful for
example crew knows just adopted indata
HPP header which was contributed by
nvidia and has a bunch of knives binding
and strongly typed in ohms and all that
good stuff this is this talk is not
about that it's more about as you'll
soon hear being thrust into the into the
front line and trying to make heads or
tails coming from a slightly different
background so as i said i joined
imagination about one year ago something
like that and before i was coming from a
different background which was GPU
compute and after GPU compute a bit of
mfc compute if you don't know what that
is you're very happy man and i was part
of a competitive analysis team and
competitive analysis teams right lots of
benchmarks you can imagine that there's
lots of excitement around in the API so
writing a new benchmark for Vulcan
should have been very cool only that you
have the new guy is coming from NFC
confusion all that stuff I don't write
some Logan so um my my my goal in life
at the moment at that particular wound
was to render two triangles why two
triangles that's a good answer that's a
good start is so it's progress yes yeah
it's in it's that's a good that's a good
point that's that's very smart but I
wasn't that smart I'm not that's what
it's something simple I mean yes so if
you write benchmarks the full screen
quad is one of your best friends because
you can do lots of magical things you I
mean and I see people around and looking
while you have such a sad life like a
full screen quad one well it's pretty
important you know you want to measure
fill rate you want to measure the fruit
for a particular shader maybe on a test
late it and you won't have it projected
also only to the screen it's
there are some benefits up I want to
turn the two triangles so what do you do
well the SDK sort of thing came out by
luna G by the way there will be a link
later on so I going they have a sample
with triangle it's an advanced sample so
it's a color triangle and George do to
do to do tend to do to to do it and it's
animated them but I thought well okay I
won't do the complicated stuff I'll just
figure out how to render a triangle and
then maybe I'll duplicate that code and
render two triangles and maybe if i get
really smart i discover iteration and I
don't need to duplicate it and that was
a bit daunting because if you look at
does anybody know the sdk samples show
of hands their kind might be not
necessarily newbie friendly unless new
binary friendliness it is understood
that you will copy these this thing and
use it as we use it for ever and don't
necessary try to understand it is kind
of lots of inline stuff and you have all
these things that look as if they could
be array i I but for some reason they're
not you have safe release all kinds of
nice things so um around the same point
I got the chance to interact some of the
people that worked on the API and also
to see one of the demos that they had
requested and one of the main requests
in the demo so that you understand why I
was not in a that was not a good day was
there shall be no abstraction we don't
want any sort of abstraction rubbish to
we have this low-level want to expose it
so do everything in line so if you can
you have one function okay fill it up I
do your stuff here you want create all
of your buffers compile your shaders
with some python script at them and as
well guys maybe you know it's a bit
difficult for a demo to help me out here
nice it's a very good demo it shows
exactly what you need to initialize and
what you need to do and I couldn't
disagree with that it's just that I I
probably was not on the level 22 to
capture it so
I kind of am an 8020 sort of guy you go
if you go to the eighty percent you're
probably in good spot so I decided to
start from the bottom I figure how the
rendering goes maybe I'll know how to
render two triangles I managed to learn
how to render 20 an ecocide one yes so
this is basically what I wanted to do
that that guy up there so I probably
return something I have a function that
hopefully has does not have the name foo
because everybody names something
through and you can grab for it and I
have some description of the sort of
work that I want to do and I give it to
the function and magically things happen
maybe pixels show up maybe numbers gets
lips bit out in a buffer or something
like that now another part of my
background is that I come from C++ am so
if does anybody know c++ amp well you're
cheating does anybody who is not at
microsoft pants well anyways you certain
concepts and ideas and names i shared
because i think that was a very good way
to program including for graphics at any
rate we just want this this foo guy and
let us think at what happens in in
rendering so in a certain case you might
want an immediate result so you might
want to read a blog it might be fine to
return like void you're in an
application that might not that might be
concerned with its real-time
responsiveness let's say you don't want
to build a long queue that will at some
point get split on into the Machine and
then you have bump in latency as it chug
chug chug because preemption on gpus is
still tricky so that's fine but on other
cases you might want some sort of
composability and we'll see that it's
even more relevant in the context of
Vulcan once you start submitting against
multiple queues all in due time so make
your future void does anybody have
anything against the future one now by
the way questions
no very good now in order to this what
sort of workloads do you have in
graphics by the way how many graphics
programs okay GPU compute people ok how
many volcom programmers do I need well
later on if I need to like detail
certain things about Vulcan do give me a
shot anyways so let's assume that we
leave in this simplified universe in
which you either need to do compute
where computers defined as some
transformation that does not necessarily
yield a visual output so multiplying
matrices or adding vectors all these
super exciting things only doing
graphics so you're rendering doom maybe
not doom but maybe a part to do major
part of a doom scene so this is not bad
and like with all computation is
everything in computers in a sort of
two-sided so on one hand we have bits
that kind of travel but they don't
really travel and we modify them when we
get new bits and describing the pipeline
eating and the workload thing has the
wii modifying the bits but we need to
hold them somewhere we don't really hold
em button so containers are good and
there are two concepts that buffer is
general it's probably the one of the
most general concepts in compute typical
container fixture is a bit more special
case to two graphics but it is a special
case of a buffer and we'll approach it
from that angle later on so I'm pretty
bad at naming you have to apologize out
but Ron pipeline might be okay because
the machine itself is a pipeline and
you'll see everyone talking about the
rendering pipeline everybody knows what
the rendering pipeline is made up of
now in terms of design we'll get back to
the rendering pipeline and it'll make
sense in terms of design there are a few
things that I hold to and I hold to them
as a C++ program and a programmer in
general and I generally get slack from
people for this but I think that they're
pretty important to have especially in
the concurrent parallel world so does
everybody know what the regular type is
okay let's go the other way does anybody
not know what regular type is so a
regular type is a type that provides in
its computational basis default
construction copy construction
assignment destructor equality compare
comparison against equality and that's
where it stops the totally ordered guy
that you see their ads default ordering
with less than and why would totally
order it be useful what does it enable
yeah and after you sort them yes and
with us I can do log search that's
probably the more useful one of the more
useful consequences of of it
semi-regular loses the quality
comparison because in certain cases is
really hard to repair things for example
comparing functions and we'll see and
the thing that we build a point in which
actually it's very hard to come up with
viable equality designer test these
might seem like spurious concerned like
why do you care and regularity also
means in another property important
property is of regularities that you
have value semantics for your types and
what it means in a parallel sort of
concurrent fault is that if you give me
a buffer thing against the particular
it's my buffer I know that I'm not going
to cut the legs under somebody or
somewhere else so and if I give me a
reference to
it I know to be careful because somebody
else might see it but once you have all
the good stuff that you own parent hates
on once that happens once you perfect
regularity it's very hard when you're in
a parallel context even more so as we'll
see on a GPU now since there weren't so
many volcom people this slide actually
makes sense I was worried that everybody
will be ha I noticed vodka is intended
to be a low-level API a low level
abstraction on top of accelerators
machines that can accelerate that
parallel computation and graphics
rendering it just so happens that right
now that means GPUs but you could think
hypothetically about the scenario in
which someone produces a software
rasterizer for Vulcan and it would still
qualify as a VK physical device even
though it's not necessarily a VK
physical device it would be enumerated
by the API so the IPA takes all of these
and shows until you look this is what
you can use this this is what I can give
all of the compliant implementations and
in order to queried this stuff you have
to go through an instance the instance
is your gateway into the hardware
resources so I already managed to kill
two people that's pretty it's your
gateway into this world of physical
things the physical things are immutable
for all intents and purposes so if
you're you suddenly get you have to
understand that a big part of the things
that Vulkan API expose this happens to
be relatively opaque handles or pointers
into structures that exist within
somebody's driver so if you actually
knew what to cost the pointer to for
example for a VK physical device or for
some other handles that Vulcan returns
you could stay into somebody's driver
and see a bunch of its in some sense you
can observe the convergence between the
drivers at ivy's came up with at any
rate as I was saying if your VK physical
device sort of disappears you probably
your machine exploded so you
waiting in a bad you're in a bad sport
you can take these as being immutable
the instance however is not immutable
you do have you grab it and you release
it at some point but since it's sort of
the gateway into some things that are
immutable it's a pretty good candidate
for being made both static and also
probably come start for you created it
and you just talk to it like well this
GPU I tell me something about it I would
like to find out something about when
one creates this gateway there are a
bunch of knobs that are useful
especially for someone who begins
programming because it certain areas can
be a bit daunting it's a broad of a buzz
API that has anybody written drivers
here drivers drivers drivers it's
verbose it's you have many structures
you have many things to set and now you
get as an old rival program will get a
bit of exposure to that so one of the
things that you can enable through an
instance is a bunch of validation layers
which basically look at for example the
arguments that you pass to a particular
welcome function and they tell you know
this will never work you're wrong and
they spit it out into a nice sear or
whatever into a log file whatever you
want to put it it's useful to enable
them and versus the initial situation in
what in which it was a bit of the Wild
West now there's just a single sort of
me natalia that activates all the
validation is will see it activated
later on extensions are more of a gray
area there are there is a set of
extensions that is useful the one the
ones that concern themselves interaction
with the windowing system or a
particular so by way of these extensions
you can theoretically go linux windows
wherever and it will abstract away some
of the difficulties of interacting with
the windowing system because when you do
rendering you do need to retrieve
handles the window to give handles to be
able to render into a log back bar
friend saw
there are the extensions that might be
more pernicious than to be potentially i
hv specific but those tend to be
associated with devices more than
anything since i was talking about the
mutability this is sort of how i propose
that you start Vokoun up like you this
is you grab your instance you create it
now you'll see a bunch of things that
are prefixed with info these are
relatively fatty structures that
describe the sort of thing that you want
to retrieve from the Vulcan runtime
itself and they have a standard form
they are prefixed with the type because
it this is kind of see so you look at
the type tag and you know sighs they
have a bunch of folks for custom
extensions and so on more often than not
this is boilerplate that can be
automated and the knobs that you have to
traced are quite limited so in this case
for example in the VK instance create
info what you'd actually care about
notifying or would ever modify is the
extensions and the layer that there's
that you enable in this particular case
for debug the validation layers are
enabled because it's noisy and
potentially a performance cost but as
for realies they are not enabled
similarly for this particular code that
will go up probably after the
presentation for a while not for long
for this particular code I sort of
planted the issue of which extensions
are good and we chant and I just enable
all of them there is a mechanism to
retrieve the extensions from the
instance itself if you see I have a
pointer I don't think it will can you
see anything with the pointer now well
anyways if you look upstairs there's a
function called extensions and there are
a bunch of useful helpers that you will
discover that you can write and
fair use that are basically projection
functions they take and they queried a
particular type particular quantity that
you want to retrieve and they give it
back to you in this case extensions
gives you back the extensions that are
supported by the instance and
interestingly not there's also a
function names which is a proper
projection function why does that exist
because what you pass into this
particular structure many other
structure is is a raise of strings zeno
terminated strings that denote so for
example the set of extensions that you
enable is basically a range of 0
terminated strings that tells VK blah
blah blah de blah blah blah VK blah blah
blah but what you get via the direct
query into the instance is a fattier
structure that gives you more
information about the about the layer
itself or the extension itself in this
case and by way of consequence since I
just need a name take it out stick it
into the proper container is going to
live throughout the scope of this and
Bob's your uncle another thing that you
will observe but this was a common
pattern for anybody hooded OpenGL oh who
did i text and so on and all of those
terrible safe release macros stem from
there generally your interaction with
the graphics API is give me this thing
which happens to be a handle I'm going
to do some things with it and I'm going
to return it to you and there are quite
a few types of handles that you can get
but for whatever reason there is a bit
of an aversion in the community towards
doing area I I because some people don't
like C++ or anyways at any rate this is
the this is a basic workhorse kind of
thing that I've found to be terribly
useful in the interaction with vokoun
whenever you get a handle put it in this
sort of handle class and in its the
structure destructor its handles the
release properly so this is boring every
C++ programmer knows it however
there is a bit of variation here because
symmetry is not nice there are multiple
ways in which you can actually return a
handle to the Vulcan runtime and they
sort of depend on who's your daddy in
what regards an instance an instance has
no daddy's it it is d-daddy therefore
you can simply call the deleted whatever
that might be on it you just get the
handle to the instance which happens to
be a pointer you call the return on that
and not STD delete a Vulcan function
that frees gives it back to the runta
and that's that however as we'll see
later on once you start getting things
from the instance for example a device
which is an actual thing against which
you can do work and is a programmatic
proxy for all of those VK physical
immutable lovely things well you need to
talk to that and tell him well you gave
this to me I'm giving it back to you so
before we move on and sure why that is
relevant does everybody kind of guess
what all this strange private
inheritance thing does is anybody not
guessing and curious about what it does
so the basically I think that in a
literature they call it BOTS and Nachman
trick for this kind of stuff so what it
does it automatically in some sense by
following a convention of a function
that you must implement yourself it puts
for example the quality and inequality
in the adequate name since it who stood
outside and it generates it for you and
the one at the bottom is actually a very
boring kind of empty class with the
context / constructing within the body
of the constructor it static asserts
that it actually has the proper property
so its default constructible assignable
and so on which is precisely what's
listed here so we can go on another
convention
that's probably useful in your code
you'll discover that you'll have to
interface even if you wrap these things
you'll interface with the API relatively
frequently so you should be able to
retrieve the handle that the API gives
you and anticipating a bit you also
discover that Vokoun is not only welcome
but is a bit like the sort of drug
dealer that wanted to use you as a mule
on your vacation and who gets caught as
in you gave me this thing but you gave
me this buffer tell me something about
it and you know it sighs you know hmm no
by which I'm trying to convey the point
that you don't have much introspection
back into the API so you might create a
buffer at some point we might create a
device there is useful information that
you will need later on that you should
store with it and as you go through the
hierarchy it's useful to store back
pointers to constant whatever you're
born from because that I might have some
other information that you need now the
point of the funky constructor is tied
to what I was saying earlier about the
delita the idea is that it's kind of
nice to hoist all of these ten thousand
billion functions into one particular
point in the half sort of symmetrical
deletion and when you construct a
particular if you construct a vault and
handle over an instance you know that it
has no daddy if you construct the device
you know that it has an instance daddy
that it might need for its division
although the device does not but when
you construct a buffer you definitely
need to give it back to the device that
gave it a buffer it's in the call of the
function so how this works there's an
otoscope again kind of empty body sort
of struct in which you have just the
coal operator which is overloaded based
on all of the types that you want to
delete and within the body of is the
actual call into the Vulcan API some
need to call other things for those that
need to call other things there
able to pass it through the forwarding
constructor at construction so you need
a pointer to you need to handle to the
device that you came from you can give
it to that you need a handle you can
give it to that and this just so as I
was writing the code as you start adding
types disc of all I need to feed this as
well and you do the Vulcan handle and it
says well I don't have an overload to
delete this thing for you and it's sort
of self filling just go add another
overall this is kind of what is enough
to do pretty interesting stuff it is
enough it was enough for my two triangle
challenge but it's actually enough for
doing reasonable graphics as well it's
definitely enough computation will talk
about each of them in context is not a
large set as you can tell and it's also
the funky funky function with the run
pipeline but it's not a ton of stuff
this is possibly the most important
abstraction in the lot of it and i
pilfered the name from amp accelerate of
you and what it maps to into the actual
API is a Vulcan device but the idea is
that this is actually your joystick your
join game controller whatever to the
resource it is your view to the
particular computational resource and
this is something that you can hand into
a thread and that thread can bang
against it and leverage that particular
device just fine and you can hand it to
another thread and that other guy will
bang against that device they will not
this is the thing that enables you to
create resources against the device to
submit computation and so on it's you
need it everywhere just like you need a
VK device everywhere you need this kind
of guy where
does anyone have any issue with the odd
requires and the domain thing no but
what do I mean by the domain of F equals
void current I saw me on I mean it's a
pool person it has a void domain but co
domain is returned it takes no arguments
yes this is slightly freakier syntax
than the well not freaky but different
syntax from the one that's in the
concepts proposal but I kind of want to
compile my stuff with visual studio as
well and people who haven't implemented
it yet and what I wanted to focus on
here is the implementation of a
particular function that gives us a
command pool and might be useful to
figure out what the command pool is
before and you can think of a compatible
as sort of a heap from which you can a
special-purpose heap that is attached to
a particular sort of Q bit of innuendo
these machines can expose multiple
avenues for ingesting work there is
guaranteed to be a one large very
generic door in which you can put
graphics compute whatever but in general
and for many machines there are other
cues which have potentially less
functionality but have desirable
properties if your workload maps to them
so for example it might be the case that
you have a compute you exposed if you
have a computer and this has compute
queues submitted day it's less overhead
and it opens the Gateway to potential
overlap in execution but we'll talk
about that later so from this these
command pools
they get the sort of associated or
definitely associated with the Q so if I
want to submit a packet which is a
command buffer against a particular q I
need to grab it from this command pool
so I go and look I have this I think I
want to do some I want to run the great
computer and I asked my accelerative you
got hello give me the command pool for a
cue that can do my computer and we'll
see in just a bit how the actual
selection goes for that what wow I
didn't feel that's so sad later on now
that was the interface you might observe
that i'm using CRT p for the interface
and not dogmatic about this it's just
personal preference i wouldn't like to
delve into it this is the actual
implementation and is anybody here a DOD
fan DoD is a Department of Defense now
there was a guy at the first CPP con
that gave a big talk about it with a
Hawaiian shirt red.mike actin data
oriented design they delve row I'm not
going there but let's start with the
data so in the actual implementation you
keep a back pointer to the device that
you're coming from why because there are
cases in which you need to efficiently
be able to query the physical device
that you layered on for example for to
see well what kind of extensions do you
support for example is there any
particular data member that seems freaky
or that needs clarification
it's these are extensions that I device
extensions the other ones were
extensions those are indeed static the
quay the question is good because there
is if you remember there was an
accelerator pool type and that actually
offers a ray rapid query into the set of
extensions that a physical device
supports and my suggest question is that
I was lazy it might be so instead of
this it might be a call into that I'm
I'm not like mad anything else if you
look at the bottom that pairing between
the command pool and the queue that I
mentioned is sort of a parent they're
literally a pair and this is how you
pick and sorry for the bit flipping it
was late last evening I literally added
this last seen this is how you select a
particular q family because within each
families which is to say within each
each doorway towards execution you can
have multiple queues against which you
can submit packets at the same time so
it's in it seems that it is a bit do
maybe it is a bit daunting initially but
it kind of makes sense afterwards and
all of these are queryable and the basic
idea is that again the spec guarantees
that you will get the universal queue
which probably will have everything that
you need that will match everything so
if you have no other q that can take
your work you will get the universal q
and it will be fine however i would like
to get the queue that actually has the
least facilities enabled but can still
support my kind of computation which is
precisely what this does and there are
some other invariants here that you will
pick up from the from the standard what
if you have a
I said these indices because they kind
of sort of appeared to be indices into
arrays that exists in the driver these
mappings have to be maintained so if
when you do your query particular q
family has index is a 0 that will
forever be index 0 so if you sort your
stuff and you don't store that
particular index you might be a bit
unhappy because you have to pass the Q
family index into various structures and
functions later on so better just the
order in which you grab them is fine by
the way there aren't that many potential
q families to begin with anyway there is
a hard upper bound on them it's two at
4-2 probably so it's roughly 14 00 so
there are four bits which control the
capability of a queue it can be a
compute q it and me a graphics Cuba
transfer curious pause you and this
pause part is about as VT sorts of
applications are not going to talk about
it today but the basic idea is that you
have four bytes but 4000 is not a value
pattern a cue that is only sparse is
also not valid because you can't do
anything with it transfer cues are
specialized for transfers you cannot
submit computation or any sort of other
request but if you need to move a buffer
from somewhere to somewhere else by
their own device or from the host to the
device they're probably the best
candidate and so on and this how
actually build them
all the query stuff that we've been
talking about so bottoms you will
observe that there are bunch of helpers
you were going to see Meg device in a
bit that a bunch of helpers for making
all of these types because there is a
recurring pattern around making a
particular welcome type you usually fill
out the structure call a function and
return the handle that it retrieves so
it makes sense to automate that into a
single because otherwise it's kind of
difficult to put things in constructors
now what you'll see here with the static
struct is a bit of a hack the role of
that particular part is technically you
can associate let us say that you
retrieve a family of cues that are
capable of computer you can associate
priorities with the cues that are part
of this family so let's say that I have
three guys I can say that the first guy
is 1.0 highest priority the other guy is
0.5 and 0.1 and maybe the runtime will
do something with this and maybe it'll
honor it but the spec says maybe to
learn it or not I I guess it is probably
useful for someone I don't know for whom
I just make them equal and we're going
to have our own sort of self balancing
mechanism a bit later on so that work is
kind of not utterly unfair it's not
baton smashing against a single single
sort of Q and it's pretty safe that no
device is going to expose any time soon
more than 60 4 q's you don't need
anything more than 640 kilobytes right
so doing it like this it just needs to
exist as you're in stationing basically
it's it's not bits filler I need it in
order to create the queue but that's
where it stops it's not useful for our
context and now we can actually do
something that is moderately more
interesting which is data movement
and does anyone have an issue with the
idea that there might exist a particular
memory space that is kind of opaque and
owned by a device that is disjointed
from you and that needs special mass
massaging to be accessed it's kind of a
bit daily and theoretical if you start
from the sea machine model and so on you
expect that you can run through all of
them however device memory can be
theoretically physically located on a
device and can be definitely in that
situation not seamlessly access you
can't take a pointer in your reference
in there or whatever it's a bacon is a
procedure to procedure to retrieve it
I'll get into that as well this sort of
changes for machines such as you might
have in your phone or with modern SOC
machines which actually have shared page
tables and actually see if might see a
flat memory space that's that's what the
fast shared memory option light map to
and we're interested in these three in
particular because the accelerator
memory which is say the one that is on
device can fear it potentially be
massively faster than the alternatives
and by massively faster we have GPS at
have 512 gigabytes per second terms of
throughput hbm good stuff there's even
my thing that the new Tesla's have even
more than that maybe that's a lot but
it's from memory that is local to the
device whereas if you have this device
that plugs into pcie or into some socket
somewhere and you're forcing it to put
it into a space that it's shared which
is a pain variant mainland blah blah
blah blah blah you're going to be bound
to maybe 15 gigabytes ignoring the
latency of the transfer maybe 80 it's
we're talking an order of magnitude
difference that's something useful to
have the fast shared memory bit where HP
is quite common as least as far as
Vulcan
concerned or SOC so for example that
machine actually has that name this
thing or another is theoretically equal
speed access from the device and from
the host the non fast one is actually
slower from the device because it needs
it needs an extra map and just host the
device cannot see it but it might be
faster for the host itself because it
might catch it so as things are now
again due to what I mentioned earlier
about how this whole shared memory space
madness works out you don't you either
get the fast shared space but the host
cannot catch it so if you do a load or
if you do right you always go to memory
or you have a portion of the normal
memory that is properly hot cached by
your CPU but that is not shared with the
GPU because the GPU kind of snoop the
caches of the CPU and this is a simple
way to maintain coherence now I spoke
about does everybody know what's
whistling is in context does anyone not
know what's reasoning is in context so
the basic idea is that within a texture
you might have the data rearranged in
blocks that follow something like a
Morton curve or its proprietary to each
GPU maker due to the fact that when you
actually fetch from what texture you
might want to do something like
billionaire filtering or maybe trilinear
filtering and the texture units are
optimized for these particular fetch
patterns as opposed to bang bang bang
bang bang because you might need two
lines or something like that both types
in Vulcan that exist linear textures
which are what you would expect sort of
row major byte by byte by byte and the
swizzle guys there are restrictions on
the swizzle guys there might be faster
on certain machines obviously but the
linear guides you can sort of almost use
directly
and roll buffer is anyway this is the
syntax for getting a buffer you tell it
type those those are just the funky
things that are constructing place they
just tags they return a particular
bitwise combination that is used deeper
down into maker functions and so on is
not in particularly fancy there are
multiple the generic buffer is what you
would expect it to be the special cases
are tend to be tied to graphics
rendering more than anything so vertex
buffers index buffers uniform buffers
which are also known as constant buffers
and so on and so forth but you'll you
can know quick you can create all of
them via the same mechanism there exists
also a constructor here that doesn't
that is not listed and that does not
take an accelerator view argument which
is useful for the case in which you have
a bunch of data you want to stick it in
there you want to use the buffer
interface but you might not have the
accelerator view ready yet also note
that these can be the Declaration of
this particular handle to memory and the
binding to the actual backing memory is
decoupled invoking so you have to call a
particular bind function at some point
and at that point your buffer actually
has its backing memory so it another
usage scenario doesn't apply here
because it i bind it at construction but
in general another usage scenario would
be you spawn all of these buffers and
then you bind memory to them later on
and we'll see one case when it can be
actually quite useful can anybody see an
issue with creating the buffers like
this but it's the number of elements the
number of keys that you put in the
buffer it's a pointer to that many T's
so it's akin to having
the vector does vector have an enchilada
with size and data pointer with a pair
of iterators always I forget does
anybody see an issue with doing buffers
like this because there is an issue with
certain types of buffers you've done
like this so if I start Alec if I start
allocating three integers four integers
five integers 1 integer two integer and
so on I get a bunch of really tiny thing
early bulbs and this sort of syntax
allows it just fine it's it's a
performance anti-pattern so if you're
always allocating buffers of hundreds of
megabytes is fine probably will not feel
it but for all these small buffers there
is an overhead with having two trays so
many handles and to grab them and to
position them somewhere in there so a
strategy to employ here is to go with
pre-painting reallocating a more a
larger buffer in a particular memory
space and treating that as a keep in
which you put all of these small guys
because there is syntax in which you can
index into a larger buffer just by
offset into a larger memory allocation
and offset into it I mentioned this
because there are you will read
presentations that will get very angry
when people just allocates lots of small
buffers so I don't making people angry
is not nice pardon no I considered it I
just did not implement it it's useful I
didn't implement it at this point
because because it also steals a bit of
the functionality from that the buffer
itself it is owning but it also has
information about its size and its
location and so on which is part of what
buffer view gives you in volcom
now the process of mapping is taking
some pointer to memory that is on the
device and putting it in a place where
the host can see it where host is the
CPU and this is all beans has been in
graphics API since forever but again if
you map it you also have to unwrap it at
some point so area is your friend so
let's do it like that why is it not just
a pointer well because there are
alignment restrictions on the sort of
pointer that you can put your mapped
pointer into and I know this sounds
interesting but it actually is device
dependent so for example only in the
machines it has to be a 64-byte aligned
the address of the pointer that you're
writing into I think on in video
machines it was 256 at some point this
is variable but that's the the reason
for having all of this stuff just so
that I can do a line and once you have
this guy can do something like this
which is pretty nice you just map into a
scope and you don't leave it mapped
forever or dangling because you can't I
mean I think it's nice and at that point
as I said you have a point you can treat
it as a pointer as normal any pointer
and you can do whatever you'd like to do
with normal pointing now because I saw
an interesting I'm going to sort of skip
over this you will you take my word that
i can copy and it we can copy data from
axillary to the device and device to
exit and so on and there will be proof
of existence it's not it's interesting
but it's not massively fancy but let's
at least get to do some compute this is
a command buffer this is the way in
which you talk to the machine
but you see that as well so I'm to sort
in parallel and we don't have much time
and your experts give me an algorithm
that we can sort of this cost and
implement rapidly this is a parallel
this is a widely parallel machine what
about side pardon that's all so hard you
guys have no mercy i'm going to please
give me something easy and could you do
merge sort and write my sorting partner
is an interesting problem but is tricky
to do to do well radisson something
simpler by tonic is a good idea and it's
pretty simple but it has one flow which
is that it is not adaptive in any sense
and it has nice runtime characteristics
but you always go and log square event
it's because the network itself is
incomplete your only guarantee to have
sorted one so simpler than that not as
good as that in the worst case but
potentially better if you have data that
is already sorted what's the simplest
sorting algorithm that you do on the
single threaded CPU something something
yes now you will be amazed that there
exists something called odd-even
transmog potentially transposition but
odd-even soil that 1971 Hammerman for
parallel machines that can actually be
potentially that can actually
potentially be sort of useful so it's
not as bad as bubble sort assuming a
series of properties for your exchange
but it's really simple to implement and
look now geo people will know what this
is people who are not GL this is just
blah no really it is an glsl is all my
fault
and this is actually how we do the
sorting in the so again funky syntax
kind of not my fault I would have liked
to do so critically and start with the
most stupid and arrived at this which is
not the greatest but is not the
stupidest but I couldn't are there any
particular questions about this
implementation yeah just that it works
in parallel it's the same so if you look
at the network it's odd even odd even
odd even which bubble so it just doesn
level but fine right ok so the ti DX
thing is your position in the globe so
assume that you have n elements these
elements are processed in chunks of
group size something something there was
an old prefix on top of do you know how
do you know how GP come ok so you know
about wavefront warps and so on so you
process these in workgroup sighs that's
the opencl term F is fine right so this
would be the starting address for the
chunk that you're going to be processed
by the wavefront the ti DX the Li DX is
the address within the wavefront so it's
basically the same delay in index and
the GI DX is actually putting you twice
within the chunk that you're processing
because each chunk is actually twice the
work group size why so that i don't need
to mask except if you're at the tail
which happens at the bottom so it's zero
maps 201 maps 222 maps to 4 and so on
and so forth and goes to two sides
and the compare exchange thing does
exactly what it says so it looks as if
there are out of order which is to say
if Y is less than X it swaps them and it
returns a bool as i soaped something and
that way i can follow the atomic add is
there because i don't want to do atomic
ads against an address that is in global
memory I don't want to do it on that
because that's expensive so that
particular variable is in shared memory
so whenever a guy actually has to swap
it implemented if it is actually
positive it means that i had some swaps
and only then is just one right /
workgroup to global memory that's why
the Socratic method would have been good
but i posit we can do it like this where
that literal is exactly the main that
you saw from before and just the main
without all of the block and now since
there is not much time are there any do
i go on or are the questions that you
would like to ask
that's very good so the question is does
Vulcan use glsl which was the OpenGL
shading language or how do you write
shaders in Vulcan and the answer is that
there is no particular Orthodox way that
is mandated by Kronos they provide spear
V which is sort of an intermediate
language and some spirity supposed to be
really great but i think that they only
did the research on compiler front end
it's really great for that it's not so
great for humans so it is possible to
actually consume glsl either by a
proprietary extension from nvidia where
it just works in line or as i do it here
via shader see schaller see is a library
provided by google it consumes the other
cell gives you the spear v vulcan itself
without the extension only talks knows
how to talk with spear v so when you
create a DK shader module something you
have to give its POV thank you anybody
else know
do you want to finish the sword I don't
think that their standard there are two
minutes so in two minutes I can explain
how this automagically actually works
just with this funky syntax the pipeline
constructor itself you'll see that it's
kind of a soup of things and if we go
back to tttt if you look here a B and C
those are names that are actually
present in that shader hypothetically
and what happens in the constructor it
does goes and the ghost wrote through
its argument list and it let's say it
sees a buffer actually that strange pair
of buffer and the string that gives it a
name it's going to insert it into a
particular set of buffers that it needs
to add to a descriptor set at the end
when it is actually in a position to
build a pipeline and the shader and it's
going to assign to it a unique binding
point which is kind this is serial so
it's sort of easy so you just have a
counterpart category I have I see a
buffer its buying point zero I see
another buying point 1 and so on there
is such a concept of binding points
within glsl and we can precisely map
these kinds of structures into the
shader it goes and sees a textured not
for the compute part but if it were not
for this case but if it were to see a
texture it would give it a unique
binding into the set of textures and so
on now if it sees a constant that is a
trivial type and actually the
restriction is kind of stronger because
not all trivial types that exist in C++
can be spit into a shader for example
you can't put the pointer it's not going
to put it into a buffer or anything of
the sort it's going to put it into the
funky called push constant space and
this is its second you can think of it
as they can
range of biotin which you can put start
at various indices that I determined by
and the way in which it works within the
constructor is that it sees an integer
and it gets the unique index for that
particular integer and it updates it
multiplies the index by the size updated
and so on which I didn't say right it
tracks the last the position in which it
should write so I write four bytes I
update where I should write the things I
write eight bytes and so on so all of
this stuff should actually be done in a
pretty nice front end as opposed to
being done manually it the ideal syntax
for this is well one of the better
syntax is for these is to use the lambda
capture part but you can actually need
to do work in the compiler front end and
you could just capture the buffer guys
and magic happens in the background and
they are put into your shader at the
right point with the program name
without you having to repeat it which is
what C++ handed now having said this I
my wonderful colleague is despairing the
decision is over so thank you for coming
we didn't get as far as I hoped we would
I'm sorry about that we didn't I didn't
I didn't kill 10 people so it's fine
it's under 10 if there any other
questions I'm here so thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>