<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: Gor Nishanov “C++ Coroutines: Under the covers&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: Gor Nishanov “C++ Coroutines: Under the covers&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: Gor Nishanov “C++ Coroutines: Under the covers&quot;</b></h2><h5 class="post__date">2016-10-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8C8NnE1Dg4A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so we will be talking today about the
magic behind the coroutines
and essentially we'll start with this
wonderful incredible disappearing
coroutine act right before your eyes and
what we have here is your guess oh it's
you Boone - LTS 16.04 forked clang and a
trunk of an LVN 4.0
from the trunk so let's just start with
the magic act so you already so
coroutines
earlier by the way how many people
attended the Mauryan talk by james
o mighty but just for those who didn't I
will wait wait where is the mouse I did
it disappeared okay good good so let's
start easy with the very small and
simple co-routine so we will generate
font size easily
I mean weekly we can keep going so
now too early too early
so we'll generate an infinite sequence
of numbers okay and then here we will
consume it too much well if it becomes
too boring I will just cut and paste I
already have it ready okay control the
short B yes you were right hold on oh
yes it tells me right here
good so let's fix it okay compiled you
know we go here we'll print it and it
brings some infinite sequence of numbers
so but infinity it's not very convenient
to work especially with standard
algorithm because what I was going to
I'm going to do I'm going to submit the
coroutine to a standard algorithm like
maybe accumulate so we will add one more
routine which we'll call take until
essentially we will be taking values
from a crew team until it hits a
particular sentinel value okay so there
will be some G and then sent it out and
here we will do what we will expecting
to do will simply take this guy actually
will take G not the Jen because we want
to build a pipeline out of them and here
if if V is equal a sentinel will break
out of the loop
and otherwise we'll just yield whatever
is being passed and let's do here order
G equal Jem and then we will create
another generator will be taken till
we'll say 10 and that will bring the
result of this generator compile and run
yep ok so let's pass the generator to a
standard algorithm how people do
initially Auto result and we'll print it
so generator is a normal input iterable
sequence level it has begin an end so
we'll do this compile and run and it
will I think thought what sorry about
that it's real it's not so as to do of
course it has to have the initial value
good 45 so now the magic act starts well
just we'll see what's going on in the
debugger so we are we are here in in the
coroutine let's add a few more
breakpoints in the beginning of this guy
this guy made it in a yield and when we
start notice no breakpoints heat
curtains started by don't not yet using
the values only when you when
accumulates starts putting the values we
will actually jump
inside and then jumpers adhere heal the
value it goes and shows some internals
then we give back and we are inside of
the accumulate and we keep going so and
if we go back to main get rid of the all
of the breakpoints and we'll go to main
no not here
wait okay we can look at this assembly
and you will see not wrong button this
guy I'm at the right place
inmate well it's a lot of code you don't
have to understand that it's a lot of
code you know well one more time I want
to show actually the actual code in
Maine oh oh I see it's the end it's
because of the screen size it now what
make it smaller rid of it so what you
see here is that we create generator
will create a until will call begin will
call and then we'll start standard
accumulate algorithm and well in the end
we run destructors a lot of code but
it's a pretty reasonable code so now
we're going to disappear the scrotum
completely first will disappear printf
but I don't have to instead I will just
do return our it's still something with
a side-effect right so we'll observe it
in the disassembly so now I'm doing the
build release which adds Oh to to the
command line so now let's go in okay it
stopped at the end I'll let's look at
this assembly
wait one more time we saved it with
press control-shift
our build release yes let's go to now
finally f5 and we'll go to this assembly
and what we'll see is this where is the
corrosion there is no more corrosion
it's just a number and by the way we can
keep piling on we can add a few other
transformers but curtain would end up
being exactly that just a constant so
our goal today is to figure out what are
the transformations which make goroutine
disappear and also how you can make your
own content types which have this
property that makes compiler to make
goroutine again disappear into thin air
and what is left the actual yes one more
time stood what ah ok I haven't tried
with that one so sorry about that a
humor it works I know ok finally get
let's get back to the slides
so engineer or compiler looks like this
you know in all the textbooks you have
the front end which does do sugaring
which takes care of the high-level
language and then it transforms it into
some intermediate representation which
is very good for the optimizer and in
this case I'm showing LLVM IR and
finally after optimizer is done
improving the code it goes to the code
gem so what would be a good place to
implement equality so some languages
implement them in the front end
completely like c-sharp and Python and
we decided to experiment what if we
implement the meat of the corrosion here
in the optimizer and coroutine is just
at least in C++ level it's a function we
suspend points when suspend point is
reached it goes back to the caller and
then there is some mechanism which
allows to resume the corrosion so Ian
clang coroutine is lowered to LVM
coroutine right here I retain in the
same structure because optimizers are
very good at optimizing functions
they're not very good at optimizing
state machines so actually we have to
kind of go routines now we have C++
cartoons the one that you probably know
with a weight and yield that are defined
by this proposal but we also have and
all VM corrosions
which are a lower level but there is
still very awesome and we're going to
look at them a little bit and they're
defined by documentation at LLVM website
in an RV m 4.0 and essentially it's also
just a function with a bunch of
intrinsics and those intrinsics tell us
were Courtin begins where it suspends
where it ends and then there are two
extra intrinsic intrinsic which allows
you to resume and destroy the core
routine
what it means is that not only C++
actually just one one extra tangent is
that two years ago we present the
superclass cartoons of this kind for the
first time and I said that superclass
guru teals are most efficient most
scalable most open core teams of any
programming language in existence so it
is true but maybe not for long because
potentially other languages can target
at all the MIR and get those amazing
wonderful disappearin routines that we
saw earlier and because our vm crew
teams are just a function with a bunch
of Etrian intrinsics are marking up the
interesting points we can actually do
coroutines in play and see and so that
we don't have to learn today how L AM
i-are looks I'm going to demonstrate go
routines using C so this is a C
coroutine which generates an infinite
sequence so there is a squatter begin
macro which is just a little bit of
wrapper around the intrinsic and with
he'll it look if you need to allocate
memory for the corrosion use malloc and
the quarter beginning will return me a
handle to a goroutine frame somewhere
because there is some state which needs
to be preserved when coricidin suspended
then at the end we have appropriately
named
Coral end I will tell by the way when
you are done use free to deallocate
memory and then we mark points where we
would like coral team to get suspended
so we have to suspend point here and
here is a usage example we call the core
routine it creates it it returns back a
handle and then we will loop four times
and resume the corrosion at the end we
will destroy it after we send it through
the optimizer it will look just like
that again
even in C coroutines just disappear
so what do we do we need to have some
state which will be preserved while the
corrosion is suspended because stack is
gone and to build that state are we need
to analyze use and definitions
definition and use of values for example
here n is used to initialize I we look
at the definition of M and n is just an
argument and this green line does not
cross as a spend point if it doesn't
cross as a spend point we don't need to
worry about it on the other hand I here
in the print it goes into definition of
I in the beginning of the for loop and
it does to screw cross a spend point
that's this value needs to be preserved
in the corrosion frame so we'll get a
struct and we'll put a value I in it so
once we build the corrosion frame we
will rewrite a function so that whenever
you use to access the variable which has
to go into the corrosion frame we will
be doing that from the struct and that
particular that color begin which gives
us the corrosion frame allocated by
malloc possibly we cast it to the struct
and then all of the access is done there
getting the field from that struct okay
now we need to create jump points
because we need to be able to resume the
co-routine from the middle of the
function we have to suspend points so we
need somehow to remember which one we
are at so again we added a field suspend
index and just before suspend we will
add index equals zero and just before
before the second one we will say spent
index equal one it's slightly more you
know complicated route there are ways to
be modified where the
want to put the suspend index assignment
but for right now let's say is before or
suspend so now we need to split the crew
team into three pieces we need to have a
resumption part that will go and jump at
appropriate points there will be a
destruction part that is going to
destroy karajan's
and it will also have a switch because
potentially not in C but in C++ we may
need to run differ instead of
destructors depending on which suspend
point we are in and finally there will
be a initial function essentially it
will just be whatever coroutine has to
do before it hits the suspend point now
those who are familiar with compilers
they were probably laughing but I am NOT
very familiar so for me it was a
struggle initially to do this split but
inspiration came from Michelangelo and
I'm not sure if it is exact quote but in
Russian this is translated into to make
it a statue I take a piece of marble and
then cut all of the irrelevant pieces so
that's what we do we'll take your core
routine as is at a single block of rock
then we will clone it three times after
that we'll chop them up and at the end
we will get you know all of those pieces
it added up being so much simpler the
code just shrunk so we will do it very
simply we clone the routine three times
and then we do little tweaks and after
that we'll shake it and it will be as
beautiful so what do we do first we will
just clone the function as is so this is
function f on the left and then F Prime
on the right so we're going to make a
resume function out of it
and for that we just need to alter in
the beginning so if our original
function of the ramp function has to
preserve the initial coding convention
return type and all of the arguments the
resume function can be
used it can use most efficient coding
convention and the only parameter it
needs to take is the pointer to court in
frame so our initial function allocates
the corrodium frame and initializes it
and the only thing that we add to the
resume is a simple switch and we will
take root in frame as a parameter and
then we call it again and again so we'll
have three more function like that so
one will be for resume and for destroy
so now we just need to do the do this
thing probation of superfluities it
something like that and to do that we
need to briefly look what are those
macros what is course has been and what
is coral and so of course the spam
simply shows us three possible ways
where we can go every suspend point one
would be we need to suspend so we'll say
go to Cora suspend another one it could
be that we need to do a cleanup when we
destroy in the corrosion and finally we
can fall through and go to the next line
now Cora
n expands into something like that we're
saying look if we need to freeze up and
here is the memory you need to free and
then Google call whatever the free
function C developer gave us for for the
core routine and then will fall to Cora
suspend which has absolutely nothing
apart from the return value and various
little markup they're built in color and
but I'll mention it later so and what we
do is simply we expand core suspend into
a constant so in a start function it
will expand to minus one in the resume
function to zero and to one in the
destroy and cleanup functions and Cora
free will be nothing in the cleanup
function because cleanup function is
used when we decided we don't eat give
allocation so we just need to run the
structures and not to run any memory
deallocation routines and for those
cases where we do have to do memory
allocation we expand it to exactly the
handle which was given to us so
once we did that again what we did is
very simple thing we cloned the function
several times add a tiny little bit of
code and expanded a few intrinsics into
a into constants then optimizer will
actually clean it up for us very nicely
I will end up with this F which just
called allocation routine does some
initialization and then returns kora
handle resume this which will be a lower
down something much simpler like hey I
would index 0 and it will do print frame
I and then say there's an index to the
next value and our destroy and cleanup
will look just like that so again just
like Michelangelo cloned a few cuts
shake and boom it's all beautiful now
when compiler knows the identity of the
coroutine it knows when to call F resume
F destroy RFP but for those cases where
identity of a protein is not known we
will add two function pointers that will
point at appropriate resume and destroy
functions so far this is just a coding
transformation this is how we transform
a function into a state machine at this
point it's it's almost normal functions
there is one little strange thing there
we score a billion which end kitten and
I will show you why we need that so in
addition to splitting coroutine which is
the transformation which potentially can
be done in the front end or in the
optimizer or even in the back end
there are several optimizations which
must be done in the optimizer and
optimizers love in line so let's see
what happens to main when it calls the
ecology so the main looks like this we
call the code in f we resume it twice
okay
we will resume with twice and then we
destroy it this is what F is and when we
combine we see very wonderful thing
because now we can observe the beginning
of the core routine marked with coral
begin and we will see the points when
the core routine is resumed
so compiler is doing the virtualization
here and for say LLVM the virtualization
doesn't really mean to divert chile's
virtual function it just means that we
have somewhere an indirect call which is
turned into a direct call so since we
observe now that all of the resumes and
destroys are routed into coral begin we
can replace them with direct calls over
we can observe that corrosion is
destroyed right here it leaves no more
so now we can replace coral begin we
simple our K which is a stack will just
dump this F frame onto the stack and
would replace destroy with clean up so
what it means is that yoga routine type
has our aii semantics and ra íí- is
great it's like the best thing but look
it's even better with goroutines because
those things give you a hippo location
illusion so now quarantines are done
what we have is a plain function and the
rest of the optimizations will take care
you know to disappear the curtain
completely so first of all what will
happen is that we'll have more inlining
since we replaced in direct calls with
direct calls and we know what resume is
compiler will inline them okay now it
needs to do this very magical thing as
s.r.o a scullery replacement of
aggregates so let me say a few words
about that so it looks simple to you
right it looks very difficult to a
compiler because this big
X is pointer arithmetic to get to this
value in memory and then we do a store
into it and then when we do the return
it's the opposite
so compilers hate those things compilers
hate memory what they like they like
constants so what Thoreau is SRA is
doing it huh either your places your
weight it seemly I destroy the slide but
let me let me speak through it so what
us SRA is doing it turns the members of
your struct into variables so
essentially this whole point goes away
and you will just have int Const int
Const y equal 1 &amp;amp; 2 and then you use
them now I said compiler like constants
so there is this wonderful thing called
SS a static single assignment which
essentially you can imagine is you
simply make all of your variable cost
but that brings complications because
for this case well I really cannot mark
X Const but solution is easy we just
rename it and then all of the places
after the second X will use x1 instead
and then some you people use go-to right
so how do you fix that initially it's
easy we'll have constant here now here
it's trouble right because here our X is
something we don't really know and the
guys go the same and when in trouble
compiler writers resort to magic and the
magic is they simply invent this magical
function called Phi and what it does it
says look if I came from the block with
a label entry I am X and if I came from
the book named loop and x1 so this is
how it's resolved but what is awesome
about as I say that average is
essentially a con
don't value nothing ever changes and
this is what allows us to finish the
optimizing this core routine into
nothing
so do sois get rid of the destruct make
average into a constant we will see here
that our assignments of suspend index
they were all pushed down after the if
and I'm using this notation to explain
where we call the magic fee function so
if I came from the Block B b1
I am I otherwise I might as well so once
we did that we run dead code elimination
this thing disappears now we do constant
propagation listing disappears
goes away as soon as we could go to the
other if now we can replace the fee
nodes with actual values and then we
repeat it one more time and we are here
at the disappearing routine but so far
we talked about generator maybe the
thing you care about is I seen karajan's
so to do the sinker routines I need to
tell a very short joke essentially
rocket you know on the launch pad
doesn't start so they are finding the
guy who knows how to start the rocket
and he gets a hammer naturally he looks
around walks around the rocket and then
hits it in a particular spot really hard
with the hammer that market starts flies
away and then he gives a bill which is
like million bucks
like why the only thing you did is
you're like heat hits your rocket with a
hammer well because I knew where to hit
so the trick to optimizing asynchronous
coroutines is just to know where do we
plug those two
optimisations we talked about because
essentially what we talked about is that
there is a current transformation which
splits it in the few pieces and then
there is another one which does the
virtualization and HIPAA lesion so we
just need to figure out where to put it
so let's go back to the picture again
front-end optimizer code gem and we
already agreed that we will be looking
at the optimizer that's where the meat
of crew team cocoa routine is so let's
let's zoom in if you look into optimizer
it has also several parts there are
early passes which are doing cleanup
after front end because front ends are
on purpose correctly a meeting rather
inefficient code but it can be very
quickly cleaned up we already saw SR or
a optimization which does a lot of
useful things converts into SSA and then
it does some kind of canonicalization
code teens are not there then there are
late passes where we do things which can
potentially blow up the size of the
function for example vectorization again
coroutines not there quarantines are in
my favorite part and I think Chen would
agree it's his favorite part too is what
there was the comment from the audience
yes
bless you so this unpronounceable thing
in the middle is the best because what
it stands for it's cold graph strongly
connected component pass manager because
it looks at your whole module and then
build the co graph to see which function
call which and then it runs optimization
in the bottom of order so first it will
optimize the reuse they will become
smaller and simpler then it'll optimize
their colors why to do it in this order
well because it allows us to do in lion
and in lion is his most amazing thing
which is in the compiler it allows a lot
of optimizations to work really
well and it keeps going like this so
zoom one more time so this is what
compiler does for every single box in
that graph first it does few
interprocedural passes cg sec passes
that are allowed to look at more than
one function in look at the current
function the next function the function
that called it and the big one here is
the in liner so do you think like and
after those guys are done it will go and
optimize the function with traditional
functional passes where would you put
chorus pleat in the beginning in the end
in the middle do you have any feelings
about that ok how about at the very end
now at the very beginning ok good and in
the middle so it's about a half and half
at the beginning in the middle so I we
actually do it almost in the beginning
and at the end and by the way we are
ignoring the correct in the first time
we see it so it is also it
simultaneously in the beginning and in
the end so I also put a line here with a
times four so even if we go back a
patient's start essentially with the in
liner where at the leaf we shrink the
functions and we will see can we inline
something in once we in lined will go
and clean up the function at the very
end there is ad virtualization detector
so if any of the function indirect calls
were turned into direct calls it will
restart if I applied for the same
function from the beginning and it can
do it up to four times configurable but
default is four so we will stick our
curricula it at the very beginning
immediately after in liner and Cora
allied which does he pollution and
virtualization at the very end and let's
see what happens
so our guru team comes here it goes
completely through the pipeline and that
is one of the big ideas of how to make
goroutines
efficient because as I said before
optimizers are awesome at optimizing
functions they're not very good
optimizing state machines so we're
trying to let the kuru team through as
the normal function all the way to the
end of the pipeline up until the point
where routine becomes eligible for in
running into its colors so once we
completely shrunk the kuru king as a
normal function well control flow is
still observable well we can propagate
constants new common expression
elimination and all of those beautiful
things once it finished the end we will
trigger the restart and it comes back to
our core split that's when we actually
go and speed the corrosion so it returns
in the into well three functions in this
case now they all keep shrinking and we
proceed to optimizing the the color of
the corrosion okay good so now we are in
main the one that called the corrosion
and by the way we already optimized and
split out the little pieces so now what
is left is you get to the in liner it
goes up
one more time and because oh sorry when
we scoria lied you remember we replaced
indirect calls with direct calls that
allows that that forces the restart of
the pipeline so it goes back and now it
is at chorus plate so now if this
function happened to the echo routine
you can speak the further so well in
this case goes back to main so
essentially if you have a code which
looks like this when a non-core routine
call the core routine that calls another
corrosion which calls the corrosion then
then you have absolutely no heap
allocations whatsoever okay so let's see
if if you have some questions because I
have more if you need to so yes ah
visual C++ is an earlier version of that
it does not do this yet as well but it
does heap location elysian but
optimizations in LLVM are more refined
they're building upon the experience we
had in the yes okay so here's the state
of the co-routines in LLVM and clang yes
the question was can we use them today
you can use LLVM versions today so what
currently is in the trunk is LOV
local tunes so if you're fine with
writing your own front-end or your fuel
you're comfortable with writing cartoons
in LLVM ir go ahead you can try them out
but if you want to use say C++ we may
get the clang compiler in the trunk soon
that will emit correct intrinsics and
will will make it all work and soon
hopefully it will be in 4.0 but we'll
see okay the question is where is an
example where dynamic allocation would
be necessary for example we are doing we
create a generator and then we moved it
to a different function what we passed
it by reference to a different function
and we don't actually you know we moved
it into their function because now that
function may run the generator and
destroy it but the core does not log as
soon as you moved it out it doesn't know
and it's caught by SSA form we didn't
even have to do anything because we can
only find this nice very clean pass from
the destroy to the beginning only if
nothing just nothing interfered with
that particular value because as soon as
you move you assign 0 to correct in
handle that's it breaks a version and
automatically hip illusion stops and
those are some of the people that were
involved in the design and
implementation of of a man clown
co-routine so great thanks to them ok so
let's proceed to the next part which is
I will teach you how to make
quarantines disappear actually it's even
better it's even better
it stands for building better future and
here I say future literally as in
building banners future like thingy or
if we think differently how would we
design a future if we had quarantines in
the language from the beginning and what
we would like future to be it we want to
enable hip Allegiant and we want to make
future zero overhead is it possible of
course of course
so what are the overhead of the future
and promise and traditionally it's a two
endpoints and what we are doing is we
are transferring a value from a promise
to a future and what we have we have a
memory allocation overhead because we
have to store shared state somewhere
that will store a variant with one of
the three possibilities which future can
hold nothing not yet
a value or inception pointer it would
need to have some atomically account
because lifetimes all the promise and
the future are not in sync so we would
have to use the accountant to do that
and Atomics are expensive especially you
know with multi-core machines 10
nanoseconds 20 nanoseconds also we need
to be able to synchronize set in the
value and get in a value so we would
need a mutex and a conditional variable
and finally there is an extra cost in
the future that requires scheduler
interaction it comes because when we say
set value and let's say we give a
callback to dot them do we execute the
callback right there in Lion when we
call dot them if we do so potentially we
can blow up the stack because
future that we execute with though then
may do something else then does we'll do
that then on another value and we may
end up with a big string of chain of
callbacks that will consume entire
memory for the stack so so frequently
what people do they would schedule a
continuation on a different thread or
possibly they defer it so that you will
get to it when you actually recur from
the current function and this is the
brief reminder of the sugar that
coroutines are doing and those who who
were at the talk earlier this morning
then ignite that for those who don't so
this is the part which is done by clan
so when somebody give us a crew team
with this body compiler will discover
coroutine traits find the promise type
which is the library customization
machine area for the core routine and
after that it will place an object of
type promise on the curtain frame and
since kuru you have to return back to
the caller when it suspends we need to
know what is the thing we have to return
at that point to the caller so a get
return object is the customization point
which tells us what to return we'll give
a possibility to suspend just before we
enter the body of the function and we'll
give a possibility to to suspend before
we reach the end and also if you want to
catch exception stop them and then put
them elsewhere
there is a possibility if you define set
exception we will put a try-catch around
your body capture the exact exception
and push it through through your class
and then you decide what to do with it
when we hit go return it will inform
your library here's the value and go to
file a suspend label same with the
return and just for completeness this is
what happens for the yield
then remember this is a courting frame
and there is a void pointer pointing to
it that what was in our sea example in
C++ we built a little bit of syntactic
sugar around it which just puts a
heavier face on the on the void star and
because we also place a promise at the
deterministic location somewhere in the
curricular frame if you know what is the
purpose of the protein we will give you
ability to reach into it and manipulate
it somehow
for example generator in the example
that James shown that's how you were
getting current value okay we're almost
done with the reminder so an coil weight
when you see that you generate something
like that where we give a name to an
expression we ask it
are you ready if so we will say please
give me the result and here I'm using
the new extension statement expressions
where there is the last statement is the
result of the of the of the book and if
not we will say to the quality please
save the state which translate into set
index like we saw earlier and we will
say hey here's the current handle do
whatever you want with that and in the
end we jump to epilogue and to simple a
waiter's to show okay so now we are
ready to design zero overhead future
which has no of the inefficiencies that
I listed in the beginning so we already
talked about earlier if we want heap
illusion we need to implement our AII so
we're trying to define a task which
which works kind of like a future so to
do our AI we need to destroy it in its
destructor and possibly you know one way
when we start adding new will also check
where the Quora is nothing and then
don't destroy it and we need a
constructor so it will look like this
and again it was shown earlier you don't
want the coroutine to run all the way to
the end and destroy itself you need to
say in the final span please suspend
then there are a few other functions
which are not interesting at the moment
so to take care of the return value we
are going to put that's variant that
stores either a value or nothing in the
previous type itself so and in the
return value we'll emplace the value
into the very end and in a way to resume
we will extract that value and return it
from any weight resume so now we cleaned
up this one and this one we no longer
need memory locations for the shared
state and we don't need Atomics because
with our isometrics essentially
coroutine is always there while you have
the task in your hands as soon as you
structure runs it disappears so you
don't need to worry about the lifetime
now to take care of the mutex and
conditional variable we need to do
something funny about the initial
suspend because why we need to do that
in the future because future the coroner
or a function starts running and it
returns a future it may complete before
you call them or before you call dot yet
so we need to synchronize the access to
the to the to this result variant well
now what we can do we can start cork in
suspended we will say sustained always
to a final suspend and we will return
from the await ready always false
because since coercion start suspended
it is never ready or artist knows in the
initial call so compiler when it
observes that continue is not ready it
will call await suspend and it will pass
a callback or occur to handle for the
guy who called it
right so here I am looking at the case
where there is another core routine
which awaits on this task and it tells
it hey this is my color core can handle
resume me when you are done so on what
we will do we will remember the color
the guy who waits for us in the curtain
frame and we'll resume our self so
essentially we delay starting of the
coroutine until somebody gave us a call
back that we need to call to when the
curtain completes so that took care of
mutex and conditional variable we have a
few little things missing we still do
not resume the waiter because we need at
some point to resume the guy who is
waiting for us and there are two
potential points where we can do that we
can do that immediately in return value
but that may be as we'll have all of the
negative properties of of : polling the
completion from set value because at
that point you cannot tail call that
presumption and they'll call is when
will you place a call to a function with
a jump to a function if we do that stag
doesn't grow so we cannot explode the
stack so to do that we need to modify
the final suspend so final stand instead
of returning suspend always like we did
before we will do something funny will
turn and a waiter that says I am NOT
ready then in the await suspend we will
resume the waiter and it is done you
know at the final standpoint where our
core routine is ready to go away so why
it is important to do it right here
because if you remember earlier when we
looked at how coil weight expanded is
that immediately after we call a weight
suspend we will do well intrinsic or
suspend which is lowered to jump to the
epilogue
it means that now this part is the end
of the function moreover because we
suspended in the beginning it means when
this code is running we are already in
the coding resume function and all
growth in resume functions have the same
calling convention and there is
absolutely nothing else after this call
so it becomes a tail call so now we can
call millions and millions of coroutines
one after another in this fashion and we
don't blow up the stack so and finally
to complete the picture when you take
care of an exception and how we do it
well we need to add an exception pointer
to our variant and we need to add one
more number to our co-routine promise
and well almost there
so now when when exception is caught it
will pass it will stored in the promise
and finally in a way to resume we will
check if the exception is stored we will
very thorough it done so this was
so we just finished to earlier with the
first part this part was like just in
case just in case you don't ask enough
questions so do you have more questions
yes so the question is to make this
optimization reliable so that people can
actually trust it do we need some kind
of guarantee for tail call in C++ 20 and
yes but this is experimental so we just
put together a future again the idea was
what would a future like if we had
curtains from the beginning not have any
overhead we need to applies them to to
to to to to to to real projects to see
how they behave
another thing missing here is
cancellation model we need that and I
think we can you know there are some
ideas how to do it and if indeed it is
as awesome as I just shown I think it
would be beneficial to add some language
to the standard C++ 20 to make tail call
optimization mandatory in some cases and
the same thing with skip a lesion in
some cases HIPAA lesion is a must
it's a correctness issue so we need to
figure out the language to make sure
that for certain cases and the cases are
relatively simple you have to implement
ra íí- and you have to see through
some functions so I need to be able to
inline a little bit if we find a way to
to say it in the language then yes tail
calls and and the hippo lesion will be
there for you in the deterministic
manner and then you will get free
futures yes
absolutely so the question was is this
future implementation is available
online well first of all it fits on two
slides
second of all for those who are lazy I
will upload it to the github bed and you
can try and play and to get the you know
the most efficient compilation you need
to use LLVM and clang version because we
did not yet
do those optimizations in the in DM SVC
okay a question is cancellation
semantics well did you notice that
coroutines here have ra íí- semantics
right and normally you wouldn't think of
having ra ra íí- semantics for the
future leg thing but with school
routines because curtain doesn't go
anywhere while you're suspended it's
perfectly fine but what if we want to
cancel the court in while it's in the
middle of the execution so we have
currently networking ts that has
wonderful thing are your context and I
think it is possible to to work with
that our context thing which essentially
you keep pacing to sockets to to other
facilities timers executors and that
facility has actually stopped and Joanne
calls so we can maybe split it up into
several parts one of them is related but
another is purely a work tracker that
allows to cancel cancel whatever is
associated with that I economist and I
think that's how cancellation might work
so essentially you don't cancel the
future itself you cancel the i/o context
like thinking and then when it's
cancelled it has to go through all of
the outs thing in our operations and
we'll complete them with some kind of
error
I am cancelled and that will bubble up
here and for example you might get an
exception from a wait resume and and
then
in destroys all by itself so that that's
the idea and we are done there will be
another coaching session is 3:00 3:15 I
will stay here for a few moments if
somebody wants to ask more questions
thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>