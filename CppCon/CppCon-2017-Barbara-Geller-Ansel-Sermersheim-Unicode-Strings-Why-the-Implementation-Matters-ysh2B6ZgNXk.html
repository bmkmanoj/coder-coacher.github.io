<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: Barbara Geller &amp; Ansel Sermersheim “Unicode Strings: Why the Implementation Matters” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: Barbara Geller &amp; Ansel Sermersheim “Unicode Strings: Why the Implementation Matters” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: Barbara Geller &amp; Ansel Sermersheim “Unicode Strings: Why the Implementation Matters”</b></h2><h5 class="post__date">2017-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ysh2B6ZgNXk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">- [Ansel] All right.
- Welcome.
Thank you so much for coming.
I'm Barbara.
This is Ansel, and we're here today
to talk about Unicode and strings.
For those of you that aren't
familiar with our work,
Ansel and I are the
co-founders of CopperSpice,
which is a GUI framework.
We're also the founders of DoxyPress,
which a documenting program.
We'll talk a teeny bit
about those at the end
and let you know how to obtain
source code and binaries,
and we also have a few other libraries.
The point today is to
introduce the CsString library.
If you are writing a
program and you use strings,
if you have input that takes
strings, if you have output
that takes strings, and
especially if you're not dealing
just in the United States
with ASCII and Latin-1,
you need to understand strings
and why std::string doesn't
really handle strings.
- So as we go through and talk
about the Unicode-aware string
library we've developed,
we wanna start by
establishing some definitions
and some terminology
that belongs to Unicode
so that we're all on the same
page as we go through this.
- Go ahead.
- So the first piece of
terminology that you need
to really understand to understand strings
effectively is the idea
of a character set,
and this is nothing more
than a collection of symbols.
Importantly, it does
not include any values.
This is just a list of
symbols that someone might use
to represent things in
strings or any text.
So for example, we're
all here in this room.
We're familiar with
the Latin character set
because it's what all the signs
in this building are written in.
There's other character sets
like Greek used in the Greek language.
There are many all over the world.
- A character encoding
are the values associated
with a character set.
Unfortunately, the character
encoding has a number
which actually doesn't make sense.
It should be really
called a character map,
and that's what we're
gonna refer to it as.
- Unfortunately, the
Unicode Consortium decided
this was called a character
encoding, which conflicts
with another term we'll
define, so refer to this
as a character map, 'cause
it maps symbols to values.
When you combine a character set
and a character map
you get what's referred
to as a coded character set.
This is a defined set of symbols
and the values associated with them,
and one of the most common ones
that nearly every programmer
will be familiar with is ASCII.
It's a coded character set.
There are many others that have been used
throughout various computing endeavors,
things like ISO-8859-1,
which is very common
on the Windows platform,
or ones like KOI8-R,
which is common in Russia.
There are literally thousands
of coded character sets in use.
- A code point is the term
we're going to introduce
and is the way you should talk
about characters in a string.
We're not talking about just the symbol.
We're not talking about
a particular letter.
We're talking about a code
point, and the reason we need
to talk about a code point
is it is the atomic unit.
It's 32 bits.
Once you start encoding,
that may take up more space
or less space depending on
what encoding you're using,
but a code point is the key
term that we're going to talk
about as we start
talking about the library
and how to move code point by code point.
- It's important to note
that code points require 32
bits to represent accurately.
At this current point in
time, there are only 21 bits
of that value used, but
there is room for expansion.
If you're not allowing for the fact
that all 32 bits may be
useful, you will have issues
down the road in forward compatibility.
Another term that's used
when you start looking
at how to represent strings
in some concrete way is a storage unit,
also called a code unit in the standard,
although we think storage unit
is a bit more descriptive,
and this is the atomic unit
of storage that is used
to represent the strings in your program.
So in UTF-8, which is one of
the more common encodings,
a storage unit is eight bits,
and every character is represented
by some multiple of these storage units.
In UTF-16, a storage unit is 16 bits.
Another term
which is very important is
the basic multilingual plane,
and you can look at the
basic multilingual plane
as sort of the beginning
of the Unicode standard.
It's the first 64,000
symbols, and these are
exactly the set of characters which fit
into two bytes in the UTF-16 encoding.
It contains most characters
you would encounter
on a regular basis plus a
lot of mathematical symbols.
- ASCII is commonly referred
to as eight bits, but it's not.
It is a seven-bit character
set, and it's only seven bits,
and this is something that
people want to believe.
It's Latin-1 that goes into eight bits,
but when you're talking
about ASCII, and ASCII was
really the beginning of
setting up a character set,
and we're going to find that
the first 128 characters
in ASCII appears the beginning of Latin-1
and the beginning of Unicode.
And this is where most
people in the United States
and working in English find
that that's all that
exists, which isn't true.
The characters go much further.
- So if you ever find yourself saying,
&quot;Well, that's just eight-bit ACII,&quot; stop.
That's not true.
ASCII is seven bit.
If it involves eight bits,
it's some other character set.
For example, it might be Latin-1,
otherwise known as ISO-8859-1, very common
in many parts of the world.
It's an eight-bit coded character set.
It includes ASCII as the
first half of the code points,
but it adds additional ones
to support non-English,
still Latin scripts.
It's a superset of ASCII,
so many people use the
terms interchangeably,
and this is just one of a large number
of other coded character sets
that support various languages
throughout Europe and many other places.
- There's actually Latin-2, -3, -4.
There are other Latin sets,
so you can't just say Latin.
Latin-1 is a specific character
sets, but you will find most
of the other character
sets in European languages.
- So Latin-1 works great if all you want
to do is represent a select
handful of European languages
and, oh, and you don't ever
need to use the Euro sign,
because it was introduced
after Latin-1 was standardized,
so there's various places
where Latin-1 simply won't suffice.
So we need to move into a
more general description
of symbols and code points.
- The reason why we
started with the letter A,
the Latin capital letter A,
is everybody knows this is 41.
What can get confusing
is what the values are
when we start encoding, but
as an example, since it's 41,
when it's encoded in UTF-8
or it's encoded in UTF-16,
we say 41, but it's actually not true.
In UTF-8, it's 41.
In UTF-16, it's 0041 because
of the number of bytes,
and this one because
very, very easy to see.
What becomes a little more
complicated is if we move
to letters that are outside this range
and we need more bytes for encoding.
- So for example, there is a symbol
in the symbol area of Unicode
called the rightwards arrow
with corner downwards.
It looks like this, and you'll note
that every Unicode symbol
is uniquely identified
by three things that go in
concert: the shape of the symbol,
or it might be a nonprinting
symbol in some cases, its name.
This is in the Unicode standard,
specifically named rightwards
arrow with corner downwards.
That is a defined name.
And its code point or code position.
That's the U Plus 21B4,
and that is a value
that is not in any encoding.
That is the raw value that is specified
in the Unicode table for this code point.
- When you're encoding
in UTF-8, as you can see,
it's gonna take three
bytes, so again, this is
where it becomes really
obviously in a value like this,
because 21B4, that is
just an assigned value
by the Unicode Consortium.
Once it's encoded in UTF-8,
we're at three bytes,
and UTF-16, it is two bytes.
What's really important to notice,
this is one code point,
not two, not three,
so every single code point
has how much storage it takes,
and these are variable number of storage
because they are different amounts,
but it's really important to remember
this is one code point.
- So if you correctly
interpret the first string here
as UTF-8 and the second string
as UTF-16, they are equivalent.
They contain exactly the
same data, one code point.
Its value is 21B4.
They are just represented
differently in memory.
Now, as I mentioned,
if we step outside the
basic multilingual plane,
we get to some more obscure characters,
so in this case we have eighth note,
musical symbol eighth
note, and you can tell it's
outside the BMP because its Unicode value
of U Plus 1D160 has five digits in it,
so therefore it exceeds 16 bits.
It's outside the first 64K,
thus it's outside the BMP.
In order to represent
this symbol in UTF-8,
we use four storage
units with these values,
and there is a representation
in UTF-16 as well.
It uses two 16-bit storage
units, and each one
of these storage units is what's
referred to as a surrogate.
This a feature that was
added to the standard
when code points grew from 16 bits to 21.
It would be ambiguous in UTF-16
if these values were
ever legal code points,
so essentially in the
Unicode table, this range
from D800 to DFFF were reserved.
They will never be assigned
to any valid code point,
so when a UTF-16 decoder
sees a value in this range,
it knows that this is a surrogate.
It needs to be combined
with the following surrogate
to form a complete code point.
The same thing happens that
these are not valid in UTF-8.
One of the differences
between UTF-8 and UTF-16 is
in 16, we have the surrogate pairs.
In UTF-8 they're multibyte, so to know
that there is a surrogate, you
would go to the Unicode table
in UTF-16, and there's that range.
In UTF-8, as by looking at
the high bits, you can see
that we need more bytes to
generate an actual code point.
That actually makes
UTF-8 easier to decode,
and encode, and understand than UTF-18.
- And that unfortunate
accident of the existence
of UTF-16 is that since it's unable
to represent certain values
in the space of code points,
we must reserve those for
use by all implements,
so they're not available in UTF-8,
even though they could
be represented in UTF-8,
because they would not be
representable in UTF-16,
and they must be harmonized.
- Unicode code points are 32 bits.
This isn't negotiable.
It is part of Unicode, so
it does become the question
of why are we using UTF-8 and UTF-16.
Why aren't we using UTF-32?
And we're gonna talk about that
and why 32 becomes wasteful
and 8 is becoming the
optimized way for encoding.
- So I've alluded to UTF-8
in several points previously.
UTF-8 is a variable length encoding.
It's capable of representing
every code point
in the Unicode standard in a sequence
of eight-bit storage
units, and it has a lot
of very nice properties.
For one thing, if you're
working with ASCII text,
then the encoding is
the identity encoding,
so ASCII text is unchanged
when you encode it as UTF-8.
Also, whenever you have a
multibyte character in UTF-8,
it's values always have the high bit set,
so they can never be
confused for any ASCII value,
so UTF-8 encoded text, for the most part,
will pass unchanged
through legacy programs
that expect eight-bit encodings.
Another very important is the
fact that since we're dealing
with individual bytes here,
we don't have to worry
about the platform endianness of strings.
It's very helpful.
In order to do UTF-8
encoding, you need to be able
to determine how many
bytes it's going to take
to encode a particular
code point in memory,
and this process is simpler than it is
in UTF-16 for some cases.
- We do have this little
code we're gonna show you
when we go over the library
that's gonna show the difference
of how you do an encoding
for UTF-8 versus UTF-16,
and the math and the code
itself is just easier
and less error prone in UTF-8.
UTF-16 is also a variable length encoding.
This is some of the differences.
If you've looked at the Unicode standard
and you've seen that
some languages use UCS,
and there are encodings we're
gonna talk about very briefly
that preceded UTF-8
and UTF-16, so you have
to ask, is an encoding a fixed
length or is it variable,
and UTF-8 and UTF-16 are
variable, as we've shown
that it can be one, two, or
three bytes, or you could go
up to four in UTF-8.
There was a time that UTF-8
went up to five and six,
but that was disallowed in
2003 by the Unicode Consortium.
- The real downside to UTF-16 is
that it gives you a
false sense of security.
The problem with UTF-16
is that it's both too wide
for things like ASCII and
Latin, so you waste up to 50%
of your storage space for strings
that don't need multibyte characters.
And it's too narrow to contain
the entire Unicode set,
so you have to deal with
all the complexities
of a variable length encoding anyway.
- Some of this started early
on when people were trying
to choose what encoding
they wanted to use,
and Microsoft kind of set
the standard way back when,
and they did choose UCS-2,
UCS-2 being a fixed width
and a predecessor to UTF-16.
Other languages followed suit,
and it really seemed like a good idea.
Everybody was like, &quot;Well,
this is the way to go.
&quot;We use UTF-16,&quot; and in
some ways now, looking back,
it's like, &quot;We didn't
really think this through.&quot;
And in fact, the Unicode
Consortium felt the same way,
that we didn't think it
through, and now what?
Now, we're partway through.
Everyone is using UTF-16.
What do we do?
- And at a certain point,
they discovered that all
of the symbols used in all of
the world's writing systems
throughout all of space
and time are not going
to fit in 16 bits, so they had
to grow the code point size,
and this removed a lot of the advantages
to a 16-bit encoding.
So most languages and operating systems
that have come more recently
to support Unicode have used UTF-8,
both for backwards-compatibility
reasons and also
for the quality of
implementation it allows.
- Joel On Software is a blog
that if you're not familiar
with his work, you should Google him
and take a look at his work.
This is a quote that he put down in 2003.
It's really valuable, because
if you don't know the encoding,
you can't interpret the text.
He ran into this a lot with email,
and email was set up to be encoded,
and some were using one
encoding, some another.
There's a gentleman who
actually did a commentary
on this particular blog,
and he looked at some text
and he said, &quot;Well, I'm gonna just guess,
&quot;'cause I'm sure I can
guess the encoding.&quot;
And at one point, he decided
it looks like a DNA sequence,
and that's where he went with it.
And then he kept trying
different encodings,
and nothing actually fully encoded,
and then somebody told him it was Kanji.
And when you look at the numbers,
and then you look at Kanji,
they're not similar at all,
so it really turned out you cannot guess.
So again, if you're writing
any software or dealing
with strings in any
way, you need to decide
on an encoding, and you need
to either inform your users
or have it set up some
way in your software
or the library that you're using
that it understands the encoding.
- So the most fundamental
takeaway from this talk is
that if you have what
you think of as a string,
and you don't know what encoding it is,
you don't actually have a string.
You have a sequence of integers
which are without meaning.
It is of the utmost importance to know
what encoding every single
string in your program is
or you cannot understand what it means.
So let's look back at the history
of how we got into this state.
The original version of
Unicode came out in 1991,
and the major encoding
that was used was UCS-2.
It was 16 bits per storage unit,
fixed width encoding, because again,
they thought that was all the
characters we would ever need.
- Something happened in 1992,
and actually reading the history
of this is quite fascinating.
Ken Thompson and Rob Pike
designed UTF-8 on a napkin.
They were contacted by a
particular group, Open--
- X/Open--
- X/Open.
- was asking for a better
standard to encode characters.
- And it's a very interesting story.
Rob has actually published,
and he used to work
on a project where he had
them pull up the old server
so he could prove the emails
of a gazillion years ago,
that this is actually the way it happened.
And they developed this,
and they got UTF-8 working
in Plan 9, which for those of
you Linux people are familiar
with Plan 9, that didn't
quite go where they wanted,
but it did do UTF-8 in about three days.
- Unfortunately, it took
a long time for people
to realize that UTF-8 was
going to be a good idea,
so in 1992, as they were developing UTF-8,
other companies started adopting UCS-2.
It seemed like the way to go.
In '93 was when the
Unicode Consortium realized
they'd hit the 64K wall.
They were going to have problems.
They had to expand the code points,
so they released a new
encoding system called UCS-4.
This is a four-byte, fixed width encoding,
and everybody said, &quot;My, God.
&quot;Four bytes for every single character.
&quot;There's no way we can do that.
&quot;That's wasting way too much memory,&quot;
so nobody used it.
UTF-8 was widely publicized that year.
It was introduced in USENIX.
- But it wasn't until
1996 that it was adopted,
and this actually amazing
to me to realize it was 1996
that UTF-8, and they did come
out with UTF-16 the same year.
But then, companies still
didn't make the change,
and we're talking about
Microsoft, and Java,
and a lot of other companies.
They didn't make the change,
and it was available,
'cause they didn't understand the power,
which unfortunately means changing
over later becomes more difficult.
The other key thing to notice here is
that Google has done some
studies on the availability
of UTF-8, and they've
released some statistics.
In 2012, it's been estimated that 50%
of the internet now uses UTF-8.
As of September of this year, it's 90%,
and that's email, XML, HTML.
So the internet is going UTF-8.
- So if you have any
connection to any sort
of network server in your
code, you need to be able
to handle at least UTF-8,
and the great thing
about UTF-8 is almost every
network server supports it
at this point, so it's the
only non-ASCII encoding
you need to support.
You don't need to worry about any
of the legacy character sets.
You just deal with UTF-8 and you're done.
- And this year, we have
actually released CsString,
and the reason why we did it,
we're gonna show you an
example in a few minutes here
of how mangled data can actually get
if you're not following your
own rules of using UTF-8.
And we have released CsString.
It is a BSD-licensed library,
and it is standalone.
You can use it in your C++ applications.
We've also incorporated it
in our CopperSpice GUI
framework under QString8.
We are developing that class,
so if you are a CopperSpice
user, you'll be able
to use UTF-8 directly
in the GUI environment.
- So let's step back for a
second and talk about how some
of the other libraries that
are out there handle strings
to sort of form the
rationale for why we decided
that yet another string
library would be of value.
A large part of what we've done
in the CopperSpice project is look
at places to improve the existing code
that we were working from,
and we discovered challenges
along the way in many different parts.
And once we got to a
certain point, we realized
that the string handling was
really subpar, so we decided
to look at it in more
detail and we realized
that in our other projects
we were also running
into trouble with Unicode string handling.
We thought there's a theme here.
This isn't just unique to
a large framework library.
Everyone needs to work with strings.
Every needs a functional way to work
with strings that actually works.
And we said okay, well, what is out there?
Well, the first place
to look is the standard,
so we have std::string.
Does that give us any help?
No, none whatsoever.
There's std::string, which might
as well have been called std:vector&amp;lt;char.
for all the help it gives you for strings.
Yes, there's some string
operations like substring,
but it really doesn't understand text.
It has no way of
representing encoding at all.
It just deals with a
sequence of eight-bit bytes.
There's std::wstring,
which might be 16 bits,
or it might be 32 bits,
depending upon your platform.
There's some interesting behavior there
that's implementation defined,
and it really doesn't help
you that much because it
still doesn't give you a way
to specify the encoding.
We need Unicode strings, not std::string.
So we looked at other libraries.
Well, as I said,
std::string has no encoding.
What does Microsoft do with MFC?
Well, they started on
UCS-2, and they moved
to supporting UTF-16 mostly.
- QString in Qt, well,
it started out as UCS-2.
They have migrated to UTF-16.
There's a few issues,
though, with QString,
and that has to when there are surrogates,
and the problem is if
you're using Qt and it's
in this encoding, Qt
itself doesn't always deal
with the surrogates, and
you have to glue them
back together in your code.
- And this is a very common behavior
in libraries that started with UCS-2
and then were extended to support UTF-16.
They leave a lot up to the programmer,
and it's easy to get things wrong.
And a great example of this,
I'll take a moment to pick on C# here.
Every one of these libraries
has similar issues,
but it's one of the
most demonstrative ones.
In C#, there is a text field
element in the GUI library,
and you can specify the
length that you want a user
to be able to type in in characters,
but it's not really characters.
It's storage units, so
if you, for example,
take a text field and say,
&quot;I'd like the user to be able
&quot;to type in 10 characters,&quot; and
they type in nine characters
that are in the basic multilingual plane.
Those each take one
storage unit to encode.
And then at the end of the
string, they type in a character
outside the BMP, it will
insert the high surrogate,
fail to insert the low surrogate
because there's no room
for it, try to report
the error to the user,
and in the process of
displaying the string,
attempt to render an invalid
UTF-16 string to the display,
and it crashes the .NET runtime.
This is an example of just
how badly things can go wrong
when you have a library that
claims to support UTF-16
but doesn't take care
of all the corner cases.
And since nearly every
character that's used
in common usage is inside the BMP,
these bugs can lurk for
years until someone hits
exactly the right corner
case and discovers it
and crashes your program, or
breaks your security system,
or what have you.
This is incredibly dangerous,
so there must be a better way.
- So as we were working on
DoxyPress, which is a documenter,
and our main focus of enhancing DoxyPress,
which is a fork of Doxygen
if you're familiar with that,
we wanted to be able to parse C++,
and we actually use Clang
as a front end for parsing,
not a Lex parser or anything like that,
so we can truly leverage
what's already out there.
Parsing isn't something
we need to reinvent.
We need to take the output
and feed it back in.
Ironically, we found problems.
The original versions dealing
with DoxyPress use things
like QCString, and these were way back
in the late, 1999, a long
time ago, and these weren't
actually handling strings
the way we think of them.
- They were basically
giving you the same amount
of support for strings
as std::string does,
which is to say none.
They just treat it as a bag of characters.
So we went through and
refactored all of this code
to use the QString class from
CopperSpice, which is UTF-16,
and we figured that this
would make a great improvement
in the ability of DoxyPress to
handle non-ASCII characters.
- So what we have here
is a problem we found.
The QString text here, this text is
just text in English that's
going to be displayed
on a particular page, some HTML output,
and this is the code it
was being run through.
We'll come back and take a
look at this code in a second,
but basically, m1 is calling
m2, and then it's printing out.
But then we decided,
hey, we're international.
We should actually test
in some other languages, not just English.
- So we translated the string
into some other languages--
- And I think that's pretty good German.
If we have any Russian speakers,
we've been told this may not be exactly
what the English would
say, but it's close enough
that that's kind of the interpretation.
I can at least tell
that looks like Russian
and looks like German.
Ansel speaks a little bit of German,
so when I was testing this,
and this is real-world case,
I asked him to come over
and look at it and say,
&quot;Is this really German?&quot;
- Well, I looked at it, and what I was
actually looking at was this.
- Was this.
That's not exactly German.
And just so that you note,
we did not put carriage
returns into this Russian.
This is exactly what
came out in DoxyPress.
As we were running it
through, we got this out,
which is sort of telling us
we had a UTF-8/UTF-16 problem
'cause we're not using UTF-8.
We were using QString.
- And here we are working
with a UTF-16-compliant string library,
and we got garbage out the other end.
What happened?
- We have been told by some friends
from Ukraine that is not Russian.
(audience laughing)
No way.
So what was going on?
Let's take a look at the code.
- The problem here is
that we have a string.
As I mentioned, QString is in UTF-16.
We're calling a legacy piece of code
that wants a const character star,
so we take this string
and we convert it to UTF-8
because that's a great encoding to use.
You can represent every Unicode character
in an eight-bit string, so any function
that takes a const character
star can receive this.
So we call m1.
It's fine.
m1 is passed data which points
to a UTF-8-encoded string.
Then, m1 calls m2.
There's an implicit
constructor for QString.
It receives this data.
It assumes the data is in Latin-1.
It's not.
- And there's no way to
tell it, not in QString.
And again, this also happens
in many other languages.
We're just using this as
an example to show you
that code like this just doesn't work
unless you know the encoding.
- So when we interpret
this string as Latin-1,
we get garbage out the other side.
This is an example of how insidious it is
to have a string in your program
that does not contain encoding
information along with it.
As I said, every string must
be tagged with its encoding
or you can't interpret it correctly.
If you have any code in
your program anywhere
which does not know what
encoding the data is its working
with, you will have problems of this form,
so we need something that
always guarantees it knows
what encoding it is.
- CsString to the rescue.
So what are we going to retain
as we're building this library,
and what do we need to change?
We did start by looking at
QString and std::string.
- And we realized that eight-bit
storage is a good thing.
For one thing, it covers the vast majority
of text use cases in a more
efficient way than 16 bit.
Also importantly as I
mentioned, it guarantees
that if you have issues
with multibyte encoding,
you'll find them quickly because nearly
every non-English character
will exercise those code paths.
But what needs to change?
Well, we need to support encoding.
We need every string in the program
to be tagged with its encoding,
and we really wanna deal
with Unicode, because at this
point in computer science,
all of the other encodings are
basically historical artifacts,
and we wanted an ability
for people to add new encoding formats
as different things become
available without having
to change the implementation
of the string class.
- So our idea was to write a
library where the iterators,
the class, the basic string was all set,
and that we have one class
where the encoding exists,
and that's all you need
to modify, and change,
and enhance to add a new encoding.
We needed to define what
comprised the basic,
and we're calling that CsBasicString.
It does allow defining
your own allocators.
We actually don't spend
much time going over that.
If you need to set up your own allocator,
the library will take an
allocator that you can pass to it.
- What's important about using
CsBasicString is the fact
that regardless of the encoding
that the string is stored in, the user
always sees a CsBasicString as a sequence
of 32-bit code points.
You don't need to deal with the complexity
of UTF-8 multibyte sequences,
or UTF-16 surrogate pairs,
or any other variable length
encoding in any representation
that you might be using,
and it supports conversion
between these existing encodings as well.
- So this is what it would look like.
We have just set up some usings
so that you can type it easier.
This is part of the library.
Currently, the library does
support UTF-8 and UTF-16,
and we're gonna show you how easy it is
to add another encoding.
But first we had to say, &quot;Wait a minute.
&quot;What is a string?&quot;
And these were come of
the ideas we came up with
of what a string is, which
is why this topic became
so interesting to us, and it
actually becomes very
complicated, because all
of these do satisfy the
definition of what a string.
But how do you handle each one of them?
- And it's really important
to understand the distinction
between a few of these that
we'll start looking at here.
So what data types do you
see in these examples?
Because many novice C or
C++ programmers and go,
&quot;Oh, I see a bunch of strings.&quot;
But as we all know, data
types are quite distinct
and can be complex.
Would anybody care to
guess what data types exist
on the first line of code in here?
- [Attendee] So abc, the
encoded abc is a reference
to an array size four of const characters.
- Yes.
- [Attendee] And I'm sure one
is a pointer to const char.
- Very well said.
- Yes.
- [Attendee] I have implemented
strings (becomes faint)
- Yes, that's very good.
- Very well said.
- abc is also referred
to as a string literal,
but most people aren't really sure.
They just read it as a
const character star.
- Mm-hmm, so let's break
these down piece by piece.
So for our purposes, we're going
to call a const character
star a C-style string.
Many people have used that definition.
It's a little easier to hear.
It's initialized with a string literal.
A string literal, being an expression,
has to have a data type,
because a string literal
is the expression itself.
Its data type is array of four characters.
As he noted, there's also a
const in there and a reference,
but the important meat
of the definition is
that it's an array of
characters, char type.
On the second line, when we
assign str1 to a CsString,
this is unsafe because we don't
know what encoding it's in.
We have no way of knowing that
this is const character star,
C-style string variable that
came in from who knows where.
This is not safe.
On the other hand, in example
two, we have a CsString
that's being initialized
with a string literal.
These are not the same, and
the reason it's important
that these are not the same
is because we wanna be able
to tell the difference
between these two cases,
because if you're initializing a string
with a string literal, we know
what encoding your string is in.
We can safely convert it to a CsString.
This yields a lot of API benefits.
If we don't know what
encoding your string is in,
this is unsafe and we
need to make this explicit
or give you other ways to
disallow it in your code.
And it turns out that
it's actually fairly easy
to tell the difference between these cases
in a string library, so we
have separate constructors
in CsBasicString, one of them
which takes a string literal,
which if you work through the
data-type manipulation needs
to be a constructor that
takes a reference to an array
of any size of const character.
And then we have another
one which allows passing
in pointers, but this
can be either deprecated
or disabled depending upon
your needs in your application.
Well, why do we do this?
Because we had an API
requirement for CsCstring.
String literals are really
important for API quality.
If you can't use string
literals in your code
when you're manipulating strings,
it becomes very difficult
to read, because you
have constructor calls
or conversions littering
anything that works with strings.
- Okay.
So this was, oh.
Yes, we're here.
Okay, so we're on sample code.
- Yes, we are.
- Sample code.
and another type of string literal.
- So there are many
types of string literal
that were added in C++ 11.
- 11, yes.
Go on.
Let's get the U.
This is not as well known,
but you can specify a string literal,
so you can specify the encoding.
It was added in C++ 11.
The syntax may not be gorgeous,
but at least it works.
Please note that UTF-32 is not supported.
We're not quite sure why,
but they supported that one.
They unsupported.
We have not, which one am I on?
- UTF-8.
- Unsupported. Yes.
Currently supported ones
that are not supported.
The annoying one is const char.
Why wasn't that const char 8_t, Richard?
- That should have been.
- This is a terrible
feature in the standard
because it means that as
a library implementer,
you can't tell the difference
between a string literal,
which is in the compiler's
runtime encoding,
and a UTF-8 string
literal, which is in UTF-8.
This is really unfortunate,
so we can easily support
string literals of the UTF-16
and UTF-32 type, but it's
ambiguous on the UTF-8 type.
- We actually have a define in the library
that you can turn on and off depending
on how restrictive you want to make it.
- So if you do happen to try
to pass a string literal
containing a multibyte character
without specifying a Unicode encoding,
you will get a warning from
your compiler, and this is
because the behavior is
implementation defined here.
And the behavior on the
compiler that we use most often,
GCC, is in most cases to encode
the string literal in UTF-8,
which then, when the string is parsed
in a different encoding,
creates some issues,
so this is something to avoid.
You should make sure that you
have this warning turned on.
If you suppress warnings,
you probably don't
wanna suppress this one.
- So the design of the
library CsBasicString,
it really encompasses
everything we need to do.
It's pretty much a drop-in
replacement for std::string.
We have written all the methods.
Find, there's a lot of find methods.
We have added numerous
ones, and everything
in CsBasicString, again,
it calls the encoding,
so nothing needs to change
in the basic string class.
It does everything you
would want it to do.
We have also started to add find_fast,
and we are adding that in
various places to do things
that return an iterator, not an index,
and this has become very powerful
for us in CopperSpice
when we want, actually,
to deal with iterators and not indexes.
If you start breaking
down the code and looking
at what it takes to do all
the methods in std::string,
you'll find that
everything is index based,
but again, it is really
nice to have iterators.
It's easier to work with.
It's actually easier.
You're not dealing with off by one errors
as much, which were notorious at finding.
- So inside a CsBasicString,
we have a vector
that contains the raw data.
In this case, we'll be looking at UTF-8,
so it contains a UTF-8-encoded string.
So we have a private data
member called m_string
that is this vector, and
the beginning and end
of this are vector iterators.
Well, we don't want to expose the vector
because we don't wanna expose the raw,
underlying stream of bytes.
These are private, so
we wanna give you a way
to access the data without having to deal
with the complexities of
encoding, so how do we do this?
- We wanna actually be
able to walk code point
by code point, so what we
did is we drew a graph here,
'cause like we said,
internally, we're dealing
with std::vector, but outside as a user,
we're dealing with the CsString.
The reason why this slide
becomes very powerful is
you can see the rightwards
downward arrow is three bytes,
so if you're looking at it in
a vector and you were walking,
the string length would
look like it had three bytes
for that, but it's one code point.
And we're you're walking
a string externally
or in an application, you want to be able
to walk code point by code point.
So here's the encoding.
This is all it takes for
us to add UTF-18, -16.
You want some other encoding.
This is all you would have to write.
This is the class for UTF-8.
We'll show a little bit
of the implementation,
but it's a using and a couple methods.
That's it.
That's all it takes.
You define these.
There's a new encoding in the library.
- So we distilled the
functionality that a string needs
in order to work with an encoding down
to this very simple API so it's very easy
to implement new encoding.
And so here's an example
of what the insert method
looks like in UTF-8,
and if anybody here has actually worked
with a UTF-8 encoding,
this code will probably
look fairly similar.
It's just a bunch of
straightforward boilerplate
of doing some bit shifts
and manipulating things
into the right arrangement for
storage in the UTF-8 format.
- This was actually very easy to test,
because we either put
in the right characters
and got it out or we didn't.
- And the second half simply
deals with the three-byte
and four-byte UTF-8 encodings.
Again, nothing terribly
complex or high tech here.
- Once you test the off by one errors
and they're fixed, the
encoding just works.
So when we ran through
some of the testing,
Ansel wrote some not-so-human-readable,
not-so-pretty testing,
and did about 1,200 tests.
I wrote a little bit
more human-readable stuff
that tests about 85 different outputs.
One of the great things
is he tested everything
that he could test against std::string,
so that gave us a lot of confidence
in the work we were doing.
- And as an example of
some of the testing,
we can do things like
this where we can manipulate
multibyte characters easily
without having to deal
with the complexities
of how they're encoded in the string,
so we can just append a character
outside the basic multilingual
plane and it just works.
- The tests here that we're
showing, these unit tests here,
they are part of the source
code, so if you go to our form
or our GitHub, these are actually included
so you can take a look at them.
- Here's another example of a test
which ought to be really easy.
Every string library on
the planet ought to be able
to do this innately.
Try this in your favorite
language that claims
to support Unicode strings
and see how much work it is
to actually get the right output.
Just walk through a string in
reverse and print each symbol.
It is surprising how much code this takes
if you have a library
that does not give you
the support for putting
back together code points
from the representation.
And then again, just simple
erasing the first character
from the string and
repeatedly printing it.
Give this a try in your favorite library.
You will be surprised at
how badly it will come out,
and if you're in C#, you will
probably crash the runtime.
- Here's another test that
we did, and the only thing
that we're trying to
point out is the storage
versus the code points, 'cause
when we showed that graph,
we showed that if you
were walking the vector,
there would be a larger size,
so we did include that method
in the library if you wanted to see
how long it would be in terms of the size
of the internal
representation in the vector.
And by the way, we are
looking at changing the vector
to be a small vector for optimization.
- So we're in the process currently
of taking the CsString
library and integrating it
back into CopperSpice, and we're going
to gain several benefits by
doing this, first and foremost
that it will gain support
for UTF-8 strings,
which are much more efficient
and better designed.
- We have about 75%
of the QString methods
working in QString8.
It was very interesting
implementing things like
to be able to normalize,
and upper and lowercase.
When we were reading
some of the existing code
of various libraries of what
it takes, using our library,
our CsString library, the
code size went way down.
We didn't have to ask,
is this a high surrogate;
Is this multibyte?
'cause we were just walking code points,
so our code got much smaller
and much easier to read,
and easier to test.
We even got to resolve an issue
that was actually broken
in DoxyPress, and this is
because you can do parsing
with using the Lex parser
and not using Clang, and
the Lex parser turned
out to be broken, which
was quite interesting
as we were trying to
display some documentation
during our own testing,
and we couldn't figure out
why UTF-8 and UTF-16 were broken.
And then we realized
the parsing was broken.
- So earlier when I said UTF-8 is designed
to pass unchanged and undamaged
through most legacy code,
the key word there is most.
Not all legacy code deals
well with characters
outside the 00 through 7F of
ASCII, and this turned out
to be one such case, so
examine your parsers carefully
for what they do when they
encounter non-ASCII characters,
and make sure it does something sane.
- And we did correct
this in the Lex parser,
but if you're going to use DoxyPress,
use Clang for the parsing.
So this is sort of why we did everything.
We're working on CopperSpice.
We're working on DoxyPress,
and we need ways to handle strings.
So this is kind of just an overview
of how everything comes together for us
as we are integrating
everything back into QString 8.
And as we do this in CopperSpice,
we're going to be able
to add some using statements,
and then do a QString and a UTF-16,
and have everything there
based on our library.
We're also gonna be able to remove some
of the wrapper classes and some
of the complexity internally.
We have already done some
studies, and we're expecting
to see the internals of DoxyPress
in many places shrink
by 50%, because so much
of our internal strings
are ASCII and Latin-1.
Basically, just to let
you know like I said,
we released this library
earlier this year.
Ansel's released a libguarded library
that is going to presented tomorrow,
and we also have a signal/slot
library for delivery
of signal/slots that are based
on methods and not classes,
so we have these three
separate BSD libraries,
and we have CopperSpice,
and we have DoxyPress.
We also are thinking of some
other things we want to do,
but we're trying to keep the
number of projects we're doing
down to just this because
we think we have enough.
We're on GitHub.
We have a website that has a form
that you can download any of our source.
Everything is open source.
Everything we can BSD, we do.
We also started a YouTube
channel about two months ago,
and we crossed over to 400 subscribers,
and hopefully we'll be much higher
by the end of this conference.
Our YouTube videos are
on YouTube/copperspice.
Our aim on these videos is
to show CopperSpice, DoxyPress, and C++.
We just did three videos
that go through data types
and value semantics, and in these videos,
we take it from the beginning
of what is a data type all the way
through value semantics, and
pointers, and references.
And on these videos, we really explain
why you can't call a
reference just a reference.
So all of these things are available.
We're here all week to
talk about all the products
that we have, and we would
love to have contributors
on the work that we're doing.
We do have a couple people
that have doing some extensive testing
on the string library, and one
of the gentlemen who is here
at the conference, he says the
more he is using our library,
the more he realizes std::string is broken
and insufficient for the work he's doing.
Are there any questions?
Yes.
- [Attendee] All right, so I'm a Rust--
- [Attendee] Microphone.
- Oh, we actually have a microphone.
- Oh, we actually have a microphone.
Excellent.
I don't have to repeat the question.
- [Attendee] So I'm a Rust programmer,
and we obviously have
a UTF-8 string library
in the standard library.
I don't know why that's
obviously, but we do.
It's pretty good, and one of
the things that was worrying me
when I was watching your
presenting was you have this kind
of thing where you have
indexes, and what worries me
about that is when you have graphemes
that are multiple code points
so people kind of start.
It's the same issue you have
with UTF-16, right, is people start
to think one code point is
one displayable character,
but if you're doing that
reverse iterator example,
unless you actually pay
attention to NFKC and everything,
you're gonna have an issue
where you'll print an E,
and then you'll print the thing
that goes on top of the E.
- The accent, yeah.
- [Attendee] Yeah, the accent.
- So to respond to that
question about graphemes,
and grapheme clusters,
and stuff like that,
that's version two for one thing.
The design basis for CsString
was let's design a container
that is capable of
representing Unicode strings
without mangling them.
Adding the ability to process grapheme
by grapheme is, in my
vision, a layer above that,
because the code point is
the atomic unit of text,
and so that will probably
be a translation layer
that is build atop CsString
that can give you grapheme-based iterator.
- [Attendee] The thing that
Rust does is it has iterators
for code points, and it has
iterators for bytes as well,
but it doesn't let you
index into a string,
which is something that
I think is a good thing
because it forces people
to think and forces people.
In my compiler, I have
to use a Unicode library
in order to deal with that kind of stuff.
- So with respect to not
having the ability to index
into a Unicode string, I can
see that when you're starting
from a clean sheet of paper,
that makes a lot of sense,
and our goal was also to
be sort of the gateway drug
to be a less harmful
version of std::string,
and people expect some sort
of index-based semantics.
You may not get exactly 100% correctness
if you have very complex
combining characters,
but at least you won't
generate invalid Unicode
to the level that a
library that allows you
to put just a bare high
surrogate in a string will do.
- What we've also been doing
with CopperSpice is we've
written normalization,
composition, decomposition, so we're kind
of spending some of our effort.
What does it take to upper and lowercase?
What does it take to compare?
So we've done a lot of
this in CopperSpice,
not with the idea of just leaving
it there but with the idea
of once we figure out
exactly the best ways,
how to do that, like he's saying,
of a layer two of the library.
We didn't wanna do it wrong,
and so it's really
right now you would have
to decompose the string,
but we've learned a lot
about strings just writing
this decompose in QString8,
so we can understand what does it take.
And when you start
getting into the accents
and the graphemes and just a language,
'cause we do mostly tentative programming,
and when we couldn't communicate,
it became complicated.
So yeah, we're nowhere near
done with what we're doing,
but part of this is finding other people
who wanna contribute, add more encodings,
and to find out what's missing,
but right now as a drop-in replacement,
we think we've covered most of that.
- We've improved on the
current situation of C++,
but thank you very much for your feedback.
- Wonderful feedback.
- Helps us know that we're going
in a good direction, I think. (laughs)
Any other questions?
- Okay.
Well, we appreciate it.
If you think of questions,
we're here all week,
and we're online, and thank
you so much for coming.
(audience applauding)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>