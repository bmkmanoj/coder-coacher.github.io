<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2014: Marshall Clow &quot;Hardening Your Code&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2014: Marshall Clow &quot;Hardening Your Code&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CppCon 2014: Marshall Clow &quot;Hardening Your Code&quot;</b></h2><h5 class="post__date">2014-10-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cg7uFBmUh_Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I hope everybody's having a great time
my name is Marshall plow I am going to
be talking about hardening your code
today before we get started let's check
couple things phone please mute it if
you have a pug is there anybody in this
room it doesn't have a phone one Wow
anyway if you have questions you know
put up your hand if you can please get
to a microphone and ask it so that the
people the recording will pick it up
if you don't I'll repeat it back this
talk is called hardening your code and
the idea about it is that is that
there's a set of techniques that you can
use to make your code better I'm not
going to be showing you no template
metaprogramming I'm not gonna be showing
really hardly any code at all I'm gonna
be talking about techniques for making
your code better making your code have
left less defects I was talking to
somebody this morning and they gave me a
great analogy this is this is like
brushing your teeth and flossing well
you really know you ought to do it okay
and you don't always do it no at least I
don't and so I'm going to encourage you
to floss and go visit the dentist twice
or twice a year and all those things
many of these things I suggest you're
going to say well yeah I already do
those great I'm hoping that you know if
if you guys are all up on modern
development techniques you'll walk out
of this room in an hour and say wow that
was a waste of time I do all that stuff
hopefully though I got a few things that
you can add to your your regime so let's
start it's a dangerous world out there
okay it's a dangerous world world for
software
Creek Creek maybe I'll stand still there
are active people actively attacking
code basically you people run in
environments you don't control you don't
envision there are there are two billion
cell phones three billion cell phones in
the world
running applications running software
and you can deploy on a huge number if
you write for Android you can run on you
know 500 different models of phone you
know including phones that you've never
seen that you don't know you don't know
how they work or what they look like
and sadly good methodology is not enough
if we were all perfect and we followed
best practices and all that stuff we
would write code without bugs but you
know everybody makes mistakes
just just in the security area okay
secure communications area in the last
say nine months what have we had
heartbleed good new TLS bugs stretching
back ten years if you you know if you
follow Apple go to fail you know and
none of these were people being
malicious people doing being making
mistakes they the heartbleed thing was a
input you know is an implementation
mistake the go to fail was a failed
merge this these caused a lot of trouble
and the other thing that is we tend to
build big systems these days we have
better tools than we did 20 years ago we
build bigger systems this is hard to
keep all the details in your head and so
people make mistakes they don't consider
things so the question is what can you
do to increase the confidence you have
in your code what is it that you make
your code objectively better and make
you feel like yes your you believe your
code is better and you can demonstrate
that your code is better and I'm going
to talk about several techniques here
and some tools that will help you with
all these techniques okay
so let's just dive right in remember
your history we have a whole class of
tools for this we call the version
control I bring this up not because I
think there are too many people here
we're not doing version control but
every now and then I run into
basis what's version control and it's
like oh please first step right setup a
version control system and use it for
your source code and actually it's
really amazing how many places version
control works really well I have friends
who are web developers that I've kept
them on version control and they can go
back to a previous version of their
their website there I was talking last
night with somebody about a package
called get RC which basically installs a
git repo in /etc RC on your UNIX system
so that every time you make a
configuration change it gets logged and
it gets put in a version control system
I don't know if you guys have spent any
time editing UNIX configuration files
but what I always end up with was dang
this worked an hour ago what did I
change to break it anyway
version control lets you get back to go
back in time to where you were an hour
ago a week ago a year ago
it lets you try things and say oh I
didn't work out and roll back yes you
remember remember how you got to what
you go back and look at look at your
history and your comments about that and
you can remember releases there's a lot
of version control systems out there
right the popular ones these days are
get your curl subversion there's a whole
bunch of other ones I'm not going to say
they're all the same cuz they're not
each of them has different sets of
advantages but frankly the differences
between all the version control systems
pale between the difference between
having vendors and control I'm not
having version control so to a to a
first approximation any of them is is
good they're all better way better than
none
but you know do a little research pick a
good one okay war story this is not one
of my war stories this is from a blog
from Eric Raymond blog people are I
don't know people were familiar with
Raymond he's been doing open sort
for a long long time and acting as an
advocate this is a blog actually the
came up a blog entry came out like two
weeks ago he was working on a chunk of
software and it stopped working you know
some of his tests were failing okay and
he said okay well let's just revert my
last change tests were still failing and
the problem was was that that that the
failures were condition condition alized
on a particular set of input data you
know that and he hadn't been using that
input data before which was why the
tests had been passing up into a certain
point and so he said Oh reverted back to
his last release and tested and they
asked he was like oh good so now it's
like okay my users are okay I know this
bug isn't in the last revision that I
shipped to them now I just have to
figure out what it is and he used git
bisect how many people here have used
git bisect there we go a fair amount
like maybe so basically what git bisect
does is you give it a test
you know that's script a program and say
this is how we tell if the bug exists
and you say at this revision in my
source control history this passed this
revision it failed and git bisect will
automatically do what you would think do
manually right go to the revision in the
middle check it out run the test did it
pass oh good then move forward and tell
it fails move backwards until it fails
but you know I'm just kind of a rude bit
says right here this commit this change
was the one that caused this test to
start failing and at that point you know
finding it is is much much easier you're
not looking at you know two weeks worth
of changes or something you're looking
at one small change
supposedly slight
I'm sorry long as you don't have a
dependency outside the version control
system yes but the point is is that if
you don't have a version control system
and you run into this problem you're
pretty much screwed okay you you you you
go and you get the tar archive of your
last release and you try it and you say
oh good it passes and then you look at
your current source code and you say
you're in for a night of debugging
trying to find out what's wrong and you
will find it but it's much much harder
than it would be otherwise okay
automated tests yeah automated tests
have a test suite run it off and add to
it whenever you can this is you know to
me this is just like so amazingly useful
it's that it's uncontroversial and yet I
run into people who don't have testers
the cool thing about how about automated
tests is that you you know you have
confidence in your code you say okay I
didn't break anything every change you
want to you will run the test suite
before you check anything in if you're
really if your test suite was running
fast enough you can make a simple change
and run the test suite because simple
change where the test suite and you
never get very far off of good you know
the if you talk to the test-driven
development people what their suggestion
is for doing development is write a test
watch it fail write some functionality
you know write a test that shows you
have missing functionality watch it fail
write the functionality run the test
watch it pass I I find that hard to do
for new new functionality but
it's really good for when you have a
fairly stable codebase and then you're
fixing bugs and so on so have hmm seeing
this a lot but but I don't have a test
as test suite and it sounds like a lot
of work and the answer is yeah it is a
lot of work writing a lot of tests this
is hard
I mean it's they're not hard in general
they're not hard but writing tests is a
lot of work okay
true but like a version control system
having some tests is better than having
no tests having more tests is better
than having some tests the goal is do
you want it you want to have a test
suite that is complete so you can start
small write a test okay pick some place
in your code some functional in your
code that you're worried about whether
or not it works correctly
write a test write another test add to
it if you're sitting in a boarding
meeting and the presenter is droning on
about stuff you already know about can't
answer write a test it's a and you know
just think about what part of you what
part of your code makes you feel
uncomfortable like you're not really
sure about it right your test to test
that party thing okay what kind of
things should you test you want to test
normal operations all right you want to
have confidence that when you call your
code is called with sane inputs it does
what you expect edge cases in places
that you want that you want to you think
this is a little tricky okay
error conditions you know you want your
code to return errors in some cases now
really error conditions that's a hole
with no bottom you could spend the rest
of your life writing tests to test error
conditions okay so you know you got to
use some judgment there what are things
that go so an example right suppose you
have a sort routine okay you have a
server tape
what kind of tests do you want about
that you should you know pick an
unordered data set and sort it and
verify that the result is sorted right
pick an already sorted data set make
sure that it sorts pick a data set
that's in reverse order
make sure it's sort a data set where
everything is equal right pick an empty
data set could they say it with one
element in big data set with two
elements in it you know maybe hours of
two depending on the algorithm using
powers of two plus or minus one you get
the idea I mean the idea is just to make
sure that it's a robust piece of code
okay what's next
somebody reports a bug to you what do
you do you write a test okay
this is this is where I am completely
behind the tester for development people
write a test watch it fail fix the bug
watch it run the test watch it pass now
what does just happen you you know you
fix the bug because you watch the test
pass you add the test to your test suite
that bugs never coming back or actually
let me rephrase that if that bug comes
back the test will fail and you'll know
it he won't get bug reports from the
field I thought you fixed this bug and
you go and look and somehow it's due to
you know somebody making a change over
it or something it's come back right
yeah we were talking about that
beforehand yeah sometimes you find
somebody was saying that they tried to
augment a test and they added it and it
wasn't failing it started failing it
turns out that yeah the test
the test was testing the wrong thing or
it wasn't getting run or something like
that okay but again the the idea is that
this is a test testing infrastructure
testing suite is not something that's
really ever done on the other hand it's
not something you have to work on all
the time right as you add new
functionality you want new tests all
right why are they important that gave
you confidence
they give you ability to change your
code without worrying without fear I've
worked in several places which I which
practice what I call fear based
programming oh we can't change that it
might break something
anybody ever ever hear that from people
from your managers yeah
oh no if you if you have a test suite
that you're confident in the answer is
yes I can change that and I can run the
test and I can be confident that I
haven't broken anything how do you get
confident in your test suite and the
answer to that is you you try to write
tests that cover all the functionality
of your software how can you be
confident that you've succeeded happy
how do you be confident that your code
is good enough to ship yeah I mean you
guessed okay you you assert that it's
good enough to ship and this is a this
is the same kind of thing you know you
you have to make a judgement that your
your test suite are good enough are
comprehensive enough I guess is a better
word than good enough there are code
coverage tools that will tell you that
that your test suite covers that covers
a some percentage ninety nine percent
ninety eight percent ninety nine ninety
seven percent whatever and that helps
you feel that you have covered a lot of
your of your your code I tend to go more
as a functionality based thing as you
know all of the functions are tested but
then again I work on a standard library
implementation I have a thousand page
specification that says exactly how
things are supposed to be behaved you
know this is almost an ideal case for a
test suite because I can look at the
specification and write the tests other
times not so much I have a heat comment
here about enables refactoring right
refactoring is what
the ability to change the implementation
and the structure of your code base
without changing the functionality how
do you test that you don't change the
functionality you run your test suite
you had a question your tests should be
yes your tests better be simpler than
your code yes I agree and disagree
because what you really want to have in
my opinion is you want to have lots of
simple tests and the tests in in the
aggregate may actually be more
complicated than your code may be
certainly may be larger than your code
but each individual tests small and
simple yes we could go I could go on for
quite a while about refactoring Martha
quick question comment actually did the
one thing that's I've recently come and
to really love this and the one thing
that's given me confidence in my tests
is that they break a lot and that that
that feels good because I found
something the other thing that I really
like is when I break a test but the test
was wrong because I I realized I really
did change the semantics of something
through a feature and it satisfies me to
see the precise tests that break that
are the ones that you would expect to
break and I felt great when that have it
yes yeah that's that's a really nice
feeling when you you know you you change
change something in the chest fail
because you changed it but you changed
it on purpose and then you have to go
fix it you have to go update your test
not fix your test
update your test the other thing is in
an ideal world right which we all live
in right this is a great ideal world
your tests are your release criteria if
it passes all your tests your code is
good enough to ship that's hard to get
to okay I know a few projects that work
that way that if if it passes all it
passes the automated tests then it's
good enough
absolutely the comment is that it's
easier with a library rather than an
application and I'm absolutely correct
you are 100% correct you know when you
have to do you know user interface and
interaction like that it's a lot harder
than automated test okay
passing leaving tests aside compiler
workings okay what one time it my
current job I was working with a another
group and they handed me a chunk of code
that they wanted to be augmented so I
tried to build it and it came up with
like 180 compiler warnings and I said
hey what's up with these compiler
warnings they said um they're just
warning sync are them no no no
who cares about compiler words I do
you should the compiler is telling you
that there's something here that looks
odd okay compilers are not perfect and
again in our ideal world compilers would
be perfect they'd only warn on they
wouldn't actually have warnings they'd
have errors but any case if you have
right so you you build your program
right and you make a change and you
build your program again and the first
time it had a hundred warnings and the
second time it had 101 warnings what's
the odds of you actually picking that
warning that new warning out pretty much
nil but if you build it the first time
it has no warnings and you build the
second time it has one you say oh I got
a new warning let's go see what's up
with that so it's really hard to find
anyone if you have a lot Thai example
right unsigned takes an unsigned if who
is greater than zero return who
otherwise return one two three
most modern compilers will warn on this
they'll give you something like warning
comparison of unsigned expression
greater than is always true why because
unsigned numbers are always greater than
or equal to zero okay
this code is not incorrect
it's perfectly valid in this case C code
compiler is happy to generate code for
it it's just the person who wrote this
code probably didn't mean that they
didn't mean to write if true return food
else return 123 the compiler is telling
you something's going on something looks
wonky here okay so here's a here's a
trivia question right what is the
difference between greater than 0 and
not equal to 0 if you're dealing with
unsigned types I heard it down here the
answer is nothing at all greater than 0
and not equal to 0 it's a it's the exact
the exact same set of values are true
and false for that ok
the compiler made actually generate a
different instruction it may generate a
not equal instruction rather than and it
verses a greater than instruction but
the results are always the same so
here's a case where the compiler is
telling you that there's just I I don't
think this is what you meant to say that
word you keep using that word I don't
think it means what do you think it does
anyway you can test with two different
compilers three different compilers
because different compilers have
different implementations they warn on
different things and you get a lot a lot
wider coverage with multiple compilers
that being said staying at zero warnings
with every on multiple compilers can be
hard because sometimes they if they
weren't on different things and you you
might have to do some some refactoring
of your code to get it into a state
where everybody's happy with it you have
to decide if that's worth it ok
sometimes compilers are just flat-out
wrong about warnings ok here's a long
blurb of text this was written by a
friend of mine private mailing list
talking about his work at on
large product that you have certainly
heard of put on by a large company in
the Bay Area that whose buildings you
have almost certainly flown over if you
flown into San Jose big green buildings
just down by the airport anyway but
we're not saying him and we're not
saying what product anyway said when he
started working on is this product the
full bill get thousands of errors and he
in in one of his co-workers spent what a
year or two in their spare time just
looking at warnings every time they went
into a source file and it built with
warnings they said okay we're gonna get
rid of the warnings in this source file
he said it took two years okay but they
have and and they have data on you know
bug reports from the field and crash it
logs and so on and they found that the
amount of crash crashes and bug reports
has gone down significantly since
they've done this correlation is not
causally right but that's the way to bet
okay these two are probably related he
said it took you know part time work a
couple years but now they're at zero and
staying at zero here you go that at the
bottom staying at zero is way easier
than getting to zero because warnings
don't just appear right people make
changes and they introduce new warnings
anyway okay let's talk about static
analysis static analysis is is a
basically a way of reasoning about your
program automated reasoning about your
program in an attempt to find bugs and
basically the way it works is that you
take a a program you replace your
compiler with a static analysis tool it
builds some kind of representation of
your
program and then it reasons about it it
tries to prove things about there are
lots there are several commercial
products that the three large ones that
I know about are called clockwork and
fortify and Coverity there are several
open source implementations clang has
one built in Visual Studio not
open-source but they have the static
analyzer there are other ones but they
all work in a similar manner here's
another example okay we have function
one that returns a string yeah it should
be constant then that line was too long
for the slide so I took the constant
just okay and then we have thing that
call sterling on this and you say when
calls get string of X okay
most static analyzers will pop up on
this and they will say what will they
say they say we'll say this string which
is passed to Len here that you got from
get string it could be no and you can't
call null on sterling you let me try
that again
you can't pass null to sterling okay and
and it's really nice when it says look
you have a failure path in this code the
other thing that static analyzers will
do is is local reasoning they will show
you your function that is don't say this
log and they say if you take this if and
get false branch of this F and this F
and you get to right here and you use
this local variable which you never
initialize because you initialized it
conditionally in some places and you
missed one path those are great things
so I like static analysis tools I like
the idea of static analysis tools
actually more than I like the
implementation of most static analysis
tools there are heavyweight tools the
the commercial ones are what I our
enterprise tools and my definition of
enterprise tool is when you try to find
out how much they cost you get a message
a salesman will call you
but they're expensive to run they are
they they take a lot of CPU time okay
they think hard about your program
noticeably slower than a compiler and
they tend to have false positive rates
high false positive rates because they
have because their reasoning about the
program and they do it at not at run
time so they don't have information
about you know what inputs you get and
so on they have to reason a priori about
how the code is structured that being
said they do find a lot of bugs dynamic
analysis okay dynamic analysis lets you
basically build an instrument they're
instrumented version of your program you
said you never ship ok so you don't
worry about lots of things about it but
you you build it and then run your tests
run tests whether your your automated
test suite some other tests whatever and
report when things go wrong okay real
simple example right you build with
assertions enabled that's an
instrumented version of your program
it's got assertions in it and when one
of your assertions fires you say oh I
have a misunderstanding you know
something's wrong here whether it be the
assertion is wrong ok or I when I wrote
this code I didn't understand the
problem or I made a coding error or
something like that that's an example of
you know dynamic analysis or just
testing debug mode you know lots of
libraries lots of compilers tools have
debug mode that add extra checking in
there these are all good for finding
things again the key is that you don't
ship these right these are for use for
you internally now Microsoft has a debug
version of the C++ standard library
that's very helpful here
sanitizers Kostya his butt gave a talk
yesterday about sanitizers and I'll talk
basically the way the sanitizers work is
that they're usually implemented by the
compiler vendor you build an
instrumented version of your program
they insert calls and checks into your
program and then you you run your tests
and they go off
there are as far as I know there are
four at the moment probably more to be
planned address sanitizers are undefined
behavior sanitizers and memory sanitizer
thread sanitizer
Andras sanitizers first shipped as part
of LVM 3:3 and GCC for 8 mu B San the
undefined sanitizer as part of LOM 3/4
and GCC for 9 and M sin and T sin or
part of ileum 3 4 but are still
experimental I believe so
the goals for the sanitizers are that
they have very few false positives goal
is none okay that every time something
goes off in a sanitizer it it is a real
bug it's that it is and it can report a
miss behavior as it happens when it
happens rather than the static analyzers
which aren't you know do things are are
doing things in an abstract sense
they're they're examining the code and
thinking about what could happen when it
was run because it's HAP this does run
time you get you can get stat crawls and
things like that which is really nice
for finding exactly what where things
went wrong ok I'm using address
sanitizer basically the way you use it
as you build your program with - F
sanitize equals address and it gets
passed both to the compiler and the
linker I ran this on this is a this
first link here is a deployment report I
ran this
on the lib C++ test suite about a year
ago excuse me it's a year and a half ago
now and Lib t-posts s suite at the time
was about 4,300 tests and it found three
bugs they also uncovered a limitation in
address sanitizer but that's something
else found three bugs I mean there were
more than that more than three instances
of address sanitizer going off but it
turned out to be three bugs there was
one bug in the library that manifested
itself probably a dozen times it was a
bug that we would never have found
otherwise because there was a case where
the i/o streams code was allocating a
zero byte buffer when you created a
straight and then under some
circumstances would write a single bite
into that buffer okay on the test system
on Mac OS the minimum allocation is 16
bytes it was harmless okay
it did not corrupt anything it didn't
you know it didn't cause a problem when
you wrote the second byte to the stream
the buffer got reallocated to a
reasonable size and so you'd never
actually see it wouldn't cause any
problems on Mac OS on the test system
but if you ever moved it to another
system web C++ is supposed to be
portable and you move it to another
system where you had the underlying
memory allocator has a different
behavior you get memory corruption you
get you get crashes so it was great to
find this and Aysen just picked it right
up and said right here this is the
problem we also found two bugs in the
test code and that's some that's a point
that I want to make that sometimes you
have to worry about bugs in your test
code the bugs in the test code were of
the form of you know passing passing a
set of data into in this case it was
into some random number generator our
passing a set of addresses to write
random numbers and it was the start of
the array and to past the end of the
array it said
one past the end of the race there was
that plus one there that shouldn't have
been there
anyway really really nice you know again
where I said early on how do you
increase the confidence in your code
doing this exercise not only fixed a
couple bugs but gave me a lot of
confidence about the limb C++ code it
just made me made me feel that they that
the Lib C++ code was at the base was
really solid and written by somebody who
really really was concerned about
correctness and I can say that because I
didn't write most of it I don't know if
Howard is here but he did a great job
also if you the link at the bottom is an
announcement from the Mozilla Security
Bulletin and it talks about some remote
code exploits that that they had found
in Mozilla and basically credits the
Google security team and address
sanitizer for finding them address
sanitizer has been a boon to people
writing web browsers because frankly web
browsers have pretty much an unbounded
input space you know you can send almost
anything to a web browser and people do
and if you run it with address sanitizer
enabled you know you can find out
immediately if you write off the end of
an array or you get a use after free or
you double delete something or that
sounds like a toothpaste ad from what I
was getting three hundred five dentists
recommend three only three out of five
browsers use it but I would guess that
that the Internet Explorer people do not
because I don't think a SAN is has been
available on Windows for very long or
even if it is available yet I know the
chrome people do and I know this is this
was a Mozilla thing I know that Mozilla
people do and and the Safari people do
yeah
the WebKit browsers or the blink rates
browsers tend to do that but I don't
think that that it's really I don't
think it's a function of what web
library use it just happens to work out
that way yes
Kostya I mean how many people went to
cause just talk yesterday about the
sanitizers okay
about 40% I'm gonna keep talking about
the sanitizers that if everybody had
gone I could skip some of this undefined
behavior sanitizer okay I have another
talk about undefined behavior and the
perils that it can lead to but you know
I only got 20 more minutes and that's an
hour talk so we're not going to go there
needless to say that the C and C++ live
languages have a definition of undefined
behavior and compilers know this and
they make code generation decisions
based on your code basically they can
assume in many cases that undefined
behavior won't happen because you know
if it does it's undefined behavior it's
not wrong okay am i undefined behavior
talk I spend a bunch of time pointing
out that once you have undefined
behavior there are no wrong answers
there's nothing you know you can't say
my program is misbehaving because you
have undefined behavior there's no
there's no correct behavior but anyway
so these are some examples on behind
behavior signed integer overflow
unsigned integer overflow actually is
defined behavior but signed integer
overflow in directing through no
indexing off the arrange of the ends of
array there's a whole bunch of other
things but and john Waco's touched on
this in his talk on wednesday on when he
sold my neighborhood but that's okay
anyway you beasts and catches a lot of
these the language based undefined
behavior and it tells you exactly where
it was this was my favorite was load of
you one-two-three which is not a good
value for type pool
yeah and you look at that and you say
yeah
why would that boolean B have a value of
123 oh yeah it's just wrong and then you
have then you go and fix it
yeah index 40 out of bounds for array of
type bubble 10 really nice - anyway I
ran this on the loop C++ test loop C++
and this is the blog entry talking about
the results this about a year ago I need
to go back and run through it again and
see if I've introduced any more bugs but
it finds all sorts of interesting things
okay I'm not going to talk about MCN and
TC n because I haven't used them but if
you're doing a lot of threading code and
you're on a system that T San supports
it will help you find race conditions
and MEMS and helps you find reads of
uninitialized memory which is
technically undefined behavior but okay
buzzing fuzzing is a technique that has
come into popularity in the last few
years in especially in the security
arena it's basically you take it's a way
of automated testing for systems when
the problem space is very large or you
have you're not really sure how to how
to comprehensively test your system it
basically you take a sample input to
your program and then you mutate it
according to some criteria and you
change it to be not quite valid or
invalid it's a ways and usually you end
up with thousands or hundreds of
thousands of test cases because the idea
is you're trying to generate some kind
of coverage and then you feed them into
your program and wait for it to miss be
there's a link here for talking of
talking about doing this this this is
again a great thing for browsers okay
because the inputs for browsers are
fundamentally unbounded and and there
are a lot of browser manufacturers out
there doing this the nice thing about
oops wrong the nice thing about dynamic
analysis and the sanitizers is they work
really well with fuzzing because pick a
SAN okay
because a SAN goes off immediately when
your program misbehaves you can you can
generate a bunch of fuzz tests and feed
it to your system and find out
immediately when something goes wrong if
you don't have something like a
sanitizer or a debug build or something
like that frequently you what you're
looking for is you're looking for your
program to crash or give wrong answers
and if it does that then do you have to
go investigate but if you have an
instrumented thing whether with a
sanitizer or debug build or somewhere
that it can point it just right here an
assertion went off or a SAN fired or you
be Sam fired or whatever you say oh I
know exactly where something is wrong
something that something has gone badly
wrong right here and then you cut your
debugging by 90% 95% 99% which is great
okay okay wrapping up all these things
you can start to small
well the static analysis stuff it tends
to be a big have a big startup home and
source control pretty much it's all or
nothing or you you should be using
source control okay you should be going
to the dentist every six months right
you'll be using source control test
tests you know start small if you think
you look at the test say okay I want to
have a test suite you look at it you
think about it you realize this is a
daunting task
don't get discouraged start take another
step gentleman right here in the green
shirt he's writing a test because he
knows all this I'm kidding but the point
is is that you can you can start small
and just keep going okay and a test
suite really is not a get it done kind
of thing it's a it's good to you know
have a good one today make it better
tomorrow and so on the dynamic analysis
stuff just you know you can that what I
do is I run the test suite for loop C++
every night my machine back at work
wakes up at midnight and runs runs the
tests eight ways it runs it 32-bit
64-bit times three C++ code three C++ 11
C+ was 14 it runs it with UV sanitizer
enabled it runs with address sanitizer
enabled and then every morning I you
know and every morning I come in and I
have a summary of the results and I look
I glanced at them and say yep same as
yesterday good no unexpected successes
no unexpected failures that takes you 5
minutes 10 seconds somewhere in between
and then I start off with my work but I
have I have this baseline confidence
every morning that codes in good shape
ok questions can we all come to the mics
Claire is running to the microphones yes
so I'm yep wonderful really really good
stuff really agree just a comment in
terms of putting into practice moving
towards getting people using tests women
because a lot of the later things only
had value if you had good test suite
coverage in the first place and when
you've got a large volume of code that
doesn't have tests understanding how to
introduce them can be really hard and
just something I learned recently was if
people get a really good foundation of
the solid principles of object-oriented
design and there's a brilliant few our
Pluralsight course on
it shows examples of refactoring to get
rid of concrete classes lay down and I
suspect that's probably obvious to a lot
of people here but if there's anyone
you're working with it doesn't know that
for me that gets people over a really
really large part hurdle of where do I
start
it just made so much stuff make sense
from which then you can start its an
enabler really to start actually adding
the test okay so I'll take a look at the
plural site course also you know out
here in the bookstore there's a book
Martin Fowler book called working with
legacy code okay the interest the most
interesting part about that book for me
was in like chapter 4 where he puts down
his definition of legacy code his
definition of legacy code is code
without tests because you're deep into
as I said fear based programming them I
can't change it it might break Casta
thanks for the Tizen fuzzing and dynamic
tools mix it's really amazing how it how
efficient it is and I want to recommend
the secret sauce to this pair which is
code coverage what my colleagues at
Google found that if you add code
coverage feedback to fuzzy it gives like
two times more bugs to you you you run
the father with dynamic tool and with
coverage and if a newly generated test
has some new coverage like it goes into
a new part of your program you add this
test back to the main corpus of tests
and that is like a positive feedback or
genetic algorithm to find any bugs
whatever use code coverage the question
was what code coverage tool the is my
colleagues are using code coverage tool
built into address sanitizer but you can
feel free to use any any to okay thank
you that's a great idea I need to try
that now
yeah the discussion earlier about how do
you get the confidence in your test
suite one comment on that regard is as
you said whatever your release criteria
is presumably you have some
if your test suite is working well your
release criteria should never find
anything else right so as you start
finding things in your release QA
pulling those back into lower tiers of
testing is always valuable we even do
this in LLVM in terms of like we have
nightly tests week that take ages to run
oh they found a failure okay add that to
our fast regression test suite by making
an arrow or example the kicker and I
don't know whether you've played with
this Marshall I haven't but I keep
hearing about it
mutation testing the idea we could build
something like build it into a low VM
where it mutates your conditions in your
program completely breaking the program
okay and if your tests find it they're
good this helps you get things better
than say code coverage interesting code
coverage only tells you the code ran it
doesn't tell you did the right thing it
doesn't tell you that you actually
examined the output so mutation testing
is a way to test your tests I have not
seen coverage seems to be a hot topic
yeah in my experience I found a cute
pissy remark about it it can tell you
how badly you're doing mm-hmm it can't
tell you how well you're doing okay
because all it tells you is you hit that
function or that line of code at least
once
mm-hmm but your code has this huge
combinatorial complexity of has you can
take so I've found that it's really good
at finding holes in my test coverage but
once your code coverage gets up there
doesn't tell you that you're really
doing a good job right okay good point
thank you the one tool you didn't
mention was continuous integration build
systems I think once you've got a test
suite and sanitizers and stuff like that
and you're using multiple compilers I
think at that point you kind of need a
CI system just to keep track of
everything um I do not disagree with
that but I didn't want to talk about
this here because really that well not
even that not even that it's a whole
nother talk but it is is more that the
things that I have here are things that
you can start as an individual in your
company okay you can you can and a
continuous integration set up kind of
you end up with a lot of over a lot of
infrastructure gets built and I like
continuous integration so the LVM
project for example has a bunch of build
bots that basically spend their entire
day looking that says check in great I'm
gonna start I'm gonna build I'm gonna
run the test suite and then I'm gonna
black the results into an IRC Channel
and blame the person who who just
checked something in because something
failed but I like those but they're a
lot harder to set up then adding
starting dad tests or adding some more
tests so Marshall you mentioned
fear-based programming which which I
have participated in and and what I
found is that unit testing is actually
an excellent excellent way to overcome
the problem that when I faced something
that has no tests I've been afraid to to
refactor it an excellent way to start on
the problem both to understand what it
is you're about to refactor and to have
confidence in the results is to start
out by writing a bunch of tests for this
thing in the process of writing the
tests you understand what it is you're
you're trying to work on and once you do
your refactoring you can have some
confidence that you probably didn't
break most out of it yep a great point
you know writing tests increases your
understanding of the problem you're
trying to solve
absolutely now had two jobs where my
first task was we have all these
compiler warnings get rid of them a it
is a nice way to touch all over the
codebase and start getting a feel for
where all the code is but it is several
orders of magnitude harder to solve them
solve the warnings that someone else
introduced because you don't know what
they want they actually wanted it to yes
it's true the compiler is telling you
I'm you know this is something odd here
and you end up with what does this code
to be doing right yes yes right and I
did not actually mention that in the
section on on the source control system
but yes modern source control systems
have have an ability to you know go down
to the line and say who checked this
code in and yeah it's usually called
blame who you know SVN blame get blame
you can look and say who checked this
chunk of code Ian and when did they
check it in it's like oh look at the
loop C++ code Oh Howard check this in
four years ago mm-hmm well it's probably
right but but yeah and and when I talked
when I had the thing about about getting
rid of warnings I mean seriously
my friend will call him Dave because you
know every Tom Dick and Harry is named
Dave the calling Dave he'd spent a
couple years of this and it worked well
for him when you when you got rid of all
the warnings did you feel that the code
was better do you have any objective
evidence that the code was more reliable
smaller had fewer bugs any of that stuff
okay
yes yeah good stuff Marshall one other
piece of this that I would bring up it's
sort of correlative to the fuzzing is
doing test randomization especially if
you have big Suites of google tests
basically you know we we have a job a
nightly job in our CI system that
basically randomized us all the seeds
into the Google tests okay and it finds
there you go so yeah introducing you
know making your tests
non-deterministically you know if you
can randomize the tests and still
determine that you get the right answers
okay any other questions
comment about compiler warnings even if
your project is completely warning free
at some point this is a constant fight
because compiler vendors
keep adding you nice warnings and this
is the endless war never play events but
you know what the thing is is that that
you hopefully your code quality is
trending upwards and that's really my
takeaway is for all these techniques you
want to get you know you want to get the
trend lines going up that you have your
code is getting better the number of
bugs is going down and you know you feel
better next week about your code than
you did today
next month better than next week next
year better than next month so so I hear
I have actually a little bit of code
that talking about getting rid of
warnings this is a chunk of code that
that I wrote for post it's real simple
it takes a a some value type and turns
it into a number it's supposed to be a
character 0 through 9 A through F okay
real simple code I cast it to a
character I check 0 the 9 a through f
some compiler we won't say which one
said who warned on this code control
reaches end of non-void function ok
pilot was wrong there's no way to pull
off the end of this function ok it's
return return return throw but so the
compiler was warning on this and I
wanted to get rid of the warnings so I
simplify returns here and that shut up
the compiler ok but you know what some
other compiler said you've got
unreachable code fine okay a little more
refactoring you know they this generates
basically the same code if you tranq up
the optimization the compiler puts the
return value into register and really
there's there's
not any difference between the first one
and this one in terms of code quality
but this is just as just as clear easy
to read and there are no warnings in
this on any of the compilers okay
I would have preferred the first one
okay I thought the first one was
perfectly clear but actually no because
because because the compiler actually
reduces this down to pretty much the
same code as the first one the
difference the difference is that the
difference is it o 0 and the difference
is in the source code but a narrowing
error on the oh you're right yeah it
should be on it should be on sign care
the thing is though is is is it's only
returning 0 through 0 through 15 you're
right it shouldn't be on send care good
but the compiler the original compiler
the compiler that was wrong
was still complaining even if it was an
old version of GCC anyway so yeah so
everybody go out there brush your teeth
floss go to the dentist right and apply
that principle to your code
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>