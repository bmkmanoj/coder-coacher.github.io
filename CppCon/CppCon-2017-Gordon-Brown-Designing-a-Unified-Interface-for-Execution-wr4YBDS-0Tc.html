<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: Gordon Brown “Designing a Unified Interface for Execution” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: Gordon Brown “Designing a Unified Interface for Execution” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: Gordon Brown “Designing a Unified Interface for Execution”</b></h2><h5 class="post__date">2017-10-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wr4YBDS-0Tc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Hi everyone, thank you
very much for coming.
My name is Gordon Brown,
I'm a Senior Software
Engineer at Codeplay Software
and I'm going to be talking to you today
about designing a unified
interface for execution.
The talk lasts for about 45 minutes
so there should be plenty of times
for questions at the end.
First of all the usual disclaimers,
the slides that I'm presenting today
are contributed by myself as
well as others at Codeplay
as well as those in standards bodies
such as Khronos, C++
and any views represented in the slides
are those of me and myself
and not necessarily those of Codeplay.
So who are Codeplay?
So Codeplay are a small
tech company in Scotland.
We develop heterogeneous
computer solutions
for semiconductors so we build
compilers, debuggers, run times
and other tools for
heterogeneous architectures,
just GPUs and DSPs.
We do this based this on open standards
like OpenCL, SYCL and Vulkan.
We target a range of different industries,
like automotive, safety
critical, machine learning.
So a little bit about myself.
I've been with Codeplay
for about five years now.
During that time I've been working
on something called ComputeCPP.
This is our implementation of SYCL
so SYCL is an open standard for
C++ program on heterogeneous systems
and I also was also heavily involved
in the contributing to
the standard itself.
Then I was interested in SYCL,
I did a talk last year at CppCon
and will be, there's more
information than that.
In the recent year I've be more involved
in the C++ subgroups for executors
and heterogenous computing and executors,
this is more what I'm gonna
be talking about today.
So a couple of disclaimers before I start.
A proposal that I'm going to present today
is still a work in progress although
we've largely reached a
consensus on the design.
There's always the chance
that things will change
between now and finally making it into C++
and also as I mentioned my background's
in heterogeneous computing.
There's a very diverse range of use cases
that motivated the executors proposal
so I don't claim to be
an expert on all of them
but we'll try to give a
high-level overview of these
and also and finally I wouldn't
be able to stand up here
and present this without all the hard work
that's being done by everyone
in the executor subgroup
as well as those in SG1 and SG14
that have been contributing to this,
this work over the last years.
So the agenda for the talk today,
I'm going to start off
with introducing some,
I will start off with a brief history
of the executors proposal
and show some use cases
for the motivated executors
then I'm going to show the threat
of the overall design
philosophy and how it looks
and then I'll show you some examples
and I'll finish off with
a look at future work
so looking at what we're still working on,
what's still to come.
So first of all what are executors
so the elevator pitch for essentially
for executors is in C++ 17 we have,
we have several control structures now
for executing work,
things like std::invoke,
std::async and parallel algorithms
and traditionally these
these control structures
have always executed sequentially on CPU,
however recently many
implementers have wanted
to take advantage of parallelism,
heterogenous computing, network computing
on a range of different architectures
such as GPUs and ready CPUs,
DSPs and all our accelerators
and this is usually done
up until now with third party APIs
and standards such as like SYCL, OpenCL,
CUDA, HCC for heterogeneous.
OpenMP and MPI for distributed,
some libraries for C++ multi-threading
and things like Boost.asio,
and the Networking TS
for network computing.
Our executors aims to
provide a unified interface
for writing generic code
in order for executing work
that can be implemented on top of all
these different standards and all these
different resources in a standard way
that can be used by all these
different control structures.
So a brief history of the
the executors proposal
so the very first proposal came in 2012
so this was quite far back so this idea
has been going around for a long time now.
Between then and early last year
there have been a large
amount of papers proposed
for executors with many different ideas
and approaches and these kind of sort of
centered on these four
main proposals here.
I won't go into any detail on them
but if you're interested
you can check them out
and these essentially
show the main motivations
and main proposals that
kind of led to what we have
in the proposal I'm showing you today.
Shortly after this, in the early
2016 C++ standards meeting,
the C++ standards
committee decided to form
the executor subgroup
so the aim of this group
was to bring together all
the interested parties
with the different use
cases and tried to come up
with a single unified proposal for this
and this is where where I
got involved in executors
so I was invited to join this group
as the sort of representative
of the open standard
heterogeneous computing use case
and over the last year we've put together
several papers and got a lot
of feedback from the committee
and the recent most recent
papers are these two,
the Unified Executors Proposal for C++.
This is sort of the technical document
that describes the the wording of what
the meat of the proposal
and the design document
is the kind of explanation
of the how we came to
the same design decisions
that we made and sort of some examples
of how you could implement
them, things like that.
So we feel we're getting quite very close
to consensus on the design,
we feel like we're moving very close
to being able to create this executors TS
so the technical
specification for executors
so that's why I'm here
today to present this.
So what is execution?
So the interesting thing about C++
is that the answer to this question
would range greatly
depending on who you ask
so if you ask someone who works
primarily with
multi-threaded applications,
they would say static
or dynamic thread pools,
std:async, launch policies and work
that's executed on standard threads.
If you asked someone
doing network execution,
they would say network
devices things like Boost.asio
or Networking TS, one-way
communication and work tracking.
If you ask someone doing
parallel execution,
they would say things like
the parallel algorithms
vectorization, bulk
execution of multiple threads
and having, channeling our
return value for algorithms.
Now if you were to ask someone that is in
heterogenous or distributed computing
they would look for discrete
non CPU architectures
managed execution
resources and task graphs
so the problem is if
everyone has a different idea
of what execution is, how do we define a
unified interface that works for everyone?
The problem is if everyone just pulls
in favor of one approach,
you never reach a consensus
in its unified design
so essentially we need to find a kind
of a common ground, something
that all these requirements
they have that we can build from.
Essentially that's all of these use cases
require the ability to execute work.
Essentially the idea is being able
to execute a callable object.
This might seem very trivial because you
think C++ is already
capable of executing object.
Well this can serve as
a kind of foundation
in order to build, build
upon in order to provide
this unified interface to give all
the features that everyone needs.
So the first thing that we needed to do
to define executors is to establish
a sort of topology of
execution so we need to define
the various components of execution,
what they are, how they
relate to each other
and the sort of the terminology
for describing execution.
So this starts off with
an instruction stream
so this is what a short moment was,
this callable objects
and an instruction stream
is essentially just any callable object
that can be executed.
Then you have lightweight execution agents
so lightweight execution agents
are essentially any thread of executions.
This could be a standard thread
or it could be any other form of thread
like a GPU thread or anything else.
Essentially a lightweight execution agent
executes instruction stream.
Then you have what's called
an execution function
so an execution function
executes the instruction stream
on one or more lightweight
execution agents
with a particular set of properties.
These properties come from the executor
so executor is essentially
the main component of this,
of the executive proposal.
Essentially this is what describes
where, when and how work is executed
so the executor can spawn one or more
of these light-weight execution agents
through their execution functions
and call each, call in
this instruction stream.
Oops, went ahead a bit.
So next is the execution resource
so the execution resource is essentially
a hardware abstraction, this describes
the underlying resource that
your your work is executing on
so this could be something
like a CPU thread pool
or a GPU context or anything else.
The final component is that kind of brings
everything together is
the execution context
so the execution context
is it does a few things.
Firstly it's essentially an instance of
an execution resource so it
manages an underlying resource
and the next thing it does is
it's responsible for managing all
the lightweight execution agents that
are executing on that resource and then
finally it provides
executors that can be used
to execute work on that resource.
So there's not much to show a long,
I thought I'd show a very
very simple three line example
of the sort of the general idea of this.
Here we have first line,
create an instance of
an execution context.
From that you can use this dot executor,
returns an executor and
execute work on that context
and then from there
execute, this is an example
of an execution function
and inside that function,
we have this lambda object.
This is an instruction stream
and you may notice that the
components I didn't mention,
the execution resource and the
light-weight execution agents
so these aren't represented
as objects in code,
these are more the underlying
resource abstractions,
abstractions of the hardware
that's executing the work
so these aren't represented directly
as objects in code but
they are represented
through properties of your executor
and your execution context.
So next thing we have to do
is once we had this kind of
a topology of how to
describe these execution,
we had to establish what
the different bifurcations
of execution were between
the different use cases
so essentially if you imagine all of
the different possibilities
that executors could have
laid out in a hierarchy, a tree
of different executor types.
This is sort of showing
where the different options
split off so essentially we came up
with three different three
main properties of execution.
These are the sort of the main properties
that describe the semantics of execution.
There's more properties as
well, that I'll get to later on.
These are the main ones.
The first one is cardinality
so this essentially describes whether
an execution function executes
a single execution agent
or multiple execution agents in bulk
so the single cardinality, a use case,
this comes from control structures
such as that std::invoke, std::async
where you want to do task parallelism,
you want to execute a single task once
and you maybe want to synchronize with it.
The bulk cardinality
comes from the use case
of the parallel algorithms
or heterogeneous
distributed computing where want to launch
multiple execution agents in parallel
and maybe paralyze them or vectorize them.
The next property is directionality
so directionality, so this
property essentially describes
whether or not your execution function
provides a channel for
returning a return value
or an exception as well as
synchronizing with the work
so these are called one-way directionality
and two-way directionality.
Essentially this boils
down to whether or not
your execution function returns a future
so the one-way directionality use case,
this came from the Networking
TS where it's important
to be able to do essentially
fire-and-forget execution
where you you launch the work
and the work is handled by the receiver,
you don't necessarily do a synchronize on.
The two-way directionality use case
came from things like std::async,
you used to be able to return a future
or parallel algorithms that need
to have a return values exception
and finally there's the blocking guarantee
so the blocking guarantee
essentially describes
whether or not your
execution function will block
the caller thread on the
execution to complete.
So there's three different options,
there's possibly-blocking, always-blocking
and never-blocking so never-blocking
essentially guarantees
that your execution function
will execute asynchronously
so this means that you,
it'll return immediately
but the work will run
in the background on some other thread.
Always-blocking guarantees
that the function
will block until the work is complete
which means when it returns
from the execute function
the work is already complete.
Possible-blocking is for the case where
you don't necessarily
prefer one or the other
and either is fine so it's the
lower guarantee of the three.
Okay so now that we have
the different properties
that define this or the
semantics of execution,
we need to look at what the
actual execution functions are.
So these are made up of
two of those properties
so you notice that the
blocking semantics property
doesn't change the interface,
it doesn't change the execution function
so only the directionality and
cardinality that does this.
The blocking guarantees
property does change
the semantics of the function.
It just doesn't change the interface
so here we have the
combinations of one-way
and two-way and single and bulk.
There are four execution functions,
execute, two execute bulk
execute and bulk two execute
so you might wonder why there's
four different functions
and we don't just have a single function
that behaves differently
depending on the properties.
There's a few reasons for that.
The first is that they all
have very different semantics.
The second is that they all
take different parameters
and they have different return values
so this was one option
that we were considering,
having a single execute function
that behaved differently
depending on the properties
however it would be very difficult to
provide diagnostics for
when you used it incorrectly
and finally we also want
you to be able to provide,
allow executors to provide
all four execution functions.
In order to do that we ought
to have four unique functions
so I'll give a little example
of what these look like
so first of all this is
the single one-way executor
so you're essentially create an executor
and you call execute and it
takes a single parameter,
it's the instruction stream.
This is executed once.
The next one is single two-way
so this is very similar
to the single way one-way
however here it returns a future.
The future has the return
value or exceptions
and then it can be synchronized with
so here you will notice that
it has the returns of values.
This is because the return
value of the function
is then propagated back to the future.
The next one is bulk one-way
so this one's a little more complicated
so it takes three parameters.
First one is the, this
instruction stream as usual.
I'll get to the parameters of
the lambda there in a moment.
The second parameter is shape so shape
essentially describes the iteration space
that you're gonna execute
your execution agents across
so for example that shape could say
I want to execute this
instruction stream 1000 times
so I'll execute that
1000 times in parallel.
Then shared factory, this is essentially
a function object that returns an instance
of a shareable object,
shareable type and that's
then passed to every iteration
of the the bulk execution as an object
that can be shared between
the execution agents.
This is very important
for particularly for
when you're running in parallel
or for heterogeneous computing,
where this can be
represented by local memory
which is often very much faster to access.
So to go to the parameters
inside the lambda here,
the first one is, sorry, is index.
This is the current index
into the iteration space
defined by shapes so our
shape said we want to execute
across 1000 execution agents
then index would be zero to 999
for each of those iterations
and then S is the instance that's returned
by shared factory, passed by reference,
you can access it and
every execution agent.
Finally you have bulk two-way so again
this is very similar to bulk one-way.
The main difference here is that
there's an additional parameter
article result factory
so because we're launching
multiple execution agents
in parallel, we need to
handle the return value
that's propagated to the
future slightly differently
so the way we do it is the result factory
is very similar to the shared factory,
it returns an instance
of this shareable type.
It is then passed by reference
into the execution function.
- [Audience Member] Is that a typo
that I is going to spelling index
on both (drowned out by coughing)
Yes sorry that is a typo
so the index should be I yep,
I think I shortened the slides
but then forgot to change it.
Thanks.
Sure.
- [Audience Member] Is the
index always the size T
or does that type depend on the data?
Yes so that's a good question, yes
so the shape type and the index type
are actually defined
by the executor itself.
Hey so for this example,
I've used the size T
just to keep it one-dimensional
and keep it simple
but that is defined by the executor
so it could be multi-dimensional.
(audience member speaking off mic)
The future type is also,
that is also defined by
the executor type as well.
So the executor could have its own future
for doing additional things.
- [Audience Member] Are
those lambda capture
absolutely necessary or that's just.
That is just.
- [Audience Member]
Actually use the executor.
Okay so there's actually,
so there's nothing actually
being captured here,
it's just a force of habit I think.
So yeah so essentially the
way the result factory works
is so you pass this similar
to the shared factory,
you pass this instance
into every iteration
of the bulk execution and then you,
the writer of the person who's writing
the actual instruction stream decides how
the return value is decided
so it may be decided
by one particular execution agent
or a result of multiple ones.
Okay so as I mentioned
before there's in addition
to these first three properties,
there's multiple other
properties that we're defining.
The idea of the current
design of executors
is that it's a very policy based interface
so there'll be a set of standard policies
but it's encouraged the implementations
will have their own
properties for doing things
that are more particular to that resource
and that maybe are not so standard.
So here's the current so these,
first of all these are the the properties
that you've seen already.
So a single bulk one-way, two-way
so essentially single, executes
instruction stream once.
Bulk executes it multiple times.
One-way doesn't doesn't return a future
whereas two-way does return a future
for the value or exception
and synchronization
and then you have possibly-blocking,
always-blocking, never-blocking,
so this is may or may not, always or never
blocks the caller thread on
the execution to complete.
So one thing to note about these is
these first four properties
are the only properties
which modify the interface.
This is because they change
the execution functions
that are available
and also because of that these properties
are the only properties
which are additives
so for example if you had an executor
that was single and one-way
and then you requested that it's bulk
so I'll get to customizing
executors shortly.
If you have to request that this
is now a bulk executor it adds that to it
so it's now single one-way and bulk,
the same with if you said
two-way, it would be single.
Two-way, one-way and bulk.
Whereas the other properties
are all mutually exclusive
at least the ones that
we've currently defined
so some of them are for
toggling features on and off,
some of them are for choosing one
of the multiple choices of guarantees.
So the other properties I've
not mentioned so far are these
so I'll go over these quite quickly
so the thread mapping semantics property
essentially describes how the work,
the execution agents are mapped to threads
so the common one would be thread mapping
so essentially means all
of your execution agents
are mapped to a std thread.
Another one is new thread mapping
which essentially means
that every execution agent
will be mapped to a new std thread
so always we launch on a new thread.
Another one we with a set of law guarantee
is the other executions so this allows you
to map to something that's not std threads
so for example a GPU
implementation would use that
because it can't make the same guarantees
that you have with std thread.
The bulk execution
guarantees so these are,
if you're familiar with
the parallel algorithms,
these essentially reflect the,
actually the properties
of the execution policies
so unsequenced, sequenced and parallel
so essentially this is what
this property specifies
so that guarantees the relationship
between the execution agents.
Caller forward progress
so this is a property
that essentially describes
the four progress guarantees
between the caller thread
and the execution agents
that are being launched and
this can be quite important
for guaranteeing when
the function is executed.
A continuation specifies
whether the instruction stream
should be executed as a
continuation of another task.
The future work submission,
it's an interesting one
because this essentially
is more of a hint so this tells
the underlying execution context
that you still have work to submit
even though there's nothing
on the context at the moment
so it can be used so an example
if you have an execution
context that may shut down
at some point, you can use
this to tell execution contacts
don't shut down yet, there's
still more work coming
even though I've not provided it yet.
Yeah so this is, that
properties is more of a hint
because it's quite dependent
on the execution context
and finally there's allocators,
the allocators is a type
that you can specify
that's used for allocating memory
from the instruction stream
if that's necessary
for the implementation.
So next part is now that we
have all these properties
and we have the executors, it's very,
it's very common that users
will want to customize
their executor, they want to request
particular properties of the execution
and it's also quite important
for library implementers
to be able to guarantee certain
properties of the executions.
They may customize the executor further
in order to enforce certain properties.
For example std::async
requires certain properties
so an implementation of std::async
would guarantee certain
properties in order to enforce
what the standard guarantees.
But we'll get to another
example of that later on.
So the way this works is we have three
what are called customization points
so there's require, prefer and query
so the first one require,
so this essentially says is
that you pass it an executor
and a series of properties
and what it will do
is it'll return a new executor that's able
to fulfill those properties.
If it can't do it, then it'll
result in a compile-time error
so this is very important when you want
to make hard compile-time guarantees
that your executor will
do what you want it to do.
Prefer is it slightly different
so the way prefer works
is that it also takes
an executor and a number of properties
but it may or may not return an executor
that can fulfill those properties
so what it essentially does is
if require would succeed, it
would compile, it must do that.
If it doesn't then it is free to return
the original executor as
it is without modifying it.
So this is quite important in the cases
where you want to see you're not,
it's more of a hint or a preference,
you don't necessarily
need those properties
but it would be ideal or in the case
where you may want to
modify the properties
of the executor dynamically.
Finally the query property
so this is when you want
to query the current value of a property
so unlike the other customization points,
this only takes a single
property and an executor
and essentially returns the current value
of that property for that executor
so this can, one
important use case of this
is in, is for after using the prefer
so you can use it to query whether or not
the prefer customization point
gave you the executor with the properties
that you're asking for.
(audience member speaking off mic
Sure, so generally the
idea of prefer is that
it will,
so this one?
Yeah, sorry so the idea is
- [Audience Member] Please
repeat the question first.
Oh yeah sorry, so the question was
he was asking me to
reiterate how prefer works.
(audience member speaking off mic)
So essentially if,
so the way it works is
if require would succeed
so if require would compile,
then prefer is guaranteed
to do the same as require
so essentially it's
like it tries to require
but if it can't it'll return
the original executor.
(audience member speaking off mic)
It'll likely.
- [Audience Member]
That's not on the slide.
There's three cases on each one,
the success team is not (mutters)
Oh sorry, yes
so to reiterate so if it's,
if required would be successful,
it must return what require would
so it would return the
executor with the properties
that you've requested.
However if it's if that wouldn't succeed
then it returns likely
the original executor.
It's unchanged.
- [Audience Member] So it's allowed
to fulfill it's main properties.
Well it would be the
original executor unmodified
so if it can't fulfill the
properties you've asked for,
it would return it unmodified.
And then that's where the one of
the uses of query comes in is that
after you've called prefer you may
or you may not know whether
you got what you asked for
so query can be used to query say,
if I ask for something did I get it?
So I've got an example of that here
so the the first example is of require
so we have a one-way executor
and then we call require with the executor
and the two-way flag
and this returns a new executor type
so essentially this is saying that I want
this executor to provide
two-way semantics,
an executor that returned
because of require.
If this compiles this
is guaranteed to succeed
so then you can call two-way execute
whereas with prefer say we
have possibly-blocking executor
we call, we prefer that
this is never-blocking
so you can say prefer and this may return
an executor type that has those
properties or it may not so
query can be used so if we
have the same example here,
we have possibly-blocking executor
and then we would prefer
it to be never-blocking.
Then we can do a query to say
is this new executor
actually never-blocking
because then that can
be used to maybe change
the schedule or the way
that you are executing.
(audience member speaking off mic)
- [Audience Member] Would
that make the decision better?
So this can be compile-time
but it may not be depending
on the implementation
so some implementations may want it
to be dynamic information.
- [Audience Member] For the
first case for the require.
(audience member speaking off mic)
Yeah so for a require
if it's not able to fulfill the
requirements of the properties
it will fail compiling.
So that's where prefer
can come in so require
is used for when you for when you want to,
when you're able to
determine the semantics
of your executor compile-time
and prefer is more useful,
could be used for when you
want to do it dynamically
so as that could require for,
I've got the next next section covers that
in a little bit more detail.
So the next part is the
last part of the design
is the polymorphic executor,
so the idea of the polymorphic executor
is that these two functions
require and prefer
can either return a static type,
or static executor type or they can return
a dynamic executor type so essentially
a wrapper around an executor.
Now the, first of all,
the polymorphic executor
is required to provide all
four execution functions
so it has to provide the whole interface
because it doesn't, it's dynamic,
it doesn't know which
properties it can fulfill.
So the benefit of this is,
so in this example so
you have a scheduler,
the two-way executor then
here we want to prefer
that this two-way
executor is never-blocking
so here so we still recall prefer
and then we're gonna say new
executor and then we use it
but there's a couple
of problems with this.
The first is that
statically typed executors
can't be stored generically
in a container like this
so for example if you want to modify it
in line, you can't do that.
You always have to return a new type
so essentially if you ever
want to modify the behavior
in an executor you have
to return a new type
and then after that's
used that's discarded
unless it's kept later on.
So the other problem with this is that
if all executive types
were statically typed,
an implementation of prefer
so the result of prefer
would have to be known
at compile-time because you'd have to know
what the return value is,
it would have to be some
static executor type
and this causes a lot of problems for,
this would cause problems
for implementations
where it's important to decide
whether these properties
are supported at runtime.
For example if you're cross-compiling
for another system or
maybe running generic code
that you may not know the architecture
that you're going to be executing on
or the properties of it,
you need to be able to term
that information at runtime
so the way to fix this,
is the polymorphic executor so replace
the two-way executor with
this polymorphic executor
and first of all now this
is a generic executive type
and the polymorphic
executor can be assigned
to and constructed from
any valid executor type
so here rather than
creating a new executor,
we can assign the result of
prefer to the existing executor
so we can modify it in line
and keep that behavior.
Additionally because prefer can now,
rather than returning
a static executor type.
(audience member speaking off mic)
Yeah that's a common implementation
so it'd be type that on the executor tab,
another static executor type inside.
- [Audience Member] So how do
you handle different executors
that have different
functions with signatures.
So the question was how do you handle
different executors with
different signatures
so this is for when you have
the polymorphic executor type
so generally the way this is work
is one thing you can do is
you can query the executor
to say can you provide
these these functions
so there's one thing I don't show here
is that at compile-time
you can query using traits
to see whether or not they're available.
For runtime you can use the
query function for creating.
- [Audience Member] But I
mean the executor is a single.
The polymorphic executor is a single type
so it can only have a
single set of functions.
What is that set?
Yes so the question was it might only
have a subset of the functions.
- [Audience Member] The
question is what functions
does the polymorphic executor have?
So the polymorphic executor has to provide
the whole interface but it
may not support all of them
because the executor inside may
only have certain properties
so in that case if you
called execution function
which isn't supported it would throw
a bad executor exception.
It would say you're trying to do something
with this polymorphic
executor that's not supported.
So the other benefit of having
this polymorphic executor
is that prefer as an implementation
can return the polymorphic
executor which means
it can decide at runtime whether or not
the properties you've asked
for are supported or not.
Those could be really important.
- [Audience Member] About two-way execute,
returns a future.
What is the relationship
between the life times
of the future object
and the executor object?
If the future outlives the executor
and then you call,
dobbed in on the future,
you'd want presumably that task
to be scheduled in the same executor
which may or may not
still be alive, right?
Yep so the question was,
if you have a future type
that outlives the executor
then how, where is that executed
so it's actually a really
interesting question.
This is this is one of the things
that is still quite heavily debated
and this is part of the proposals
in the execution context
so essentially what you would want is
an execution context
underneath which handles
the actual executions so even
if an executor is destroyed
the execution context can
still continue to execute work
so a future would likely
have a handle to the work
associated with the execution context
so it could be something
like a thread pool
so if you execute work on the thread pool,
that future is then tied
to the result of that,
the work on that thread so obviously
if you destroyed the thread pool,
then that would likely throw an exception
of some kind to say you know the,
you're trying to continue
work on something,
a resource that's no longer available.
Generally that's the way
that we would see it working.
So the next part of the talk is,
I'm gonna go over a few examples
of executors and what they would look like
so when I was writing
this I wanted to split it
into three different
sort of target audience.
First of all there's
those who would actually
want to implement executors
so they want to know like
how would you actually write
an executor and execution function.
There are those who implement libraries
that want to use executors
and then there's actually
users who will be using
these executors in
interfaces like std:async
so I'm going to go through
an example of each of those
so the first one is a visual
of a very naive implementation of
an executor with a two-way execute
and I say naive because I have
to keep this implementation
quite short so they'll fit on the slide.
So essentially here we have
the two-way execute function
so it takes a function
object by foreign reference
and returns the result of the function.
The first thing we do is we
have our using declaration
to the return type just
to shorten the code.
we create a std::promise and
then we get a future from it
so this is the future,
the promise that we use
to trigger that the work is complete,
the future that will
return from the function
so that you can synchronize with it.
The next thing we do we spawn a thread,
remove the promise inside
and then we create a try-catch block.
Inside the try we call the
function that's been passed in
and then we take the result
and assign it to the value of the promise.
If there's an exception thrown within,
catch that exception and set
it in the promise as well
and then here we detach the thread
and then return the future.
Obviously as I said this is
a very naive implementation.
You wouldn't want to
detach the thread like that
because essentially the
future that you're returning
is not tied to the thread,
it's actually tied to the promise
so you could run into
situations where technically
the value of the promise has been set
but the thread is actually still being
a context switch and it's
still running somewhere
so it's not a very, this is
a very naive implementation.
It's not very long in
order to fit onto a slide
so essentially what you you'd
want to do is use something,
have spawn a thread onto an
underlying execution context
like a thread pool so this function
would likely have a link
back to its execution context
and use spawn work on that context
and then return the future to it.
So next using that executor,
I'm going to show how we
could implement a std::async
so here's the existing function,
called for std::async.
So this function by foreign reference
and a number of arguments and then returns
the result of that function
called with those arguments.
Now if in order to adapt
this for using executors,
we simply add another parameter
so the first parameter
now becomes an executor
so this now says I want to run
async, std::async but on
this particular executor
so first of all as I mentioned earlier,
certain C++ control structures
such as std::async will
require certain guarantees
of better behavior so here we do a require
to essentially guarantee that this
is a single two-way never-blocking
so that runs asynchronously.
Now the the other overloads of std::async
would involve the launch policies
and these policies can also be managed
by the other properties but this
is the simplest case for now.
So the next thing we do is
we take this new executor
and then we call two-way execute
and then we take the future
and inside that we call the function
forward on the arguments
and then we return the future to that.
Finally if you wanted to use an executor
so if you're just interested
in using executors
for running something like std::async,
here we have a very simple example
doing a factorial
computation using std::async.
In order to use this with executors,
you simply pass the executor.
It's as simple as that.
Say for example you wanted to
use this on another executor
on another device, maybe
even something like a GPU.
Essentially from the interface perspective
it's as simple as that.
So in reality of say if you're running
on something like a GPU,
there's other considerations
to take into account.
There's the performance considerations
of the way you write your code.
There's potentially limitations
about what you can execute
but from an interface perspective,
it's essentially as
simple as just changing
the executor that you use
and then it'll then run on that resource.
Okay, I'm just gonna grab a drink.
The last part of my talk
will be on future work
so this is things that I felt
we're still working on that haven't
quite been solidified yet
but they're kind of a work in progress.
So all of these things are not necessarily
what will be decided on
but this is kind of to give you a preview
of what we're currently thinking.
The first one is the execution
context and resource.
As I mentioned in the current proposal,
this isn't defined in
a great deal of detail
because there's a lot of different kinds
of extra contexts and resources
and it's very difficult to define
the sort of the gap, the lower guarantees,
lower bound guarantees of everything
that they have to provide.
But in the the current proposal
we do provide an example of what
an execution context would look like
so here we have static thread pool
so this provides, has an in line class
for the static thread pool executor
and it provides the
four execution functions
and then you have a function
for returning the executor
and then a detached
stop and wait for managing
the work from the thread pool.
This is just an example
of an execution context,
there'll be many other different
kinds of execution context
for different kind of resources
and they'll all likely
behave very differently and
provide different interfaces.
The next is futures and continuations
so if you remember back to this table
that I showed you with the
different execution functions
so this is this is actually a lie.
There's actually a little more than this.
There is a position to
one-way and two-way,
there's also then
which provides then executes
and bulk then execute
and these are used for adding,
adding continuations on to previous tasks
that have been executed so the reason
that I left this out of the current,
the main part of this presentation
is that this work is very heavily based
on existing work in futures
so there's a lot of work in the committee
about deciding how
futures are going to look
and how they're gonna work
and the different types of futures
and this works very based on that
so we're still debating
how this will look.
To give an example of what
it would look like though,
just if you're interested
so here we have a two-way executor
and we call to execute and return a future
so what we can do with this is instead
of just assigning the future you can then
call dot then execute on this
and then you can call another function.
The way this will work is that the future
that's returned from the first task
will then feed in as a
predicate to the the next task
so when that future is satisfied
the next task will start
so it allows you to chain multiple tasks
together in task graphs.
So this may not be what it
will look in the final thing.
Oops, sorry, there's a question.
- [Audience Member] So linear,
and current CTS feature,
experimental feature has a
member function dot then.
It's not called dot then execute so
it's the relationship between those.
So this is the functions
that would be provided by a
future that supports executors
so this is one of the reasons
why it's still kind of a work in progress.
We need to find a way to
bring these ideas together
so that the executors work seamlessly
with future types that are being defined
in the concurrency TS.
- [Audience Member] So
you're discussing changes
to future to support that.
Yeah.
(audience member speaking off mic)
Yeah so the current futures
that are defined in the executors proposal
don't relate directly to the futures
in the concurrency TS
but we do want them to.
So this is an idea of
what it could look like
but it'll likely take a different look
when that's when it's
finally decided upon.
Next is that for those
of you who are familiar
with the concepts TS,
you might have noticed
that the word require
seems very like requires
and this was probably
there so it does cause
a lot of confusion as to whether or not
require actually is a concept
or whether it uses concept
so although require
does match what we want
the require customization point to do
we're now considering
different alternatives
so into the bike shed where we have
many different ideas for names.
The most popular at the moment
seems to be transform executor
and try transform executor and essentially
describe the fact that
you're transforming executor
into another type or
you're trying to transform
the executor that mean
so prefer would be try transform
because it may transform the executor
or it may return the original
if it's not successful.
This is still being debated,
this is very very recent
like last couple of weeks
so it's not being decided on at all.
- [Audience Member]
What do you guys think?
(audience laughing)
This isn't actually all of them,
it's just the best ones that
I picked out from the the chat
that could fit on the slide
without been too small.
- [Audience Member] Some of the words
on the left adversary.
- [Audience Member] There
is a suspicious lack of past
since you actually returned a different.
(speaking off mic)
Okay so the point was that is,
maybe we should describe as a past tense
because you're returning
a different executor type.
I see.
So you mean for the prefer.
- [Audience Member] I
mean one that transform
instead of transform
'cause they modify it.
(speaking off mic)
That's true.
Well the way the we
we're thinking about it
is that transform reflects the actual,
the act of transforming the executor
but that's a good point,
you could use it to describe
this is the return executor
would be a transformed executor.
- [Audience Member] It
sort of works to sort that.
Yeah, yeah.
Hi.
- [Audience Member] So what would it be
back in your horrible baby policy there.
All terms under prefer are
far too busy with all the
(speaking off mic)
So the point was that the ones on
the right hand side here,
there's the very long and
there a lot of underscores
that are very wordy.
Yeah, sorry.
- [Audience Member] Do I actually want
this to stick out like a sore thumb
because it's doing something
that is potentially rude
and you really want people
to know that's said.
(speaking off mic)
Yes so once we kind of
opened up to different names,
we had a whole lot of different ideas
and names flooded in about
potential different ways
of describing what it was doing.
(laughing)
That could work.
Hi.
(audience member speaking off mic)
Yep so the question was whether
the require function or
whatever would be called
as in won't compile if
the properties aren't,
can't be supported, that's right yeah.
(audience member speaking off mic)
Sorry.
(audience member speaking off mic)
I believe there would be, yeah.
I would believe there would
be a context per interface.
Hi.
- [Audience Member] What's the difference
between require and prefer
on polymorphic executor.
So the question was what's the difference
between require and prefer
on the polymorphic executor
so this is an interesting question
so the require could still
return a polymorphic executor
but the actual calling of the function
has to be resolved at compile-time
but it can still choose to
return a polymorphic executor
if it wants whereas prefer it doesn't have
any requirement to file compile-time.
(audience member speaking off mic)
Yeah so the question was
can the argument to require
also be a polymorphic executor.
It can yeah so you can
have a polymorphic executor
and then require.
- [Audience Member] Perhaps compile time.
Actually no that's a good question.
No yeah I think you're right.
Yeah so I think that's
an interesting question.
I think maybe you wouldn't be able to use
a polymorphic executor as a require
so I think if you're doing
compile-time guarantees
for the property of the executors,
it would have to stay at compile-time.
So the implementation could
return a polymorphic executor
but it's unlikely to
because then you wouldn't
really be able to do much with it.
Yeah so that's a good point yeah.
Thanks.
Yeah.
- [Audience Member] Then that means
that you can't use polymorph
executor (mutters).
Yes so the question is would you be able
to use a polymorphic
executor for std::async.
I think yeah in that
case you wouldn't be able
to use a polymorphic executor
because it would have to be compile-time.
- [Audience Member] You have
some things to work out.
That's an interesting comment
so I'll have to think about that.
Alright.
So the last future work,
the work into is so one type of executor
that you could create
is a one-way executor
that has, that is never-blocking
so in this case you imagine
the way this would work
is it wouldn't return a future
but it would launch
the work asynchronously
which means you're essentially
fire and forgetting about the work
then having no way to synchronize it
so the way this is generally handled
is that you'd have an
execution context in that case
like a thread pool that
would do the synchronization
then we would wait on the result.
However the one thing that doesn't do
is it doesn't cover how
you'd handle exceptions
so in some implementations
you may just want
to drop the exceptions because you don't,
you're not interested in exceptions
within the instructions to units executing
but if you are interested,
the suggested approach that
we're looking at for this
is that the execution
context would provide
a back channel for handling exceptions
so you could use the execution context
to trigger exceptions to be thrown
so this is just an example where,
oops, sorry, wrong button.
So this is an example
what it could look like.
This is just something.
This is kind of similar to what we do in
the secular interface because we do,
we have a one-way execution,
we have to handle
exceptions being thrown back
so this is an example it could look like,
it's not necessarily what you would
choose to implement it like
this, it's one where you could
so essentially here you call execute
on this executor and it throws
an exception from the side.
Obviously there's no future to propagate
the exception to, so that would be caught
and handled by the execution
context in which case
you could then maybe
call something like throw
that would then handle it
as an exception pointer.
Okay so in summary the unified execution,
sorry the unified proposal for executors
essentially means you can
write generic applications
for execute, execution
that target a diverse range
of different resources underneath
with this large amount of customization
and they are coming soon.
Thank you very much.
Should have something left for questions
(audience applause)
(audience member speaking off mic)
Okay so the questions
were how students doing NM
is there a library so there
are some implementations
by those in the executors
group that are working on it.
They're not complete implementations,
they're more for prototyping
so we're a company, we will
hopefully be looking to
just start working on
something at some point,
maybe once it becomes a TS
so there will be
implementations coming soon
particularly after it's
formed an executors TS.
In terms of students, it
depends on how quickly
this goes through the
standards committee I suppose
but we feel we're very close
to consensus on design.
Michael?
(audience member speaking off mic)
- [Audience Member] Either way I think
the implicit answer to your question
is does it have, question
is there a good chance.
(speaking off mic)
Question here.
- [Audience Member] So if I've been in
an earlier version of the proposals
but at one point there was a observation
that a one-way executor could be turned
into a two-way executor by wrapping it
with a future and promise.
What happened to that?
So this is still in the proposal.
Unfortunately I didn't have
enough time to fit examples,
yeah, so originally the proposal does
have this idea of adapting executors
where I didn't have time
to fit this into this talk.
Yes so essentially the idea is that
you can have one executor
that can be adapted
to another executor so maybe
have a one-way executor
that's adapted to a two-way executor
so an implementation of executors
may provide certain execution
functions but not others
so you can, an implementation you choose
to adapt an executor to another type
so when you do have a require,
it'll say I don't natively
support this executor
but I can adapt it and this is something
that can be queried through type traits
for the executor type.
There are still some things
we're trying to figure out
about some of the concerns
about what happens
when you do adaptations like for example
if you adapt a two-way
executor to a one-way,
what happens to the future?
Does it just get dropped or
handles in some other way
so we need to be careful
about how we allow adaptations
so that users don't accidentally choose
to shoot himself in the foot
by doing something they don't expect.
Hi.
- [Audience Member] So I
guess have two questions.
One is that there's executors
in the Networking TS
and have you guys started thinking yet
about how to bring this proposal
and the Networking TS together?
So the question was how does this relate
to the executors in the Networking TS
and if we thought about
bringing them together
so one of the major contributors
to this executor proposal
is Chris Kohlhoff who works
variably on the Networking TS
so the idea as far as I notice
that the Networking TS will be updated to,
to match the proposals in the executors TS
so that will be brought up to date
with what we've been
doing with the executors.
- [Audience Member] And
my other question was
the Code Routines TS.
Obviously execution and code routines,
they intersect I'm sure
in interesting ways.
Has anybody thought about that yet?
So the question was how does executors
relate to code routines and
that is a very good question,
it is something that we've got in minds,
we've not spent too much time on that yet
but it's something we will be looking into
later down the line.
(audience member speaking off mic)
So is the question,
can the instruction should be
running on different resources
so like code for different devices.
That's it.
It's a lot of (mutters)
- [Audience Member] A
modification of this question
that would make more sense
is let's say I submit a lambda
to a GPU resource and
it needs to be compiled
into a different assembly,
can the compiler know that?
Yeah so the question is,
how if you were to say
have the instruction stream
that you want to execute on a GPU,
how would that be handled so the way
this would typically be handled
is that you'd have to
have another compiler
that compiles the code for a GPU
so this would work very similarly to how
for example we have a SYCL
parallel STL implementation
where we do this and essentially
the code that's being executed
and the instruction stream part
has to be compiled with another compiler
that is then linked in with
the the host application
and then lowered onto
some GPU architecture
so it's, if you're using some,
targeting something like
a heterogeneous system
like a GPU it's not as
just straightforward
as just having the client compiler
just compile it and
run in the general case
but if you have a compiler
that can support that GPU
or multiple compiler
reports that can handle
the double compilation then you can do it.
- [Audience Member] Is
there a way to specify
or if you know (drowned
out by coughing) compiling
that specific compiler (mutters).
Are helping you specify
what you want to do.
(speaking off mic)
So the question is how will
it be certain restrictions
if you're executing on different devices
and so the answer is yes
so say for example
you're executing on a GPU
you may not be able to do things
like recursion or dynamic allocation
so the way that that will be handled
is one of the properties that I showed
is this thread mapping
so it could be usually
it'd be, threaded
mapping, thread execution
where you're executing on std threads
but there's another option
where you're actually
executing on non-std threads
so there should be
something used for a GPU
and in that case there's less guarantees
that you can make about
what you're able to do.
Generally an implementation
that supports GPUs
would likely provide additional properties
and additional traits
that can tell you more
about what you're able
to do inside the code.
I think I'm being told.
There's always a time for
any more questions, okay.
Has anyone been waiting?
I think.
- [Audience Member] What will
be the type to resolve that?
So the question, how do you
type erase the executors.
- [Audience Member] That
the GPU is (mutters)
Oh, for the GPU so the way
it would work for GPUs is
it wouldn't be
straightforward to type erase
because you'd have to have
like static executor types
that know that these
are being compiled for
by say a different compiler
so when you're working,
when you want to execute
on something like a GPU
then you would have to have
a specific executor type
that handles those,
the requirements to
compile and execute with
the restrictions on the GPU.
(audience member speaking off mic)
So you mean you couldn't
build to assign it to.
(audience member speaking off mic)
That's a good question.
So I think essentially you would be able
to assign a GPU executor
to the polymorphic executor
but then you may not be able to make,
you maybe not be able to query it
for its capabilities anymore.
That is a good question.
I love to think about that
and I think I'm out of time for questions.
Okay so we've gone over so if anyone
has any other questions,
I'll stay at the front to take questions.
(audience applause)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>