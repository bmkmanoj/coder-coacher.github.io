<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: Marshall Clow “Customizing the Standard Containers” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: Marshall Clow “Customizing the Standard Containers” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: Marshall Clow “Customizing the Standard Containers”</b></h2><h5 class="post__date">2017-11-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NyivAC3WE6g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">My name is Marshall Clow, I
work at Qualcomm in San Diego.
I also work on the standards committee.
I tend to spend most of my time
in the library working group
and I am the maintainer of Lib C++.
The standard library implementation
that ships as part of LLVM.
Hopefully I know a little
bit about this stuff.
All the code that I'm gonna
show you compiled once
before I stuck it on the slides
and dinked with it to fit
so it may have some
trivial like missing comma,
missing semicolons or things
like that but it worked once.
It worked once.
we're gonna talk about customizing
the standard containers.
Now before I start, I gotta ask.
How many people in this
room saw Matt's talk,
Wednesday afternoon about
that high performance hash map
that they did at Google?
Okay.
Setting expectations,
this talk is nothing like that.
(audience laughs)
Nothing like that.
He started with standard unordered set
and then took a sharp left and went out
and did some really amazing things
but I'm gonna start with
standard unordered set
and I'm gonna stay with
standard unordered set.
- [Audience Member] Wow.
I'm going to show you how to make it do
things with your types.
Make it play well with your
types, things like that.
We're not going to invent
a new hash table here,
we're not going to invent a
new kind of red black tree
or anything like that.
We're going to use the
standard containers.
But hopefully I'll show
you ways to do things
that you weren't quite
sure you knew how to do.
Also if you have any questions
just raise your hand and ask
because, don't save them up till the end
because chances are by then,
you'll have lost your train of thought
or I've lost my train of thought
and we won't get as good answer.
Any questions before we begin?
Maybe if I turn this on
it'd be a good thing.
Well what are the standard containers?
There they are, there are 17 of them.
Kind of, well 18 of them kind of.
Why I say kind of, because
string is kind of a container
and kind of not.
And then there are the
three container adapters;
stack and queue and priority queue
which are not really containers,
they add functionality on
top of the other containers.
Disclaimer, that was
not my stomach rumbling.
(audience laughs)
My stomach rumbles it's
loud but not that loud.
By the way as an aside,
I'm a big fan of the container adapters
and it seems a shame that
we don't have more of them.
If you have this idea for a
container you might think about,
&quot;Can I do this as a container reductor,
&quot;reuse all the functionality
and say deque or vector?&quot;
I recently tried to
write a circular buffer
on top of a container
and just decided the semantics
just didn't quite match
but it was really tempting.
I got really close.
These are the standard containers;
array, vector, deque, list, forward_list,
set, multiset, map, multimap,
unordered, unordered.
And then string because string is,
string behaves like a
container but it's not really.
I think that most of the reasons
that string is not classified
with the rest of the containers is,
all the rest of the containers
will take arbitrary user-defined types
while string takes character like types.
They don't have to be constructed really.
And the container adapters like I said,
sit on top of other things.
We're going to talk about the ways,
each of these containers have kind of,
customization points that let you,
customization interfaces,
probably a better way to say,
that let you bend the
containers to your will,
make it do what the designers
weren't quite sure of
or didn't know how to do for your types.
In particular, there are three of them
and we're going to talk
about these three today.
We're going to talk about allocators,
we're gonna talk about comparators
and we're going to talk about
hash functions or hashers.
Just so you know, I'm
probably going to call these,
comparison function and hash
functions all through the talk.
They don't have to be functions,
they can be objects, they can be lambdas,
they can be STD functions,
they can be whatever
but I'm going to call them functions
because it's a nice thing to hang on to.
There's a lot of power here
so we're gonna start with allocators.
Allocators.
Wow, it's Friday afternoon,
we've had a lot of
allocator talks this week.
A lot of allocator talks.
I just went through the schedule
and searched for the
word allocator in titles
and this is what, one,
two, three, four, five
and one of them is a two-parter.
I am not going to spend a lot of time
on nuts and bolts of
writing your own allocators
because these people spend
a whole hour doing that
and you can watch the videos.
If I had been scheduled
on Monday, I could say,
&quot;Hey you guys should go watch these talks
&quot;because they'll tell you how
to make your own allocators.&quot;
But it's Friday afternoon
and these guys have all gone,
already, they're done,
they've given their talks
and so you're gonna have
to watch it on YouTube
or channel 9 or wherever.
Bob's talk yesterday was really good.
I didn't go see John's because
I've seen John's before.
And Alisdair's I didn't see.
Alisdair and I have talked about this.
And then Pablo's stuff
I have also seen before
so I wasn't in his talk this morning.
There's lots of stuff here.
And since the the Bash Films people
are so good at getting
the videos up quickly,
you should be able to not
wait forever to do this.
How does this actually work?
This is a declaration for vector.
A forward declaration for vector,
taken right out of the standard document.
Except I added the STD part here,
it doesn't actually say
that in the standard.
But vector, vector takes,
you think of when you
were a vector you write
vector bracket int.
And you go and use it, now that's fine.
But really, vector has
two template parameters.
And the second one is your allocator
and it defaults to STD allocator of int.
And the allocator is typed
just the same as the,
as the value type of the container.
In fact if you try to pass
my allocator of string,
it'll fail to compile.
So that's all well and good.
But what does a vector do?
Oh I'm sorry, I note here.
In these slides we have two things here.
We have a type of the allocator.
Which is all well and good,
you need to get the
types of everything right
but when you actually make
make a container, you need
not a type of an allocator
but an actual allocator object.
And in a lot of the examples
that you'll see around
the wide wide world of the Internet,
they just talk about this and
they don't ever say anything.
But there needs to be a way
to go from this type to an object.
How do we do that?
It's called a constructor.
Sometimes when you create a vector,
if you just say vector int, like this,
if you say vector, int,
std, allocator, int,
V, semicolon,
the vector gets default constructed,
the vector contains an
allocator object inside of it
and that allocator gets
default constructed.
But you can create your own allocator
and pass it to the constructor of vector
and it will use that or
you can provide parameters
to the constructor of vector
to initialize your allocator.
You want to be really
clear about the difference
between specifying a type here
and specifying an allocator
instance in your containers.
Most of the time your allocators
will be default constructed
because that's what people are used to
but they don't have to be.
We want to keep the
distinction between the type
and the actual instance clear.
And that will be true
actually for the comparators
and the hashers too.
What can I do with that stuff?
What does an allocator do, I should say?
What does an allocator do?
Really, okay, there are four
things an allocator does,
basically that are
really important for you
and two of them are optional.
The first ones are,
it allocates and deallocates memory.
And for traditionally, this
is all an allocator did,
back in 2000, the C++ 2003 time frame.
But that's what an allocator is all about.
It comes from the name, allocator.
It allocates memory and
it deallocates memory.
But in C++ 1114,
I don't remember which,
we also added the capability to construct
and destroy objects.
Now notice, when you create
an object on the heap
and you say new, int, blah,
you get back a pointer
to a bunch of storage
that has an already
constructed int or new foobar
that has a constructed foo in it.
You get a pointer to an object
and the object is ready to go.
There are two things
going on there, right?
The first one is some space is allocated
and the second one is that
the object is constructed.
In the allocator interface those
two things are split apart.
You allocate memory and
you construct an object
and those are two separate
calls of the allocator.
And on the way out, the
inversing is the same thing
but in reverse.
The object is destroyed and
then the memory is freed.
So you have allocate, deallocate
and construct and destroy.
And construct and destroy are optional.
You don't have to do
those in your allocator.
If you don't do them,
there's a bunch of plumbing
in the standard library
which will give them
default implementations
which are just like calls to placement new
and a call to the destructor.
If you don't have any special requirements
on object construction and destruction
then you don't have to
actually do any this stuff.
What do they look like?
What do these things look like?
I give you sample implementations
or simple implementations
is probably a better way to say it.
Allocate, just takes a
size and returns a pointer
and since allocate of T,
this is an allocator
for objects of type T,
it returns enough space for n objects
of type T.
Deallocate is given a pointer and a size,
this is the size deallocation stuff
that was added in C++ 14 but
you don't have to use that
and here we just call operator delete
on P.
Now what's going on here
with this funny cast avoid
is, we're saying basically,
we're not running any destructors here.
Yes Gaspar.
- [Gaspar] Is size
guaranteed to be positive
or can it be zero?
Size, where, which size?
- [Gaspar] The n.
N, it's a size T, it's an unsigned number.
- [Gaspar] Can it have
a precondition or not?
Oh I see what you're saying.
Can you pass in zero to it?
Wow that's a good question.
- [Gaspar] Is it to v or are
you required to interlope?
I don't know.
My belief is that it has to
be at least big enough for one
but I don't know that for sure.
I'd have to look it up.
The question was,
what are the preconditions
on the value of n
that is passed to
allocate, can it be zero?
Obviously can't be negative because size T
is an unsigned type but can it be 0?
Can you allocate nothing?
And I don't know the answer to that.
I mean it's not a sensible thing to do
but that's never stopped
anybody in the past.
- [Gaspar] It is a sensible thing to do.
Yes.
- [Audience Member] Well I was saying,
it might be undefined behavior--
Yes, it might be undefined
behavior, I don't know.
I suspect that I could
research it and tell you
but I don't know.
- [Gaspar] You can do that for malloc
and it will give you a unique pointer.
Right, malloc has defined
semantics for size of zero.
I do not know if,
allocate does.
But yes.
Malloc will in fact give you that
but malloc does that as far as I know,
that behavior was put into malloc because
they have realloc and you
can resize something later
because really a pointer
to a block of zero bytes
is not useful.
If you can resize it to
something useful, then yes.
But C++ doesn't have the idea
of resizing a block of memory.
You just allocate a new block,
copy the useful stuff over,
throw away the old block.
- [Gaspar] Yes.
What?
That's as maybe.
Thank You Belay.
One of the things you can depend on
is that your deallocate function,
only gets handed pointers,
that came out of your allocate function.
You don't have to handle
other people's allocations.
You won't have to handle,
just some arbitrary pointer.
It has to be a pointer
that came out of your allocate function.
For example if you're allocating
out of a pool of memory
and you're handing out,
handing out pointers
into a pool of memory,
unless there's a bug
somewhere, bugs always happen
but in general you can assume that,
when you get a pointer to deallocate,
then it's something in that
pool and in particular,
it's the start of a heap block
that you allocated with Alloc.
You don't have to protect yourself
against something really malicious.
Yes.
- [Audience Member] Think
I know the answer but,
the container is the combined allocator
both for the data that I
really want i.e. the string,
as well as say the, string
class member that it needs
to manage the container.
The question was,
is the container going
to call the allocator
to handle both the data for say, a string
the actual character data for the string
as well as the string class
members to manage that?
And the answer to that is, it depends.
In the case of string,
the answer is actually no.
The allocator is only used to
allocate the character data
because all the other
things are member variables
in the string object.
But when we get to the node
based containers like say, list
it calls the allocate to
allocate what is called nodes
and the nodes contain
a T and two pointers,
upfront pointer and back pointer.
- [Audience Member] That was
a question I was gonna ask.
Somebody else have a question over here?
- [Audience Member] Over there.
- [Gaspar] How does this
work with deep propagation
of allocators not sideways like for list?
If you instantiate the vectors
straight with allocator,
and your
allocation resources are MROs,
then your vector has to
propagate the allocator
to the inter strings level?
That's something that's actually new in,
but basically what...
The question was,
suppose you wanted to
say a vector of strings
and you want to make sure
that all the vector stuff
was in a memory resource
and then all the string data
was in the memory resource as well
and what you would do is...
Is Arthur here?
Arthur gave a class before the conference
about the standard library from scratch.
He spent two days
going over a whole bunch
of the standard library.
What you would want to do is,
you want to say the
strings that go in here,
take an allocator which allocates
out of the same memory pool.
You give it a, like a PMR
and you attempt a
a polymorphic memory resource as the type
and as the instance, you
hand it one that says,
here I want this to go into this pool.
I saw a hand coming up over here, no?
Alright.
Yup.
- [Audience Member] I just was wondering,
this might be shooting
yourself in the foot,
but did you actually say that
you might add a allocator
which is a global allocator,
you wanna keep all,
all kinds of objects that,
kind of use the allocator
and just,
and you wanna make sure that
when you delete something,
that it's actually only to the object
that we've deleted,
is there any way that
you can kind of customize
these functions to say that
the subject's passing in
the size T,
that you're also passing the size T
in old collar, or is that--
That's, okay, so there's a bunch there.
The original wish that he wanted was to,
have a global allocator that in fact,
logged all allocations and deallocations
and tracked their owners.
And that's certainly possible to do.
There's two ways to do that by the way.
One is you can, you can
do it via an allocator
but an allocator is per container,
that's not all allocations
but that's all allocations
for a container.
And so if somebody just
calls, says new foo,
that's not going to track it
because that's not in a container.
But you also have the
opportunity to replace
the global operator new
which will do that for you.
New and delete.
Those are replaceable functions.
That's a little out of
the scope of that talk
but it touches on this stuff.
But the second part of that was,
determining who the owner
is and keeping track of that
and that's,
yeah, you're not going
to get extra parameters
to operator new and delete
or allocate and deallocate
because the things that are passed to it
are usually passed well,
in the case the allocator,
they're passed by the containers.
They know to put, to pass one parameter.
You could in fact if you had...
Who's was it yesterday or this morning
about stack tracing thing?
If you had a stacktrace utility,
you could look down the
stack in your allocate
and figure out where
it's being called from
but I'm not sure that's,
that maybe more work than you want to do.
Big thing here is yeah,
separation of concerned
allocation versus construction.
What can you do with this?
Well there's lots of things.
We talked about this.
Actually I'm sorry, it's coming up.
You can manage your own memory pool.
People in the embedded world
say, &quot;We can't have any dynamic
allocation in our program
&quot;because we're in embedded machine.&quot;
And I've talked to
several of them and I say,
&quot;Really, how do you handle such and such?
&quot;How do you handle such and such?&quot;
And they say, &quot;I allocate
a block of memory
&quot;at system startup time,
&quot;and then as needed, I
handle pieces of that out.&quot;
And I say, &quot;That's dynamic allocation,
&quot;you're just not doing
it in the global heap.&quot;
You can make an allocator
that runs out of a little memory pool
and then you can use vector
or map or set or deque
or whatever and it will stay
in that little memory pool
which satisfies the people,
&quot;No, no dynamic allocation.&quot;
I mean no dynamic allocation
in the global heap
but that's fine.
You can allocate in shared memory.
If you have a shared memory area
that's shared between different processes,
you can teach an allocator
how to put it out there
and you can have data
structures that are shared
at memory speeds between
different processes.
Now you have to play
some games with pointers
to make sure that if you
have something like a list
that the pointers are relative
to the start of the shared memory block
but that's like so that
you can traverse the list
in both address spaces.
- [Gapsar] How about relative
to their own list pointer.
That's another way to do it.
The question's comment was relative
to their own this pointer.
That's another way to do it.
There's a facility in allocators
which I'm not gonna
really going to talk about
other than mention that
which we call fancy pointers
or non-native pointers and basically
these are things that look like,
that represent memory addresses
and you can turn them into actual real,
memory addresses through a call
but they don't have to
be raw memory addresses.
You can allocate, you
can enforce alignment
which is really nice
because maybe your underlying
implementation of malloc
doesn't actually have the
alignment guarantees you want.
Let's say your underlying
memory allocation gives you,
four byte alignment and you need eight,
you allocate an extra
four bytes and then fine,
optionally bump your starting block,
your starting point or by four bytes
and you get eight bytes alignment.
Yeah, you can hand stuff
out of a memory pool.
John Lakos did two hours
about arena allocators
where you pull them out of a pool.
Many years ago, I wrote a spam filter
for an email program I was
working on at the time,
Eudora's.
What I did when I started
working at Qualcomm
back before free email clients
killed paid email clients.
I wrote spam filter,
one of the data structures I had, was
a map of strings to integers
where you look at
individual strings, tokens,
whatever, you've got a score.
And then you do a bunch of the
Bayesian calculations on it
and you come up with,
are all the words in the message
and you come up with score
which suggested how spammy this was.
This was a big data structure.
And actually we had two
of these data structures.
We had a fixed one,
which we shipped
and then a much smaller one
which the user could train
to their particular thing.
They could say, &quot;Yes this is spam.&quot;
Or, &quot;No this isn't spam.&quot;
It would learn.
But the fact that the big one,
the fixed one never changed,
thought to myself,
&quot;I don't really need those strings,
&quot;I don't need all the power of strings.
&quot;I just need just the raw text.&quot;
And so I changed the,
I changed the mapped from a map of
int, string,
to a map of int, care star
and then when I read the data at the end,
I just allocated a big block of memory,
I think it was like 64 K
and I'd laid the strings
into it one at a time,
the character data.
And pointed it in there,
slapped in all on the end
and if I didn't have enough room,
I just went and added,
allocated another 64 K
because this data never changed,
I never had to delete it.
When the program was over I
just let the whole block go
because, didn't matter, it never changed
and the program was ending.
And you can do the same kind
of things with memory pools.
If you know that something,
you know something
about your memory usage,
about the way your objects
get created or destroyed,
you can take advantage of that.
This is a very general solution
and you're the heat manager in your OS,
whether that be J Malik
or TC Malik or whatever,
is a very general solution to that.
Maybe you have a situation like I did,
where there's no deletions
or almost no deletions
and if you have say,
two million spam words
and over a course of our program run,
you delete two of them,
just let go of the
pointer and let them go.
You've wasted 30 bytes
of storage, big deal.
You'll save way more
than that in code space,
trying to manage a free list.
This is, the customization
point here is for,
you have special requirements,
you know more about your system
than the people who designed
this very general mechanism.
That's when you want to customize.
Talked about that.
These are the optional calls.
Construct and destroy.
This is a very simple implementation
and this is the
implementation you will get
if you do not in fact implement
construct and destroy.
This is the implementation
that the standard library
will gen up for you.
You say template class that
says, &quot;I need one of these
&quot;and these are the arguments,&quot;
and put it here.
This is a pointer you
got back from allocate
or some function of a pointer
you got back from allocate.
Because vector for example
will allocate enough space
for say, 20 of these
and then call construct
throughout that block.
It calls placement new
and then forwards args
and you're done.
And destroy is even easier, it just says,
&quot;You, destroy yourself.&quot;
Call the destructor.
Any questions about this?
Yeah.
- [Audience Member] What
would be a typical use case
when I would want to specialize this?
The question is,
what would be a typical use case
when I would want to specialize this?
I'm glad you asked that.
(audience laughs)
See me afterwards I'll
pay what you wanted.
Suppose you wanted to...
Thank you.
Register every object creation
and every object destruction,
log it, something like that,
this is a great place to do that.
Suppose you wanted to add parameters
to your constructor call.
I mean you can do that.
Just because you get these args
past the constructor,
doesn't mean you can't swizzle them around
or add some or leave some out or whatever.
You a lot of freedom here.
You can give each object a
unique ID or a unique tag.
It's not serializing them but it's,
I don't even wanna say memorizing
because it's not those,
it's marking them, stamping
them each unique one.
If you have to do a global registry,
you have to do a registry of some kind,
this is a great place to do this.
What people like to do, is they do this,
in the destructor.
They do it in their destructor.
They have this global registry of objects
and in their constructor
they're registered
in their destructor, they deregister.
Deregister, is that even a word?
The problem with that, is
that it's undefined behavior.
If you have to actually look at,
if the process of deregistering
it has to look at the object
it's undefined behavior.
Because why?
Because once you enter the destructor,
the object of the lifetime has ended
and none of the invariance
can be guaranteed anymore.
So if you have say, a map of things
and in your destructor you call
remove on the map,
say, find this object in the
map and remove it or a set say,
you don't really have the guarantee that,
it'll find it in the set
because you're trying to find this object
whose lifetime has ended.
If you're just a single class,
no inheritance or something like that,
it probably is going to work
but I'd hate to depend on it.
If you're going down an
inheritance hierarchy,
your superclass's
destructors have already run.
Yes.
- [Audience Member] I'm curious,
because it returns void the construct one.
Does that mean that this is the place
where I assert that the
pointer is suitably aligned
because I'm not allowed
to actually change them.
You're not allowed to
actually change it, no.
You could--
- [Audience Member] When U
returns the new pointer--
But you already have the pointer.
- [Audience Member] Yes but,
I thought that placement new
was allowed to adjust for alignment
and then return the pointer
and then stood longer
it comes in a stronger
view and all that stuff.
That has changed a lot in C++ 17.
The whole extended
alignment stuff went into 17
and we're still figuring
out exactly all the places
that needs to go.
- [Audience Member] My
actual question was,
if I have data that needs
to be 256 byte aligned,
is this where I search for that?
No I would...
- [Audience Member] If I allocate,
let's say the size of my datum is
actually, I don't know, 10 bytes.
It happens to be aligned to that
and that requests I need this menu.
The vector is gonna try like, size of T
times size of T, and
that's what I wanna assert,
like you're trying to
create something in place
that uses that to recode.
No.
There's some funny stuff going
on here that I haven't shown
and I'm trying to remember
exactly where it comes in
because if you try that with vector,
you'll get the same loud
as an array of those T's
and then every element
will be 256 bytes along.
- [Audience Member] Because
that's the align off?
Because that's the line off.
But before C++ 17, the extended alignment,
the stuff bigger than long double,
you had no guarantees about it.
Either in array or in vector or anything
and in particular in
vector, you didn't get it.
So, don't know, don't
know where that kicks in.
Yes.
- [Audience Member] The
allocator here you static
cast the p to U,
what I wonder is try to prevent
the destructor to record.
Because, we have destroy,
which calls the destructor again,
we're separating the concerns,
we're separating the
destruction of the object
from the freeing of the memory.
Yes, you are exactly right.
The question was, is the
reason here that we are,
static casting this to
void, before calling delete,
is that to prevent the
destructor being run
and yes, it is.
Because we run the
destructor somewhere else.
If we just passed a t-star
to, if we say, delete P,
it would run the destructor.
What can you do with this.
Like I said you can log
every object creation
and destruction, you can
inject additional data,
all sorts of things you can do.
Some really simple examples
about using your own allocator.
I have my own allocator
here, it's called Alloc.
I'm not showing you a
definition for Alloc,
I mean, please go to
some of the other talks
to see really how to
write your own allocators.
We're gonna assume that Alloc
has a default constructor
and has a constructor
that takes three ints.
We have vector int V1,
this uses STD allocator.
STD allocator int in particular.
We have a vector int of Alloc of int, V2.
V2, when V2's constructor gets run,
it's going to default construct an object
of type Alloc int.
Just like the first line
when its constructor runs
it's going to default construct an object
of type STD allocator int.
Now here,
I'm making a type def for my vector,
my vector v3 this is going to look,
this is very much the same as v2.
My vector V4, I'm passing in an allocator.
I'm making an allocator and passing it in
and that's going to get,
because it's temporary,
it's going to get moved into the vector.
This bottom one down here,
here I'm declaring an allocator of int
and then I'm making another vector,
v5 and passing in
the allocator as a constructor parameter
and that's gonna get copied in
because it's not a temporary.
The point is that the reason
I made with this slide
was to drive home the fact that
the thing that I talked about earlier
is you want to keep the
type and the instance
of the allocator and the comparators
and the hash functions.
Make sure you're clear on the fact
that they're two separate things.
Most of the time people will
do things like this
where the allocator
gets default constructed
and in almost every sample
program you ever see,
the allocator will never get mentioned,
it just gets default constructed,
and everything happens behind the scenes.
But you can create your own allocators,
there are variables just
like everything else,
you can pass them in.
They have to get copied
between containers,
when containers get copied
and things like that,
there's a whole infrastructure
there that I'm not going into
but the point is is again,
make sure you know the difference
or actually, you guys
all know the difference,
make sure you're aware of the difference
between the type of the allocator
and the actual allocator variable.
The allocator variable is stored
as a member in the vector.
Any questions about allocators?
Yes.
- [Audience Member] Given all that,
how would you implement
back to the spam filter
how would you implement something
that can allocate most strange
lots of memory contained
and they need it once
if they need it once?
Do you just not call the program--
Well, so there's a couple ways to...
The question was, going back
to the spam filter example,
how could you write
something that, let you,
where you could allocate a bunch of things
and then delete them all at once
or not delete them at all.
What I did was,
what I did was I made my map
be a const care star int
mapping of a word which is
a null terminated string,
a null terminated C string to an int.
Pointers like that, care pointers,
they don't have destructors.
When the map gets torn down,
the character data just leaks.
Which was fine because
the map got torn down
at the end of the program
when I didn't care.
All the nodes in the map got deleted
but the actual character data didn't
but then I had these
blocks containing those,
the end of the program, the
environment got torn down,
they went away.
But you could in fact,
you could do things like,
you can play games here,
to not delete things.
You can manage, you could
keep a cache here of,
the last four deletions
and and reuse them,
you can do all sorts of things here.
- [Audience Member] So
if I don't delete here
then how do I delete at the
end for the whole block,
for the whole block?
Or I just bookkeeping--
Yeah, you just do bookkeeping.
The question is if how do I,
if I don't delete here, how
do you delete the whole block?
You can delete the block say,
when the container goes away,
say.
You can coordinate between the
container and the allocator
or actually a better place to do is,
you delete the whole block when
the allocator gets destroyed
and then you just, what
John Lakos likes to call,
winking out.
You just, it's all gone,
you don't run any destructors or nothing.
Yes.
- [Audience Member] If you
actually had to deallocate
just do nothing rather than,
rather than just do a delete operator.
The question is, can
you have your allocator
just do nothing instead
of actually call delete?
Yes you can.
It means the memory usage of your program
is only going to grow but presumably,
you have a good reason for that.
- [Audience Member] Well if you,
I was saying if you're
basically not really allocating,
allocating space when you need,
maybe you're using a constant
buffer that you chose,
that might be a reason why
you want to do nothing.
Absolutely.
If you're allocating out of a buffer
that you're planning on
deallocating all at once,
which is what he was asking about, yeah,
you may want to, when the
time comes to deallocate
an individual element out
of there, you just say,
&quot;No, I'm not gonna do that.&quot;
That's fine but as long as,
either they're simple types
or they get destructed
or you don't care about
the resources they hold,
you're fine.
- [Audience Member] Well I think that the,
I'm sorry.
The destructor might be then...
- [Audience Member] Call the destructor
without calling deallocate.
Yes.
And that's the whole point of having both,
both deallocate and destroy is,
one runs the destructor,
one frees up memory.
I was going to spend about
20 minutes on allocators
and we're 45 minutes in,
so I'm gonna move along.
- [Audience Member] Wow.
Let's look through the containers.
Let's start with, array.
Array is the simplest.
How does array use an allocator?
It doesn't.
It doesn't at all.
Array stores all its elements on the stack
just like a built in array,
it doesn't have an allocator parameter,
it's done.
There are contiguous
containers, vector int,
vector deque and string,
they allocate in chunks.
Vector puts all the
stuff in one big chunk.
Deque has a lot of blocks, each holds
each holds several elements.
String, string may not
use its allocator at all.
Starting with C++ 14, 11,
you can have a small string optimization
where it stores the string data
in the string object itself
in which case it never
calls the allocator.
List and forward, list
are node based containers
which means that they,
they will allocate nodes
that contain a T and some other stuff,
usually for a forward list.
It's going to be a next
pointer for a list,
it's going to be a next
pointer and a previous pointer.
The associative containers
are node based point,
node base, blah, containers as well
as are the unordered
associated containers.
They allocate nodes rather than just Ts.
That's how they all, excuse me,
that's how they use their allocators.
Associative containers.
I'm done with allocators.
If you have questions about allocators,
I'm happy to answer them after we're done.
Associative containers.
Here's the definitions for set and map
and the definition for
multiset and multimap
are the same except for the name.
We have a key, we have an allocator
which is an allocator of key.
That looks very much like
vector and it should.
But there's this thing
in the middle called Comp
and that's new.
And for map we have
key and T, key in value
and Alloc and then Comp.
What the heck is Comp?
Comp, because the associative containers
keeps things in an ordered tree,
they need to know how to order them.
They need to know how to order them
and given an arbitrary type,
how do you order an arbitrary type?
Here's an example.
Here's an example of
a comparison function.
This is not a function.
This is an object that has
a procedure call operator
member function,
but I'm gonna call it functions.
This can be a lambda,
this can be a functor,
this could be a STD function,
this can be a pointer to function,
this could be one of these objects.
It doesn't matter, the point is,
can they be called with,
like they were a function?
That's kind of the
definition of a functor.
It's something that can get called
with procedure call syntax.
A couple things to note.
It's a const member function.
In C++ 17, this is required.
Before C++ 17 it's merely
a really good idea.
And I'll tell you why.
Suppose you have a set
and you have a comparison
function like this
and you forget to make it const
and you try it and it works just fine
and you're going along
and you're putting things
in your set and everything
you run your unit tests
and everything is great
and then you add a new
procedure in your program
and you call it and it takes
your set by const reference
and suddenly it fails to compile
and you get spew all through your console
and you look through it
and you look through it
and you look through it
and it comes down to,
it says, &quot;Attempting to
call a non-const function
&quot;on a Const object.&quot;
When the set is Const, the comparator
which is a member variable
of the of the set,
is now const because
the whole set is Const
and if you have a non
const member function,
it will fail to compile.
You can't even do things like
find in a set that's const,
if you don't have a const commperative.
Lib C++, tooting my own
horn just a little bit,
will static assert on this
and give you a really nice
error message that jus says,
&quot;No, your comparator has to be const.&quot;
Other things about this.
This is a really really
terrible comparison function.
(laughing) This is a
terrible comparison function.
Compares the last names,
it sorts by last name.
You put this in a set,
what does this mean?
It means that Bob right Ted right,
you can't put both of them in the set
because they have the same last name.
Because it will say,
&quot;Oh they're the same.&quot;
How many people have heard the term
strict weak ordering before?
How many people want me to not rant
about strict weak ordering
for a few minutes?
Ansel, Ansel do you have a question
or you want me to not rant?
- [Ansel] If this is a really
bad comparison function
it always returns false.
- [Audience Member] That covers Ansel.
(audience laughs)
Yes, even better.
That's an even better.
Thank you.
It should say yes.
As seen, Ansel said it
always returns false,
this should be L, left hand side
not right hand side, right hand side.
- [Audience Member] That's
why you name them x and y.
No that's why I name them left hand side
and right hand side but
I got this one wrong.
I have seen X dot whatever
less than X dot whatever
is all.
Why is this a terrible...
That's one of the reasons
is a terrible thing.
Strict weak ordering, right
what it's strictly weak
ordering, it means that,
your function has to be,
reflexive.
If X is less than Y, Y
can't be less than X.
They can both be false, that's fine.
Think of three and three,
three is not less than three
and three is not less than three.
But yes and it's transitive.
If two is less than four
and four is less than eight
then two is less than eight.
If your comparison function
does not implement a strict weak ordering,
bad things will happen.
The standard library will
not protect you against this.
If you're lucky it will just
give you subtly wrong answers.
Actually if you're lucky,
it will crash very quickly.
If you're unlucky, it will
give you subtly wrong answers.
There's a lot of reasons
this is a terrible one
but you get the idea.
You can write this as,
write this as a really simple struct.
Most of these are stateless
because why would you want a
stateful comparison operator.
Three needs to be less
than four all the time
no matter what the state of
your comparison function is.
Maybe you want to do some
blogging but in general,
since it's const that makes it harder.
They return something that
can be converted to Boolean,
in practice they've just
always returned bool.
Set, map, multimap, multiset,
all keep their stuff ordered
according to this relationship.
Smallest first.
And if you use less, the
smallest ones are first.
If you use greater, the
largest ones are first.
This is a cheap way of doing,
if you need to pick off like the top three
and you were scared by
priority heap as a young child,
you can do that.
You can use a set to this.
It's okay.
This is about as complicated as,
as the form of comparators needs to be.
Yes.
- [Audience Member] Excuse
me, what if you don't like
to create your own struct but the operator
or your functor class, what
if you wanted to use lambda
to define your code
because it's gonna be,
the lambda will be closer
to actually the definition
of your code or your object
than the functor where you
might have it in the node class
and if somebody was hired to figure out
how it's sorting.,
they're not gonna be able,
they have to look at the other class
before you go through it.
The question can be summarized by
and then you can complain
about my summary,
why don't you use a lambda
because it's right there in the code?
And the answer to that is because,
you can do that but it's not near as clean
as you would like.
And the reason for that is,
because you have to tell
the template the type
of this.
Now maybe the template argument
reduction will help you here
I should try that.
But if you have to actually name this,
well lambdas don't really have a,
they have an unpronounceable name.
The only way to get it is through decltype
and so you would have to
actually take your lambda
and put it in a variable and say
decltype of that variable.
Now if template argument
deduction comes to your rescue,
if you don't have your custom allocator
that you have to specify
or anything like that,
if you can just, you can go with that
then that will help you a lot.
- [Audience Member] Is the
constructor know your context
and if not who can do that?
Can't do that in 17 yet.
- [Audience Member] Will we expose?
His question is, is
the constructor running
an ODR context and I don't
know the answer to that.
Said that Louie was
trying to get this fixed.
Template deduction guys
may help you here too in 17
but since I haven't
implemented those in Lib C++,
I don't know for sure.
Shi Hau.
- [Shi Hau] What can
you still go on do that
past humongous challenging
different heights
therefore you create
two identical lambdas,
and you generate tow different types
and you end up with containers
that you can't compare.
He said you don't want to do that
because if you have two lambdas,
you generate two different types
and you end up with containers
that you can't really compare,
even if they're sorted of the same way.
Not yet.
We need some more
infrastructure in the language
to make that work nicely.
But I agree that is
something to shoot for.
(humming loudly)
To that, here's examples.
Like the allocator
stuff we had set person,
person, this will not compile
unless your person has a an operator
less than defined on it.
This will default construct personless
and use that as the comparison,
personless, yes.
Some persons are less than others.
(audience laughs)
And in this place, everybody
is less than others
because I can't type.
My set person, personless,
this is really the same as,
set person, personless, allocator, person,
v3, personless, paren, default
constructed personless,
default, it's constructed,
allocator a personless.
And here I'm making a comparison,
I'm explicitly passing the
comparison function int.
Yes.
In this case, you don't have to do this
because default
construction works just fine
but suppose you had some
funky constructor for that.
Yes you had your question?
- [Audience Member] Yeah,
I just was wondering,
if you put the new allocator,
you would have a memory like,
abruptly if you put it in to a personless,
myset c4, right?
Or am I being--
I'm sorry, if I put?
- [Audience Member] Briefly if you put,
before the bracket you use personless
that would create an object on the,
that would be a memory thing.
If you said new personless here,
instead of personless, you'd
allocate something on the heap
and you would have a leak
because nobody would,
nobody would free it but
more importantly actually,
you would get a compile error
because it would not,
the set doesn't know to say,
&quot;Star thing prin pran.&quot;
It would just say,
&quot;Thing, prin pran,&quot; says,
&quot;I don't know how to prin pran a pointer.&quot;
It is, I got five minutes left
and I have like six slides left.
Unordered associative containers.
Uordered associative containers
are just like associative containers
except that they're unordered.
See we're done now.
Unordered associative containers that,
the interface looks just like
the associative containers
except they have this thing called hash
and they have this thing called pred
and they don't have
this thing called comp.
They're different, they're not the same.
They're exactly the same only different.
Most of you I asked earlier
had been to Matt's talk
about implementing hash containers
so you know how hash
containers are implemented.
You hash things into a bucket
and then you use the predicate
to find the object you're
looking for in the right bucket.
They're implemented as hash tables.
The predicate implements
equality not less than.
It doesn't try to impose
an order on your things,
it just says, &quot;Is this
the same as the other?&quot;
And the hash function and
the comparison operator
are required to play well together.
What the heck does that mean?
It means that they have to agree.
In particular,
because you use the hash
to find the right bucket
and then you troll through the bucket
to find the right thing.
If two things are equal,
they have to hash to the same value.
If they don't have to the
same value and they're equal,
your hash table is going to misbehave.
Now obviously, you can have
two things that are not equal
hash to the same value, that's
called a hash collision.
If you think about, suppose you have
a set of strings
and your hash function returns a size T,
that's 32 bits or 64 bits,
there are way more than
that possible strings.
You're going to have a
collision eventually.
Two things that are not equal
so may hash to the same value
that's fine.
There are hash talks this
week, there were a lot.
Some of them were really good.
I went to about half
of Phil's this morning.
Nicholas's talked about hashing as well
but Matt's was great.
That's a very very fast hashed algorithm
that I was very impressed by.
One more slide really.
It's important to use a big,
a good, good hash function.
You can in fact, when
I talked earlier about
bending the containers to your will,
you can take an unordered
set and bend it to you will,
make it into a linked list.
Now most people feel
that this is a bug not,
this is an idea of something
you really don't want to do
because you've taken an order one lookup
and turned it into order n but hey,
maybe that's what you want.
I took as an example,
I took all the prime numbers less than 100
and dropped them into a hash
with three different hash functions.
This was the type I used.
I notice that here I had
int and then this function
that takes an int and returns a size T.
And I used three different hash
functions just for testing.
I used IDhash which just returns int,
I used halfhash which takes the number
and divides it by two,
and then I use random hash
which returns a random number
chosen by a fair dice roll.
- [Audience Member] When you talk
about a random number
dice roll, is that,
that give you one dice
roll and choose what number
or is it just--
- [Audience Member] I think you roll four.
I rolled the dice once and said
that's a random number four.
The reference check xkcd.
It's a joke.
It's not a random hash,
it's a constant hash.
I expected that this one to be okay
and this one to be significantly better
and this one to be terrible.
I was mostly right.
This one was okay,
this one was okay and
this one was terrible.
The reason I expected
that this one to be better
than the first one is
because all the hash,
all the hash, all the prime numbers
with the exception of two are odd.
And so I expected half the
buckets to be empty because
when they all hash, these hash two itself,
they never got an even number.
But it turns out when I
examined it that they,
that the number of
buckets in the hash table
was on the order of
46, 45 something, 47.
I think it was a prime number less than 50
and so the fact that it
never returned an even number
really didn't matter, it
still was spread out okay.
Both of those, the first
two behaved about the same.
The last one, every single
one went into the same bucket
and so I got terrible lookup performance.
The takeaway from this is really,
you want to be careful
with your hash functions
because a good hash function can help you,
a bad hash function
could absolutely destroy your performance.
It can do way more harm
than a good hash function can do good.
Questions, we'll go right past that
and we'll go on to thank you.
And I will happily stay around
here and answer questions
but people are done.
(audience applauds)
Yeah, if you got
questions just come on up.</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>