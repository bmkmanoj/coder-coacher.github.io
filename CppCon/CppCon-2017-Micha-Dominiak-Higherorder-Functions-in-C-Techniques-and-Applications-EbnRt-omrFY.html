<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: Michał Dominiak “Higher-order Functions in C++: Techniques and Applications” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: Michał Dominiak “Higher-order Functions in C++: Techniques and Applications” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: Michał Dominiak “Higher-order Functions in C++: Techniques and Applications”</b></h2><h5 class="post__date">2017-10-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EbnRt-omrFY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Hi, my name is Michal Dominak,
I work at Nokia Networks
in Wroclaw in Poland,
and I'm here to talk to you
about higher-order functions
and the title says
Techniques and Applications,
there will be more about techniques,
because I made a presentation
about techniques,
and it's already too long
for the time slot I have, so,
hopefully I can get through it all.
There is microphones that
you've probably noticed
throughout the week.
If you have a question,
please use the microphone,
if you can, if you can't, just
shout it, I will repeat it,
but it would be preferable if
you could use the microphone,
and if you have a question
during the presentation,
feel free to ask it.
It's easier, it's very often
easier to answer in context.
Alright, and if there's
any standard library
implementer here, or a
library working group member,
I would like to be sorry
for misrepresenting
your hard work (laughs).
Okay, we are through with
interactions like this,
let's dive in.
So, what actually is a
higher-order function?
Wikipedia gives us a
quite helpful definition,
and it says it's a function
that has at least one of
the following properties.
One of them is it takes a function,
or more functions, as arguments,
or it returns a function as a result.
The second property is
slightly less interesting,
there is not so many
considerations to be taken,
so I won't be really
talking much about that.
I might mention something
somewhere during the presentation
about that, but the more interesting part
is actually taking a
function as an argument,
which isn't as straightforward
as it might seem.
Okay, so oh, this is not
supposed to look like this.
I know what happened, and I'm sorry
for editing the slides at the last minute.
So there is just a zero
as the last argument here.
That's the thing that I
was missing previously,
my editor helpfully formatted it for me.
So we have the function
in the standard library
called accumulate, accumulate
sums all the numbers
inside the range that we
passed it by to iterators.
Right, that's the thing it does.
Except not really, because,
really, we can use the
accumulate for anything.
A better name for this
function would be fold,
but C++ has this weird
history of renaming things
in a way that is not always obvious.
But the point is we can pass
anything as the accumulator,
like, as the function that does
the accumulation inside this algorithm.
We can pass something like
this, so this lambda here,
indexes the first argument
with the second one.
So if we have a vector of keys
into some recursive data structure,
and we have the root element,
we can just index all the
way down, with all the keys.
For the purpose of this talk,
a function is anything that is callable,
just in case that I would
forget about to say this later,
this is a function, I'm not
going to make a difference
between a function object,
a lambda expression,
a function pointer, whatever,
because that's what interesting for us.
Okay, so we can pass a function here.
There is another use case which differs
in a slight way that is
not particularly obvious
from the code, but I will
mention it later, the difference.
Get calculation gets us a future,
a future is a representation of a value
that will probably arrive in the future.
And here I'm using
something that's not exactly
the dot then from the
ds because this dot then
just takes, gives us a
value in the the future,
but the point is I can pass a function
that will be executed once
the first future is fulfilled.
So futures, I don't know how many of you
were in Hartmut's talk yesterday,
but futures allow us to
build chains of dependencies
that will allow us to execute code
on many threads and executors efficiently.
Alright, we can of course
merge those two together.
This code, I have no clue
how this would look like
if I couldn't just pass a
function inside something else.
This would be just crazy.
What it does is goes through
a statement in a function,
it's like a part of a compiler.
Goes through statements
in the function, and,
once it reaches,
the idea is that once it
reaches one that always returns,
so either a return statement
or a throw statement, something like this.
It just doesn't do work anymore,
otherwise it continues and
optimizes every other statement.
So, I don't know how to write this
if I couldn't pass functions
into other functions.
Alright.
So, function pointers are
somewhat of a first idea
for how to pass functions
into other functions,
that's how we did it in C, right?
So we can have a function pointer type,
this one is a template, but,
it's a comparison function, right?
It takes two elements
and gives us some result
that's boolean, okay, and we
can have a function like this,
which takes two elements
and takes this comparison
and just invokes it supposedly,
and does something if
the comparison is true.
It doesn't matter what
exactly this function does,
it's the example I will be using
throughout this talk for
different techniques.
So if we could actually
write something like this
instead of that pointer there,
we can just write a function type
and pretend that we are passing functions
and not functions pointers,
function pointers is
exactly the same thing.
Okay, so if we have a comparison operator,
there's a free comparison
operator like here.
We can just invoke this function.
Right, we pass the function pointer
for that comparison
operator into this function.
By the way, none of the
code that's on this slide
has been compiled
(audience chuckles)
so if you see a glaring
error, please be my compiler,
and point it out so I
can fix it for the slides
that will be published
after the conference, okay.
However, if I were foo,
defined the comparison
operator as a member
and we tried to call this
function like this, doesn't work,
because this is a member function pointer
and not a function pointer,
and member pointers
are not pointers, despite the name.
We would have to do something like this,
introduce something that can be passed
using a function pointer
with the correct signature.
If somebody decide to declare
the operator like this
for whatever reason,
right, if the signature
is slightly different, then
we also cannot do this.
And again, the workaround
is exactly the same,
but this is not nice,
right, we have a function,
we want to pass a function,
and we have to create another function?
This makes no sense.
Alright, so function pointers are clearly
not up to the task
that we are giving to them.
So, let's try something
that arrived in C++ 11,
and is often considered by some people
to be the go-to solution
to pass functions around,
which I will argue that it is not.
Okay, how it looks like,
we just get the function
type that we had previously
slapped standard function
around it and we have our type.
And we can write the function
the exactly same way,
and just change the typedef,
and now this works,
okay, that's good.
This also works.
And this also works.
So, looks like we achieved our goal,
we can pass anything that somebody
has declared before into our function.
So how does it work?
The very short answer is type erasure.
The very long answer is
on the next two slides,
which are the part where I'm sorry
to standard library implementers
for making it seem like
they have an easy job.
So we have function, hopefully
you can all see this,
we have a function, first we
have to declare the template,
and then we have to do
some pattern matching
to actually determine the signature
that somebody has given us.
We are going to to do type erasure,
and a kind of standard type erasure way,
like technique, is to have base class
that exposes some interface,
keep a polymorphic
pointer to the base class,
and then do something funny,
but this is our interface,
so the only thing that
we are allowing here
is calling the function,
which is not exactly
all that's required
from standard function.
But, we have the base pointer,
and so our call operator
of the function thingy,
will just use that virtual
function to do the dispatch.
Then we have the constructor that just
creates a proper implementation,
what impl is we will see in a second,
and moves the value
that was given by value,
and everything's fine.
And then we have impl,
which actually stores the thing
that was passed to the function,
and when invoked, for the
virtual function call,
it calls the proper function
using standard invoke,
which is the thing that allows us to pass
member function pointers,
for example, into this.
So standard invoke is a C++ 17 feature,
as a function it was
previously a syntactic macro
which wasn't really macro
because it was overloaded,
but it was used throughout
the standard library.
So, standard function uses
it, standard thread uses it,
it allows us to pass any
callable, and then some arguments
and invoke figures out how
to actually call this thing.
Okay, so, this is the, like,
classic implementation of this.
There's a lot of function
pointer dereferences here.
I mean, pointer dereferences.
There's a lot of jumping around,
we have indirection through data,
we have indirection into the v table,
and then we have indirection
into the actual call,
which is not particularly good.
So we are going to forget
about this implementation,
although I think this is
what some implementations do,
I think looks, I tried to look at libc++
while trying to run here and be on time,
and I think it uses something like this.
And it's probably libc++.
We're going to work with a
slightly different version
that allows us to do slightly more things.
So, it starts the same,
but then we are going to have
a function pointer inside.
So we are going to use some more functions
to implement function, which
is kind of nice, right?
Building functions of the functions.
So by default, this
pointer's going to be null,
this is not actually used anywhere here,
but it could.
Okay.
Then we are going to have
this weird-looking type,
which is a unique pointer to
void with a custom deleter.
The deleter is a function pointer,
so at any point, we
can change what happens
when the deleter is called.
So this is, those two members are the part
that powers our type erasure
in this implementation.
Invoke erases the actual code
that needs to be called
to invoke the function,
and data erases the actual type
of storage for this function.
Does this make sense,
I hope it does, okay.
Then our call operator will
just grab the void pointer
pass it into invoke together
with all the arguments
that were passed into this call operator.
And now the building
block that makes sense
actually is the constructor.
There's some crazy code going on here,
but it's not that crazy
once you look at it closely.
The data just makes a copy of the,
well, actually, it moves the thing
that was passed as an argument and then,
sets up the deleter
to actually invoke the current destructor.
And the first one,
the invoke,
just saves the function pointer
to a function which knows
which type is stored in data,
so it can do the proper reinterpret cast,
and actually invoke this thing.
Hopefully this makes at least some sense.
If not, please look at
the slides afterwards.
Hopefully it will start making sense.
Okay, yes, can you use the microphone?
- [Man] Shouldn't you call
the destructor directly
instead of delete, because
that was not stack allocated.
Come again?
Can you ask it again?
- [Man] Shouldn't you call
in the custom deleter,
the destructor itself,
as opposed to delete,
because the object was not heap
allocated --
I'm doing new.
Notice that the first argument
to data is a nude pointer,
so I'm deleting the thing.
Alright, make sense?
Yes?
- [Audience Member] How is this
faster than virtual calling?
How is this faster than virtual call?
Less pointer indirections.
So a virtual call has to look
through the unique pointer that we have
to find the v pointer
that points to the v table
where it finds the function
that it wants to call.
This has the function
that would wants to call
immediately here, it's called invoke.
So it's one indirection.
- [Audience Member] So you have one less
indirection with this.
I have,
yes, kind of,
one less indirection, yes,
but in a tight loop is
going to adapt, right?
But this is nicer for other reasons, too,
so, stay tuned.
Okay, does this make sense to everybody?
Is there anyone, yep?
- [Man] When I tried doing this technique
on Visual Studio it wouldn't work
if I used the member initializer list,
is that why you don't do
it either in that slide?
In Visual Studio, it wouldn't work
with a member initializer,
I'm not doing this here
with a member initializer because
I think this looks nicer
and the member initializer
in this case looks like, crazily.
I have no idea whether it would work
in Visual Studio or not.
(man chuckles)
As I said, this is not actually
code that I've compiled,
so I deeply hope that I haven't
made a stupid mistake.
Alright.
Alright, so we are going to go forward,
because as I said, I,
this is slightly longer
than this time slot,
so we'll try to get
everything that we can.
So there are some problems
with standard functions,
first of all, it requires that the thing
that we hide behind it is copyable.
Because the type erasure thingy actually
also has a clone function
or something like this,
because function has a copy constructor,
so everything that we pass
into it has to be copyable,
which is not optimal.
I keep playing with this, and,
so we cannot actually hide move-only types
behind a standard function,
so my opinion here is
that standard function
shouldn't be copyable, and we
should have something else,
called something else,
that actually is copyable,
this ship has unfortunately sailed.
And.
To, oh, I have the paper
mentioned later, alright.
There's actually a paper
that helps with this.
Another problem, imagine
we have this thing.
It has a non-const call operator,
which increments the value
it holds and returns it,
and we have the const one.
Alright, the const one
doesn't change anything
because it's constant.
So, if we just created some
function object instance,
and call it like this, we will get one.
If we create an instance like this,
we will get zero.
Right, that follows from the code.
Now, we wrap them, so the first one,
when we wrap it in standard function,
the assertion won't fire.
If we wrap the second
one in standard function,
we have a problem.
Because it will, it is
going to be the non-const
call operator that is
going to be called here.
Why?
Well, remember this string?
This operator is const,
so it can be called
in a const function,
and data itself isn't const,
just a void pointer.
We are not trying to
propagate the const nest here.
Which is kind of
unfortunate, because let's do
surprising behavior like the thing above.
So, I would like to be able to write this
and have the proper behavior
and have the previous
slide not compile at all.
There's the paper for this.
This is some slides, here, are like,
there's a paper about this.
From David Krauss, P0045,
do you remember the exact status, Matt?
- [Matt] (drowned out by
microphone distortion).
Okay, it's going to have
another revision, okay.
So this might be actually
coming, so this would be nice.
The paper actually also deprecates
the const call operator,
so the code would still compile,
we would have a migration path,
and then at some point
it would be removed.
So that's a nice way to
get rid of this problem.
How we are doing with time, okay.
So,
when we are doing type erasure,
and notice that this slide
doesn't say is problem
with standard function,
it says problems with erase wrappers,
so this is going to be a problem,
whichever approach we
take with type erasure.
We cannot actually deduce any
part of the call signature.
We have to know the call signature
for this to actually make sense, so,
with argument types
this is not really hard,
because generally we
know with what arguments
we want to call a given function, right,
but with return types it can be
hard and there is a lot of
questions on the internet,
how do I do this, the
answer is usually you don't.
So we have a function like this,
the return type being
a template parameter,
and we have a function like
this, we cannot do this.
Because the compiler doesn't know
what the template parameter is,
because it's not able to deduce it here.
So we could do some silly thing like this
as it's a function, so
the decltype will actually
give us the correct function type.
This is ugly, right?
Passing bar.
What?
Passing bar.
I cannot understand you.
- [Man] Isn't bar as an argument there?
I mean bar as an argument,
yes, thank you, yes,
that last line should
say foo of std function
decltype bar address of bar, thank you.
So we can actually spell
it, but spelling it is like,
contradicts the idea of
type deduction, right,
so we cannot actually do
anything useful with this,
the code gets very verbose very quickly.
Okay, that's it for now,
about standard function.
Another way to pass functions
into other functions
is actually pretty widespread
in the standard library.
The standard algorithms pretty much
all take their arguments this way.
So, instead of having an alias this time
we are just going to have
another template parameter.
This gives us some flexibility,
because we've erased wrappers,
we are
kind of locked in into
having either value or reference wrappers,
kind of, because it's
not really true, but,
it looks less,
here we can specify
anything, so we can say,
comparator ref ref and it will work.
So.
Assuming the person implementing
do if true knows what he's doing,
so namely he uses invoke,
all the things we tried before will work.
So, this will work, this will also work,
provided invoke is used.
This was work either way.
So, how it works, you
probably know how it works,
generates a new function
for every different thing
that's passed into this function.
So this case,
we can actually do some more deduction.
So as we are deducing the argument type
and not the call signature itself,
we can,
knowing the arguments,
we can find out what the return type is.
So for example we can write
something similar to this.
Is very much like the,
is very much like the deduction
we tried with standard function,
only this time we have three
arguments, not two, okay?
Actually this should also say
standard invoke, but, whatever.
This is template, so you
could also do some funky stuff
to try to deduce the arguments themselves,
but let's not go into that.
You can, in some cases,
but let's forget about it for now.
So, deduction isn't always your friend.
Say we have a function like this,
and we have an overload set like this.
We cannot call foo with an address of bar,
because the compiler doesn't
know which bar we want.
If foo specified what function
pointer type it wanted,
this would have worked,
because function pointer,
like, conversions,
not conversions, taking
an address of a function
is the only place in the language
when information flows backwards,
so context of the expression
actually changes what
the expression means.
So we can write something like this,
which will give us the
first overload of bar,
but this is not very nice, right?
We are back to we cannot deduce anything.
We can write this (chuckling).
So,
how many of you like this abomination
that's on the slide right now?
No hands, good (chuckles).
There's been a proposal a
while back with some revisions
that would say the thing on the bottom
is equivalent to the thing above it.
So just passing overload sets as,
as objects.
It's basically a way to
generate the lambda above.
So,
as I said, the proposal had revisions
but the authors of the recent revisions
are not very eager to
actually pick them up
and go back to the committee.
I plan to do this in some time,
but I don't know which
meeting that will be for.
Maybe the next one, but I
don't think I can make it.
But this would be nice, right?
Alright, so, code bloat
is often an argument
against templates, right,
and we are generating a
new function for everything
that we pass into some other function.
This allows the compiler to do more,
because the compiler knows
exactly what's going on,
it can inline more aggressively,
optimize more aggressively,
this is why standard sort
will often out-perform,
like, qsort from C.
But we pay for this by
making the binary bigger.
Often this does not matter at all,
but there are some environments
where this is going to be
a problem if you use this
technique extensively.
And, actually
this little guy on the bottom here,
while we are at compiler optimizations,
carries more information
than a function pointer.
This lambda can be
expanded into just a call,
and it can be inlined.
If we pass a function pointer,
then unless the compiler
does some devirtualization weird things,
then it's not going to be
able to actually inline
the function.
Alright.
So, with template arguments,
generally we only get static polymorphism,
which works only at compile time,
and if you need runtime
polymorphism with this technique,
you are going to have to
wrap them in a function,
like a standard function.
But then we are kind of losing
the deduction is your friend part.
Because suddenly we have
to spell everything out
because the compiler is
not going to figure out
what is the call signature of the thing
that we are hiding behind
the standard function.
This should not be a surprise
to anybody using templates, right?
Now, if we want to
constrain the signature,
this is also not going to be pretty.
so we have this function, still the same,
and we have some foo, which does nothing,
takes no arguments.
Clearly our intention is that do if true
should not be callable
with foo as an argument.
Clearly, right?
And if we just call
this function like this,
then the place where we
will get a compiler error
is inside do if true.
which makes it not
detectable at compile time,
which means that nobody can SFINAE
on whether he can call
our function or not,
so what we will do first
we need to make some space,
and then we are going to put
some crazy template things inside,
I hope this is correct,
because I copy-pasted it
from somewhere else (chuckles).
So we are checking whether we
can convert the return type
of this function to the one we expect.
Actually, R should be bool,
Yeah, sorry for that.
As I said, copy-pasted
from somewhere else.
Because I want to never have
to write code like this,
like, I like writing templates,
this is not the kind of
template I want to write.
So this is crazy, right?
Concepts help a little bit,
we'll see how much they help in practice.
But they certainly make this
code slightly more manageable.
Alright, so at this point
we are past the standard directory
and we are
somewhere else that might sometime
be acquired by the standard.
Function ref.
The name suggestions is a
function and also a reference,
and that is the point,
we want to pass something
that's callable as a reference
while also keeping the information
about the signature and so on available.
So, looks pretty much
the same as function,
so we just replace name,
everything's alright.
And again, we can call
this function like this,
this also works, this also works, great.
So what's actually the point
in how it's implemented?
So the answer to the second
question is type erasure,
again, because how else
are we going to do this?
And we are actually going to go
with the second implementation of function
and kind of morph it into a
definition of function ref.
So the first thing we need to
change is the name, obviously.
We had the invoke function pointer
which did the hard work for us,
this is going to stay the same.
We had the unique pointer
to void, with some deleter.
This is the part that's going to change.
We don't actually need a unique pointer,
we can deal with just a void pointer.
We had the call operator,
well, it used the data pointer,
it used to be a unique pointer,
now it's just a raw pointer,
so we can just remove data dot get.
That's nice.
Then we have the constructor
which used to look like this in function,
and oh, of course I didn't
change that class name
of the name of the constructor.
So there is actually two differences.
One of them is how we initialize data,
and the other one is how
we take the argument.
So, in function we just
grabbed the value, right?
In function ref, we are
going to take a reference,
because that's what we want,
we want a reference to a thing
that actually exists already.
And then instead of
using new to initialize
a unique pointer to hold our data,
we just save a pointer to the
data somebody passed to us.
Just grab the address,
and everything else is exactly the same.
So,
function ref is a reference.
References have this
problem
of lifetimes.
When you pass something by reference,
it's take my word
that this thing is going to be alive
for as long as you need it.
This is what the reference means.
It's easy to pass a temporary object,
that was kind of intentional,
due to something, due to the next slide,
but it makes it easy to
write slightly incorrect code
in some cases, we will come back to this.
So, when you have function ref,
you have to either then save it,
or tell the user hey, you better remember
that the lifetime of the
reference you are giving to me
is going to be longer
than you might expect
from just looking at the code.
And otherwise we get dangling references
which is just a bad thing, and,
especially if you ever had to debug,
like, code that heavily used futures,
and somebody made a mistake
of capturing a thing
by a reference instead of by value,
debugging that stuff is going to be pain.
I've done it, I've made mistakes
like this, I know the pain.
So, my opinion here is
that we actually need
core language lifetimes.
I think that we need a
core language feature
that tells us what the
lifetime of this thing is.
Library features I don't think have it.
I think it's the compiler that
must actually do the checks
whether we are doing something illegal.
This would of course be optional, right,
but I think we need this thing, so.
But please, please, please
make it look slightly better,
and in general be more
manageable than in Rust.
Because Rust lifetimes, I
don't know how many of you
had the pleasure of working with them,
are not very great.
Yes.
- [Man] Is there any way
for user of that rvalue
of references from the construction?
Is there a way to prevent rvalue
of references from construction, yes.
But I actually don't want
to do that (chuckles).
Okay.
For reasons
that I have on slides later on.
Somebody want to disagree
with my comment about Rust lifetimes?
Good (chuckles) okay.
So,
function ref forces reference semantics.
This is the same problem
as on the previous slide,
just it's the flip side of it.
And, this means that
it's not very easy to pass
copy of the value that we have.
If we explicitly don't
want to pass the object
we have just a copy.
We know that in a given case it's safe
and we want to pass a value.
There is no easy syntax to do this.
And this is why I support
rvalue references there.
So I have a function ref,
and I have some callable,
and I want to pass a copy,
this passes a reference.
This will pass a copy,
but at the price of having
a separate statement, right?
That statement might be
like, completely disconnected
from the code that uses it in some cases.
What I would ideally like to be able
to write is something like this.
Look at the comment, we can
already do this in one context.
You can say new auto, and
with a single argument,
this expression will deduce
the type it has to allocate
and initialize and give you a pointer to.
But we only have it there,
as if new was something that
we were using frequently
and needed this feature for.
I think this is a place where we more
need this type of deduction
than anywhere else.
- [Man] Do you know if there's a rationale
for why we don't do that?
Do I know if there's a rationale
for why we can't write this.
I had a discussion with
Ville at some point
about this but I don't remember
if if there was rationale,
I think it was like nobody thought of it.
Yes.
- [Man] It maybe have free-function copy.
Can you,
And work here.
Can you, the, closer.
- [Man] You can have a free-function copy.
Yes, I can have a free-function copy,
but that free-function copy
is going to be a template,
that template is going to be associated
every time I call it for
difference arguments,
and as one of our friends who
is here at the conference,
I don't know if in the room,
is going to teach us in
some of his presentations
creating an instance of a function
is one of the most costly things to do
at compile time.
Of course you can do this,
whether you should depends on how long
your compile times are right now.
Alright, so this is the
part of the presentation
where there's a lot of
text on the slides but not
really much code,
so brace for it.
There is a bunch of my opinions
that I know some people don't share.
I propose that
whether we care about ownership
depends on the kind of a function
that we are working with.
This is what I was
talking about previously,
and this goes back to the first section,
to the example with, like, accumulate,
with dot thens inside.
We have two different kinds of functions
that we pass other functions into,
generally speaking.
We have synchronous functions,
which are going to fully
execute below our context,
and
they don't save anything
that we pass to them,
so we can pass references,
we can pass references to temporaries,
and nothing is broken,
which is why I also want to support
rvalue references for function ref.
And there is asynchronous functions
which are probably going to
save the callback we gave them.
So, for synchronous algorithms,
whether we have value semantics,
or reference semantics, doesn't matter.
Because the lifetimes are
not going to be a problem.
For asynchronous functions,
reference semantics
can lead to illegal behavior.
That means dangling references.
Can.
But,
will not necessarily lead
to the undefined behavior.
If we can guarantee that the thing
that we are passing via reference
will be alive for the entirety of time
it needs to be alive
for, everything is fine,
we can pass via reference, it's cheaper.
We allocate less memory, we,
don't have to copy stuff around,
and so on and so forth.
So, for synchronous algorithms,
we will generally want to benefit
from the performance
of function ref, right?
There's not reason not to.
For asynchronous algorithms,
we as the caller,
would like to be able to specify
whether the thing that we are working with
is going to outlive the
asynchronous context or not.
The author of the API doesn't know.
He doesn't know what we are
passing into his function.
We know how long the object
we are passing in is going to live.
So, it would be better if
we could make the decision.
So yeah, so I propose that the decision
of value versus reference semantics
should not be tied to
the algorithm itself,
it should be tied to the way
the algorithm is invoked.
That is my ideal way to write
code that takes functions.
And other contexts, too, but we are mostly
are talking about functions
right now, so let's stay there.
Although, of course, an algorithm
should be hard to use incorrectly,
so the default should
be the safe behavior.
We should have to explicitly
say we want the thing
that is potentially unsafe.
This is general guideline, right?
However, if we have two
behaviors that are correct,
so neither of the
semantics will cause bugs,
and we can guarantee that,
this sentence might look
and sound complicated,
but I think that the
default should be the one
that is harder to use
when it is not a default.
In other words, the behavior
we have to opt-in into
should be the one that
is easier to opt into.
So, opt-in pass-by-value,
that is pass me a copy into this thing,
and by default pass a
reference is harder, right?
We saw that.
It would be not much harder if we actually
had the out-of thing or if
we can pay for copy function,
that's instantiated for everything,
but generally speaking,
you have to spell the name
or use decltype to construct the thing,
or use a MACHO, oh no (chuckling).
Although when we can pass-by-value,
we can very easily pass by reference too.
There is a little thing
that everybody hates
that called standard reference wrapper.
How many of you like
standard reference wrapper?
(chuckles)
Can we like,
half-raise our hand?
Can you half-raise your hand,
yes you can half-raise
your hand (chuckles).
(man laughing)
Alright (laughs).
So standard reference
wrapper is a weird thing.
It's a reference, but
it's not a reference.
It looks something like this.
So we have a constructor,
we can construct it from an lvalue
we cannot construct it
from an error value,
which kind of again goes
back to your question, right?
We can get a reference, it's convertible
to a reference to T,
and it also has this one little
curious operator down there
which is only present when
you can actually call it,
so it's SFINAEd away.
It's a call operator, I actually
didn't know that existed
in reference wrapper,
like a couple of days ago,
Matt told me that it exists.
I was like, wow.
So,
the way to create a reference wrapper
is call a function called standard ref,
which is easy.
It's short.
So this code compiles and
works the way it should.
But there is a kind of
big thing going on here.
Standard function is
a pass-by value thing.
Except, it's not.
Because we can create
types that look like values
but behave like references.
So, I have one problem with this.
Namely, it's still a standard function,
it's still going to be as
expensive as standard function.
We have to copy the reference wrapper,
we have to allocate memory for it,
we have to store it.
What if we could do something different?
So this is function.
This is not function ref,
we go all the way back to function.
This time I call it my function,
because it's how I would like to have it.
There's one thing missing,
then that one thing missing
is a constructor
from a reference wrapper.
So when we construct
from a reference wrapper,
we can again save the address,
just like in function ref,
and we can set the deleter to do nothing.
So if we are given a value
we allocate memory for that value,
we save a way to deallocate the memory
and free the resource.
If we are given a reference wrapper
which is a value meaning a reference,
we just save the address
and don't free anything in our destructor.
And invoke is exactly the same,
because it's the same thing.
Makes sense to everybody?
So we've saved again like
a pointer indirection,
because reference wrapper
what it actually is
it's a pointer, so if we allocated
a new reference wrapper and went for that,
we would have to go for another pointer
to get to the thing that we want.
In this case we just save the pointer.
And saved ourselves a pointer dereference.
And saves ourselves a memory allocation.
At the cost of like, a function pointer
over a function ref in space requirement
because the unique pointer here
is going to store a function pointer
so that's the one thing more
that we have over function ref.
So, if I use my function
instead of function ref,
I lose some information.
If the user is meant to
pass me the same thing,
I lose the information
of this as a reference.
This is kind of dangerous,
but as long as we document
exactly what we do,
and we assume that our
user is not an idiot,
then everything should
be fine (chuckling).
I know it's a big assumption, yes, I know.
But if we use my function
instead of standard function,
we don't lose any information,
because standard function
can already hold a reference wrapper,
only slightly less
efficiently than we do here,
so, not a big deal.
So it can lead to more subtle bugs.
So we can more subtly
point to data that we
shouldn't be pointing to.
But the thing is,
now that we don't pass
anything by reference implicitly,
we always have to say std ref.
Suddenly the caller side
that uses our API
explicitly says I am passing a reference.
So while it can lead to more subtle bugs,
especially if we throw
the function thing around
and we don't exactly
know where it came from,
we kinda have a problem, but,
on the caller side,
tracking bugs like this
should be kind of easier.
Because we see oh, I am
passing via reference,
what am I thinking?
So this is kind of a double-edged sword,
we can cut ourselves, we can
kill our enemy, (chuckles).
We have to be careful, but
every time we use references
we have to be careful, right?
Every time.
So I like how this works.
Yeah, and this problem we already have
with standard functions since
we already can pass std ref.
Okay, so,
one last unique point
is that my function
doesn't actually require copyability.
Because I don't have a copy constructor.
I don't need that.
This is what I want in many places,
like when I am implementing a future
which is a dear and close topic to me,
I don't want a copyable thing,
because sometimes somebody
will give me lambda
that captured a thing that's
not copyable by itself,
I don't want to have to invent
a new type to deal with this.
I mean, I kind of already
have it on my slides, right,
but I want the standard to have it, too.
And there's nothing in the standard,
currently, that does this.
But there is a paper,
P0288, right, yeah.
A polymorphic wrapper
for all Callable objects,
which proposes unique function
which is exactly this.
It's, again, by David Krauss.
Alright, we are coming to the end,
and somehow I made it on time.
Alright.
So some takeaways, some of
them were spelled before,
some of them I am spelling right now.
When you have static polymorphism,
you can implement static dynamic
polymorphism on top of it,
but not the other way around,
not the other way around.
Some people forget about this.
Slap dynamic polymorphism
everywhere without thinking.
Sometimes it's better to
have like static polymorphism
by default and then for some
cases use some hierarchy,
or a value semantics wrapper
for polymorphic things
as the fallback.
We can mix
polymorphism types, especially
now that we have variant.
If you don't require runtime type erasure,
don't use type erasure,
just use template arguments.
Function ref is nice
when we want just to say
this is only a reference,
it might be in your best
interest if you don't store me.
It's completely fine for those cases.
Std function looks like
it says this is a value,
but that's a lie.
Even if reference wrapper didn't exist,
like implementing reference wrapper
is five minutes of writing code.
And that's mostly SFINAE
for the call operator.
The thing that I did
with the unique pointer
and sometimes making
the deleter do nothing
is what I like to call
ownership erasure, because it,
we are not only erasing the type,
we are also erasing who is
actually the owner of the data,
and it gives you the same semantics.
If you are already
supporting reference wrapper,
which standard function implicitly is,
then this might be an nice thing to do,
to reduce the number
of allocations you do,
to reduce the number of
pointer indirections you do,
and so on.
It's way more scary in some other cases,
so if you are implementing
like a generic value
semantics wrapper over
a polymorphic thingy,
this is way
more
scary.
But I still intend to
use this in some cases
where I kind of have a variant
of a raw pointer and a unique
pointer, this is exactly this.
Standard functions requires too much,
and I hope that unique
function lands quite quickly
because I have many use cases for it.
There are some links,
you probably can't copy
them quickly enough,
they are going to be in the slides
that will be in the GitHub repo.
The first two are the
standards proposals, p0045
is again a qualified
call signature thing for
standard function, p0288
is the unique function paper,
the third link is Vittorio Romeo's
blog post where he like does a quick thing
with implementing function ref,
calling in function view,
and does some benchmarks comparing
how it fares against standard function,
and the last one is a
draft of a proposal
for function ref, also from Vittorio,
this time with the proper name
that doesn't look like it's a range,
so expect this to be coming soon
to a standards committee near you.
And that's all I have for you,
if there is any questions,
come on to the microphones
and ask them, thank you.
(audience applauding)
- [Man] I think that std
function uses the small buffer
optimization so there won't
be any memory allocations
when you use it with
the reference wrapper.
Std function uses small
buffer allocations,
it probably does in some
implementations, yes, but,
you are still going to pay
for the pointer indirection.
It's going to be in the same cache line,
so it's not going to be as bad,
but it's still going
through all that, yes.
- [Man] Hi, thank you
so much for the talk,
I did something similar in my company,
and I had a question, what was the,
the idea behind not copying?
Like, I used a basically
similar implementation,
but a shared pointer only when you had,
like an rvalue, like
anonymous lambda type.
So you would store that
in a shared pointer
which could be copied, otherwise
you just had the invoker
for the member function
pointer and non-member function
(clears throat) 'scuse me, pointer,
I was just kinda wondering
what was the idea there?
Was it just a performance issue,
and you need to copy?
Can you,
can you reformulate the question?
- [Man] Basically, what was
the idea behind not copying
and using a unique pointer,
versus say, like a shared pointer
where you could copy the object across.
Oh, so shared pointer
doesn't actually implement
copy semantics, it makes your function
be a reference to its internal data,
which is
Right.
kinda, it depends on your use case, right?
Sometimes that's going
to be what you want.
You want, sometimes you will want function
to be like a shallow handle to
some data sitting somewhere,
but that's not what I usually want,
which is why I'm using
just unique pointer here.
- [Man] Got it, thank you.
- [Audience Member] Have you
actually done any bench --
Can you, can you?
Yeah, have you
actually benchmarked the
speed of this technique
with my function versus
what standard function does
with virtuals and the
small buffer optimization?
I mean, you're claiming it
could be faster, 'cause it --
Vittorio has benchmarks
for function reference
versus function pointers,
for versus std function,
and this is pretty similar, right?
This just, this is, my
function is a function ref
when you pass a reference wrapper,
and is a std function
when you pass a value.
- [Audience Member] Okay.
Alright, if that's all,
then, thank you very much.
Thank you.
(audience applauding)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>