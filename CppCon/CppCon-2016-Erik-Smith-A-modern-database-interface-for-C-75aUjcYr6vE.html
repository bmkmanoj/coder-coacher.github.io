<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: Erik Smith “A modern database interface for C++&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: Erik Smith “A modern database interface for C++&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: Erik Smith “A modern database interface for C++&quot;</b></h2><h5 class="post__date">2016-10-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/75aUjcYr6vE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks for coming to my talk today I'm
going to talk about modern database
interface for C++ my name is Eric Smith
so first of all why do we care I'm going
to try and boil this down to just two
data points is there a lot there are a
lot of reasons why me we might care
about this they're probably pretty
obvious but I just I'll just put these
two data points so if you think of a
database like sequel light sequel light
is installed on every smartphone in the
world I tried to Google what that number
is but I have to think it's in the
billions at this point so databases
literally are everywhere and I'm sure
probably everybody in this room has
probably encountered a database if not
on every project at least on many of
them so they really are everywhere a
second data point is has to do with JDBC
so and this this talk very much is about
that layer of the stack which I'll get
into in a moment jdb JDBC was introduced
in 1998 and I think a large part of the
success of Java and its domain has to do
with the fact that you get that
connectivity very easily and here it is
2016 and we do not have a standard
interface it's not that we don't build
databases with C++ it just isn't
something we the standard doesn't help
us at all here so I did not name this
talk a standard database for C++ because
I think it's going to take quite a bit
of time to get a standard push through
so I'm just gonna call it a modern
interface I just want to acknowledge
some previous repose to work in this
area by these individuals and I have
read them and there were there are
points from each of these that I have
taken so credit to them so just a little
bit of a primer here for those who may
not be familiar with this this is just a
quick picture of the relational model
this is a type of structured data that
you get out of a database and it's
it's really straightforward you just
have columns that define a datatype per
column and the rows so this is a type of
structure information stored in the
database it's also the same structure
that you get back from the client api's
as well so this is this is what you'll
this is what the type of data that this
interface is designed to work with that
the second item on the below that is an
example of a sequel query which I'm sure
no doubt probably all of you have worked
with this is an example of a text query
that you use to pull data out of a
database and for the purposes of the
interface which I'm going to show today
I'm gonna call this a row set just
because that's how I've named it so
let's take a look at the client stack
for this for a moment that the areas in
blue are really the areas I'm focused on
and I talked about what this talk what
the focus of this project is and what it
is not so I know that there's a lot of
existing work one particular project
there are a couple projects that are
focusing a higher layer of the stack in
addition to the layer on focus focus on
which is like Roland's CCPP project I'm
focusing on the driver layer itself and
I think the main reason for this is I
think this is a really necessary
foundational layer for other types of
interesting work to be built on top of
and there's just a lot of details to get
right in this layer so it's really a
project in and of itself just to
describe a little bit of detail on this
stack you've got application code which
can either be built directly on top of
this interface like it is some in case
cases with JDBC or you can have an
ecosystem on top of this layer which is
where other things can be build things
just like straight database utility code
on top of it
lightweight Clery query builders or
full-blown or EMM frameworks can exist
on top of this layer now as far as the
layer itself I'm going to describe later
in the talk the design of this layer
because there
a front-end layer which is intended for
people writing user code and then
there's a driver layer in which you
would want where you be interesting that
if you were implementing a particular
database driver and then on the bottom
we just have the client interfaces for
the various database drivers sometimes
they're written against those interfaces
sometimes they're written against just
plain sockets if the protocol for the
database is known there's other options
for the future such as fibers and
co-routines so just to get into it in
detail here I'm I'm going to show you an
example of what this is and the code has
been I this is not just this is code
that I have that's working so I've given
the examples I've in this talk some a
bit of time to ensure that this is
actually a workable interface although
there's plenty of work to be done but
this this needs to be an easy to use
interface first and foremost so I hope
that what this conveys is that it's it's
a pretty easy interface to use I don't
want to sacrifice any functionality in
favor of that but we'll get into the
functionality as we go through the talk
so a couple things to notice here
there's no explicit types mentioned here
so this is this is using that the
chained call style which I'll talk about
in a minute but it's I think this lends
to a very succinct and compact style now
a few other details for that example
that I want to throw in here is that you
would have to have a and include and you
would want to alias a namespace so when
I talk about this being a standards
candidate I don't think we're ever going
to see actual drivers in the vendor
implementations that doesn't seem likely
to me so the idea here is you'd want it
to be as to seem as uniform as possible
so the way you can do this is including
a header for your particular
implementation which may or may be
provided by the compiler but I don't
think so and then just create an alias
Elya so that you have consistency among
your interface if you want to switch
vendors you can do that when I say
vendors I really mean open source
efforts and that's what this is this
particular effort is a reference
implementation for the interface I'm
proposing
so without addition you have a fully
working example so a little more on this
style of interface this is a composable
interface it's using a classic method
chaining approach which is really been
around for a long time and this I'm not
sure if everybody likes this but I think
it's I think it's it's a it's completely
appropriate for this particular model
and I think it has a little recent
support added to it with some of the
proposals for uniform function call
syntax so that would suggest so there
are people on the committee who like
this style and and want to promote it
with this kind of work now this this
isn't has made in the standard but
yharnam South has supported that
proposal so and that's a proposal where
if a method call fails to resolve it
will call a non-member function so you
can retain the chaining call and not
have to have everything be a member
function although most of the ones in
this core interface are one thing I
should mention here is that all of the
examples here until later in the talk
our direct interfaces by that I mean
that most people when they implement a
database are just coding against one
database and if that's all you're doing
you should be able to do that without
going through our extra layers of
indirection and that's supported by this
driver you can either say I'm only using
my sukul or only using sequel Lite or we
as we'll see you later in the talk you
can you can access a poly interface
which is the exact same interface but
allows you to resolve to a particular
driver at runtime so let's look at the
various types in this interface and
these should be pretty familiar to
anybody's who has used any type of other
library that's it's they're all fairly
similar in the end the types I declare
and database interfaces are all about
managing resources so each one of these
is paired with a resource that needs to
be managed on the client layer so just
going through these pretty quickly
you've got the database which is a
top-level context the connection is
maintains a connection to the server
these are all REI I type interfaces
statement for query execution primarily
statement not only manages things behind
the scenes but if you need prepared
statements that's which that's why
you'll need a statement column set is
from for metadata for columns a column
is of specific metadata for a column or
metadata for a specific column the row
set that's the primary data structure in
this API that is probably most important
here a row accessor is just a particular
row within that row set and field now
these last two do tell us two objects
are proxies and we're gonna we're gonna
get into that what that means so just
just to break this out a little bit more
so you can see that the types more
clearly this is the same example but
just in a more classic form a non
chained form where you can see each of
the individual types in action here
still not having to refer to the types
but in this case you can see a broken
out you can see clearly the database
being connected to or the database being
created then the connection then the
query then the rows and then just a more
C++ 98 style of for loop a little bit
about the methods here so I think
there's I've actually have two styles
here one is what I'll collide by type
name and this is where the accessors on
these class refer to are just analogous
to the types themselves so if you if you
want to connect if you want a connection
object the name of that access ER is
just connection versus a natural style
which is more like a noun or a verb
where you say connect query rows I
prefer the natural style but I can see
use cases for both so they're both in
the interface at this point now maybe
somebody will come along at some point
you must choose between one or the other
but nothing here standardized for so for
every I'm keeping options open here just
by having both of these available this
interfaces should be flexible so all of
these statements are equivalent so one
of the things I mentioned that this
design has a front-end layer and a
driver layer the front-end is common to
everything and is not is not anything
anybody needs to extend the driver
layers where the extension is done so
because of that design it's easy to
achieve this what I mean by this is that
if you want to query something you can
do it from the database you can do it
from the statement you can do it from
the connection all of these are ok so
this leads to a flexible style in which
whatever object you happen to have at
the time if you want to do a particular
operation that makes sense you can do
that and it's hard to get wrong ok so
one thing I should mention here is all
of these objects are what I call
reference types and what I mean by that
is they're all holding standards shared
pointer to internal data now this if
you've tried to hand roll your
interfaces before you may have not have
seen this detail you don't actually need
that if all your example such as the
ones that we've seen on the previous
lights are all nested within the same
scope there's no need to have a smart
pointer in this context but as soon as
you get to a use case where you have a
let's say some type of utility function
where you want to pass in some some user
data and you want to get a row set out
of that now it makes total sense why
they should be reference types that are
that you share pointer and the reason
here is that you'll notice inside of
this utility function I'm creating a
database context and implicitly getting
a connection via this query accessor and
then I get the row set as well and
unfortunately missing a return statement
in there but there should be right at
the DB line
this is going to return a result there's
nothing wrong with this it's it's safe
to do this because the rosette is going
to hold the state information it needs
until it goes out of scope so this and
this would be the kind of thing you
would do when you reach a certain design
level in your application you want to
design for this so therefore they hold
reference types and don't think that
impacts the performance at all however
there's also a policy capability the API
if you really if you really care about
that you can specify a policy not to do
that okay so I'm gonna go through a
little more detail in each of these
layers to give you an idea about what
they're supposed to do and these are
just certain examples this the database
is a top-level object and it's a context
object in some cases that manage your
resources for the driver in some case
there are no resources to manage
depending on the database driver but it
does things like it's gonna get
connections you if it if you specify at
the database layer a URI then when you
ask for connections you do not have to
specify it it will has a notion of a
default URI which just makes it too
convenient in your code to not have to
litter your code with a bunch of
connection strings everywhere it also
has the if there's a difference between
connection and create connection most of
time you just want a connection but
there are some contexts in the presence
of connection pooling where you want to
actually ask for another connection not
the same one handed to you based on your
thread ID so that's what's creates
connection for and we'll see an example
for that the talk so that's what this
does but also mentioned before if you
want if your use case is simple in fact
if you you're you're executing queries
that don't return results you should be
able to just execute that query straight
from the database object and you can do
that a little bit on connection strings
it's just using an URI syntax this is
something I've seen done in other
database drivers and it seems very
reasonable to do this you just have the
name of the driver at the top like in a
URI syntax colon slash slash the server
the Debian and some
these details will be specific to the
driver but there is some some overlap
between all the drivers that would make
sense you can also specify a name source
which and this is just an extension
mechanism in the framework to say hey I
want to name my sources and I want those
sources to be looked up in a config file
and rather than specify exactly what
that should be
that's simply a hook you can extend for
if you want it to look for some you know
any format in some location within your
application or in your home directory
all of that's possible through an
extension and that's through a custom
resolver connection connection is where
there's two things you can do here and
this is true for the API if at any point
you have an object and you want to get
the parent object that's always a
possibility so if you were handed a
connection you need to get the database
just say dot database the other thing
that the primary responsibility of a
connection is transactions so there's a
bunch of transaction calls here that you
would expect if you're familiar with how
transactions work in a database ability
to start a transaction do a set of
operations and then commit them
checkpoint them or rule them back this
is something that you can do if you have
a feature called scope exit and this is
not in the language so I only mentioned
it briefly but there is a proposal to
add this and this just allows the
ability to define a scope within your
function that causes these the
statements within the scope to be
executed upon failure so again this is a
really nice thing I'd like to see added
the language and you'll see that in a
couple sites of the talks of things that
I think need to be there that would be
great this drastically simplifies
complex transactions in which you have
to manage state carefully the statement
object this is primarily again needed
for prepared statements and I'll have an
example of this a little bit later but
essentially a prepared statement is is
when you're going to execute the same
statement repeatedly and you want to
save the work of
your driver layer or database to have to
repeatedly parse the query you want to
to do this outside of a loop your
program at a higher level say please
prepare this query and then you use
statement execute to pass it parameters
and these parameters correspond to the
question marks so so the work of
preparing the query is down front and
then you and then you pass parameters
and that can be a big performance
improvement so that's a primary role of
a statement object okay now we get to
the row set so the minor accessors in
this row set are things like Rho dot
width which would just be the number of
columns if you you know it's a useful
thing if you're trying to loop over it
rota columns returns column metadata so
that you can get the names of the
columns row dot length is the number of
rows and your result set and this would
only be defined if you actually read all
over the results or if you had some type
mechanism that was materializing them up
front but I still have it in here just
to have a general notion of what a row
set can do so the big question here is
what about row traversal and this is a
really important aspect of the API is
how are you going to iterate over the
data and there's a couple approaches
that have traditionally been done that
are in existing libraries things like
next and done where you say give me the
next row check to see if if there are
any left so I've got a couple options
here that the front pop up front and
empty our notion of ranges that you may
see in other languages well in C++ we
have iterators so why not iterators well
this this is what we use is iterators so
in this particular case it's input
iterators this is a weakest kind of
iterators but I think completely
appropriate for this type of interface
because in virtually every interface
what you're doing is just stepping
through the results one at
so you can only go forward and you only
have access to the current result so the
big enabler here I think the big win is
that now you can use this with range
based for just like that and here's an
example so I'm creating a database I
immediately get the rose from this query
and I go straight into a range based for
loop and it just works and so this is I
think matching most closely what you
would expect from an interface and C++
in terms of matching features it makes
it really easy to use in the way that
you'd expect so in fact it's even better
than that because I think if you've seen
some some talks by STL he recommends it
with range base for that you do auto ref
ref because in many cases if you don't
do that you've got an expensive copy
that you may be able to avoid if what
you're if the container you're iterating
over is actually returning references
this interface uses proxies so what's
returned from a row set is actually a
proxy object and that's going to create
a few issues but for range base for this
actually is a win so if you do the thing
which you're probably most likely to do
which is not our reference just playing
Auto it's fine it's since it's a proxy
doesn't matter if it's copied or you can
just take the advice and use the auto
ref ref also fine and of course taking
just a single reference either constant
nonce constant make sense in this
context which is totally fine there was
a proposal by STL to actually eliminate
the auto altogether and that's that was
discussed but I think that's going to
come back at some point in a different
form and that would also be nice here so
you may be asking yourself well okay it
arrays are great but is that going how
much overhead is that going to add to
the cost of the interface and because
these are input iterators it's actually
not down bad now there this is
and you know a subject of discussion as
well see but it's really pretty light
for input iterators and you can see
right here there is there's a runtime
cost of doing this because you don't
know which iterator you're gonna get in
which order and all and these checks
have to be done to run tight but it's
not as bad as say with Ford iterators so
this to me is is okay I don't think it
actually matters that much compared to
the other costs that you're that you are
likely to occur overall in a database
driver so what else can we do with this
iterator design well you can here's an
example of a standard library algorithm
just in this case find if and you'll see
here there's a typo it should say RNG
I'm getting a range from the query and
I'm passing it to find if and it just
works so this example is looking for a
key within the result set and returns an
iterator to that row on the first one it
finds so this is this works exactly like
you would expect except now we're doing
in the context of database code so we're
able to leverage standard algorithms
which i think is just great here's
another example this one with just
happens to be the cumulated you say you
want to do you want to accumulate a
score on the client side you can use
accumulate now this is probably
something that databases do really well
with aggregation but for the purpose of
showing another algorithm that would
work here this is it so there still are
issues with iterators that need to be
considered and it's not so much with the
input iterator but there are use cases
in this design for other types of
rosettes in particular stronger sets
like full random access Pro sets so you
can imagine maybe you you want to read
in the entire row set instead of just
having to buffer it for every each time
and we're going to talk about that
optimization but there
this is something if in more complex
types of iterator models theater issues
iterator issues really start to show so
the answer to this is ranges and and I
assume that you've all probably heard of
the range proposal by Eric Kneedler but
this is really a phenomenal piece of
work I think it's really impactful for
the way we're going to write code in the
future even though I think it's quite a
ways away it's usable now and I just
think it's going to it really effects I
think how this interface can work with a
standard library so I definitely
recommend checking it out it's going to
it basically addresses the existing
issues with iterators particularly with
composability and brings a whole class
of functionality and I'll show you an
example of that so just to give you a
sense for how this would work with that
proposal a row set is an input range and
so a row set there's a couple of
concepts in that standard which define
classes of access for whatever you're
particularly working with and the way it
maps here is an iterable concept is
simply anything we're beginning and is
defined it turns out that I don't
actually need to expose that in
isolation because row set is both an
editable and a range so if you think of
a range a range object which in this
case is the row set has a begin and end
so that works the range based for it's
also lightweight in that copying is
cheap it doesn't own the elements and
it's default constructible caught people
assignable indestructible so it actually
serves both of those purposes which also
further simplifies the use of the API
and then on top of that if you think of
these stacking it's also an input range
so it does map perfectly into that
proposals notion of concepts and how
works so based upon that proposal how
would things change the first thing I
want to show you is an optimization so
the first operator compare this is for
iterators within row set the first one
is the one we had before and you can see
it has a certain complexity if you're
using ranges then it collapses to the
one below so that's a little bit more
efficient the reason it's able to do
that is because it's it knows a
compile-time
how to compare the iterators and the key
thing which I which I didn't mention
here is the key thing within ranges is
that a begin and enter it end iterator
are not required to have the same type
in fact if they have different types it
allows a compiler to see in the code
that you're trying to compare an
iterator to an in condition and that
eliminates branches in the code and
simplifies the comparison so so you get
some improvement from there but that's I
think really maybe the minor benefit in
this case a little bit better benefit is
that with the composability so
everywhere where you would pass a
beginning in you can now pass just a
single range object which in this case
is just the row set so what I did in
this case is I just put it in line you
don't have to do that but it does allow
you to do that and makes the code a
little more succinct and you can compose
the expression as the argument so so
that that improves the use of the
existing algorithms now I think the big
win for ranges is in what's called range
adapters and I'm really excited about
this this is an example of a range
adapter in the ranges library and what
it's doing is it's filtering the
database result but what it's the way
it's doing it is it's fetching let this
the results lazily so if you can imagine
here it's similar to copy of if you have
used that what you're doing here is
you're creating a filter and you're
specifying the input range that you want
to filter on and then
a condition in the lambda in this case
the example I'm giving here is you're
looking for all results that have a
minimum score so it's a fairly
straightforward example this code is
written hasn't actually isn't actually
doing anything the only thing that's
doing is creating a new range which is
going to perform that result so all
you're doing here is setting up the
ability to query and then when you
actually access the range itself then it
executes the query and then it fetches
the elements of one at a time this is
able to do something that you can't do
with the exist that it's doing it lazily
it actually worked so so if you tried to
do this with copy if what you would find
is that it would not work and the reason
is this because copy up is going to
iterate through the results and input
ranges can't it's going to exhaust the
results so if you were to try and access
those copied results later you'd have a
bunch of proxy objects which were
invalid but if you do it lazily it works
perfectly fine so this is actually doing
something that it really isn't possible
with this before and you're getting a
lot of composability benefits so I think
this is just a huge addition to the
standard library and I think it works
really great with this type of interface
for databases so just moving along to
some of the other objects the row object
is simply a way to to access fields
within the row so you dereference a row
set you get a row proxy the row proxy
then can be dereference to get a field
object you can it you can do it by
position you can do it by name or you
can do it by column which column is
another object that comes from the
columns metadata object available at the
row set and then there's the field
object the field object is another proxy
and its primary role is to handle
conversions so if all you did is you
just wanted to send it a standard out
that should be fine if you wanted to do
a conversion to a particular type you
can specify it via as template type T
and all of those conversions are handled
within Slayer and also it has to handle
the case where the way it was bound
by default in the lair may or may not be
the type that you're asking for so all
of those have to be accounted for you
should be able to ask for a variant and
you should have support or optional note
this the interesting thing here is that
the the accessors on their listed above
have the possibility of throwing and
that's because of this notion of null so
the the value that you get back to
pending upon the database may there's a
possibility may be null so you cannot
you cannot marshal into a type that
doesn't inherently support an illness if
if the values actually know so if you
use the access search below such as
variant and optional those are okay
those do not throw and it just means
that if the actual field value is no you
will get that null reflected in the
variant and optional so that's a nice
convenience they have a couple other
accessors you can test upfront whether
it is know the the name and the type are
available at the field level even those
that's metadata that you would normally
get from the column it's very convenient
to have them at the field so that you
also you don't have to work with
multiple objects if you really don't
have a need to so let me talk about
field annex a little bit more so when
you ask for a field by name this isn't
the most efficient approach and that's
because you're having to take a string
and compare it to the to the names of
the column and then return the field if
you use a numeric index is a little bit
more efficient so but that's not as
maintainable so what can you do about
this well you can you can set up code
like this which is if you create index
objects ahead of the loop say idea ID X
name ID X what you're doing is you're
looking up the indexes outside of the
loop and then when you get into the loop
then you can use these integer variables
to index the fields out of that and
that's that is more efficient it's
harder to maintain whether it actually
matters may really depend upon just
how critical performance is for your
particular setup but there may be a
better way to do this and this uses
varied act templates and let me show you
how this works so here I have I'm
getting a row set out of a database and
then what I'm doing is I'm going to go
back inside because I'm out of order
here here is an example of what I call
into so into is a very dag template in
which you pass in the variables that you
want bound to based on the query and
this works when your query is just a
single row and you just want to get
these in two variables with the least
amount of work as possible so you don't
even necessarily want to index set up
the indexing even by name if you have a
query that's this short which is four
values why not just put them right into
the variables and that's exactly what
this does so therefore single row
queries this is a great way to just
achieve that without having to worry
about indexing into the row object it
turns out this also can be applied of
the row proxy object as well so if you
can imagine that you know this this can
extend beyond just a query that returns
single rows it can apply to actually
ones with multiple rows and it simply
means that within your for loop itself
you say row into and the names of the
variables so here I've got an example
where I have a query that may return
more than one result I have variables
that I want to put that data into then I
go into a for loop and on the row object
that I got from the row set I can now
say row into and whatever variables I
put in there whatever type the very deck
template will pick those up and do the
assignment so it's flexible in that
regard to other possibilities here is
that you could use a range you could put
into range so instead of putting them
into variables they could go into a
range and an output range or they could
do that you
either vertically for the whole result
set or by horizontally for a particular
column and there needs to be some work
in figuring out how to disambiguate and
what what makes sense at what levels so
that you're getting what you expect but
that's also a possibility
I should mention serialization here's I
think this is a huge need in the
standard for to have this this ability
to be easily implemented so what I mean
by and I think this is really not this
isn't something that has to be
integrated into this framework I think
it actually sits above this framework
but the idea here is it if you have a
row set and you have an object you'd
like to use some type of reflection
based mechanism to serialize it into
your object and there are many ways that
you could do that with the syntax this
this is something that other languages
have and is is considered just a
commonplace
to be able to do this so serialization
just not only just for data it would be
applied to lots of different contexts
but particularly here for databases as
well as things like flat files things
you get over a network connection so
this is an area that I think really
would benefit by reflection in the
standard just really small feature here
is in some cases you may want to have
access to the underlying handle the
native handle of the driver width in
that's underlies your particular choice
of database and that's what this does so
for example if it does if you say
connection not handle you will get a
void pointer to a my sequel handle and
that maybe maybe that's you for testing
maybe it's useful because you have
legacy code when what you actually need
to get a handle to hook it up to the
interface does provide that capability
but you have to be careful with this
because realizing that this is escaping
the shared pointer mechanism so in this
example here I'm I say DB connection not
handle because it's not returning a
smart pointer that will go out of scope
and you'll have a lifetime fail on that
my sequel pointer so you have to be
careful with that now I want to talk
about a particular feature that moe
strivers offer which is important which
is called output binding so what this is
is that the binding mechanism is is set
up by the driver where you where
internally you declare in a buffer in
which database coming information from
the database goes into this buffer and
that's all managed by this framework you
don't have to ever deal with that it's
never exposed at the user level there's
something called array output binding
which is an optimization many drivers
offer and the way it works is that you
specify an array the size of the array
that you want to allocate for the
results to go into so I'm gonna explain
how this works so let's say you have a
thousand or a table if you did not
specify output array binding what you
would get as a buffer to hold just one
row if you do specify it then it what's
going to happen is it's going to fetch
however whatever size you declare each
time it talks to the database so you can
imagine this is going to have some
performance benefit depending on your
use case so for example here's a case
without any binding here and I've just
measured this for a particular database
set 203 milliseconds and I'm reading
this house enroll table and I'm just
fetching over the results and adding
them so now I'm going to specify a row
array size of a hundred and you can see
right here that it goes from 2 or 3 to
32 milliseconds now that's a hundred
rows for a thousand row table so if
100's good may be increasing it will be
better so let's edit 500 now goes down
to two milliseconds and now let's just
create just specify at the full size I
want a thousand rows which covers the
size of that table now unfortunately
that number there was not updated but
it's something like 500 microseconds
instead of that 2 milliseconds but this
is essentially 400 times faster than the
first case without array binding and I
graph this here of the four data points
and and just to illustrate that how
much of a performance increase this is
that's that's a log scale right there
it's orders of magnitude faster to do
this it's even may even may set make
sense to just create a default in
certain circumstances and in fact row
array sites could be set at the database
level so that you can ensure within your
application that all of your connections
may I have some type of defect default
row set size now maybe this you know
this does cost memory but you know how
to there's I think there's a certain
number in which it makes sense for
probably every application to have this
so that is a pretty dramatic improvement
and all of this you get all of this
without having to affect user code just
by specifying the road race ice on top
of that some drivers also support this
notion of I'll call continuous array
binding where you can say normally when
you specify these column arrays they're
separately allocated but some database
drivers allow you to actually overlay
those those arrays into the same
contiguous memory and so what you end up
with is your entire result set in
contiguous memory and so if what you're
going to do is fetch data from your
database and you're going to spend some
time with it processing it then this
could be an added improvement because
you can get the entire result
along with all the columns in contiguous
memory so this is another opportunity
for improving performance detached
rosettes so the row sets we've talked
about up to now are just forward only or
they are input only one row at a time
but here's a notion where you can ask
for detached rows and when you do this
you get a row set that is random access
so what's happening here is if if you
have the ability to just get the row set
all at once and you can see from the
previous slides that this has a real
benefit because of the performance then
you have some added abilities that come
with this and here again this is why I
mentioned earlier Y ranges plays into
this because now you have a row set that
may benefit quite a bit more from the
capabilities that ranges provides this
detachable row set all
can outlive the other resources so if
you want to take this detachable rosette
and just hand back the connection it
automatically releases a connection all
the other resources associated with it
you can keep it within your application
in a in essentially a long state and
what this does is it enables caching so
for example you can imagine that if you
have a database application and you want
to start you know small tables locally
this is something that will help do that
so just on the same notion I want to
revisit input binding which was
mentioned before just as output what
binding
really benefits from array the same can
be done for input binding input binding
is where you're specifying with execute
variables that are going to go into a
statement such as insert with no results
coming back you can do rate and put
binding with many drivers and that you
it's the same pattern where you say how
how large you want that buffer to be
this also is a huge performance win so
you can imagine the only downside of
this is that as you're inserting
information none of those are being
pushed to the database until you reach
the size of the buffer so if you have an
application where you're not having to
transact a row at a time
you're just trying to stream data its
data into a database as fast as possible
then this makes a lot of sense and every
time you fill the buffer it's gonna
flush out to the database and then keep
writing them locally just a note about
type conversion which I said before the
field object has to deal with a lot of
type conversion details in terms of how
the data was bound internally and what
it is that's being requested and
depending on how those match up there
may not there may or may not be a cost
associated with that if and there's ways
to control that if you know that you're
always pulling things out of strings you
say you know binding everything natively
internally as strings so that there's no
conversion on this end a little bit
about policies so this this design is a
template based design
and that does facilitate the ability to
control certain parameters about how how
things can be controlled to compile time
things like custom allocators connection
pulling things like resource resolvers
there are other possibilities that I
think may be possible as well here such
as if you really don't want the cost of
shared pointer you could specify just
make it scoped that's possible here I
want to talk a little bit about a
utility example here by that I mean
here's something that you can use on top
of this interface which is an
interesting use case so here you may
have experiences this issue before where
databases aren't actually particularly
good at returning hierarchical results
so if you can imagine you have an
inventory and an orders in a parts table
you end up in a situation where you
having to redundantly have column values
because all of this has to be flattened
and the result set that comes back and
part of what this does is address that
problem and the other thing it does is
try to achieve it with high performance
so at this example what it's doing is
its opening a connection 3 connections
database and it's streaming simple
select results on these 3 connections
back to your client and I'll call it a
it's like a client-side join you take
the results coming back from from each
of these tables and you do the joint on
the client side and I'll call it a
natural join because the idea here is
just for simplicity sake just state just
infer how to join this from the collet
keys within there so the ID matches ID
matches from one table to the other and
there are a few caveats as approach the
the overlapping keys have to be ordered
in the right way so that as these
straight these streams have to be
ordered together and what's happening is
it's it's much like a merge algorithm in
the stew
under library is that it's reading the
values from each of these streams and
joining them up and the cost is really
almost nothing and if you do this the
there's no space taken up by it and it
scales quite well and it solves the
problem of having to deal with redundant
data so this can actually be made to
scale quite large there's something
you'll notice that when you get into
very large databases even trying to pull
things out by index becomes expensive if
you have a database that supports index
organized tables or clustered indexes
this can scale to many hundreds of
millions of Records so this is a simple
utility that can be because the
interfaces using iterators using a
container like approach it's relatively
easy to do these kinds of higher level
algorithms on on that there are other
possibilities for joint algorithms more
general examples including instead of a
natural join you could say just have an
order join which takes into account
maybe column conditions specific to what
you're trying to join and the other one
mentioned before which is a much more
general type of joint if you have a cash
result set possibly from other databases
than than the one you're querying on and
you want the benefit of joining with
that because it's resident that can be
built on top of this interface mention
quickly here that we've been I've been
showing examples of a direct interface
which I think most the time is what you
want but sometimes people want to have a
polymorphic interface because their
application has to talk to multiple
databases and that's what this does you
can say at runtime I want to have a
different database on the connection and
we'll give you that and the way this
does design is completely transparent to
the drivers so for instance if you
implement a driver for a particular
database it's available in this poly
interface and this is all done through
type erasure basically the interface for
the driver if you specify standard
database create database you are asking
for the poly driver and this is
something that could potentially be in
the standard
because it's not specific to any
database you get it for free if you want
to look like what it would be like to
add drivers this is what it would look
like you just register them based on the
type so you can say I want to register
all four databases and by doing that in
your code you can now ask for
connections on any of those four I have
a reference information implementation
test suite which I won't talk about too
much doing due to time but needless to
say this kind of a project needs lots of
time spent on running through all kinds
of use cases so I've spent some time
trying to build out a test suite that's
going to cover all of these and verify
that they run for every driver not only
direct motive but also polymorphic mode
so just briefly I'll talk a little bit
about the implementation and a
implementation detail not all of them
but as I mentioned before there's a
front end and there's a driver layer and
the front end takes care of although the
reference counting none of that is
exposed to the user defines all the
interface functions including redundant
ones that you'd like for convenience
manages state manages connection polling
none of that is done at the driver layer
so this I see this type of a design as a
big win otherwise it would have forced
all kinds of complexity on the driver
layer that you don't necessarily want
now that technically you you wouldn't
have to use this mechanism it is a layer
on top of that if you wanted to just
implement a driver to spec you could do
this but I see this as a big win for
driver implementation at least for the
reference implementation driver
interface the nice thing about that
drops out of this is that it it really
it not only is the driver interface
fairly simple and familiar once you have
certain template definitions you'll see
at the bottom here the things which you
must have implementing this driver to
work with the front-end is really the
same layers that you have in the
front-end database connections statement
and result and you don't really have to
manage any resources the resources that
you need for insta
it's having to pass parent object to
child object is all handled by the front
end as it seen here now I'm going to
talk a little bit just briefly about a
challenge although I'm running out of
time this is an implementation detail
this this is about polymorphic execution
and one of the things that is
challenging about this implementation is
that you have to pass this is the case
where you're preparing a statement and
you're passing arguments repeatedly and
that must go through a very data comes
on the front end but what it has to do
if it's a polymorphic driver is is take
those and call them with a very Datak
function in the driver at runtime so I'm
thinking I you know just because it was
so motivating to take all of that work
out of the driver layer maybe I can take
at runtime that information repackage it
and call the driver layers very attic
function without having to put any
additional complexity and the driver
layer there are two challenges that
unpacking variant arguments and second
needing to transport arguments for one
variadic template to another and this is
what it looks like it's I think that
this is unusual because what you have to
realize is that you're taking something
at runtime and you're trying to form a
very data call that's that's a really
unusual thing to do you're going
upstream so you're taking your you're
taking a vector a very odd a very vector
of variants and you're saying I want to
package that into an actual fixed
argument call and that's what this
diagram represents and then what I'm
going to do is I'm going to unpack the
variants and then I'm gonna call the
drivers execute and then the driver
doesn't know whether it came from
polymorphic driver or not seems okay is
this a good idea
so this is what happens when you - this
is the reason this took two minutes to
compile and I'm thinking okay why is
this so what's happening here is I can't
this this is most definitely a fail but
it's also kind of awesome to think about
what it's doing I'm taking if you can
imagine that you have variable number of
arguments taken from ten types and you
have your going to support it up to five
arguments you are asking the compiler to
generate over 30,000 functions the fact
that what this works at all is actually
kind of interesting now if it hadn't
taken so long to compile I might have
thought you know this is great you know
this look what I did but because it took
so long that was a tip-off that well
maybe this is generating far too much
code but I have to wonder just how much
code is too much I mean if it really is
performing work in the modern age maybe
you know this seems excessive to me but
the point is is that the impact of this
is not that great it simply means that
your driver must support a second call
with either a vector variance or your to
your very Dadich argument must support
variance so it's a little just a tiny
bit more complexity in the driver and
that's probably the right call although
I did learn in STL's talk that the the
approach of peeling off arguments in a
very directive template is a horrible
way to implement it so we'd like to
least try it for a better approaches in
parameter packs and see if that may be
drastically reduces the compile time
there's a lot of future work here in
this project and one of the big things
that should be of interest to everybody
is to have non-blocking functionality
this isn't feasible with every driver
but some drivers do provide this and
what's needed is for the underlying
driver to support a non-blocking i/o
there's one in particular that I have my
site on which is a project called
web-scale sequel which is a project out
of Facebook and a couple other companies
and it that project
offers a my sequel compatible driver
with the additional non-blocking calls
so if you have a project built upon that
you can literally use the driver out of
this project and use it against your
existing my school database and I'd see
this is a the first driver with full
support for this to make this work
I believe Postgres can also do this as
well
reference implementation roadmap there
is current support here's from my sequel
and sequel Lite although these phase 2
databases should appear very quickly I
do have this project on github although
there's no code checked in it will be
checked in soon as soon as I clean it up
a little bit but this all phase 1 and
phase 2 do actually work pretty well now
there's there's a notion between having
sort of a shallow support for all these
databases and having deep support for
instance are you supporting you know
things like blobs and very you know
specific types of columns that's going
to take some time to fill out but in
terms of being able to run a growing
test suite that's including you know
basic things like selecting stuff out I
think that that's pretty achievable so
and then phase 3 is to start thinking
about asynchronous designs and support
other databases and that's it any
questions
so the question was about the fact that
sequel is different among different
databases and did you did you say it was
I'm not sure if you're talking about the
binding types but I would say that this
particular layer is is actually not
concerned with differences in sequel for
the most part in fact things like that
the binding syntax is question mark in
my sequel and is colon filled in another
database and and this this layer is
agnostic to that for the most part I may
be entirely it really matters for a
higher level code like if you're if
you're trying to do know where I'm
framework there's an absolutely
consideration but because I'm trying to
focus on the foundation that's that's
not something I largely see as having to
handle there are some details there but
I think was that your example is that I
think if I recall correctly you are
looking at higher level constructs for
how you can know we haven't have to
write code that will work on any
supporting database without doing a if
Oracle something I'll see if my sequel
something you know yeah that's much more
ambitious and that's this this is just
providing the foundational work for you
to build that kind of an ORM or or
hibernate like facility I think it's I
think that's definitely an interesting
thing to do but that's not necessarily
what we're trying to do here interesting
presentation thank you can you go back
to the slide that shows the papers
you've read or referenced I just didn't
I'd like to just get a picture of that
if I could thank you right so first of
all I think it's great to see that
several people are now trying to get
databases into the standard again that's
been dead for quite some time so thank
you for that I'm not sure if string
based approaches are the thing for the
standard but that's a different question
certainly not enough nothing that
not enough time for it for this year I'm
interested in in connecting your library
to SQL plus 11 one feature in SQL plus
plus 11 is that it can change syntax
things as as mentioned before depending
on which data is actually used does your
database have this information at
compile time available for a layer like
SQL plus 11
I'm sure could I just write probably I
need to understand the specifics of what
you need I mean up here so if it well
the thing is just the just a code note
or the compiler know at compile time
that hey this isn't as MySQL database
for instance so I think it could I mean
the question is how to implement that I
mean it's you know I can think of a
tagged type mechanism but they have to
be careful about what I specifically put
in that that in code that might be a
candidate at some point in the future
were standard ation because you because
nothing in the standardization can refer
to any particular like say enumerations
or tags yeah it can be I know if it can
really be a string and the compile time
but I think I think it's definitely
doable one way or another so we should
have a talk afterwards and see and I'd
like to understand and by the way this
is you know this is my sort of notion
after you know years of hand rolling
database interfaces and looking at
various projects and just just
experience about what is sensible to me
once I I think this is on github and
people come interested I'm really
interested to see what the community
thinks of this interface and I might
expect it to change quite a bit over
time based on a larger group of people
trying it and finding what works and
what doesn't so I really if you have any
kind of effort or interest in you know
working on this project please please
talk to me so yeah I think that I would
like to talk to you further about that
okay hi of simple questions what is the
licensing licensing level of the of the
library that's on github whatever is the
most liberal so I don't know if that's
MIT it's definitely this is this is
not there's no attempt to commercialize
this at all is going to be the most
liberal license it works for you know
everybody's use case great my second
question is the exam the code examples
that you gave in the slides are they all
examples of current functionality they
were not everything but maybe 80% I mean
there are some things I think there a
couple slides where I had maybe some
future capabilities that depend upon
things appearing in the standard but I
would say that 89% is in the code once
it's checked in you will be able to do
that now there probably some things yeah
I would say that's reasonable now there
are certain kinds of like I said before
rounding out all of the the various
support for types within the day basis
is often a lot of work just making sure
that everything every type is supported
and can be input bound output bound but
yes you should see nearly all that
functionality available and they may
depend upon of course C++ 11 by minimum
I'm going to try and work my way
backwards from 17 because I suspect that
there will be people interested who and
want to use framework in 14 or 11 and
and I can probably just reduce some
features if they're not supported so yes
are there sample programs who can
download there will be I mean I the
intention is I'll put lots of examples
on the github page and and you'll be
able to see a lot by looking at the test
framework so by the way this is this is
a header only a library and part of the
reason for that is it forces me not to
have to choose one of 20 build tools
including my own I'd like to write so by
doing a header only just you should be
able to just you know check it out and
actually drop it in as a clued path and
it should work except for the test suite
that might require a slight build but it
should be I do want to be extremely
convenient to use even to the extent of
like if I can put it on brew to just
make it paint there's really just quite
simple to use I would be happy thank you
very much
sometimes results
from SQL statements are returned in
chunks to the calling program would
there be iterators that are smart enough
to let you go through a whole returned
data set and so that it would hide the
fact that it's actually being returned
in in chunks that's exactly what output
binding does for you so you know that a
lot of times when you look at a database
API it shows you as a user how to
achieve that and at some point in
rolling databases I realize that that
could be hidden from the user so just
when you specify an array binding size
internally it's going to allocate a
buffer for a certain amount of size and
when you are fetching row by row you're
not going you're not round tripping in
the database you're only round tripping
when that buffer needs to be fresh so is
it did I did I answer your question yeah
so hopefully you get all those benefits
without having to do anything in the
user code just by specifying an output
buffer thank you
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>