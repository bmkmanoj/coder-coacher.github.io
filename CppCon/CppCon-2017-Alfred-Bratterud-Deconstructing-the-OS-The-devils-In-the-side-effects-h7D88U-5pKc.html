<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: Alfred Bratterud “Deconstructing the OS: The devil’s In the side effects” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: Alfred Bratterud “Deconstructing the OS: The devil’s In the side effects” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: Alfred Bratterud “Deconstructing the OS: The devil’s In the side effects”</b></h2><h5 class="post__date">2017-10-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/h7D88U-5pKc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">- Okay, hello everybody.
Nice to see you.
My name is Alfred.
I'm the CTO of IncludeOS.
Today I'm going to deconstruct
the operating system.
Actually, I'm going to build,
or show you how to build,
a tiny little operating
system from the bottom up.
So if you're not familiar with IncludeOS,
how many knows about
IncludeOS from before?
Okay good.
How many knows about unikernels?
Yeah.
So, IncludeOS is a zero-overhead
library operating system.
And is written from scratch in modern C++.
If you add single address
space to that definition,
you'll fulfill the
requirements for a unikernel.
So, when it's a single address
space operating system,
that kind of implies that
it's also a single process.
So we're making a library
operating system designed
to make your ELF binary bootable,
and completely self contained.
So, I wanna repeat this fact.
There's zero percent Linux inside.
We've given talks about
IncludeOS, and we've
told people that it's
written from scratch in C++.
Still, after an hour,
people raise their hands
and ask, &quot;but there is
Linux inside, right?&quot;
No, there is no Linux inside.
It's all C++.
So, I'm gonna start with a question.
This is a real StackOverflow
question from 2015.
How to boot my simple hello world program?
Suppose I have a simple
hello world program,
which is built in C, now how can I boot it
during start my PC?
(laughing)
Okay, nevermind the syntax.
Is it a fair question?
How many thinks it's a fair question?
If you were a moderator on StackOverflow,
would you allow this question?
(laughter)
Not many of you.
Who would deny this question?
Who would say it's not an okay question?
None of you.
Well,
the people of StackOverflow didn't think
it was a fair question.
It got downvoted, it
was closed as too broad.
People were actually
quite rude with this guy.
So, this guy is saying, sorry to burst
your bubble here, the
very fact that you ask
how to do it means you don't have a deep
enough understanding of computer science
to be able to do it.
I mean, that's pretty rude.
But where does this come from?
Where does this idea
that it's so hard to boot
an hello world program,
where does it come from?
It comes from the fact
that on your computers,
you have these huge operating systems,
and you're used to the fact that
that's just how it is.
But it doesn't have to, so
let's go back in time a little.
There used to be a time
when users were in control
of their computers.
Are you guys in control of your computers?
You're programmers, right?
I don't feel I'm in
control of this computer.
I mean, I think Apple is, to be honest.
I see these updates, I
don't know what's going on.
I say, okay, well, they do
something to my computer,
it's probably fine.
But you know, as a systems programmer,
and as a C++ programmer,
I like to be able to
control my own computing.
That's also a famous
statement from somebody else.
Let's not go there.
But I like to be able
to control my computer.
So, let's look at an ad.
This is an ad for an
IBM personal computer.
Because the guy wanted
to know how he could boot
his hello world program on a PC,
so here's the PC.
This is an IBM personal computer XT, okay,
so it's not the original IBM PC,
the extended version where
you got on hard drive, right?
So it's slightly more sophisticated.
So IBM sold these first PCs with 16
to 64 kilobytes of memory.
Would it have been a
fair question back then?
I mean, I'm absolutely certain
that the operating systems
that were popular at the time,
I think Microsoft DOS
was probably on this one,
it was a tiny, tiny, tiny thing
compared to what you have
on your systems today.
So I think maybe the fact that machines
have become so large, that
could be a contributing factor.
But I think the fact that you want
to run so many things at the same time
is kind of the main factor
for why operating systems
are very complex these days.
So let's deconstruct, let's try to make
the smallest possible operating system
for running hello world.
I know, it's probably not
an interesting example,
but it kind of is.
And we'll get somewhere
more interesting later.
So I'd like to start here.
This is what happens when
you start your computer
with an empty hard drive, okay?
And this is actually
how IncludeOS started.
I was doing research into cloud computing,
and I was interested in virtual machines.
I wanted to run thousands or actually,
if I could I would like to run
millions of virtual machines
to do interesting research
on cloud computing.
So I thought, actually, hello world
is quite a good place to start,
to figure out, what is it that makes
these virtual machines large?
And how can we make them smaller?
So I'd like to answer this question,
and I'd like to answer it in the spirit
of Bjarne Stroustrup's
zero-overhead principle.
Now, why should we listen
to Bjarne Stroustrup?
Well, he actually just won a medal!
(laughing)
Right?
(applause)
Did you guys win medals?
(laughing)
I didn't win any medals.
So I'm inclined to listen to this guy.
So let's try to boot your service
and to apply this zero-overhead principle
and not pay for what
you don't need, right?
Is it possible?
Yes, it's possible.
This is a bootable hello world program.
If you're interested in X86 assembly code,
you might want to study this.
I'm not going to go into the details.
It's about 30 lines, so
that wasn't so hard, right?
I booted hello world.
Well, I wrote hello world,
and this is how you boot it.
It's two lines to assemble
and then use, in this case, a
virtualization tool like QEMU.
That's a hypervisor.
That's something you
can use on Linux or Mac.
You could also boot this on VirtualBox,
or you could boot it on your physical PC.
So this is what happens, hello world.
So did I just boot hello world?
Yes.
This will also work on hardware,
so I would say I booted it on a PC.
Oh, but these guys don't agree.
They're actually gathering
angrily outside town hall,
demonstrating, pointing out
what's wrong with this example.
First of all, it's not C, right?
He specified that he wanted to boot his C
hello world program.
Okay, so I gave him an assembly version.
That's not quite good enough.
16 bits, yes, well caught.
It's a 16-bit instruction set you're using
when you're starting, so,
and also one guy noticed that
this is not a generalizable solution.
Inside of that first boot
sector will only fit 512 bytes.
It's okay for hello world,
but you can't do much else.
Well, you can do a lot more,
but it's not completely generalizable.
So this guy isn't angry.
He's just determined.
(laughing)
And, okay, so he's not
happy with two lines.
He wants one line.
So a one-liner to build and
boot a hello world program.
That's something we actually made,
and we'll go through that.
So first, let's address these issues.
The fact that it's not C or C++,
that could be easily alleviated.
Obviously the compiler is much better
at writing assembly than I am,
so it could probably, at
least this for loop here
and the actual print
statement, could be much nicer,
probably, if you allowed the
compiler to output this code.
But there are some other problems.
We are using some privileged
instructions here.
You can see that I'm saying cli and hlt,
just above the arrow there.
Those are privileged.
Also, at the bottom, I
have this special statement
to fill out the rest of
the binary with zeros
so that, in total, it
forms a 512-byte file,
and at the very end, the last two bytes
is supposed to be AA55.
That's like the magical signature
for a boot for the BIOS,
and it sees those last two bytes,
and then you're absolutely certain
this has to be a high-quality bootloader.
(laughing)
Cause those bytes are at the end, right?
Okay, so the fact that it's 16 bits,
is that a problem?
For hello world, maybe not.
It's not very generalizable.
Obviously if you want to do
something more interesting,
like do something cryptographical
or do something that require
speed and performance,
then of course you'd expect my system
to be able to alleviate
the full instruction set
of the architecture.
So let's consider this boot one-liner
that we're trying to make here.
We just want to say boot and
then your program, right?
So that statement has some
interesting side effects.
And we're going to look
at some side effects
or various things that pop up
when we're trying to
make an operating system,
and we're going to try to address
the zero-overhead principle
to those side effects,
or those questions.
So obviously it was an assembly solution.
He wanted a C solution, so
we have to link with printf.
That's part of the C standard library.
Now, printf isn't going to randomly start
writing pixels on your screen, right?
You're probably happy it won't.
And it's not going to
decide actually where
that output is going.
Printf is just a library function,
and of course it needs a backend
in terms of a system call.
So we're gonna have to
implement that as well.
In order to satisfy
the guy who didn't like
that we used 16 bits,
we need to switch to 32
or 64-bit mode.
We need to load an
arbitrarily-sized C++ program,
not just 512 bytes, so it
becomes a generalizable solution.
You probably also really quickly
want us to initialize
heap and stack, right?
At least you want a sane stack
so that you can use functions,
call functions, have stack frames,
be creative and destroy without,
for example, colliding with the heap.
You also want the heap so that
it's a safe area where you know
that you can use malloc and friends,
or you probably shouldn't
use malloc and friends,
but you should use more
sophisticated C++ techniques
for memory management.
And then eventually you want
me to jump to your program.
And you also want me to kind of handle
displaying that output on the screen.
So the linker can take
care of the linking part.
If I provide a
statically-compiled C library.
And we do that.
That's part of the bundle you get
when you install IncludeOS.
Now, this part, let's try to implement it.
How can we make the simplest
possible backend for printf?
So printf is part of a library,
and of course this
library will already have
programmed into it calls
to the operating system.
And that's what we have to implement.
So this is the set of system calls
that the newlib, that's the
version of libc we're using,
so this is the minimal set of system calls
that you need to implement
in order to run libc.
So let's see what's needed for printf.
I think you can get away with only write.
There might be a call
to isatty for printf.
It will check, is this a
terminal or is it a file?
Do I have to do some open first?
But the one that's actually doing some I/O
and actually doing something dangerous,
that's the write statement.
So let's make a backend.
So this is a complete backend for printf.
It's a minimal backend, but it's complete.
And let's take a look.
So first we have some abstractions
around the in and out instructions.
You can see I'm using
some inline assembly here.
That's because these are
privileged instructions
that the compiler isn't
going to randomly just emit
when you're building your program.
The reason for that is that
if you try to run these
instructions on a normal user-space Linux
or Windows binary, what's going to happen?
You'll get killed, mercilessly, right?
But, and we'll get to that part.
But we need them for this
exercise of making a driver.
So we start by making some
abstractions around those.
Now we make a serial port driver.
That's quite small, and
this is one of the reasons
why we like the serial port.
It's the only peripheral
that really doesn't need
anything in terms of a driver.
You can just start talking to that port,
and it's going to work.
You might need some
initialization in advance.
You can look at the comment there
to see where in IncludeOS you
can find this exact function.
We have this.
And then on some systems, some platforms,
there might be some initialization ahead,
but it's really very straightforward.
So it's a for loop.
It's reading from the status register,
and it's checking that,
is this serial port
ready to receive data?
And once it is ready, then
you actually output the byte
one by one.
And then we can do our first system call.
So we implement write.
Let's ignore the first parameter for now
and just see it's a pointer and a length.
So we pass that on to the
serial print statement,
and that's it.
Should probably be implemented
a bit more carefully,
but this is going to work.
And now, finally, we can make our int main
printf hello world, which
is something I expect
is a reasonable answer to
the original question on StackOverflow.
We have allowed you to use printf.
That's normal C.
We have implemented a backend for C,
and we have also
done the necessary things
to bake this together into a binary.
And we're going to look at
some of the details of that.
Oh, these guys are worried.
How about kernel protection?
Are you using blocking I/O?
That's crazy.
Isn't out privileged?
Yeah, I mentioned that.
We probably have to address it.
So let's take a look.
There are some tricky side effects.
Inb, that's in byte.
That's again using a
privileged instruction.
But the important part there is that
this while loop is going
to be blocking, okay?
So
this is one way of
communicating with devices.
This is a way you could
implement networking.
You could have port I/O
talk directly to the device
using in and out ports.
The problem with that is the
CPU is going to be occupied
100% of the time.
And of course that's not very efficient.
So another thing you have to deal with
is privileged instructions,
because they are
supposed to trap.
We'll get back to that, but
it's also an interesting question,
should we context switch here?
Usually when you do system calls,
I just called this a system
call, and nobody reacted.
But usually, what are system calls?
They're not just function calls, are they?
Are they just function calls?
No, they're not.
System calls usually
trigger a context switch,
where your process is actually
completely scheduled out,
the kernel is scheduled in,
and it's running in a
different CPU protection level.
And that's necessary in order to do
these privileged instructions.
So usually, a system call
isn't just a function call.
So we should probably ask ourselves,
well, is this correct?
Because this works.
So what's wrong?
Is there something wrong here?
Is there something important
that I haven't implemented?
So we could ask ourselves that question,
should we do a context switch?
Should we enter into a
higher protection level,
or isn't that necessary?
What's the zero-overhead solution?
So we've talked a little bit about
the privilege and context switches.
The important thing to point out is
who are you actually
trying to protect, right?
Because these sensitive instructions
or privileged instructions,
they are going to cause a trap,
but only if you are in
an unprivileged state.
If the CPU is set to be
in an unprivileged state,
that's when it's going to cause a trap.
If you are in Ring 0, the default state
and the most privileged state,
is it going to cause a trap?
No, of course not, because
somebody, at some point, has to be able
to actually talk to the devices, right?
So
I say that the zero-overhead solution
for some use cases, not all use cases,
is to stay in Ring 0.
It's a surprising amount
of things you can do there.
So yes, you have a lot of privilege,
but remember that the compiler isn't going
to emit these privileged
instructions at random, right?
So if you write normal
C++, it's going to emit
non-privileged instructions.
And that's going to be quite okay.
But if you want to start doing
these privileged instructions, you can.
But that's not going to
be writing normal C++.
So port I/O versus direct memory access,
direct memory access is
the usual way we do this.
And I don't think we're going to have time
to look into the details,
but our network drivers
are implemented in such a way so that
we just use port I/O for
signaling the physical device.
And then for initializing
the physical device.
We're not using it to
transport data, okay?
So the physical network device is going to
receive the packets off
of the physical wire,
it's going to put those
packets up in my memory,
and then it's going to interrupt me
and tell me, now you have packets.
So I don't have to spend
a lot of CPU cycles
just fetching all these packets.
I'm just getting notified
when they're already there.
The same thing goes in reverse.
So for something that's
even remotely performant,
we have to use DMA.
So I think that's the zero-overhead
solution in this case.
But it might not be that simple
and clear-cut all the time.
So we make it platform-dependent.
We are bundling parts of
IncludeOS into different bundles,
and we're calling them platforms.
And we have, one platform
is called X86 PC.
And that contains all
the components you need
in order to talk to a
modern X86 hardware platform
with advanced interrupt controllers,
advanced I/O controllers, everything.
But then we also have this X86 Nano.
If you know that your program doesn't need
any of that stuff, for example
we're making a chain loader,
all it needs is to read
the binary and jump to it.
In that case, you might not want
to go through the trouble of initializing
all of that hardware.
So let's get back to booting,
and let's reuse IncludeOS parts
to get this C program booted.
So the linker part is done.
We implemented the sys call.
So now you need a bootloader.
We're not going to put this code
inside the bootloader anymore,
which is essentially what
we did in the first example.
But it only fits 512 bytes.
So we're relying on a
third-party bootloader,
or you could use our very
simplistic, rudimentary bootloader
that we made to be able to do
the smallest possible binaries.
That's just a 512-byte bootloader
that's going to lift your code up,
put it up in memory, and then jump to it.
So this bootloader is
going to switch to 32-bit.
We can bake in, also,
or by default we're going to also bake in
the necessary assembler
to the very beginning
of your binary so that it will also switch
into 64-bit, so that you'll start
kind of in the most modern
X86 environment when you boot.
So loading, that's taken
care of by the bootloader.
We also initialize heap,
stack, and bss, et cetera.
We expect that you want this for something
remotely more interesting than
hello world.
So you can look at that code there.
Kernel start, that's where all that is.
And that's also the good place to start
if you're interested in
writing your own kernel.
So we have all this tooling around
to make it easy to boot and bake things in
as a bootable binary.
And this is where you start if you want
to implement your own.
And then display the output on the screen,
we showed the original bootloader
was actually writing bytes
directly to video memory,
so that's one way to get
pixels on the screen.
We also showed you how to do serial port,
which is nicer if you're running
in a virtual environment.
You'll get the output as actual data
out into your terminal.
So here's your one-liner.
We made this little tool.
It's a Python script.
And it's actually controlling QEMU.
And we're going to work on improving that.
But it's quite useful already.
So if you have that code,
just the code that I had
in the previous slide,
all the C code with the
printf backend, et cetera,
you put that in a file called service.cpp,
you say boot dot, after
having installed IncludeOS,
and this is going to happen.
Okay, so it's booted your
hello world C program,
and it did it in a one-liner.
That was kind of the mission
for this first project.
So this is an overview of the tooling.
We have libraries, we have your program,
and it's going to, for
example, if you say printf,
then the linker's going to
pull in the printf function.
The printf function,
again, needs the backend,
the system call.
And that's located in the os.a library,
so that's going to get pulled in.
You can attach drivers
for various platforms.
And you can also embed a memory disk
so that you have a file
system, et cetera, in there.
So with all that put together,
you don't have to write
your own backend for printf.
You can actually just write a normal C++
hello world program.
And you can say, int
main printf hello world,
and you can just say boot dot,
and that's going to come up and do this.
Slightly different output,
because we don't use
the main signature by default.
But we made it into a weak symbol
so that you can supply the main,
if that's what you prefer.
And when main returns, what's left to do?
I'm a single-process operating system.
I can't really do anything else.
You're in charge.
Your program exited, so I'm just reporting
the exit status.
These guys are rioting again.
Hello world doesn't pay the rent.
So what pays the rent?
They want the web server.
So they want me to show you how to boot
a simple web server
and how to implement the
backend for a simple web server.
Should we do that?
Yeah?
(laughing)
Just use HTTP, right?
Not that hard, how hard can it be?
I'm telling you that 90%, I think,
of our efforts in IncludeOS has gone
into making a networking subsystem.
It's not by means trivial.
We've done it, and it's
actually working really well,
but, so I can't show you that in detail.
But I'm going to at least
address your questions.
Okay, that's quite a tall order,
but we're getting there.
We actually, we are there,
at the point where we can do this.
So let's see if we can get
help from the system calls.
I want to write a hello world web server.
I have all these system calls.
Maybe if I implement all of them,
not just the write one,
maybe I can get a web server.
Do you think?
I don't think.
But let's take a look.
So the green one, the sbrk, that means
extend the memory
assigned to this process.
Actually, just give it more space.
That's actually the backend for malloc.
So malloc is provided by the libc.
It's just an algorithm for handing out
buffers of different sizes.
And then it uses a very
simple sys call, sbrk,
in order to provide that.
So that's useful,
certainly, and we need it,
but it's not going to
give us what we need.
But this read sys call,
that might be useful
for actually reading off a socket.
You could use it for
reading off a socket, right?
So maybe we could start using that.
So this is POSIX signature for the read
function call or system call.
So maybe that's a good starting point,
or maybe it isn't.
Is this how you'd start in modern C++?
If you were writing the
backend for a web server,
if you were writing that
networking subsystem in C++,
is this how you would start?
Who would do that?
Is this beautiful C++?
Well, let's see.
Well, if you read the specification,
it's blocking by default.
So that means one of two things.
It's supposed to block, right,
because you're supposed to
have continuous execution here.
You're supposed to just say read,
how many bytes you want to
read off of the TCP stream,
which might not be open yet, who knows.
But you're supposed to just say read,
and it's going to sit there and wait
until all those bytes have been filled.
There are async options to this call,
but the default is to block.
So I have a choice to either spin
in a spinning loop, spending 100% CPU,
or I could do a context switch,
which is really costly.
So I think this approach,
just already here,
I'm saying that doesn't
sound like zero overhead.
These context switches are costly.
I have to implement some kind of threading
and some kind of stack switches.
I have multiple stacks
that I have to juggle.
That's a lot of stuff just to be able
to print hello world in a web server.
And it might come in handy.
It might be that we need to have
full-on preemptive scheduling
with all these context switches.
But we don't need it yet.
And we don't want to implement stuff
until we actually know why we need it.
This is another thing.
I don't think this is natural to C++,
to have these integers that
represent file descriptors.
What is a file descriptor?
I have no idea.
What's behind this?
It's just an integer.
What's behind there?
Is it a file?
Is it a socket?
Is it open, is it closed?
What is it?
- [Man] Magic.
- Yes, it's magic, exactly.
It's magic, and it's opaque.
So is this what I should
start implementing?
Should I make these file descriptors?
It doesn't seem intuitive
for me as a C++ developer,
does not seem intuitive at
all to our developer team.
They hated doing this.
I asked them to do POSIX,
and we've done a lot of POSIX.
But it's not something
they do enthusiastically.
It's a kind of
polymorphism, you could say.
It's like a poor man's
polymorphic interface.
POSIX is great for many things.
It's much better to have a standard
than not to have a standard.
But it's not something I
would start by implementing.
This is not where I would start.
Also, you have this void pointer.
Is that good C++?
I don't know.
I have to do some kind of typecast there.
And then there's the fact
that it's a pointer size interface.
I've seen core guidelines,
at least in some revision
of the core guidelines,
there was a recommendation
that you should do spans instead of this.
I think that if you can have some
more type-safe interface, you should.
So but whatever the case may be,
however you might feel about
this function signature,
the fact is I have to implement that magic
that's supposed to be living
behind that file descriptor,
that thing that makes the internet work
inside your computer, that
has to be implemented.
And then I'm going to have to provide you
with some kind of user-friendly
interface on top, right?
So let's look at the other system calls,
if there's any help.
We have a lot of file system ones.
That's quite a lot.
It represents quite a large portion
of the system calls backing newlib.
And then we have these rarely needed,
for our purposes, kill.
We're a single-process operating system.
What are you going to kill?
You can only kill yourself.
Yes, you're allowed to do that.
We've implemented this
because we have to, but
doesn't really make
that much sense, right?
Environment variables are
good for communicating
small pieces of data between processes
and between operating
system and processes.
You can have them, but
in IncludeOS, it's much
better to just go ask
the operating system directly.
Just fetch the values you want directly.
There's one there for timekeeping.
That's probably useful for a web server,
but it's not, doesn't take us miles ahead.
And then we have these
that are completely useless
in a single-process operating system.
Fork, I can't fork.
I don't know about processes.
I'm one process.
Should I duplicate myself into two?
No, that doesn't make sense.
Waiting for another process
also doesn't make any sense.
So, oh, let's just look
at this very quickly.
Why so much file system stuff
and why so little networking stuff
in the C standard library?
My only hypothesis is that this is what
the internet looked like in the 1980s.
(laughing)
I remember this internet,
except it wasn't FedEx.
I never used FedEx.
I had all these diskettes in my backpack.
And the diskettes were taken out,
taken out of backpacks and
put into other backpacks,
and there were of course never
anything pirated on there.
(laughing)
But there was definitely
a lot of games on there.
So that's how we exchanged information.
So maybe that's why there
was such a file system focus
on the system calls.
But it's not nearly
enough for a web server,
so we have to do more.
So we actually have to
implement this whole
networking subsystem, and we have to do it
with zero overhead because
that's our mission.
And we also want to alleviate the
opportunities we have when we know
that we actually don't have to worry about
other processes getting in the way.
So we have some unique opportunities
to do something different.
And then the question is, when I implement
all these subsystems, I'm
a library operating system.
So I provide, for example,
if I provide a TCP object
to you guys, you're making the process.
I provide the TCP object.
Do I need an extra set
of interfaces on top?
I don't know, but let's see.
So let's take a small
survey of the subsystems
in the modern operating systems.
We have memory, we have file systems,
we have timekeeping, networking,
parallelism, and miscellaneous.
I probably forgot something, but
these are at least some
very important ones.
And if you looked at
libc, I think this is,
I've used a very scientific model
to derive this precise line here.
It roughly describes how libc,
what kind of services libc provides
in terms of support for or access
to these operating system subsystems.
So POSIX goes a lot further
and gives you a lot more.
Most notably, obviously, you
get the socket interface.
So you actually get to create TCP sockets,
and you get to create UDP sockets.
You can send datagrams, and
you can open TCP streams.
That's huge improvement, obviously.
You also have p threads,
so now you can actually do threading.
That's nice.
Libc++ adds a lot of value on top of that.
Again, in terms of memory, we have STL,
we have std file system,
I think that's just recently
gotten approved, has it?
So that's great, that we have std chrono.
That's much better
abstractions for timekeeping.
And then there's a networking TS
that I'm hoping is
going to turn out great.
It's not there yet, but of course
in terms of concurrency,
there's a lot of work,
lot of addition C++
has been doing as well.
Std threads, async, core
routines, et cetera.
So still some things might be missing.
I'm always interested
in the low-level stuff.
Might just be me, but
I'm a systems programmer.
I think many of you guys are as well.
So we talk to people,
we see a lot of people
trying to get the Linux
kernel out of the way
and trying to kind of get
through this opaque barrier
of system calls without going through
the whole hassle of
modifying the Linux kernel
and writing kernel modules.
That's quite hard.
So having some very clean,
low-level interfaces,
I thought that would be interesting.
And obviously, HTTP is missing
and all, so.
We contribute with our squiggly line.
It's not any straighter.
It's not that much cleaner line,
if you try to express it as a line.
But we have a lot more
going on the networking side
because we actually implemented
the whole subsystem.
Obviously, that's not the job
of the C++ standard library.
At least, I don't perceive it to be.
But we had to do it for our purposes.
So we have added some stuff.
But instead of considering this a line,
I just want to talk
about how we're doing it.
We're just implementing all
these well-defined subsystems
as C++ classes.
So it seems a bit artificial to draw
this kind of absolute
line, this distinction
between, this barrier
between this operating system
and user space.
It seems a bit artificial,
at least in our context.
So we're implementing
all these subsystems.
We're providing a lot of
high-level abstractions,
and we're also implementing
objects for the low level.
So people might be missing
this very clean boundary.
I don't know if you guys are.
But it's of course an important question
for me to ask myself when I'm saying
that I don't really, I
don't want to shout hooray
for the POSIX standard, even
though I see its importance.
So some people might complain,
and they might want these clean layers.
So we're thinking about that and trying
to figure out where should
those clean boundaries be.
This is one place to draw the line.
If you want to address web developers,
this is one way to do it, to just say,
let's just provide some
really clean HTTP interfaces,
because obviously, if you
have an IP stack in TCP,
well, you're gonna want
HTTP, and that's all.
Yeah, that's true for web developers,
some web developers.
But it's certainly not true
for systems developers.
So you want something more?
Okay, so you can get
access to TCP connections,
or part of the TCP connections,
through these opaque
file descriptors that,
they're just magic numbers
that, I don't know.
POSIX provides some of that.
You also have this other,
less clean interface.
POSIX also includes a whole set of tools.
It's standardized.
Actually, a lot of these
command line tools,
which to get all together
forms kind of an unholy mess,
a way to access all the
parts of the systems.
But at least, yes, it's very useful,
and that's just how
things evolved, I guess.
So but if you want clean
access to everything,
I don't know a simple way.
But we're trying to make that happen.
So some of this comes from,
some of these layering issues,
it comes from the protection boundary.
And it makes a lot of sense.
Let me stress that.
It makes a lot of sense.
It's absolutely no way
to make a general-purpose
operating system without having
this protection boundary,
obviously.
You can't have one process here,
Microsoft Word here,
and Google Chrome here,
overwriting each other's memory,
just not possible.
You can't have it like that.
So for that reason, you have
these protection boundaries.
But once you don't need those anymore,
it opens up the space of opportunities.
That's just a look inside,
to be more concrete.
These are some of the
classes we've implemented.
We have the network interface card,
we have ethernet, we have TCP controller,
we have ICMP, we have TCP connections.
For each of these protocol handlers,
we have implemented packets
as simple, clean C++ classes
where you can actually
get the actual IP4 packet,
and you can access the
members of that packet
through a normal C++ interface.
So that's just what we did.
And then POSIX.
Obviously, we want this
operating system to be useful.
We want it to be able
to support legacy code.
Yeah, so we're making a
POSIX compatibility layer
on top of there.
But it introduces some strange
and unnecessary abstractions,
the first of which is blocking
because our operating
system is async by default.
We've used the simplest possible
form of async programming, which is
the leanest and smallest
way, and that's callbacks.
You can build a lot of
abstractions on top of that.
That's not the only paradigm we support.
You can use Boost.Asio on top as well.
But having to put this
POSIX compatibility layer
on top, it forces us to support blocking.
Okay, so we need to
support context switches
in order to have that.
It's not efficient, but
we need to have that
for this legacy interface.
I say make your own layers.
We already have these C++ objects
which are small APIs in their own right,
representing well-defined objects.
We didn't look at the POSIX standard,
or we didn't primarily look at Linux
when we implemented this.
We went to the source, the RFCs.
IATF, it's the standardizing
body for the whole internet.
They have really well-written standards
for all these protocols.
So we went directly there and implemented
using modern C++.
So the result is that we have
all these quite well-defined,
they're getting more and more useful.
We're actually using them
to deploy software now.
And I think that's,
in my mind, what I need in my job.
I don't know what you need,
but I don't need POSIX.
But we're implementing it.
So obviously, we wanted
to also stay synchronized
with the standard libraries.
So there's a networking specification.
I think it's scheduled for C++20.
It looks like it's going to
be working on top of POSIX.
So that means you'll have a rich set
of C++ abstractions from the standard
on top of this opaque POSIX layer.
And if you have this
running on top of IncludeOS,
that's modern C++ on top of ancient C,
on top of modern C++.
It seems unfortunate.
So I hope we don't get there.
Although it might seem
unreasonable to have
the std network conform
to the IncludeOS IP stack.
I mean, maybe sometime in the future.
Might seem unreasonable,
but I think Bjarne Stroustrup said today
that all progress depends
on the unreasonable man.
This is a quote from George Bernard Shaw,
so who knows.
I'm not giving up.
So anyways, I thought I
was done with these layers
until I got this email
from Dan and Ricardo
at IBM Research.
So they were running IncludeOS on top,
and they were running the demo application
we showed last year, which
is a lot of HTTP abstractions
for making Restful APIs.
And they were running this application
on top of their new,
very I would say avant
garde kind of hypervisor.
And very cool is that
they reduced our boot time
from 300 milliseconds to 10 milliseconds.
I thought 300 milliseconds was quite good.
But 10 milliseconds is much better.
Let's look at that.
So we have all these squiggly lines,
and this is where Solo5 comes in.
That's actually a pretty straight line.
I'll validate this straight line
by actually looking at their code.
So this is the interface.
This is the low-level hardware interface
that these guys have defined.
And it's sufficient to run this very rich,
modern C++ application on top.
So they have network packet
read, network packet write.
That sounds very intuitive.
I understand immediately what that means.
Block device read, block device write.
So read a single block,
write a single block.
That's something you would
put below a file system.
But it would also make it easier for you
to figure out how to
make your own file system
or to experiment with different
types of file systems.
And then you have fast console
output, obviously one output.
Okay, that sounds very
nice and reasonable.
And you have two types of clock,
monotonic clock and wall clock.
Yeah, sounds like all you need.
And then you have this
very interesting one
that actually replaces
all of our IRQ handling
and all of the timers,
bundled into one single call.
It's called poll, and it says sleep
N number of nanoseconds,
or sleep until N number
of nanoseconds have passed
or until there was some I/O.
So our whole event
loop, instead of waiting
for interrupts, we are
just doing this call.
So we're looking at our timers,
and we're saying okay, so
no timers have expired yet.
When is the first timer
that's going to expire?
The first timer that we have registered
is going to be expiring in N nanoseconds.
Okay, so I pass that
number to this call here.
And that call is going to wake me up
when a timer has occurred
or there has been some I/O.
So it replaces pretty much all of this.
Now, it's not true that it replaces it,
because Solo5 is just an interface.
But just to get an event loop running
and to get timers running,
we had to implement a
whole lot of stuff on X86.
You can look at that code.
It's a lot.
And this is not even all of it.
Ah, this guy.
You noticed blocking calls.
Yes, that's true.
There are blocking calls
in the Solo5 interface.
And so this is one of the
trickier side effects,
number four, I'm not going
to go into detail about it.
But once you want DMA to happen,
what does that mean?
It means that you have a device
that's supposed to put
data into your memory.
And then once it's put
data into your memory,
it's going to interrupt you, right?
And you could start
thinking how should such a
interface look like, a shared
data structure like that?
You could say okay,
let's just have them all
in our ordered array.
I have a continuous
array of network packets.
Well, that's great, but
how about fragmentation?
Do you think network packets
are always going to
just line up like that?
Then it's a lot of copying, right?
So in order to avoid copying, et cetera,
you need some sophisticated
data structure.
And it's quite hard to test, et cetera.
This is something tricky with DMA.
Zero-overhead solution, I
still think it is to have DMA,
but it's surprising how much
you're able to do with Solo5.
So it works like this.
This is just how the layer enters.
So Mirage, that's another
unikernel project from Cambridge,
acquired by Docker, those guys.
So they use Solo5 as a overlay
on top of their drivers
for running on KVM.
So that's running in full
hardware virtualization,
they use this simple Solo5 interface
to get their application.
And the rest of their operating system
running on top of there.
The IP stack, et cetera,
is all running on there.
So that means inside the virtual machine,
they have a set of drivers that, again,
will implement this Solo5 interface.
And that's all inside the virtual machine.
Another way to run it,
which is how they had
implemented it for us,
is that they actually
put the devices, they
don't put the devices
inside the virtual machine.
So that means they
provide a network driver
for IncludeOS, which
just does a trapping call
whenever it wants to
fetch a network packet.
So, and this adds a lot more protection.
So it's hard to visualize all this stuff.
I hope you can, it's
probably hard to follow,
but what's happening here is that
the Solo5 interface is the bottom layer.
And below Solo5, we don't
have any network drivers
that we have implemented ourselves.
We just have these trapping calls.
So essentially, the work of the driver
has been moved down to the host.
So the host is going to be in charge of
moving network packets in and out.
So it adds a lot of flexibility, and also
they give us some security,
some real cool security
guarantees.
When you run IncludeOS in Solo5,
it's actually going to
do memory protection
of the ELF binary, because
we provide an ELF binary.
In that ELF binary, there are segments
with different protection flags on them.
So with Solo5, it will actually load that
and set the protection
inside of the virtual
machine memory from the layer below,
so that we, inside of
IncludeOS, can't change it.
And that gives you absolute protection,
if that's what you guys want.
So that means you can
actually have a guarantee
that says you can not
write to the same memory
that you can execute.
So that means you have a strong guarantee
inside of IncludeOS.
There is no way that I can receive data,
write it into memory, and
then jump to that memory.
It has some interesting side effects.
For example, we're doing
something called live update.
That's not going to work.
We have live update, where
you can receive a new version
of the IncludeOS binary.
You can actually replace yourself.
So you can replace the
whole contents of the
virtual machine in five milliseconds
or 10 milliseconds or something.
It's really fast, and it was really neat.
That's not going to work there.
So still some interesting
work in figuring out
exactly where this
balance should be struck
between security and the
ability to update, et cetera.
This could also obviously be used
as a hardware interface
on bare metal as well.
I want to give a shout out to Bareflank.
Rian Quinn is here today.
They're taking an even
more radical approach.
So they're actually tossing KVM aside.
So Solo5, they use an interface to KVM,
which is a kernel module in Linux,
in order to run the virtual machines.
Bareflank, they're actually implementing
all of this from scratch
for both Windows and Linux.
I still don't know exactly
how these interfaces
between guest and host are going to look,
but I'm sure, is it
somewhere along these lines?
Yeah, yeah.
So I'm really excited
about that project as well.
This is pure C++.
It's really well tested,
so go see Rian Quinn's talk
and check out their work as well.
So approaching the end here,
we're seeing that, we're
making an ecosystem,
we're implementing all
these protocol objects,
these subsystems in C++ already.
It doesn't seem like we really need this
neat POSIX layer on top.
But it looks like it's possible
to make some very neat
layers on the lower levels.
So we have a guideline for POSIX.
We want to implement the
modern C++ variant first.
And then we do this
optional POSIX layer on top.
So there are no perfect layers.
So how much should we
allow the user access to?
And I think the answer is everything.
Would you agree?
Can you tell me one thing
inside the operating system
or inside the hardware that you want me
to restrict access to?
Something you're absolutely certain
that you never want access to?
I think the general answer has to be
I want to be able to access everything.
So
we want to give you access to everything,
but we don't want you to
get everything at once.
We don't want you to pay for
the parts that you don't need.
So unless you explicitly ask for it,
it's not going to get included
into the final binary.
I also said today, Stroustrup too,
that you shouldn't make a
connection with hardware.
It's abstractions all the way down.
And I agree.
Unfortunately, some of these
abstractions are very opaque.
So if you just start
trying to interface with Linux,
you're going to see that
you'll reach the level
of the system calls,
and below it's just a black box, really.
Obviously it's opensource, which is great.
Can go in there, rebuild Linux,
make your own kernel modules.
But we are trying to make
an environment where
you as a C++ programmer
already has access to all
these subsystems directly.
So we're trying to answer
all these questions.
How do I boot my hello world program?
We answered that today.
How do I boot my custom kernel?
We have tooling for that,
so that you can start
implementing your own
kernel and say boot dot,
and then boot that kernel
code and start working.
Boot a web server, C++ web service
with modern abstractions
that we showed last year.
We're working on routers and
firewalls and load balancers.
So these are systems where you typically
need part of an IP stack
and not the whole IP stack.
So it makes a lot of sense for us
to have a modular IP
stack, where you don't
just get this huge box or nothing.
You just get, you can pick and choose
the components you want.
So the green ones are available now.
Firewall, routing, load balancer,
those are in the works.
Our CEO actually reported 13% faster,
that we were 13% faster than Linux
when we were routing a ping flop.
So we're very good on latency, it seems.
13% faster, that's pretty cool.
Yeah, so he wants me to
boot that web server.
I've been talking about it.
So this is how it looks.
I'm not going to have
time to go into details.
There is a talk tomorrow
where I'll cover more of that.
But this is how it looks,
and you might notice
that we're making a unique pointer here
to something just called a HTTP server.
But what I think is interesting is that
this is just one of several abstractions
we have available.
We have, if you want,
just to have an example,
where you run TCP and
write text directly to TCP,
you can do that.
This is an abstraction for HTTP.
And what I think is interesting
is that you build that HTTP server object
on top of a very transparent
set of subsystems.
So we have an IP stack
that you can access.
You can grab hold of the
TCP part of that IP stack,
and then on top of that TCP part
of that particular IP stack,
because you can have many,
so on top of that, you
attach your web server.
You can see already that we are,
this is our callback.
This is a way to do callbacks.
So on request, and we're
transmitting a lambda in there.
So whenever there's an
HTTP request coming in,
this lambda's going to be executed.
That's not the optimal way of
using this callback system.
But it's very efficient.
But when you use delegates
and add delegates
into the equation, which I'm
going to show you tomorrow,
then it gets much easier to work with.
So you can boot it.
Now it has networking, so if you boot
something with networking, and you want it
to be able to talk to the
surrounding environment,
you say create-bridge.
So we'll set up a bridge for you
so that that virtual machine will come up,
and it will have kind of a virtual wire
connected to a virtual bridge
so that you can talk to it.
Boots something like this,
and then you go to the web browser,
and you go to that IP address,
and hopefully you see that webpage.
So how am I on time?
I actually have gone a little
bit faster than I thought.
So tomorrow, I'm going to
cover this code in more detail.
I never thought I'd get to
the end of these slides.
But here we are.
So I'll introduce you
to modern C++ delegates
and how we wire all these C++ objects
that I've talked so much about,
how we wire them using delegates.
That's a quite interesting technique,
and I'll show you much more code examples.
How to do fast DMA zero-copy IP stack
with tens of thousands
of concurrent connections
and zero context switches on a single CPU,
that's a true statement.
We're doing that.
We're not doing any context switches.
But still, we are getting
a lot of performance
for a lot of concurrent connections.
And the reason for that is that we have
a very, very slim and
minimal sort of event loop
that drives the whole thing.
So we're gonna talk about delegates,
how they make the zero-overhead
async programming easier.
You can also build other
stuff on top of that.
I mentioned Boost.Asio.
That's also something,
it has a flexible backend
so that you can make an
IncludeOS backend for it.
So there are alternatives, but of course
we're also going to point
out some tricky issues.
It's not just easy.
So, yeah.
We'll look at those.
And there are reasons for
wanting core routines,
channels, multicore abstractions.
We do have multiple cores in IncludeOS,
and we do have a way for you to assign
a function to an actual core.
That's going to be a separate talk
on meeting C++ internally.
Conclusions, operating system subsystems
don't have to be sub anymore.
You can get access to all of them.
Some unusual side effects
you have to consider
when you're programming
for the operating system,
but the resulting
environment that we provide
is something where you'll feel like
you're just programming normal C++.
But you actually are in full control.
POSIX isn't bad, but I think it's bad C++.
It also has some costly side effects.
So that's one reason why I don't think
that's the perfect operating
system abstraction anymore.
I'm not saying we should
throw it out the window,
by all means.
But it's not the perfect abstraction
and not suitable for our purposes.
So that's it, actually.
Come find us.
If you have any questions,
I guess we have time.
Yeah.
(man talking quietly)
For ARM, oh, that's a good question.
Well, one of the things we have done
recently, or actually,
within the last year,
we switched from 32-bit to 64-bit.
And when we did, we tried
to keep support for 32-bit.
So that means if you go
into the source directory,
it's all opensource and
available on GitHub,
you'll already see that
we have done a lot of work
in terms of separating
architecture-specific stuff
into separate places.
And the build system
is integrated with that
so that you can kind of specify
which architecture you want to build for,
and it will produce the
binary corresponding to that.
We have been running a lot of our tests,
and I think the IP stack
has been run on ARM.
But the subsystem, the driver layer,
that's not implemented for ARM.
We are planning, we are moving
into running on bare metal.
We've done successful tests
running on X86 bare metal.
That was quite exciting.
And ARM is obviously the natural next
choice, but I can't give
you a particular date.
Any other questions?
No?
Okay.
Come find us.
Go to the talks.
(applause)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>