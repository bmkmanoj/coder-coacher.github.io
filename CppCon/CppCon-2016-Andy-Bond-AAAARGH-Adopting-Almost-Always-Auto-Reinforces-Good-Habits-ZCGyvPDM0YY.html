<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: Andy Bond “AAAARGH!? Adopting Almost Always Auto Reinforces Good Habits!?&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: Andy Bond “AAAARGH!? Adopting Almost Always Auto Reinforces Good Habits!?&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: Andy Bond “AAAARGH!? Adopting Almost Always Auto Reinforces Good Habits!?&quot;</b></h2><h5 class="post__date">2016-09-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZCGyvPDM0YY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay good afternoon everyone my name is
Annie bond I'm a lead software engineer
at Blizzard Entertainment I've worked
there for the last 16 years I've on
games like Warcraft three more than
Warcraft Starcraft 2 and most recently
here is in the storm and I want to thank
you all for joining me to talk about
what many would consider to be a
controversial subject that is the almost
always auto idiom so before I get too
in-depth the far marshal has asked me to
let everyone know that if you have
torches and pitchforks please take them
outside it's not safe in here if you
want to form an unordered mob outside
that would be the best thing I think so
to give you a heads up of where we're
headed today first I'm going to cover
what the idiom is in case you're not
familiar with it then I'll walk you
through a case study that I picked to
try to understand the implications that
has on code that I work with and then
I'll walk through examples for how we
can apply almost always auto two
variables two functions lambdas then
we'll take a look at how we can deal
with some problems that come up with
branching and looping and I'll conclude
with a overall take away kind of my
observations based on this experience so
the idiom if you haven't heard of it
before really what it's all about is
trying to prefer to reduce types trying
to deduce types as much as possible
rather than using explicit types it
leverages new C++ 11 and 14 keywords
like Auto and deco type and tackle type
ah no it's primarily been put forward in
the community by herb Sutter and Scott
Myers and I think herbs
sums it up pretty well here that the
intent is to write code against
interfaces not implementations when I
took a look at trying to see how this
could be applied in code bases that I
work with and talking to the rest of my
team there was a lot of concern quite
understandably so about the impact that
using this style would have on code
readability versus flexibility so since
I'm from a gaming background I picked a
very simple game to try to understand
the implications that it would have on
code bases that I'm familiar with so we
have a very simple game loop on the
right hand side which will form the core
of our evaluation and the game just
starts your player at a maximum amount
of life and then you cast one of two
random spells each turn each spell will
either increase or decrease your life
and then the game ends when you have no
life remaining so here's the definition
of the game struck that we saw use them
a previous line pretty straightforward
again this is no this doesn't have any
almost always auto principles assigned
to it yet this is just a framework for
us to talk about the effect that that's
going to have so at the top I have an
alias named life which is currently an
unsigned integer below that I have a
maximum amount of life as a static
constant property of the class
underneath that I have the default
32-bit unsigned 32-bit Mersenne twister
pseudo-random number generator which
I'll used to do a variety of random
choice in the program underneath that I
have the current value of life which is
default member initialized to
the maximum amount of life and then
finally I have three functions that will
help to us to understand how almost
always auto can apply to them to them
our spell functions heal and hurt they
both take a life value as an L value
reference and then return it back out
and then finally the turn function which
we saw in the previous slide just simply
returns a boolean to indicate whether
the game should continue so here's the
implementation of the healing hurt
function nothing very sophisticated here
I've had to add an extra alias here for
uniform and distribution just so that
everything fits on the slide so inside
each function we define a uniform int
distribution which either will pick a
random value between zero and the
missing amount of life or zero and the
current amount of life and then it'll
either add or subtract that value as we
go forward and use these spells and then
finally here's the turn function it
declares an alias at the top to kind of
hide the nastiness of a pointer to
member function syntax we define an
unsigned array with each of the to spell
member functions inside of it and then
below that we have another uniform and
distribution which we're using to try to
decide which element we're going to pick
from the unsigned array up above and you
can see that we're using the uniform
distribution underneath that and then
dereferencing the pointer to member
function and then calling the life
passing at the life value checking that
the result is greater than zero to just
sign if we should continue okay so when
starting to apply almost always Auto
principles I
I kind of followed these general
guidelines and by the way for any code
that you see on here it's all on github
there will be a link at the end and I'll
send my my slides out to the committee
so they have those available the the
guidelines I followed were to use
forwarding Auto as much as possible
it's very universally applicable it
works with both l valuing our value
references works with non copyable and
non moveable types any in any instance
where i had a variable that i wanted to
make sure that compiler enforced was not
mutable then I'd add I used Const L
value reference to auto instead and for
any circumstance for I definitively want
to copy or move then I'll just use plain
auto and I avoided using pointer to auto
or L value reference to auto because I
felt like for the forwarding auto that
kind of encapsulates everything I need I
don't need to specifically use the L
value reference daughter and uncle type
on it was really mostly intended fries
with forwarding functions anyway so I
started to apply these principles and I
immediately ran into trouble because the
only variables that are members of the
class that I can convert using almost
always thought of style is the maximum
amount of life because the standard
doesn't allow you to use to define the
other two variables here the engine and
life values as auto and I believe the
reason for that and some someone can
correct me if I'm wrong is that we're
concerned about potential ambiguity if
you have constructors and initializer
lists so that's a real shame
the syntax at the bottom I didn't even I
just included for
completeness sake this is basically
mimicking what
Declan ibotta would do but I would I
it's not worth it to really do that we
have a little bit more luck with the
non-member variables that are inside of
the spell functions those are very
straightforward to convert over I just
picked her as an example here you can
apply the same transformation to the
heal function it simply moves the type
to the right hand side initializer and
then uses forwarding on it for the array
of spells that I had inside of the turn
function this was a little bit more
difficult to contend with at the top the
first attempt is stood initializer list
at least that's what it reduces to which
isn't really what I want because you
can't directly use subscript operator
with the initializer list you can of
course use stood begin on an
initializing list they're guaranteed to
be contiguous so you could use that to
kind of index into it but that's not
really very convenient next you might
try to do to add brackets brackets there
to specify an unsigned or a sized array
unfortunately it doesn't work either the
compiler says that that's arrays of auto
or not permitted the closest I was able
to get was to define an alias which has
the type there so that the braces can be
treated as a constructor but this still
isn't that scalable because for each
different type that you want to create
an array of you have to declare an alias
so that's not a really great solution
either the library fundamentals ts has a
function that they're proposing called
make array which actually helps quite a
bit in this case
simply provided however many arguments
you want and based on the number of
arguments it will create a stood array
using the common type of all arguments
that you pass in so I think this is this
is a pretty useful addition and I hope
to see it added to a standard officially
soon it has a nice property as well
which you can see at the bottom here
where if you explicitly pass in a type
here it will override what it would
normally try to deduce so what would
normally be a dinner a of three intz
becomes a stud array of three doubles
even though many of the Makery
are sorry many of them make functions
are likely to go out of style with c++
17 I think this this function in
particular is still going to be very
useful okay so next I took a look at how
I can apply almost always Auto to the
functions that I have and the general
guidelines that I followed were using
Auto for any circumstance where I wanted
to return a local variable or an hour
value and if a function has multiple
return types then on the auto will be
deduced as the common type of all return
statements I didn't really have any
getters in this example but if I did
have them then I would use an l-value
reference to auto for those as the
return type and then for any functions
that simply return the value of calling
another function basically forwarding
functions I'll use deckle type audio so
that way if the function that I'm
calling happens to return by value or by
reference
it'll pass that directly through as the
same type and then finally if I needed
to fina anything I prefer to use Auto
even though it doesn't really bias
anything here just to kind of help to
corral the spin a statement out of the
left-hand side and a
after the parameters that has a nice
side effect where if you want to use
expressions VNA using the parameters you
can you can do that by moving it there I
think it just looks nicer to have it on
that side so the first thing I did was
to try to take an opportunity to look at
the common patterns that were already in
the code you may recall there were
multiple instances where I defined a
uniform in distribution so I said well
let me see if I can do more deduction
here by creating a helper function I've
called it make UD here just to keep it
on the slide and what this does is it
takes two template parameters a and B
which can be different types it will
then deduce the common type of those and
pass that as arguments to the D type
here which is the uniform in tester
bution you may also notice that this fee
name is based on whether or not the
common type is integral so you can
imagine defining an overload for this
which span a is based on whether it's a
floating point type and then you don't
have to worry about typing out uniform
and distribution everywhere so I like
that approach so here I've updated the
functions to apply the rules that I just
mentioned as well as to use the makey d
helper function that I wrote the logic
is all the same but it has the most of
the types removed the only thing that's
really still visible is the parameter on
the heel and the Herk function which
isn't shown here just for space reasons
I think I can do one better for the
selection of a random spell I really
want to pick a random element in the
range since I have an array to work with
I'm might as well have a function to do
that so C++ 17 has another function
coming in that's going to allow you to
select n elements from a range but in
this case I just want something simple I
just want one so I have the begin and
end of a range as well as the G is the
gonna stand in for the uniform stood
around a number generator and then I I
simply figure out how much how many
elements are between the two iterators
that I passed in and as I did previously
and then I call stood next to advance
the first iterator that many times now
I've specified this is an input iterator
you could do that it would be better and
more efficient as a random iterator so
just keep that in mind if you want to
use this and you your own code here you
can see and apply it to the turn
function it's obviously more code than
we saw before but we don't have to deal
with trying to calculate the distance
between those two and everything else is
basically the same here so you may
recall that the functions that we still
had for the spells they still had a
parameter with a named type so I want to
take this a little bit further and try
to find a way to get rid of that type to
see what it would look like in that case
so the guidelines that I followed for
lambdas I use forwarding Auto
for any circumstances where I have a
Landon that I want to give a name to
I'll use forwarding Auto for input
parameters and then I'll use an l-value
reference to auto for any parameters
that you
kind of have their lifetime managed
outside of the lambda like we did with
the life for any lambdas that need to
return by reference I've done I've used
L value reference to Auto as the
trailing return type here since by
default lambdas won't return Auto just
playing Auto and then for any forwarding
functions or forwarding lambdas that I
want to use
I'll use the trailing return type of
deckle type ATO to get the same
functionality I had with forwarding
functions so I can now define the heel
function within the body of the turn
function as a lambda and this gets rid
of any explicit types that we had listed
in a signature I had to update this to
pass the engine as an additional
parameter you'll see why on the next
slide and I did that instead of just
capturing this and passing it through so
beacon
sorry because we can now do I might go
up okay sorry because we can now define
the spells as lambdas we can actually
declare them as independent parameters
of make array and this the only
constraint that we have to use in this
circumstance is that because these
spells are all lambdas lambdas all have
a unique type so I have to cast the
lambdas to a uniform function pointer
which I've defined up above the
signature for that just to make sure
that if I have multiple lambdas passed
in to make array they'll be considered
the same type then this is the rest of
the turn function wouldn't really need
to change any further
so I want to take a stock of where the
changes that we've done so far so we've
added a good amount of reusable
functions that can help to deduce things
going forward but we have a lot of
difficulty trying to deal with C style
arrays if we're really trying to take
deduction to its extreme I don't want to
have to get in the habit of defining my
array sizes so utilities like the
experimental make array I think are
going to be pretty useful we can get
those in the standard as we saw in the
turn function if you want to just add
another spell it's as simple as adding
another parameter to the maker a
function you don't have to remember to
update things independently which is a
nice property it would be very easy to
go in and add another member function
that we had earlier and then forget to
update the array this has the property
that the spells are no longer visible
outside of the turn function and they're
actually even hard to spot individually
inside the turn function unless you're
doing something like adding a comment
before each lambda so as far as the the
changes that we we saw that we can
actually measure I counted the total
number of types that were in the both
versions before and after we started and
you can see that the explicit types
decreased quite a bit the we couldn't
get rid of all of them because of course
the member variables that were
non-static can't use almost always auto
style and we were able to get most of
the types different defer to deduce the
total number of words actually increased
a fair amount and the total number of
characters increased
it's a substantially so after running
the game for 11 million turns I measured
that the time actually to do that
decreased with the almost always auto
version and that was a little surprising
but I think that performance improvement
came largely from the conversion to
lambdas we no longer had the complexity
of dealing with the pointer to member
functions that we had previously so I
look at something a little bit more
complicated here so I now have a spell
that I want to add to the game which is
going to deal a conditional amount of
damage based on the current state of the
player so if you have between 80 and 100
percent life it's going to deal 25%
damage going on down to if you're
between 0 and 20% life we won't actually
change your life at all and you can see
here the definition in the non almost
always out of form pretty much follows
that pattern that we saw in the previous
slide and the key here is that I wanted
to find a way that almost always auto
could tackle a common practice of say
defining the value of life conditionally
I don't want to have to incur the
overhead of assigning a default value to
begin with and then changing it later
now there's other ways that you could
deal with that
besides converting to almost always auto
but if you'll bear with me I just wanted
to view this as an exercise of how to
deal with this particular constraint
there's sometimes reasons why you can't
simply use a helper function to do that
so to to kick this off I'm going to use
a very antic function to evaluate all
the branches that we had previously the
very on ik function has three template
parameters
if then and else they're all function
objects else's is a very attic parameter
pack so I'll evaluate the if if it's if
the result then it returns is
convertible to true then I'll return the
result of calling the then function
otherwise I'll recursively apply the
else parameter pack until I run out and
here's the terminating case and I'm sure
if STL is in the audience he would
probably chastise me for using the
recursive version of this but this was
on purpose because I want to make sure
to short-circuit and not evaluate the
other branches when I don't need to you
can see an example a trivial one at the
bottom so if the first lambda
there's pairs of Lando's there and the
first one is the condition the second
one is the result that we'll use if that
conditional land ever returns true so in
this example you can see that the
results because the first conditional
lambda returns false and the second one
one returns true is not the result is a
double of 1.0 and here we've applied
that same logic to the branches that we
had previously and this has a nice
property that even though it doesn't
look like a traditional series of
if-then else's change is only ever
assigned a value once we know which
branch we're going to take so choose I
feel like it's kind of like four
branches what 4-h is for raw loops it
expects a regular pattern and we'll try
to help enforce that for
each branch that you take on the
downside just like with 4-h the the raw
behavior is kind of hidden behind the
template function and you can have
errors due to mismatch arguments that
could be hard to diagnose if you don't
have a good amount of static asserts or
or potentially concepts to help you
the initial version that I had was using
a stood pair of the condition and result
function objects which is gonna be a
little bit safer but it was a lot more
verbose of the call site so I opted in
for the version that fit on the slide a
little bit better and then finally as I
mentioned earlier you could if you don't
want to use something like chews you
could use lambda as an immediately
invoked function expression or just
another helper function to kind of do
that branched evaluation as you see fit
and the the overall impacts on our code
base was that we now decrease the
explicit types to zero and the number of
deduce types actually went up
substantially a lot more than we had
explicit types originally and the reason
for that is that we have a number of
types that are kind of hidden due to all
the lambdas that are being used the
lambda type itself and then the deduced
return type for the lambda the total
number of words increased a good amount
from 81 and 97 a ton of our characters
increased a good amount to you but the
really surprising thing to me ms that
the performance was identical and that
was because the optimizer did an amazing
job of taking both of those forms and
recognizing that they're doing the same
exact thing okay so most of our games
have multiplayer so I thought why not
finish off by adding multiplayer support
to the game to see the impact that all
always otto has with loops so we'll
change the current amount of life that
we have to an array in each turn we'll
iterate over the array and we'll skip
any element if the life is already zero
if they're dead then we'll end when all
life values are zero so here's the
changes that I made to the none almost
always auto version I had to omit some
other stuff that didn't change just for
space here but at the top you can see we
have a stint array of size three for one
for each of our players of life and then
I've had to update and add a constructor
here that fills in each of the values
with the maximum amount of life that's
because the only other alternative is to
add braced initialize or a default
member initializer afterwards that has
one element for each of the three life
values and that's not really very easy
to maintain so I kind of prefer using
fill in this circumstance and then
finally I updated the body of turn this
isn't the complete code but I updated it
to loop over the values in the array and
apply the logic that we saw earlier and
the spell here it's not defined but it's
basically just a shortcut for picking
the random spell and then calling it so
now if you followed shown parents C++
seasoning talk it's amazing talk he
recommends using stead for each to try
to avoid raw loops and I've done it here
but because state for each doesn't
really allow any output it's really just
geared towards modifying your your array
I found to capture I haven't define a
the any alive
outside of the 4-h call so that it can
persist after the call is done and then
I capture it and update it with the
Landa so this is pretty good but it does
have the downside that we've had to do
that association with explicit
association with a pool which isn't
great if we want to update the logic
that happens inside of the lambda as we
iterate over each element so I looked at
the standard algorithms and none of them
really helped me out here so what I did
was I kind of smashed the idea of
student community and transform reduce
into this kind of monstrosity and I've
rearranged the order of the parameters a
little bit simply to try to help
actually deduce the type of T and that's
helpful in this case because I have a
value that I can figure out entirely by
looking at the signature of the unary
option and deducing that by providing it
with the input iterator and
dereferencing on so it'll produce the T
type that I'm interested in so even
though it's a little bit different from
the order that parameters appear instead
accumulate ørsted transform reduce I
like that you can define it in this way
and have that extra initial parameter
kind of default initialized so we'll
take the first and last elements in the
range the unary operators going to be
our transform and the binary op is going
to be our reduction and then just simply
iterate over the range and apply them
and then return the result when we're
done here it is applied to our turn
function
it's a lot more code now we have the
begin and end of the life range as the
begin and end parameters then we have
the lambda that's going to be our
transform function it's responsible just
for checking to see if the life is the
current life value that it's iterating
over happens to be greater than 0 and if
it is then we'll call the spell function
and finally return whether or not the
that particular player is still alive
and then at the bottom we have our
transparent lambda which will take the
value that we've been accumulating over
time and the latest result that we just
calculated and reduce them together and
it knows I didn't have to specify the
initial value here it can completely
deduce that because of the type of the
transform land up above so that would
start it off at false so overall I felt
like if you're trying to avoid raw loops
and you're trying to use almost always
out of style that's going to require a
bunch of additional work to try to
understand how to make that function
properly most standard algorithms don't
really want you to try to mutate the
contents of the range some don't even
let you invalidate iterators it would
have been nice to use a function like
said any of here but unfortunately that
wouldn't work because it exposed
explicitly says that the range shouldn't
be modified so a key mutate unlike state
transform reduce can figure out the type
of the T parameter and default it so I
think this just kind of highlighted that
if you're developing a generic algorithm
that the parameter order is important
and that if you're trying to use
standard algorithms that you have to be
very cautious of any potential narrow
contracts that they might have and it
finally just kind of taking a look at
the overall impact that the looping
changes had we were able to eliminate
almost all of the explicit types that we
had the only ones that we couldn't get
rid of our non-static member variables
the total number of deduce types is
actually larger than the total number of
explicit types that we started out with
because in the additional land is the
total amount of words and characters
both increased substantially due to all
the extra land is that we had to use and
this is a little surprising the
performance is slightly slower with
almost always auto version the optimized
assembly is pretty close but not
identical
I think the there were probably one too
many layers of lambdas for it to kind of
chip all of them away so here is kind of
my overall takeaway after going through
all these examples and trying to see the
impact that they had I'm not going to
read through all of them but I think
these kinds of properties are important
for you guys to consider when figuring
out if almost always a lot of style is
it's the right thing or not for your
code base and since I think we're
running a little bit early on time I
have a couple of bonus slides after this
but I sorry for the formatting mess up
there but if you want to take one thing
away from this talk it's that more
typing for Less typing if you use almost
always auto that was kind of something
that my co-workers and I joked about so
just keep that in mind and forget the
bonus slides I'm to thank bunch of my
colleagues for providing some great
feedback on on this and there's a link
to the github repo that has all the code
that I developed I'll take questions
first thing we have time I can go over
the bonus slides
questions how many people use almost
always auto ok how many of you feel who
were kind of on the fence feel like
you're more interested now ok how many
are less interested all right fair
enough thanks for your honesty go ahead
could you expand on your reasons for
using Auto ref ref for local variables
just Auto ball yeah the main reason for
that is to work with types that are not
movable or not copyable so it works
nicely with unique put our shared footer
proxy types as well like if you're if
you're trying to iterate over a vector
bulls or a bit set you don't have to
deal with any problems of not being able
to do that correctly it just kind of
works inversely which is nice any other
questions so this seemed to have a lot
of boilerplate due to the lambdas and
trying to put everything into stuff that
looked like standard functions yeah so
my question is how much of that
boilerplate do you think would have gone
away if you'd been I guess less extreme
about the always almost auto and used
auto everywhere that it was say you know
easy or not writing a bunch of
boilerplate and how much fun effect
would that have had on the code base
over trying to force it as far as
possible
right which you know may be why it's
scaring people off this talking that
kind of stuff
yeah I mean my intent and going this far
was to see what it looked like when you
do apply it to this extent I don't think
anybody is necessarily advocating that
you go that far
but I wanted to see what it looked like
and it was interesting that as I
continued to try to push things I felt
more and more like leaning towards
generic algorithms was helpful or trying
to develop additional ones that was the
surprising result I wasn't really
expecting that that I would develop a
bunch of helper functions outside of the
scope of the talk necessarily I wasn't
even trying to do most of those to show
as examples but they ended up being
useful so go ahead do you really write
quote like this in production no this is
this is admittedly a toy example I think
we're on my team we're starting to look
at how to practically apply almost
always auto whether or not to even do it
this was an exercise to try to help me
understand the impact I've shared it
with folks on my team so I think it they
can feel more comfortable with the idea
of even trying to do this before it
really did
I went through this exercise I think a
lot of people were very understandably
apprehensive about the potential impact
that it could have on readability versus
flexibility so I think you know I went
very far along the scale probably
farther than herb would want me to go by
it it was an interesting exercise
perhaps the last question has made this
bit moot but how do you overall feel
that this has affected the readability
maintainability of your code and the
productivity of working on it
I think I've seen cases I mean aside
from this toy example I've seen cases
where it actually has helped quite a bit
as we have a lot of cases where we're
trying to convert from say our own
custom containers to something like
standard library containers and by
trying to leverage almost always Auto
more and more we don't have to worry
about updating so many places at least
in terms of the the simple st. tactical
change to convert from one named type to
another obviously you stopped I'm
worried that the interface is compatible
but if you tackle your conversion
project and good phases I think you can
do that good well I think the recurring
theme that I observed in your talk it's
it's more cold you know every step it's
more code yeah and I think everyone will
agree that it's a lot less
comprehensible then so I would like to
coin the term almost never Auto doesn't
doesn't quite roll off the tongue as
easy as almost always but I I can
appreciate where you're coming from I
think the complexity of some of the
tricks that I've pulled here is probably
beyond what most people would recommend
go ahead
could you go back to slide 27 sure so
you have a comment that says that the
return of the lambda is a double but
could it also be a float and if it could
and at that point is it possible that
other types could be incorrectly deduced
and how would that affect I'm not sure
how it could be a float in this case
it's the common type of both the first
result which is returning an integer and
the double which is the second result
maybe I misunderstood your question no I
think that was it okay I wanted to
mention a case where you didn't go far
enough I thought oh this one's good but
actually 34 I think is maybe a little
more compelling yeah
yes so here you actually have explicit
typing even though it looks like
everything is deduced and it's hiding in
the deckle type this I mean previously
was also hiding in the result of and the
mistake here in highly generic code
which I would worry about in the
standard library although it would
probably never occur in application
production is you have asked the
question what would happen if I invoked
Yuna or you up on D referencing the
iterator and the value category matters
your actual invocation uses you up as an
l-value always but if you've been given
an hour value the deckle type is asking
what if I invoke this thing as an
r-value and those can now give different
answers with rough qualifiers yep so a
sufficiently motivated attacker in some
sense can force you to deduce the types
incorrectly because the T asked the
question not with Auto but with deck
eval forming it through different paths
so here you didn't go far enough with
Auto thank you for pointing that as
versatile yep any other questions I can
show you some bonus lines so one thing I
I ran into while trying to develop this
talk was difficulty with trying to pass
templated functions through two standard
functions like in this case if I want to
calculate the maximum value in a range
you could use stood max element to do
this but I wanted to find a way to deal
with the fact that if I were to try to
pass stead max trying to explicitly
qualify it is ambiguous so I didn't
really have a way of trying to deal with
this in a case where I wanted to deduce
as much as possible so I realized that I
could use a very annek generic lambda to
actually capture the function that I'm
interested in in
using and use argument to dependent look
up inside the lambda to actually forward
it through transparently so this way
whenever I pass in two stood accumulate
it will be passed through directly to
the periodic lambda that I have here and
I don't have to worry about trying to
qualify max with an explicit type so I
found this to be useful it's a lot more
typing than using stood max element
obviously in this case but I think it
might be useful beyond beyond that so
there's no more questions thank you all
for your attention and for not rushing
the stage to attack me with torches and
pitchforks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>