<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2014: Howard Hinnant &quot;Types Don't Know #&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2014: Howard Hinnant &quot;Types Don't Know #&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CppCon 2014: Howard Hinnant &quot;Types Don't Know #&quot;</b></h2><h5 class="post__date">2014-10-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Njjp_MJsgt8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right I guess we better get started
here title this talks is types don't
know pound actually its types don't know
hash my name is Howard Hinnant I worked
for ripple labs and I'm thrilled to be
here at CPP Con 2014 so today I'm going
to be talking about a new way to hash
types now I'm not going to be talking
about a new algorithm but rather a new
infrastructure for hashing types the
technique I'm talking about is being
considered for Standardization it has
not been accepted and there's no
guarantee that it will be accepted in
fact the odds are probably against it
however whether or not the committee
standardizes this infrastructure and if
they do the soonest would be C++ 17 so
that's three years away if you like this
technique you can start using it today
there's source code that I can point you
to at the end of the talk it's a github
account you can download the code and
use everything that you're seeing here
today if you like it and I encourage you
to do so I I think it's a great new
technique if you're interested in
hashing types and putting them into
unordered containers and that sort of
thing also if there's any questions
during the talk I'm the type type of
speaker that you know is fine with
interruptions just chat out might be
best if you use the microphone there in
the center of the room if you have a
question just get up from your seat
there you go in evidence thank you so
because I only have an hour this this
technique is fairly simple but there's
some some details to it that that can
get kind of complicated I will mention
those details as I come to them but I
won't dwell on them
this talk will concentrate on the just
the high points of this technique just
because I want to give you the idea of
what's going on and when I come to
something that I'm really proud of or
think is really important you'll see one
of these these stars beside it so if
you're multitasking maybe checking your
email or something
if you see one of these stars that's
when you really should look up and pay
attention because that's the part that I
really want you to hear as I mentioned
details will be mentioned in passing
mainly just to let you know that the
details exist that we thought about
these details but I won't be dwelling on
a lot of the nitty-gritty but my main
point when I mentioned details is to
just let you know that they exist let
you know that we have are forgotten
about such details and if you want to
learn more about them you can read about
them in the in the standard proposal and
I'll give you a link to that as well and
know that there the details are fully
fresh fleshed out in the reference
implementation so it's not that we were
skimping on the details and in the
actual code just in the presentation so
some of the issues that I want to talk
about as the first one is how should one
combine hash codes from your bases and
data members that is when I'm when I'm
talking about types I don't really care
about hashing the intz and hashing
strings I'm talking about the classes
that you guys write which are usually
made up of several strings or a vector
answer or what have you once you hatch
each of those pieces how do you combine
them together in a good way and once you
do create that how do you know if you
have a good hash function or not a lot
of times if you're just using standard
hash the specific algorithm for standard
hash isn't specified so you really don't
know what algorithm you happen to be
using except that it was supplied by
your your standard live implementer and
if somehow you knew that you weren't
happy with your hash function by some
kind of measurement how would you go
about changing it how much work do you
have to do that's really what this
entire infrastructure is about it's
finding ways to figure this out and
finding ways to easily easily switch
from one hashing algorithm to another
I'm not going to be suggesting any
specific hashing algorithm although I
will dwell on one for certain reasons
and when I get to those out I'll tell
you about that so to start off
the whole thing I'm going to keep using
this class customer as just as an
example it's got a couple of strings in
it it's got it in in it and I just want
to explore different ways of hashing
this relatively simple type as an
example so the way people usually start
doing this you know you might have a
hash code function or however you want
to name it and people often use standard
hash and you know you hash your first
name you hash your last name you hash
your aunt you're left with three hash
codes but you only hit get to return one
of them so somehow you've got to combine
all these hash codes together and
there's a boost function called hash
combined that'll do this for you and
that's even been proposed for for
Standardization and that will smash all
these all these separate hash codes into
one by some unknown algorithm so is this
a good hash algorithm well we don't
really know what this is doing we don't
know what hash combined is doing and so
we we really don't know besides testing
if this is a good hash algorithm so you
might test it and discover oh this is my
sample data set and it's colliding this
amount of time is that good or bad
well the only way to really tell is to
try a different hash algorithm and see
if your number of collisions goes up or
down and you might also be curious about
whether hash function executes slower or
faster with this alternate alternate
hash algorithm so to do this you know
alternate hash algorithm how do we do
that what do we what do we need to do to
use some other hash algorithm so as just
an example my other hash algorithm is is
going to be this thing called FN v1a
it's a fairly old hash algorithm it's
actually surprisingly good but it's not
the best in the world the technical
reason that I've chosen to concentrate
on this one
is because the whole thing fits on one
slide it is the it is one of the
simplest hash algorithms in in the world
but despite the fact that it's so simple
it contains all the key functions all
the key characteristics I should say of
almost every hash algorithm out there so
its simplicity is great it's got
everything I want to show you
and yet this thing is really very simple
and don't worry about all these strange
numbers here because those aren't part
of the characteristics that I'm that I
want to show you and I'll explain those
characters characteristics in a minute
but at any rate if we're going to use
this other hash algorithm just taking F
and V 1 a as an example we might use it
just like we use standard hitch we
hashed the first name we hashed the last
name we hashed the int and now we've got
three hash codes and we've got a
fallback to boost hash combined to clump
these all together so I'm not really
happy with this solution for one if I
want to use F in v1 a I want to use F in
V 1 a or if I want to use sip hash or
spooky or whatever I want to use that
algorithm and I don't really want to
pollute it with this hash combined step
it's a well-known fact that good hash
algorithms are really difficult to
design so we've still got this this hash
combined thing and and I'm not happy
with that because this is polluting my F
in v1 a so the first thing I want to do
is get rid of this hash combined and to
do that I first want to talk about the
characteristics or the anatomy of your
typical hash function hash functions
first of all they have a state sometimes
the state can be very simple in the case
of FN v1a
our internal state is just a single size
T but in general a hash algorithm could
have like an array of size these 5 of
them 10 of them whatever or really any
arbitrary state and the first job of the
algorithm is to initialize this state to
some initial state the second in the
second phase of a hash algorithm
computation it consumes bytes into its
internal state and then there's a
finalization stage where it's no longer
consuming bytes but it's continuing
mix or do whatever to this hash State
you might think of it as the boost hash
combined phase but it's particular to
every specific hashing algorithm and
that's really is all there is to any
hashing algorithm it's these three
phases and I'm gonna be a little bit
repetitive and they keep coming back to
these three phases because it's it's
it's key to making this whole system
work so let's take an let's go back to
our example FNV 1a the initialization
state is just this one line here's our
internal state a single-sized T and to
initialize it we simply cram this number
into it and it's not important what this
number well it's important for the
algorithm what this number is but it's
not important to this talk what that
number is it's important that that is
the initialization phase right there
it's very simple other hash algorithms
will have much more complicated
initialization stages but this one fits
on one slide and is easy relatively easy
to understand so the next four lines are
the phase where you consume bytes into
the internal state and then finally this
is our finalization state here that's
about as simple as it can get it's the
identity operation to finalize this
algorithm you simply return the single
size T as the hash code other hash
algorithms will have much more
complicated finalization States but we
get to go with identity here so consider
repackaging this algorithm to make these
three separate stages separately
accessible now how would you go about
that the next the next slide is going to
do a neat little animation and the
animation isn't there just to be cute
it's to emphasize that when I repackage
this thing I'm not going to change any
of this source code I'm just going to
move it around I'm going to turn this
function into a class and you'll be able
to access each of these three phases
separately so looks like this
now we have a class we have a default
constructor that's responsible for
initializing the internal state I'm
using C++ 11 here to implement my
default constructor that's just a detail
to help me fit all this on one slide
it's not really important in fact it's
not that important that it be a default
constructor you could construct this
thing any way you want but with a simple
algorithm like this default construction
seems to be the right the right
technique then I've got you can call it
an update operator but an operator paren
that takes the the same arguments as
before that consumes bytes into the
internal state and the key thing here is
to recognize that I can call this over
and over and over again I can call it
more than just one time since it's now
separately accessible and in my
finalisation state I've coded just as
explicit conversion operator to result
type which is just a size T when they're
in the repackaging you can imagine that
for other algorithms this this could be
arbitrarily complicated but here it's
just very simple oh and this parts
really important so separating one
algorithm into three phases that's key
to this whole technique let's go back to
our customer class and again look at how
we might write our hash code algorithm
so the first step in using this is
simply to default construct our RF and
v1a algorithm question yes sure so the
quote the question is is can we can we
stick a Const here
I would think generally no for that for
this particular algorithm you really
could but in in non-trivial out well I
shouldn't say non-trivial and more
complicated algorithms this will change
the state further as it's doing the
finalization stay
and so you would have to make your state
mutable if you wanted to make this
constant so you might as well keep it
non constant yes so you're exactly right
this should be called only once and we
can we'll be able to wrap that up into
other code to enforce that that
invariant yes that's a reasonable
reasonable tweak to this algorithm you
know we could one could think about
doing that any other questions before I
move on okay so I'm sorry
oh that the comment was we we could do
in our value ref on the finalization
stage and our value refuge you would
have to say move paren and then convert
it would get the syntax would get a
little bit messy but you could do it and
and it's not a bad suggestion so the
first thing we need to do to use it is
default construct our algorithm then we
call the update stage for each of the
strings and the age and then we call the
finalization stage which is just
explicitly convert it to a size T and we
have no more hash combined so the
important thing now is we're hashing our
entire relatively complicated data
structure with FN v1a and if you think
about it if we would get the exact same
result if we copied the first name and
the last name in the end all two
contiguous memory and fed the whole
thing to FN v1a at the same time that
the result would be exactly the same so
this is really just a nice technique for
making your discontiguous memory look
contiguous for you to your hashing
algorithm so that you don't have to do
this hash combined step so that's a win
so anybody have any questions
about that stage before I go on because
that's kind of important okay
note that this same technique can be
used with almost every existing hashing
algorithm so in in later on in the talk
I'm going to show that we're going to
want to switch not only to FNV 1a but
any other hashing algorithm you can
think of or that somebody has written up
it's going to be very important to
switch from one to the another very
easily so making this recognizing this
is is very important now what if we want
to put customer in oh yes
please go ahead that excellent question
there is one hashing algorithm on the
planet that I found that this technique
does not work well with and that is siti
hash now city hashes a is a great
hashing function but it has a property
that it wants to see the entire length
of the hashing of the memory right up
front and so the only way to really use
this technique with city hash is instead
of consuming the bytes as you see them
to store them in a vector or something
and then do everything at once and that
would just be ridiculously expensive
certainly easily implementable but you
don't really want to be allocating
memory under your hash function yes oh
I'm not sure I'm understanding the
question some other class ok oh okay yes
I I think I'll be able to answer your
question a little bit further in the
talk and if I don't please ask it again
yes
I'm sorry I'm not quite understanding
here maybe if you spoke into the
microphone it would be louder and I
could hear oh sorry I went to went too
far here are you're asking about this
static cast here and why is it there
yeah oh okay
FairPoint this is just syntax at this
point so I'd like to move on and yeah
the syntax of this can be can be varied
somewhat you know it's just the naming
but the important point is that as the
technique we're using to be able to
switch from one algorithm to another one
hashing algorithm to another so what
happens if we put customer into a larger
class and let's say we you know now
we've got a class with a customer and a
product and a date and we prepared each
one of these with our FNV 1a algorithm
and how do we hash our larger class now
so our first try is you know you call
hash code on on each of these three
things and lo and behold we we're back
with hash combined we've got the same
problem we started with so we need to
fix that one another way of saying this
is this solution is not yet composable
and and and we want to make it
composable so let's go back to our
customer class and fix this if you look
at this
we what we really need to get rid of is
constructing the hash function here and
finalizing the hash function here all
customers should do is just the update
stage here in the middle so just for the
time being imagine that some other piece
of code don't have to think about where
yet is going to initialize our hash
function and some other piece of code is
going to finalize it and all customer
needs to do is append to it so with that
in mind we've got a function here
instead of instead of computing the hash
code right here in customer we've got a
function called hash append that gets an
FN v1a object from somewhere else a pins
to it and that's it doesn't bother
finalizing it and we'll explain later
how we get the hash code yes it should
be a friend because we're going to use
the same syntax for scalars and so think
of this as a swap function this is very
much like swap and it doesn't have to be
a friend but it should be a namespace
scoped function so with this let's now
go back to sale class we have our sale
class it has a hash append now it has to
do is called hash append on each of eath
its members so like I was saying before
this is a bit like a swap function or
even an operator equal equal if you've
got some class and you want to implement
the operator equal equal on it you
usually call operator equal equal on
it's all of its bases and all of its
data members and that may in turn
recurse down and call operator equal
equal on its basis and members etc etc
so we have a composable solution here
since we just update state to the hash
append this calls hash append and then
each one of these individual hash
depends may call hash append further on
its data members and so forth and so on
until you get down to scalars primitive
types are scalars
can then just call hash append on their
on their direct memory oh I'm sorry I
skipped ahead a little bit yes primitive
types and and standard defined types can
be can be given hash append overloads so
we can simplify this bit this part is
actually why I'm trying to get this
standardized if if int and unsigned long
long and all those have hash appends and
standard string and standard vector and
tuple and pair etc etc they all need
hash append overloads to now in the next
three years if you want to go ahead and
implement this before the committee
provides it for you there is software to
do this I can point it to you it's just
a pain in the rear it would be so
helpful if the committee would say okay
we'll supply hash append for nth and
long long and string and so forth and so
on
and then you can write your hash a pins
like this instead of calling the
extremely ugly update operator and this
way you know this way you let string
itself to find how it's going to update
its state to a algorithm and you let int
defined how it's going to update its
state to an algorithm those are details
for stringing int in other words if you
look at this in the bigger picture each
type is individually responsible for
saying this is how I want to present
myself to a hashing algorithm and so
types that compose it simply have to
forward to its hash append so if all
hashing algorithms follow the same
interfaces I've shown for FNV one a hash
append can really be templated on the
hash algorithm instead of being
specialized for just FN v1a and now
customer can be hashed using any hash
algorithm it doesn't have to know
anything at all about FN v1a just by
templating it so another important point
there
yes what so the question is why not make
hash a pin to function plated on to
things and then specialize it yeah you
could write you know you still have to
specialize it for each class because
it's gonna be a different number of hash
of pins for each class depending on its
data's you know how many data members it
has in how many bases and what their
names are
etc etc okay a minor point it's it's
very easy to to write a very attic
version of this hash upend it doesn't
change anything it just except for the
syntax yes a very attic version of hash
append exists so you can write it like
this if you prefer there's no
performance difference there's no
functionality difference but a lot of
people really prefer this syntax so that
exists when you get down to two scalars
or if you have to implement this
yourself because the standard committee
hasn't done it for you yet hash a pin
for an INT you know is just take the
address of the int and send in you know
however many bytes is the nth is long
typically for or for a pointer take the
address of the pointer you send it in
and this is calling the update of the
algorithm and just as a reminder those
calls are specifically calling into this
function right here so in general this
is going to be called for your ents in
your unsigned Long's and your your
pointers your scalar types and with any
luck a few years from now that work will
be done by the committee instead of hat
you have
to put it into your own application so
if you look at a built-up complicated
class like sale which is composed of
customer product and date and then if
you look into customer product and date
they're going to be composed of other
things and eventually you drill down to
scalars and you can think of this this
class is being composed of a whole bunch
of scalars and discontiguous memory and
what this is what hash append is doing
is recursively drilling down into this
data structure until it finds a scalar
and then sending those bytes to the hash
algorithm this is actually very
analogous to serialization works the
same way you when you serialize
something you say ok serialize the first
member and serialize the second member
and those in turn will have
serialization that'll drill down until
you hit something like int you know with
a value of 5 and you print out of 5 and
here we're simply sending the 5 to a
hashing algorithm instead of to a stream
so this really is it very strange it's
just that people haven't seen it in the
context of hashing before that's the
only thing that makes it strange so in
general for this technique every single
type that you might want to hash or even
somehow participate in a hash
computation has to have a hash append
overload and that'll overload will
either call hash append on all its basis
and members or at least those bases and
members that should participate in a
hashing computation or it will send
bytes of its memory straight to the hash
algorithm as would an int or a long-long
or what have you and no type at all is
aware of any concrete hashing algorithm
that's key because you want to be able
to switch from one hashing algorithm to
another so I've talked a lot about hash
append and I haven't said much about how
to use it in fact we still don't know
how we get a hash code out of this thing
well it turns out that that's assuming
you've got a hash append for every type
in the universe now and perhaps the
committee has helped us with with half
of those types to get a hash out to get
actual hash code well you default
construct your hash out
then for whatever your type is here I'm
calling it t you have pinned to it and
that may in turn call hash upend on each
of its parts and so forth and so on
until it gets down to scalars and then
you finalize the algorithm with and here
I've you know relatively arbitrarily
chosen the the explicit convergence in
text to finalize so just three steps to
do this of course one step is always
better than three steps so you might
wrap this up in a class and that class
is called a standard conforming hash
function it on the hash algorithm for
grins up put a default template to our
favorite FN v1a hashing algorithm and
it's got a nested type result type which
is the result type of the hashing
algorithm if you're putting this into
unknown or containers this result type
has to be a size T so you can just think
everywhere I've written result type here
just think size t and then our three
simple steps are just wrapped up in the
operator paren here so now that we have
this conforming hash function forming
hash function you just drop it straight
into your unordered set and now you can
hash customer using standard unordered
set or unordered map or what have you
now I've talked a lot about switching oh
before I go on question yes actually
you're you're getting into one of the
details that L that I'll get to on a few
slides or at least is contiguously
hashable at any rate yes sure
as in the right here in the construction
yes it would your a couple of slides
ahead of me let me just catch up on the
slides real quick get her that's the
trouble with putting too many animations
on one slide alright so if we want to
change hash functions the great thing is
that we don't have to to touch anything
but this guy right here we just slip in
a new hash function here I'm using sip
hashes an example and now we're now
we're hashing sail on this completely
different algorithm we just change it
right at the point of use and the key
thing is here we did not change sail one
bit and if you remember sail is composed
of other types customer product date
what-have-you we didn't have to change
those either we can keep swapping out
different hashing algorithms right here
and it's very easy and because it's very
easy it becomes trivial to experiment
with different hashing algorithms and so
we can we can compare one hashing
algorithm to another see which gives us
the fewer collisions which gives us the
greater performance and and what we can
do about securing against attacks if
what we have to put into our unordered
containers is coming from untrusted code
so very important point here today when
you want to switch hash algorithms you
go and you have to modify each of the
types that that are that you want to
hash and so this gets rid of changing
modifying the classes that your hashing
entirely so getting back to your
question
wouldn't it be useful if we if we could
seed our hashing algorithms I talked on
the previous slide I briefly mentioned
security one way you guard against one
way you harden your your hash containers
against attacks is to randomly seed it
some hash algorithms not FNV one abus
amount algorithms will allow you to seed
it so imagine you've got some get seed
function here and it doesn't really
matter how you implement that typically
it might be with a random number
generator or what have you you can
imagine it's very easy to write a
hashing algorithm that simply has a
constructor that takes a seed so how do
we use that well it goes much the same
way we construct it we append to it with
our type we've finalized the algorithm
and we wrapped the whole thing up in a
conforming hash function forming hash
function up to fit on one slide that
means they're easy enough that you can
make as many of these things as you want
you can make an unseeded hash funkier
you can make a seated hash function
functor you could make hash functions
that salted are padded this this type by
appending to it either before you call
hash append here or append to it with
salt or padding afterward you can do any
number of things in these
special-purpose hash functions and I'm
sure you know if people start using this
technique like you guys you're a lot
more clever than me you'll think of wild
things to do with your hash function to
at least to create the operator per in
of it
so creating hash functions is it's very
easy and it's very easy to use them you
just now plug this into your your
unordered set or an unordered map right
at the point of use and so you can not
only change from one hash algorithm to
another you can change from seated hash
functions to not seated hash functions
back and forth to see how that affects
their performance your collisions etc
etc very easy to experiment
it's also easy to set up defaults you
don't always have to use unordered set
directly and plug in a custom hash
function now with using template aliases
you can just create your own template
alias make your hash function default
whatever you like and now whenever you
use I called mine hash set whenever you
use hash set it's going to be using your
favorite hash by default so this doesn't
have to make your day-to-day earlier use
a lot uglier you just set one of these
up wherever everybody can see it and go
to town with it so I mentioned that
there were going to be a few details one
of them is this trait there's a trait
called is contiguously hashable and what
it basically says is can you feed this
types bytes directly into the hash
function it's update operator so it's
going to be true for two's complement
intz and that sort of thing be true for
pointers on on most platforms it's
actually not true for floating-point
types a I Triple E floating point type
is it contiguously hashable because one
of the requirements for being
contiguously hashable is that every bit
pattern should should every bit pattern
will hash to a different value and thus
every bit pattern should not be equal to
any other bit pattern and if you recall
in floating points negative zero is
equal to zero but they're represented
with different bit patterns but since
they're equal you want them to hash to
the same hash code so a hash a pen for
floating-point might set negative zero
to positive zero before sending itself
to the update algorithm so as
continuously hashable is also
performance optimization for types like
tuple string and vector string is
composed of this contiguous array of
chars we will know by this trait that
char will be contiguously hashable i
hope and so this tells string that it
can send its entire data buffer at once
to the hashing algorithm update function
and the more modern hashing algorithms
the more memory you send them to them at
once
the faster they work so that's that's
really the main motivation for having
this trait here is optimization for
string vector and even tuple if you can
prove that there's no padding between
the different elements then it can also
be contiguously hashable and there's
there's a way to do that and I don't
want to go into those details here but
it's in the it's in the source code it's
not terribly hard but I really would
like the committee to supply that code
instead of asking you guys to do it at
least three years from now do you have a
question Nevin or oh okay all right
so another detail is there does exist a
way to write hash a pin for pimple types
pimple types is where you have a
incomplete type in your in your header
that's surrounded by a handle object and
you go to your source and that's where
you expand your your your incomplete
type to a complete type and if you
recall all the hash append functions
that I've shown you so so far our
template Adhan the hash algorithm so you
might have been wondering well gee if
I'm in a source file how do I get this
generic hash function into my pimple and
the way you do it is with what I call ie
a type erasing hash algorithm adapter
and you can think of this it's it's very
analogous to standard function standard
function is a type erasing func door
adapter when you use a standard function
you don't know what type of functor
you've put into it except unless you
happen to have access to the way you
constructed it and you simply call it
without knowing what type of functor is
in there X lass a the function pointer a
lambda you just don't know it at the
point of call so there's a type of
racing hash algorithm adapter works
exactly the same way in fact it's
implemented by using a standard function
it's it's in the source code it's more
than I wanted to present here but I
wanted to let you know that if you're
writing if you're using the pimple idiom
now which is a you know very good at iam
you're not out you're not left out in
the cold you can use this technique with
the pimple idiom finally if you're
concerned about Indian there's a way to
handle that this is actually true at my
company we we have a situation where we
have a network of computers and we're
hashing data structures using sha-256
for security purposes just to preserve
the integrity of the data structure if
one machine on this side of the node
hatches this data structure and another
machine on the on the other side of the
network hashes the exact same data
structure with the same values in it it
better get the same hashcode otherwise
these two computers aren't going to be
able to agree about the contents of what
they're hashing and the hashing is
important of course for security
purposes if these machines happen to be
of two different Indians but otherwise
they have identical layout for stuff
like int sand and pointers these two
machines ought to be able to agree on on
how to hash these things so there's
within within this whole technique
there's a trigger for saying before you
hash your 64-bit swap the swap the bytes
on it because the Indian isn't right on
your native platform that detail exists
it's in the reference implementation but
I didn't want to take time on going into
it today so moving along here
in summary every type that may be hashed
or participate in a hash computation
must have a hash append overload and
this is really the hard part and this is
why I'm trying to get this technique
standardized because if we get the
committee to write hash a pin for int
and unsigned long long and pointers and
enums and pairs and tuples and vectors
and strings that will take a huge amount
of work out of implementing this
technique for yourself it will take
practical
all of the work out of it as it is today
the way you're going to handle this is
download my source code from the github
reference and all of that code is in
there to do it for you on the other hand
when you're writing hash a pin for your
own type it's very easy to do it's about
the same amount of effort is writing an
operator equal equal for your type you
new hash append each of your basis and
members and it's relatively
straightforward as I demonstrated for
the example customer class in the
example sales class so one mildly
difficult part is any hash algorithm
that that you want to use in this tape
technique it must be adapted to expose
to three phases initialization updating
and finalization but note that you only
have to do this once for a hash
algorithm and then hash algorithm is
good to use for all of your types so
it's it's kind of like the STL where
before the STL we had if we might have
in algorithms in m containers and to
give each container the the correct
number of algorithms you had to write in
n times m source code well that's the
situation today if you're using the
standard hash T style of hashing your
functions if you've got in hashing
algorithms and a type that's made of M
sub types and you want to change hashing
algorithms you're talking about writing
n times M source code to arrange that
using this technique we've separated it
out so that you only have to adapt in
algorithms and then write hash a pin for
your M types and so that's only n plus M
source code instead of n times M that's
that this decoupling is is the whole
backbone of this this technique it's the
whole rationale for it to exist
and finally the probably a very
important point hash functions are very
easy to write all they have to do is
initialize algorithm update it with an
item to be hashed and finalize the
algorithm
and this is very important that it be
easy because you need to be free to
write hash function to do different
things like hash function that doesn't
see the hash function that does seed
there's very there's at least two
different ways I can think of that you
might want to handle random seeding you
might want to have hash functions that
get one random seed every time they're
constructed or you might want to just
get one random seed when your
application starts up and use that for
every hash function
both ways have advantages and
disadvantages and because it's so easy
to write hash function you can you can
create whichever technique is right for
you we don't have to depend on the
committee to standardize it and get the
answer wrong for you and if you do all
this work what are the benefits you get
again you get to experiment with
different hashing algorithms very easily
hashing algorithms are you can either
use non seeded hashing algorithms or
seeded hashing algorithms and switch
between them very easily I talked about
getting rid of boost come I'm sorry hash
combined from boost the hashing
algorithms that you use are exactly as
the authors of those hashing algorithms
intended they're no longer polluted with
these combining steps and finally what I
think is the the most important point
when you're writing hash support for
your type you don't have to get in bed
you don't have to marry any specific
hashing algorithm you write your hash
support once and you know that it's good
for any hashing algorithm whatsoever so
clients who use your type maybe three
years after you've written it they can
decide at that point maybe I want to use
FN v1a
maybe I want to use spookier sip asher
even sha-256 whatever that decision is
down the road and can be made by
different people for their different
applications so types don't know hash a
type should only know what parts of
itself should be presented to a hash
algorithm it should not be aware of any
specific hash algorithm so thus the
title type stone
I've been promising this link for quite
a while it's about time I give it to you
don't worry about memorizing this
because I'm sure these slides will be
made publicly available but it's on my
github it's called hash append and
within that directory the whole meat of
this is in one source file called hash
append a CH but there's also a bunch of
other hat files in that source for
example there's the sip hash adapter the
spookie adapter the sha-256 adapter
there's the type e racing hash append
functor adapter whatever you call it all
kinds of so when you when you download
it there'll be a bunch of files in there
but don't be scared off by that you can
get started just with the hash append
dot H function and if you want to know
more about those details there in this
paper here this is the paper that was
submitted to the committee in 3980 and
you can find it right at this link and
also should mention Bloomberg got
excited about this and they've they've
implemented it in their open source what
they called VSL I believe or B DSL I
can't remember what they call it but
they're all excited about it too and
they they've implemented it
so it's certainly implementable by other
people besides myself it's implementable
by you guys you just go here and go to
town questions
I'll try to be quick um okay I'm really
nervous now writing for all those yes it
is largely the legwork of just because
there's so many types but there's some
types that you could implement only
suboptimal sub-optimally for example
deck is a contiguous array of several
contiguous arrays the way that if you
don't know the internals of deck you
just have to send your elements one at a
time if you do know the internals of
deck and if the element is contiguously
hashable you can send an entire chunk of
elements one at a time so this the
standard library can really do a better
job than we can vector bool is another
problem but vector bulls are always a
problem so you imagine that will start
having the idea with the I'm writing my
class I'll start saying okay well I need
to have certain things all right such as
swap is one of those things they may be
hashed and would be one of those
standard functions that you write and
then you have an external function that
just is maybe norm for your type of
classes should that be maybe a good
practice to start adopting so you have
well if you are excited enough about
this technique to go here and download
it and start using it the answer is yes
if if you're not that excited about it
you might want to take a wait-and-see
approach and see what the committee does
then you know and if the committee
standardized is that then at that point
yes hash append will be one of those
functions that you just need to write
along with operator equal equal and swap
and so forth and so on
yes I have two questions
um one is because operator equal equal
and hatch you don't have a mathematical
relationship give any good strategies
for keeping those in sync without having
to do essentially rewrite the same exact
boilerplate code in every spot
I thought the what I recommend is always
use operator equal equal equal for your
predicate in your unordered containers
doing anything else
you're just often a quick sand it gets
complicated and if you really need to go
there just go there and don't use hash
append because it's or you know yeah I
suppose if you if you really wanted to
you could sync hash append with some
weird version of operator equal equal
but yeah I wouldn't recommend doing that
I would just write a special has if you
had to do something besides match with
sync with operator equal equal I would
just write a custom hash function and
use that the other question is so part
of a good hash function is depending on
and say how the buckets are allocated in
an ordered set you know are their prime
number of buckets or their power of two
do you envision someday a proposal be
becoming too you know
tie those kind of things together you
pick the standard isn't exposed what
kind of number of buckets you what kind
of algorithm
I don't say yeah do you see some kind of
hiding advantage of that I I don't see
that coming
III don't see a way to take advantage of
that in the future and I don't see any
proposal that coming down the pike in
that department I will say that I am
biased on one way that the Lib C++
implementation will switch back and
forth between whichever you like you
give it a power of two buckets and it'll
keep power too as it doubles you give it
a prime number of buckets and it will
keep as it doubles it'll find the next
prime so yes I'm just sorry I'm late I
tried my best
what kind of pushback you see the the
pushback I'm seeing so far is on what I
call niggling details that that I don't
Carol out like what is the signature of
the update operator in a hash function
that that we need to specialize in
should it be void pointer or pointer to
ensign character or whatever I can't get
really excited about that question but
but but a lot of people are really
excited about about that part and other
push backs are some people don't have as
good an overview of the entire system as
you guys hopefully do right now because
this is the first time I've given this
presentation and so people keep trying
to improve it and that's a problem so do
you think that makes sense perhaps we
need to do it more than once which means
you know put things into sorted
containers when I sort them differently
sometimes so perhaps you wanted to
present itself to the hashing algorithm
differently on different occasions so
the second question first I guess I I
have not come up with an application
where I wanted to change what was
represented to the to the hash function
as opposed to changing the hashing
algorithm I've had plenty of plenty of
motivation to change my hashing
algorithms but but not what's presented
and I I don't know of a good way to
handle that outside of something gross
like if death and I'm sorry what could
you repeat your first question it's
already blown skipped out of my mind
automatic house of manpower inflection
an interesting way to do that might be
with equal default I don't know whether
that's technically possible
it would definitely have to be opt-in
because not every type wants to present
everything it has to a hash algorithm
for example you'd never want to have
vector present its capacity to a hash
algorithm so I don't see it as something
that would be completely automatic it
would have to be opt in whatever syntax
is used
I actually have thought about that and I
I don't know of a clean way to do it yet
because you need to do different things
floating point is my poster child
example on that for serialization you
want to keep the difference between
negative zero and zero and for hashing
you want to hide the difference between
negative zero and zero and so I don't
have a good solution for that very
problem so in some hashing strategies
you actually want to like insert the
Ling's in there as well so that you can
reduce your alias thing you know like a
name mangling kind of thing right how
would that plug in here if you want it
well in the in the specification I have
right now if you take vector for example
the specification is that vector will
send every element of its in its
container to hash append and then it
will also hash append it's linked at the
end of that and that way you don't
accidentally get aliasing between
vectors of vectors which can happen if
you don't append a length introspection
solution but there are definite cases be
different but I think one thing to
hijack
realization code that supports all the
booze containers to add support for okay
it's a very interesting suggestion thank
you very much yes there is that's
actually excellent question the the hash
function has to be copy assignable and
copy constructible for very subtle
reasons and it mainly has to do with
that that type erasing hash hash append
adapter that I saw it has to take the
hash and copy it and send it on and sure
you could you can you could have the
seed in the in the hash function struct
one it could get a new seed a new random
seed and so you could put one hash
flunked every R same out same hash
algorithm another one over here same
hash algorithm and just have them
differently seated and Oh in that case
you could you know just have a global
that's
that's what I'm getting at portion of
the interface yeah yeah the only first
thing comes to my mind is just making a
static of your of your hash hash
function even explicitly sure yes in
fact that's the the reason that the
result type was up there so that you can
customize that for example the sha-256
doesn't return a size t it returns a
256-bit animal and so that's the reason
result type is they're heterogeneous
look functionality so that I can I can
do find with the key type that's
different so long as they're comparable
but that wasn't added to the unordered
containers because nobody was sure how
to how to make sure that the hat that
the hash function works the same on
different types this seems like it could
help with that because it's all about
sort of delegating to the I that's a
really interesting question I haven't
given that a lot of thought but just off
the cuff here at least it puts the power
of what gets presented to a hash
algorithm in your hands and it puts the
power of what the hash algorithm is into
your hands and so I can I can easily see
that if you set your your key up your
external key up to present the same
information as your internal key then
you're golden and then it if it presents
different information if it presents
different information then you're not so
in that sense it certainly sounds doable
but you know you'd have to be on your
guard and and make sure that it did
indeed present the exact same
information and that yeah and then it
should just work just as an aside along
along the same lines I thought I
actually wrote a hashing algorithm that
I call debug hash that does nothing but
collect the bytes and then when you
convert it to a size T it just prints
them all out to standard error so that
in hex format so that you can debug your
hash append algorithm which would come
in very handy and doing that that very
exercise any other questions well thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>