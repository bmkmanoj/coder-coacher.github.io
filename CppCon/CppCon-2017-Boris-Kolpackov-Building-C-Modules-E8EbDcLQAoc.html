<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: Boris Kolpackov “Building C++ Modules” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: Boris Kolpackov “Building C++ Modules” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: Boris Kolpackov “Building C++ Modules”</b></h2><h5 class="post__date">2017-10-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/E8EbDcLQAoc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">- [Boris] Okay, I think
we are going to start.
Those that are late will
miss the most fun part.
Are we good?
Okay, so, my name is Boris and today,
I'd like to talk about
modules, C++ modules.
Most specifically,
practical sides of them,
there is this funny
quote from the standard,
those of you interested
can go read it in detail.
But, it summarizes well
what the standard can
and cannot say.
So, we're gonna say a bit more.
The plan is as follows: we are going to
introduce modules as a language feature,
then we will look how that
affects the build system,
then with that understanding, we will try
to get some basic design
guidelines for modules.
As you will see, it's
not as straightforward
as it might seem initially.
And, we will close off with, again,
some guidelines and how to
convert existing codebases
to modules, as well as provide
backwards compatibility
with the headers, if we need to.
Okay, so, let's just dive in.
Lots of ground to cover.
&quot;Why modules?&quot;, first question.
What are the benefits?
Well, modules provide isolation
from preprocess and macros, as
well as other module symbols.
Modules also force us to
explicitly export entities
that should be visible
to the module consumer.
So, in this sense, they are
a physical design mechanism
that forces us to think about
how we structure our code.
Modules are also a first step
towards not needing the preprocessor.
At least in most translation units,
hopefully, one day.
The most commonly used preprocess
to directive is included,
so modules make it, hopefully, unnecessary
in most cases.
Modules also open the door for a reliable
and generally available
distributed C++ compilation.
But, module as a built
system can make sure
that the compiler, and your local host,
and the remote machine have
exactly the same set of inputs.
This is not the case with headers,
compiler searches for
headers on your machine
in some unspecified directories.
And it's hard to make it work reliably
on this tightly controlled environment.
Did I miss anything?
Right, this is what we
are all here for, right?
Who cares about that other stuff?
We want faster build speed.
But anyone knows how fast
modules will make our builds?
Anyone seen actual modularized
build of a library?
There aren't many benchmarks.
The reason for that, and
we also state that clearly
at the outset is that modules
are still work in progress.
Well, this might all seem smooth to you.
There are lot of rough edges,
especially in the implementations.
Also, I forgot to mention,
we are talking about
modules DS at the
specification that is proposed
for standardization.
Some compilers provide
their own flavor of modules,
for example, Clang, so we're
not talking about this today.
All right, so how fast can
modules make our builds?
Well, we modularized a real library.
So I'd like to show you a demo.
This build to utility library,
so it's like a low-level
library with some basic
utilities that we use to build
the rest of the tool chain.
It's, I would say, probably
small to medium size.
There's little bit over 30
modules, bunch of unit tests.
So on the left, I have
a modularized build.
And on the right I have
exactly the same source code
just built as headers.
So I'm going to show
it side-by-side because
it's quite illuminating to see
the difference in the build,
in how the build's feel.
I'm gonna give each build
to course this machine
as four course.
I also disabled two bubbles,
so we have in a fairly even
playing ground.
Cap some, we have this little contraption
with locks to make sure that
they all start the same time.
Okay, ready.
So left we have modularized
build, right we have headers,
exactly the same end result.
I don't know, to me, the header build
feels a bit tedious.
So here we get about
two-and-a-half speed up.
If we run it separately on all course,
we get about three times
speed up over a header build.
This is, by the way, with Clang.
And we are also using
modularized standard library
from GCC.
'Kay, so hopefully I
have your attention now.
What exactly is a module?
Well, it's actually hard to answer this
intuitively and shortly, so
we're gonna try to answer
this question from three
different perspectives,
that of a module consumer
and module producer
and the build system that tries
to make the two play nice.
But let's make something clear.
The outset modules are not,
are a language-level mechanism,
they're not a
preprocessor-level mechanisms.
It's an import declaration,
it's not an import direct.
From the module consumer,
a module is a collection
of external names called module interface.
That become visible once
the module is important
by a consumer.
So to import a module, we
use the import declaration,
import keyboard fold by the module name.
Module name is a sequence of dots supplied
to the identifiers.
Standard does not prescribed currently
any hierarchal semantics,
though, it is customary
to refer to, for example, hello.core
as being a sub-module of hello.
We'll talk about what exactly
that means in a minute.
What exactly visible means?
Let's go on the standard.
An import declaration
makes exported declarations
visible to name lookup in
the current translation unit
in the same namespace as and contexts.
Note, the entities are not redeclared.
So this is quite a bit
different compared to headers.
When we include a header
we get a declaration.
When you import a module,
the names aren't merely
made visible.
One intuitive way I like
to think about it is
imagine here that a single
giant translation unit,
where you cooperate all
your modules and all
the consumers in this one big, say, file.
So in this single translation unit,
nothing will be redeclared,
you'll only have one copy
of everything.
And everyone will see declarations
in exactly the same way and
exactly the same namespaces
and context.
This visibility semantic,
such as that modules
are not name scoping mechanic, right?
Module and namespaces
are orthogonal concepts.
Modules can export names from
any number of namespaces,
including global namespace.
Namespace name and module
name may not be related,
though, generally,
it makes sense to to have
a parallel structure,
we'll discuss that in a bit.
Specifically, an import
does imply any additional
visibility of qualification for
names declared in namespaces.
So here's an example.
Let's say we have module
hello.core, which exports
function f in hello namespace.
Merely importing this module does not mean
that you can call f unqualified.
So we still have to use the
usual qualification mechanisms
or a using directive.
Modules also deal with names, not symbols.
Everyone is clear what the distinction is.
Well, a quick way to recap, names,
our compiler complains about,
and symbols our linker complains about.
So modules talk about names not symbols.
And we use the usual,
if we're using a name
from a module we may have
to satisfy its symbol
in the usual way, by
linking an object file
or a library.
So, in this sense, modules
are pretty similar to headers
and like headers, they make
perfect sense in programs
not only libraries.
In fact, a library can
have private/implementation
specific modules that
are not meant to be used
by module consumers.
'Kay, so that was consumer perspective,
some new concepts, but I
think fairly straightforward.
The producer perspective
necessarily more complex.
Before modules we had
the single translation,
now we have a single type of translation.
Now we have three.
We have to module
interface unit, we have the
module implementation unit
and we have the old kind,
which we'll call a
non-module translation unit.
So from a producer perspective,
a module is a collection
of module translation units,
exactly one interface unit,
zero or more implementation units
and, I must add, and
this is unlike headers
and makes a lot of people excited.
A module intferace can
define non-inline functions
and variables.
So we'll see where that leads in a bit.
A module translation unit
is a module interface unit
that if it contains an
exporting module declaration,
export module and the module name.
You can guess probably
it's an implementation unit
if it contains non-exporting
module declaration.
Now let me also note that
this is a fairly new syntax.
It's not supported by all compilers, yet.
Notably, Visual Studio.
But I believe that's gonna
be the syntax going forward.
All right, so I think
you get an intuitive feel
that module interface units
correspond to headers,
and like headers, it makes
sense to distinguish them
with a different file name extension.
With compiler, vendors
predictably suggest different
extensions, none of them make
much sense to me, honestly.
So my recommendation would
be if you're following
the .hpp/.cpp naming scheme,
like Boos, for example,
the natural choice would be .mpp.
Another popular scheme is
.hxx/.cxx, then use .mxx.
And if you are using something else,
perhaps now is a good, you
know when you're switching
to modules maybe it makes
sense to also switch
to one of these two naming schemes.
A module declaration
starts a module purview.
Now this is fairly central
concept in the module machinery.
Names declared in the module
purview belong to set module.
So, in a sense, a module declaration,
exporting or not, either in the interface
or in implementation unit, it
splits the transformation unit
into two halves, which we'll
see have very different rules.
So here, an example, we
included stood string header,
out of the module purview.
We then have exported module declaration,
which starts the module purview.
And then we declare a function,
which now belongs to this module.
A name belonging to a module is invisible
to module consumers unless
specifically exported.
So this is explicit exportation semantics.
And name can only exported
in the module interface unit
and only the module purview.
And we can use syntactic ways to do that,
there are several syntactic ways.
We can use the expert specified
before any declaration.
Like here we have a enum
class and a function.
If we have a bunch of names
that we want to export,
we can use any exported group
without too many repetition.
Finally, we can also
export a namespace body,
notice that it is only
applies to the immediate body.
So in this example, this
function is not export,
unless we also stick export here.
So, so far, we've been
talking about names.
What about corresponding symbols?
This is where it gets a
little bit interesting.
A module has this curious ownership model,
as specified currently
that which is called
a weak ownership model.
So in this model, names that are exported,
their corresponding symbols are unchanged,
so they look exactly the
same as if we actually
never used modules.
Those that are not exported,
they have what is called module linkage.
And names that have module
linkage are only visible
in this module purview, so
they're essentially private
to the module.
And they cannot clash
but identically names
in other modules.
So to give you an example,
let's say you have two modules,
each of the declare
non-exported function if
in the global namespace.
Pinning those two modules
together in the a single problem,
everything will be fine, because
those symbols are private.
So that's normally implemented
by decorating module linkage
symbols of whether the module name.
This first point, the
fact that an exported name
looks exactly the same
as if we declared it
without any modules being used.
There's one really important implication
and that is we can build
a library as modules
and consume it as headers and
even the other way around.
You can have a library that
was built with headers,
we can come up with suitable modules,
module interface units, we
can consume it as modules.
And we'll see where that leads in a bit.
What about the preprocessor?
Modules do not export macros.
Furthermore, a consumer
of a module cannot affect
the interface that here it's gonna give,
by defining any macros.
So, in the sense, the consumer
and the module interface
that isolated from each
other when the preprocess
is concerned, that is
not to say that either
cannot use preprocess.
It's just the preprocessor
stuff does not leak
through the interface boundings.
One practical implication of that is that
import, or the order of
importation is not significant.
Names made visible, this is
also an interesting point,
names visible made visible by
any in particular iteration
in the interface purview are
automatically made visible
in the module implementation.
So here we're importing hello.core
that exports say_hello.
We don't need to duplicate those imports
in the implementation.
So in this sense, an
implementation purview
is kind of an extension
of the module purview.
And I think it's pretty nice
that we don't have to repeat this stuff.
So here we exported say_hello.
We don't need to do anything else.
In the implementation, you can just call.
This is not the case,
however, for consumers.
So this is the same example except now
instead of implementation
unit, we have a consumer.
So if we merely import
hello.core, hello.extra,
the say_hello function that was imported
from the hello.core module
is not automatically visible
unless they interface
these sides to re-export
the imported module.
So this is this funny looking syntax.
Caused quite a commotion on Reddit,
but I think it actually
makes perfect sense.
So if you export, imported
module hello.core.
Re-export is the mechanism
for assembling modules
a bigger aggregate modules
out of subdmodules.
So here, for example, we have
three small modules in our
library and we want to make it easier
to import for the user.
So we just create an aggregate module,
which exports the other thing (mumbles).
'Kay, so that is the
producer perspective basics.
Now let's take a look what happens
in the build system space.
The central piece of the
module infrastructure
in the build system area is the
binary module interface spot.
It's produced by compiling
the module interface
translation unit.
And it is required when we
compile every translation
you need that imports
said module as well as
its implementation units.
Let's see how it actually
works by building
a simple modularized
program with the the three
most popular compilers.
This is our simple interface,
implementation unit,
and a consumer.
Pretty straightforward. Nothing.
Single function, implement
function, import module code.
(chuckles) People ask me what do I do,
so I say, &quot;Well, I write software.&quot;
And they ask, &quot;What kind of software?&quot;
And I say, &quot;Well, build systems.&quot;
&quot;What is a build system?&quot;
So these days, I just
keep this on my phone
and when someone ask me,
I just show them that
and then no more questions.
(audience laughing)
It's not that bad.
So let's start with GCC, just to recap.
We have three files interface unit,
implementation unit,
a consumer, the first thing we do,
we compile the interface unit to produce
the binary module interface, BMI.
So here, and you see, it
does the nms extension
for the time being, might still change.
So here we use the option to specify
where to put this binary
module interface file.
Notice something else.
Besides the interface,
the binary interface file,
we also get an object file.
And if you think about it, it makes sense.
Remember I said that an interface you
can define non-inline
functions and variables.
So those have to go somewhere, right?
So that's where they go.
We have to link, as we'll
see in the last slide,
we have to actually link this object file
to when we're building our program.
So the next we build the interface,
implementation unit, only
difference compared to
vanilla compilations is we have to specify
where to find the module
that this implementation,
well, the BMI, for this module.
The compiling of the
consumer is exactly the same.
In fact, the option is
used exactly the same.
So the reason we have to
specify this two options
in these two command lines.
In the first case, it's
because it's an implementation
of this module.
In the second case,
it's because we are importing this module.
Finally, we link everything together,
remembering to also link the object file
produced by when we can't build the BMI.
Clang equivalent command line,
so I'm not gonna go into too much detail.
The only difference here
is that producing the BMI
and the object file's
actually two-step process.
We first get the BMI, which
has the PCM extension.
And then we compile that
to produced object file.
But I was told that eventually
there'll be a mode to it
in a single compiler (mumbles).
Visual Studio, again, pretty similar,
follows the similar model to GCC,
in that we get both the
object file and the BMI
in the same compiler location.
So it looks like, in a
nutshell, supporting modules
in a build system, an
existing build system,
boils down to two things.
First of all, figure out in which order
to build everything, based
on the import declarations.
And then make sure that every compilation
has access to the BMIs that it needs,
to the modules that it imports.
Well, the details are a
little bit more complex
and to understand the implications
of modules in our build process,
let's take a look at a
couple of build pipelines.
So here we have time
going from left to right.
In each column we list source files
or translation units that
we can build in parallel.
They don't depend on anything after that.
So here's our plain header project.
Everything is nice and simple.
We have two translation units.
We can compile them in the same time
Header is not listed because
we are not building it,
we're not compiling.
So now we are adding a module.
So now we have to compile the
binary module interface first.
And we cannot compile either of the other
two translation units, because
they both needs this BMI.
Let's complicate our project a little bit.
So we're gonna add another module,
which imports the core, the old module.
Also, adding in a aggregate module,
the three exports the two.
Then we have two implementation units,
and we have our consumer,
that uses now the aggregate module.
Pretty simple.
So this is the pipeline.
As you can see, it gets
a little bit spread out,
and a little bit more interesting
Think, most of you can understand why
we have to build things in this order.
We cannot build anything before
we build the BMI for core,
'cause everything else
precursory depends on it.
On the second stage, we
can start compiling extra,
because it only depends
on the BMI for core,
as well as core's implementation unit.
Similar here, we have to start compiling.
We can start compiling the
BMI for hello, because it imports
and it exports these two,
as well as an extra implementation.
Finally, we can start
compiling the consumer.
Now some of might have noticed,
especially looking at our first simple
modularized project is
that it looks awfully like
a generated header.
Now building a project
with a generated header,
say we have a tool that
probably uses our source code,
example, facilitization,
on database storage.
And we first have to make
sure this is generated
and up to date.
And then we can compile our source code.
So if we, for example,
hello is generated by tool,
and it looks exactly the same
as our modularized example.
So this might suggest that
we can probably retrofit
modules quite easily into
existing build systems
by just utilizing the same approach.
Well, how do we handle
generated source code
in our build systems these days?
Well, most of them, most popular ones,
have some kind of a ad hoc pre-build step.
We first ran some custom commands
that make sure all the
source code is generated
and then we have the main
build where we build a graph,
and build dependencies
in the correct order.
Now some of you might think,
okay, well, we'll just use
the same approach.
This actually doesn't work very well.
And the reason for that
is that modules, or BMIs
are actually worse than generated headers.
The problem with BMI is that
they depend on each other.
So one module can import another,
which means that you have to build things
in the correct order.
So you still have this
discovery of the dependencies,
creating creation of the graph
and building things in the correct order.
Might as well integrate
in your main build stage.
A pre-build step will also greatly reduce
your parallelism abilities.
This is what a pre-build
step will look for our
slightly more complicated project.
If you have to compile all the BMIs
before you can start
compiling anything else,
then you'll have this long drawn out stage
of sometimes serial compilation,
followed by when you
can compile everything.
So compare this to this.
And, of course, it's only gonna get worse
the more modules you get.
What exactly is in a BMI?
Well, it's compiler-specific.
But we can guess it can range
anywhere from our sequence
of preprocessed tokens
to something close to the object file.
And we can also feel that probably
the closer it is to the object file,
the more benefit we are gonna get,
the faster our build will be.
And this suggests that, in general,
we should assume that BMIs are sensitive
to compiler options we used to build.
This has a pretty nasty
implication for build systems.
Imagine you have a library build
that you're trying to use in your program,
but the two might be built
with different options.
And while the build system
should strive to use BMIs
for performance reasons,
the options that we're using
in our program and in the library
can be sufficiently different.
And it has to actually build the BMIs
for us on the side.
So in Build2 we call it side build,
so we have to build things on the side,
hidden from the consumer and use that.
This is dependence on compiler options,
or potential dependents.
We also notice that this
is a very murky area
and un-specified currently.
This dependence on the compiler options
may suggest that BMIs actually not a good
distribution mechanism.
They probably should not be installed
and should not be distributed.
And instead, well, maybe
with some exceptions
like standard library but
provided by the compiler.
Instead, we need for our own libraries
should probably install the
interface you need source code,
which again, build
system has to be prepared
to side build.
All right, so that is the
build system perspective.
As you can see, some complications,
but nothing I would say
nothing that we cannot handle
if we have a proper build system,
a proper mental model
for our build system.
No pre-build steps and so on.
And we also quickly mentioned the
proposal for the standard
libraries modules,
once you get modules
in some workable stage,
the next actual thing is to
modularize standard library.
This is still very early.
Even the module names are not finalized.
So yesterday I heard that, or complained,
that there's not std module
that re-exports everything.
And, you know, it's five lines of code.
You can actually write it yourself.
You don't even need a
standard library permission.
You can write it yourself,
build it, and use it.
So this is the least of our problems.
So here's some basic modules.
We have std.fundamental
and that's basically utility std.core,
which by the way, re-exports fundamental
and adds containers and strings.
We just have std.io
for iostream and so on.
And we have std.threading
for basic concurrent scripts.
So I'm not gonna go into too much detail,
because it's still very flux.
All right, so now we have
a fairly good understanding
of modules as a language features,
we have some implications
for the build systems.
Let's see if we can derive some
basic design guidelines from that.
We'll start with module granularity.
Well, how big should we make our modules?
And note that, well, standard
says that importing a module
should be...
A cost of important a
module should be negligible,
unlike headers, so this
might attempt you to create
what I call mega modules,
that you just create
the one module for your library.
Why not?
It's free to import, easy to write.
There's a big one negative
implication for going this way,
and that is recompilation.
The bigger your module,
the more likely it is
that any single change that
you make to this module
does not semantically affect
most of its consumers,
but because it's a single module
and you made a change to it,
all of them will have to be compiled.
This is, by the way,
you might have noticed
that standard library
has quite chunky modules,
well, the standard library, this problem
does not hit standard library, because
it doesn't change very often.
The other drawback of mega-modules is that
if you have your interface littered
with your implementation details,
it because hard to read.
You can work around that,
by moving your implementation details
towards the bottom of the file,
but you might as well just factor it
into a separate translation unit.
So the other extreme is mini-modules
where you split everything
into tiny bits and pieces.
And this is both tedious
to write, to maintain,
as well as to import.
So the guideline we came
up with is to combine
conceptually related and
commonly used entities
into modules.
And this happens to also
be a generic good design.
Just to give you an example,
let's say we are writing an XML parser,
an XML library which provides
parsing and serialization,
it's fairly common for
applications to only use
one of these two functionalities
that makes sense to provide two modules.
We can also provide an aggregate module
for ease of importation, though.
In this case, importing
two modules instead of one
is not a big difference.
So I would personally not even bother.
Okay, that pushed out of the way,
how should we split our modules?
Remember, a module interface unit
can have definition of
non-inline function or variable,
unlike header.
So some of you might feel that
this is a great opportunity
to get rid of this whole
header, source file divide,
and be like Java.
Well, there are a couple of drawbacks
to going this way as well.
And the main one is a compilation.
Again, if you keep your implementation
inside your module, and you
change this implementation,
all the consumers of your
module are gonna get re-compiled
unnecessarily because they
only need the interfix.
So the guideline here
is to have a separate
module interface unit
except perhaps for simple implementations
that are mostly inline or a template.
Inline and template function definitions
and variables we still have to keep
in our interfaces.
But, wait, what about header libraries?
What happens to header libraries
once we modularize things?
Do they become module on your libraries?
Remember not we can have the definition
of a non-inline function
in a module interface.
Do we have the Holy Grail?
Look at that.
It's all work.
Well, maybe we just got
the better foot gun,
the ODR are still in play.
We still have to make sure
that only a single definition
of any on-inline function or variable
ends up in a final program,
or in a final binary
that we are building.
Also, what about incompatible versions?
Let's say you have a library
that is using a module.
You might not even be aware
and you, yourself, is
using a module-only module.
The interface-only module.
You might have worked around
its duplicate symbol issue.
For example, threw away
one of the object files,
but what if the versions of
the two are incompatible?
You cannot use the object.file
from one in the other.
And, finally, and this
also applies to header
on new libraries, where are the tests?
So my personal belief or feeling of hope
is that modules, we will
get better build systems
and we won't need this crutch
of header on your libraries,
or module on your libraries.
The only reason we have them
and that they are popular,
and that everyone strives
to make the library header
only is because they don't want
to deal with build systems.
Okay, so let's now look inside the module.
So we can have covered the meta topics,
how big and how to partition,
so now let's look inside.
First question that pops up is:
Where do I put includes?
Where do I put imports,
which order I should do that?
And there's actually a
good reason why you should
ask these questions.
Remember, a module
translation, the interface
or implementation, it is split
by the module declaration
into two halves, essentially.
We have the module purview at the bottom
and we have outside of
module purview at the top.
And the rules are quite a bit different.
So out of the module purview
we have the old rules.
In the module purview
we have the new rules.
And specifically non-exported functions
are invisible to anyone
except the module itself.
So, with this understanding,
who can tell me
why this is a bad idea?
(man speaks from a distance)
Right, so what we did here is we included
standard string in the module purview,
which means that all the
names that it declared
now belong to this module.
- [Man] But it's not export.
- Well, it belongs to the module,
it's in the module purview,
so they become private names.
And the end-result can range anywhere
from silent code blot to weird looking
and defined symbols.
Finally, you stood string in
some kind of strange module
for some reason is undefined.
So the guideline is clear here I think,
including headers in
module purview is bad idea.
Except for some special headers.
And the two common kinds are
the headers that only define
macros, like visible configuration file,
or export file that defines
a symbol exporting macros,
as well as headers that
we actually want to end up
in the module purview.
And a good example of that
would be implementations
of inline, or template functions
that have been factored
into a separate header for
code (mumbles) in the management reasons.
Some of us like to do that.
Here's an example.
So we move to string out of purview.
We then included export
header, which presumably
only defines macros, we
can do it in purview.
Finally, we have to include inline file
at the back, at the bottom,
it has to be in the module purview.
'Kay, what about import?
Now, remember import
declaration is unlike included,
does not actually declare anything.
It merely makes things visible.
So this might suggest
it doesn't really matter
where we import things.
And it is the case for
implementation units.
For interface units, there are
two importance differences.
Only an import in the module purview
is visible to an implementation units.
And only an import in the module purview
can be the export.
So the guideline here is to...
Interface units to always import,
well, to import in the module purview,
unless you have a good reason not to,
and you understand the reason,
so you're doing it consciously.
And do it the same in the implementation.
It's just for consistency.
So one less thing to think about.
An example, inclusions
still out of purview.
In the purview we import out our modules,
include special headers,
the rest is the same.
So based on this five, six guidelines,
we can actually come up with
the typical module template.
We start with headers.
We then start module purview,
where we import our modules,
we include special headers and
comes the module interface,
and at the bottom we include
inline and template files
if you have those.
The same for implementation template,
headers out of the module purview again.
Then we have the start the module purview.
We add extra imports.
Remember, we don't need to
repeat the ones that were
imported in the interface.
And then we have the
module implementation.
Let's also briefly talk
about module naming.
Module names live in separate,
what I'd call, name plane,
they don't clash with a
namespace names, function names,
type names.
Standard also does not
prescribe hierarchal semantics
for modules, though it's
customary to call, for example,
hello.core and sub-module of hello,
and to also expect that importing hello
will also import
recursively its sub-modules.
So the guideline we use in our
own project we came up with,
for naming modules is
to start with a project
or library namespace.
And finish with a name that
describes the functionality
of the module.
Oftentimes we found that
a module is dedicated
to housing a single or primary
entity, for example, a class.
So we just use that name directly.
Worked very well.
So here's a concrete example.
That's the utility library
I mentioned earlier,
well, I showed you how
it was built modularized,
so it's called the B-U-T-L,
everything in this library
lives in the butl namespace.
And, as you can see,
all the modules start with the butl name,
and then most of them are
just names of the main entity
that they are dedicated to.
Okay, when do we re-export our modules?
Look at this example.
So we have a function that uses
std string in our interface,
so we need to import std.core.
Should we re-export it?
Should we make it easier for our users
so that they don't need
to do it themselves?
Well, I think most of you know that
I'm opening a big can of worms here.
And we're not gonna be
talking about it today,
but I'll give a link
at the end of the talk
where you can read some
thoughts on this subject.
Okay, let's now see how
we can modularize existing
codebases.
So this is where it gets interesting.
At the outset, I would
suggest that you start
with a build system with
proper module support.
And your life is gonna be...
For any non-trivial codebase,
your life is gonna be
hard enough to also fight this battle.
Another point is it
helps a lot if you have
well modularized in a
general sense set of headers.
Specifically having header inclusions,
will they really hurt,
because module interfaces
cannot have dependency cyles.
Also, if you're planning
to provide a dual-header
module interface, then it helps
to have one-on-one mapping,
so you have one header, one module.
So I would actually suggest
that you spend some time
before attempting any modularization,
trying to cleanup and
rearrange your headers.
So we found that it helps quite a bit,
though our headers are
mostly pretty well separated.
All right, let's start with understanding
why modularizing this way is a bad idea.
Well, we mentioned that our hello header,
which belongs to our library,
so we want to modularize it,
Imagine it includes std string.
So we already discussed
why including std string
in the module purview is a bad idea,
here, we're not only doing that,
we are also exporting std
string from our module.
So I think, hopefully,
everyone understands
this is not a good way to go.
But what if this is the
only way available to you?
What if you want to
modularize non-intrusively
a library that you cannot modify,
for example, standard library.
That build I showed you, it
uses GCC standard library
that is modularized,
what we would call a guerrilla
modularization approach.
So you can work around this include issue.
There are other issues by the way,
for example, if your
header declares a name
with a local linkage, internal linkage,
then this is illegal to
export from an interface.
But the biggest issue we
found is actually including
headers that you don't want to export.
And you can work around
that if you really have to
by pre-including them out
of the module purview.
So here were pre-include std string
with the assumption that
the second inclusion
inside the header is
actually gonna be ignored.
Needless to say, this is very brittle.
I don't recommend it
except for some prototyping
or for exploratory modularization.
But sometimes you have to
do what you have to do.
'Kay, when it comes to
modularizing things properly way,
actually able to change things,
the biggest issue is this...
Or the biggest constraint
or biggest limiting factor
is the fact that implementations
do not currently,
do not support mixing an inclusion,
mixing inclusion importation
of the same entities
in the same translation unit.
So you cannot, for
example, include iostream
and import std core, I mean, std io.
And I don't think it's an
unreasonable limitation.
I mean, this thing is
already complex enough
to support some crazy scenarios like that.
So this bites especially
badly when you try to
switch to a modularize standard library.
And the reason for that
is it's used everywhere,
presumably, in your code.
The two strategies that
we found works best
if you plan to switch
to modularize standard
library exclusively,
so you are getting rid of
headers and replacing them.
But the imports, then it may
make sense to do that first,
before you begin modularizing
any of your own code.
So you switch, you make sure
everything builds and works
and then you continue with
modularizing your own codebase.
And if you can afford that,
if you can make it work out,
strongly recommend going this way.
The alternative strategy
is kind of an inverse.
First, modularize your whole codebase,
while continuing using
standard library as headers,
and then switch at the end.
The reason to wait until you
modularize your entire codebase
is to get rid of includes.
If we can continue using
includes for some of our modules
and re-modularizing some
others and we are switching
to the standard library in the process,
you will end up, well,
we ended up with situations
like that, you know, hello.core
is still a header, so we include it,
but it happens to include iostream,
but we are already switching
to modularized standard library.
This just blows, I
mean, this doesn't work.
When it comes to modularizing our own
components, the strategy
that we found that works best
is to identify and
modularize interdependent
sets of headers, one set at a time,
and starting from the
lowest level components,
so that any newly
modularized set only depends
on the previously modularized one.
Now, it would be nice
to be able to modularize
one header, one module at a time.
Again, this does not work very well,
because if you're still using includes,
sometimes you'll end up
with bizarre situations
like you include a header
that imports a module
in its own implementation unit.
So none of the implementations currently
handle this gracefully.
'Kay, let's quickly talk about providing
backwards compatibility.
We identified three
levels, so modules-only,
you don't provide any, you
just switch to modules.
Lucky you if you can do that.
Modules-or-headers,
where we support headers
for backwards compatibility, but we expect
our library and its consumers
to be on the same page.
They both using modules,
are both using headers,
and finally we have this third level
where we actually support
cross-usage, right?
We support consuming our
library build as modules
as headers, and even the other way around.
Now that might seem
farfetched to some of you,
but actually fairly plausible case.
If you have a ton of existing consumers
and none of them can be...
And they cannot be all switched
to modules at the same time,
or ever, in fact.
All right, modules-only, pretty simple,
follow the templates and guidelines.
Above, I would also
strongly suggest that you
consider using modularized
standard library exclusively.
Using standard library as headers
in modularized application
is actually more painful than using it
in a header-based application.
If you want to know why,
I'll give a link at the end.
Modules-or-headers.
So, here we expect the
consumers to be adjusted,
to be kind of on the same page as us.
The way we found this can be set up,
I mean, there are probably thousands ways
you can arrange this and set it up,
but what worked for us is
to reuse the interface file
as a header when modules
are not available.
And to decide which mode we are in,
we use the feature test macros,
so the CPP modules is defined
if we have modules available.
And CPP lib modules is
defined when we have also
modularized library.
See what it looks like.
Remember, I talk about getting
rid of the pre-processor.
Doesn't go this way,
But, yeah, the idea is that
you'll probably get rid of it
once you switch to exclusive to modules.
So the first thing we do is we make sure
that this is the interface
unit and we need to craft it
in such a way that it can
also be used as a header.
So the first thing we need to make sure
is that it's not re-included
in the header mode.
You can probably make it
work with include guards.
It will just get really ugly, I think.
And I think it's just
better to bite the bullet
and use pragma once.
Then we have the C includes, for example,
and we have block of includes for
when standard library is not modularized.
And we have some other
includes that you might have.
And we have a block for
when we are actually
in a modules mode.
So we start the module
purview, and then we have
a block of imports for the
modularized standard library.
Now, you can probably
arrange it a bit differently,
probably shorter.
The thing that we like about this approach
is that it's linear.
It doesn't have too many Ls
blocks, too much nesting,
it also will be fairly easy to clean up
once we drop support for headers,
which is basically remove blocks
or remove if divs.
Corresponding module implementation unit.
So instead of pragma,
once we have an include
for when we are in the header mode,
then we have the, again,
C includes, that block of
includes for the standard library.
Now here we have to actually re-include
the standard library headers
we specified in the interface.
And this is where the pain
of using standard library
as headers in the
modularized library comes.
You're gonna read why we have to do that.
It's actually fairly annoying.
So then we have other includes.
We have the start the module purview.
And, again, we have extra includes for...
Extra imports for the standard library.
This more or less follows the template
I gave earlier, just is
a little bit uglified
to also support headers.
So that adjustments to
consumer, straightforward.
We import if modules are available,
we include the interface
using it at as a header demo.
The last level is fairly...
You would imagine this
thing gets really ugly.
And there's a bit more pre-processing.
But we can actually tweak
the previous model to work
without too many changes.
Another thing we'll have
to do, we'll have to keep
the old header name.
So we'll have kind of two files now
for each header module pair.
I'm not gonna show the code,
so I'll give a link where
you can read about it.
But it's like complication
over the previous model.
And with this, I think
I'm pretty much done.
So everything I've covered
in quite a bit more detail.
And discussing quite a bit more nuances,
you can read about in the
build2 Build System Manual.
There's a whole chapter
on C++ module support
with introduction, all these guidelines,
all these templates I listed there.
I also want to thank these individuals
for answering my questions about modules
and reviewing patches.
And, yeah, thank you, any questions?
(audience applauding)
- [Audience Member] Hi, so I
do actually have a question.
At the beginning of your talk
you had a quote from Richard Smith
saying that the compiler should
not become a build system.
And I had asked Gabby on Monday
how, you know, if you have
module B and module A,
and A imports from B,
and you compile A first, what happens?
So how do we...
And his response was, &quot;We'll
make the build systems
&quot;understand modules.&quot;
How do we do that without
having the build system
turning into a compiler?
- Well, I can tell you
how it's done in build2.
If you studies the
specification for modules,
one nice property of the grammar rules
is that all the module declarations
are what I would call top-level.
They are all at the top
level of your name scoping.
The module declaration has
to be in the global scope.
So what we did in build2, we
just pre-tokenize, shallowly.
A translation unit and
extract all this information.
Now, at first, even to me,
that sounded a bit heavyweight,
but in the end, it
actually worked perfectly.
The cost of that on the modern machines
is not even a percent of you build time.
And, in the end, as a
bonus for doing this,
we actually got a more
precise change detection.
We now hash the tokens that we get,
so any wide space change that you make
to your translation
unit we can now ignore.
- [Audience Member] Okay,
and so does that include
like if someone were to do the worse case
of, &quot;We're gonna use the preprocessor
&quot;to change the module
name or to change like
&quot;what imports there are.&quot;?
- Yeah, if you're doing that,
then we have to run the
preprocessor before that.
Which, again, might sound like crazy idea.
But interestingly, on modern hardware,
it's, again, like a
percent of your build time.
That was actually one interesting finding,
surprising finding.
Like, let's say, how many
percentage points of your build
it costs to preprocess all
your translation units?
You'll think maybe 5%, maybe 10%.
It's actually less than a percent.
- [Audience Member] Okay, thank you.
- [John] Hi, this John
Lakos from Bloomberg.
I wanna thank you for the talk.
I'm trying to learn about modules.
I was approached about 10 years ago.
Somebody asked me my opinion.
And I said, &quot;Why do we need modules?&quot;
Well, 10 years later, I
think we do need modules.
But I wanted to ask you,
very practical questions.
I have a company that has
over 5,000 developers.
We have an immense amount of legacy code,
unbelievably large, it
includes four trans C++.
We're moving forward.
It turns out our core infrastructure,
by some luck is levalizable,
I don't why, but it is.
And I was wondering how would you advise
that we take advantage
of modules at Bloomberg,
because the chances
that we're gonna go back
and retrofit code from the
80s to use modules is slim,
and we want to start using them.
But we have clients right now
that are perfectly happy not to use them.
And then later, we're gonna have clients
at the middle level who
do and don't use them.
And then we're gonna have
a client at the top level
that says, &quot;I want to use
the core infrastructure.
&quot;And I have some middleware
that uses modules
&quot;and some middleware
that doesn't use modules,
&quot;both of which use BDLT
date, which is at the bottom.
&quot;And now what do I do?&quot;
So how would you advise
Bloomberg to adopt modules
given what I just said?
- All right, my follow up question:
Can you switch all the
consumers of say that date
at the same time to modules,
or do you have to maintain
some as modules, some as--
- [John] Okay, I don't
know if there's a word
that's stronger than no.
(audience laughing)
But if there were I would use it.
- All right, well, in
this case, I would suggest
you provide a dual, sorry, you can take,
if you start from the lowest level,
you take the component that nobody else,
that does not depend on anything else.
And that's not necessarily
a single header.
It can be an interdependent
bunch of headers.
You modularize it.
- [John] What does that mean?
- Provide--
- What do you mean?
Do I actually have to change the code?
Or can I make something that depends on it
that has a module interface?
Do I have to change the original source?
- If you can change the
source, it will be--
- [John] I can't change the source.
- Well, then, I guess
you can define a module interface,
you'll just have to maintain the interf--
Well, since you're not
changing it, presuming ever,
so you cannot change it,
so you never change it.
So you can just copy an interface--
- [John] No, I can't copy it,
because it has to be the same type
because they're used by module
users and non-module users.
And I can't touch anything,
no code at all can change.
- Well, you have a header, right?
(audience laughing)
With some declarations?
A header.
- [John] Yeah, I have a header, yes.
- So can you open it in an editor, copy,
open another file with
a different extension,
paste it in there--
- I can do that.
- So you're not changing
the header, header is read-only.
And then you put X,
you basically have a
bunch of includes, maybe,
for C or C++ tenant library.
And then you have, I
don't know the namespace--
- [John] Are they same C++ class?
The same date class now?
I have two different things?
They're the same.
- As long as you are exporting.
Remember I mentioned that an exported name
looks exactly the same as
if you never used a module.
- [John] So to be very specific,
I have the original date class.
And now I have something else.
I happen to use cut
and paste to get there,
but I have something else that depends
on the original date class
that exports it through
a module interface,
is that correct?
- Right.
- [John] I wouldn't really
need to cut and paste it,
I could just simply refer to it, right?
- Well, that goes back to
that guerrilla modularization
technique that I described.
Your problem will be that
if you just export a header,
wrap a header in an export group,
you're gonna export your C
headers that include there,
your standard library header,
so you can hack around
that by pre-including--
- [John] But you can imagine the problem
of duplicating the code
so I have two different
full implementations
of a class and keeping them in sync.
That would be problematic, wouldn't it?
- You said you never change
it, so why would it be--
- [John] Well, I'm allowed to refer to it.
I'm not, by the way, this is not a joke,
this is extremely important.
And the reason is is that we do have code
that is stable for 30 years.
And yet we want to be
able to have new clients
adopt modules.
So we have to, there's a duality here.
If you understand, it's like a dialectic.
We got two truths, we got this
truth and we got that truth.
And they have to co-exist.
And the problem is you can't
change the world in lock step,
because you can't.
And, therefore, we need
a strategy for modules
that allows us to
incrementally and addititively
make that chance.
(drowned by Boris)
- I believe there is.
You have said in constraints, right?
You cannot change the header.
- [John] By the way, it's not just me.
A9, Microsoft, Google,
Facebook, all agree.
Just saying.
- Okay.
- [Audience Member] Hey,
thanks for your talk.
So you mentioned that it's a bad idea
and it makes sense that
if we somehow include
like string header inside
the module purview,
can we enforce that, though?
Because mistakes happen.
And some developer did something
and passed the code in,
for some reason, but will
the compiler catch it,
will the build system catch
it, or how does that work?
- 'Kay, so let me see if
I understand the question.
Is there a way to enforce,
maybe to mark a header
so that it cannot be included
in that purview module.
- Especially
the standard header, especially
the standard headers,
like can we force that nobody
includes standard headers
in the module purview?
- I haven't seen anything,
but that might not be
a bad idea, and it might not
actually be that difficult
to implement.
A compiler could easily define a macro
once it's in purview.
- [Audience Member] Okay, so it's up
to the compiler then?
- I think it's a good
suggestion and good point.
But we are also in
quite a bit early stages
of this whole thing.
- [Audience Member] Cool, thanks.
- [Audience Member] Hi.
How do you think modules
compared to pre-compiled headers
in terms of well speed?
- I personally haven't use
the pre-compiled headers
too much, because I
believe it's just a hack.
So, to me, when people
compare pre-compiled headers
to modules, I don't think
ample storage is comparison.
So I don't know, anyone
knows what speed up you get
if you use a Visual
Studio pre-compiled header
in a typical application?
Is it two times, three times?
I don't know.
- [Audience Member] 10 times.
- 10 times, well, but
I don't know, I mean,
if you're aware how it's
implemented in Microsoft.
In Microsoft, for example,
in a Visual Studio compiler,
I was told that a pre-compiled header
is a compiler memory dump.
So when you use a pre-compiler header,
just loads the memory.
So I don't know, can you compare something
that's part of a language
to a memory dump?
Probably not.
- [Audience Member] Thank you.
- [Audience Member] Hi,
thanks for the talk.
My question was about the
distribution mechanism for this.
So you mentioned earlier that
we don't wanna use these to,
quote/unquote, install modules,
but there's nothing from stopping us from
generating the implementation
in a separate DLL or lib
that is then linked in to the final thing.
So is it a good model to sort of have your
actual module implementations
compiled somewhere
and then have separate interfaces
that sort of allow you to bridge your code
to this compiled lib that then
you take everything together
or is that a bad approach
to solving this problem?
Because, we would love to
be able to take our code
and compartmentalize it
where there are chunks of it
that we just don't compile regularly,
because they're more or less stable
unless we make changes in there.
And it would be nice
if we could use modules
to sort of like bridge in between
rather than having to
include tons of headers
and getting into just nested header hell.
Is it a good idea to sort of build
your module implementation separately
or is that a bad idea?
Because you keep talking
about the re-compilation cost.
Then we're trying to figure
out is there a way to avoid
having to recompile your
module implementation
for each file and each
place that's reusing it.
- I'm not sure I understand
which problem you refer to.
Are you trying to avoid re-compiling
the binary module interface?
Maybe stripping-
- Yes.
- You can do it if you have
a controlled environment.
If you say all my projects
are built with exactly
the same options, there's
not reason you cannot ship
a pre-built BMI.
In fact, you can even do
that theoretically without
this restriction, just
the build system needs
to be able to detect, okay,
this BMI I cannot reuse,
so I have to build it.
Or, no, these are compatible,
so I can reuse it.
- [Audience Member]
Okay, all right, thanks.
- Last question.
- [Audience Member] Let's
say I want to put interface
and implementation in one file.
And then if I change
only the implementation
does it mean that I have to
recompile all the consumers
will have to recompiled?
Is it a limitation of the build system
or does the BMI change as well
if I only change implementation?
- Good question.
I supposed you can
imagine an implementation
that would, yeah,
that would keep the--
- That would pass 'em--
- You know, if you
haven't changed anything
in the interface, it will
produce identical BMI,
which can then be checked
some by the build system
and detected that there are no changes.
Again, very early days,
but, again, not a bad idea
I think to consider.
- [Audience Member] Okay,
this will do it, nice.
- Thank you.
(audience applauding) ÷</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>