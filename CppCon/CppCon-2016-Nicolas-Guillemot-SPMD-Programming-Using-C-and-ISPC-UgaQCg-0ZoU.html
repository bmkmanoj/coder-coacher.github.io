<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: Nicolas Guillemot “SPMD Programming Using C++ and ISPC&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: Nicolas Guillemot “SPMD Programming Using C++ and ISPC&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: Nicolas Guillemot “SPMD Programming Using C++ and ISPC&quot;</b></h2><h5 class="post__date">2016-10-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UgaQCg-0ZoU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so welcome to my talk I'm gonna be
talking today about SPMD programming C++
basically are we gonna write a sim
decode and C++ that's gonna be easy and
fun so just a little bit about me my
name is Nicolas I mostly work in BO
games technology in the past I've worked
at some Game Studios like in Lights
entertainments and you sports I've also
worked at Intel doing graphics right now
I'm working a computer graphics research
lab at University of Victoria by the way
that's me as my girlfriend Jessica and
these are our two cats so here's the
overview for today's talk first I'm
gonna talk to you about just basic Sims
II building blocks so just the basic
fundamentals of how to write code using
cindy after that i'm gonna give you an
introduction to what SPMD is and in
order to get you comfortable with the
idea of SPMD we're gonna look at some
case that use of where SpMT is used in
the wild and be able to understand how
to deeper level finally I'm going to
show you how to do SPMD programming in
C++ using a small library I've made
called VPS BMD so I would like her to do
let's begin so for simply building
blocks I'm gonna basically show you how
to write some basic sanity code using
intrinsics which I'll explain in a
second
so the big idea of sim d is if you're
not aware it stands for a single
instruction multiple data which means
that in one instruction you're doing up
you know you don't operation on multiple
operands you know in parallel so for
example if you have these four floats
and you want to add them in parallel
with four other floats you can Det in
one operation and so in one sim the
instruction you can do an addition in
parallel that gives you the result of
four floats and part like that so if you
have to translate this to actual you
know today C++ code you could do it like
this so okay ease you into this notation
here these statements initialize the
input so you can see the top of the
slide so you can see on the left there
there's a kind of a new type maybe this
is m1 28 so the idea is that's 128-bit
datatype that's a non-standard type the
reason why it's hard 28 bits is because
in 128 bits you can store four 32-bit
objects so those you store four floats
and you can initialize these very
in a variety of ways but right now we're
just using mmm set PS and this is a
intrinsic function that lets you
initialize one of these hemos twenty
eighths with four specific values which
basically it'll translate something like
a move or a load so let's say we
initialize these values and by the way I
should mention that mmm at the start
that's just the namespace for all these
intrinsics for the faithful instruction
sets and PS stands for packed single
precision float so the word packed is to
emphasize the fact that there's more
than one object being put into the same
object right and the S for a single
precision is just to say that's 32-bit
floats so that's how you decode
basically these and these intrinsic
names to do the addition it's actually
pretty straightforward so mmm add PS to
just add to pack single position float
registers and that's how you get the
results you can see on the top of the
slide moving on you know that's how you
doing operation on four objects but on
four floats but what if you want to do
it on an array of floats so that you do
that is basically you just iterates over
the array of floats in steps of Sindhi
with so you might start here do a
parallel addition here move on to the
next one in a step of four do another
one moving a step of four do another one
alright that's how you get an addition
using sim D on an array of elements if
you have to write this in C++ code we
can do something like this so for
simplicity we will assume that the N is
a say multiple of four just so we don't
have any weird trailing objects and the
for loop you're pretty familiar it's
just a saml for a loop but incrementing
it steps of four so at every loop we
load the operands that are gonna be
inputted so here let's use the load PS
intrinsic which just yes takes an
average of memory and loads the four
floats there so we've got two arrays and
put one input to that perform the
addition just the same way as the last
slide and finally store back the results
to memory using the store PS instruction
which will or sorry intrinsic voice we
shall write it so the output array so
it's as simple as that
now that was how to implement the loop
and when it's all trivially Pera like
it's just a loop everything's pretty
easy but what if you have an if
and then it gets kind of weird cuz it's
not as obvious how to actually turn this
into a sim decode so I'm gonna show you
how to do that and I'm gonna show you
how to do it step-by-step and so the way
that's gonna work is that there's gonna
be basically two things moving here two
moving pieces there's gonna be a mask
which tells you which of the currents
crepitations are active and that in here
is the input and the reason why there's
four numbers under a is because if we
convert this function into a sim D
version of that function it's gonna be
working on four inputs in parallel
giving you four results and so basically
what I want you to think about this the
way I want you to think about this is
think about as if we're running this
function four times in parallel like if
it was running on four threads in
parallel and each of those threads of
execution they're gonna be represented
by one column in the image as I'm going
to show and to explain more that the
mask thing it means that those lanes are
active and you'll see what that means in
a second and just explain the not zero
is to say that it's it's like all one's
like all fully hi to see that's active
so the way that you put this in Sim D is
when you get to a conditional statement
like this if here what you do is you
evaluate the expressions a less than 0
but in since if we could read this as
sim D the value of a is actually four
values and so the result of the
comparison is different depending on the
value so you can see on the left there
I've only turned on the elements of the
mask where the comparison returned true
and the ones that are blue are the ones
so the comparison failed and I kind of
like color coded on the right as well
and so the way it works is that when you
do the statements inside the if block
where you assign 0 to a for example that
assignment only happens on the lanes of
execution that are currently active so
you can see on the right there for 8 the
elements are in blue which are not
active those ones didn't get affected by
the assignment of 0 only the ones that
are active got it got assigned to 0 when
we got to the else you can just put the
mask that's when we were doing it and
now the points that are off of the on
and the ones that are on or off and when
we do a plus equals 1 that addition of 1
only affects the lanes of execution
where the mask is active in the else
block so finally you return the result
what do you know we get the results of
busy dysfunction being around four times
in parallel using sim D so I'm going to
translate the same function again but
this time using intrinsics and if you
know intrinsic swell ago you'll see that
I'm kind of like cheating here there's
like some shortcuts of notation that
don't actually work so this is basically
just to fit it on slide so you'll have
to excuse me for that so going over the
same process again we start with a mask
that's all on initially and the inputs
for a the first step we do a comparison
so this is the compare less than just
doing a less than comparison and so the
result of the comparison is actually
exactly what it's shown in the mask
value so then the next statement I'm
using this blend V intrinsic my blend B
does is it takes two values and it
merges them based on the values in a
mask so the value of mass decides
whether the result should be taken from
the from a or from zero and so that's
how the two was the two values a and
zero are merged into one value based on
the results of the comparison now you
get to the else blog so you just flip
the mask using this imaginary not
intrinsic which doesn't exist but it's
convenient and it's nice if it did exist
and then when we get to the two the
blend be for the else block it's
basically the same thing where were
merging values of a and a plus one based
on the result the masked so only the the
lanes that are active in the else block
get +1 and the ones that didn't don't
change and there you go we get the final
result so that's pretty much how you
would actually implement this using
intrinsic and and match it matches very
closely what the assembly code would
look like
so if else is pretty basic so what about
all the other control flow you get in a
regular C program like for a while or
switch or continue you know those are
all possible and I think that what I've
covered so far is enough for you to
understand how to implement them so I'm
leaving as an expense for the reader and
just as a hint is just masks like
everything's just masks like everywhere
so that's basically the TLDR if I
implement all these other things now
this I've shown you so far how to write
seam decode using assembly intrinsics
but it's not always the best choice for
the job so let's see some pros and cons
it's nice that the intrinsics are
actually
be pretty close to assembly so in that
way you can kind of like maybe just sum
up you know assembly level optimizations
of your code but the problem is that
it's so ugly to implement stuff like
if-else and for loops and stuff that
actually it's it's hard to actually make
your algorithm better and it turns out
that a lot of time that actually has a
better payoff and then puts it around
with little like changes of assembly
code also pretty knowing is the codes
not really portable it's it's bound to
like a particular rule the ones I showed
our balance are basically like x86 but
even like if you if you look like a
certain intrinsic like stringent
intrinsics only work on certain x86
processors so it's not even portable
like across x86 on top of that so if you
if you haven't been to this problem in
production and you might report to like
arm or something you'll have to write
your code again and so not only are
gonna have duplicated code but actually
you're gonna have like complicated
duplicate code because this is like this
is like assembly ish code and it's it's
not very easy to read or write and
there's lots of tricky details so it's
not easy to duplicate this code and
actually do it properly so how can you
fix these problems well the solution I'm
here to talk to you about today is SPMD
honest imd so lots of acronyms here so
let me explain so SPMD stands for a
single program multiple data what it
means is that you write a program as if
it was just a regular old serial program
but in reality the serial code you're
running actually corresponds to doing
Sindhi work so we're gonna go more into
this it warranted a detail about this so
don't worry if it doesn't make sense
right away one of the things that's
really nice about it that you'll learn
to appreciate hopefully is that with
this design you get where they call
maximal convergence and what maximal
convergence means is that let's put it
this way earlier I told you that you
should see the code being run as for
instances of the same program running in
parallel and you could implement that
with for POSIX threads like if you want
to run a function four times in parallel
you could just spawn four threads run
the same function from the four threads
and that would work the problem is that
if you want to be able to communicate
between these threads so for example
maybe you have some computation that's
only that's that's dumb once and then
shared between other threads if you
don't do that kind of communication is
gonna be really tedious
you'd have to put like mutexes and stuff
in barriers and all sorts of weird stuff
but with Cindy you just you don't need
that like there's no like Hardware
threads that are running on different
like different speeds
it's just lockstep Cindy you don't need
barriers there's no redness you can kind
of just like communicate between these
different distances of the programming
run and the way you can see it kind of
is this kind of like it's a kind of like
secret ization at sequence points so
it's one way you could see is like if it
was multiple threads running it'd be
like a mutex to lock like earth to
synchronize them like in between every
statement and actually this person was
pretty closely to what actual c++ works
like today because of sequence points so
moving on I want you to get a feel for
SPMD to understand kind of like how it
works and and your mind around like
thinking in the SpMT kind of way so
we're gonna be looking at two case
studies the first one is is PC which is
a CPU programming language for SIM T and
we're also me looking at our house
shaders work on the AMD GCN GPU which is
GPU programming language and so you
don't necessarily need to focus too much
on the details of ice PC or AMD but more
I want you to get familiar with the idea
of SPMD so history number one is the SP
C compiler so ice PC is a compiler for a
C programming language made by my father
and some other people I guess is PC guy
github diodes where you can find it if
you want to go check it out
she's gonna do a quick overview here
it's basically a C like language for
SPMD on SIMD in fact it was originally
based on a C compiler so it's very close
another way you can see it if you're a
graphics programmer this might make more
sense for you it's it's like shaders for
the CPU so it's actually it's an Intel
project but it's actually open source it
supports a wide variety of platforms to
basically hooks into LLVM at the end of
day so you got x86 64 you got an arm you
got xeon phi it works on ps4 so that's
all good now let's move on to an actual
example of how use ice PC so just gonna
walk you through this code here and
hopefully it's gonna be insightful so
here's the signature for the function
I'm gonna demonstrate this is a simple
function it's gonna do only a little bit
of trivial work you can see a few new
things here from a regular
program first of all you can see there's
a uniform keyboard that shows up so the
uniform keyword in is PC means that
value is a scalar which is like
basically if you come from C++ when you
see uniform Biscay it's the same thing
as if it was in C++ I mean basically if
you want translate this to C++ just take
off the uniform keyword and it means the
same thing but that's how I see it
anyways and then there's a new keyword
also on the left here export and so what
export does is just I species way of
creating the foreign function interface
so this says that this function can be
called from C and it works into toll-f
fi system so this function is going to
loop over the array for inputs and keep
just interpretation and write the
outputs so this is a for each loop in
Nice VC which is again like a small
temperature from how C works but should
be pretty easy to understand how it
works basically just does a loop over
the range 0 to n it's like a it's like a
what is it half upper bound so it it
goes to n minus 1 and then that's how
we're gonna write our loop that goes
over the same boots so the first thing
it does is it loads the inputs for one
step of the computation and again we've
got a new keyword here so this new
keyword here bearing is very interesting
one what it means is that the value of
this variable V is different depending
on the program instance so I was saying
earlier that you should think about SP
decode as or a Sindhi code that's going
to be code you should see it as a bunch
of different instances of the same
program or any parallel and what the
varying keyword here means it means that
in each of these instances this variable
has a different value which is different
from the uniform variables the uniform
variables have the same value and every
program instance because they're scalar
so that's that's a distinction that's
made between those two and so what's
interesting here is like the index
variable for example the index variable
in the first iteration of this loop is
actually the index itself is a varying
variable so the index in the first loop
if you're running on SSE to the index
might correspond to 0 1 2 3 so it's
actually responding to 4 values of the
four first indices of the iteration and
when you index the array V in with this
varying value you're indexing with four
indices so that means you actually know
it for example with us as u2
so
that actually loads for values and
that's why V has a varying values
because you're loading for values with
different indices from the same array so
once you've loaded this this variable
from memory you can do some computation
with it so I'm just gonna show an
if-else again
so it begins with an if and the
interesting thing is that this if
comparison since B is varying the result
of the comparison has a different value
depending on the programming sense and
so the code inside the if block should
only appear as if it should only appear
to have run inside the program instances
where the tests passed and the way
that's implemented is exactly I showed
you earlier with the masking and the
blending and all that stuff then we got
the else block same thing as earlier
again where it'll just like flip the
mask and then run the else block and the
assignment of like square root of V to V
will only actually appear to have
happened in the instances of the program
where the test resulted in the else
branch being run finally at the end
we're at the outputs back to the V out
array and so again index is a varying
variable so this right the memory
actually corresponds to the for writes
the memory in parallel by writing to the
indices 0 1 2 3 in the first iteration
of the loop for example
so there's actually an interesting thing
here it was like the way I explained
this is I explain this in terms of like
kind of like how the SIMD works for it
but one thing you can do is actually
this variant keyword if you just like
you know if you're just interesting the
idea that just imagine it wasn't there
just imagine it's not actually on the
slide and if you imagine it's not there
you'll notice that the code actually
reads like a regular C program you don't
actually have to think about the fact
that it's Cindy it's just if you read
this and you imagine it's just like some
weird sea dialect you would see a for
each loop and you would see an index and
it would do an if else and then write to
memory and there'd be like there'd be my
thing is specially weird about this and
actually a nice PC bearing is the
default qualifier so if you leave it out
it'll slick a pile and do the same thing
and that's kind of like the idea of SPC
is that you can write programs that
appear as if they're just a regular old
C program and reality that's running in
is running back to rice code and so you
can kinda like shift between these two
perspectives when you're writing code
like either you think about it was like
okay it's just a C program and I'm just
writing it like it's a C program or you
can get like
you can kinda like switch your mind to
the other mode where you're thinking
like okay it's actually a vector here
and a scalar here and blah blah so you
can't like switch back and forth these
two modes of work when you finish
writing this program making pilots with
the SPC compiler so you know if it's
called simple dice PC on your file
system you just compile it and as a
result you'll get two files you'll get a
header like a C header or C loss header
that you can include from your C++ code
to build a call this function and then
also give you an object file like an
object file that you can just link to
your program and I'll just work so I
should pretty easy to integrate alright
so moving on we're gonna look at a
second case that you know now we're
gonna look at shaders on the MV GCN and
so GCN maybe if you're a gamer it might
sound like GameCube but it's like
GameCube it's graphics core next so
graphics core next this NPC parent GPU
architecture and we talked about it a
little bit so it's not just the GPU
architecture actually GCN it's it's also
an instruction set architecture in the
sense that they have specified that can
actual assembly language so you can use
the program for it this you know this is
kind of like part of a big push for
gpgpu so especially like if you're
programming on game consoles right now
you probably have done a lot of compute
code tends to be that has to be the
faster way to write code on consoles
right now and namely that's like
probably most important cases that are
these in my my like daily life it's
mostly important to know about em GCN
because it is a GPU used in current
generation game consoles so let's look
at some basics because I'm gonna show
you some assembly code and I want to
first make sure that we know what the
notation means
so GCN has two sets of registers that
has a set of back two registers and a
set of scalar registers so the scaler
registers I'm gonna talk about in a
second but the vector registers are
named r0 r1 r2 and r3 and r4 and etc and
each of these vector registers
corresponds to you could say a sim D
register with 64 values it's actually
very wide to 64 and you can actually
operate on them in a pretty
straightforward way so for example this
instruction here V add F 32 just does 64
additions in parallel so it'll take R 0
and R 1 do these two are parallel
additions and write the result to R 2
and so you can you probably guess like
the VR
where the story means that's a vector
operation and f32 means it's a 32-bit
floor operation should be not too
surprising so this is vector registers
but there's also scalar registers and so
the scalar registers are named s your s
0 s 1 s 2 etc and you can use them for
scalar operations so for example here in
this case I'm doing an ant so just a
bitwise and between s 0 and s 1 slowing
results in s 2 and again you can
probably guess the prefix s underscore
is for scalar and be 32 to say that's a
32-bit operation moving on there's a few
special registers that you need to know
about first one is VCC so the vector
condition code this is me you do a
comparison like for example here compare
less then between R 0 and R 1 since
those are vector registers the
comparison has more than one result as
64 results and they're encoded as a bit
set like 64 bits where each bit
corresponds to the past didn't fail and
so when you do a comparison like that
one the output is stored in the BCC
register so that's how that works and by
the way the VCC register you can maybe
you notice a color coding the purple
letters I'm using here are four vectors
and the blue letters are first scalars
so PCC is actually a scalar register of
64 bits ok moving on there's the another
special register the execution mask
called exec and so the execution mask
was actually very similar to the mask
that I showed you earlier in this talk
when I was demonstrating how to convert
C code to assign B code and basically
what it does is just the value of the
exact mask is used to mask out any
operations that the GP does so whenever
you do an operation with vectors it will
only affect the execution lanes that are
set in the exec register and you can
actually just arbitrarily read and write
to this so for example here I'm doing an
end of a BCC and exec and storing that
in exec and that's a very common pattern
you'll see because it's used to like
mask
execution for like an if block for
example if you died like a person and
use that comparison as a for an if so
moving on
let's look at how this is actually used
to compile code so on the left here you
can see a very simple OpenGL shader
program or COAG it could be a direct
actuator program honestly it's it's
simple enough that it could be a bisque
any language at this point but for the
sake of for the sake of discussion as as
soon as the shader if we want to
translate the shader into gcn assembly
you would do it like this so let's begin
hopefully you're not too small hopefully
you can I'll read it we would begin by
doing a comparison so this says compare
greater then between the two inputs so
it matches the first line of code and in
the function that just does a greater
than comparison then the trick is so
this is like an added dimension too I
showed you earlier in this shading
language is possible that the calling
function exact mask was not all on like
in the example I showed you earlier the
execution mask was all on at the start
which was like a nice assumption but in
this case you can't assume that the
exact register is is all on when it's
function starts so what that means is
like if we're gonna be messing around
with the exact register you have to make
sure that it goes back to what it needs
to be at the node function and so this
one should begins by storing into a
temporary variable the value of the
execution mask and that way it's gonna
be able to restore it at the end all
right then similar to how I showed you
in last slide just do an end of the
execution mask at the BCC and that I'll
make it so that only the lanes that
passed the greater-than comparison are
gonna be active from for the ones that
started off alright then the so this
kinda like a few things happening here
if you direct your attention to the
purple line of code here you can see
that's the multiplication that's
happening inside the F block and then
around it I've got like a bit of like
control for logic so here you can see
the label for the else block which
corresponds to of course the else part
of the program here and above it I've
got this branch so what I'm doing here
is actually it's doing a branch if the
VCC is zero and so what that means is
like if the comparisons all failed
that means that nobody is going to be
running the if block in the sense of
like if if nobody if you if you input it
like a set of a set of values for a and
B and the pairs and resulted in no
passes like everything failed that means
that you don't even need to run the if
block you can just not run it and that's
what happening here so if everybody
filled the test it oh just branch
directly to the else block and not run
the F block it's kind of a little
optimization there you'll see pretty
commonly so
moving on we got to the else plot the
first thing we do is we flip the mask
like I was talking about earlier but
there's like an added detail here again
which is that we have to take into
consideration that the mass was not all
on at the start so this is just making
sure that you take into account the fact
that the initial mass was not all on and
and and that to make sure that you
respect the original constraints all
right and then very similarly to before
we do a little branch trick to make it
so that if none of the execution lanes
are on and we just branch and skip the
else block entirely but if that didn't
happen
then we do a sub and that'll do the
subtraction between the two inputs and I
should mention just be clear that this
multiplication the subtraction that
happened in this code they only affect
the lanes that were set in the exact
mask okay so this is kind like a little
bit difference because in the earlier
example I have to explicitly do it like
a blend instruction but in this case
it's actually just done implicitly so
it's just everything's masked always and
alright so that's the end of the
function so just bring back the
execution master whatever's at the start
and we've all cleaned up our slate and
it all works so that's all I want to say
for GC and assembly all right in summary
where did we learn from these case
studies so first of all we've seen that
we can use SPMTs map sealing we justice
IMD the cool that we can write is high
level so we can use it to write like
loops and traditionals and ways that let
us write like better algorithms more
easily rather than focusing on little
assembly finicky details and the nice
thing is like once you understand how
the C code Maps through intrinsics or
assembly you can still kind of like look
at the code and understand what the
performance is going to be like because
you know how the implementation details
work basically in the sense that you
know those give me something ask in here
and this can be some jumps here it's
like no make sure that whatever just to
say like it's possible to understand
what's actually happening behind the
hood and that's like an important
characteristic of c-like languages
because of course we wouldn't be writing
see everything have a performance so
another cool thing is that I showed you
that it runs both on CPU and GPU so it
shows that this part I'm actually has
quite a bit of versatility and I've
shown you also that these languages
exist today
like today you can write
high-performance CPU or GPU code using
SPMD like languages but you can't really
do this in C++ so how can we do this new
code in C++ which is the description of
my answer for the rest of this talk
basically and so the way that I've
suggested to implement this in C++ so
far is what I call VPS BMD which is way
to write SPMD code in C++ so what is
SpMT RCPS pindy
CBP SPMD is a little header only library
I've made it's a subset of is BC in
plain C++ so basically I just look at
like the ICC spec and I just go like oh
I like this function I like this
function I just like put them in so it's
basically khatola ripoff but it it works
so it's implemented with intrinsic s--
like the actual header itself contains
intrinsic stuff but when you write the
code you don't have to care about what
specific instructions that you're
running for really and that's that's the
same thing with ice BC for example and
if you want to get like the executive
summary of how it's actually implemented
is basically just control flow is
represented by lambdas and these lambdas
are executed with masks that's like the
one sentence summary of how this library
works and I'll go in more detail in the
next slides and I should mention this
library is just like a proof of concept
so I've only implemented what I needed
for my tests and I summary for
production although I've had a lot of
people are interested in it so maybe we
can actually like take a bit more
seriously and turn to something that's
actually useful all right so just going
to show you quickly how to translate ice
beauty types test EVPs media types so
earlier we were talking about uniform
ants and you have front float and I told
you that when you see a uniform inter
uniform flow it's basically the same
thing as if it was just one INT or one
float just like a regular c scaler and
so that's how I should be convenient
because if you want to present these
types in C++ it's actually just a
regular interflow there's nothing quite
special about that but what about
varying it the varying float these are
kind of like new and exotic in sickle
cell and so the way that I've translate
that is I create my own types
vient and B float which represent a
variants or varying float so these are
types that are given by CBP SPMD moving
on I'll show you a quick example of how
to do control flow so you can get a
probably a feel for what
is gonna look like uh for a sweetie a
CPS moon decode you can see I've added
like my own versions for control flow so
here instead of if I say SP MDF and for
example here when I do be less than
three the value of V is a varying float
so the comparison less than three
actually is a like it returns like a
varying bool and based on the results of
this varying bool the function or the
code that's that's inside this lambda
here is gonna be run with a mask that's
that fix that if test into consideration
so to give you an idea of how this
actually works just gonna kind of like
quickly go over not it's like a
simplified version of the SVM D if
implementation it's like a bit more
complicated if you actually look at it
but I think I'll give you like a big
idea of how this is supposed to work
it's basically very similar to what
we've seen before but now written in C
so same as always save the old execution
mask into a temporary variable then I'll
do an and to apply the if test so that
now the institution mask only has its
lane active where the if test passed
then I'll just run the all off
optimization so if the execution mask is
all off just don't run the if block at
all it's just a cute little optimism and
otherwise it's just run the if body so
just passing a lambda there and finally
at the end of the day just restore the
execution mask so it's basically like
that's like again that's a simplified
version it's a little bit more
complicated in practice but that's
basically the principle and that's it's
pretty much at the end of day that's
it's as pretty much as suppose it gets
so alright so now to have meant the
varying variables like V here which is
like a V float I'm going to quickly show
you the again simplified version of how
this is implemented so the V float in VN
classes are basically just wrappers for
Emma 28 types or m62 56 types whatever
is the intrinsic implementation detail
data type the mathematical operations
like the x operation or just implemented
with operator overloads and so here if
you do operate at times on 2d floats it
just doesn't multi s like a
multiplication of two passing precision
floats and one thing you might notice is
that
in this multiplication here I'm not
taking the mask into consideration which
is a little bit weird but actually it
works because the trick is that it does
really matter if you multiply things
together that are masked out it's like
yeah it'll do some multiplications that
are gonna be thrown away so it's not the
best thing but it doesn't actually
matter that you have these these like
unnecessary values because if the the
fact that they're they're necessary is
gonna be reflected only when you
actually do it like a load or store so
actually like it's kind of I'm it or is
it the the store and the load are things
that take the execution mask to account
so this is actually partly why if you
have some foresight you'll see that this
is actually why I have to put store into
a function so I can access the execution
mask from from this function and so when
you do a store it'll take a bet
execution mask into account and only
blend values then so that's basically
how the masking is actually implemented
and yeah so let's look at a sample
program of how this works so this is
going to be some ugliness but I promise
it's all for a good reason at least so
far so when you want to write a spam D
program or an SVG function with this
framework you have to write you have to
actually wrap into a struct so instead
of a function it's a struct so this is
like declaring a function called simple
but instead you make it a struct and you
have to inherit from STD kernel
now the body of the function I can have
it can have any return type you want and
can take any arguments you want but the
convention is just that it has to be
called underscore call and again I
promise this is a good reason for this
well a good reason for now so this is
gonna be very similar to this simple
program that I showed earlier with ice
BC so we're gonna do a for each loop and
you can see I've implemented my own ice
cream V for each pass in the upper bound
and lower bound and I'll just loop
through that and at every iteration
it'll call the lambda that corresponds
to one iteration of this for each loop
and so you can see we've got the index
variable it's back but now it's actually
there's a new type that I haven't
introduced you yet
here it's ELINT so ELINT is a linear int
and what a linear int means is it's
actually a special case of bearing so
when you have a varying variable in the
gem most general
a varying variable has a completely
different value in every execution lane
but we have a linear value it means that
the value is increasing by one without B
lane which is actually very important
because it means that instead of doing a
gather operation you can do a load
instruction which is maybe like maybe
this is gibberish to you but there's
just say that if you if you load from
memory with contiguous indices it can be
a very simple load that just like reads
out those values if you do a load from
memory with different indices like
completely random indices there's still
instructions to do that but it's much
slower than doing a regular old plain
load although the gap is closing it's
getting better and with re-architecture
so very limited before load the inputs
into a B float this time and then here's
the if-else so a bit gnarly because of
the lambda notation but hopefully you
know two unreadable or you can see about
the f-test at the start would be less
than three and then I pass in the if
block and the else block has lambdas and
so the idea is that this being the
if-else statement is going to do the
comparison and then is gonna run the if
block and the else block with the
appropriate mask set in between the
calls okay and finally you store the
results back to memory so you can see
there's a explicit load and store
function names which is something I'll
talk about later but other than that
hopefully not too unreasonable if you
actually want to call this this this
function its program you can do like
this so let's just suppose you've got
some input array and some output array
that you've set up here's what kind of
like what the mean would look like so
you use this SPMD call function and
instead of passing in like okay so you
passionately the the function name you
want to call or I guess the kernel need
gonna call has empty arguments and then
you just pass in the argument of the
function as if it was just regular
function call and that's gonna invoke
the kernel and in this case since you're
calling this this kernel from outside of
the kernel it's gonna start off unmasked
like this damascena be fully or fully on
I guess so this is like no maybe I first
it's kind of like is it really gonna
work because you know we've got lambdas
everywhere we've got this like V float
type we've got like these magical stores
and floats and stuff so like is this
gonna hurt performance it's a big
question because all this is an
optimized
if you think about it so I did some
performance tests so what I did
basically is I took the sample programs
from the ISP see examples folder and I
the examples folder and is bc contains
an implementation in c++ and it contains
an implementation is PC and so I took
those programs and i ported them and I
created a CBP SPMD version of those
programs and I used that to compare the
performance so starting off with the
plain C++ code I brand this noise
function code 100 times I think and that
took 45 4 5 seconds which is actually
pretty long time
porting it directly to CPS BMD lowered
the runtime down to 10 seconds we just
like a 410 speed-up right off the bat
which is actually pretty good but then I
ran the ice PC version of a program and
it did a lot better so it's like almost
around twice as fast so it's kind of a
disappointment but you know I thought
hey this is C++ we should be able to
make things fast how could I specie beat
us so I just mystification found out
that actually it seems like civil slows
compilers just like aren't optimizing
aggressively enough at some stuff
especially gathers like SBC is way
better at finding like we're done and
gathers and pulling them out of loop it
just say like the optimization it's like
much more aware of like what's fast and
what slow in terms of architecture it
seems so I found what optimizations I
specie was doing and basically just
redid by hand and I went around did a
few other things just like tweaks and
stuff and then ended up getting hey so a
little bit faster nice PC with a bit of
work and I found actually like running
it with profile guide optimization made
it even faster so you know getting up to
9x performance that actually feels
pretty good because this is running on a
BX 2 in the X 2 instruction set and the
FX 2 instruction said let's who run
vectors of width 8 so it's kind of like
super linear speed-up which is kind of
like what but hey works I guess
and also on Monday Barney's true ship
said that he wanted like 10 times
improvements to C++ and I was looking at
the sly of City and I was like oh no
it's like it's like 9 X it's like not
high enough but then I know it's like
actually I ran this program on my laptop
here which is a newer architecture than
the one at the top of the slide there
and actually with the improvements in
the architecture hey it's actually
relative to the first one let's up to
the older architecture
playing super close code it's actually
11 times faster so I think this is proof
that if you want like a even more than
10 times improvement in civil source
code we can't actually accomplish that
with a combination of using Cindy and
you know embracing your architectures so
hey this it's promising I've got some
other examples so for example here's the
man robot set again like you can't write
out to talk about colors and with Cindy
without having a none of us said
apparently so at first but just like
regular C++ code doing a thousand runs
took almost 100 seconds it's actually
like almost painfully long to wait for I
poured a street to see bps BMD and went
down to like 2 times or you know 53
seconds not bad but still pretty slow
compared to everything else no it's like
ICC the otaku part is a bit better job
so down to 30 seconds that's nice and
basically just like these differences
between Capas that are so huge I think
it just makes me see that we need to
make like a power vendors aware if I cut
out two mice code for this basically
that's what it but that's what it means
to me
moving on though it's it's again like I
species I managed to get like a huge
speed up from this GPS can decode going
down to 16 seconds and again in this
case I was like come on this is C++ be
sure to do better so I went in and like
figure out where the bottlenecks were
and did a bunch of optimization stuff
and realized I okay so does this waste
actually speed it up and and then I got
down to 15 seconds but with some work
right so again like kinda like similar
to the first one
it was floored that I specie at first
but with some hand optimizations you can
you can get it back to where it's
supposed to be I've got a few more
examples so this one is a volume
rendering example where I takes a point
cloud and renders it as a nice-looking
stream of I know smoke I didn't have
time to actually like hand optimize this
one so I kind of like just a minute
defeat still though the superclass code
like the regular old C++ code is pretty
slow and just putting at the cps BMV got
a huge speed up on both visual C++ and
Intel compiler running a nice PC still
is the champion but the gap is not so
far compared to the Intel compiler
example all right and since Finance is
so important in C++ I've supported some
of the I guess like
finance algorithms like I don't really
I'm familiar with them but I think these
are used for like stock buying stocks or
something like that I don't really know
anyways i ported this code without even
knowing what it does and so the you know
you can still see an improvement from
plain c++ so running the epsp new
version of binomial options got me a
small speed up and i species still a
little bit faster actually it's kind of
surprising that the binomial options is
like it's really not getting that much
juice out of Cindy and I haven't
investigated why but that's like an
interesting case out of all the examples
that it seems to not scale that well and
then there's a black Scholes algorithm
that one got all faster with CPS BMD
with a straight port from just getting a
four x feet up like that running with
IntelliJ faster but again here I specie
was a champion and I didn't have time to
make a hint optimized version
so to summarize all these examples
here's some nice craft so the plane
Super Plus is the blue bar and the
orange bar is CPSP in these performance
relative to the the blue ones I species
the gray bar and then when I took the
time to optimize it that's the yellow
bar so I can shape you should give you
like a big idea of what's going on here
it seems like if you want like the you
know really great results and like not
have to do any like tricky optimizations
up and all that kind of stuff you can
just use I specie today and that seems
like probably the best choice but if you
really want to C++ code and you're
willing to maybe profile your code and
maybe like I don't deal with the fact
that current compilers or maybe not as
good at optimizing vector code CBP ice
cream he might be an option so that's
the performance of it but the court
earlier is still like had a lot of ugly
parts and so what I want talking about
now is just like all the quirks of how
this works and part of the idea of these
perks is that it's going to be also like
a way to suggest improvements this is a
closed language so one of the first
works is the fact that you have to
actually explicitly load it in store and
the reason why is because what I'd like
to do is I'd like to make it so that
when you do an assignment so if you
float with the operator assignment I
like you to do a like a mask store but
that's not possible and because I need
the execution mask in that assignment
operator and that assignment operator
has to be a member function of you float
which doesn't have access to the
execution mask and something happens for
like my my V float ref class so lethal
ref is supposed to be like it's the
results of an indexing operation and so
I mean you convert that to a V flow to
gives you like the results of floating
from the address and again this this
conversion operator has to be a member
function so I can't access the execution
mask and a member function so you know
but that's why I can't use it maybe it
says you're close defect because I don't
see why this isn't really possible they
maybe it's just like we don't have the
syntax for it or something when I wish I
could just write is just like how my V
flow class and then read the assignment
operator in the body of STD kernel and
in that case I can access the execution
mask and like I mean like I already have
this code it's just that it's called
like load and store instead of being
called operator assignments so other
than like syntactical issues I don't see
why this isn't possible but so yeah
maybe that's an improvement as possible
another thing you might have noticed if
you if you look carefully is that when I
index race
I say index operator instead of pointer
of index which is like a bit weird so
the reason why is because you can't
overload the operator to index a float
pointer because I guess you just can't
overload operators from building classes
like that as far as I can tell so I kind
of like abuse this identity here which
by the way this works in all C programs
just the fact that like when you do
pointer if I it's the same thing as
doing star pointer plus I which is the
same thing as being higher plus pointer
dereference which is the same thing as
being a pointer like this actually works
in all C programs and so by using that
identity
I just overloaded the operator for VN so
you say vient like quote no braces flow
pointer and Biscay when you translate
code you just have to switch the order
of the like the the arguments to the the
braces operator and or the square braces
operator and other than that it kinda
just works so kind like a dirty trick
and it's basically just syntax but maybe
there's a way to fix this by adding new
like waste for overlaying operators in
C++ another quirk is the need to call
SPMD call like
it'd be nice if you could just call it
as if it was a regular function like as
if it just worked like a regular
function but instead you've to the SPMD
call and the reason why is because when
you call a function like a SPMD function
from another function you have to
actually do an implicit like pass by
value of the execution mask and so right
now that's not possible like you know
it's kind of weird because it is
possible to implicitly pass like that
this pointer like this pointer is
something that simplicity pass between
member functions but the execution mask
like you can't do that right now so I
don't maybe this way to fix that and
other than that thank you other than
that this is busy at work so it's like
if you call it from the outside of an
SPD kernel I'll just call the function
with a mask that's all on and if you
call a CMD call from inside an SPG
kernel then it'll like the only thing
like the body first when you call is
actually extremely small all it does is
it copies the mask and then calls the
function that's all it does and so that
also explains maybe y-nough also
explains why it's called underscore call
the reason I made a suit you have to
call it under spare calls because it's
just to give you a hint that like you're
not supposed to touch this basically
like if you have to explicitly say dot
underscore call like you know you're
doing something wrong so I just read is
it really I don't think so yep
so wrong well good so so that's why I
call it like that and it's kind of ugly
but it works for now another quirk is
that there's these lambdas everywhere
and like these lambdas like it's not
like you can do much with it like this
is basically just noise it doesn't
actually add anything like it there's a
functionality that you can have like
these lambdas with that they that
capture everything and just do whatever
so from what I saw it seemed like they
usually get in lined so it's not really
like a performance
now you don't actually get transit into
function calls most of the time but just
ugly syntax so I don't know if there's
actually a good way to fix this other
than actually changing the single source
grammar so maybe in the future there's
gonna be like an actual extension of the
grammar that lets you do something like
this more easily I hope maybe there's a
way to do with macros I haven't really
thought about too hard because I just
dislike macros and I feel like that's
defined the purpose but maybe there's a
way to do it if somebody something it
was like a clean way to do that all
right next thing is the fact that you
have to inherit from my stream is
eternal so it's like why do you have to
inherit from Eastern you criminal the
reason why is because it gives you the
executioner mask and also gives you the
related logic for the execution mask so
that's that's basically I have to
inherit from that and I kind of see it
like it's not necessarily a bad thing
because actually it could be used to
configure the implementation the Cindy
so for example whenever you buy that is
imagine you want to write a kernel that
you know you wanted to use a px - this
is just like in theory maybe if it could
be like an SMD kernel avx2 and then that
way you're guaranteed about the
instruction set is being used for your
kernel alternatively maybe it could be
something like this we're like you got a
template argument for the width and that
can be useful because when you're
writing code that interfaces between
like cindy code like this this code in
another code as long as you want you
want to assume that just like you're
working in blocks blocks of 16 like
maybe you're working in blocks of 16
pixels or something like that and the
fact that you're using an instruction
said that works in terms of 4 or in
terms of 8 or in terms of 16 it's kinda
like an implementation detail so be able
to say that like be able to say that
this kernel should run with with an
emulated width of 16 is something that
could be pretty convenient and it's
obviously just to give you an idea like
if you're running like a SPD kernel that
is supposed to pretend to be 16 wide but
the instruction set you're using only
has four wide vectors it basically means
that every operation is crippled like
just every statement just happens four
times that that's what it means and
other than that I think that that's
pretty much it so yeah I think I'm
to exploit that but the promise is when
you do the SPG call you have to be able
to set the mask and all that kind of
stuff so yeah it'd be nice to do like I
don't I I kind of got it working but
there's a lot of things that could be
improved by people who who know better
or like the detailed roles of SIBO fuss
yeah I'm actually gonna talk about that
in a second yeah
so in conclusion we've seen today that
SPMD is like a actually pretty like
widespread portable way to write code
that seems to be you know works on both
CPUs and GPUs so it's actually pretty
nice I've shown you that you can
actually commit to it and relatively
simple sequel close code so like I
didn't write any like weird template
metaprogramming stuff there was no Mac
was involved it was just like like this
Ben you kernel class that just like has
a few like functions in it and it runs
slam does so it's nothing like too
spooky I think anybody can understand it
really based on the performance
measurements that I did it seems like
today if you want to write code that
looks like this
the best bet is to use is PC but hey
maybe tomorrow C++ is gonna be the best
choice so hopefully we can work through
it something like that maybe we're
missing like language support in terms
of like new syntax is for things like I
showed earlier maybe we also need to
have compilers be more aware of how to
optimize code for Cindy architectures
which is a thing that maybe me maybe
explains like the big differences in
performance between different compilers
but hey we've got the right people in
the room at the conference so you know
let's think about how we can close this
gap other than that thanks for listening
we have any questions or comments let's
talk about it you can find the
implementation here again it's not
production ready it's just like it only
implements what I needed for the
performance measurements I did before
basically and if you want talking on
Twitter here's my Twitter that's all
thank you
right so so as far as I know when you
write into Simon's operator okay so I'll
be the question the question is why
can't access the execution mass from
inside the assignment operator the
reason why is because as far as I could
tell the assignment operator has to be a
member function of the class that it's
assigning to and so it has to be a
member function of V float and V float
is a separate type from STD kernel and
so it has to be able to access the
execution mask that that's stored India
is going to be kernel that contains it
and in this case I'll take this way to
do that it's a goes plus and like yeah
maybe I could do something like maybe I
could store the pointer to the SMD
kernel from inside the V float but I
decided that seems like to or head so
yeah yeah the kernel is an object and
all it does is give you the execution
mask and and it gives you the functions
that are necessary to rate SPME code
like you just inherit those
functionalities
okay actually fluid is defined like in
the scope of assume you colonel like
it's like a inner class yeah but but I
think I wasn't really change anything
about how big a nice is totally yeah so
you can look at the code yeah let's
let's move on yeah right
so I'm repeat I'm gonna try to summarize
this comment then where you're
suggesting is that we could implement
this by returning evaluated like like to
see that thank you so the question I'll
try to summarize or the comment is is if
you try to extend the native Cindy with
by duplicating every operation does that
not lead to the case where you actually
do need to put a barrier and I think it
doesn't
my main like inherently the reason why I
think it doesn't is because I specie
lets you do it in the sense that I
specie lets you say like run this AVX
code as if it was 16 wide and that works
so I assume like the model doesn't
prevent it it should in theory work I
haven't got a proof of concept in CPSP
MD so maybe there's some other details
I'm not thinking of but I think it works
and I think the important part to keep
in mind is that
the synchronization happens at sequence
points so that means is like in one
statement which will be executed
multiple times if you're doing like a
wider with like or at least it'll be
executed once but it'll be executed and
they'll do multiple vector operations
you can't assume that like you can't
communicate between lanes of execution I
guess like yeah you you know how kind of
say you you can't communicate you can't
communicate using shared memory between
lanes of execution inside one statement
you can only do it in between statements
and I think that that makes it work out
so I mean it's kinda like mind-bending
so maybe we can think about a bit longer
but I think it should work and I think
that the reason why well what is it I
think the reason why I buried a
necessary on a GPU for example is
because you actually do have multiple
threads of execution in the sense that
like but by the word thread I mean it's
actually different pieces of hardware
running the same code in parallel or
without being in lockstep so since these
different executions are non locks that
get to put a barrier but in this case
it's in lockstep so it's a bit simpler
so right so right so to repeat that on a
GPU how can I say this doesn't scale two
GPUs because GPUs I guess you're saying
needs to be wider and need to be running
at multiple threads like actual
different Hardware threads and this
model doesn't consider that I guess and
I think I think you're right about that
and I think that that that problem might
be on GPU vendors and GPU vendors hands
that they have to make a more flexible
computation model that that's my opinion
but yeah but Biscay like I mean the way
the original GPU is like they'll have
these different like they'll have these
independent streams of like wavefronts
of like 64 64 bytes vector operations
but they're all getting scheduled in a
penalty and I don't think we have a good
way of like controlling that
from our code anyway that would make
sense to C++ right now but maybe in the
future right
but locks that would kill the
performance so as long as you're inside
of one rate front yeah and actually I
think that's a that's the thing that's
getting more more more and more popular
I think like shader model six I think it
is like the the new your shader model of
explosives may level operations so that
kind of stuff is something that I guess
we'll be seeing more and more all right
any more questions comments the license
I think it maybe it's MIT or something I
remember it should be not a problem yeah
if it's a problem Tommy and I can do
anything necessary to make it possible
to fix yep anybody else okay I think
we're just about done so thank you for
listening</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>