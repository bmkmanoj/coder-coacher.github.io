<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2017: John Regehr “Undefined Behavior in 2017 (part 2 of 2)” | Coder Coacher - Coaching Coders</title><meta content="CppCon 2017: John Regehr “Undefined Behavior in 2017 (part 2 of 2)” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2017: John Regehr “Undefined Behavior in 2017 (part 2 of 2)”</b></h2><h5 class="post__date">2017-10-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TPyLrJED0zQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">So as I was kind of ending up saying,
Static Analysis tools,
at least sound static analysis tools,
remain something of
not necessarily a researchy.
They have a researchy flavor.
They're not
ready to apply to our biggest codes yet.
That leads us to the
dynamic analysis tools
and this is where we've had the
really amazing progress in the last
seven years or whatever.
These things have come
along really well and really
I think have
made a difference.
What I'm gonna focus on
while I talk here is,
there's a lot of these tools,
I'm gonna focus on the LLVM based ones,
which you've (mumbles)
Address Sanitizer has
made a enormous difference
in undefined behavior
and undefined behavior checking.
It's just this incredible thing.
We had Valgrind before
but Valgrind ran too late
on compiled code and it wasn't very fast.
Address Sanitizer is
just enormously useful.
It's not exactly what we want,
I'm just gonna have to be
careful with what I say
'cause (mumbles) is right there.
It's not exactly what we want,
what we want is balance checking.
We want real balance checking.
Address Sanitizer is sort of
a red zone based approach but
it's so close to what
we want and it's there
as efficient that it just
makes an incredible difference.
I don't know how many of you,
I guess I was already saying it.
In the 90s if you ran Purify on
almost anything it would just dump
pages of crap.
It was just incredible that anything ran.
It's still a mystery to
me why things used to run.
(laughter)
And that's not the case any more.
Most software is fairly clean.
Undefined Behavior
Sanitizer is another one.
Address Sanitizer,
I'll just borrow some of the terms
from (mumbles) talk about this.
The hard checks,
it requires quite a lot
of infrastructure to work.
Undefined Behavior Sanitizer
are sort of the easy checks.
These are the ones that
don't require very much
infrastructure to check.
These are things like
the shifters that I
talked about earlier in
(mumbles) native client.
Signed integer overflow.
Pointer overflow was one
that recently was added.
In C and C++,
as you all know you can go
one element past the end of an array.
You can compute that pointer but you can't
due reference it.
You can't go further and
you can't go before the
beginning of an array and
you can't compare pointers
between two arrays.
Pointer overflow checking is this
pretty efficient,
pretty weak check which
only looks for pointers
actually wrapping around
the end of the address space
or the end of the pointer range.
This is in Undefined Behavior Sanitizer
now and it's pretty cool.
It's a cheap check and
it does catch some things
that people shouldn't be doing.
- [Man] You can compare
something between (mumbles)
You can't compare pointers
between two different arrays.
- [Man] You can but--
You can with something like standard,
which is it standard (mumbles) down?
- [Man] Even though that's
not such a surprising thing.
Somebody find the quote.
Somebody we need to talk to him.
A bunch of stuff is made into
Undefined Behavior Sanitizer.
The alignment check stuff
is actually really cool.
I don't know
how many people have run the full
Undefined Behavior Sanitizer
on big stuff but the
alignment checks dump a lot
of stuff on typical software.
It's worth fixing both.
Like I was saying at the
beginning of the talk,
not only because of
architectures that don't do this
but because the compiler
is actually free to
assume that things are
aligned and could break things
in sort of weird ways.
One of the things that
is pretty cool is that
UBSan has capacity to check for
also unsigned integer overflow.
This is pretty cool to watch
people actually use this.
People actually use this
sometimes and so of course
integer overflow isn't undefined.
It's perfectly well defined
but it's often indicative of a bug.
It's not indicative of
a bug and something like
a hash table where you're trying to wrap
the unsigned integer around but it is
indicative of a bug in many cases.
Turning this on selectively
and white listing
the cases where you want it
to overflow actually turns out
to catch quite a few bugs.
This is an interesting thing is that
this points to an interesting
issue which is that
we like to look at C
and C++ and say that the
undefined behavior,
this aspect of the language sucks.
Just something that at
least I've often said
and it's actually not really
quite true because Java
for example defines both
unsigned and signed integer
as wrapping in a too complicated fashion
and that robs us of quite a
lot of error checking power.
What it means is the
language guarantees us
semantics for something.
If people can count on it
it's not a bug any more.
The fact that C and C++ have
all these undefined behaviors
actually it opens the
door to a lot of checkers
and finally these checkers
are pervasively appearing.
If you look at some of the
very early rationale for C,
they did design the memory
allocation sub-system of C
to support checking.
That was intended all the
way from the beginning
or near the beginning.
It's unfortunate that it's
only relatively recently
that these checkers have gotten
quite good.
Let us briefly mention
some of these other ones.
Memory Sanitizer can check for
use of uninitialized storage.
Thread Sanitizer can check
for data races and deadlocks
and I don't know how many of you have used
Thread Sanitizer but
it's really a pleasure to use.
For a lot of kinds of
bugs at least that I make,
I avoid writing threads when I can.
When I do write them and
I have bugs it really
mentions the problem fairly concisely.
There's a new tool that's
just under development
so you can't use it and I really hope it
comes to fruition.
It's a Type Sanitizer.
It's a type based alias analysis sanitizer
and this is a big thing that's
been missing for a long time.
The type based alias analysis problems
are lurking latent in
an awful lot of codes.
They get broken weirdly and
like I was mentioning earlier,
quite a few codes disable
type based alias analysis
just to
not run afoul of these problems.
A type based alias analysis sanitizer,
when this thing actually becomes available
for LLVM you should definitely
run it on your big codes.
This will be super cool.
I expect it to really
produce interesting results.
Often what the fixes are
gonna involve is putting
a lot of mem copies into your code.
Instead of using cast to
type unsaved views of memory,
you basically end up copying
them through (mumbles)
That's the hole that C
and C++ have put in the
type system
for explicitly supporting these different
views of memory.
It's often the case it is
better to just mem copy
a piece of storage into a
region with a different type
than it is to try to
somehow use typecast to get
two different views of the same memory.
The bummer about this is that,
although those mem copies
often get (mumbles)
by the compiler at least
in sort of easy cases,
when you turn on the
optimizer those mem copies
aren't gonna get taken
out for debug builds.
There's a risk that as
we make our code correct
with respect to type based
alias analysis that our
debug builds will get quite
a bit slower and this is
something that web browser
people in particular
that I've talked to have worried about.
I don't know how that's gonna play out
but I think it's gonna
be extremely fascinating
to watch the type based alias
and roll out assuming
it comes out in the next
few months or a year or whatever.
It's gonna be extremely
interesting to watch what happens
to people's codes.
There's some really
interesting trade-offs between
static analysis and dynamic
analysis and one of the
awesome things about dynamic analysis
is that it's sort of
finds bugs on popular code paths.
It finds bugs along the code
paths where you have test cases
and of course this is both good and bad.
It's obviously bad because
you may have security bugs on
unpopular code paths but
it's good because it actually
lets you fix the problems
that are at some of the most
relevant first.
That's a nice thing.
Dynamic analysis tools don't give you
typically false positives.
They're only giving you real bugs and
like I was alluding to earlier,
I've spent a lot of time looking
at static analysis results
and the real problem there is
you could spend a long time
tracking down something until
you get to the root cause
which is just an imprecision,
it's just a false positive
and this is extremely frustrating.
With dynamic analysis,
if you're gonna spend a few
hours tracking something down
at least you know that you're
gonna get to something real.
(mumbles) bugging tool.
Finally the dynamic tools typically
don't inundate you with little minutia.
Things that you know are
right but sort of are
technically wrong.
Whereas the static analysis tool,
this is almost their entire job in life
is to inundate you sort
of with sort of crap
because that's what it really
takes to make code correct.
It turns out that often we
just don't wanna pay the cost.
Often we don't wanna pay
the cost of really making
it correct on all the cases
it's just too hard for real code.
The drawback of dynamic
analysis of course is that it's
only as good as our test cases.
This is why infrastructure like the stuff
(mumbles) was talking about,
stuff like our asses fuzz
is so incredibly important
because the dynamic analysis
tools are limited by test cases.
If we can have really good
testing we get an enormous
amount of leverage out of these tools.
There's an incredible
synergy between the dynamic
bug checking tool and
the tools that exercise
dynamic behaviors in our code
like the (mumbles) fuzzer and like AFL
and other tools like it.
There's a very strong
positive feedback loop
between these two kind of tools and
this has really been
beneficial for people like us.
This has really made,
I think completely made our lives better.
If it was on a panacea,
in complicated programs especially
ones that process really
highly structured inputs,
there's always always always corner cases
that the fuzzer can't find.
Cross is gonna shake his head
or something but it's true.
But they really do
make a big difference
in what we can reach.
I made this figure
to sort of try to show
the kind of universe of
dynamic checking tools
or at least one view of it.
There's this universe
of undefined behaviors.
Things like UBSan and
find one particular subset.
Valgrind and Address
Sanitizer find another subset.
There are pickier tools,
pickier dynamic tools
and there's a couple ones
that are made by companies.
One is made by a company
just as often as another one
by a company whose name
I'm spacing right now,
to make much pickier
dynamic analysis tools
and those find most of the bugs found by
UBSan and ASan and also a bunch of others.
There are quite a few
undefined behaviors which
aren't found by any of these tools
and the fact is though is
that most of those ones
that aren't found aren't the big ones
that sort of matter.
There's a lot of,
like I said earlier that there
are 200 undefined behaviors.
By the numbers,
by far most of them aren't
very interesting and they
could just be nailed
by the standards committee.
I don't go to these
meetings so I don't know
why they have them.
I just wanted to put this up to show you
how I think of the universe
of undefined behaviors
as they relate to dynamic trackers.
The last thing I wanna
talk about with respect
to tools is mitigation.
Mitigation is pretty cool because
dynamic checkers are great
because they allow us to
find things at the bug time and fuzz time.
Mitigation tools allow
us to not be harmed by
undefined behaviors
that somebody else could
trigger and deploy code.
Mitigation is really
important because we have
such a hard time with that
last part of covering our software,
generating the test cases for that
last bit of functionality.
Let me give some examples of mitigation.
One of the unsatisfying
things about mitigation's
is that
there's not a lot of
uniformity or portability.
It has a very patch work kind of a feel.
Let's talk about some of what people do.
Linux compiles for example
with a flag which says,
don't delete in all pointer checks.
Even when the data for
the analysis part of GCC
can infer
that no point or check can be deleted
and the reason is is because
Linux has been burned for real
a number of times by bugs
like the one I showed you
where something like
a pointer dereference is
done to a struck member
or something and then there's an all check
and the problem is is by the
time we got to the all check
the compiler has already
inferred by the usage
of a pointer that it wasn't
null and deletes the null check
and this has caused real
vulnerabilities and there are
well known examples of
this causing problems.
The Linux kernel people
are simply unconfident that
they have eliminated
all bugs of that class
from their kernel which is big and has
a huge variety of authors and
it's just this enormous thing.
They use this (mumbles) flag
which says just don't do that
to avoid surprise
security vulnerabilities.
MySQL for example compiles
with a GCC flag called -fwrapv.
This takes
signed integers and C and C++ and makes
them two's complement.
Makes them two's complement
for real instead of
two's complement instead of
just having undefined overflow.
Why don't they wanna go and fix those?
I'm not sure.
I talked with them a while
ago and I never quite got
necessarily a strong sense of
what it was but either
they're unwilling to go
and fix them or they're
worried about not being
able to fix them all.
Does that kinda make sense?
That (mumbles) is a mitigation for
undefined integer overflow.
A number of programs compile
with the no strict aliasing.
The Microsoft compiler,
the Visual C compiler doesn't
support strict alias and
based compiler optimizations.
(mumbles) a number of open
source project turn them off
in their (mumbles) files
because they're just worried
about getting burned
or they know they're all gonna be burned
by strict aliasing bugs
in the code in question.
Like I was mentioning,
this is something that
we hope can change soon.
If all of the M based type
based alias analysis sanitizer
comes out and works well.
Something that I'm really
excited about that I
think is super super
cool is some of Android,
some limited parts of Android,
use some of UBSan in
the production really.
In the phone that's in your pocket
there are traps in that
code for integer overflow.
Not only for shift overflow
and signed integer overflow
but in some of these codes
for unsigned integer overflow.
That's really really cool.
I think it's really nice
that they've gone ahead and
pushed that into production.
There's this general question
of when can a detector
also be used as a mitigation mechanism?
It's not just a question of overhead.
Of course if the detection
method is like Valgrind
and has a 20 times slow
down then obviously
that's not a good mitigation
mechanism but it's also
the case that the runtime
for something like Valgrind
or ASan or whatever,
may add attack surface itself.
It's not just a question
of efficiency it's also
in a question of have you
added any attack surface?
There's some alternate runtimes
for UBSan that don't give
as good error messages as the default one
but that our design to be
quite minimal in terms of
code size and that shouldn't expose,
at least hopefully expose
any additional attack surface
and that's the kind of
thing you can turn on.
So this is very cool and
this is the kind of thing
that I would encourage people to explore.
Can you turn these
things on in production?
If you can that's very
nice because then you don't
have to worry about
that one person finding the packet that
triggers this particular
behavior in your code.
Chrome on Linux is built
with control flow integrity.
There's a very low overhead
control flow integrity that
avoids control flow hijacks
that's part of LLVM
that's good enough to
run as part of Chrome.
This is super super cool.
These kind of things are in some sense
less satisfying than the debugging because
we're admitting that we
haven't necessarily gotten
rid of all the bugs but
in another sense they're
much cooler because what
this means is that the
last few bugs that we
haven't been able to find
aren't gonna burn the product
and cause major vulnerability.
I think the dissatisfying thing is
these mechanisms aren't very
standardized or portable.
What does (mumbles)
mean and is it reliable?
These things don't necessarily
receive a lot of attention
or scrutiny and it's not
necessarily the case that
they do the same thing
across all compiler versions.
Some of the mitigation space is
not particularly satisfying.
Some undefined behaviors like
for example race conditions,
it's hard to think of a
good way to mitigate these.
It's hard to think of a way
to mitigate currency errors.
Memory safety error mitigation
tends to be expensive.
Address Sanitizer's not really designed
as a mitigation tool.
You agree?
(laughter)
It's not just (mumbles)
One way to see that is,
it's often the case
that Address Sanitizer,
if you're an attacker you just have to
compute a different offset often.
Does that make sense?
(laughter)
- [Man] If you don't mind I will hijack
your talk for a couple
of minutes maybe less.
ASan is not a mitigation
tool and I'm not aware
of any technique
in software that can
mitigate memory safety bugs
but I'm aware of the
released hardware assistant
memory safety mitigation
which is extremely useful.
Unfortunately it's only
implemented in one CPU that
probably nobody here's using (mumbles)
It has a very very simple
and very very useful
mitigation against this stuff.
It's called ADI,
application data (mumbles)
or something like this.
I want John's support and
everyone's support here to
push on the
hardware vendors other than Oracle
to produce something like this.
ADI is very cool.
(mumbles) why don't you stay up there.
Why not bounce checking?
What's wrong with real bounce checking?
Just so everybody knows,
ASan fundamentally uses
this red zone based approach
that can be jumped over.
Actual bounce checking
can't be jumped over.
Is that not what we want?
- [Man] Memory safety is two things,
it's spacial and temporal.
Spacial is bounce checking and
temporal is use of (mumbles)
We can solve
bounce checking if we
follow something like C++
core guidelines where the bound
is attached to the buffer.
We cannot solve bounce shaking
for the old Legacy C++ code
but even the core guidelines
looks like they're not
helping against temporal,
against (mumbles)
At least I filed a bug yesterday.
An example is (mumbles)
or string view where string
view takes a pointer to
a dead string and you have a (mumbles)
Even the core guidelines
seems to not be helping
and we have Legacy code from decades.
We need to solve both at
the same time and the only
thing that really is,
which is the closest to
solving this is (mumbles)
It's not ideal but it's so much better
than anything we have.
Production grade memory
safety remains illusive,
an illusive goal and it will be great when
this finally appears.
If it does.
Things like you'd be saying
(mumbles) can figure it
as a hardening tool if you
don't mind the fact that
a bug might be turned
into a denial surface
if somebody can trigger it.
I guess the decision has to be made on a
project by project basis.
In my ideal world what would happen is,
all of the 200 plus
undefined behaviors in C++
would have one of these
things done with it.
One thing we can do is a
lot of undefined behaviors
and I'm including a lot
of the ones I didn't
talk about 'cause they're boring,
could be defined and this really
wouldn't be that hard to
sort of stay in the standard
that the implementation just
does this specific thing
and I'm talking about all of the
fiddly undefined behaviors like
the unterminated compilation
unit or something.
These kind of weird ones,
some of these weird limitations,
don't seem to me to need
to be undefined behavior.
I can't see the advantage of this.
Another set of undefined behaviors
can be reliably detected
with fatal compiler errors
and this is of course
a perfectly good option
because then the software doesn't go out.
As a fallback,
the third place alternative and this is
much worse than the first two,
is to have a reliable runtime sanitizer.
The reason that that's
not as good is because
then we don't notice the
problems until runtime.
We're not there yet.
The situation has improved
vastly over the last 10 years.
Not all these sanitizers exist.
We're sort of getting
to this place I think
but kind of slowly
and in pieces.
How are we doing overall?
Not too bad overall things are fine.
Remaining big problems
include production-grade
bounds checking,
strict aliasing stuff
and I think the situation
might be improving there.
- [Man] (mumbles) also you
have initialized variables
and it's probably the
simplest thing to me to get
just initialized all the
variables and all the (mumbles)
That would be pretty easy.
We have minor issues like for
example non-terminating loops
and unsequenced side effects.
That's an undefined behavior
that I didn't talk about.
Probably not a big deal.
These are easy things to fix
that haven't been fixed.
- [Man] When you say we
should do one of those
three things for every
undefined behavior in C++,
does that include undefined
behavior in the library?
Every precondition on a
library function should either
not be preconditioned any more or
should be diagnosed to compile time
or should have a sanitizer for
catching violations of it?
Some of them will be slow.
- [Man] That's a bold position.
(laughter)
- [Man] That's what Fortify tries to do.
Some of them will be slow.
That's fine don't turn them on very often
or turn it on for small inputs.
- [Man] It's not the
speed I'm concerned about.
Oh it's writing them?
Well sure that's right.
- [Man] A lot more than 200.
That's right.
- [Man] More like (mumbles)
I'm a professor I can
say things like this.
(laughter)
What I do is this.
I just finish up with recommendations.
Everybody who writes
these languages has to be
pretty familiar with undefined behavior.
It's hard stuff and
we all need to know the big ones.
We need to explicitly
consider undefined behavior
during code reviews.
We need to test like crazy.
It's like
fuzzers are one part of it,
manually written test cases are another,
and then watching code coverage is another
and we all like to be
lazy with code coverage.
It's really easy to be lazy about this.
We really need to
lean on the code coverage
tools because this is the
only time you learn if a
fuzzer is actually doing
what you wanted them to do versus
getting stuck in some
(mumbles) and not actually
getting anywhere meaningful in your code.
You have to stare at the coverage.
This is super super important.
We have to all use the
sanitizers and easy static
analysis tools and then
fix the bugs they find
and this is hard.
It takes discipline but
once we fix the bugs
and get into a place
where the software works then
it's pretty easy.
Then finally moving forward,
maybe not necessarily now,
but moving forward we need to be familiar
with the hard tools.
With the tools that do
more for more verification
kind of stuff and I think
the future is gonna
include more of that stuff
at least for safety critical codes and for
security critical codes.
Thanks and I'd be happy to
take any more questions.
(applause)
- [Man] Not quite a
question but a comment.
Earlier was
the discussion
upon the comparison
between (mumbles) objects
for beyond specified or undefined.
There's a change in the
text between 14 and 17
which make more clear
but in both cases for C
it says unspecified.
In 17 it's very clear it's unspecified.
(coughing)
- [Man] I was prepared for it.
(laughter)
- [Man] Do you feel that
everybody should actually change
signed overflow
should define that behavior
or would you rather
it stay undefined or would
you rather it go to a,
it has a value but
might not know what it is?
No that's fine I think the sanitizer's a
reasonable answer there.
There's quantifiable benefit
for the undefined behavior there.
Something like shift
farther than bit width.
There doesn't seem to be much benefit
to that being undefined but something like
signed integer overflow is pretty,
the fact that you can make
some kinds of code faster
by exploiting those
facts is pretty ingrained
in how compilers work now
and I don't think it's
really practical to back
that kind of a thing out.
That's not something I would argue for.
- [Man] So you're not
arguing to get rid of
all undefined behavior
but to have realistic
solutions to the problems?
And the sanitizers are
absolutely a part of that.
They're good enough in many cases.
- [Man] I have a question about
unsigned overflow detection.
Is there a way to specify
that I expect this operation
to overflow?
Yes the sanitizers have basically
a little white listing functionality.
The few of them
where you want that to
happen you can mark them
and then you'll get the automatic
checking on all the rest.
- [Man] Oh except it's an exhibit.
Otherwise it wouldn't be workable.
Thanks a lot.
(applause)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>