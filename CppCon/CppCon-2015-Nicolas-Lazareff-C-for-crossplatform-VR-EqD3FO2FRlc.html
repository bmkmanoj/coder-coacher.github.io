<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2015: Nicolas Lazareff “C++ for cross-platform VR&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2015: Nicolas Lazareff “C++ for cross-platform VR&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2015: Nicolas Lazareff “C++ for cross-platform VR&quot;</b></h2><h5 class="post__date">2015-10-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EqD3FO2FRlc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so thanks everyone for coming as the
slide says this is a C++ for
cross-platform VR and I'm Nick it's
great to be back here in the east side
of Seattle they're being gone for a
couple years I used to work at Microsoft
and like we're just chatting a second
ago so to get of idea how many of you
guys have made VR apps or games all
right so just the one loan guy in the
back all right so I mean hopefully this
is informative then I think it's
relatively high level so everyone I'll
be able to learn at least a little bit
of something I know this is the last
talk before the you know the dinner
break and everyone wants probably to
come back for the 8:30 grill the
committee so I'll try to get through
this quickly and also I'll pepper this
with some food recommendations from my
time here in the east side also as a
bonus and I was just doing a second ago
you can check out some demos in the qvr
I brought it here this is a contest that
oculus and Oh toy where I work ran
called render the Metaverse there's some
pretty cool scenes that give you a sense
of what's capable on today's HM bees and
feel free to check it out after the talk
so we're all here to well I guess to
learn but VR development isn't easy and
the stakes are actually quite high and
the reason the stakes are high is
because getting it wrong causes nausea
and it's not just a little bit of
sickness you can actually leave someone
six the whole day so with a normal
application or with normal software if
you have some performance issues the
most you'll get is an annoyed person but
in this case you can actually cause
someone to throw up in addition there's
actually kind of non-trivial technical
challenges that support a variety of
operating systems Windows Linux Android
ps4 in addition there's a ton of devices
they all have different capabilities CPU
capabilities graphics and every SDK is
different sometimes actually in
different languages also and then
finally really great VR experiences rely
on some form of
and the problem is all the vendors are
kind of competing over what the
controller of the future will be and to
support all these input devices is quite
a challenge and then finally and
probably the most annoying thing of VR
dev at the moment is these are just
alpha and beta SDKs there's still tons
and tons of bugs it crashes all the time
so it's not exactly the smoothest
development experience so poor latency
leads to poor VR experiences
it's a driver like I was saying of
simulator sickness which is when someone
experiences VR and they end up getting
sick and the latency requirements for VR
are quite high most games are ok with 30
frames a second and some it may be go as
high as 60 but certainly 30 is not good
enough for VR and 60 starts to be just
the borderline acceptable we want
significantly higher frame rates than in
30 or 60 in addition today's devices are
also quite high resolution so the GPUs
and the software has to push quite a lot
of pixels games and apps today don't
have to deal with these types of
resolutions and VR apps and games do and
actually to make things worse all the
manufacturers are competing along
resolution and frame rate axes so today
basically everyone is around 1k for AI
and around 75 Hertz some have more some
have less but the ideal future and this
is also courtesy of Michael Abrash is 16
K 4 I at a thousand Hertz now
these displays won't be around while
we're alive but this you know endless
march towards higher and higher
resolutions and faster and faster frame
rates will continue for quite some time
it turns out that the bar for recreating
reality is it's really high so all these
things make c++ kind of a well-suited
language for the job c plus one of its
strengths and certainly one of the
reasons is having its second Renaissance
now is that it's cross-platform gives
you really tight
performance it's suitable as a library
and then finally it has good interfaces
to other languages which is important if
you know you want to rapidly prototype
or you want interface with designers and
artists as a bonus almost all the SDKs
are primarily C++ so this is probably a
good sign that most of the kind of big
minds in the in the industry are
thinking C++ is the right language for
the tool so like I was mentioning we'll
take a quick breather here this is food
tip number one so as many of farms right
down the street they make really good
apple juice it's worth checking out I
can't recommend it enough
yeah it's a it's worth it so like I've
been saying the art velman is quite
difficult so are there any solutions I
don't really have any but instead what
this talk is going to cover is
approaches that I've tried over the last
couple years on a variety of platforms
and SDKs and you know some of the
results have been good and some of the
results not so good so how's this
talking to progress I'll start with
discussing the separate code based
approach this will cover oculus mobile
and cardboard then I'll discuss how to
turn these two separate code bases in
two separate languages into one shared
code base that's entirely C++ and in the
process cover oculus desktop open VR and
PlayStation VR and then finally as a
final note we'll discuss how to add
quick little scripting layer on top of
the C++ library will build up to see how
to kind of rapidly prototype
particularly UI experiments in VR so all
the our apps effectively look the same
and this actually looks similar to a
game also the skeleton is you initialize
some stuff and then you have some kind
of run loop and you get frame callbacks
or you write your own frame callbacks
and then when you're done obviously
you shut down and clean things up
so on oculus mobile it's C++ cardboard
is Java and when it comes to
initialization since they're both on
Android we have to do some Android
lifecycle management we have to do
obviously some of our own C
initialization will leave the opengl
stuff the details of it to the SDKs and
then finally if our app needs it we'll
have our own loaders resource managers
etc inside of the run loop which for
both oculus mobile and cardboard will
let the sdk handle for us
we'll handle input update our scenes as
necessary based on user input or based
on what the user is looking at and then
finally we'll draw once for I and then
unsurprisingly when the app is finished
we have to tear it down and return to
the US without any crashes so what does
this look like for a oculus mobile app
we subclass in this case from VR app
interface and following the skeleton
from before we have some initialization
we have some drawing we get a frame
callback and after the frame callback
draw I view is called twice and then
finally when it's time to shut down we
shut down and of note here
oculus also supports what are called
hybrid apps which means apps that work
in the AR mode which is when the phone
is plugged into the hmd and also apps
that work when the phone isn't plugged
into the hmd so a library browser for
example is an example of that so how
does this look for or how does this look
like with a cardboard app it looks
basically the same this time obviously
we're in Java we in it so one common
theme with all the initialization we get
some configuration parameters once again
we have a frame callback and then
- I callbacks and then when things are
shut down we have to go and clean up so
the app doesn't crash and returned
successfully to the Android homescreen
so what does this look like in practice
one of the main things that all the SDKs
provide is what's called tracking and
that's the position of the head in space
as long and along with the orientation
of the head so it's what you're looking
at and where your head is so in this
case we're seeing what the oculus struck
looks like this quaternion stores the
orientation and this effect three stores
the position and actually of note here
when it comes to the mobile SDKs no
mobile sdk at the moment provides the
position of the head in space this is
still a large open problem that no one
has yet been able to to figure out so
this is a kind of more in detail how are
we going to use these frame callbacks to
actually do some drawing so one of the
key functions you have to implement in a
oculus mobile app is this frame it hands
you the VR frame and inside a VR frame
we have the head pose so since frame is
called unsurprisingly once per frame we
might want to update our scene update UI
but most importantly we want to store
off what comes inside of the frame which
is the orientation of the head and then
after frame Drive you unsurprisingly it
gets called twice also with some
parameters and inside of draw I view is
where we find the usual kind of OpenGL
commands with the pose that we saved off
a second ago we can calculate Model View
and Model View projection matrices and
then obviously do our drawing of our
scene for eye
another quick breather here I know I'm
trying to go through this quickly here
so that you guys have a chance to eat
right down the street is a facing east
this is walking distance both these
restaurants are it's really good and
Mediterranean kitchen also right down
the street also really good I can't
can't recommend either of these high
enough it's better than McDonald's all
right so back to back to our story here
so the state of the world at the moment
is we have two separate code bases we
have oculus mobile and C++ and then we
have cardboard and Java and it'd be nice
to have one combined codebase and in
addition the more code bases we have the
more problems we're going to get into
the more platforms you want to support
if we have one code base for each
platform things quickly can get out of
control and like discussed a little
earlier we have at least three more
platforms to support open VR PlayStation
VR and oculus desktop so how can we do
this again we'll turn to to our VR app
skeleton the concept of really all these
VR apps we in it we have a run loop and
then we shut down so in this case well I
remove everything and two entirely C++
one is appropriate we'll let the SDK and
it the window OpenGL and i buffers so in
the case of for example oculus mobile
it's convenient to do so and then we'll
do our own init and textures loaders etc
so similarly we have our per frame
callbacks will let the SDK do the buffer
swap distortion and time warp that's a
common theme across all the SDKs as
usual we'll get the head pose from the
SDK that's we use to draw our scene and
respond to input a little side note here
some of the SDKs manage or at least
provide or run them for you and some
don't and we'll see which ones do and
don't a little bit
that is in either case an option and
then as usual nothing surprising here we
just show down so how does our new
cross-platform class look like following
the same themes in it frame shut down we
have a configure initialize and entered
VR mode rather than having platform
dependent types we have our own settings
and launch config and since oculus
mobile supports this notion of a hybrid
app we'll also have this note you know
enter VR mode and exit VR mode we'll
have our frame and also we'll drop her I
will handle input as it comes in and
we'll leave the R mode when appropriate
user takes the hmb off or will shut down
when the user closes the app nothing
surprising here so how can we do this
structurally one suggestion is to rather
than have if deaths inside of many many
files instead will limit the if deaths
to the header of VR application and for
each one of the different platforms what
we'll do is make a different translation
unit so here we have oculus mobile with
the oculus mobile specific types VR
frame and in a separate translation unit
we will define and you know use that
function appropriately so what does
cardboard look like since it's in Java
we can't avoid using the J&amp;amp;I and you get
these nasty looking functions like this
sadly it's the only way to do things and
actually I found a humorous comment on
the oculus forums so the guy that's
responding here is Chris Pruett which is
kind of the face of oculus mobile
developer relations and you can see some
of that somebody asking them if there's
going to be a Java API for the oculus
mobile sdk and his response is you can
use the J&amp;amp;I if you're brave I found that
candid for a developer support
so like I was saying a little bit
earlier some of the SDKs provide you a
run loop and some don't open VR is one
of the ones that don't and so in this
case our VR application is going to have
to have its own name loop this will be a
standard loop effectively looks like
while the app is running go do some
stuff so how do we get the kind of
important VR things and this is a theme
that we'll see across the open VR SDK
oculus mobile and desktop SDKs placed it
PlayStation VR really all of them it
just comes down to cracking which is
where is the head in space what's it
looking at it'll provide distortion
based on the optics and if the SDK
supports some kind of input device like
many of them do it will give you events
to those in this case the open VR SDK
does exactly that
so the PlayStation VR SDK is the exact
same we also have to implement our main
loop and unsurprisingly it has its own
little libraries that give you all the
usual VR stuff that we've been talking
about the whole time here so what does
oculus desktop look like same deal
what's interesting about oculus desktop
is that it is quite different from
oculus Mobile I'm not sure why that is
but it certainly potentially points to
the fact that it's not easy to get
cross-platform SDKs cross-platform apps
right the apps and the SDKs for oculus
Mobile and oculus s up are almost
incompatible but any rate the themes are
the exact same we have a library here
it's libo VR we have some initialization
we get tracking and we submit a frame to
the sdk which will then do the
distortion for us and then finally and
as usual we
shut down so another common theme here
is that all these platforms are really
the same but they're all trying to do
things in slightly different ways and
this kind of is reminiscent of old
platform kind of graphics API Wars
ideally at some point there'll be some
standardization I think that's part of
what valve is trying to do with open VR
there are some other efforts like OS VR
as well though OS VR really hasn't
gained any significant steam or traction
so finally what we need to do or we'd
like to do is add a scripting layer on
top of on top of our C++ library and
will appeal to the same concept as
before which is an it frame and shut
down so this time we'll have primarily
C++ and we'll add an additional
scripting layer the candidates at the
moment are still up for debate at work
at Oh toy we use Lua but I think
potentially another good idea is Java
Script just to appeal to developers and
our web developers in a language that
they're comfortable with and another
candidate is scheme which Carmack is
calling John Carmack the CTO of oculus
is calling a VR script in a couple days
apparently he will do be doing the demo
using that at an oculus connect so some
interesting experimentation happening
and scripting and one of the reasons
that the scripting layer is nice on top
of C++ is that for apps that aren't
super performance intensive and in
addition for apps that are UI driven
having a scripting layer makes it easy
to prototype different UIs and also to
separate the work between the people
working on the C++ level stuff
and designers and artists working on the
higher levels so in the long term it's
likely that some mix of C++ Plus
scripting layer will be the way that
most apps are developed and curiously or
maybe unsurprisingly enough that's
exactly what unity and unreal are
heading towards unity primarily using
c-sharp and unreal using their
blueprints scripting whatever it is
language / drag-and-drop UI so how do we
do the scripting well it really depends
on what we want to script and for the
layers that our script kind of
prohibitive which might be the core
rendering loops will avoid that but for
layers like may be responding to taps or
creating objects in a scene or even for
networking between these devices
scripting is a good candidate and for
all these things when we want to call
from script into C++ we can set up some
handlers for that and then similarly
when we want to call from C++ into the
script we can set up callbacks I found
this to be most useful in initialization
and like said are like mention a little
bit earlier you know responding to UI
events and so finally what are the
frontiers here and kind of what are the
lessons learned one of the problems is
that there's no real standardized and
uniform way of implementing these VR
apps at a high level the init and frame
and shutdown pattern it's common to them
all but everybody does things slightly
differently and as a result you actually
end up with quite a bit of code for each
platform that feels like you're doing
the same thing but in slightly different
ways one of the
kind of next work items things that
planning on trying next is having
uniformity with the run loops so on
oculus mobile and on cardboard you're
relying on their SDK to manage the run
loop for you and in an ideal world you
either standardize on the SDK is doing
that or you standardize on yourself
doing that and it seems given the fact
that most the SDKs don't give you a run
loop writing a run loop for oculus
mobile and for cardboard might be the
way to go it would also be nice is to
try out other scripting languages when
talking with other developers I've heard
suggestions of even C++ scripting it
also be nice to make the C++ components
increasingly modular right now the code
is or as described the code is very
heavily dependent on C++ and as a result
it's difficult to separate things from
one another one of the reasons that
that's required and this is how the
modular Ness is tangled in with the
uniformity and all related to
cross-platform is everyone's ultimately
doing the same thing they're all
effectively providing tracking
information and providing some kind of
distortion but everyone's doing it
slightly differently so this is a common
problem on mobile platforms which is
each one of the mobile platforms
provides their own kind of set of UI
widgets and if you want an Android app
to look like an Android app then you
have to make sure that your C++ library
interfaces properly with the Android OS
and similarly with if you want an iOS
app to look like an iOS app you have to
use the iOS widgets and this quite is
quite or this hasn't quite happened yet
in VR but you can already see signs of
it as these SDKs are starting to
standardize so for example the
Kilis mobile sdk has its own set of
widgets and it encourages you to use
those widgets and then I'm guessing over
time an oculist mobile app will start to
look like an oculus mobile app which
won't look like a PlayStation app which
won't look like oculus desktop app what
that gives you or the problem that
creates is it makes it harder to create
cross-platform apps that look native to
that platform so on the one hand you
have the nicety of being able to use
these widgets and on the other hand you
have the hassle of having to deal with
one standard interface to a whole bunch
of different widget types and then
finally all of these VR experiences and
platforms are trying to create their own
input devices and as a result it makes
it very difficult to write code for all
of them so perhaps in the long term
there won't be uniform VR input device
but in the short term what this leaves
you is having to write code that deals
with controllers that deals with certain
kinds of wands that deals with the
PlayStation Move the oculus touch there
are rings the leap motion uses your
hands so everyone has its own idea or
everyone has their own idea on what the
right model is for VR input and no one
really has given any tremendous thought
on kind of standardizing what that might
be so an example of kind of what Michael
poorly if there is no standardization or
no attempt to come up with like what is
the basic VR controller is you know
imagine if Sony and Microsoft hadn't
agreed and at a high level what what
does a basic console controller look
like you couldn't write games for both
consoles you certainly couldn't design
them and design them well so if there
isn't some kind of this is what a
general VR controller looks like
the design of VR apps will suffer and
then as I've talked with people the
counter-argument is like sure while
Microsoft and Sony have in principle
agreed
what a console controller should look
like there are still a variety of
devices that attach to consoles
obviously Microsoft's got to connect but
then even there's things like the rock
band guitar and the drum set so it's
possible that in the end what happens
with VR is people decide there's a
general kind of wand like what valve and
Sony have and for each unique uuhh VR
experience sometimes you'll have
something different and maybe sometimes
use your hands but ultimately when it
comes down to designing the experiences
for these things you'll have to design
the experience with the input in mind
and then finally as a the last little
breather here so I don't know if you
guys have noticed and almost not every
one of his talks but a common theme in a
Scott Myers talk is him asking about
pizza so serious pie is my favorite
pizza here in Seattle that one's not not
super close to here but it's definitely
worth the drive and I recommend the
buffalo mozzarella pizza there it's
quite good and so it looks like we got
this got through this quite quickly and
thanks for listening any questions
yeah so there's no there's no great
reason so you could have for example
like if we go back a couple slides here
so you could have I think what you're
suggesting is so for like say
PlayStation VR
you'd subclass VR application and just
say PlayStation VR app or something like
that
yeah there's no great reason what this
gives you is the ability to so say you
want to have like one global object like
it's it's a design pattern called like a
program global program
I guess it's common in games and so say
you want to have something simple like
you have a global program object that's
used in all the apps and for each
platforms run loop you don't want to
have a separate type so you say you
wanna have it run loop in a standard
file that is in a layer above your
platform layer in that case you'd have
to if def inside of the run loop in this
case you could just go via our
application dot frame and it handed some
stuff will drop dry but it ultimately
it's a design choice yep
yeah so just like everything else
Audio is SDK specific and everyone does
things a little bit differently a
because of differences in OSS and B
because the industry is so new and C I
think it's just some level of kind of
everyone wants to build their own walled
garden and everybody wants to be the
dominant VR platform that said it is
something that is I'm kind of under
active research because like I was
saying earlier or I was mentioning
earlier about the simulator sickness one
of the ways that you can prevent
simulator sickness is by having
positional audio it significantly for
some reason impacts just how sick you
get especially with things where you're
moving quickly through space so I guess
it's not a tremendously good answer
other than you know it's under active
development and everybody does it
differently
they all provide kind of I guess the
best way to say it is they all provide
in it an SDK or they provide a way for
you to give like three 3d positional
audio and everybody does it differently
in some cases you'll provide a wave in
some cases if you just say like a video
for example a 360 video and in some
cases you'll actually provide you know
where the object is in space so that it
can calculate properly you know what
year to to play it on yep
so you're asking on the Sony sorry can
you okay so what you're asking is the
Sony Morpheus display is inherently
different than the rest of this place
and aren't there any differences or are
there any ways to optimize or you know
take advantage of that that's a great
question I'm not sure actually what I
have heard and I don't know that it's an
opinion that like I kind of strong it's
not that I disagree with it it's that
it's just something I've heard people
are very kind of I say best people
really like the Sony display and they
really think it's the best one so maybe
that's one of the reasons but I'm not
sure
yep can you go into a little bit what
would be involved
yeah I mean just like everything else oh
so sorry the question was what would be
involved in switching from Lua to
JavaScript or you know to whatever
language of choice and in some sense
just like everything else is platform
dependent so on Android you might use
the Android OS javascript interpreters
you could also add like some apps are
doing today
v8 directly into your app so the final
kind of interesting component when it
comes to that and especially in regards
of loop in regards to Lua bridges
scripting languages in general some of
the platform vendors or some of the kind
of VR vendors don't allow cheating on
their platform presumably that's - they
say it's because of security reasons but
you know kind of a under that's what the
underlined but maybe the real reason is
that allows you to maybe put your own
app store on their platforms
so I guess hopefully the best way to
answer your question is it depends just
like everything else there's no great
answers VR is kind of Wild West at the
moment so if you're interested in it you
should definitely work on it
anyone else yeah actually
so I'm not sure what the PlayStation
uses for JavaScript yet although they do
allow it I'm not sure what engine what
they don't allow is they don't allow
legit yeah yeah on the PlayStation hmm
so a good example of that and this
doesn't really have much to do with VR
is for example like iOS doesn't allow
 inside of an app if you embed a
webview it does yeah but if if you
yeah oh I see so we haven't tried this
yet but I do remember reading somewhere
in the documentation that they do allow
JavaScript jet inside of a PlayStation
app presumably yeah exactly because they
use some engine of choice and maybe they
run it through some like pre pass to
make sure that you're not doing
something they don't want you to do I'm
not sure they definitely don't allow
what would yet
yeah so if we're not talking about VR
anymore just mobile development so we
were asking is just repeat the question
does JIT or the ability to JIT on a
mobile platform and particularly the
phone which is what the Andes Android
phones which are the only ones support
at the moment give any like battery life
or performance gains
I haven't measured that but presumably
yes and certainly there'd be performance
implications so say you wanted to do
things that aren't just responding to
user events maybe you want to create a
bunch of object or maybe you want to add
some scripting into the kind of the main
run loop you definitely want jitter in
that case does that answer the question
yeah anyone else
all right thanks so we got here</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>