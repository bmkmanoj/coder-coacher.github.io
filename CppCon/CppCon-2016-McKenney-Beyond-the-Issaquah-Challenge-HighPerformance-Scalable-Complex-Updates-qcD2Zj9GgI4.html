<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: McKenney “Beyond the Issaquah Challenge: High-Performance Scalable Complex Updates&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: McKenney “Beyond the Issaquah Challenge: High-Performance Scalable Complex Updates&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: McKenney “Beyond the Issaquah Challenge: High-Performance Scalable Complex Updates&quot;</b></h2><h5 class="post__date">2016-10-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qcD2Zj9GgI4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay may as well get started here so
this is a kind of a follow-on to the
talk two years ago that was the Squatch
challenge and was one approach to
dealing with it and we'll be looking at
a little bit beyond this a lot challenge
on this one I asked a literally ER but
I'll ask again some work people can how
many people were at the talk and 2014
okay so several be that's good well
it'll this talk relies lived on that
will do a little bit of a review to
catch up but if you hear if you have a
little advantage those are the top was
going to cover and first off I'm gonna
do is you kind of review what the
issaquah challenge itself was to give a
starting point and then show up what
we're doing beyond that point so the
point of the issaquah challenge is you
have binary search trees and you need to
be able to move stuff from one tree to
the other atomically and that means that
if a reader goes and looks in the
right-hand tree and doesn't see element
for that if it looks in the left-hand
treated better see it okay so that's be
atomic in that sense and also the other
big thing and then the same thing for
element 1 in the other direction the
other big thing is that in this case
there's no relationship between these
guys in a data structure sense they're
entirely different parts of the tree and
so it's a requirement that these moves
be carried out with no contention
whatsoever okay and that means no lock
contention no memory contention no none
all right and that means that most
solutions based on locking in fact most
solutions based on a lot of things just
need not apply because they will have
contention lock contention or if you use
some of the non blocks organization
you'll find yourself doing Kaz's on the
same element that's contention sorry out
of the pool okay so the next slide is
just kind of a quick history of where
we've been with this the very first
thing after the meeting escalon
february2014 was a c-plus paper the
presentation here I followed up at LCA
with better scalability which will see
at conference in June
I made some changes the main thing was
laziness on my part I was getting ready
to start definitely some of this stuff
for real and realized that meant I had
to have two copies of every algorithm
yet have a hash function for just RS you
look up hashes and then another one for
if you want to do tonic moves and that
deeply offended my inner sense of
laziness and so that meant a bit did
more work to avoid that so we can just
use one underlying algorithm and rapper
the stuff on top of course that means we
start from Ground Zero on scalability
and reliability and I've made some of
that up but I have made it all up anyway
here we are in September 2016 looking
another round of this I'm just going to
quickly run through this some people
would argue that parallel updates or
solve problem we got hash tables we have
locks in each each bucket and you know
randomness should work you should have
no contention life should be wonderful
but if you actually try running it well
your global blocking you'd expect that
to be horrible and it is but per bucket
locking that's the wonderful stuff for
the updates and it falls off there and
this is a log-log scale so that drop is
is it looks general but it's not alright
and we'll see that and we'll see the
next slide yeah poof real down hard we
can get some of that back by making the
hash table bigger okay we don't have
that many CPUs going up to 60 but still
with 124 you've got some chance of them
running into each other but we never
really it's still a cliff it's a shorter
cliff but it's still a cliff and the
problem we have is a little thing called
the laws of physics the thing is that
the machines we have our set up kind of
like this in fact in the talk just down
in the theater before us there was
discussion about newman effects it had
and we having that here we split our
computers up into pieces it takes time
to get the information one piece to
another and that shows up in our
performance results the speed of light
isn't all that fast
scale and the speed of electrons or
holes depending on would look at it is
even slower we are not a vacuum where
silicon essentially and we're not light
we're little particles not only that it
gets worse we are not just transmitting
a signal from one point to the other
we're going through a bunch of clocked
logic going through cash is going
through cache coherence protocols going
through bus protocols things get slow
but if we could get rid of all of that
we still have two fundamental laws of
physics that are actually constraining
up via problem the first is the speed of
light sorry it's finite now there's been
some variance in the measurement over
the past century or so the people
measuring it accurately but it's still
finite the other problem we have and
this is not mine Stephen Hawking made
these observations at a tour of a lab of
some years back is that two atoms are
not zero thighs they're the problem we
have is that transistor is kind of
cartoonishly like structured kind of
like this you have a base in the middle
and the electrical with the base
controls how quickly you can switch the
transistor and about ten years ago we
had bases that had about there were
about this many atoms thick like four or
five okay they had scanning electron
microscopes of these things pictures
these things I don't know where they're
at now but I know they've made these in
research labs and actually operated them
I don't know what the production
transitioners look like but we're
probably not far off of that now there's
a bunch of things where they could do in
hardware and they will do and hardware
vacuum tubes believe it or not are
making it come back and not you think he
come back and silicon rather than have
that base B atoms haven't be a gap right
it turns out at these scales the
atmosphere is essentially a vacuum of
the odds of molecule of air actually
hitting that junction at that point in
time is vanishingly small your radiation
is the higher probability in some sense
because you don't have to actually hit
directly with the radiation so but still
we have some serious limits we're up
against and we don't know how to
abstract these away I mean some people
say they do but I always look at what
they do in their performance results
don't
aren't consistent with the eerily
abstracting it away but abstraction may
feel the may fail us but dirty tricks
and workarounds are still with us and we
can make those happen all right I've
been doing this for a long time and well
you know one trick which I have used a
lot over the past 20-plus years is read
mostly access you see if it's read
mostly you don't have to communicate it
you can just get it out there to start
with the Akamai trick except apply it
inside a computer and before i come i
was thought of you just make sure the
data is spread out everywhere it needs
it's read-only it stays in the caches
and you get instant access to it life is
wonderful unfortunately sooner or later
if you want your computation doing the
interesting you're going to have to
update something I mean somebody you
might be able to prove me wrong on that
but every time i've come across
something sooner or later you have to
update something and you know we got
these little values or from cave a
little black square is that same value
replicate out everywhere as soon as you
update that value sorry poof all gone
it's now back where the in the updaters
cash and every else has lost it the
update operation was expensive although
the CPU designers usually overlap that
with everything so you don't notice it
as much right buffers wonderful things
but the next time those other guy is
read they get the full electrical prices
the system to get that value back and
that hurts well there's tricks and work
around for this as well one of them is
to leverage locality this is the big
thing with sharding they talk about
across as root systems we do the same
sorts of things inside of systems for
example replicating statistical counters
across all the CPUs or all the threads
you increment your own counter you want
to read the thing out you sum them all
up and if you're incrementing a lot and
something Sullum like you might if you
have an operating system that receives
packets increments a cap pack a counter
for each packet received and maybe every
five seconds or a minute or so it puts
out the sum to some kind of monitoring
system works great so there are some
workarounds and I guess one way to dodge
it is the
right unless you have to at least a
shared memory if you're writing to your
own memory okay that's not so bad and if
you can do a read-only traversal and
then only right at the edges where
nobody else will notice as much that can
be helpful too we'll talk about that
more and if you can you want to char the
data and give each CPU its own little
piece and not have them talk back and
forth although sooner or later they
usually have to and the problem with
hash tables of course is you have a hash
function and that means your accesses
are sort of random although you can
cheat and use a hash function that chops
the CPUs up then it's been done before
trees are really nice for this because
they spread things out unfortunately
there's just bit about having to
rebalance them every once a while and
that is difficult although it's easier
to skip lists than with other things
apparently although again skip lists
don't need it as much because they kind
of Iran but life's like that sometimes
okay I'm going to go through this next
part pretty quickly because it's just
what you'd expect if you lock at each
node and keep going down that's a really
bad idea because everybody locks the
route that becomes a bottleneck
everything's slow the conditional over
the place don't do it okay I'm going to
go through this part pretty quickly too
we're going to have a talk magid michael
michael wang and i'll be presenting on
hazard pointers in our see you and
concurrency field kits will be a little
more information on this plus there's
references into the slide set and other
things available but the idea behind our
see you is that you just let the
traverse reversing things read you don't
require them to do updates to note their
presence and then the updaters have to
be careful in order to avoid disrupting
the readers all right and yeah well care
is required but and I'll just quickly go
through insertion what this is is four
different states three transitions
between them we have a very simple
linked data structure which is just one
pointer and one element hanging off of
it maybe to start off with we don't have
any element hanging off of it null
pointer or null and see which for i'm at
usually we allocate a new data structure
it has garbage in it okay no problem
nobody can get at it so it's okay that
has garbage the only person is access to
this guy there's allocated assuming your
memory allocators working which I hope
it is then the next thing we do is
initialize it still a big deal nobody
else can see it and then we assign it
into the pointer the reason we use a
special thing instead of an equal sign
is that the compiler and the CPU can
often mess things up for you but once we
do that suddenly already can see it but
because we stored it carefully that
pointer store is a single instruction a
single store that means somebody racing
a reads from it if you're using proper
see Atomics instead of just assignments
and even if you are using assignments
like pilot it'll be a little bit why
don't miss to get at you but some might
what happens is that anybody reloading
that pointer will see either the null
value the old value or they'll see the
new value but they won't see some mush
of the two values and that means that no
matter what they do they either you see
a null pointer and see nothing there
which is fine or they see your structure
properly filled out which is also fine
okay so what this means is we can insert
things into a link structure without
having to do anything to the updaters
the updaters can just go around and do
stuff to us and the readers don't have
to exclude them they can run in
concurrently with them and it works out
fine for insertion and there are some
affair it's kind of surprising there are
actually a feral on a software that uses
just this and does stop the world tricks
when they need to get rid of things okay
but stop the world can be a little
annoying so we'd like to remove stuff as
well same situation we this time we're
to get a little more complicated we have
a three element linked list and remove
the cat now if we store the pointer from
the bullet to the cat and we make it
point to the new and we do that again
using C++ tommix or something equivalent
so that we just store the pointer in one
shot that means readers see either the
pointer from the bow to the cat or they
see the pointer from the bullet to the
canoe they don't see some mush of the
two pointers now they may disagree as to
whether the cats there a nod to given
point
I'm pending on when they show up and
when they get cramped and all that stuff
but they'll all see a valid list and if
we can somehow magically wait for all
the readers to get done once they were
done there no numerator can find the cat
only old readers can be there so once we
wait for all the readers there can't be
anybody with the updater with a
reference to the cat and at that point
we can free the element override it do
whatever we want to it the readers can't
see it okay of course you do actually
have to implement the synchronize our
see you magic operator operation and the
readers aren't leaving in the in the
most aggressive case if you compile a
linux kernel for a server with config
preempt equals n you will get this case
where the readers leave no trace of
their presence in memory okay but we
still have to deal with them and we do
we cheat as always what we do is rely on
the fact that it in non prepped
environments if you're holding a
non-parental resource a spin lock for
example you're not allowed to block if
you did block while holding a pure
spinlock you a deadlock you've got the
spin lock you block every else tries to
go for the spin lock they spin well
they're not going to stop spinning tilly
at the lock you're not going to get a
CPU until they get the lock until you
get the CPU you can't let go of the lock
and life is hard at that point so we use
the same rule for the readers okay if
you're reading you're not not allowed to
block what that means is if you see a
cpu block that means that all the
previous readers have to have finished
if it worries following your rules on
the other hand if people fail to follow
rules no synchronization world mecos in
the world it will help you right you can
break anything if your malicious about
it well that means that once we see all
three of these guys context switch so we
move the cat over here we do you think
right as RC went we blocked so we're
done and as soon as this guy does his
conscience which that readers done and
finally this guy the third guy in last
guy does his highlights which he's done
now the only reader that could possibly
see the cat's this guy but that's a
okay it's okay to be a little longer
than maybe we're just returning memory
once we've seen all three of them that
means no reader can possibly be seen the
cat anymore and we can free it or
override it or do whatever okay and what
that means is that the main thing is in
the middle there are sila
synchronization via social engineering
the primitives in the most aggressive
case optum the developer who has to
refrain from blocking if you desire to
read lock he has to not block until he
gets to the arch you read unlock just
like all the other synchronization
mechanisms if you are going to use
transactional memory you'd better have
all the relevant accesses in a
transaction if you don't it won't work
okay similar with locking and there's a
void data races is a big thing in C++
memory model the thing that's unusual
blood RCU isn't that it relies on social
engineering but then in some
implementations relies solely on social
engineering and the nice thing about
that is that there's not a whole lot
faster than doing nothing doing nothing
is pretty fast is pretty scalable its
energy efficient there's whole bunch of
nice things about it and in that
aggressive case we get done with that we
can take advantage of that but there's a
downside that downside is that is
specialized the best place is things
like networking stacks where there's or
any kind of a situation where you have a
data structure in the computer that is
tracking some external object because of
our friends the speed of light delays on
the atomic nature of matter that data
structure is out of date if something
changes it takes time for it to be
updated therefore any algorithm dealing
with that has to deal with the fact that
there will be times when it is stale in
those situations this works wonderfully
because the fact that you might see
something old well he nice and level
anyway because the update might have got
not it got to you yet something they
have changed out there but you haven't
seen it yet therefore if some of the
system has seen it some of it hasn't
that still okay in the case of routing
tables of TCP you may send the packet
the wrong way but you've probably been
sending the packets the wrong way for
quite some time because the routing has
update hasn't gotten to you yet and if
you
the pack of the wrong way for another
millisecond or so nobody cares okay but
that's not not all about algorithms are
that way there's some of them were you
need consistent data so for example in
Linux kernel our CEO is used to mediate
the translation from a system 5
semaphore ID to the internal internal
data structure well it's a foul it's
really bad to let somebody do something
to a semaphore that got deleted a moment
ago okay you can't allow that and so we
have to apply out some additional
synchronization we have a lock on the
screen Colonel data structure selfie
market say I'm deleted you release
Locker it comes in he finds it because
he got there a little fast he says all
I've been deleted okay I pretend I
didn't find it and that works pretty
well there if you have a lot of updates
and unique assistant data there are
places for example where this is used in
Linux kernel for example the translation
from pathname to I node structure is
example that however if you update
mostly unique this is data you probably
should be using something else okay
there are a couple special cases we come
across where it actually does work well
but usually if you're down there
updating a lot and using this isn't date
a lot you something else so of course
that means that's a challenge and we try
to do it anyway which is where this
presentation is that ok so what we do
for read-only traversal to update
location is we use our see you to keep
the stuff nail down so we're in recycler
kill section that means that if we find
getting it a reference and by reference
I just mean we get a pointer to it we
don't haven't done anything smart
pointers or anything like that no
reference counts don't anything we just
have a pointer to it that thing cannot
disappear it cannot be deallocated until
we exit the read site critical section
that means we can just reverse down a
tree we enter the recycle it achill
session we traverse down the tree and
once we get to where we want to go maybe
where we're inserting or the thing we're
looked up or other thing we deleted then
and only then we acquire locks all right
now we may have to do some checks and
we'll talk about that a little bit we
may try to delete
something was just something else just
deleted we have to detect that and retry
much as you would for something like
sequence locking in this case okay but
what if we get there and the checks pass
then we release the locks we go and
we're done there's quite a bit more on
this it's the idea has been around for a
long time maybe back to nineteen eighty
it's not Wrigley Neil idea using it
organized away and actually using in
production is somewhat more new but well
my kids are all out of college now when
Jack and I started doing this they
weren't in in kindergarten yet so it's
been around for a while as well in our
use okay I'm going to go quickly through
the solution this Glock problem and we
start off with the tree here and the big
thing here is that because RSU is
specialized what that means is we use
other synchronization primitives in
combination with it we don't try to go
it alone and so we have different
domains in the data structure that are
doing different things so we've RCU
protecting the upper part we're
reversing it and that's really important
because if we actually did something
about stop knows we take in a really
horrible contention and we have to avoid
that even if it wasn't a rule for the
issaquah solution we still want to avoid
it because it's expensive so when we get
to the bottom though at that point we
need the consistency so we rely on
locking now locking is only going to
protect a point update and we need
something that deals with this atomic
move from one tree to another and we're
not going to have a lock spanning both
trees at least not if we want to scale
or perform well either so we're going to
use existence structures to mediate that
and will show that in a moment I'm not
going to go through this in detail these
are just the four cases you run into
when you go down without locking and try
to update something and it's broken one
of the things might have been deleted or
something not even stuck between them
and you have to you could there you
could be used in very complicated
recovery mechanisms what I currently do
is just start the thing over okay and
then as it just drop locks and retry you
could if you retry too many times
actually acquire locks all the way down
there's a bunch of
stuff you could do and I haven't had to
do that yet so what's an existence
structure well we're adding another
level of indirection this is the common
computer science approach to the world
and initially in fact in 2014 I was
actually adding three levels of
indirection just to you know keep things
going and the trick here and I'm going
to just show kind of I'm just going to
step through this without explaining it
but the idea is that you can flip one
value this is yellow existence which and
change the existence or not of the
structure now you could have any number
of structures tying into this thing and
what this allows you to do is kind of
synchronized on/off switch on any number
of structures that are making up another
structure all right we'll go through an
example showing showing that in a real
tree in a moment but three levels of
indirection was too much for Dmitri view
Cobb and he says come on I can't get
your act together do it this way this of
course takes us outside of the c++
standard you're not allowed tag pointers
but it's really convenient a lot of
people do it so I'm doing it to the idea
is that because the switch is big enough
to be aligned that gives you some bits
on the bottom so instead of having this
extra three levels a thing you just use
the bottom fits the pointer and they
match this integer or they don't if they
match the integer this other thing out
there exists otherwise it doesn't okay
so it's a fairly simple computation if
the pointer is null then it exists
because it's not changing at all and
will represent this structure like that
with a little just a little rectangle
with the red and blue parts of it just
because otherwise the diagram get too
full we showed the example on the tree
but the same thing applies what happens
is that by doing a store into that
distance which okay it starts out 0
which means a exists and B doesn't we
store a 1 into it and bang suddenly a
doesn't exist in B does exist at the
same time so with a single store we can
make any number of data structures pop
into and out of existence at our at our
control okay
so let's apply this to the 2014 problem
which is our tree and this is our
initial state we want to as one atomic
thing move for over to the left-hand
tree and move one over to the right-hand
tree so we want for it no matter what a
reader does going through here it can't
see anything that would show those being
non-atomic in other words for example it
can't see one in this tree and then see
one of the one on the right hand tree
and then c1 a left hand tree it can't
see four in the left hand tree and then
go around see one in that same left hand
tree because that would mean it was a
non atomic update it can't see anything
that indicates that both over one tree
at the same time or that there was a
time when there's nobody there so the
first thing we do is we get new
existence structure we allocate some new
a new four and a new one and you can use
in direction if you want to make a
common data structure or you can do
copying take your poison and we start
off with Ellen one existing and I look
forward to seeing the dark green ones
and the thing is that we had to make a
change here but the change didn't really
change anything it just made the
computation more expensive so before we
added this elint one the left-hand tree
existed and you could tell because
there's a null pointer there after this
now what one still exists and the way
you tell is there's a pointer and it
goes off you check the bits and they
match that says that zero in the bottom
bit this thing has there on the bottom
bit life is good and the st. and Owens
four and one that are coming in there's
no big deal nobody can see them so we
can make this transformation on
atomically and not affect the readers
aside from making their computation a
bit more expect making their life more
difficult I guess ok the next thing we
do is we actually add the new four and
one to the tree we can again do this non
atomically beforehand they didn't exist
because you couldn't find them
afterwards they don't exist because you
look at the bottom of their pointer it's
a one and it's a zero still the blue
part is the one that's the current state
all right so beforehand you went and and
that brown node you saw a null pointer
nobody's there afterwards you go there
for here but it's
where'd bottom disz pointer doesn't
match therefore it doesn't exist pretend
it wasn't there so we can make this
change again as slow as you want we are
just inconvenience Lee readers making
them a little slower we aren't changing
their answer the next thing we do does
change things we store a one into that
assistive structure when we do that
suddenly the existence of the fours and
ones exchange so the old for the one
that used to exist don't anymore
suddenly and the new foreign one that
didn't exist now suddenly do and the
readers coming in because that's a
single location if they see it in one
state and then they see in the new state
by all the memory models we have and by
the the fact that you do a relaxed load
you have to get coherence if you relax
load of a variable and then later on to
a black same variable you're required to
see them in order and therefore we get
we get this atomicity yeah unfortunately
it isn't quite that simple you have to
do a acquire a load of the pointer
itself but you know life's hard
sometimes once we've done this people
really don't see that one on the left or
the four on the right I mean they go
through some work to see they don't see
it but it's not there and so we can non
atomically remove them from the list and
once we've done that we can clean up so
that's the basic sort of a thing we're
doing and this is you may recognize this
as kind of one of the components that
some transactional memory
implementations use it's in some ways
kind of similar so we have existence
pointers if it's null it's there
otherwise you check the bit and the
thing it points to and you better have a
good API I'm not going to go through the
API and detail it's here if you want to
look at it but other if I didn't have an
API I know I would have a really hard
time having something equal know being
it existed all right so you have to put
it behind something so this is kind of
an overview of what it looks like you've
got some kind of data structure header
you guys this is head you got a user
pointer if you if you if you need to
have stable pointers to the things while
they're moving around obviously you
could take this green thing and have two
copies of it once in each structure if
that if the long-lived rougher
to it well as moving around different
data structures is not required and if
it's small okay so that's kind of what
it looks like this is pseudo code for
the move and basic goes to what we're
gonna do there this is the old stuff so
I go through this in detail and it
doesn't like me right now well that was
exciting let's try this again okay
member where I put it it was this would
be much easier there we go
there we go okay and it's just if I want
to recover it yeah I kind of like to
thank you let's try this again okay well
it looks promising let's see if it'll
put up with me going through this
quickly I've got a stress test a little
bit let's see if it does it this time
too you know okay we're so far so good
so far so good I do have a PDF you see
if worse comes to worst okay all right
and I'm not going through that detail
what I'm going to do is go through the
performance results we had last year we
got to 80 on 60 CPUs and we got to an
LCA we got to about 90 and you may
wonder why you're getting 90 on 60 it's
because of the cash effects this is
super linear scale up beat up because
more cpus they have the smaller piece of
instructions are looking at and the less
cash they is ok if you that was read
only if you add a small amount of
updates things get a little bit worse
only 40 X on 60 CPUs it's at least beats
of the arnaz 10x he wanted this morning
I heard and if you're only doing updates
this is on eight CPUs things were really
horrible back into 2014 they're a little
bitter CPP con not much better at LCA
however one nice thing about the LCA
results is that if you add more cpus you
still got better up to about thirty two
CPUs what happens is 32 CPUs is that
this is an Intel machine that has
hyperthreading and it's one of the older
ones that has thread 0 it through 0
through 31 and then thread two on the
same course from 32 to 63 and this thing
is able to use more than half of a core
so you get nice slope and 10 then you
don't get quite as much out of the rest
accor's still room for improvement but
that's not this still beats yarn is 10x
you know not bad maybe kind of okay not
great but all right
but as I said at the beginning this
requires me modify my algorithms it's
not a big modification you have these
little thingies and you know you go
through your tree thing you traverse it
you say does this thing exists in a few
places and then you have to have a way
of backing back out to start over if it
doesn't but still it's different and and
I didn't want to maintain two different
ones because i was lazy which men i did
a much more work to avoid the laziness
so the goal is to be able to take just
an RC yew tree like a ballad rhythm or
just an RC hash table algorithm
unchanged all it knows how to do is
insert delete look up that's it it
doesn't know anything about this atomic
stuff and make it so that it can support
atomic moves among a bunch of different
data structures in fact we want to make
it so if you have a skip list in the
hash table you're gonna tonnelle move
stuff from the Skip list of the hash
table in back all right why mess around
you know I guess you could already the
whole thing's messing around but okay
fine gotta have some fun right so this
is kind of what we're doing here so we
have in this we're going to start off
with rotating elements through hash
tables so we're going to take first off
we have element 1 and hash table 1
element 2 and hash table 2 element 3 and
hash tables through two and we're too
kind of rotate them so when we get done
element 2 is gonna be a hash table 1 l
but three is in the hash table to an
element one is going to hash table 3
we're do that atomically it's going to
happen all at once as far as the readers
are concerned a reader going through
there's nothing he could do to ever see
a time when there were elements when
there wasn't when each hash table didn't
have one of the elements or other or
anytime when a hash table clearly had
both of them all right so no matter what
it does there's only three elements and
each hash table any given time only has
one of them okay what we start off with
we're going to make these existence
things and we march some as incoming and
outgoing and these are hooked up to
these I ran out of space i'm sorry i
don't have a little diamonds but you
think of each one of these things i'm a
little diamond hanging off of it and
point at the right thing of it and we
have the existence structure down here
says 0 that means the things that are
outgoing which have a zero on the bottom
of their pointer exists now the incoming
ones which are tagged with one of the
bond the pointer don't that's why
they're red so if you look if you look
up in hash table 1 you'll find out what
one you won't find element 3 because
its marked as not being there with that
red incoming guy however as soon as we
store a 12 that yellow existence
structure everything changes all at once
and we have atomically rotated those
elements through those three hash tables
and then once we've done that we can
just clean things up and we end up with
something looking like that and what
happens is that on the incoming things
we store null into the pointer and if
it's a null pointer it doesn't point to
any existence stretch at all that means
it unconditionally exists so these
things become white permanent things the
outgoing things we pull out and free
them up because nobody's looking at men
anyway and life is good we've rotated
the data is fairly similar the trick we
do here is that we put we put an element
the H this hehd a thing is H tlm that is
a hash table element alright and all the
RCU hash table thing knows is about is
that thing it doesn't know or care about
the rest of this stuff and so we just
hand this to a normal hash table
algorithm and it hashes it and throws
the right place we tell it move it
everything's fine and on top of that
will it we lay our code that uses the
rest of these guys for example this
existence head structure which is going
to point to any when they say assistant
flip the guys we use those to implement
the atomic moves on top of the structure
that is just an unchanged normal RCU
algorithm and then once we do that this
looks a little bit ugly because I wrote
it therefore it looks like see okay
sorry you know it's encrypted to you
guys you convert C++ and I wouldn't
understand it either the but the general
but still is pretty straightforward what
we're doing is we're allocating the
existence thing that's a big yellow
thing the top allocation is a big yellow
thing of bottle Cruz diagram we make
sure we got one we initialize this so
it's there we do an RC read lock we
allocate the new exists of structures
for the place we're going to and then we
set the ones that are going away to
outgoing we get out of we don't need our
see you anymore we do existence flip
which to essentially just does that
store and we do call RCU to fremont
existence flip
this stuff maintains lists of the things
that are coming or going and so
existence flip flips the value and then
cleans things up either freeing up the
stuff that's going away or storing
zeroes into the appropriate places of
stuff that's staying so it does a
tracking for you a little bit of it
anyway so that's all you need to do a
three-way rotation thrash tables you
allocate the thing you go through and
you make the new existence structures
you set the old ones to being outgoing
you flip the switch and the outgoing was
no longer exists suddenly in the
incoming ones are there and then that
frees up old it also frees up the extra
stuff and then we call RCU to get rid of
the of these structure itself and this
is kind of this is kind of a cheat
because I very carefully reverse into
the hash function make sure I had
absolutely no contention and therefore
the outgoings can't fail all right
they're always there normally you'd have
to have a check there and do an
exception or something to get out if if
you can flicked it with something else
if you just if you didn't have some
other way of organizing it and again the
big thing about this is you can have an
artery protected hash function that
knows nothing about atomic move and on
top of it yet atomic moves and the next
question is well how well this
performance scale well for readers is
great but as I mentioned the beginning I
kind of had to start over from on both
reliability and scalability from ground
zero as of a few months ago and so it's
not so good would be a polite way to put
it on the other hand this is down here
this is I'm using our seen a problem
where I've said many times as stupid to
use our see you okay but you know
sometimes you gotta do something stupid
yeah and the other thing is nice about
this is an opportunity to prove the
infrastructure if you've used something
and a break she fix it you may make it
work better for things that aren't
abusing it so it's not necessarily a bad
thing to do my usual traditional quote
for writing perfect scale loading for us
is like committing the perfect crime
there 50 things if I go wrong and pure
genius you might build for sea and
forced all 25 of them as you see that
list is not 25 long so there's some work
left to go well I did over the last week
or so get some more stuff and it's a
little bit more filled out one of the
problems I'm having is that this thing
just kills memory alligators I mean
these things just were not meant to
handle a producer consumer relationship
or you jamming elements down one side
just allocating out the other none of
the alligators and lat well at all I
cheated and made a special purpose
allocator the switch the lock was Q the
thing is is that i know the thread that
is freeing things up i know the threats
Alec image pass the stuff back stupid
that it works so that that helped a
little bit and that made it so I
actually got positive scale of illegal
you'll notice that I'm getting nowhere
near the order of magnitude that yard I
would like to see okay again I had to
start over from ground zero I am doing
better than it was last June so I've got
a little bit of improvement out of it
but I mean we're at two on this side and
we got seven cpu you want to be 14 over
here or not at six and a half okay I
mean pretty straightforward plus i'm
only using seven threads so you you
really want to be using at least a few
tens to even show you're serious these
days he last hash tables I'm not skip
list right well this is the same diagram
we had before substance SL down up on
the top I mean it's exactly the same
situation and you know we do exactly the
same thing and they rotate around and
life's wonderful and you know here
instead of having a hash table we have a
skip list structure and skip list
pointer to the head but and then the
code looks rather similar yeah you do
pretty much the same thing which
probably means there's an opportunity
for attraction here somewhere although
I'm being included if you're mature
abstraction through illegal but that
maybe that's just me anyway and again
this skip list is just an RP sorry super
take a skip list it knows nothing of
atomic moves or anything like that it's
just it's just there and this wrappers
all that stuff on top of it
unfortunately it's scalable really
horrible
what's happening here is the hash table
I very carefully avoided any contention
and the Skip list like I could make it
the boy the contention but I just let it
randomly choose stuff and so we do have
contention and therefore we have the
line there and skip list is kind of like
a randomly generated tree and what I'm
doing is I'm having different threads
deal with different sub trees and the
way the Skip list is laid out there they
will share some locks unless you are
very carefully step your skip list which
I wasn't in this case okay all right
well you know there's a bunch of things
you could do to make that better I could
tune the skip lists I could I'm doing
huge amounts of memory allocation I
could patch that up in various ways
there's a bunch of stuff I could do but
first off let's just try you know one
thing you try is doing more elements
right I'm taking three elements rotating
through and I'm paying a certain price
just for the fact I'm rotating so why
not rotate more elements and so you can
do that what you do instead of so just
rotating three elements rotate three
pairs of elements ok so you rotate
through triple I can't make a diagram of
that and have it looked at all
reasonable so I'm not going to try but
it's just the thing is the top instead
of atomically moving three elements
round and round through these hash
tables skip lists we have pairs of
elements there were triples of pairs of
elements are rotating around around or
moorim which is making a bigger problem
essentially and this can be done I did
it but the end you'd expect the
performance graph you'd expect to go up
and then kind of level off right as you
as you do more and more of them you
amortize away the overheads of just
doing an atomic move and eventually get
to wear just the memory allocation is
hurting you and that's sort of what
happens but it looks like that I haven't
had a chance to look at this my guess is
that I'm getting an extra cash line
every fourth element or something like
that it's possible i'm also popping out
of a page of your fourth element it does
out like eight more memory than it
should in some sense and so and if you
count you see three one two three up
four down one two three up four down
Sosa does that all the way across
nevertheless we are getting better
efficiency out of it it is going up
although
we're coming short on set on this is on
seven threads and we're still not met
quite making 25 million operations per
second 25 million rotations rotations
sets per second notice i rotate to
account twice right and that's a little
disappointing but if you think about it
an even bigger mystery than those
jaggies on the performance is why would
you do it this way I mean if I do three
rotations I end up in the same place I
started so why bother allocating d
allocating the memory okay I mean you
know why bother we're gonna allocate
we're in a free and we go through grace
period and every one of these things why
because we're just coming back where we
started why not instead the thing is a
state variable I mean it's just a
variable and we got a sick sport machine
you got three bits on the bottom the
pointer all right so you're not limited
to there or not you could have states
all right and we've got three states in
fact except that and then what i call
this is a kaleidoscopic data structures
kind of like you turn the kaleidoscope
you different picture right okay and
that's the effect you have you just have
these things each pointers tagged with
which state it is and then you can have
the variable has take long takes on one
of those numbers and you just match up
or you don't and you change the number
you get a different set of things going
coming or going you can go further of
course you have multiple existence
things wearing the same time and update
them separately or you could use shifts
and masks and have a 64-bit number and
then you know each pointer has a tag
with it saying we're in that thing it
pulls its value from or you can even
have a mat you do a bunch of things I
mean you go crazy I decided not to i
just use the bottom bits and match them
exactly what they integer because that's
all I needed now I'm only showing to
what I'm doing is I'm rotating from a
skip list to a hash table so I mean I
could have two of each or but it did
seem it is seem fair to have two one one
or the other so I just have one of each
and what we're gonna do is we're make
that element 1 and 2 swap into the hash
table into the Skip list atomically same
rules as before if you if we before we
do the switch if you look
if somebody doing a look up exactly new
switch sees element 2 in the hash table
it better not see element 1 in the Skip
list or excuse me a better CL and one of
the Skip list I'm getting the pact let
me try that again that was uh yeah okay
let's do this again okay so if it looks
up in the hash table sees element to
there that means the switch has already
happened therefore if it looks up in the
Skip list it better see element 1 okay
if it sees any evidence that the switch
has happened anything it looks at after
that had better see that switch is
having happened and the way we can do
that we have our kaleidoscope structure
it just has a number this case we only
need to need to two elements that's fine
and we have a state 0 thing which used
to be outgoing we have a state one thing
which used to be in coming and we can
have a state two and A three and a four
and a five and a six and seven we could
do more than that if we wanted to go
back to having three levels in the
direction but why bother now it's
initially 0 which means state 0 is the
thing that exists and state one doesn't
so currently we don't have element 1 in
the Skip list because that state 1 which
doesn't exist because the current state
is 0 but we store a 1 in there and
suddenly they flip places and now the
hash table contains element 2 and the
Skip list contains a little one and we
could flip it again and we could flip it
again and go back and forth now and the
loop to do this is kind of
straightforward right you just
essentially just while you're while
you're supposed to keep running the
benchmark you set your state to the
current number of rotations percent to
when you increment Oh rotations and you
can c % 3 or percent for if you had more
of them whichever it was and you'd hope
you'd get prettiest kale ability to that
because all you're doing is doing a
restore release over and over again and
thankfully we we do in this case we're
get we're doing linear scalability up to
32 and it tails off after that because
we're getting more than half of a core
just with one thread but we're getting a
factor of 32 which nicely exceeds yarn
is
man for a factor of 10 so on the other
hand this is you know this is great this
this is the kind of scalable you like to
see but we're talking about something
pretty specific I mean you have to know
what you want the data structure to do
through time and you're you're just
changing it through a couple of states
so a big lesson out of this is be wary
of benchmarks because this is a
legitimate solution to that problem it's
just very fast and very restricted
nevertheless it's something that could
potentially useful in some situation and
it's possible that it may be that it may
be something where we can use this with
some other things to make some nice
stuff happening advantage this
advantages you still this is not
something you just wave a wand you do
have to make some change your program
you have to you know put some things in
data structures I'm sure if I knew C++ I
would just do a template and suddenly
bang it be there are inherit from this
the other thing and I started doing that
a little bit with the arceus stuff and
it's been interesting education and
maybe I'll get to their hair or maybe
somebody also beat me to it which is
fine right now this is works for linked
structures and not much of anything else
there might be some way of making it
work without link but one
straightforward thing is to take your
stuff that isn't linked and put it on
the other side of a link which of course
get you an extra level one direction and
an extra cash miss and further down the
road of the cs always takes the computer
science always takes if you have to
explore some memory management you could
use as the garbage collected language i
expect but right now we're talking about
mary manage things if you wanted to take
the same key and flip it back and forth
same key different value you would have
to have a structure that could tolerate
duplicate keys all right mine don't
right now but you could do that if you
wanted we can have rear revocable
operations or you can do whatever you
want while you're doing this stuff in it
it's fine go on to some I oh great when
do some networking operations okay
whatever you can exploit locking
hierarchies to make it so that you can
coordinate your updates if you have
overlapping atomic updates I haven't
messed with that yet but it's something
that it should not be a difficult thing
the fact that we can get semi decent
form scalability we create great form
scalability if we we benchmark the
problem to death but what else is doing
and there's a lot more automation and
the fact we can use the RCU elegance
unchanged makes things a little bit
easier and this thing is a really mean
allocate memory allocator RCU test case
I'll tell you I mean you can find all
sorts of any sorts of bugs and all sorts
of performance problems and scalability
problems and those things really well
with this tub what would you use this
I've had a couple people say they
thought they might have something but I
haven't heard of anybody actually using
us for real all right this started as a
challenge well since it wasn't intended
to be healing real it's just a ball you
do this okay sure and I've got kind of
interesting and that kind of got carried
away with it what can I say you know um
this is my guess best guess is where it
might be usable or might be something
you do many small updates to a big
complex thing I could imagine that my
desk is something with graphs maybe but
I haven't got to that point yet besides
if you haven't done it yet you know I
say it has to be that um it should be
read mostly you know fairly complex
updates there's a lot of overhead there
I've been about doing only updates with
it is probably an abuse but if you don't
abuse you want to you want to abuse it
before your users reviews it I mean
they're going to eventually if you abuse
it first you have a chance to fix some
of your own bugs it's kind of a good
self defense technique and the other
thing is if you need compatibility with
Hardware old hardware it works fine and
also one side benefit is that you don't
have to have software fallbacks I mean
the software is the fall back its own
fall back you know you don't have to try
this in hardware and if it succeeded
great otherwise do something a software
production readiness I've know a lot of
people and burned by research code and
if you don't want to burn don't use it
yet this is kind of my scale of but the
thing is you see you know if you've got
when I started working my way through
college I had to users right and if I
kept those two years happy
didn't matter what bugs I had elsewhere
was that was fine later on in the 90s I
had like six thousand installations and
that seemed really impressive at the
time I was impressed with myself and my
employer with all that but you know if
you only got six thousand salacious
murphy's actually kind of a nice guy you
know everything that can happen will
eventually maybe in geologic time and
you know you get away the full source of
stuff and just won't ever happen right
now with Lance Colonel RCU I'm us well
above a billion instances there's once
most people like 1.4 billion Android
smartphones alone right and when you got
the few billion users Murphy can be real
jerk I mean everything can't have will
and it can have a really really fast all
right well this stuff is not ready for
that kind of environment give you that
rent tell you that right now the old
stuff that required things I got up to
kind of the prototype stage this thing
in June was probably at like limping I
think I got it to benchmark special at
this point so if you really want to use
in production i would suggest a
validation effort and let me know you
know i might be willing to help with if
you tell me about it thing is that the 1
billion is actually kind of not much
because Internet of Things is coming
along and we're gonna get two trillion
pretty fast and I don't know how to do
that okay i can i can actually make a
test plan for linux kernel RSU that Lou
a billion users and I can do that in
about 18 hours of test time on a large
machine all right I've learned a lot of
dirty tricks over the last 25 years all
right but a trillions like through his
pet banging more than that and I don't
know how to do that with testing
fortunately there are some people
getting interested in formal
verification and I've heard rumors
there's three different groups that
claim to have formally verified some
part of linux kernel are see you now I
take that with a grain of salt because
they haven't reported ate bugs I know
there's bugs in there and they didn't
find them all right so but still it's
actually it's actually something that's
kind of encouraging these things might
actually after they've been telling your
decades that stuff's great you should
use it and you're going do anything for
me they may actually be getting to a
point where it's actually useful in real
life
anyway these are some antecedents of it
some things that done before standing on
the shoulders of giants and all that and
onto the summary here we can't actually
do complex updates we can do it to
unmodified RC you protected structures
all we need is to building to add remove
and free the elements in the structure
the structure itself doesn't need to
know anything about the atomicity or the
complex updates and you can use any
synchronization method negatives you
want these things and you can use any
member allocator you want although
better she's a pretty good one because
it really Amber's of every alligator
hard you can automate the back out
processing and back when I was here last
time you had to do that by hand and that
was a real pain getting it right so it's
kind of nice having automated just bills
list of the things and used to clean up
and needs to fix up hi update rate is a
really good diagnostic tool and the read
mostly mostly work codes consider to
continue to work well and I think that's
mostly where people will be at there's a
lot more read mostly stuff that used to
be and the same applies the
kaleidoscopic updates and so it looks
like there's a lot of operation invasion
although I feel better about if I
actually had some people using it so but
you know canon everything right these
are for the people that might want to
dig deeper and that's sponsored by OB
and legal and again as always you seen
this many times some of you if you
remember only one thing from this
presentation use the right tool for the
job you know if you if my stuff's right
till great use it I'm proud of it but
you know my stuff is not the right tool
use something else anyway we got a few
minutes left for questions that people
have any yeah
sure let me see if I do this a lot
crashing my display thing here okay so
look like this for example so for what
he's asking is you know how's this how
the readers really protected I mean
you've got all these updaters doing
stuff why are the readers protected so
as a couple things one is that when the
readers are going through and looking up
the state they're using an acquirer load
okay and what that means is if what you
could have if you didn't have an acquire
load is that both readers could go down
that side now the compiler could split
them up let me let me try to say that
again let me try let me start over if
you didn't have an acquire load the
compiler could say ho we got two things
to have nothing to do with each other
I'll just enter leave them I'll generate
the code for them step by step in
between and you know who knows what
happens in what order right and you
could in fact when you thought sling up
the hash table first it could look up
the Skip list first because you don't
have any thing telling it not to so you
have to have an acquire read when it
pulls out the indicator the thing that
points to this kaleidoscope structure so
that means the reads are going to pull
them out in order all right so what
happens a bad thing would be is if a
reader came through and looked up in
will go to the next state here to see
this the reader go through into the Skip
list and it could look of element 1 and
find it all right it was really bad if
it then went to the hash table looked up
LMK one and found it afterwards that
would not be atomic but that can't
happen because the two reads from the
state variable are acquires therefore
though we ordered the choir is not
allowed to move them the CPU is not
allowed to move them okay so that means
that it looked up the Skip list first
and then the hash table it and then it
went down here it has to see the early
value in the late value can't
go backwards because as a relaxed load
is not on to the same variable plus the
reads are forced in order and so it
can't see the amount of orders result so
the the fact that relaxed loads are
required to to the same variable are
required to do atomicity and the fact
that we're doing acquires to get the
address to load to load should do it and
if we want it to be more careful which i
think you would you would if we ever get
it fixed use them every or consume to go
through the through the pointer as it is
right now i use volatile as we do in the
legs colonel because never consume is
broken although i think i'm getting
closer so it's a good question did that
did that help it's okay other questions
yeah yes well see the okay so the
question was i'm using these bits in the
lower bits of the pointers how do you
know how can i use the standard
algorithms which don't expect those and
have it work a good question well the
trick is that the Skip list is up there
I just look it up there's no bits in
anything until it gets to the element
and it hands he back this thing here I
get an element and then I and then the
next levels is okay great that elements
inside this thing so get me the full
structure there's a pointer pick it up
okay and that's the thing that has the
bits in it so the thing that has bits on
the pointer isn't exposed to the Skip
list of hash table it's a it's a it's a
wrapper around it in C++ terms you'd
probably take so you have an element in
the Skip list you have an element at
hash table you would inherit this other
structure from those so you have a skip
list and then you have the pointer as in
the not in the base class but in the
what do you derive class derived class
that's so yeah
see i'll let you talk linnaeus
Horrible's into taking C++ into the
kernel anyway the so what happens then
is that is that if you think of it that
way the RC particular algorithm is the
base class and the point of the bits is
in the derived class it's just that the
it's just that the algorithm for the the
base class doesn't ever look at the
stuff that's in the derived class
because I mean I can't because it's the
base class now we look okay the way I do
it and see is I have a field that's the
thing that the Skip list expects and I
have some other fields after the Skip
list is only in a mess with this
structure here there are no bits on the
bottles of pointers Harry I went past it
let's see if I can okay so this thing
the s the struct skip list is thing the
Skip list our looks at it's just
standard normal pointers no bits that's
right the this thing is just a pointer
the header the Skip list so i can find
it and then the bits are in this
existence head guy okay and so the Skip
list doesn't have to know about that but
yeah it's a I should have made that
distinction clear to begin with okay I
think we're out of time thank you very
much for your time and attention it's
been firing this up rueful on my right
hope you got fun with us as well</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>