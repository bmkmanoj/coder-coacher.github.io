<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2016: &quot;WG21-SG14 – Making C++ better for games, embedded and financial developers&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2016: &quot;WG21-SG14 – Making C++ better for games, embedded and financial developers&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2016: &quot;WG21-SG14 – Making C++ better for games, embedded and financial developers&quot;</b></h2><h5 class="post__date">2016-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dMupATOJKWc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone my name is Skye
Davidson I'm gonna be talking to you
about SG 14 also talking today will be
Sean Middleditch and Michael Wong
they'll be presenting the second and
third parts of the talk McGill Amato
also helped us with this presentation so
here's our summary the talks divided
into four parts the first part is a
brief reminder about what SG 14 actually
is as some of the problems that typical
contributors face in their programming
lives I'll then move on to what's
happening at the moment and discuss some
papers that are in flight and this is
the meat of the presentation Sean will
be taking over here as well SG 14 is
actually having a meeting on Wednesday
so we'll advise you of the agenda at the
moment most of our contributors are from
the games industry but we are reaching
out further into other domains we'll
discuss some of these and finally of
course there'll be the call to action
really I suppose the purpose of this
talk is to get more people to get
involved with our study group but also
with with any study group with the whole
of the standardization process I'll be
signposting all the talks as we go on as
well Sean animal Michael if you want to
get your phone out and consider your
schedule on shed dot org and now is the
time to do that and now is the time to
fiddle with your device this is the only
time to fiddle with your device please
make sure your phones are on silent and
be aware of where the emergency exits
are so the great was created in response
to a question asked at CPP Con 2014 of
all of the podium and that's where the
games company representatives we have
particular needs low latency real-time
operation but don't we all really don't
we want to write performant code that
runs like a train that's super fast
super efficient but we have special
needs particularly in console games
programming performance and efficiency
for games is really it's really
important I work for a games company so
do the majority of our contributors and
I'm going to focus on that two main
particularly but it is quite
transferable indeed the interests of all
of these areas so the financial side of
WG 21 SG 14 we'll get used to that name
Kyle cook meal hall doc Thomas Rogers
Nevin leavers all have a financial
interest and when I say financial
interest I don't mean they're investing
money I mean they're qualified if only
if only we had people giving us money
there was a talk it's three stack from
the financial stuff which is a financial
software conference for high-frequency
traders as well as algorithm designers
and low latency infrastructure so we had
an SG 14 meeting at the major financial
centers additional notables of course
absorb the embedded programming study
group was led by Daniel guts and we've
taken that on so there's no duplication
EA STL is an important library this was
open sourced thank you I am Rob Rob
Pollan this is open sourced recently and
form as many like the library forms many
classes that we could consider for use
in games see that paper by Michael Wong
I believe now this is the organisation
at the moment is everyone familiar with
this chart get familiar with this chart
it's really handy from the ISO cpp dot
org website this gives you the
organization now I'm interested in all
of these study groups actually one in
six have some crossover with us so
that's the concurrency group and the
numerix group the concurrency everyone's
interesting concurrency there's no end
to it
and numerix is actually surprisingly
important as I'll be discussing a
particular numerix paper as we go on so
how we do business there's a reflector a
Google Group that work that we send all
our post to that we discuss in common
it's a really good group if only because
the signal-to-noise ratio is very very
high there's about 10 posters a day we
don't go shouting at each other
there's no Hitler references not about
it's a really very valuable a great
example of good communication amongst
experts there are several papers in
flight this is what we will discuss and
we put together there's a github
repository which is not as busy as it
used to be but that's where we'll stage
a lot of the papers and a lot of the
consideration we have monthly telecoms
telecom teleconferences they have a good
attendance as usually over a dozen
people's sometimes we have had over 20
people so we have to be quite
disciplined about you know taking our
tone speaking and getting things
together but we're good at that we're
all professionals it's chaired by our
convener Michael wall will be speaking
to this later this man is a powerhouse
but I'm not gonna embarrass him right
now but we're really very lucky to have
him running the show for us he has
interests in many relevant areas
particularly parallelism concurrency now
I was going to show you this trailer but
that would require YouTube and streaming
and things like that's what decided
against it does anyone here actually
play games yes brilliant that makes it
so much easier fabulous so that was
about 2/3 of the hands went up now
particularly I work on the Total War
franchise and the Warhammer title in
that franchise when we had Scott Myers
in recently for some training a couple
of years ago and as soon as he came
through the door we started the
conversation I said by the way Scott we
do things a little differently here and
he said everyone says that but it's
actually true for us we do do things a
little bit differently if you've played
one of our games or if you've seen any
kind of simulation of game simulation
you'll have seen 20,000 figures marching
using different animations across a
terrain fighting each other throwing
things you're seeing horses or flying
creatures or all sorts of things
but we do this at 30 Hertz it's going
through a television screen quite often
we'll be at 60 Hertz that which is very
painful but particularly we have an
awful lot to do in 33 milliseconds we've
got to do all of the activity and all of
the rendering so let's do the mass on a
3 gigahertz processor you have a hundred
million cycles per frame with 20,000
soldiers for example that's 5,000 cycles
per soldier they have to choose what to
do and have the animates had to animate
the soldier as a result of that choice
and then you've got to worry about cache
coherency it's it's really important to
get things done speedily there are some
tricks you can do which is you can run
the world at 10 Hertz not 30 Hertz and
then just interpolate the animation and
that gives us 15 thousand cycles per
soldier instead of 5 thousand you can
demand to use 2 cause of the user and
share out some of the work but of course
we've got to render the advert as well
so we end up putting that on a
particular core fortunately we have a
GPU to help us at telling you it what to
do is it's very CPU intensive let alone
the actual doing of it so although it's
great we've got heterogeneous computing
it's actually got to prime the thing in
the first place and it's not a trivial
or a trivial job at all you have to work
out what you have to draw from the
camera position and what resources you
need to push onto this graphics card
onto the GPU and we have two different
styles of programming for two different
types of microprocessor I say
microprocessors it nano processor now
they're really really tiny
this parts are getting just smaller and
smaller all the time and I haven't even
mentioned sound actually making the
thing you know be heard and there that's
not it there's a variety of specs that
we have to worry about do we have 64 gig
of ram or three gigabytes of ram have we
got a 400 pounds graphic card or an
integrated laptop part but not great for
games it has to be said optimization is
front and center we have to keep the
caches full you have to keep the cause
busy and this is not much different from
the regular advise but we can't throw
more cause of the problem our software
needs to run on a broad set of hardware
which is specified by the public
or it's a single piece of hardware which
is specified by the console manufacturer
but we don't get a say in what the final
hardware is going to be it's what our
customers say it's going to be we have
one fortunate situation which is that
the architectures are all very very
similar nowadays since the ps4 and the
Xbox one came out everyone's working on
x86 64 processors they're actually
custom AMD parts in the consoles or an
Nvidia or an ATI or an Intel graphics
part the whole thing is quite different
from a windowed application which wakes
on messages and then processes those
messages and then waits for another
message and it takes as long as it takes
to process a message and if it's too
long for you then you upgrade your
hardware and you get faster processor in
there that's just not a luxury we have I
just have to keep reinforcing this we're
stuck with what our target market says
we're stuck with HD 14 also does cater
for embedded programmers similar
situations with consoles finite amount
of RAM limited tools you know it's a
similar experience
now I divided the areas of concern into
six chunks so we have fixed point
numbers containers graphics concurrency
executors RCU you find out what that's
for and hazard pointers heterogeneous
computing Michael was gonna be talking
about that vectorization and parallelism
and miscellaneous I'm sorry
miscellaneous is a very weak words to
use but it does reflect the diversity of
approaches that we have in the study
group that we bring into the domain so
before we go on does anyone here
remember what was significant about the
Intel 4 8 6 DX processor coprocessor yes
particularly sorry there may well have
been I don't know
but particularly it was the first
processor to come with a massive Procol
process with the mask oppressors are
actually on the chip beforehand you had
to have another coat presser so you can
rely on it being there and it was the
first Intel processor to ship with a
floating
floating-point coprocessor is standard
but why are we talking about fixed point
numbers unless you've got a background
in mathematics or experience with older
cpu to probably take non integer
arithmetic for granted which is not
necessarily a bad thing who's heard of I
Triple E 754 all right plenty of you I
guess I should have expected that right
so plenty you've heard of I Triple E 754
this is the standard for non integer
arithmetic it celebrated its 30th
birthday last year thirty thirty years
old
and standards are meant to be invisible
that's you know that's the point of them
they simply state the way that things
are and we quietly you know a happy
they're there but ignore them not all
standards like that this one is and
we've got fruitfully three papers in
flight related to fixed point arithmetic
take the numbers down and let's look at
why we need them so the standard uses
two formats offered by I Triple E 754
and it adds a third which is not
standard by only theta 2 in binary 64
corresponds to float and double long
double is typically an 80 bit type and
great it's a great mature piece of work
the the standard has been optimized to
hell and back in in in silicon for many
years now it's comparable speed to
integer arithmetic it's sometimes
sometimes is even faster
occasionally slower division obviously
is quite complicated but there are two
problems with floating-point uneven
point distribution that's kind of the
biggest problem we're we're we're
concerned so consider the representation
of a float as operations are carried out
it grows and reduces the exponent can
get bigger and smaller the faction will
change obviously all the time but the
fact that the exponent grows and reduces
implies that the what we have is a
dynamic radix point the point where we
actually say here's the integer part
here's the fraction part and this is why
it's called a floating point but this
can represent a vast chunk of the
rational number line
but it's at the cost of precision it
looks a little bit like this you'll get
lots of good numbers lots of precision
around zero when the precision will tail
off around the ends around the edges you
actually have five decimal orders of
magnitude so 10 kilometers can resolve
reasonably to about one meter one part
in 10,000 this is a problem for example
in our battle games everything has a
position a joint in a skeleton for
example it's one joint there's another
joint there's another job they're rather
less than a metre apart you could move
to double precision but that would mean
doubling the size of your data which is
absolutely not an appetizing thought as
I said for constrained very much on the
amount of RAM we have on a large
battlefield you've got fists landing on
faces you've got blades missing by
centimetres do you need a narrow escape
kind of staff and you might decide that
you could just not fight the edges and
restrict combats to the center of the
battlefield where the precision is nice
and high because that's the only place
that higher precision is required is
where the combat is you actually can't
do that your designers all look at you
as if you've grown another head they'll
say no straightaway so we're stuck one
solution is to decide that rather than
have an uneven distribution of positions
over a huge range you have a fixed
resolution over a smaller range that's
the motivation behind fixed point
arithmetic so John McFarlane who used to
work for Creative Assembly where I work
at the moment and Lawrence Krauss
they're working on this
sg6 that's the numerix group there's
also looking at this work it's a more
appropriate group obviously numeric C
but st 14 is user focused rather than
feature focused so there's a potential
for a lot of crossover and we're
cooperating with sg1 concurrency as well
in the same kind of way the fixed point
types are actually a library extension
they consist of class and function
templates two of which are appended to
the type traits header and the remains
are live in a new header file called
fixed points let's take a look
so fixed-point numbers of
specializations of this template so we
have a first parameter which describes
the capacity and the sinus of the
underlying type which represents the
value which defaults to integer and the
second parameter is equivalent to the
exponent and it shifts the stored value
by the requisite number of bits
necessary to produce the desired range
the default for this is also a source is
zero we also got two helper types the
helper types offer a more intuitive
description I think you'll agree by
using the cardinal number of integer and
fractional digits and we have an
unsigned version as well and this would
probably be the most widely seen way of
representing of distinguishing fixed
point types so here's an example PI
favorite pi is a 32-bit signed fixed
point number so we have two Institute's
represent three and we have which leaves
us with 29 fractional digits so fixed
point numbers can be explicitly
converted to and from arithmetic types
significant digits I'm not lost but
rounding errors will be made so this
equates to true it's an acceptable
rounding error you've said it's
acceptable because you've chosen four
and for for your integer and fractional
parts so operator overloading is
provided they perform as little runtime
computation as practical possible and
with the exception of shifting
comparison operations binary operators
can take you know any combination of one
or two fixed point arguments and zero or
one arguments of any arithmetic type so
for example when non-identical you know
when you've got one fixed point type and
one other type then we have to apply
promotion like rules to determine the
return type so when both augments a
fixed point then the fixed type the
result type is the size of the larger
type at sign if either input is signed
and has the maximum integer bits that
the two inputs if one argument is a
floating point type then the result type
is the smallest floating point type
of equal or greater size than the inputs
and if one argument is an integral type
then the result type is the other fixed
point type so for example we are adding
two different types of two different fix
point types so that gives us the five
for the number of integer bits and three
for the number of fractional bits if we
add an integer to you fixed it stains
there's a you fix five three if we got a
float the type is converted to a float
now overflow and under they are in flux
I should point out John McFarlane is
actually right here in front of me which
makes this a very hard presentation to
to make oh I see oh thanks for coming
John right
hello and underflow need to be taken
into consideration right consider this
the result is 16 but this can't be
represented with for instability we have
an overflow the result depends on how
the representation type handles overflow
for built-in sign types the result is
undefined
for unsigned types the value wraps
around and that's overflow we're used to
it from normal integer maths but
underflow requires a little bit more
getting your head around so look at this
the result is seven and a half at 7.50
sighs seven can be represented with six
bits nor point five can be represented
with one bit so we have an accurate
result but in the next one we're only
using seven integer bits and no
fractional bits we have underflow we
have an inaccurate result we suffer a
loss of precision but that's generally
considered acceptable when all bits are
lost due to underflow underflow that's
the value asset has been flushed and
like overflow the result of a flush
depends on the underlying representation
and in the case of building integral
types the value will become zero
dealing with errors resulting from
overflow and flush biggest headaches in
the domain I think integers are easier
to deal with they've got my fractional
bits it's easy but floating point values
are shielded from the problem by that
variable exponent it's because the
exponent gets larger and smaller it
absorbs all these kinds of errors and
the paper presents four strategies we
should leave it to the user promote the
result just the exponent and then this
preserves the most significant digits at
the cost of least significant digits for
arithmetic operators choice one most
closely follows built-in behavior it
causes the least surprises and it
requires less computation where as three
and four represent different trade-offs
neither of which is the best fit in all
situations particularly this construct
may fail so choice is three and four
promoting the results and adjusting the
exponent upwards they're named functions
so that you know exactly what is you're
doing and making that choice so the
function template promote returns the
same value represented by a larger fixed
point specialization to this promoting
make fixed 5 2 after doubling the size
will give you make fixed of 11 4 we've
gone from 8 8-bits to 16-bits and
there's a complimentary function demote
which reverses the process so finally
we've got some named arithmetic
functions we've got some unary functions
these kinds of names binary functions
with these plans of names and the paper
goes into considerable more detail which
I'm sure John will be talking about
later this afternoon we had some
feedback from GDC but it looks like it's
going to go into the language I'm quite
pleased about this an additional
solution of course might be to bypass SI
units entirely the problem we have here
is you're working with meters and we
need to get down to small resolution one
thing you could do is decide right I'm
gonna work in millimeters 32 bits and
millimeters will give you millimeter
resolution from Yemen to Greenland so if
your map is taking place over a big
chunk of the world it's probably quite
sufficient
right there's one more paper numeric
width this is paper p03 8:1 it contains
a proposal to address manipulating the
width of numeric types defines these
three symbols so it sells an interesting
problem problem the user must insure the
capacity meets demand so we're taking to
say stupid integers we're multiplying
them together so that means we need to
return or accommodate 64 bits what
happens if you've templated that
function
what's your result type going to be oh
it's stuck so we actually have this
beast but our result type is now derived
from the understanding of the operand
type right let's move on to containers
that's fixed point numbers so this area
probably causes the most heated
discussion within our particular
community containers Oh people bitch
about containers all the time there are
three papers in flight and there's one
waiting to launch those rings
there's flat containers there's
extending memory memory management tools
actually it does relate to containers
and then there's the colony and stack oh
by the way job your talks today it's two
o'clock John McCallum two o'clock more
information on fixed point right the
ring paper so this is proposed last year
it's been through a couple of meetings
it's acquired suggestions for
modification to quite a co-author it's
been quite busy let me take you back to
the 80s 80s what remember about he
remembers the 80s good
lovely airbrushes athena posters
programming they said eighty by rodney
sacks I read that in the 80s great text
everyone should read it I first wrote C
in the mid 80s I'd learnt basic said
eighty sixty eighty thousand thought of
trying of the language didn't quite
realize what I was getting myself into
frankly but Here I am now it felt like
assembly but with better names for
things it was like a macro assembly
language now I took great pride in
getting buffers to bow to my command
particularly what happened was using DMA
transfer using direct direct memory
transfer or fill up a buffer and then
start processing at one end and then
once I kind of got most
the way through i'd start filling the
buffer up at the other end things would
go round and round and have two
processes working at once I'd feel her
God we've all done it we've all felt
we've all had that moment of supreme
potency thinking yes I have two things
going on at once
this is concurrency quick phone beyond
brilliant I'm glad it's not just me but
I came across this concept time and time
again over the next 30 years
filling something up processing it and
then filling it up whilst I'm processing
it but everyone had their own name for
it usually two words the first word was
something like ring or cyclic fixed or
rolling and the second word was buffer
or cue or five foes so I'd have a cyclic
FIFO or a fixed FIFO or a rolling buffer
or a ring cue or something like that
people are very vocal about identifiers
it's very hard to label things anyone
heard of Parkinson's Law triviality so
Parkinson's in 1957 yeah I'd be the
organisation's give disproportionate
weights to trivial issues it's also
known as bike shedding yes you've heard
of bike shedding the bike should affect
all the bicycles shed example and when I
first heard of it being used as a verb I
was a little worried about late what lay
ahead because I first heard about it on
the reflector I thought well blimey
shattering about names as it turns out
it's all been quite so far now the ring
buffer is a useful container for SG 14
it crops up everywhere
the usual uses are for asynchronous
processing of messages or for keeping a
buffer of the last any events and it
differs from stood queue that's an
adapter of list or deck but it's not
necessarily contiguous it's in progress
I'm hoping whoever didn't pursue plus
plus 20 there's anyone submitted a paper
to the standards body in here okay great
excellent so my story so I started work
after a CCU 2015 which was named limbs I
was about
spring and I thought it was finished
after about three months of tinkering
and some review from friends and
colleagues after all it's not a tricky
concept how hard can it be really I
posted it to the reflector for
consideration then I first presented it
at cpp con this time last year got some
feedback spruced it up might have one
presented this at Kona in Hawaii in 2015
it got a bit of a lukewarm reception
there was a very matter-of-fact note
taking which was a good thing frankly my
implementation of pop was unpopular and
it was decided not worth putting in the
standard maybe if it was a circular
range very good well he didn't know in
the memory well if you supported
iteration maybe if I had presented her
you know a specification rather than a
header synopsis it was a longer list of
things that I was expecting but I was
contacted by someone who had come up
with an alternate implementation after
my presentation at cpp con Arthur ed wah
all right okay good job
this version was based on a buffer
constructor of address and length so it
was in fact a spam but it solved many of
the concerns of the committee so we
combined our efforts to spruce it up
polishes it again it went to
Jacksonville Mike rips into Jacksonville
and there was more feedback
everyone was much happier very positive
review then it went to GDC Arthur
presents it at GDC this is the game
developer conference that we have every
spring the game community has every
spring we had good feedback but still
not really quite what people wanted I
said well you know we want something
that has this multi producer or multi
consumer on I now have a multi producer
multi consumer ring I'll be presenting
it on Wednesday at our face-to-face
meeting that we have that that we have
scheduled I'm hoping to finish it before
recycler
we shall see I do encourage you to
participate though it's great putting a
paper together working out you know all
the nooks and crannies getting the
positive feedback and the negative
feedback but the polite feedback that's
the thing we sent it will be very polite
and very good at doing this sort of
thing it's been an illuminating process
I'm gonna have to show naff the rest of
the containers running back all right
so we're going to talk a little bit
about some of the other papers and
containers and we've been working on
here so yeah we have I'm Sean Sean mill
ditch I work at wargaming Seattle so not
too far from here I'm a lead engineer
primarily on the server and wargaming
Seattle
I'm also co-chair of SG 14 so I've been
kind of pretty heavily involved in some
of the organizational stuff going on
there
and it's it's been a lot of fun working
with you guys in the wrist the games
committee or games community you know
iterating on C++ and standard so the the
first paper that actually I've put out
for C++ has actually been the flat
containers proposal so flat containers
there I'm so sorry
Sarah way to get the notes bigger all
right so fly containers are an
associative container that unlike the
standard map is not a node-based
container it is a single contiguous
chunk of memory much like a vector so
the idea here is that it's a bit more
cash friendly in order to iterate
through or find elements and containers
of a certain size these are pretty
common in certain certain industries
particularly games flat containers going
to be pretty common I've seen very few
game engines actually that don't
have their own version of a flat
container it's pretty common in certain
kinds of managing game objects or
certain kinds of managing various bits
of physics or AI it's used all over the
place
they're pretty common in other fields as
well boost has had a flat map flat set
the multi map multi set for sometime
interest in this container has actually
been pretty high from a large part of
the C++ community we put out the idea of
putting it in there getting the standard
and we got a pretty large unanimous
interest in getting this container in so
what are the benefits of a flat map is
that it is an ordered container so we
get a lot of speed from an onward
container if you have a large number of
elements a hash container is probably
gonna be the flat map flatmap is still a
binary search it's gonna be O log n
versus a 1 however sometimes you
actually do need an ordered container
particular for using algorithms like set
difference at Union things like this
they don't work with an unordered
container the the algorithms just don't
don't even really make sense in some of
those contexts so a flat map can also be
very useful if you need in order to
iteration but you don't want to pay the
cost of allocations or the cash on
friendliness of a node-based container
so there there is a little bit of open
discussion still going on about whether
or not we want the flat container to
actually be stored in ordered memory or
to be stored in a more level ordered
format and the difference here mostly
comes down to iteration speed versus the
insert and erase speed so if you have an
inorder container then iterating through
it in order is just a simple iteration
incrementing pointers incrementing
offsets into the container some are
iterating through the elements of the
vector
however the find operations insert
operations as the container grows the
binary search is jumping around through
memory a little bit more so you tend to
lose a little bit of your cache
friendliness in this in this case you
can instead restructure the flat
container to be a little bit more
friendly to the binary search so that it
is
to be jumping from the first the first
element to the second element to the
fourth element and kind of build more
clustered in the beginning of the cash
the downside here is now iteration
you're jumping around a little bit more
so there's some open discussion about
what is the ideal use case for a flat
container what sizes are we optimizing
for yeah we're still working through
some some some optimization measurements
but it looks like we're probably leaning
towards keeping things in order
it just it's the use case for flat map
if you need a large number of elements
you're probably using a flat map anyway
and so search speed searching over a
large number of elements isn't really
going to be a bottleneck so now we're
gonna talk a little bit about the
uninitialized memory algorithms this
paper has actually been accepted for c++
seventeen so it has been worked on by
Brittany Friedman it's pretty here oh
there she is so the idea of the
initialized memory algorithms is that if
you're writing a custom container which
is pretty common in some of the high
performance areas game is particularly
we have a lot of custom containers so
for example you're sort of a flat map
most games have had to write their own
flat map game sort of write their own
ring buffers lots of different
specialized containers to specialize use
cases writing some these containers can
be a little bit difficult because
there's there has not been so far the
library support for some of the
internals of how containers are
implemented the allocate memory for a
container you now need to initialize all
that memory these standard algorithms in
the library are all based upon
manipulating existing ranges of valid
objects rather than creating new ranges
of that objects so for example the
initial uninitialized memory of items
add the operations unrelated
uninitialized copy analyze copy n which
is to copy a range of objects into some
one initialized memory to be useful for
example if you were writing a container
like a flat map and you were given a
range of iterators of elements that were
already sorted you need to get them into
the memory you just allocated for the
flat map now you'd have a nice simple
well tested and correct
library facility to help you write these
right these sorts of containers so
there's also algorithms like fill to
take a single value fill it in to urinal
shows memory we've got the buffer work
which can help certain containers when
doing manipulations raw storage iterator
which is a nice way to write further
abstractions that operate on
uninitialized memory while we're running
your own algorithms and yeah it has been
approved for C++ 17 it is in the working
draft of the standard unless the
Committee does makes a really weird
decision it's gonna be in C++ 17 so
that's actually one of our first big
successes in terms of us 314 so we
should all think Brittany for seeing
this through and and you know really
helping to improve the standard for
everyone yeah so there's a few other
weird cases when it comes to initialize
memory algorithms and how some B's work
destroy and the under sized
move-move-move in a lot of this has to
do with dealing with oh well too far so
a lot of the problems with these kinds
of memory algorithms actually comes down
to our good friend exceptions if you
have an exception that throws well in
the middle of a copy or move or when
trying to initialize a set of memory you
you will have partially initialized
memory you know for example you're
trying to copy ten elements you copy
five and exception is thrown you know
have five elements filled into five
elements that initialize it's not
obvious how far you got into this
initialization dealing with some of
these tricky parts is really hard and a
lot of even very experienced C++
developers myself included a lot of
cases have not gotten this right to the
past so getting these things into the
standard really helps with making sure
that the tricky cases with moving
constructing destructing in ranges with
types that might throw is done right and
it's done in a predictable way that's
not going to cause surprises or bugs
down the
it's just it's it's really useful to
have these implemented in the correct
way
another important chemo on this is that
these are not so much new things almost
every standard library you've used or
every standard law reviews I've access
actually implemented these algorithms
this standard library implementers
working on vector or or you know some
other containers that are in this
layered library they need these same
utilities if you look through standard
library implementations you will find
that there are copies of these
algorithms implemented just usually in a
private hidden fashion so this just kind
of takes standard practice for library
rotations and exposes it to you to C++
user selects you can write your own
containers yes this is a lot of what
over here alright so Ptolemy and stack
is another set of very interesting new
containers that are being proposed so a
common use case we run into in games
particularly and many other domains as
well is we need a very large number of
objects to be initialized managed and
maintained we do not necessarily care
about the order of these objects we
don't care how they're sorted we don't
care about looking them up very often we
just need to have them have some data
initialize ready to go we're going to
iterate over them perhaps every now and
again we're going to add and remove them
putting we don't care where they're
added remove too we do however need
stable references to these objects you
need to be able to grab a pointer to it
to know that if we insert another object
it's not gonna invalidate all the other
pointers we have there's a lot of
different ways that excuse me a lot of
other ways that these sorts of
containers have been implement in the
past they're a common one is to put or
to use a vector to know that you're only
going to insert at the end of the vector
and if you remove from the vector that
you're then going to use a swap and pop
sort of algorithm and then use reference
or a terriffic sees me indices into the
vectors in order to access the objects
at a stable position or a stable known
location these themselves can render
problems if you're using indices you
have to carry references to put the
vector and the index and I you've got
these kind of like fat references to the
object different reference because
otherwise when you when the vector grows
and resizes all of your pointers would
become invalidated
so colony is an attempt in or a very
successful version of trying to make
sure that we have a container that
allows us to push pop remove insert
objects that are in a known stable
location while being efficient for this
purpose the the allocations are meant to
be efficient iteration through the
container is meant to be efficient while
giving us these stable stable locations
I believe we have a talk coming up on
this yes there is yep so we're gonna
talk about this if you were more
interested in the specifics of how this
the algorithm works
certainly I can't speak to it with great
a great expertise with math you will be
will be going over that's 315 so another
another actual study group is the 2d
graphics study group that has been
pushed by a number of people in the
committee so this is the idea of having
a way of drawing to the screen with 2d
2d primitives now certainly this isn't
the kind of graphics output that is
going to be sufficient for example with
a large 3d game the Total War series is
not going to be drawing things with a 2d
output any time soon they're using
high-end custom 3d rendering primitives
or api's so this kind of library doesn't
seem immediately appropriate to some of
the stuff that we've been talking about
so far that we've talked about in
previous talks rush g14 however an
important thing to keep in mind is that
a very large percentage of games
actually are 2d you know we get a lot of
mobile games even a lot of desktop games
social games you know these games are
primarily 2d and having a good well
supported weld
community endorsed way in the language
of America nice is certainly important
to the game industry obviously well a
number of other industries yeah so it's
yeah this has its own study group
working on the graphics I believe it's
renamed to the i/o group now so they're
working on both the output and
eventually the input side of this as
well so yeah it's got a lot of the basic
primitives you would expect out of 2d
rendering if you've done 2d rendering in
the past it's it's made to really solve
an actual problem and kind of be a
complete solution in terms of the 2d
drawing needs that a lot of us have so
it is very much working towards solving
real problems now that said there are
some potential problems with the current
proposal in there that some of us in the
games industry a little worried about so
one of the problems with the current
proposals is that it is a stateful based
graphics API so the stateful API is the
idea of you tell the API I want to use
the red color now and then later on
you'll tell ok draw this shape and it
will remember the fact that you told it
to draw red soon a girl's the shape they
draw the red shape which seems very easy
it's actually the way a lot of libraries
have been built in the past including
the html5 canvas library tomorrow a
collection however this has some
problems both in terms of API design and
performance so if you look at for
example Vulcan versus OpenGL Vulcan is
the new standard by Chronos that is a
low-level direct faster more concurrency
friendly graphics API whereas OpenGL is
the well-known venerable very stateful
graphics API it's existed since 1991 if
I recall so looking at some of these
some of the differences in performance
between bulk and opengl we find that the
stateful nature of OpenGL has actually
been a problem it requires a lot more
driver code to be
you can't communicate to the hardware as
well because the hardware itself is in
fact stateless it takes small programs
small small bits of fully encapsulated
state and executes them it doesn't have
it doesn't the hardware doesn't remember
that you set the color to red the harder
it gets a command it says draw this
triangle and it's gonna be right
essentially so when you have a stateful
API that is layered over this hardware
you have to write a lot more code in
order to to work around these
limitations you also can run into
certain problems in terms of
composability if you say I want to set
the color to red and then I wanted to
have this helper library I use it's
gonna go off and maybe calculate a shape
for me what if that helper library
accidentally or not accidentally but
intentionally even sets to go to green
for some internal test code or something
it has in there and then you don't know
that was set to green so now you go to
draw your shape that the helper library
generated and it comes out green instead
of red this is a pane seen up having to
then use a state stack if say I take my
state where it's gonna be red save that
state do this work restore the state
it's just more performance problems and
more room for errors and bugs and it's
just a pain it's not it's not composable
so with a stateful library we lose speed
and we lose composability whereas with a
stateless library where you say draw
this shape and it should be red when I
draw it you end up ending very
composable interface it's faster there
are existing implementations of
libraries like this pretty much all the
users of libraries that were spayed
stateful have switched to a stateless
type library for example replacing Cairo
with Mozilla seizure library and then
there's also some future work needs to
be done on the input side of things
there's a lot of different ways I mean
they can this can be done certainly
modeling off industry practice like
boost or QT is an approach I do not
believe that the big group working on
this has quite yet made a significant
proposal in terms of i/o but they are
working towards it come along and I'll
hand this off to Michael
okay thanks
thanks everybody I always learned so
much whenever I listen to these two guys
even because I'm not actually in the
game of the industry I'm actually in the
in the business of the heterogeneous
devices and programming them things like
neural networks machine visions and
self-driving cars so I I can't believe
it's not that I'm learning from these
guys so one of the things that I wanted
to point out does this work okay great
so that some of you guys asked you what
it means to go to what a Wednesday's
meeting I put together a bit of an
agenda as well on - in terms of the
times and some of the proposal that are
going to be reviewed in details we're
gonna be talking about fixed points
we're gonna talk about ring span we're
gonna talk about hazard pointers I'll
see you so these are most things so this
is an official XG 14 meeting meaning
that we're going to be it's going to be
pretty Drive you're not interesting
located your faces looking at code
giving comments back but it turns out a
lot of you guys actually want to do
these things so I'm pretty happy okay
so for the rest of this I want to just
talk quickly about where we are you guys
already kinda know to be honest II know
we are at C++ 17 review the committee
draft three or four things make all four
things made it the special map the file
system the library fundamental one and
parallelism one okay
all the other things are still in flight
because they would just not be mature
enough for us though I want to talk a
little bit about so SC 14 it cares about
the little things like initialize we
care about the big things like ring
spans flat map but we also have the big
picture in mind thinking about you know
what it means to reduce you know enhance
C++ 4head oh gee you know for Hedrick to
support energy use devices what it means
to to support it for concurrency for
further forms of concurrency so that's
why we cross
with a lot of other whatever laughs a
lot of other people so this one slide
kind of gives you an idea of some of the
things that's been accepted the red is
the only thing that was accepted for 70
the blue stuff are what's inflamed right
now okay and some of that definitely
crosses over to the interest of the
games community the financial trading
community as well as the embedded
community
okay now executives there is a talk
coming up Tuesday by my colleague a co
play Gordon Brown as well as me on what
exactly on what executives will look
like okay because we've been holding a
constant every two week meeting with all
the awesome is executives right now
there were three or four proposals has
been deadlock about three years but I'm
happy to let you know that we do have
something that looks kind of like this
diagram that is a minimal executive
design that bifurcates out what it means
to be have an execution resource what it
means to have execution platforms what
it means to be an executor okay if
you're interested come to that talk and
I'll give you a little more information
about that the reason I'm interested in
that is because that's important for
heterogeneous computing we need to know
the how the executives interface between
the diverse control structures that we
have at the bottom like a sink like for
each colu teams like beaver and how it
would access the various different
resources like a bunch of threads about
you GPUs some OpenMP runtime for
instance or consider runtimes whatever
that you might be used one englander
okay you definitely don't want to end to
any relationship between every one of
these bad boys contract to all of those
different resources and that's the kind
of direction we would have been heading
if we don't have something in between
executives is kind of like the marriage
between algorithms and containers that
we have in terms of iterators okay I'm
going over the fast because I want to
talk a little bit about concurrency
toolkit that's also come up coming up
there's a talk coming up between with my
colleagues maggot Michael who is
absolutely the worldwide expert on
concurrency he invented hazard hunters
as well as my other colleague from my
former workplace an idea Tom McKenney
who's going to talk about the interface
we're going to show what the interface
now looks like a C++ interface for
concur for has a point
and I'll see you okay Hauser corner is
going to have various operations for
allocating for acquiring our ownerships
for setting the setting or reading or
clearing the value the most important
it's it's also about how to reclaim
about reclaiming the resource so I don't
want to close go through too much
because I am running out of time so come
to that talk I think it's on Fridays
okay and we're trying to bear Perry
together with this idea this supports
hid this concept of a Schrodinger Zoo
where there's a bunch of okay
yeah year is that there's but it has
it's a construct and in memory database
for the animals ensuring the zoo and we
call the goods and results in the deaths
as a deletion and what happens is there
would be queries that would be available
at least would be concurrent now it
turns out that does that there's a lot
of query about the lifetime the cat
probably mostly from the mice so if you
want to hear more about that particular
story we're going to talk about her on
Friday and how you can do all these
things concurrently okay and this is a
picture of Heisenberg's uncertainty
principle where yep storing this you can
you can see these half there and half
alive at the same time other things
Specter Cindy this is going to be in
parrot this is most likely gonna be in
parallelism to okay and part of the
things we've had we don't have any
standard but we've been reached
reinventing this over and over again
we've had boost Cindy but right now we
have two proposals going on
unfortunately both the name is kind of
kind of like Matthias one is the P is
going on and get it once menti is
correct it makes a little bit confusing
but they managed to come together so
that at the end we kind of usually when
these things happen we we do it what's a
shotgun marriage this is like a little
bit of herself in the West I guess so
but the the interface is coming to very
nicely you've heard this to them now
it's called beta Paul okay gives you the
number and the size okay and I'm get I'm
being indicated I'm gonna
needless on the slide so you can see
what it looks like okay couple of other
things that I want to go over final
things I want to go over things like
hello genius computing we've been
talking about that I've been looking at
four very big on the based sickle is one
of the programming model for
heterogeneous computing that's strictly
for C++ I've also been it's now just
recently released as a community edition
I've been looking at LSU's Stellos HDX
for distributed computing a very nice
way of doing asynchronous computing very
thorough very well well supported and
videos Agency for bulk dispatch these
are all very very good okay I'm sorry
alright so other things like a like
asynchronous and distributed parallelism
API in a GPX that I've already mentioned
that as well as heterogeneous computing
compiler from HSA okay these are the
next big frontiers that we want to talk
about and part of that will be covered
on on Tuesday's talk on heterogeneous
computing this is about massive parallel
dispatch we talked about the fact that
c++ in order to be efficient this is the
age we're coming to we want to keep it
moving in that direction okay
I think I'm gonna close with one more I
think I'm getting close to the end I
want to close with one thing we spend a
lot of this summer connecting with the
financial people the games gamers kicked
us off for this patoot particular group
but but there's also interests on the
financial trading group and they've been
and over the summer these are the kind
of things that they've asked us to look
that look at things like massive
parallel dispatch on heterogeneous
devices things like CPU cache memory
affinity as well as high bandwidth
memory yes we're looking at trying to
make c++ support things like that this
is one of the in fact this is one of the
number one things that the the the
high-frequency traders as well as some
financial people are looking at
composable memory allocation
something that I think Andre talked
about in couple of keynotes and before
as well as exception handling light
we're not joking away from big things
Patrese has been leading some of that
effort and we've been talking about way
and giving you something not to remove
exception handling but give you
something that gives you a lightweight
exception handling if you didn't know
it's already sneaking in the c++ 17
because the parallel algorithm right now
when it has an exception it actually
terminates and does not unwind so it's
already is sneaking into c++ alright
other things that the financial people
interested in i'll comment some of the
things and we're gonna be how about
intrusive containers on wednesday during
the SG fourteen review is there's work
on on a hot set that's been that's going
on right now okay and i've already
talked about how executor is is heading
up that that same direction i think with
that i want to close with asking you
guys about joining the group and what we
plan to do we plan to continue the
direction we're heading with pushing
proposals through some of it will make
it in through various different
iterations through various TSS we're
gonna try to make a big push toward for
embedded computing and that group joined
us and we're speaking to and one of our
mandate is certainly to cover things
like constrained resources in a
real-time environment as well as how to
do high performance in a low latency
environment so that's certainly
something that we're going to be looking
at and with that I'm hoping that you
guys join us and participate in the
group many of you guys do one of the
reason we get so many people is because
doing these talks we're talking about
what you've done not so much this what
we've done so thank you very much for
coming questions
yeah absolutely
the presentation will well this part the
all presentations I believe will be
available so yeah
other questions over there right so
unlike unlike joining the C++ standard
requires you to company and countries to
send you as she 14 like all SGS are free
to join now it's easy to join in 14 just
google iso cpp space as she 14 and
you'll find a mailing list you listen to
it it's really open this is actually
normal for all as geez you're almost
anyone is allowed to join even if you're
not a regular standard committee member
because that's the point is that we want
to solicit everybody's feedbacks okay
other questions over here yeah why do
they have weird exceptions they have
they originally was going to have these
things for exception lists which would
have created an exception list of
exception list if there's a complicated
nested parallel parallel situation we
could we realize that that was a mistake
yes we make mistakes all the time and we
pulled it out in the last moment at the
last at the last day in the chat in the
in the in the loo in the in the Finland
meeting and replace it with a simple
system where you just terminate and
don't unwind with the with the promise
that we might replace it with a slightly
more advanced system like maybe
exception through reduction operations
okay in future now doing it this way
means that we can still we can add on
top of it but once we have mandated the
more complicated system it would be very
difficult to reduce it back down okay
back there if you show
so the question I believe is is is the
compile time exception handling
mechanism still being discussed okay
I think it it is but I don't think I
don't have much to say about it it is at
this point unfortunately okay other
questions okay well thank you very much
everybody</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>