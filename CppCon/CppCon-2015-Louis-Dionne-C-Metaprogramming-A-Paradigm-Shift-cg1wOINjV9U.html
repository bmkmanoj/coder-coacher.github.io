<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2015: Louis Dionne “C++ Metaprogramming: A Paradigm Shift&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2015: Louis Dionne “C++ Metaprogramming: A Paradigm Shift&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2015: Louis Dionne “C++ Metaprogramming: A Paradigm Shift&quot;</b></h2><h5 class="post__date">2015-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cg1wOINjV9U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Louie teon I'm a math student
and a computer programing enthusiast
I also freelance from time to time but
mostly I do open source libraries and
today we'll be talking about meta
programming actually I will introduce
what I claim to be a new paradigm for
metaprogramming a new paradigm that
makes everything much easier and much
more expressive due to C++ 14 so first
up I would like to introduce the
different types of computations that we
can do in C++ just to set you know like
that just so you can see basically we're
where we are going to deliver this brand
this presentation like in which part of
C++ we're gonna dive so first there are
n time computations the ones that you
usually use at work ones that we all
know the first ones that we that we
learn about so in that world we have run
time sequences right likes to the
vectors to the lists to do whatever
these sequences the they are homogeneous
in the sense that they can only old
objects that all have the same type so
you can have a still vector containing
ends we can have is the vector
containing strings but you cannot have a
vector it's the directory that contains
both ends and strings right unlike in
some dynamically typed languages then we
have ran time functions which are just
normal C++ functions the operator at
runtime and then we have runtime
algorithms to manipulate these these
sequences and and some of these
algorithms can also take current time
functions like higher-order algorithm
static functions to modify sequences and
stuff like that so so far nothing new
then since C++ Alvin and well suppose
plus 14 mainly because of a generalized
context where we also have constructs
for computations right so this world is
pretty much like the runtime world in
the sense that everything is emoji news
except if you are nice enough with the
compiler if you do not do anything nasty
inside the computation
and by nasty I mean like throwing
allocating memory or stuff like that so
as long as you are nice enough with the
compiler you can ask the compiler to
evaluate data at compile time all right
that is context but basically so in that
world we have concepts for sequences we
have context for functions and we have
concepts for algorithms or we could have
sex for algorithms there are not in the
standard yet but most of the algorithms
in the center that just manually
iterators there's no reason why we
couldn't stick Const exper in front of
them and it will work just as is but so
yeah so just so in theory we also have
concepts per algorithms it's just like
not implemented in style yet and now
third quadrant now we're getting kind of
funky right
heterogeneous computation so what does
that even mean so in that world we have
a thorough genius sequences
heterogeneous sequence is simply a
sequence that can all objects with
different types say suitable is an
iteration sequence and then we have a
genus functions which is really just a
fancy way to say it's just a fancy name
for template functions really it's
nothing more than that because the
template function when you think of it
it can take objects that have different
types and depending on you know which
the type of the arguments it's going to
maybe return an object of a different
type unit so the return type type can
vary depending on the on the type of
their arguments and then we have a
thorough genus algorithms or yeah well
we we trying to do so we don't have them
in the standard right but it would make
sense that we have them just like
concepts for algorithms why not but
there is like a library that does that
but we don't have them in the standard
and of course yeah it's not that easy
unfortunately so that brings me to my
first claim which is that we actually
need algorithms to manipulate that or is
it original sequences I think we need
them
because it simplifies a lot of meta
programming tasks it make them it makes
them
you know almost as easy as writing
normal regular C++ I mean this this
transform on a two-pole is really not
surprising to anybody here right
anybody who has written Python or Ruby
like understands that out of the box
it's very very clear that we were going
to call the function object to string on
each element of the tuple it's not not
surprising that elements have different
types it just makes sense and then we
get back a tuple of strings so I think
we need them in the standard or we need
the good tool to to to algorithms and on
sequences and heterogeneous sequences
and then we have type level computations
that is the the fourth quadrant type
level computations well so in that world
we have I'm sorry type level sequences
which are basically sequences that can
hold types they can open up more than
types so there is no like value
associated to each types due to each
type in the sequence and we have type
level functions which are basically meta
functions that's all we call them right
you probably know about type threads
well pipe threads are just an example of
a type level functions and then we have
typable algorithms to manipulate these
type level sequences with type level
functions or meta functions it's a bit
clunky but it works and now let me make
this other claim which is that MPL is
actually redundant why my claim that I
will try to demonstrate during this talk
is that pure type level computations are
actually nothing but heterogeneous
computations so computations on tuples
are strictly more general strictly more
powerful than type level computations
and if we add a very good library to
manipulate origina sequences we could
also do type level computations with
this library
Oh God okay yeah how do you saw
everything so but the most important
point and I guess that is my third claim
is that C++ 14 is just like a huge game
changer it just changes everything when
it comes to metaphor dreaming mostly
because a to deduce return type generic
lambdas and generalize context pair is
also nice but only in the implementation
of the library it's not really useful as
part of the interface though
but yeah so of course this is just me
claiming stuff and I'm biased because
some of you might know I offered up made
a programming library recently so yeah
I'm competing against these other
libraries that that I'm claiming they're
less powerful so so just see for
yourself so this is all we used to check
for a member this is like the classical
female based trick or a diem or I would
say hack which allows us to check
whether a map is a type as a nested
member called exit tax
I won't even explain it because you know
either you know it or you don't
but basically this is yeah this is just
a trick of the language you're able to
to know whether a type has some member
but it's a bit convoluted like when you
see this for the first time you're like
okay now soon in C++ 17 there would be
this detection idiom using stud boy T
and we're going to be able to make it
much nicer right I think it's much nicer
involuted and and yeah it it's easier to
explain through your co-workers and it's
better but what I would really like to
see is something like this I want a
one-liner for checking whether type as a
nested member and I want it to look
natural and I won't you know the the
idiom to be such that anybody would
who's new to C++ can say oh well I
really kind of understand what this does
right and this actually works I mean
this is completely possible with suppose
plus 40
so now we're talking about you know a
one-liner for checking whether a type is
a nested member and it's as you it's
also important to see that it's it's
variable so it's it's a lambda which
makes it possible to declare it like in
a in another function you don't have to
be at a global scope or and namespace
scoped to a to declare such such
detectors so it's much more flexible
okay introspection so most of you
probably already wish you could iterate
over the members of us trucks right a
user defined type and that's always easy
to do it we can use the boost fusion
library to to like adapt a struct into
into something that looks either like a
tuple or a map a compile-time map where
the keys are types the types that
already find at the top of the slide
there they're basically types really and
then we can access these we can access
these these members the members of the
struct using the the types that are
associated to them okay now with C++ 14
we can do better we can we can use
instead of using like types that you
have to declare beforehand we can use
compile time strengths for the keys so
this is an ugly macro but basically what
this does is create a a compile time
string and so you do not have to declare
the members beforehand I mean the the
keys beforehand which is very handy when
you have 100 of them and this is the
future where we have a user-defined
literal that creates a compile time
strain you don't need to use a macro
it's super fast compile time I mean and
and it's supernatural
and this is a new extension it works it
could be in c++ 17 it the standard
comedy try decides that you know it's
worth it and it's like trivial to
implement but for now it is just a good
new extension yeah
well this remote is getting crazy I just
pressed once and then it gets all crazy
just a minute sorry about that okay
I am right there okay now how many of
you have already tried to you know
generate Jason for serializing or
something like that most of you probably
yeah okay so of course I'm not gonna
show how we used to do it because it
might have been nesting but now it's
pretty easy actually so basically you
I'm really gonna try to put this back on
I guess it's annoying yeah okay so now
you just define the user defined type
using you know this macro here that
provides some introspection capabilities
and then what we want is to be able to
very simply to very simply say to Jason
print that and it should give us that
outward good okay so first off we are
going to end all base types so whatever
can be to strength we just do it we want
to quote characters we want to quote
strings nothing new then if I receive a
heterogeneous sequence then I want to
transform that sequence just likes to
transform right no no no no more
complicated okay so just I transform
that sequence and then I call to Jason
so I gather JSON representation of each
of the members and then I joined that
with a comma and then for user-defined
types like the one I just defined using
the macro in like two slides ago I again
I transform the keys of that that user
defined type which are basically the
names of the members of the stroke and I
fetch the value of the member associated
to that key I and then I just yeah I
represent the JSON representation
that member and do the obvious thing and
it that's it
there's nothing more and it works and it
compiles okay now maybe maybe I found
some cute examples that you know we're
like wow nice nice everything works and
and actually it doesn't work so well so
I'm gonna give you a bit or so there
were messages yeah there were messages
they used to be very very very nasty
basically you you would you know just
make a little mistake and then you get a
big spew of very implementation-specific
stuff so for example here I'm calling MP
I'll reverse on the integer of course
it's not going to work because it
expects the MPL sequence and I get
something like you know clear Impala
missing blah blah blah it's very clear
to me because I know the MPL quite well
and I know that like your Impala is just
part of their type dispatching logic and
blah blah blah so I know exactly what it
is but most of you guys don't and that's
a problem whereas with static assert and
ordered you know tricks it's possible
that so if I do the same mistake I can
give you like a very good error message
and just say like wait well you know one
is not a sequence and you try to call
reverse on something that was not a
sequence so now it's pretty obvious so I
think that is out pull compile times
another thing that is quite problematic
when we do metaprogramming so this
benchmark shows the time required just
to include different meta programming
libraries I'm not doing anything it's
just like empty CPP file including these
libraries and of course you can see that
we are able to to have much lower
include times and the reason why is just
because the implementation inside of
like the implementation details of the
library are so much simpler with c++ 14
then you know the library is just
smaller we don't need to have like big
preprocessor hacks so this saves on the
pre-processing time and it's also easier
to go with fewer dependencies so we
don't have to pull in
many you know external dependencies to
do what we have to do so it's yeah it's
possible to reducing two times now this
is the compiled line performance of
calling the transform algorithm on a
tooth pulp from the hana library a MPL
vector and a fusion vector and as you
can see the Hana tuple is is slightly
better it's actually ok it's much better
than than fusion and it's slightly
better than MPL it's still most
satisfactory to me but we're working at
that and the reason why a fusion vector
stops at 50 is because you cannot create
a fusion vector with more than 50
elements it just blows up because of C++
whole treat limits okay so I think that
we must rethink meta programming I think
that c++ working is such a game changer
that it requires us to like it we just
had to rethink it from the base we'd
it's not sufficient to just you know put
it like type name dot dot somewhere and
then very early templates and then alias
templates and then casts exper here and
six four there it's not enough we need
to like rethink the way we do it from
the front of bottom of course now the
question is like how we're gonna do it
and well of course I'm here to talk so
here's my thing so most of you have
probably heard of integral constant I
hope so
basically it's it's a a wrapper for an
integral value that's known whose value
is known at compile time and we wrap it
into a type because it's it makes it
possible to manipulate it more with more
flexibility so the way we usually do
compile time arithmetic is by defining
meta functions so this plus meta
function here it takes to integral
content x x and y and it just you know
compute the integral constant whose
value is x plus is the value of x plus
the value of y simple simple not pretty
but simple in it works and then as you
can see i can just test
that indeed the integral consent in 1
plus in plus 4 is just it's okay but I
not super awesome
either because of all these type name
and common common type and stuff like
that there's a lot of syntactic noise
and it secures what we're actually
trying to do so let us just try
something for fun and that thing is well
all about defining these this plus
operator instead of defining defining it
as a medicine we could also define it as
a you know template function which
returns an integer constant okay and the
decor like a very important point here
is that like we're returning an integral
constant not an integer not like a that
the result of V Plus u really the result
of like an interior constant which
contains the result of people assume
that is really really important and then
if we did that we could eventually
create integral constant objects instead
of creating of instead of using the type
sizes just create the objects and then
and then use the operators that we all
know and love right and then since this
plus operator returns an integral
constant in something and then this
equal operator returns an integral
constant and bool something right
because it compares two integrals and
said then you can take the deckle pipe
of that it's an integral it's like the
type integral constant will true or
false and then you can fetch the nested
value in there so yeah this is an
alternate way of doing compile-time a
relay is everybody following me at this
point no questions everything is clear
as water yes
oh yes okay so the comment is that like
if you wanted to add just let me know if
I get it correctly ah the the comment is
that if you want to add like one plus
word you could just do one plus four and
then it's going to be a constant
expression the compiler would say well
I'm happy to compare one plus four
equals five at compile time yes that's
it that's a comment okay yes that's
totally correct and this is like a toy
example really because in some other in
some other context you might get these
integral constant into one if your are
constant in four they might be the
arguments to a function and then you
don't know whether they are really like
integers or or compile-time you don't
know whether they are they are
compelling or not and the only way
really to to and then the only way to do
arithmetic in that context would be to
use to use like the the plus meta
function that I showed earlier or this
or this technique like you wouldn't have
the the value of this integral constant
until you fetch the current column value
of the nested thing because that's what
you receive as an argument
am I being clear so I'm so basically
what I'm saying is that in this toy
example yes of course its equivalent in
other in order you know situations it's
just you just can't do it
yes yes so the comment is that won't
like the the key idea is that there is a
type associated with the value right so
you can do a bunch of things also like
overloading and the value of these
expressions whereas you cannot do it if
you have just one plus four okay
of course since the integral constants
also provide a context for implicit
boolean constructs for implicit
conversion to you know the nested to the
inner value that they provide then you
can just drop the the whole pickle type
column count value thing and this is so
basically again this whole expression is
an integral constant rule something
right it's an object of that type but
that can be converted to a boolean
sex / so so we can just do that and then
we can use context for variable
templates to make it a bit shorter so
we're which is going to define say an
integer an integer int underscore C is
going to be an integral constant and
with that value and then we can just use
drop you know de the lengths thing so
we're there so now we've simplified in a
weird simplify the syntax quite a bit
and then the next step is to actually
use usually define the it rolls right
and then so I define a user-defined
literal and then I parse the content of
that user-defined literal which
represents you know a number and I
create the appropriate integral constant
and what I can do is just 1 under square
c plus 4 under square C equals 500 or C
now if you go back to like a couple of
slides ago and compare this with what we
had we have a ug n of X / - BT really I
mean this is compile time arithmetic yes
okay so the question is why are you
using the chart at about a version of
the user different define literal
instead of say the unsigned long or
something like that the reason is that I
want to create an integral constant type
I need to so inside the function I need
to parse the value of the literal at
compile time
right so that but at compile time I mean
like you know I need the type that is
going to be returned by by this operator
this user-defined literal here is going
to depend on the values of the C's here
right because it's an integral constant
which whose value represents what was
you know the number in the indo-pak if I
receive the value of that number in as
an argument I do not know because we do
not have context per arguments I do not
know that this argument was context per
and the type the return type cannot
depend on that this is clear for
everyone so basically I need the value
of my literal to be encoded in the type
of my in
yeah in the type of my function so I
need to receive it as a template
parameter because the return type of
that function is going to depend on a
value of that number okay
now let's see a real world example so
we're going to compute the Euclidean
distance in a 2d plane this is a formula
this is what it looks like
normally I would have to define minus a
square root brace yourself
plus multiplies and stuff like that
equal to and then I just compute my
distance and it's a bit verbose but it
works very well now this is the way this
is how we can do it now we just have to
use normal operators because well we
defined you know arithmetic operators on
integral constant so everything just
works square root has to be implemented
using you know just normal operators to
which is much easier and the key thing
here is that I'm using auto and that
these guys are template parameters thing
is that I'm using auto here because I
cannot because like them this is going
to be an integral constant you know
something it's not going to be like an
int or float or whatever it's going to
be an integral constant so I need to use
auto and the type of this YS here is
also going to be an integral constant
and my square root has to be written
such that it can work with entry port
constants but it it's not like overly
difficult and and then I just return so
the return type of square root is going
to depend on you know the type which is
the type of this expression here and I'm
going to return an integral constant
with the proper value inside it but the
real killer thing here is that since we
only used normal arithmetic operators
this function also works with runtime
values right whereas the template that
we wrote earlier it doesn't work with
runtime values it's a template it takes
the interval constants as a template
parameters so it doesn't work with
runtime values whereas this one works
with runtime values and this is super
cool so the thing is with this new way
of seeing of doing computations
compile-time using a normal value level
C++ no you know normal C++ syntax thing
is that you might have called right now
that is read written for doing meta
computations and for normal computations
and this is the same code and you could
reuse it right but you don't know it
because because just of the way you
decided to encode your type level
computation and this is not all once you
start looking at into your constants as
objects you just you realize that you
might want to you know improve their
interface to do some funky things for
example here I define a times member
function which is going to call it takes
a function and it's just gonna call the
function n times so this allows me to do
loop unrolling so for those of you I've
already done Ruby this is pretty neat so
I just say 5 times F and it just does 5
times 5 times F at compile time
so do I mean like the loop is enrolled
at compile time which which can be nd
but this is not really like I'm
necessarily a standard internal
constants should add that I'm just
saying like this is the kind of things
that we can achieve when we think out of
the box for you know metaprogramming
doesn't have to be ugly it can be just
very useful and every time saving tuple
access so right now we use to get to get
the nth element of the tuple instead we
could define a operator bracket that
takes an integral constant and just
those you know stud get with the
integral the value of the integral
concept and so that way we could use the
bracket operator to access the members
of a tuple and which is like the nice
thing with this is that say you add a
vector but you only accessed it using
and this is our Nolan compile time well
you could swap with a tuple in it would
still work because we both defined this
time the same operator bracket operator
so as long as your indices are known at
compile time there is no reason why you
shouldn't be able to access a vector in
the tuple differently
and of course why should we stop there
still the ratio defined is a quite
ridiculous interface it if you ask me
for doing computations on compile time
ratios like stood equal a ratio equals
the ratio plus the ratio multiplies the
ratio divided stood ratio blah blah blah
I mean it would be much simpler if they
just defined the operators and it would
be more natural so this is actually
something that we could maybe study and
proposed our standardization because it
would just improve the interface price
you know such a such a lot that and it's
actually so trivial to implement to do
that it's it's really worth it into
integer sequence just the same we could
maybe add like a bracket operator to
check that and element of the integral
of the integer sequence okay now on to
type threads because I claimed that we
could also do type level transformations
and and well I need to show how to do
that right so type threads we add
functions that take types and and return
types so for example I could define a
add pointer made a function that just
adds a pointer this is equivalent to the
stood at burner in well in this channel
but now let's try to replicate basically
what we did would enter your constants
where we lifted you know the types to
values so instead of using you know
enter your constants as types we use
them as values and instead of having
meta functions to manipulate them we now
have functions the way we do it is quite
simple we just define the type threads
so we defined a dummy wrapper to all the
types okay
just like integral constant was a demi
wrapper to old an integral constant well
you know it like an integer value that's
known at compile time it was just a
wrapper to hold that and to pass this
around now we're gonna do exactly the
same with a different compile time
entity types and so I think I define a
function that takes the type returns the
type and I take a function I define a
function that takes the type and returns
like an integral constant I can do this
and then you can create an object that
represents a type just call your
function which does the type trait on it
and that's it so you have value level
syntax normal su + % x4 doing type made
of metal computations type level
computations now you can go one step
further and just define like a context
per variable template you don't actually
save any typing it's just for
consistency in this dog okay now why
should we really want to do this
well since since types are represented
as objects they are first-class citizens
which means that we can put them into
two poles okay
we can also put like create a vector
with types in it but they would need to
all represent the same type right
because you would say like stood vector
type int for example and then you would
just add like default constructed
objects in that vector so it's not
really useful you could but it's really
not useful but where this is really
useful is if you if you use it to pull
because now you can have different types
inside you tuple and yeah so then you
can just manipulate types as if they
were normal objects now the following
which can be used so before say you
wanted to to filter to filter the
elements of a type of sequence you will
need to use the tender nasty MPL lambda
expression domain-specific language to
define your predicate and now since we
are just manipulating normal C++ objects
there is absolutely no reason why we
couldn't just write a normal generic
lambda to do it so instead of writing or
predicate as a type level you know meta
function or something like a NPL lambda
expression which basically is a hidden
meta function we can just write it very
naturally using the normal C++ syntax so
what I'm doing here this example is
really like I take it I create a
sequence which contains types and then I
just feel
and I just keep the ones that are either
a pointer or a reference so this is a
new temple which contains type types
each are and types avoid butter now
again since we are using the same syntax
for type of and valuable metaprogramming
we just need a single library to do it
so whereas we needed MPL and fusion to
achieve this in well before I suppose 14
now we can we can achieve exactly the
same thing using a single library and as
you will probably observe the syntax is
pretty much the same all the time so
it's easier to learn too soon easier to
teach fewer dependencies and it just
interoperates like perfectly because
it's actually just a single library now
the fact that we have a unified syntax
means we can reuse more stuff like I
said earlier with the compile time
arithmetic example it's possible that
some functions or some code that you
wrote for normal for normal you know C++
runtime C++ actually works with compiled
by entities to and you're just not aware
of it so what I did is I took boost
proto which is very nice but also very
complicated like boost library for doing
expression templates so of course the
library is complicated because the
application is also quite complicated
and so I went into the tutorial and
found called a an example there which
basically creates a domain-specific
language a very simple domain-specific
language for creating arithmetic
expressions so this is something that
basically represents you know well the
first argument - the second argument
over the the second argument and the
nice thing is that when I evaluate this
expression and I pass it to compile time
entities it works it returns an integral
constant and I can also so it was a risk
written for our runtime computations of
course but it turns out that with like
very very little modification you can
work it can also work with compile time
entities and what I can tell you for
sure is that when Eric nibbler wrote
this library he had no idea that I would
sometime you know come and and just like
put integral constants in there and it
would work like he couldn't know it
right it wasn't it wasn't planned but it
just works because we're reusing the
same syntax this is really really nice I
was actually very surprised at this that
it I was like wow I mean didn't I didn't
think it was gonna work but I know oh
okay I think we got something else again
since we have a single syntax for type
level and value level computations we
can have more consistent code so this is
an example of creating a compile time
map with boost fusion a hit originals
maps are so basically you defined the
keys of the map here and the values of
the map here and it's not exactly
obvious to someone who has never seen
this code what it does it stirs but not
exactly intuitive and then you access
the elements of the map using you know
the type to which they are associated
the syntax is slightly clunky it works
very well but it's likely clunky and you
have to know what you're doing
whereas I think this is while this is
more verbose it's also more obvious you
would expect to create a map using you
know sequence of pairs just like we do
in the center library and then you
associate types to you know the value
you want and then you just use your
bracket operator to to get the value you
want
okay
I went quite fast so now let us let us
look at a case study so this is a switch
for a boost and the goal here is the
goal is to is to create a switch which
takes a boost ne and then depending on
the basically it's going to look at the
dynamic type of the boost ne and it's
going to dispatch the proper function
right inside the cases that I gave and
so if the boost I need turns out to be
empty I want to get to the empty class
and if any nothing matches I want to get
to the default class so first we want to
make it really simple so we're just
gonna use so we're defining we're gonna
define a case in in this here we're
defining a case to be like a pair which
associates type to a function okay and
then we define this we define this
default case here to be just to be we
just defined a dummy type which
represents the default choice and so
case case angle bracket default II is
just going to be you know like this
function here which associate default
underscore t to whatever function you're
going to pass to the lender and
similarly to for empty now here's what
the switch looks like so since I want to
have this cute little syntax here I want
to have this cute little syntax area of
calling a and then parens parens and
then BOOM my cases I'm going to have to
return a function from the switch here
this is what I'm doing here switch
returns
Olinda which takes the cases good
then first I so this lambda here takes
the cases now a pearler pack is very
nasty to manipulate if you want to do
anything non-trivial so I just put this
in a tuple and then we have all like
fancy algorithms to manipulate tuples
just as we do with studio so I'm going
to find the default case because the
default case could be anywhere so I'm
just gonna find the default case by
saying a so each see here is a is a pair
right which associates a type to a
function so I'm gonna find the first one
which type is the default type which
dummy type that I said would represent
the default case and then so I find if I
find yet the first one the default case
basically now finally if he returns a
compile-time optional it's like a stood
option or boost optional except that
whether it is empty or not is known at
compile time so then I static assert
that you know I found the default case
because otherwise you messed up right so
compile time it's gonna tell you I
you're missing something I need like you
know to be exhaustive and then I get the
other cases I just get the rest of the
cases by filtering by just keeping all
the ones that are not the default case
okay filter here is like copy F it's the
same except I really don't like Kabir
the name so and then I unpack the rest
of these cases and to this generic
lambda here and I call in poll which I'm
going to show you in a second what
unpack does is is the same thing as to
the ply which is proposed like for the I
think it's the library fundamentals TS
but basically what it does is take a
tuple and cause a function with the
elements of the tuple and the reason why
I am doing this is because I'm going to
want to process the the cases
recursively using parameter packs
because in this case is the simplest way
to do it so I'm not advocating that you
should use like two poles and algorithms
and then all the time sometimes wrap our
owner back Sarge is a simplest way to go
not all the time all the time so yeah so
here I use algorithms algorithms and no
more algorithms in there so now let's
dive into our result oh yeah and so
default arrow segond here is because
default is a compile-time
optional right so I'm just fetching the
second member of the pair which is
inside the optional and I have the right
to do it because I already static
asserted that it was it contained
something and a type area is just like
the runtime type information of the
Boustany like the element inside the
blue stain so now I'm gonna process
cases so so there are two branches in
the if let's ignore this branch here so
like like if the type ID you know of the
the case that I'm processing right now
is the type ID of the you know it
matches the runtime type of the Boustany
then I just I just do this which I'm
going to explain next and then otherwise
I just you know presses the rest
recursively very simple I'm going to
show you the base case and then we'll
come back
so the base case is when I'm empty I
just called the default case with no
arguments okay now we're going back here
okay okay good fifteen minutes so I'm
really okay so basically here I fetch
the pipe represented by the type
underscore C okay
I actually didn't show you that because
I thought we would be running out of
time but normally these these like type
objects type angry bracket objects
haven't nested Colin Colin pipe okay
which represents that pipe that's in
there that the t you know so a type t as
a nested Colin Colin type alias which
represents T so when I get when I get a
case which is a pair which associates
you know a type and liberated T to a
function object I can take the first
pair member of the pair which is a type
angry bracket T okay
and Jen then they call type this object
which gives me the the actual you know
type angle bracket T and then I fetch a
nested column column type and that gives
me the T in there
is everybody following so that's what I
do here and then so if the run time type
of the boost any matches the T inside
you know the K well basically the the
type of that case I ran this and
otherwise like I said I just do it
recursively now
now if the type here is void
it means that I got an empty any so I'm
going to return from the if not from the
function from the if I'm going to return
this lambda here and otherwise I'm going
to return this lender here and I'm going
to call whatever lambda I returned with
the case and the any the reason why I'm
doing this instead of using a normal run
time if is because if if the type T here
so if my Amy is not empty if I'm not
currently processing the empty case I
cannot call the function with no
arguments so it's going to be a compile
time error so I need to to to like to
make you know this this call here
dependent on something so that the
compiler only does you know syntactic
analysis but no like it doesn't actually
try to to call the the function until it
really needs to so the thing is that
this if ear is a takes a compile time
integral constant boolean integral are
constant and it's going to return this
one or this one and since the C inside
this function is auto the compiler
doesn't know what is the type until I
call it but I'm never going to call it
if it's not the empty dmt in is
everybody following me yes so the
comment is that it's pretty much a
static if and it is exactly a static it
actually I think I will change the name
so it's a static really but the way to
emulate you know etiquette which could
be a language feature but now to there
will be a way to emulate it with the
library is to make both branches you
know lazy by just making them lambdas
and then you return the branch and you
do whatever you want with it and then so
if it's not the default case no the
empty case then I just call and just
test the you know the boost any to the T
to you know that the type that I'm I'm
currently processing and then I I just
call my function with that type here and
that's it is everybody following awesome
yes okay so the question is or the
comment is that so this function here is
not context burst so intent is that this
can only work with runtime objects and
yes indeed it doesn't always make sense
to you know to have all computations at
that working it both at compile time and
you know can sexpert and uncle sexpert
because for example well boost any does
allocations that you know the RTT i did
they stood they type index we do not
have this compile time so yeah it only
works with with runtime objects it
wouldn't it wouldn't make any sense to
have this con cipher yep
okay so the base case we already saw so
this is about like 70 lines of code and
your co-workers could understand it
mostly and so this was actually based by
unlike a presentation that was done and
C++ now by Sebastian riddle he's a very
very very smart guy
but he didn't use a meta programming
library and his solution was it add more
features but it was still much more you
know much longer and more complicated so
it really helps to have a meta
programming library to to help you with
non trivial tasks and then when you are
you know actually doing something that
that's quite simple like processing
cases recursively just drop them into
programming it's going to be a real
pinion you know and about to try to use
it so just just do it recursively but
for the filtering for finding something
in you know in the in the types in a
sequence for doing that kind of stuff
it's very handy to have you know nice
standard algorithm looking tools okay so
now my proposal and hopefully your
deliverance from art to do meta
programming is Hannah
actually now boost Hannah which is a a
library for entertainers and type of
computations so it does everything that
the MPL does which is type little
computations it also does everything
that fusion does except except it's not
lazy
it's eager so it's just for you know
people who know choosing very well
everything in infusion I mean in Hana is
is eager instead of being lazy yes I
have no idea
well I mean I could look at it but oh
yes so the question is what is the
approximate time compile time for for
this for this switch any sample ah maybe
one second but there are like many test
cases in my in my big because like all
of this code compiles actually um the
samples are taken automatically and put
into my slides so
but there are many unit tests so maybe
the file takes something like 1 second
or so there are a couple of unit tests
so yeah it's it's really not that bad
it's much better than if you use another
metaprogramming library and it's much
less complicated than if you rolled your
own if you rolled your own is depending
on the complex so depending on the
complexity of the problem that you're
trying to solve it might be faster you
can might compile faster than if you use
say an ax depending on the complexity of
what you're trying to do if you're
trying to do something come slightly
complex be assured that we are more
clever than you in Hana and that we make
it like we are the algorithm that that
we use are more optimized but for very
simple things you might be able to you
know to have something that can pass
faster because you have no you don't
even have the overhead of just including
the library which is like 0.3 seconds or
something so yeah so it's quite fast at
compile time and I wasn't really clever
actually in this implementation because
as you see as you might have seen I'm
I'm I find it and then I filter and then
I unpack there's like duplicate work
here I'm looking I'm like going through
the sequence finding this case and then
I go again through the filter this all
sequence filtering I could have like
partitioned instead partition the
sequence into two different things like
a sequence that contains only you know
the default case and a sequence which
contains all the rest it would be
probably more efficient so yeah but it
was mostly for education here so yeah
the genes-- anti-public computations
although the the Trojans computations
for now our only eager I'm planning on
maybe adding views because there seems
to be a need for it but for now it's not
there there are more than 80 algorithms
most of which are highly optimized both
for a runtime and compile time we are
using pretty clever techniques which I
will have the time to show go a bit
faster and then there are about eight
versions containers like a compile time
map the compile time set a two-pole
which is actually much more compelling
efficient than its dead tuple so you
might want to change
and and there is like also a
compile-time optional there's a
compile-time strain class there is a
compile-time compile time range stuff
like that and so yeah the compile times
are much better the run time the
execution times are quite good also they
should be matching with those boost
fusion which is pretty much you know
what you would write with what you would
achieve with and written code it's
working on C++ 14 compilers which means
only client because even though GCC is
supposedly C++ we can comply it it's
full of bugs so so it's not quite
working and I mean yeah so um it's it's
almost there there are a couple of bugs
that still need to be fixed
I'm I'm really looking forward for the
GCC team to take my bug reports slightly
more seriously and to be slightly more
responsive but apart from that like
we're really close to maybe two or three
bug reports left to fix and and we
should be good for maybe five point JCC
five point three or something and other
than that well it works on Apple crying
and and client yeah you know then very
very funny
and miss PC well I'm sorry guys and yet
so the good news is that it was accepted
in boost I'm working very hard to make
it part of the next you know release now
this is my own work towards you so my
own work towards you is to continue
improving the library to fix bugs when
there are some to work very hard so that
it can be part of the next books release
you know to make this available and
production really as soon as possible
for you guys your homework is to try it
it's just to use it to you know file bug
reports submit suggestions so we can
improve and you know there's no library
that that's really good without having
large user base which can really like
say hey I need this I need that that I
don't need so we're gonna you know work
together and and build ourselves a very
great programming library which can be
used to do some very interesting and
very and things that would be very hard
to do otherwise so to finish up I would
like to invite you to embrace the future
you know the new suppose was fourteen
standard and and suppose for seventeen
to try to keep your compilers up-to-date
to try to think out of the box because
as I hope I was able to demonstrate it
is possible to do some crazy interesting
things if you just think out of the box
for a bit it's been like ten years that
we've been like metaprogramming with
angry brackets a little bit of place for
like ten years and now I think it's
possible to like this you know part of
the past and also obviously since I
wrote it I would like to invite you to
embrace Anna because well I think this
is really a library for the future of
meta programming and actually I would
even like for some examples I mean for
some ideas from Anna to be reported to
the standard because I think some of
these ideas are just no brainers okay
I'm not saying like it's pretty
functional library I mean like
programming functional library the
concepts come from personal programming
I don't want this in this time madness
oil yeah I'm not trying to force it like
a button
anyone but some like just having a
forage that works on tuple just makes
sense for everybody okay so thank you
very much
so I had the time to take some questions
but I would also like to show so I would
like to show some implementation
techniques for those that want to see
how this is actually done like okay can
you filter a tuple so any questions okay
the question if you had to pick one or
two language features that will make my
life easier in this paradigm what would
you pick I want to be able to have a
lambda appear in a unevaluated contacts
which means that I want to be able to
say they call type some algorithm and
then pass a lambda to this algorithm and
it still works right now it doesn't I'm
going to open a core defect for that
which I submit they told me that it was
that this restriction was now not
required anymore so this should work the
other thing that I want is a compile
time I mean I mean compiler generated
closure
I won't - tuple to be part of the
language I wanted to be part of the core
language this way we can have very very
compile time efficient optimally runtime
efficient heterogeneous closure and this
is like the this would be like the best
feature ever this no seriously this
would just make like compile long
compile times mostly part of the best
especially if they give you like a way
to access the nth element so random
access into your sequence as part you
know what the core language then it
would be just like super fast probably
and yeah so that would make a big
difference and apart from that I think
that's it yeah so yes so the comment is
that there are parent packs
random access things that are being
proposed I do not like burner packs
because they don't have compose very
well I think it is much cleaner to to
just stick your barriner back into a
sequence and then to manipulated without
rhythms because say you want to filter
like a peridot peridot back with a
predicate how do you do that you you put
the predicate first first and then you
expand the parameter I can into like the
parent into the list of the
it's just really key just like you
wouldn't want to represent your state
vector as some kind of magic syntax
using that it's just easier to put it in
a container and then capacity function
just yeah how would you return the
periodo back you can't you can return to
both so I know I'm really not really
fond of peridot packs I would rather
these kind of features not not going to
the language yes okay so the question is
I I say that the compile time is better
with this approach then with say uh
explicit angular bracket stuff and blah
blah blah so what do i attribute this
speed up to actually it's not faster the
reason why it's faster is because we can
use other so the fastest way to do pure
type level computations is to go the
dirty way and to do it like with the my
rotor packs and the old MPL way it's
faster but it's also it also makes you
want to die when you write it so the
speed up is actually due to just other
implementation techniques that we're
using that are part of C++ 14 and this I
could like I got some bonuses I I'm
going to show it but yeah so actually
the fastest way to the pure type of a
computation is not with this paradigm
that I've shown you but the most sane
way to do it is definitely yep a bar
with I've I tried to write a switch for
booze variant which does exhaustively
checking with Hana
I haven't tried it no I think it
wouldn't be much harder probably than
writing to boost any switch right
because boost any is just booze variant
with unbounded types like with unbounded
possibility of types yep
yeah yeah I was in your talk and and and
I was thinking this thing you mean the
the the the any switch or it could be
I'd like to see it I'd like to see it
okay but I'm not sure it's more trivial
than with it anyway right because you're
still saving a lot of fuss you still
have like algorithms to abstract some
operations anyway yeah but in the case
of a boost variance which it might not
really be a such a huge game okay so the
session is over if you still want to
stay I so like I think we're gonna cut
the video but i but but but don't do it
if you don't if you don't want because
everybody's uh might be interesting
interested in seeing the implementation
techniques so you can leave if you want
but I'm going to show how to implement
algorithms now so basically what we do
is the goal is to always do the index
computations with you know Const expert
if possible or to use to the next
sequence to to expand the parity backs
so say you want to implement transform
what you can do is you take your tuple I
mean here you take it to pole and then
you take your function and then you just
compute the size you just trade an index
sequence which contains you know a
parameter pack of the size of the number
element in the in the tuple and then you
call a helper function which as here
these indices and since this is a parity
pack going from 0 to n minus 1 where n
is the number of elements in your tuple
you can just expand it and call F on
each of this you know elements of the to
call that way ok
this is transform now then somebody
close the door please
now okay this is easy you can implement
other things with like say for each or
stuff like that using the similar
techniques although some body else is
going to talk about that in a different
session so I'm not gonna show it
actually but so now this is easy brace
yourselves
here comes filter so filter is a nasty
beast basically okay we're gonna we're
gonna do it step by step because this
this one is actually very difficult to
up to to implement so we get a two pole
we get a predicate which contains an
integral which returns an integral
constant we just create a an index
sequence with the size of you know the
tuple and then what we're going to do
here is we're going to to use an helper
to create an index sequence okay and
this index sequence is going to contain
the indices of the objects for which the
predicate returns true and only that
okay and so this indices here again is
an index sequence still index sequence
that contains only the indices where the
predicate returns true and then if we
have such an index sequence which I'm
going to show you out how its
implemented after okay but this is
slightly nasty but I'm so once you have
this you can just slice you to pole
using those indices and slicing your
tuple is just as easy as just you know
get the get the proper elements get the
elements at the proper indices okay so
if we can actually get an index sequence
here with the proper indices we're good
to go
you're just so it's clear to everyone
I'm just like I said predicate is
returning an integral constant to buoy
an integral constant so I can nickel
type that fetch the count count value do
this for all the elements in the in the
tuple and right so this is like a this
is an boolean true false true false
depending on the value of the predicate
okay let's go here so filter indices is
just this helper here the real trick is
going to happen in the filter in this is
alper here okay
so what happens is we create an array of
the results it can stacks per array okay
then we use stud count except like a
context perversion of stud count but
it's exactly the same it just stick
context where in front of stud counting
it works so we use stud count to count
the number of elements that are true now
since this is context / we're happy the
result you know we know what it will be
the size of our resulting tupple and
then we compute the indices so we are
going to create an array which contains
the indices of those elements that are
true this is pretty trivial this is just
normal C++ really there's no like type
level thing here or anything so we just
you know start the index at zero and
then whenever we find a result in the
array that is true we just you know say
a so the index of this true element is
is that and we put it into that array
and now we create an array you can sex
for array with the computed and this is
here so here this is a historic context
breasted array which contains the
indices of the elements that satisfy the
predicate and only that what do we still
need to do is so the only thing that we
still need to do is to put this into an
index sequential yes what
and this is as a result yet
is a current no it's not yeah no n is
the number of elements in the in the
resulting sequence so I just feel my
array you know using the I just fill my
array using wait a minute oh crap I
think that's right it's really crazy
because this actually jump out and work
okay so there might be there might be a
subtle bug here but so yeah I think you
get it that we're just basically filling
the array it didn't test enough right
this is not the implementation in Hana I
just could be pasted it and then
simplified it and I made a mistake doing
it so yeah but basically what we're
doing is just filling the array with the
parentheses and now so assuming that I
wrote my code correctly
I should this should be like a solar
array which contains the indices of the
elements that I want to keep in the
resulting sequence now the only thing
that's left to do is to put this into a
stirred integer sequence and the way
we're gonna do it is like this so we we
yeah so this is just a nice trick to you
know evaporate back from from 0 to 2 n
here and what I'm gonna do is just
create an index sequence using the
computed indices which is a context for
array containing the indices so what I'm
doing basically is I'm saying like I'm
creating an integer sequence that
contains you know the first the fear the
first computed index and the second
computed index and and so on and since
this interest from stood index sequence
I can use it in my slice here like this
so this is the way we do it yes
okay so the question is that wouldn't it
be simpler or more or less efficient to
instead use like a normal approach
recursive approach to filter all the
indices that do not satisfy - pretty
good the thing is no because okay and
actually yeah so the interest in this
technique here is that there is no there
are no in sensations it's just constant
for a modernist code the compiler
doesn't do any instantiation
right there are no templates there are
no different types if you recruit simply
you know look at the type list you are
doing you are like instantiating all
those different types so this is
supposed to be much faster and from the
benchmarks I've learned so far it is
also so so so yeah the interests here
that we are doing all the heavy
computation the index computation we are
doing it constructs per homogeneous
which is quite fast okay so that was it
I'm really out of time so thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>