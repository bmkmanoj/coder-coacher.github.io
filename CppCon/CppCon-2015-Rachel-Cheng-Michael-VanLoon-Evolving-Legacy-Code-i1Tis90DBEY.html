<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CppCon 2015: Rachel Cheng &amp; Michael VanLoon “Evolving Legacy Code&quot; | Coder Coacher - Coaching Coders</title><meta content="CppCon 2015: Rachel Cheng &amp; Michael VanLoon “Evolving Legacy Code&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CppCon/">CppCon</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CppCon 2015: Rachel Cheng &amp; Michael VanLoon “Evolving Legacy Code&quot;</b></h2><h5 class="post__date">2015-10-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/i1Tis90DBEY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well thanks for coming everybody um I'm
Rachel for those of you don't mean this
is Michael Van Loon my coworker I'm a
software engineer at f5 networks grads
doing at Georgia Tech alumni of the
Evergreen State College um if you didn't
know Sheree Schulman my former professor
was here and she gave a talk on
functional programming which is a pretty
cool who added that how did make it on
there anyway i work at us is my coworker
Smither michael van loon mrs. Smithers
is wrong um we both work at f5 um I'm
old and wise he's also honored for
syphilis plus so what does that vibe do
Oh too many fingers all right go ahead
so basically eighty percent of all
internet traffic on the on the internet
goes through an fi device somewhere now
I haven't verified that that's
statistically true but we are in a lot
of data centers all over the world so we
create devices that move packets and do
a whole lot of other things load
balancing security everything in between
we make your applications run well
inside your data centers we also
distribute traffic across data centers
so we're all over the place so we make
networking devices essentially and this
is what it roughly looks like um has
three layers of abstraction the data
plan pushing the packets implements the
protocols the control plane dictates how
the packets are going to be pushed it
manages configuration and provides other
core services such as clustering
failover config synchronization
monitoring and so on the management plan
is usually or gooeys your api's and
other ways the users can interact with
the device so we Michael Van Loon and I
wanted to create a new modern monitoring
system with all these fancy features
awesome code so we nuked it entirely and
replaced with something else no we did
actually really do that the title of our
talk is evolving legacy code so this is
process over time right so what we'll
discuss today is how we evolved and
continue to evolve the code and this is
joel on software he said it wonderfully
the single worst strategic mistake that
any software company can make is that
they decide to rewrite the code from
scratch you give your opportunities
years head start on beating you you have
an opportunity cost you still have to
maintain the old product you ship a
minimally Viable Product for really long
time and it's never a wise idea to start
from scratch would you like to make a
comment about this okay so we had really
good reason we did we're wanting to
revamp the system right right so I mean
obviously it had a whole number of
problems she has notes here she's
probably going to want to talk about go
ahead and Anna and I'll touch every
Wednesday so architectural problems
right it makes it hard to add new
functionality it's difficult to write
tests for it's also very difficult to
maintain so legacy code has a lot of
code that doesn't conform to internal
standards right so there's a general
code flow that it kind of works around
you know it doesn't really use the
internal frameworks the functional
constraints of the code is kind of
unclear therefore the code is also
really ugly and hard to read right
degrading performance is also another
big factor technical debt a term that
we're all familiar with it shows up in
the form of difficulty and adding new
functionality performance and
maintenance yeah i'll go ahead and okay
took the next one uh just to give you an
idea of what we're working with the
monitoring subsystems the oldest piece
of code in on the device and because the
other frameworks kind of outpaced in
development this code tended towards
legacy over time custom code was built
around to cope with the new GUI
frameworks and the middleware frameworks
and so it became increasingly harder to
maintain and add new features over time
so the thirty thousand lines of code i
would estimate about thirty three or
five percent of the code is actually
just dealing with custom code to fit the
more modern stuff right
and it's not actually code that
implements a system itself another
aspect not listed here is that it was
originally written in C and then some
developers would come in they'll add
some C++ and then leave before they can
be tagged as a subject matter expert and
then another person would come in
they'll add more C++ and on top of it
and you know over time reading the code
you can almost see the archaeology right
and it takes too long to understand and
completely maintain so so that all
sounds bad we'll go back just like so
that all sounds horrible makes our
products on really bad the thing is as
as it says there this started out of C
code 14 years ago and so it's going to
be ugly but it's part of a multi-billion
dollar product it's been running for 14
years it supports some of the biggest
companies in the world so it works you'd
think reading this slide that just throw
that stuff all away and start over but
the fact is we have some of the biggest
customers in the world running on this
stuff and it and it works so after you
looking at the warts you might say well
you know there's there's a lot here
buried treasure in the code is one of my
co-workers put it the that you just
can't toss out because you have a
working system you have customers using
it and you have to keep those customers
running I click OK you click so we can't
scrap the entire sub system has pointed
out by Michael and so what can we do
about this what we did was we had a
long-term view and sold it kind of in
pieces and productize each work item for
customers right that way we can evolve
the code while still making forward
progress and adjusted in addition to
just the code we also think about other
time gentles as well such as our
processes are testing and code review
processes so let's take a look at some
example code so this is hypothetical
following the metaphor the subsystem was
originally written in C so here I have a
struck that represents a monitor at one
point it was fine suit
for requirements at the time we only had
like maybe two or five protocol
implementations and it only had a
handful of data members right each
instance of the structure is passed by
reference around some c functions it
traverses down a tree like a decision
tree and the tag dispatches you know
where the struct will go down which
branches so it does its thing save some
important state like up down pending the
implementation of the protocol through
the send and receive and stores the file
descriptor during runtime fast forward
10 years and now the product supports
over 30 protocols and thus trucks grown
by say over 200 data members right this
becomes untenable and not only that I
mean you're dealing with types here we
still have void star functions and and
so there's there's a lot of usability
problems when debugging the code like
what is this function which which one is
it where does it go what happens when i
call it I don't know with an act without
actually calling it so yeah other
problems not many attributes were really
reusable and it's not clear what data
members belong to what protocol it's not
clear what can be modified and when and
it becomes increasingly harder to add
new protocols as the tree got larger
right at this point the tree doesn't
even resemble a real interface anymore
with many sub functions and routines
that work around the code flow so some
new monitoring types such as diameter
might want to reuse the same file
descriptor for its multiple interactions
right so it goes around the usual
workflow you can have multiple data
members with similar names such as IP
address a B and C and it's not obvious
which IP address data members being used
for transparent probit that transparent
probing and path reading or IP and pipe
IP so um yeah you want to add anything
else here no you see anything else wrong
with this I see lots of things wrong but
we have we have lots of things right
that we want to do so so there you go
yeah
so one found a point in legacy code you
know learning the code often involves
learning the history of it as well and
you infer this from just tracing the
program very laborious so if we stop
there and we can wonder what can we do
about this you know customers noticed a
huge memory usage increase when they're
upgrading from an older version to newer
one right the host operating system
doesn't give us much resources to begin
with and as people are turning on more
modules you know we get even less right
in addition we're also interested in
making it easier for internal customers
to add new protocol support and so we
could start looking at some options here
right so option one is a pretty common
one we add yet another layer right a
quick patch that accomplishes is going
apart right so I the idea is we let
developers write in a new clean space
right the old framework can provide some
hooks and will call into the colon to
the binary right so this is kind of the
fast simple answer and it keeps a lot of
new people from having to learn the
internals and stuff right but you know
if you already have too many of these
layers you might consider something much
deeper such as changing the data
structure itself and consider the impact
of the underlying system right so yeah
um one of the things we could consider
so instead of having a monolithic data
structure that contains any possible
thing that any possible monitor protocol
could need how about if we we use an
object-oriented design where you you
have some common things all monitors
have intervals and timeouts these are
things that we use universally but
various protocols might have unique
things as well so how about if we have a
hierarchy where we have a base monitor
type and then we have some some some
commonalities we have TCP based monitors
UDP based monitors you know various
other protocols we have some raw
protocols and then you know some
specific things for each of the monitor
types we replace a struct that
is hard to understand and incidentally
memory intensive because you have a
whole lot of data in that thing that
doesn't get used for most monitor types
with something that is easier to
understand because it's specific to each
monitor type and it's also doesn't
contain it doesn't carry along data that
it doesn't need the the other side
effect of this of course is that we
could even be more generic and have a
configuration stored separately from the
code that's necessary to implement a
protocol and then you know in the places
where you don't need to actually probe
you just want some configuration you
have a lighter weight object as well so
these are you know a few of the things
that you can consider doing patching
that into your code is an exercise left
for the reader we're still doing that so
it's it's a work in progress but it's
one of the things that helps so some
other examples is in just general class
design this is kind of a subscriber
class and a subscriber and in terms of
function L we usually think of something
that receives some transaction we get
some callbacks during processing maybe
and you know we have some transaction
processing code and maybe other
functionality again here at one point
this class kind of started as a typical
subscriber class and over time it seemed
that it became this convenient place to
put new things in it right and the end
results kind of confuses the intent of
the original code and so you know this
is a pretty you know general C++ stuff
so we don't you can see how you can
clean this off of it do you know you
don't know how to go back on this thing
this one yeah cuz I wrote this last
night I'm sorry it's it's pseudocode
yeah it's yeah it's hypothetic I didn't
paste this in on my code base or
anything right so okay so we also look
at things like performance right and one
of the things we want to really evaluate
or like where our biggest opportunities
so right with with the monitoring
subsystem um we inherited it from a
chain of developers and one of the
things that we we knew about was that we
had some performance limits that were
lower than we'd like but we didn't know
what they were we knew that we had some
customers who exceeded the the abilities
of the monitoring subsystem usually the
suggestion there was buy a bigger box we
had you know various other limits but we
didn't know what they were so as
Chandler pointed out in his talk the
first thing we needed to do was find out
do some measuring and and that was very
enlightening because some of the stuff
worked exactly the way we thought it was
it failed kind of in ways we thought it
would but we also found some areas where
things were totally surprising and so
performance testing revealed some some
things that we we learned which was kind
of nice as a result of course we started
with low-hanging low-hanging fruit there
were things that we could do to make
things run better for instance looking
at the code the the path that the the
code took to process all this data it
was clear that we were maybe checking
some things more often than we needed to
we may be calling some stuff more often
than we needed to and so just remember
removing the number of cisco's or
lowering the number syscalls we had
helped because we're on a box that
sometimes extremely busy and we only get
a limited number of cpu cycles and so
being as precious with our cpu usage as
we can
is very important also verifying that
all of our data structures that do any
sort of ordering or look-up are either
hash or map based rather than being
linear searches we have some very
scientific slides as you can see another
thing that we did because like I said
this is this this is 14 year old
originally C code and once upon a time
select was the correct way to look for
file scriptor availability and it no
longer is so so for instance it kind of
looks like this when you use select and
you get a lot of file descriptors you
start to get some pathological behavior
because select is very inefficient with
a large data set epoll on the other hand
is much more linear with its performance
so the more you need that performance is
when select becomes your worst enemy one
of the tests that we did showed
basically a fifteen percent improvement
i should say fifty percent reduction in
cost waiting for busy file descriptors
by switching from select to epoll
another test that we did showed cpu
usage for a very intensive data set it
was like four thousand HTTP monitors two
thousand HPS monitors on a small box
resulted in a CPU drop from I think it
was like sixty seven to fifteen percent
or something like that because was
spending a lot of time just waiting on
file descriptors so these these are
examples of taking your testing finding
the biggest bang for the buck but the
biggest bang for the buck we got of all
was our monitoring process used to be a
a single single threaded process and
what we decided was it already did a
little bit of hashing across blades in a
chassis we could split our monitors up
and divide the load among the blades so
we already had some hashing code in
there it's like well why not we have
lots of course let's make it so that we
can run multiple processes on each blade
or each proton each box and so we used
we reuse the existing hashing code that
we already had and modified the
processes slightly so that they would
run side-by-side multiple on the same
box wrote a little process manager it
was pretty trivial code for the most
part and the result was that we got near
linear increase in performance so for
example going from single process to
four processes we might be able to
handle almost four times the number
monitor instances on the same box other
limits you know withstanding and so this
was a small amount of additional code
with a really big payback we also
thought about multi-threading why not
take this single threaded process and
make it multi-threaded and we still may
we haven't yet the advantages to
multithreading of course is we could get
finer grained scheduling instead of
coarsely hashing each monitor instance
to a specific process who's always
responsible for that set of monitor
instances with say a worker q type of
approach you might be able to have it so
each thread pulls the thing that's ready
next and that way you get a little bit
lower latency it's more responsive the
disadvantage being of course
multi-threaded code is more complex it's
funner I admit that but it is harder to
write and it's harder to get right and
then you have to do things with like
potential idle wasted time blocking on
excessive blocking to make sure your
stuff is actually safe and so these
these are these are costs it's it's a
opportunity cost analysis I might get
some extra benefit out of
multi-threading and I could combine the
multithreading with the multi-process
but it does have a much higher cost to
implement so the multi-process happened
first
so some others we walked through a
couple of things right couple of code
things for those things that could be
evolved pretty easily the low-hanging
fruit type stuff and they provide kind
of immediate benefit to our internal and
external customers some other examples
that we're not going to go into here is
the console bridge just bringing up
legacy code to internal standards
framework usage right and another big
one throughout this conference is
applying modern c++ standards especially
ones that reflect code safety right this
is already well covered by several talks
this year including the rnase herbs Gwen
so I'm not going to get intimate here
mm-hmm go check out their talks no but
I'll talk briefly on it so slightly
different vein so one of the ways to
implement modern c++ in this kind of a
context because like we said we can't
just rewrite the whole thing yet you
can't just put drop modern C++ right on
the top of old c style code how do you
get that best bang for the buck one way
is you write a replacement for a piece
of the subsystem like the configuration
we talked about earlier that is modern
C++ it's very well designed and you plug
it in to the rest of the system and
continue to use the code that works with
it so you're not replacing everything
wholesale you're just replacing
individual pieces one at a time and so
for instance you might be able to
replace the configuration code something
object-oriented but it still calls all
of the original socket handling code the
original monitor probing code without
replacing everything at once because we
know that stuff all still works okay
testing so as other talks of previously
referenced a unit testing didn't really
become a thing in the early 90s and so
it seems true here historically the code
only had functional testing and you know
the scope of that was you know
exercising each protocol to some extent
right we didn't have good cross
functional testing probably because the
functionality such as synchronization
distributed monitor
me and others were just developed many
years later and so there's not a lot of
cross functional testing you know the
monitoring subsystem has been largely
neglected for you know 570 10 years it
is not uncommon for legacy code to lack
unit level testing and because the code
design doesn't contemplate unit testing
it usually doesn't have clean interfaces
that would make it easy to mock things
out such as networking code or other run
time dependency code just an
illustrative example you know here's
like a little subtree of functions I was
time to do a probe is it an address or
is it a service bound to a port and then
you know this is a big decision tree
this is not necessarily reflection of
what actually happens and all the
highlighted in green has socket or
networking code the highlighted in red
highlights an external dependency to
create route domain context and things
like that so this is not stuff that can
be really easily forged into a
compile-time running unit tests and
things like that and what we really want
is for things to become better
compartmentalized and componentized so
this is familiar to us code centralized
by functionality and therefore easier to
walk out right another hitch that we ran
into while the multi-process stuff is
that Global's made it very difficult to
write unit tests for right yeah so you
know we're writing this multi-process
conversion for a single single process
and the thought was well we need unit
tests so I wanted to write a unit test
that would spin up a bunch of you know
logical processes inside a single
process test them against each other and
that wasn't possible because Global's
and statics and it's just you know a
side effect of like I said 14 year old Z
code it's the way they wrote it once
upon a time you know we have to deal
with it but the end result was that the
testing had to be done spin up a single
process instance tested spin it down
spin up another process instance tested
spin it down and so the testing is there
but because of some legacy issues it was
not as efficient not as nice as I would
like it to be
so we're going to go back and talk about
another story so let's say your new
company you're going to call yourselves
be 20 your pitch is four times the speed
for quarter the price you want to
quickly get to the market and so you
create a basic l4 load balancer
supporting only let's say TCP and HTTP
protocols so you create the product you
bolt on a shell and push it to the
market then your early adopters request
a GUI and so you create one using
angular and then it requires a different
interface to the product itself that's
more conducive for gooby development so
you have a completely separate you know
I had picked I was going to do pictures
for this you're going to have to imagine
this as I tell it to you so yeah you
have a completely different
communication format and channel than
the shell right next you get bigger
customers and their enterprises require
roles based authentication control and
so you quickly think the best way to
implement security is through a single
you ice surface right so you redirect
all the gooey are back stuff over to the
show and before you know it the growth
and the code starts to look very strange
and in addition newer concepts in
industry are pushing towards things like
automation consistent interfaces many
other things that really challenge your
product and this comes to a point and
nobody that is successful has the
pristine code base as Shane here the
problems in code is really just a
microcosm of change in the broader
organizational level and the entire
product vision cannot be complete
without contemplating quality this
includes making the product easier to
test more serviceable documentation
amongst many others what I mean by
serviceable is from the perspective of
the customers as well as support right
how easy is it for your customers to
diagnose problems on their own what
information do you give to them that's
actionable are you publishing
indecipherable error messages that
requires knowledge of the actual system
internals like your schema and things
like that documentation which is
kind of a big one in my opinion just
read the code is not an acceptable form
of documentation I want to know how to
configure the product what is the
expected behavior not just for the
developers but for your customers as
well it might be the case if legacy code
that there is no documentation and over
time it's not clear what customers can
expect even in terms of supported
performance and system limits you want
to anything here no okay I'll just keep
talking then keep talking we also think
that we think about code review process
in our component what are the main areas
we want our reviewers to focus on right
we're not only interested in Lego you
should name this a certain way or you
know whitespace tabs you know we want to
think about you know just specifics of
networking and socket coat it should
also cover configuration management like
some eyes on that we also want eyes on
General C++ code review so for each we
define a rubric of items to to look at
right forming a product focused team it
helps garner support for the roadmap
delegates these task to a variety of
stakeholders it really helps you push
your legacy evolution right you really
have to own it like a business so yeah
so no no I mean other than not guess I
do like I said these are these are the
things the challenges that we have it's
a this is the live thing that we're
doing we're in the process of this is
this is a real product as I said it's a
product that supports and continues to
support a you know people all over the
world a multi-billion dollar company so
as you said every company that
successful has this problem maybe not
always as bad but we're trying to make
it better in these are some of the ways
so yeah so we're those of you have two
minutes for questions actually could
take more of it yeah
it's so so he asked he said the project
is 30 thousand lines of code which is a
small project for 14 years and that's I
guess it could be seen in different you
know different ways it may actually be
more than 30,000 lines I think that's
just the main part of it but it's also
spread among my own 30 different modules
they're there in various languages this
is a null c c++ we also have some
monitor protocols written in java we
have some written and script and they
all interact in different ways those
auxiliary protocols are probably
additional lines of code that we didn't
count but yeah it's it's more about the
interactions and the complexity than the
sheer number of lines sure so right so
what he says when he's analyzed old code
before he's frequently found a lot of
dead code and a lot of code that's
primarily its job is to support code
that does work is that accurate okay
right because so so thousands lives a
code that don't really support stuff
that's useful anymore yeah there we have
found some i mean but i don't think i
would characterize it quite that way if
the code is pretty dense so especially
in the main main part of the product
there isn't a lot of wasted code it's
not necessarily a code that couldn't be
it I'll put it a different way yeah so
for instance say a big chunk of code
that does the Select loop the main
timing loop I did rewrite some of that
and reduce the the number of lines
probably by fifty percent but it wasn't
like any of it was wasted it just was
written like C code it was it was very
it managed micromanaged all the
resources there was a lot of explicit
handling of things that we know now can
be done in a much more declarative style
or with things that take you know take
care of our lifetimes of our objects in
a cleaner way that doesn't require a ton
of code right but I understand what
you're talking about and I don't think
we have a lot of that but yeah it could
definitely we could definitely shrink
the number of lines just by writing it
better so so the question is how do we
deal with the where you might find some
old code that's that's really gnarly but
it might be better attacked from an
interface perspective rather than going
deep in it
you realize that's my secret source
that's what makes this product work you
want to make it maintainable yeah it's
the secret sauce that makes it work and
right carefully because right you
especially with something that's that's
highly a diverse number of network
protocols yeah there's some there is
some secret sauce for sure and it's I
don't want to break that you know it's
it's probing something with a raw
protocol that uses route domains and it
uses a loose source routing and it's
like mmm okay I there's probably some
magic in here and I don't want it to
break so the answer is usually code
around that tried encapsulated in a way
that's one answer the other is
understand it go through it a lot over
and over again learn its secrets like I
was talking about the main timing loop
it was some really ugly code and
basically just going through it so many
times and tweaking it here tweaking it
there I finally kind of understood all
of the magic that they had originally
put in there and I was able to code
something new that replicated the
behavior but did it a better way so
there's two different approaches did you
have anything else you want in yeah
that's basically what I did for the
control playing elements first I had a
lot of unit tests and the second I took
on a lot of customer cases learned how
the things interacted learned what kind
of usages that that people would
exercise different areas right and over
time I gained a lot more confidence to
kind of write things in a different way
that were more standard to the rest of
the framework so yeah so I guess it
differently to answer what she just said
is you have to be invested I mean if if
if this is something you want to do to a
product and you're just going to hit and
run you're probably better off not
touching it because you're going to want
to invest the time to understand it
deeply or else it's your serving
yourself and your company better if you
just leave it alone so we're actually
over the time but you know we have some
more time I'm speaking for her if
there's any other questions all right
thank you for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>