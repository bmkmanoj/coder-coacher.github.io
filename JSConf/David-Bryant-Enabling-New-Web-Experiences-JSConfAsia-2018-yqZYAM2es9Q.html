<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>David Bryant: Enabling New Web Experiences - JSConf.Asia 2018 | Coder Coacher - Coaching Coders</title><meta content="David Bryant: Enabling New Web Experiences - JSConf.Asia 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>David Bryant: Enabling New Web Experiences - JSConf.Asia 2018</b></h2><h5 class="post__date">2018-02-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yqZYAM2es9Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm willing to bet that pretty much none
of you has ever heard of the emerging
technologies group at Mozilla that's
okay and we're gonna fix that I'm sure
you're all familiar with the Firefox
group after all that's the team the
engineering team at Mozilla builds
Firefox in emerging technologies we are
the other engineering team and our a
quick summary of our role is really the
title of my talk enabling new web
experiences and so I'm hoping to spend a
little bit of time this afternoon at the
end of the day walking you through the
work that we're doing in the emerging
technologies group introducing network
and getting you acquainted with some of
what we work on in what we do but I have
another motive in doing so which is that
I think it's fair to say that while the
title is enabling new web experiences we
expect that actually building those web
experiences is something that you are
all are going to do and so we have a
very strong interest in spending a lot
of time with developers understanding
what their needs are what the
requirements are what technologies are
relevant what kind of new experiences
would you like to be able to build or
better versions of today's experience
and so I'm hoping that in walking
through the various projects that we
have underway and the technology areas
that we're active in we'll find some
place that will spark some interest
they'll have an opportunity to come and
talk to us in in the booth or tour
tomorrow or Saturday or just generally
afterwards I will say that I'm guessing
you might be familiar some of you at
least with the graphic that's on the
screen here this is something I
hopefully you will have seen before this
is the mark 57 power suit part of the
visual identity that we created for
Firefox quantum the major update that we
made to Firefox and launched in November
of last year and the reason for using
that graphic and my talk is part of this
new web experience enablement work that
we did was in playing a critical role
in Firefox quantum and in the components
of the mark 57 Power Suit and so in our
walking tour of emerging technologies
that's where we will actually start so
the story in that particular vein begins
with rust we've had a substantial effort
in rust it was a programming language
and you may wonder why talk about
another programming language at a
JavaScript conference but if you hang
with me for a few slides I think you'll
see how the dots connect but rust is a
programming language that was begun at
Mozilla in earnest in about 2009 and it
was motivated by a problem that we had
trying to maintain a large complex C++
six million lines of code product and we
kept bumping our heads against a couple
of problems that really took a lot of
time and energy out of the product out
of our customers and out of our
engineering teams and we began to wonder
if these two major classes of products
were products that we could actually
find a better way to solve one of those
problems was that we were seeing the
emergence of hardware that had a
tremendous ability to support
parallelization and execution more cores
more execution threads and while it's
great that the hardware had those
capabilities as programmers and as
humans as I'm sure many of you know
parallelizing things robustly is is a
non-trivial problem to solve and so we
had the suspicion that we could actually
find a ways to help us solve that
problem in the programming languages
that we used and so that was one
motivation the other one was that we
spend and you may actually to spend a
lot of time fixing problems that occur
only after your product is built and
deployed and out in the world and used
by end-users now maybe those products
are crashes or performance issues maybe
there's security vulnerabilities but
there's a class of software issues that
arise because of the dynamism in
applications and the way in which they
behave especially for a web browser like
Firefox when it's out in the world
absorbing all sorts of unanticipated
will comment content and user
interactions and so the other problem we
were interested
in solving if we could was to try and
avoid having our engineers have to spend
all that time finding and fixing and
debugging those problems and worse
having our customers go through the
consequences of having those problems
when the product was deployed and out in
the field so the rust programming
language was sort of built around the
initial idea was the slogan was hack
without fear the idea really was to
create a programming language where many
of the runtime problems could actually
be found and prevented by the compiler
so a large class of issues that you
would have in your programming a
low-level language or systems
programming language like C or C++
actually get caught by the compiler and
never get out into the world to cause a
pain or anguish for your customers or
for your engineers and the other one is
its optimized to really do Russ's
optimize to do a great job with
parallelization and concurrency and in
fact the initial mantra hack without
fear makes a great t-shirt but it
doesn't actually tell you too much about
the language and that's evolved over
time to be more along the lines of
fearless concurrency so the first part
of the story and we have a small team in
the emerging technologies group working
on rust we have a large community
working on rust is delivering the
capabilities that we're living up to
that potential in the programming
language the next piece of that story
is a project called servo servo is
serves two purposes one it is a proof
point for the RUS programming language
if you're gonna assert that you have a
programming language that has new
qualities the way russ does you really
kind of have to back it up you have to
write a large body of code to
demonstrate that you can actually make
good on that potential and so servo is
an alternative web engine not unlike
simple web engines that you find in
browsers today it's not a fully featured
web engine or solely wouldn't wasn't in
those days the work started in 2012 and
the idea was to be able to prove the
qualities of Russ but actually give us a
way a workbench upon which we could then
do some of this work to paralyze the
components of the web engine taking
advantage of the of the properties of
rust and building new ways of doing
layout or styling in the web
browser built inherently around the
language enabling parallelization and
then the hardware underneath really
letting us take full advantage of it a
couple of other interesting benefits of
doing the work on servo is ìletís focus
on embed ability it's really great if
you build these components it's even
better inside of an engine it's even
better if you can use them in all sorts
of other applications and services and
so servo evolved over time and reach the
point where whoops in early 2000 late
2016 where we realized we could actually
take some of the components out of servo
and and bring them to to Firefox as part
of Firefox quantum and so we continue to
have interesting work inside of the
emerging technologies group not only in
evolving the RUS programming language
with the community but in continuing to
build and enhance the capabilities that
are in servo as a workbench for
alternative web injen components and
then highlighting or extrapolating from
those components to put them in
applications like firefox build a better
engine build a better platform and
provide a better experience for
end-users and running the code that
we're all going to build and deploy
using the traditional components of the
web HTML javascript and CSS the third
project that fits in this little sub
narrative of my larger narrative is web
assembly now all I willing to bet many
of you might not have been too familiar
with Russ tour with servo I'm hoping
more of you are somewhat familiar with
web assembly and I'll tell you we'll
talk a little bit more about what it is
and why I mean it actually does a better
job of relating to JavaScript promise me
then then servo arrested and around
about 2009 we began to get concerned
about the problems we were seeing with
handling of JavaScript on the web as web
content got more sophisticated as web
applications became more more nuanced
and richer developers were building
larger and larger bodies of JavaScript
and sending them over the wire as part
of presenting a web application to the
browser to be rendered on
Green that's fine JavaScript grew as a
language to give developers a lot of
those capabilities but one of the
consequences of doing that is all of
that javascript that gets sent over the
wire as the page loads has to be parsed
and compiled by the browser before it
can actually be executed and we began to
theorize that if we didn't do something
we might ultimately reach a problem
where we were going to see the
performance limitation in web
applications and content on the web was
really going to be bound up in the CPU
of the device that was running the
browser and we realized that was
probably not a good idea so we started
an experimentation effort to see if we
could actually find ways to remove some
of the impediments of parsing and
compiling JavaScript in real time as it
was loaded into the browser as part of
displaying the page that the user wanted
to see now the first step in that effort
was a process or a project called azzam
j/s and the idea with azzam jas was to
take a strict subset of JavaScript
statically typed and and think about it
as an intermediate language
representation that could be fed into a
browser could be compatible with every
JavaScript enabled browser on the planet
but could be built in such a way that it
would be efficient to execute to load in
to execute and to run into the browser
and avoid some of the challenges of
runtime handling of dynamic typing and
other pieces of the JavaScript language
as I'm DJ s was you know initially just
an experiment but it actually worked
phenomenally well what we saw with Azzam
j/s was the ability to actually
streamline the delivery and the loading
of content on the web and the ability to
actually craft although it's kind of an
odd looking programming language if you
looked at it as a human to craft runtime
components to do interestingly complex
computational things and get them you
know rendered and handled by the
JavaScript engine in the browser and
more efficiently than sort of fully
featured JavaScript so as emmaus was
successful it was typically not
programmed in by humans as I mentioned
it was an intermediate language and so
it was mostly produced by tool chains
and in fact compatible with with the
LLVM tool chain
so that it was easy for us to build
tools and we did they could take other
programming languages see for example
and compile them down and render them in
azzam j/s and then efficiently feed them
into the browser that experiment worked
well enough that we realized we could
accomplish a number of things by
evolving the technology forward and
webassembly was born webassembly was
designed to really be a complete virtual
machine inside of your browser and so
it's pretty much the case today that
every browser every major browser most
of the browser's running in people's
desktops certainly these days supports
web assembly it's a w3c standard and web
assembly takes the architecture and the
idea of as Emmaus and sort of pushes it
to the limit so oops
now we have a a binary runtime in the
browser and we can take representations
in almost any other programming language
and compile them down into web assembly
and create modules that are extremely
efficient to load and to run as part of
your web application and let's actually
look at what that's going to look like
should you be interested in trying to do
something like this as you can see from
the simple recipe card here you start
with some native code some assets that
you may have something that's
computationally complicated or
sophisticated complex that would be
inefficient and not it not run properly
particularly well there's a JavaScript
application and downloaded you use the
tool chain to compile it down to a web
assembly module the web assembly module
gets bundled up into your web
application along with all of the other
regular components of your application
so JavaScript images assets other sorts
of things packaged up as your web app
and then when the browser loads it pulls
all of those assets over but takes
advantage of the fact that the web
assembly module is already pre compiled
and ready to much more efficiently load
and execute in the browser the end
result is that large complex features
can be delivered in web assembly
and and it is efficient enough that it's
more can you think of it more like
loading an image the the load on the
browser of actually processing and
loading the web assembly module is a
much lighter weight thing and we see now
with web assembly applications can be
built to run more at network speed and
so what the user gets when they when
they they load the application is
something that's much more responsive
and much more initially loads and we're
seeing all sorts of examples of people
now taking web assembly and building
very powerful web applications and
delivering them today so Google Earth
for example recently announced that they
have transformed Google Earth moved away
from their own version of native code
that was compiled in as part of the
environment and they're delivering
Google Earth these days it's available
with web assembly and we're seeing
others Facebook others use as Emmaus and
web assembly to handle image loading
audio
encryption other computationally
expensive tasks and provide them on the
web and one of the the other reasons for
making this sort of interesting path
available to you and seeing what you can
can do with it is that we can take rust
the programming language I mentioned
earlier and compile it and make it part
of this webassembly pathway and so you
can actually get the benefits of rust
the efficient memory management the
ready parallelization in code that can
be compiled and rendered and built as
part of your web app so now web
applications can be much more diverse in
terms of the assets they use and
performance for end-users is clearly a
much happier thing and there are tools
available to make it easier for you to
do if you're interested in web assembly
I mentioned it's supported in all of the
major browsers no reason not to get
familiar with the technology and take
advantage of it and one of the things
we're eager to do is to make web
assembly part of a larger collection of
the tools tool chains and frameworks
that you have have access to and use on
a regular basis the benefits of that is
of course you don't actually have to do
anything as those tool chains and
frameworks incorporate support for web
assembly all of the performance and and
network throughput webassembly will
accrue automatically in your
web application and that virtual CPU
that's inside of every browser that
becomes a much more powerful tool for
you to run not only traditional web apps
but personal productivity apps or video
editing or all sorts of other complex
things where you may even have native
language assets or your teams have
native language assets that you'd like
to really be able to reuse as part of
building and delivering app so all of
those are pieces that came in as part of
Firefox today a couple of others I'm
going to highlight here that we're
working on sort of in the survey of
what's happening in emerging
technologies
VR mixed reality and speech now I'll
step back a little bit web VR I'm sure
many of you are familiar with we've had
demos in the lobby if you've never had a
virtual reality headset on I encourage
you to take advantage of the opportunity
to do it
in 2016 we began work at earnest on web
VR as the rest of the industry was
excited about virtual reality in general
and the goal in those days with Web VR
was to simply demonstrate that the web
was a viable place for virtual reality
Mozilla worked with Google we built a
standard initial implementation that was
ultimately standardized by the w3c of a
web the our API and the idea being that
we wanted to expose the interfaces that
you needed in order to create a virtual
experience through the web to all of the
typical ways in which you build and
deploy web content today so that if
you're familiar with HTML CSS and Java
all right JavaScript it would be easier
for you to actually then expand the 2d
kinds of web experiences you build today
to be something that was a virtual
reality based 3d kind of web experience
that was - that was great it was an easy
thing to do but we learned that there
were a lot of opportunities to really
put more powerful development tools in a
creator's hands developers hands to make
it easier for them to build and share
compelling web VR experiences which gave
rise to a frame
a frame is an easy language or toolset
that you can avail yourself of if you're
a familiar web developer to actually
build and share components and construct
entire virtual reality experiences and
easily deploy them on the web using all
of the same techniques at your filling
room familiar with today one of the
things we've learned from the web vr
standard and for making a frame
available is there are a lot of people
interested in doing this telemetry that
we we have in Firefox
tells us that about a million Firefox
users in the course of navigating the
web every day encounter some sort of VR
content or experience that each day so
that's actually perhaps a surprising
expanse of web VR that's available
people are using it for 3d 360 video and
for other things but we saw a lot of
growth in 2016 and 17 in web VR in the
use of a frame and the tools that were
provided as part of the a frame
environment so if you're interested in
trying to build a piece of virtual
reality or component that can be shared
in virtual reality and stop by and talk
to us we can show you how to use a frame
or a painter if you're an artist to
actually build and create that
technology and make it easy to use now
as big as virtual reality was especially
in 2016 in 2017 even more buzz and
interest in the market around augmented
reality and in fact the nomenclature
evolved so fast that what we now talk
about is mixed reality so mixed reality
is the combination of virtual reality
and augmented reality and it's ways to
actually blend the 2d world and the 3d
world in the actual physical real world
and create a whole new class of
experiences for end-users there as well
so just as we worked to propose a
standard interface for web VR we've
proposed a standard interface for mixed
reality and there is a web X our API
that's available now that you can begin
to experiment
and easily build and deploy virtual
reality experiences using the web as a
platform and about 10 lines of code and
we've provided not only the ability to
do it in desktop browsers such as
Firefox but we also have an open-source
mixed reality viewer that'll run on an
iOS enabled mobile device all off of the
same back-end mixed reality content and
therefore make it easy for all of you as
web developers to create virtual reality
augmented reality and other kinds of
experiences on top of the same platforms
and tool chains that you're using every
day one of the things we learned from
putting virtual reality and mixed
reality capabilities in the hands of
developers and end-users is that you
begin to want even other kinds of new
experiences on the web as part of
creating those new environments it's not
particularly convenient in the middle of
a virtual reality session to actually
try and use a keyboard to type to
provide input or commands or options and
so one of the the logical consequences
of building more of these kinds of
augmented reality experiences in mixed
reality experiences as you began to want
to be able to talk to your web browser
talk to the web and so another area of
activity for us in the emerging
technologies group at Mozilla is around
speech and speech recognition deep
speech is one of those projects and it's
an effort we began last year to build a
completely open-source speech-to-text
engine based on machine learning now
speech recognition has been around for a
long time it was well established when I
was in college many years ago but most
of the speech technologies that you we
encounter in the world around us today
are relatively closed proprietary
ecosystems and they're not particularly
readily available to us as web
developers to build and deploy in any
kind of web-based content so we embarked
upon a deep speech project to really
provide a completely accessible open but
useful speech recognition engine and
also give us a platform that we can use
to make speech recognition of a
for more languages and more cultures
broadly than is available through some
of the more typical commercial systems
so deep speech launched officially two
months ago we have Python JavaScript
income I come in line versions of it
that are accessible that can be
incorporated in your application or back
in service the word error rate is about
6.5 percent that's approximately how
well we do as humans so you've
misunderstood 6.5 percent of my words
but deep speech is actually capable of
roughly human performance and to
demonstrate how you can use it we did a
test pilot experiment in Firefox called
voice fill where we packaged up access
to the deep speech engine and allowed
you to actually conduct searches and
other interactions through the voice
bill it can add-on to Firefox just using
your voice so I'm sure you have talked
to your browser on and off for many
years now you can actually talk to your
browser and it will do something and
we're eager to work with folks not only
to expand the the engine and make it
available in more environments but also
to work on the corpus of text that goes
along with it
speech recognition as we've implemented
in deep speech is a machine learning
based application and it needs to be
trained and the more data that you have
the better the training is the more
effective the recognition is and so in
parallel with deep speech we launched a
thing called project common voice and
the idea of common voice was to use the
web to collect the speech data that we
needed to train and improve the deep
speech engine so we went live with with
common voice we asked people to
voluntarily give us samples of their
voice and so if you still could do it if
you like you go to the common voice
website offer to volunteer your voice
will ask you to read some snippets of
text and you do that using the
microphone
you're in your computer with the browser
we will record those samples and then
accumulate them in a large back-end
database and then we have other people
who volunteer to actually listen to
those samples and verify that you
actually said what we asked you to say
and so over the course of the last
several months 400,000 people have
400,000 voice recordings have been
contributed to the common voice database
from 20,000 speakers that's over 500
hours of text and the community has has
been part of creating the The Voice
corpus and database and we now have
people working to provide language
support not only for English but for
French German Spanish Macedonian odoo
Persian and Kurdish and more languages
are are coming as we can enable more of
the data collection on the backend and
so a common voice and deep speech
together means that you now have access
to technologies to let you take a
traditional web experience and build a
speech input component to it or build
new kinds of experiences and deliver
them on the web where speech is a viable
means of users actually interacting with
your content for your applications or
your service the last piece of the
emerging technologies organization am I
going to talk about is actually not a
piece that's oriented towards any of the
engineering efforts like the ones I've
been describing but we actually have the
the emerging technologies organization
is the home for Mozilla's developer
outreach effort and we did that for a
couple of reasons one is our focus on
developer outreach is really broadly
across all of the web and the
technologies that make up the web this
is a reflection of Mozilla's mission
where we're all about the Internet first
and foremost and making the Internet
open and free and accessible and
empowering for all and so clearly we
advocate for a wide range of
technologies well beyond those that are
incorporated in Mozilla's product web
assembly is a good example of that and
so the work that we did
in in advocating for webassembly
adoption led to it being pervasively
present in all of the web browsers and
one of the positive benefits to that was
that it allows us to get to the point
where application developers that had
been using flash and had been reliant on
plugins in the browser to get access to
that native functionality no longer had
to do so and through web assembly we
were able to provide a mechanism where
we could deprecated native plugins and
deprecated flash and that was all not
because we built it into Firefox but
because we designed it and built it for
the web and we advocated it from a
developer perspective for all browser
vendors to adopt additionally it's
important for us from a developer
perspective to be aligned with
everything else that's going on in
emerging technologies and so we're just
as happy to talk to you about the api's
or the tools or the standards or
anything else that you may require as
developers to really help you adopt or
become more involved with any of the
other technologies that i've just talked
about that we're working on in emerging
technology so we're just as happy to
talk about where your needs may be if
you're interested in building a speech
based interface to the web or a mixed
reality based one and all that work can
be taken up through the developer
outreach team as part of the emerging
technologies group and so that brings us
to the end of our tour I didn't actually
talk about everything that we're doing
in emerging technologies we have a
number of other efforts that are
underway that are probably less relevant
in this audience but I will highlight
that we're doing work on a royalty-free
high-quality audio and video codecs and
so if you're interested in delivering
high-quality media on the web and in
doing so in a royalty-free way we should
talk we're part of the Alliance for open
media in support of those technologies
that are becoming available and we also
have some early phase work on the web of
things and so some of the technologies
that Flocka showed us earlier in terms
of bringing javascript and the web into
microcontrollers and hardware is work
that we're also engaged in and we'd
certainly be happy
to talk to you about any of that work
lastly in this space we're spending a
bunch of time on I mentioned machine
learning as part of speech but we know
that machine learning is a technology or
that's going to be pervasively
interesting or replicable in a wide
range of ways across the the broader web
and we're happy to explore the
intersection of machine learning and
assistance and what that might be
interested of interest to you all so
thank you very much that's me
catch us in the in the booth outside or
talk to us tomorrow and we'd be happy to
find out what you're interested in and
how we can make some of this technology
more accessible or valuable to you going
forward</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>