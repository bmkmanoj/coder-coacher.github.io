<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[JSConfUS 2013] Felix Geisendörfer: tus.io - Squeezing Cats Through Tiny Mobile Tubes | Coder Coacher - Coaching Coders</title><meta content="[JSConfUS 2013] Felix Geisendörfer: tus.io - Squeezing Cats Through Tiny Mobile Tubes - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>[JSConfUS 2013] Felix Geisendörfer: tus.io - Squeezing Cats Through Tiny Mobile Tubes</b></h2><h5 class="post__date">2013-09-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ilCxWswGm1I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the presentations called test Alejo
squeezing ketsu tiny mobile tubes my
name is Felix caisson defer and I'm
involved in a bunch of projects one of
them is note copter note copters the
full day went of programming flying
robots with JavaScript we started this
in Berlin last year at she askin for you
and the people I saw with with are
actually here there's torsten Robin and
Tim and what's really fun is that here
Jess conf yes we're actually able to do
node cop the event for the activity day
tomorrow so I'll not say too much about
this I'll just give you a little teaser
this is kind of what it's going to look
like so if you want to come maybe you
can trade with somebody if you haven't
signed up already what's this should be
fun unfortunately I don't get to play
with flying robots for living so have a
day job i'm a co-founder at this company
at least we have a robot in the logo so
that's good so we're called trans loaded
and we do file uploading and file
processing as a service so we help
companies receive user-generated media
files and then we convert videos and
images and all that stuff and we censor
original files in the modified stuff
back I've also been involved with a no
chess project I was one of the first
contributors to no trace and did a lot
of early contributions the reason this
happened was when we built trans noted
we were trying to get upload progress
bars for users and back when we did says
this was really hard to do in javascript
basically the only option you had was to
constantly ask your web server hey I'm
uploading this file right now how much
data have you received so far and so you
keep pulling the web server and in order
to actually be able to pull the web
server like this the web server kind of
needs to be aware of that you're going
to pull him and said that it keeps track
of the upload the streams and this was
really hard with the web server said
we're outside back then most notably
Mabley Apache and we saw nodejs and no
chairs was really great because suddenly
we could do this really easily on the
application level we would just use the
normal node HTTP stuff and would be able
to stream and upload in and send kind of
keep track of the state for the clients
asking about the upload progress though
that was fun but we were using node way
too early so I ended up spending more
time contributing to know it and fixing
bugs and doing stuff
working on the startup but it was fun
these days I don't do much of the note
core anymore but a maintains the modules
and maintains a MySQL module which is a
pure JavaScript implementation of my
sequel protocol and I do formidable
which is a module for parsing
multi-platform data and I'm going to
talk about this in a bit a little bit
blasphemy I'm kind of moving away from
nodejs these days to go I will not say
too much about go but it's really
beautiful language so if you want to
hear more about it to find me later and
I'll talk your ear off and yeah check it
out I haven't contributed yet but I plan
to and we kind of went to bed very late
last night so chances are i'm going to
say stupid stuff and incorrect stuff
when this happens just let me know so I
can kind of clarify afterwards or
something so let's get started let's
talk about file uploads and let's kind
of put things into perspective about how
we get file uploads on the internet or
can is a history there's so this trip
starts in 1971 1971 was great because we
get this thing called ftp you have to
appreciate how long ever time this was
to go so i'll see 114 was published in
1971 this was three years before tcp/ip
we had ftp which i saw it was insane and
two must have taking a lot of foresight
i actually don't know what's networking
stacks were at that time and what's also
amazing that ftp it kind of remains the
state of art of internet uploads for 25
years so if you wanted to bring files to
the internet you'd usually use ftp
what's kind of said about it ftp it's
not said that it's being replaced but
it's kind of sad that it's being
replaced by a proprietary technology
mostly amazon s3 and I'll kind of talk
about this a little bit later but let's
fast forward for 25 years basically
nothing happens uploads on the web don't
change and then 1995 comes around and
1925 was a cool year a bunch of things
happened PHP happened for the better or
worse internet explorer happened for the
better or worse javascript happened for
the better or worse hopefully the better
HTML 2 20 s release there was the first
time HTML was standardized and it gave
browsers a way to implement it in a more
compatible fashion than before
and just a day after this there was a
new off see coming out which described
how to do file uploads through HTML this
was later on merchant with the HTML
specification and was part of HTML 3 and
it's now still part of html5 and this
was RC 1867 form-based file upload in
HTML you may be familiar with other
works FC all services this was done by
larry maher center and one notable RFC
he has also worked on is RC 2324 does
anybody know what is this this is a
hypertext coffee pot control protocol so
if you've ever received the 418 I'm a
teapot status code from a web server
that's this evil genius at work it's
Larry anyway I admire this RC because it
made something that is kind of complex
underneath incredibly easy and I kind of
want to show you how easy you've all
done this before but I kind of want to
go through the troll a little bit so
let's let's do programming all right so
let's say we want to do a file upload
and we want to do it like we would do it
in 1995 so we're doing this form that
HTML thing and we're going to do this
form and it's going to get it's a font
size okay for everybody okay cool we're
going to get it an action let's say
we're going to /a action as post no no
no no too late last night messages post
and the action of / and one of the
things GRC defined was an encoding type
before we had and it's called
multi-platform data like this before we
have multi-part formed at us the only
way to get form submitted on the web
worse by URL encoding them and doing
this with files is technically possible
but the escaping mechanism would blow up
the payload quite a bit so you would
have a two or 3x increase in payload
size because you have all these e escape
sequence is going on and so people they
had to come up with a new format to kind
of put files into and those whose
multi-platform data another thing that
they did sa extended the input element
and they created this input type called
file and we're going to put this gives
us a name and say my upload
on now we need a little submit button
this was actually part of HTML before
submit value and some / form okay this
should give us a file uploader okay so
you've seen this before this is
basically the file selection element
notoriously difficult to start with CSS
but it works and what you can do is you
can choose a file and we can select this
tiny image here and hit submit and
nothing happens why does nothing
happened because we haven't written a
backend for it so it's 1995 we don't
have a lot of options for back in
technology so let's use my 1995
technology its use PHP let's go and do
PHP and what this looks like is this
print our files and I'll show you first
how it works then I'll talk a bit a
little bit about it what we can do now
oh there's one mistake form that PHP all
right now we need a web server and these
days luckily PHP does ship with one and
we can do form that PHP and we can
select the file and hit submit and
what's this is basically doing is we
just implemented file uploading so
forcing front-end and back-end we were
just hitting submit button to payload
get encoding multi-platform data PHP
automatically picked up on that decoded
sub payload and gave us reference to the
file on disk as a temporary file there's
a lot of problems with this but what I
think is amazing is that this to me is
the appropriate amount of complexity
file uploading should have on the web
and anything thats kind of gets more
complex is kind of and we've
gotten a lot worse with this over time
and i'll talk about this so this is this
is a really cool in terms of complexity
what's not so cool is that features were
missing so what's most notable about
this is that this wasn't really a
scriptable via JavaScript so we most
notably had no way to get up
progress events so the user was uploaded
file and we would get no feedback on
what's going on and even worse the
process at the time when Damon shown
existence the status bar at the bottom
so the user had virtually virtually no
indication so what happened on the web
for a while we can enter the dark ages
people look for solutions and the way
happy to take anything coming along the
way and flash it was and this was a huge
step back from what we had in 1995 sure
we get file upload progress events but
dealing with these flash-based uploaders
was just a huge pain in the ass we had
to deal with us for a very long time
which is unfortunate then like Lisa
standard bodies started moving again
after kind of taking a break for quite a
bit and in 2008 they came up with this
xml httprequest level two which is
basically HX version 2 and they added a
bunch of new features they basically
give us the ability to file uploads
previously HX could do file uploads they
give us progress events for up and down
loads they gave us cross-site request
which is useful and they gave us a form
data interface which actually allows us
to create this multi-part formed at our
request when using HX very easily and
this is now part of the official hhx
petrification it was merged into the
main spec and it's good to go and in
fact it's actually widely implemented at
this point so seventy percent of all
browsers that people are using have
support for this API the most notable
exception is always Internet Explorer
didn't have it until version 10 but so
if you have to support file uploads
really well and Internet Explorer you
will have to go back to the dark ages or
do other unholy things but for all the
new stuff it works really well 2009 they
released another API as a file API
what's the file API does it basically
takes these file input elements and
gives them a new property called dot
files and this is essentially an array
of file objects there's a file interface
this gives you name and last modified
and a bunch of other informations file
size of the file and you can kind of
play with it it also gives you a way to
slice so you can say file that slice
right 100 to 200 and this returns a blob
what's important about this is the plot
that this point doesn't get loaded into
memory you just get a reference to it so
if you actually want to load it into
memory and breathe this data you have to
use the file
either interface kinda flower reader
interface takes a file or a plot object
and allows you to read the data in it's
a little weird but it works really well
and security Isis is also fine because
you only get access to files if you user
has selected them so you cannot just
take random stuff from the hard disk
what else so this is available and
sixty-five percent of all browsers again
the same limitation Internet Explorer
version 10 is where it starts so you'd
assume that by now everything is kind of
very good I'm actually one second get my
purse n denote the back so you would
assume that by now we have seized
powerful API and file uploading on the
web should just be amazing and so much
fun to do and easy but I don't think
that's the case I think we made a huge
amount of backwards progress in terms of
simplicity in 1995 we had an appropriate
amount of simplicity but we don't have
this anymore even worse we don't even
have two features while to implement we
could do these things but we don't have
them so let's take one example that I
find very important and this is the
sample of resume ability right now a lot
of file upload us on the web like resume
ability and by resume ability I mean you
get to ninety-nine ninety-nine percent
of an upload something happens and
basically the SU hey there was an error
can you upload this again and this is a
few lucky if you're unlucky the progress
bar just stops and doesn't tell me
anything it was kind of unacceptable and
I believe that this is actually the
major reason why millions of cat videos
get lost every year on the internet and
this is also a problem when you kind of
look at the landscape HD cameras are
everywhere now if you buy a new device
with a camera it will be HD and you get
these huge file sizes so a 45 second
video clip on iphone 5 is 100 megabytes
that's a lot of data and unfortunately
our app links are hardly keeping up with
this I mean they're a thing so the
download is usually faster than the
upload and so kind of slow so if you
have a Wi-Fi with a backing 5m bit
connection uploading this 45-second clip
takes you two and a half minutes it only
gets worse from here lt10 to be 340 edge
66 minutes this is terrible when you
consider that we're living in a world
where we can measure how 100
milliseconds make a difference in user
behavior and revenue so
you're looking at minutes here you don't
want to this up because if you
 this up people will not come back
to your site and if you run on a
business model like Facebook or Twitter
where you show these activity streams
you really need that content because I
don't go on facebook to look at walls of
text I look at the pictures people
upload and I look at the videos so you
really want to nail this so how come
does not be a solve problem and how
could we even do this so let's say we
want a sausage let's say we want to do
this how can we resume an HTTP upload
well whenever you have an HTTP you kind
of consult the ancient scripture and by
that i mean our see 2616 HTTP one at one
actually HTTP is a lot like ancient
scripture and the Bible so people
basically think they understand
everything and it explains the whole
world but they really they're just pick
and choose parts that they like and
probably even get so strong so um let's
htp doesn't say anything about uploads
but it says something about this kind of
similar range requests what range
requests do is they allow you to
retrieve a partial file from a web
server so you can send a header called
range and you can say i want to i don't
know first 100 bytes of a file and the
web server understands this it will
reply with the content range header that
kind of acknowledges that it's now
transmitting a part of this file so this
is good and it looks kind of like it
would be useful for uploads so companies
have started to use these headers for
uploads most notably YouTube they have
an API for resumable uploads and it's
based on the Google gears protocol and
they do a bunch of terrible things say
and then the new status code 308 resume
incomplete this is in violation of
upcoming specifications I guess if you
google you can invent status codes and
not bother to register them but I think
this ball gets him in trouble and it's
also an interoperability problem with a
lot of libraries and server side stuff
they use as I said it's the content
range and range chatters and unfortunate
part about this is they are also in
violation of upcoming specification so
they are working on the HTTP
specification again the HTTP bit working
group and one of the things they define
the set put requests which YouTube is
using must explicitly not use these
headers when they talk to a server so it
works but you really shouldn't do it
according to specification
and they also use put to query would you
scatter head for this to get the upload
status it's kind of weird API but the
last thing is kind of most important
they actually have two similar protocol
internally that's your use for google
drive it's also public API and it
actually looks a lot like the YouTube
protocol but it's slightly incompatible
and what's this says to me is that even
Google cannot figure out how to make
this work with HTTP they can make it
work but they cannot figure out how to
do it really well it's not it's not
solved so assuming that it's not really
solved in HTTP what else is kind of
around in terms of prior art there's ms
on a three which is big if you're
dealing with files on the web right now
they have a thing called multi-part API
which is the most terrible name ever
because it has nothing to do with
multi-platform data which is what prod
uploads to the web but or whatever what
it allows you to do is to send files and
chunks so you define the chunk size
let's say a few megabytes and then you
cut the file at these chunk intervals
and you make individual requests
uploading these chunks of the file and
protocols not entirely unreasonable I
mean sir API is a little weird but it's
doable one thing that's really sucks
about it this has a five megabyte
minimum chunk size so if there's a
network error you have to kind of go
back five megabytes in the worst case
and if you're on a mobile connections
that really has a lot of network errors
and it is very slow this may mean that
you never make progress you used to just
keep repeating the same chunk over and
over again it's not really ideal maybe
they can fix it maybe not um biggest
problem I see with Amazon s3 is that its
proprietary and this wouldn't be a
problem by itself but Amazon s3 has kind
of become such a force that open source
storage solutions has adopted the api's
just to be able to be compatible with
the existing ecosystem of client
libraries and this is really really bad
because we used to have an open standard
and protocol for this this was ftp
unfortunately ftp is not web technology
so nobody is using ftp anymore but now
that amazon s3 is kind of dominating the
way that we exchange files with web
servers people implement their stuff now
what happens if they want to make
changes to the protocol they cannot make
any changes that are incompatible
because then they lose the reason why
they chose to go down this route to
begin with
and what essentially happens to see have
to go to amazon and i think amazon has
literally zero interest to work on open
standards and to work with the community
and to work with anybody unless you pay
them a lot of money which is a
reasonable approach to business but it's
not really good approach to have an open
web so amazon has we even if the API or
protocol for resumable uploads was
create which should never be under
consideration what should you use if you
actually want to solve this problem
today and you just want to solve it with
JavaScript as inks this library is great
it's called resumable pjs it's actually
based on multi-platform data files are
split into fixed size chunks similar to
the s3 protocol you can choose your own
chunk size as as probably the best open
source solution that's out there right
now it works really well and say they
kind of define a protocol so you don't
have to kind of go through the steps and
figure out how to do it over HTTP like
you would do with other JavaScript based
uploaders unfortunately this is not to
find us a standard and this is not a
problem all you care about is solving
this problem for your little wet damp
and doing it only in JavaScript but it
creates a situation where we have seized
one thousand one week project of
solutions that barely work and just keep
repeating this stuff over and over again
and it just cannot compete with the
power we would have and the simplicity
we would have this was a standard so
what could happen first of all what's
addition observation is adding resumable
file uploads should take five minutes
instead of five hours I think that
should be the basic goal like the 1995
level of complexity in demo i was
showing we should be able to do this
life right now without using a huge
amount of external libraries and if it
said what's the case the future could
look like this is just but I
entertained the sword for a second we
could have a resumable attribute
informed and this would make a former
assumably upload a ball and then pull
the HX stuff you would also just have a
property called resumable on the HX
object and would make sure that on HX
request is resumable and so how can we
get to this future well unfortunately
nobody is working on this problem right
now nobody's working on anything for
resumable uploads so we kind of thought
ok let's start this project and we call
the toss today oh and what toss today oh
is it's an informal working group to
resume resumable file uploads over HTTP
this is a fancy way of saying that we're
a bunch of people on github and
everybody can join and help we are also
a collection of open source project that
implements the draft specifications we
do this for HTML iOS and Android as well
as server side platforms like noches go
Ruby Python PHP etc and the reason we do
this at this early point is to just see
if what we are defining makes sense if
it's portable and if the end result is
something that's nice and that we would
want to use the goal for this is to
publish this as an internet Engineering
Task Force standard as an RFC and if we
could get there to this point the future
could be really nice because then
languages could just thought start
building this into the back end and when
you use file uploading it will always be
resumable on the back end you don't have
to worry about it its built-in same on
the front end you'll just have the stuff
available maybe in web browsers maybe
you have to use the library but it will
just be much easier and there will be
one way to do it you will not have to
ask yourself am I using the right HTTP
headers am I doing this correctly and we
can also do this for mobile I mean
people here don't want to develop mobile
apps finish our script conference but if
you do native mobile you also need a way
to do this and maybe your company has to
shoot all kinds of apps native web and
native mobile so it's good to have a
protocol so what does all protocol look
like I'll just go over it real quickly
at this point we have this protocol
where you do post request against a
well-known URL you can define this
anything you would like here we use /
files then you use two headers content
lengths which is an existing header you
sub set to 0 and final lengths which is
a new header we're proposing which we're
setting to 100 here what this means is
we're essentially creating an empty file
on server and with letting the server
knows that we are intending to upload
100 bytes into it so its final length of
this file will be 100 bytes but we're
not uploading it yet which just asked me
to server to create the mt resource and
the server responds with the location
header saying hey I created this
resource for you at / files / one for
example we just get a fully full
absolute view ALB and then we can start
the actual upload and the upload would
be done with a pet request if you're not
familiar with patch it's a new HTTP
methods that we specified or released in
2010 Realtors now heavily adopting it
and it's meant to modify
files without completely replacing zamp
so the tube partial in place
modification of resources and so we
would do a pet request again / file / 1
which is ul we get from the server and
what we would do by default is try to
upload the whole thing so we did
content-length to 100 offset 20 I'll
talk about this in a second and then we
just sent a whole file if this succeeds
we receive a 200 ok status code if this
doesn't didn't work we have to ask the
server how much data received because on
bsd sockets and most most libraries we
reduce we do not gets information how
much data was actually sent across the
wire successfully and if it was received
do we have to ask the server so we would
do a head request to doing that so we do
a head request again / file / one which
is our ul and thence the server could
reply with an offset header which would
tell us how many bytes did you receive
so in this case the server's like hey I
received 70 bites and something terrible
happened so now we can use this
information to do another pet request
and now we set to Compton like 230 and
see offset 270 and this basically allows
us to upload the remaining 30 bites and
the server will know where to apply them
it's pretty simple we're also as I
mentioned lamenting clients and servers
we have a reference implementation go
because I want to play with this we have
the noche s server that was imminent
contributed by narrow and from return to
community we have jquery iOS and a
Python client and if you want to play
with this in kind of experiment if you
want to do this for Ruby or some other
language go ahead and edit to this page
but really interesting and see more
stuff we also have an idea for an
alternative protocol I'll just go over
this really briefly it would also be
possible to take a more form centric
approach and deal with the fact that
forms consist of multiple fields and
kind of broaden the scope of this
project a little bit the benefit of this
is that we could be compatible with the
alt request and we could potentially
make it this more seamless upgrade where
you don't have to completely change the
way you upload stuff there's good end up
more complex but potentially also more
powerful we'll see if we go this route
for now the other thing that I showed
you looks like the most promising
candidate another thing we're really
interested in is upload
acceleration we want to explore how we
can make file uploads faster and the
idea behind this is set tcp performance
over multiple mobile networks is not
always ideal and this really depends on
many many factors it depends on the
congestion window package loss link
layer latency and it's really complex
subject I mean you would assume that for
example the TCP protocol takes care of
resending lost packages and you can
build a mental model of the network
based on this but it's actually not the
full truth when you go to mobile
networks for example LTE it will
actually do similar things on a link
layer so LTE will actually recent
packages on the link layer IP packages
so when you're trying to model this on
how it TCP work it's just not going to
work what I'm saying is this is very
complex but it's also very likely that
TCP doesn't always choose the optimal
window size to get optimal throughput
and so there may be benefits to using
parallel requests and parallel
connections for single upload this would
mean extending our protocol a little bit
because the server will need to reply
with multiple offset but it's something
we want to explore before we want to add
such complexity we want to study this on
the real world conditions so we want to
create a little app or something where
people can try this out all over the
world under different network conditions
and we can actually get a lot of data on
the different upload methods and see if
there's actually performance benefit I
think we can show a little demo of what
this looks like so on right now when you
go to toss that I oh and you click on
demo you have this little demo uploader
which implements the current protocol
it's using the jQuery client and the go
server and we can choose a file here
that was too big let's choose a smaller
file
come on demo gods if resumable uploads
should work actually hang on a second I
need to rename this file
right
okay so we have this upload here and now
let's interrupt it we could force a
network error here but we could also do
something different closing the browser
this essentially kills the upload
connection but it's actually an
interesting use case because it was
killed by the user the user became
impatient and just close the window and
now if we came back to test today oh and
we go to demo we click to choose file we
can select this file again and we're
lucky it continues to upload right where
we left off how does this actually work
how does it know where to resume once
the browser was closed because that
state has to be kept somewhere what we
were doing for this is we were using the
protocol for one but also when if pile
is selected we take the file name file
size and last modified field and we
combine these into an ID for the file
and we take CC IDs and we maps them to
the URLs that we get from the initial
post request so we creates a file with
post we get a location header with the
URL and then we take local storage and
we use a file id as defined up here and
we map it to the upload URLs that we got
and what this basically allows us when
somebody's like to file again we'll know
that this file was already the upload
already started before and we know the
URL for it so we can do a head request
to inquire how much data is there and
where we need to continue this is not
perfect but it's simple by not perfect I
mean it's conceivable that somebody has
a flower was the same name sighs and
last modified time on his disk and he
wants to upload both of them on the same
size I don't think it happens a lot so I
think it's reasonable for now but if it
does happen a lot and we need to deal
with it we can improve this by actually
using a sha-1 checksum for the file ID
this is kind of a little slow still but
I think this is going to get lost faster
things to stuff like smgs has everybody
seen a SMS where's the end ok cool
everybody knows this so this is this and
other JavaScript engine optimizations
are going to make check sums viable very
soon um I think we're almost done here
beach time ah you should join us if you
care about resumable uploads and you
care about doing it right and not just
doing these one-off solutions anymore
and kind of fix a WEP a little bit
better so this is one project to help us
with
we're already seeing some interest from
bigger companies as well for example
vimeo came out and one of the developers
is working with us they're using a AP I
very similar to what YouTube is using
right now and say sees the same problem
with it that it's kind of taking HTTP
and abusing it in a way it's not
supposed to be used so they are
interested in working with this one of
the developers is helping out and I
think there's a good amount of interest
from the community of all that's it
questions
I have a question can we go to the beach
now okay so the question is if we also
include progress events know our our
protocol is basically just the network
protocol so the progress depends on the
API you have if you have JavaScript used
to javascript stuff of xhr too if you
are native you use iOS libraries and
callbacks whatever you have but it's not
part of all right is there a reasonable
expectations that the partial upload
will stick around for a while that's a
good question so one problem is that
somebody starts uploading a file then he
close this browser and he comes back two
years later and once to resume the
upload do we keep the partial file
around for two years I think this goes
potentially a little outside of the
protocol itself but i think the protocol
will include the sections that makes
recommendations for how long to keep
files around I don't know if we need a
way to negotiate this between client and
server because if the file is not there
it basically gets a poor for when it
does the head request and then it just
starts the upload again so it's not a
deal breaker so the server can decide
how long to keep the fault
okay the question is what happens if i
send patch requests for somebody else's
upload the answer to that is first you
should use this over HTTPS if you care
about security and then you should use
your l's when you do the post request
it's up to you to return a random URL or
like how to guess URL so just use a uuid
or something in your return location and
I think that should make covers a
problem entirely alright let's go to the
beach thank</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>