<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>James Kyle: From Zero To Binary Search Tree - JSConf.Asia 2016 | Coder Coacher - Coaching Coders</title><meta content="James Kyle: From Zero To Binary Search Tree - JSConf.Asia 2016 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>James Kyle: From Zero To Binary Search Tree - JSConf.Asia 2016</b></h2><h5 class="post__date">2016-12-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bM5Wfmh9i5k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">ah there we go hi jas conf Asia I'm
James Kyle i work at facebook i work on
the flow team where we're trying to make
developers happier and more productive
writing JavaScript so that you can all
go out and write more code that we need
to install I also started this project
called Babel which was designed to
convince people they need to install 400
packages so that just so they have
pretty-looking syntax I also helped
build this project called learner so
that's easier to create a bunch of
packages that need to be installed and
then finally I helped launch this
project called yarn which takes the four
billion packages we just created it
makes it way faster to install them
anyways if you wanna make a bad decision
you can follow me on twitter at the
james Kyle this is my first time in
Singapore and I must say it's really
freaking hot I'm dying out there I'm
from Boston so I'm much more comfortable
in weather like this yeah anyways so I
know what you're probably thinking data
structures are awesome and you're right
because they're very important not just
to pass computer science 101 but in
order to be a better programmer knowing
your data structures can help you manage
complexity and make your programs easier
to follow and build highly performant
memory efficient programs the first of
those is I believe to be more important
using the right data structure can
drastically simplify what would
otherwise be really complicated logic
the second point is important too if
performance our memory matters then
using the right data structure is more
than often essential so what are data
structures essentially they are
different methods of storing and
organizing data that serve a number of
different needs data can always be
represented
many different ways however depending on
what your code or what your data is and
what you need to do with it one
representation will pretty much always
be a better choice than the others to
understand why let's first talk about
algorithms algorithms is just a fancy
name for a step-by-step set of
operations to be performed data
structures are often implemented with
algorithms and algorithms I'm go to data
structures and just data structures and
algorithms all the way down until you
reach the tiny microscopic people with
the punch cards that control the
computer yeah it's not by code it's it's
it's these people any given task can be
implemented an infinite number of ways
so for common tasks are often many
different algorithms people have come up
with for example there is an absurd
number of algorithms for sorting a set
of unordered items there's insertion
short there's selection sort merge sort
bubble sort heap sort quicksort
shellsort Tim sort bucket sort and
there's more but you get the point some
of these are significantly faster than
others some use less memory some are
easy to implement some are based of
assumptions about the data set every
single one of these will be better for
something so you'll need to make a
decision based on what your needs are
and for that you'll need a way of
comparing them a way to measure them
when we compare the performance of
algorithms we use a rough measurement of
their average and worst-case performance
using something called big o big o
notation is a way to roughly measure the
performance of algorithms in order to
compare them against one another when
discussing them Big O is a mathematical
notation that we borrowed in computer
science to classify algorithms by how
they respond to the number of items that
you give them there's two primary things
that you measure what they go there's
time complexity which refers to the
total count of operations and algorithm
will perform for a given set of items
and then there's space complexity which
refers to the total memory and algorithm
will take up when running
on a given set of items we measure these
independently from one another because
while an algorithm may perform less
operations than another it may also take
up way more memory depending on what
your requirements are one may be a
better choice in the other so these are
some of the common big O's we have their
name and their number or notation and
how you feel when they show up at your
party uninvited first you have constant
or 0 1 which means it's always going to
take the same amount of operations and
when you see this friend walk in your
leg we need to take a selfie right now
the next is logarithmic or o log of n
which means the number of operations
increases very slowly as you add more
items and when this shit friend shows up
your leg hey let me get you a drink
let's do this up next is linear or 0 n
which means the number of operations
increases at the same rate as a number
of items and when this person shows up
you're like oh hey how's it going it's
been a while we should catch up later
when you're done running next is linear
if Mick or a log at our 0 n log of n
where the number of operations increases
a bit faster than the rate that linear
does and when this person shows up
you're like who brought them they smell
like soup next is polynomial or 0 n to
the power of 2 where the number of
operations increases exponentially and
quickly gets to be too many when this
person shows up you get all in their
face like salty you're like I don't
remember inviting you I was like really
drunk the other day so maybe I did
invite you then but didn't want you here
and last is factorial or 0 factorial of
n where the number of operations just
shoots like straight up getting into the
billions and trillions and quadriplegic
aliens really really fast and when this
person shows up and you're like
I invite you for a very specific reason
and that reason is I hate your guts so
bye I'm a very mean party person to give
you an idea of how many operations were
talking about let's look at how these
would equal what what these would equal
for a given set of items with five items
nothing is really that bad small number
and we can do lots of operations so but
by 10 items you're already got a pretty
big difference for polynomial starting
the millions of operations but
everything else is mostly acceptable
next ship 20 and it's getting absurd and
then by 30 polynomial is just just
ridiculous and you can already see how
the other ones of those are already
getting to be pretty large numbers for
what could be like pretty low numbers so
with data structures you have four
primary types of actions that you can
perform in sess search insert or delete
and it's important to note that data
structures may be good at one of these
things and not at another and so here
you can see three common types of
ordered data structures arrays linked
lists in binary search trees and you can
see their average time complexity for
the most common operations and here's
them with our party descriptions even
further some actions will have a
different average performance in a
worst-case performance meaning they
perform very differently depending on
the type of data set and sometimes
random things are thrown in there but
there is no perfect data structure and
you choose one over the other based on
the data that you're working with and
the things that you're going to do with
it this is why it's very important to
know a number of different common data
structures so that you can choose from
them and know what you're getting
yourself into a computer's memory is
pretty boring it's just a bunch of
ordered slots where you can store
information you hold on to memory
addresses in order to find information
let's imagine a chunk of memory like
this if you've ever wondered why things
in programming languages are zero index
sort of works kind of like memory in
terms of like it starts at zero but ends
at one so that's like the first item and
so when we're reading a block of memory
we're reading the space between 0 and 1
or 1 and 2 and so on your computer
obviously has way more memory than this
we have to have some space to store all
that JavaScript cached by code but it's
pretty much a continuation of the
pattern above memory is a bit like the
Wild West every program running on your
machine is stored in this same physical
data structure and without layers of
abstraction over it it can be pretty
difficult to use and these abstractions
serve two additional purposes storing
data in memory in a way that is more
efficient or faster to work with and
storing data in a way that makes it
easier to use so now that we've covered
a lot of the basics I want to dive into
some actual data structures and we're
going to quickly cover lists hash tables
stacks queues graphs linked lists trees
and binary search trees we go through a
lot of stuff and don't worry about
understanding all of this code it's
really only there to act as an aid to
the things that I'm saying they're not
even like really feature complete
implementations so don't really worry
about it but let's get into it so to
demonstrate the raw interaction between
memory and the data structure we're
going to first implement a list list is
a representation of an ordered sequence
of values where the same value may
appear many times because lists have an
order you can insert insert stuff at the
start middle or end of them for our
implementation we're going to focus on
adding and removing values from the
start and end of our list using these
four methods push pop on shift and shift
which you should hope all hopefully be
familiar with because I'm assuming most
of you write JavaScript since you're
here
starting with push we need a way to add
items to the end of our list actually
skipped a bit here let me go back sorry
we're gonna in our list we're going to
start with a empty block of memory which
we're just going to represent with a
JavaScript array and we're also going to
store the length of the list note that
we want to store the length separately
because in real life memory doesn't
really have a length that you can read
from so you want to remember that so
starting with push we need a way to add
items to the end of our list it's as
simple as adding a value to the address
at the end of our list and because we
store it the length it's easy to
calculate we just add the value and
increment our length pushing an item to
the end of the list is constant next we
need to wait to pop items off the end of
our list similar to push all we need is
to remove the value at the address at
the end of our list and then just
decrement the length popping an item
from the end of list is also constant
push in pop both operate on the end of
the list in our overall pretty simple
operations because they don't need to be
concerned with the rest of the list but
let's see what happens when we operate
at the beginning of the list with
unshifted shift in order to add a new
item at the beginning of the list we
need to make room for our value we can't
just keep going past the beginning of
memory so we do this by shifting all of
the items in our lists over by one in
order to slide all of the items over we
need to iterate over each one moving the
previous value over because we have to
over iterate over every single item in
the list on shifting an item from the
start of a list is linear so that o n
first we start with the value at the
beginning the list we iterate through
each item replacing the current value
with the previous value and storing the
current value for the next iteration and
then finally we just add the last item
new position which is the start of our
list and increment length finally when
you write a shift function or to move in
the opposite direction we delete the
first value and then slide through every
single item in a list to move it down
one address shift is pretty much
identical to on shift except backwards
so the code is very similar and again
shifting an item from the start of the
list is linear so lists are great for
fast access and dealing with items at
the end of the list however as we've
seen it's not great at dealing with
items that are not at the end of the
list and we have to manually hold on to
memory addresses so let's take a look at
a different data structure and see how
it deals with adding accessing removing
values without needing to know memory
addresses so we'll talk about hash
tables so hash tables don't have any
order to them instead we have keys and
values or a computed address in memory
is its computed by the using the key so
this is exactly what objects are in
JavaScript the idea is that we have keys
that are hashable which we'll get to in
a second and can be used to add access
and remove data very efficiently again
we're just going to use a plain
JavaScript array to represent our memory
in order to store key value pairs in
memory from our hash table we're going
to need a way to turn them into an
address we do this through an operation
known as hashing all that happens is it
takes a key and serialize it into a
unique number for that key you have to
be careful though if you had a really
big key you don't want to member match
it to a memory address that doesn't
exist so the hashing algorithm needs to
limit the size which means there's a
limited number of addresses for an
unlimited number of key value pairs the
result is that you can end up with
collisions
places where two keys get turned into
the same address any real world hash
table implementation would have to deal
with this however we're just going to
kind of glaze over it and pretend that
doesn't happen so let's set up our hash
key function don't understand don't
worry about understanding the logic of
this function just know that it accepts
a string and outputs a mostly unique
address that we will use in our other
functions next let's define our get
function so that we have a way of
accessing values by their key hash table
access is constant yeah so we turn the
key into an address and then get that
address we also need a way of adding
data before we access it so we create a
set function that inserts value that
does basically the same thing except
setting at this time and setting and a
hash table is constant friendly we need
a way to remove items from our hash
table which is just deleting the value
at the memory address that was
calculated by our hash key function in
this operation is also constant from
this point forward we're going to stop
interacting directly with memory as the
rest of these data structures start to
be implemented with other data
structures these data structures focus
on doing two things organizing data
based on how it's used and abstracting
away implementation details these data
structures focus on creating an
organization which makes sense for
various types of programs they insert a
language that allows you to discuss more
complicated logic all well abstracting
away implementation details so that the
implementation can change to be made
much faster so stacks are similar to
lists in that they have in order but
they limit you to only pushing and
popping values at the end of our list
which as we saw before are very fast
operations when mapping directly to
memory however stacks can also be
implemented with other data structures
in order to add
functionality to them the most common
usage of stacks is places where you have
one process adding items to the stack in
another process removing them from the
end prioritizing the items that were
added most recently we're going to again
be backed by a JavaScript array but this
time it represents a list that we
implemented before and rather than the
memory that we were using often times
people don't implement it with a list
but we're going to you for the sake of
this and we're going to implement the
two functions from lists push and pop
which are going to be identical in terms
of functionality we push items to the
top of the stack and pop items to remove
items from the talk of the top of the
stack we're also going to add a function
just in order to view the item at the
top of the stack without removing it
from the stack next we're going to build
a queue which is sort of complementary
to a stack the difference is that this
time you remove items from the start of
the queue rather than the end removing
the oldest items rather than the most
recent again because this limits the
amount of functionality there are many
different ways of implementing it a good
way might be a good way might to be used
a linked list which will see a little
bit later again our queue is just using
a JavaScript array rather as a list
rather than memory similar to stacks
we're going to find two functions for
adding and removing items from the queue
the first is NQ that will push items to
the end of our list in DQ which instead
of removing them from the Edit list
we're gonna remove them from the start
and you could see we're using the shift
function there which as I mentioned was
not very fast but we're abstracting away
to this functionality so that it could
be implemented in many other ways and
again we're just going to find a peek
function from viewing the next item the
queue the important thing to note here
is again that we use a list of a car q
in
that performance of shift and you can
use a linked list which we'll get to in
a few seconds the next station structure
is graphs note that these are very
different than a visual graph that you
would use to represent data instead
imagine it like this we have a bunch of
nodes ABCD and E that are connected with
lines that sort of point to one another
these nodes are going to look like this
where they have a value and a set of
lines that they're pointing to other
nodes and the entire graph will look
like this and it's going to just have
all the nodes which will contain
references to one another will hold on
to all of our nodes in a regular
JavaScript array not because there's any
particular of order to the nodes but
because we just need a way of storing
them as references for everything we can
start to add values to our graph by
creating nodes without any lines next we
need to be able to look up nodes in the
graph most of the time you'll have a
different data structure on top of the
graph in order to make searching faster
because otherwise you're just searching
through every single node and that's
kind of slow but for our case we're just
simply going to go through every single
node that we have and try matching the
value next we can connect two nodes by
making a line from one another we're
going to find the nodes for each value
that we have and then we're going to
freak out if we don't have one on the
other and finally we're going to add a
reference to the end node from the start
node finally you can use a graph like
this this might seem like a lot of work
to do very little but it's actually
quite powerful pattern especially for
finding sanity and really complex
programs they do this by optima
optimizing for the connections between
data rather than operating on the data
itself once you have a node in the graph
it's really simple to find all the
related items in the graph
tons of things can be you can be
represented this way users with friends
the 800 transitive dependencies we have
in a node modules folder the internet
self is a graph of web pages connected
together by links in next we're going to
see how a graph like data structure can
optimize an ordered list of data linked
lists are a pretty common data structure
it's often used to implement the other
data structures as I mentioned before
because of its ability to efficiently
add items at the start middle or end of
list the basic idea of linked lists is
similar to a graph you have nodes that
point to other nodes that sort of look
like this and visualizing them as a data
structure that looks like this where we
have the value that points the next
value which point to the next value but
what's the next one unlike a graph a
linked list has a single node that
starts off the entire chain this is
known as the head of the linked list
we're also going to drink the track the
length of the list here oops first we
need a way to retrieve a value for in a
given position this works differently
than normal list because we can't just
jump to the correct position instead we
need to move through the individual
nodes will start with the head of our
list and then slide through all of the
items using node next until we've
reached a specified position and then
we'll just return the node that we found
next we need a way to add nodes to a
specified position we're going for a
generic add method that accepts a value
into position first we create a node to
hold our value and then we need to have
a special case for nodes that are being
inserted at the head will set the next
field from the current head and replace
it with our new node otherwise if we're
adding a note in any other position we
need to splice it in between the current
node in the previous node so we just
sort of like split it apart and link it
back together
so we find the previous node in our
current node we insert the new node in
by between them by setting its next
fields the current node and updating the
previous nodes next field to the new one
and then finally we just increment the
length the last method we need is a
remove method we're just going to go
look up a node by its position and
splice it out of the chain again if
we're removing the first node we simply
need to set the head to our new to the
next node in the chain for any other
position we need to look up the previous
node and set it to the node after the
current position and then we're just
going to decrement the length so the
remaining two data structures we're
going to cover are both in the tree
family much in like real life there are
many different types of trees like a lot
little did you know you'd be studying
dendrology today and that's not even all
of them but don't let this scare you
most of those don't matter at all there
was just a lot of computer science PhDs
who had something to prove trees are
much like graphs or linked lists and
that they are you need directional all
this means is that I can't have loops in
their references if you can draw a loop
between connected nodes in a tree well
you don't have a tree you have a graph
trees have many different use cases they
can be used to optimize searching or
sorting they can organize programs
better they can give you a
representation that's easier to work
with we're going to start off with a
extremely simple tree structure it
doesn't have any special rules to it and
it looks something like this where we
have a root and a value with children
with values and more children so when
they keep going that way the tree has to
start with a single parent or the root
of the tree we need a way to reverse our
tree and call a function on each node in
the tree will define a walk function
that will call recursively on
every single node in the tree it'll
first call the callback on the node and
then recursively call the walk function
on all of its children and then we just
kick the traversal process off at the
root next we need a way to add nodes to
our tree first we create the node that
we're going to add if there's no route
we just set it to a new node otherwise
we traverse the entire tree and find a
node with a matching value and add the
new node to its children so this is one
of the most basic trees that you could
possibly have it's probably only useful
if the data you're representing actually
resembles a tree identical to this but
with some extra rules a tree can serve a
lot of different purposes binary search
trees are a fairly common form of tree
for their ability to efficiently access
search insert and delete values all
while keeping them in a sorted order
imagine taking a sequence of numbers and
then just turning them into a tree
starting from the center this is how a
binary tree works each node can have two
children the left which is less than the
parent nodes value and the right which
is greater than the parent nodes value
note that in order to make this work all
values must be unique in the tree you
can't have two fives because they would
fall in the same position this makes
traversal to find a value very efficient
say we're trying to find the number five
in our tree we go start at four and we
say five is greater than four so we move
right five is less than six so we move
less and then boom we reach tree or
reached five notice how we only had to
do three checks to reach the number five
if we were to expand this to a tree of
1,000 items we'd go 500 to 250 to 125 to
62 230 12 15 27 23 24 25 and that's
sound like a lot but it's only ten
checks to go placed in 1,000 items
and while it would have been faster if
we just went 1 2 3 4 5 in general if we
were going to 999 that would have been
909 checks down to 10 that's where 0 and
comes from the other important thing to
note about binary search trees is that
they're very similar to linked lists and
that they in the sense you only need to
update the immediately surrounding items
when removing or adding or removing a
value so same as the previous tree we're
going to have a root of our binary
search tree in order to test if a value
exists in the tree we're going to need
to first search through the tree we
start at the root and then we're going
to keep running as long as we have
another node to visit if we reach a left
or right that is no then this loop ends
and we assume that we did not have
anything in the tree if the value is
greater than the current value we move
to the right if the value is less than
current value we move to the left
otherwise if it's not greater than or
less than it must be equal to and so we
return true if we not have if we haven't
matched anything then we return false
that's how we implement contains in
order to add items for the tree we're
going to do the same sort of traversal
as before bouncing between left and
right nodes depending on them being less
are greater than the value that we're
adding however this time when we reach a
left or right that is null we're going
to add a new node in that position first
let's set up our node well special case
for when there isn't any root node so
that we just add one and return
otherwise we start at the roots and
we're going to loop until we've either
added our item or discovered that it
already exists in our tree if the value
is greater than the current value we
move to the right if the right does not
exist we set it to our node and stop
traverse
otherwise we just continue on to keep
searching the right node if the value is
less than the current value we move to
the left now we do the same thing where
we check if it does not exist we set it
to our node and stop traversing
otherwise we just move on to the left
node if the number isn't less than or
greater to then it must be the same and
so we don't do anything we just break
and stop and the note isn't added
because it's already exists and that's
all all the different data structures if
you want to read this code and review it
again you can go to this URL I have a
whole guide on it contains mostly same
content you can also check out some of
my other works I wrote about a compiler
a super tiny compiler that you can go
see here because of my work on babble I
also wrote a Babel handbook that you can
also check out anyways now we're
actually done I'm James Kyle follow me
on twitter at the james Kyle</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>