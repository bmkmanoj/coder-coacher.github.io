<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[JSConfEU 2010] Kris Kowal: CommonJS, I Promise | Coder Coacher - Coaching Coders</title><meta content="[JSConfEU 2010] Kris Kowal: CommonJS, I Promise - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>[JSConfEU 2010] Kris Kowal: CommonJS, I Promise</b></h2><h5 class="post__date">2013-06-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IbDF3UdgOb0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome and Jason brief is a sort of
strange confluences of people whose name
starts with k andar Chris I think there
are three of us it's really weird but
there's Chris's eyes and Chris Walker
and me which makes the mailing list a
bit confusing but that which brings me
to the point commonjs is a mailing list
and a wiki and our Charter is to develop
specifications for JavaScript ad hoc
from from the grassroots for contexts on
the browser and outside of the browser
and beyond we started about two years
ago by Kevin Dan goor with a blog post
and there are first our first thing that
we did was we constructed a module spec
which was probably most noted because
node implemented it pretty quickly on
and it's certainly the the widest
deployment of it it's but not the only
there's also Narwhal gypsy whole bunch
of server-side embeddings also in the
browser for by a few so the perp the
purpose for the group originally last
year has been really quiet for common
j/s the group was originally started
because there were a whole bunch of
server-side JavaScript frameworks that
we're not really taking off and the
Kevin's theory at the time was that the
reason they weren't taking off was
because it was kind of pointless to
write JavaScript for any single one of
these sort of somewhat cramped platforms
because he really couldn't you could
there was no escape route you couldn't
go to a better system if you could if
you found one there was no degree of
interoperability they were just you just
have to rewrite it every time you move
to a new platform so he started the
group to work on some of the basic
standards that we would need for
server-side in systems programming
things like a module has a basis for
everything packaging binary data file
systems and IO within the so we worked
pretty hard the first year to get
file systems and binary and stuff like
that worked out but we were going to go
in the wrong direction and node sort of
proved doubt that that we really need to
look into a synchronous file systems in
i/o before we start writing and actually
get some asynchronous implementations in
JavaScript before we start standardizing
them and was it was an easy trap to fall
into because i was there are so many
well vetted synchronous file system API
is on the server we figure is pretty
pretty well researched prior art and so
we just took those and found the best
things of them and tried to make the
very best synchronous file system API
there could up that there could ever be
and put it in JavaScript and I think
that a lot of that work is still useful
at this point but I'll get to that about
promises and the second half of the
presentation but yeah so the actual
problem turned out to be that there
weren't any JavaScript server-side
implementations that were interesting
enough to use that could differentiate
themselves from from Java from other
programming languages and implementation
languages on the server side and the
last year has really proven that out so
what makes a good spec what are the
things that common Jason come in here
should be talking about and
standardizing as a pretty pretty common
question we get there there's for the
last year we've really stepped back and
let let things happen in the foreground
which is just focused on some very core
some very core proposals but but the
Charter is very much the same we still
need to get out there and have specs for
the whole spectrum of things so that
there can be there so that they're still
can be an escape route and a degree of
interoperability to the to the sense
that it makes sense for there to be
interoperability like if you have a
package of code that has absolutely no
dependence on Io it makes sense for
there to be like a markdown package that
just works in the browser and works in
the works in the client and no
difference so that yeah so working it in
that way so what makes a good a good
specification is a
and it has to there have there has to be
compelling reasons to write a spec
because it's ten times harder to write a
spec and get a whole bunch of people to
agree on agree on it and it's not nearly
as fun as hacking arguing with people is
a real real pain so it really has to be
worthwhile and what makes it my suspect
worthwhile is if it builds a new
ecosystem where a whole bunch of code
can be written to be interoperable
modules was a very obvious place for
that basic asynchronous i/o by basic
asynchronous programming constructs are
another big one that that area hasn't
settled so the so what makes a bad
specification is specifying something
that people don't agree on in the first
place and there's a lot of room for
experimentation so modules are sort of
done ish and then we're moving on to
packages packages are the next big thing
that makes sense for common gs4 first
sink for building new ecosystems of
stuff so we have a stopgap proposal for
packages called one point o this
proposal doesn't really define any
behavioral requirements it's sort of
like I don't know if you've ever been in
America we have the Liberty Bell it's
this gigantic Bell that had a crack in
it really early on and just kept on
getting worse every winter and they
drilled little hole a little hole at the
end of the crack to relieve the pressure
so that the crack wouldn't grow any more
packages one point O is sort of like
that and less about actually
guaranteeing any degree of
interoperability with packages in the
skywriter talk upstairs they talked
about just being able to give a common
J's package and use it on the use it on
the browser and the fact of the matter
is that at the moment there are packages
for Narwhal there are packages for NPM
and their packages for for jet pack and
bet on sky writer and none of them are
actually interoperable but they do have
the packages one point o in common which
prevents them from diverging too much
away from eventually of being able to
specify their dependencies in a
meaningful way the packages spec just
reserves a bunch of names for things for
metadata about packages so that
eventually we can have an eco
them that can analyze that data and use
it for installers and stuff like that
but Michael Rogers has been been pushing
for for the last year on new packaging
spec and there are three major proposals
for extending packages for handling
dependencies one of them is approached
by NPM the four node by Isaac shooter
there's another I wrote 12 years ago for
a narwhal called tusk and it had a
repository format as well and then there
which is based off of this concept of
overlays and then there's a third method
but it's being presently promoted by
chris's ID and as embodied and
implemented through this node package
called nodules so there are three major
approaches there's overlays mappings and
linking by version through a registry
and none of them are really perfect and
we still have a lot of a lot of room to
experiment with these things let me
describe some of the problems and
benefits of each of these those
approaches the the overlay approach is
similar to Ruby that's what we used in
narwhal and tusk and the the way it
works is that it that the package
manager is responsible for installing
your packages and predictable locations
and then Narwhal discovers all of those
package locations upon initialization
which takes an unreasonable amount of
time in rhino anyway and the way it
works is that it it goes into your main
package directory and then does a
breadth-first search of the packages
directories of each package that is
contained in that package transitively
it discovers all of those packages and
then looks at its dependency mapping and
does a topological sort which linearize
is all of the packages out and
constructs a require paths array so that
it knows so that are well knows where to
search which directories to search for
each of the each of the modules in all
of the packages the problem with this
approach is that it conflates the module
name spaces of all of the installed
packages than one of the advantages of
the approach is that it really makes it
easy to enjoy
act engine specific code anywhere along
the way and it also makes a really great
composition mechanism if you have
something like Django apps in JavaScript
where you can have a media a media
directory tree that can be searched for
the most relevant stuff and you can
stack it on top of each other and
override lesser versions of that
information that's the narwhal approach
and it's 1 and n p.m. is the second one
really and the way it works is that it
creates symbolic links in a common
directory so the difference in approach
is that node does nothing at run time to
discover anything about packages there's
only a single directory that contains
the entire module tree or a small number
of them in a fixed require paths and the
way the way it works is that the package
manager is responsible for telling the
entire system the names of every package
and how to find them by using symbolic
links so and and then thunk modules that
alter the require paths as as you call
through require which is a major
disadvantage of the approaches that
require behaves differently when called
in different terms of the event loop so
you really can't use that approach
reliably when you have multiple versions
of a particular package and ND recalling
require at funny times which has largely
not been a problem for the node
community yet I'm sorry
so Michael points out that that because
requires synchronous during the context
of the require call your required odds
will be consistent I'll think about that
a little bit more you just have to be
very careful about anything where state
is captured in your stack because it
tends to vary from from turn to turn the
other so the other disadvantage of this
approach is that whenever you install a
package well it establishes a race for
naming packages there's a gold rush for
the good names going on in the node
community right now and ever and the
collective consensus of everybody who's
chosen a name is reserving names in your
in every packages in every programs
namespace effectively which makes for
unpredictable unpredictable composition
problems down the road possibly I really
like the idea of having sovereignty at
various layers of of naming conventions
so that people in different roles have
the ability to give names to things in
their own scope so they have absolute
control and one of the at I think of it
as the the in a particular module your
local scope should be sovereign to you
you should not be you should not be
subject to other people giving you other
global variables in from from other
modules you should have absolute control
over the local variables in your scope
similarly at the package layer where
people are composing pieces of larger
chunks of codes that have been produced
by different developers you want to have
sovereignty of earlier module namespace
and ultimately you want to defer all of
the responsible are all of the
responsibility to for for naming things
to IA na or just to urls in general so
that you don't have to mediate conflicts
and naming by talking to people who have
authority you talk to get your domain
and put it up it's at there's
conflict but in any case so those are
the major three approaches and we're
still continuing experimentation with
them I imagine at this point that what
while it may seem like designed by
committee sort of end result where you
have little bits and pieces of each of
these approaches I think each of them
has their own merits and demerits and
disadvantages so down the road I imagine
that that the the packaging approach
that we ultimately use will be a hybrid
of these approaches where easy is simple
and the long out problems are solvable
so that's packages we also talked about
binary in the first year we talked about
binary in the context of making binary
data types that resemble the rain string
so that we could use to narrow City to
our advantage and also because there are
good security properties of strings you
can give a string to somebody and
they're guaranteed immutable by both the
consumer and producer so we have that
layer of abstraction for Strings and
also it also was made to come
accommodate older versions of browsers
the idea was that people not browsers
but older JavaScript engines the idea
was that it could be implemented in pure
JavaScript without involving the
embedding which made it slightly of
compromise with fast forward a year node
has given us a buffer type so I went and
took that and codified it and made some
made some changes and revised the design
and that's the binary F specification so
node as essentially a command GS
compliant buffer by virtue of being the
inspiration of the spec and and and
everybody else has one now now too now
the neat thing about the the binary
specs is that we have this more abstract
byte string and byte array specification
binary be and we have the buffer
specification the more abstract one is
easily implementable even including
possibly campeon right semantics in
terms of the lower level buffer the
problem with buffer is there are a lot
of problems with buffer if you ever
introduced
if you if you ever tried to use node in
a secure way there's a buffers are
they're never there never blanked out on
initialization for because that would be
a performance cost that note doesn't
want to make but that means that if you
have multiple distressful distrusting
parties running in the same process
through javascript which is a dream that
is reliable I zabal through akma script
five and harmony forward you won't be
able to use buffers in those contexts
because the there would be potential of
binary garbage data linking into those
contexts so that's binary but I really
want to talk to you about promises today
there's a there's a specification for
problem bro there is a specification for
promises long predating the entire
common jsf effort by a fellow Tyler
closed for a project called refs end and
the queue API as he called it and I we
carry forward is this really highly
highly researched very carefully
thought-out API for composing a
synchronous asynchronous programs in
reliable ways in the face of hazards
distrust and all sorts of other all
sorts of other other things so it's a
really really robust way of dealing with
asynchrony 80 so let me let me let me
show you what oh I was going to talk
about said exports don't have to do that
or the module constructor or yeah we can
come back to that this is a promise so
the way whata promises is the
unidirectional communication channel
between a producer and a consumer
possibly many producers possibly many
consumers the way it works is that you
construct vehic you defer a deferred a
deferred is an object that contains a
resolver and a promise and they are
separate for a reason the idea is that
you can give your promise is a
capability
to resolve the difference and the
promises is it gives you the capability
to observe that deference so you can
give these two different people and they
don't even have to like each other and
and they're guaranteed to not be able to
not be able to communicate in any other
way then then the two objects that
you've given and this leads to all sorts
of interesting fun patterns like you can
give the resolver to a bunch of people
in the first the the first person to
resolve it wins the race to resolve the
thing and at all sorts of other patterns
so more about deferred in this box in
the middle I've disposed represents the
two-state nature of a promise it has a
before resolution state and a post
resolution state before a resolution it
its contents are a list of people who
are interested in the value of the
resolution and those by people I mean
other promises so and then after the
promise has been resolved it has a value
and that value gets sent to all of the
promises that are interested in that
value and the promise in the resolver
and these circles with the arrows on the
inside are a sort of representation of a
closure the idea is that if you have a
reference coming out of the edge of a
circle that's something that's a
property of an object and an arrow
coming from the inside is a property
that is enclosed by the object that by
the idea is that if you give an object
to somebody else they have access to all
of the capabilities that are on the
surface of that object but not
necessarily that they have to object all
of the references inside of it so you
can protect access to those things
so here's a simple defer this is a this
is an abstraction on the set timeout and
it's really really simple the idea is
you construct a deferred you call set
timeout the callback is going to be the
resolver and then you pass the time out
as the second argument and then you
return the promise so you've got the two
parts the resolve is the resolver and
the promise is a promise the what
happens with resolve is it takes one
argument in this case it's going to
resolve to the value of undefined
because set timeout is going to send
done divine to it as its as its first
argument so what this does is it returns
a promise that will resolve after
whatever time you provide and the way
you observe the resolution of that
promise is using a cute when he taught
when was originally in the e programming
language it was a clause it was more
like a try-catch than a try-catch as an
expression instead of just like instead
of a function call but in JavaScript we
can use a function call to do this it
has it has a try claws and a catch
clause effectively the way this works is
that you pass a promise in or value as
the as the argument to when and if it's
if it's a if you give it a it treats it
as a resolved promise so it will it will
proceed almost immediately but not in
the same turn if you give it a pure
value which means that you can pass into
when you can get just get a value from
somebody else's API regardless of
whether that API is returning you
promises or values which makes for a
really really clean level of abstraction
where you can build a promise based API
in terms of any API at all and the code
is identical and the the first the first
operand you get is a call back this is
the call back that's going to be
attached and it will
deserve the resolution of the promise
and it receives the fully resolved value
is its argument from there you have the
ability to return a new value so
supposing that you were trying to to do
a computation of some kind that depends
on data from that there must be acquired
asynchronously from somewhere you use a
when block to observe the resolution of
that promise perform your computation
with that given value and then return
that value to to whoever to whoever is
asking to whoever who you are beholden
to so if you're creating an asynchronous
API all you have to do is use it in if
you are both producing and consuming an
asynchronous API you never have to use
defer you just use Q dot when which will
be most of the time and so you're
consuming a and you're producing be the
capital B is what you return to your
consumer and that will be resolved with
whatever you return from the from the
inner block and the neat thing about
promises is that they accurately model
both returning from a function and
throwing exceptions from a function and
they do it in a single similar way to
the way try-catch works in that you
don't have to pay attention to the
exception unless you are interested in
the exception because if you do not
provide a way to observe the rejection
that rejection will be forwarded from
your consumer from your producer to your
consumer the way you do it was a
constructive rejection it's just another
promise q dot reject returns a promise
that that embodies the knowledge that
this promise has been rejected and you
provide as as its as its argument any
object you want strings are good that
that tell you why the promise is being
rejected sometimes it's interesting to
provide additional metadata like my
stack traces
this is how you do error recovery with
promises the qn receives as its second
argument and airbag and it's not quite
it's not quite an error back because
it's it's responsible for either
continuing to resolve the promise or to
reject the promise so the value returned
from the air back is going to be either
your resolution or your continued
rejection now you have an opportunity if
you're rejecting it to construct a new
rejection with more information or or to
just use cute or reject and pass the
reason through or provide a new value
and if you omit the air back your the
rejection reason from your producer will
be forwarded to your consumer similarly
if you omit the the call back the first
argument the value that you've resolved
to will be forwarded to your consumer so
you can also use Q dot when to just
attach air backs and not and to not
attach callbacks this is how you use Q
dot when in a calm count to do a
compound computation suppose you're
you're waiting for two different four to
two different promises to resolve and
these promises are potentially being
resolved in parallel before before you
call Q dot when you acquire promises for
a and B so they're they're both off
doing their job and then you use Q dot
when nested to join those promises and
then provide a computation based off of
those two values so suppose you're going
to a database and also making an HTTP
request you can use this to get your
database response in a and your HTTP
response and be that performs some
computation generate a new value or
another promise the way the reason this
works is that Q dot when in your
callback all your air back you can
return another promise to further defer
so if you which is a pretty common
pattern you're you're in your callback
you're like oh I made progress but I'm
not done yet you can you can then return
promise to continue waiting and this is
super super elegant some more
complicated composition problems can be
solved using our friend from computer
science reduce I'm sorry these things
can be really easily wrapped but I want
to show you the guts because guts are
cool in this particular case i'm using
the reduce function who doesn't know how
the reduce function works the reduce
function works by taking an array of
values and it tries to aggregate them to
a single value using some function so
the the trivial example of reduction is
a sum so suppose it's important
regardless of the order in which you
resolve the you you can you combine the
values in an array to construct it some
it will always be the same Valte which
isn't actually important but bear with
me so if you take any two values from
that and construct the sum you can take
that out and then put the the sum in the
array and eventually you'll be rude
reduced down to a single value and
that's what reduce returns reduce
accepts as its arguments well if
receives an array it except and a a
function that takes the the so far
accumulated value and also the value of
interest at the point and then you
return the new accumulated value it
receives is an optional last argument a
basis for the recursion although it is
performed iteratively in the engine so
the way this reduction method works is
it's a supposing that you have an array
of mixed values and promises what you
can do is use this reduce method to wait
for all of those promises to be resolved
and then perform a computation on the on
the aggregate values in this case it's a
sum and the interesting thing about a
reduce is it's strictly left to right so
the way progress is going to be made by
this particular pattern is all of
supposing that there's a random
distribution of resolutions and time as
as you go through
the game loop in turns you're going to
get resolutions at different times and
then whenever the the first two are
resolved you're going to aggregate them
and then when they're the third whenever
the third is resolved you're going to
aggregate it the fourth is already
resolved but we wait until we have the
accumulation of a and B and C 2 to
accumulate them and the neat thing about
promises is you can create various
reducers for different scenarios you can
create a left-to-right resolver you can
/ left a right reducer you can do a
right-to-left reducer you can do an
opportunist to producer which reduces
whenever values become depending on what
the math is you can you can reduce out
of order this is an M we're all really
super familiar with procedural
programming using continue and break and
stuff like that so it's a using promises
you do have to get a little clever with
solving problems of how to do that kind
of thing this is a solution for a break
or a short circuiting reduction so the
trick is that you want to continue you
only want to continue making
computations like searching the file
system for for directories which was the
case where this came up for me up to the
point where you find the thing of
interest and then you want to cut off
the computation in this case the way the
way to do this is to construct a chain
of callbacks using reduce and the way
the way this one works is I'm using the
generic or a method to create an array
of functions that perform some
computation which in this case is just
returning a letter of the alphabet and
then I reduce from right to left and the
reason for this is that I'm taking the
rightmost function and making that the
otherwise claws of a choice so in
aggregate I'm creating essentially a
linked list enclosures for functions to
call next and then the function that
comes out at the end is the first
function I want to call so as if you
if you follow this the otherwise call
the basis for this is going to be
rejection so if nothing if nothing
returns a valuable value I'm going to
get a rejection and for each of the each
of the each of the components I'm going
to get a letter of the alphabet and if
the letter of the alphabet is
uninteresting to me i'm going to call
the otherwise function that was the
accumulated the accumulated value and
reduce and this this models the the
order of execution this is how you do
error recovery this is um I had this
working at one point in our wall on node
normal one note is not really going
forward I'm in the process of
translating all of that work into NPM
packages like qu till which is done and
qhttp which is sort of half done so I
think that's one actually works the way
this is an HTTP read retry loop so we're
going to try to make a request several
times there's going to be a constant
time out between tries and you're going
to type try and certain number of times
before giving up and the you can also
you can also model exponential back-off
with this with without too much
difficulty at all so the way this is
working is I'm first going to call HTTP
read on the URL this is going to issue
an HTTP request and return a promise for
the body of the response which may be
rejected if it's not a 200 status and
then I use Q dot when to wait for that
content and I return it if it's good if
there's an error I and there are no more
times left I reject but if there are
more times i'm going to further defer
using my old delay thing from up top to
wait the timeout and i'm not going to do
another HTTP read retry with 11 fewer
times and this looks recursive button an
event loop you actually get a new stack
each time you're on the body of a Q dot
when let me tell you about some of the
promises of Q dot win it I mean
invariants no promises pardon I want to
load
my vocabulary too much q dot when
guarantees that the inner callbacks are
going to be called in a future turn of
the event loop this is to prevent
confusion logical confusion with in it
permits you to do in one turn of the
event loop to set up a whole bunch of
things to happen in the future and
guarantees that all of you all of the
values in your lexical scope are going
to be preserved for the duration of your
turn you are in complete control of your
of your values it also guarantees that
the Q dot wind function guarantees that
your callback in Arabic are only ever
going to be called once and only one of
them will be called so this is really
resilient against many many hazards and
malice even this is how you implement an
HTTP request via xhr using promises I
think everybody's done xhr is this
pointed directly at we construct a
response response deferral we
constructed a row HTTP request we open
it we set up the onreadystatechange
andler and we resolved with the response
text if it works we resolve with the
rejection if it does not and we return
the promise for the value and initiate
HTTP request there's a little thing in
here with the timeout equals set in and
set timeout that that it that adds the
set timeout semantics and it I think
that one line really expresses the
awesomeness of this API in one line I
have implemented timeouts and because
the promises guarantee that the first
person to resolve the promise wins if
it's rejected its rejected even if the
HTTP avenge a request eventually manages
to give you some data the timeouts out
your your your promise we'll never be
modified again this is a this is a
demonstration of how promises can be
used as currency so it even why that
money has really freed up us freed us up
from the barter of things promises have
the
to free us up from bartering reclose ok
so our burning promises so if you have
symmetric api's where responses and
requests have a certain degree of
symmetry these things can be passed
around really easily so this is what
happens here is that if you're issuing
via the request API a request and the
request is a promise and it returns a
promise and this is completely
asynchronous but looks very very
synchronous I'm going to just skip this
this is an hd2 PQ and promises there's a
really cool promise implementation I
mean there's a right really cool promise
trick you can do where you can create a
queue of promises and you can actually
pop things off of the queue before
they're resolved and it just construct
this it's really cool look into it this
is the implementation it works in
browsers it works in node works on
Narwhal it's really small there's no
reason not to use it it really
simplifies complicated asynchronous code
both on the server and the client I
really encourage its use you can get it
on github with my alliterative name and
cue as the project name you can also NPM
install q it's there then I was going to
show you some stuff from a utility
library i created a qu till it's in
progress this does shallow resolution of
an array so it gets its implies you
don't have to do use reduce you can just
use the shallow resolver to take an
array of promises and get a promise for
an array instead and this can do a deep
resolution which you have a whole tree
of objects that may include promises and
shameless plug since May I've been
making a map of middle-earth it's like
Google Maps it's really cool and because
it wasn't awesome enough I also did in
elvish and have a good day
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>