<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Michael Starzinger: The Footprint of Performance | Coder Coacher - Coaching Coders</title><meta content="Michael Starzinger: The Footprint of Performance - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Michael Starzinger: The Footprint of Performance</b></h2><h5 class="post__date">2012-10-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZhshEZIV2F4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Michele rotzinger I work for
Google as a software engineer I work on
the v8 team which is now totally based
in in Munich so we ate this developed in
Munich and engineering office and the
purpose of this talk is basically
twofold one is performance of course we
are all talking about performance but
the second point is the memory footprint
that all the performance optimizations
introduced and so I want to give it a
different spin from all the other talks
that have been given about v8 and see
how we can get both of best worlds so
great performance and low memory
footprint so before I head off into that
first one slide basic overview of how v8
works and kind of a reminder of what you
might have already heard so the main
thing there are a few things at Google
that we know to be true and one of those
things is fast is better than slow so
obviously that's the main driving force
for v8 we want to be the fastest
javascript engine out there how do we
try to achieve that so there are a few
ingredients as to that one would be
inline caching which allows us to access
properties of objects fast because
that's the main thing that all
JavaScript applications do manipulate
objects access properties then as we
heard in a previous talk optimizing
compiler to really kick ass at the hot
methods and also another important
ingredients an efficient garbage
collector and we actually have a new GC
that's an incremental low post garbage
collector it's generational and we try
to get the power the post post times as
low as possible by basically
interleaving mutator work so work that
your application has to do with garbage
collection work slicing these up and
interleaving it so that we can make
progress with garbage collection as well
as pro
with your application and a lot of other
ingredients --is we mix those up and
stir them well and hopefully get high
performance characteristics in our
engine so we got speed awesome but what
else did we get with death
imagine your you bought a new car and
you know it has a pretty damn engine in
there and you want to take it out for a
quick Drive and suddenly you find
yourself in here so you look around and
see you want the other cars and start
thinking about well hang on wait a
second what is the footprint of all of
that in your car you might be worried
about carbon footprint if you're talking
about JavaScript engines you might be
worried about memory footprint so before
I dive off into the memory footprint
first of all how would you optimize a
JavaScript application the most
important thing first of all is to find
the actual hotspots find what is
important for your application
performance wise that would be functions
that are worth being optimized because
they are executed often frequently a lot
of times memory wise that would be
finding objects that dominate the heap
that are omnipresent in the heap and
they live long or that have a bad memory
layout but once you found the actual
object is causing a problem you need to
understand why it's actually causing a
problem so without understanding the
actual problem there is no way you can
fix it and then you fix it and the last
item is really just that fixing it so
here is my very personal very
unscientific opinion of how much time
you need to invest into these steps so
fixing it is really just that if you
understood the problem getting rid of it
should be easy
this talk is mainly gonna focus about
understanding the problem at hand and
since these fix things
since fixing is so easy we will also
do that okay so let's look at a few
examples and three examples that I want
to present here are objects like
tracking array representation and
execution context we will look at three
examples in depth and discuss a few best
practices how to improve hot code around
those optimizations the first one will
be about how our objects represented in
memory second one our area is
represented in memory and the third one
how is your actual execution environment
of some function represented in memory
okay let's dive into that so the first
thing objects like tracking most of you
might have already seen this example the
famous point example and how would this
point be represented in memory so please
stick with me I'm gonna give it a
different spin this time with the
addition of slack tracking so let's go
through that application step by step
and I promise so I try to do this
without assembler so I just have fancy
graphics explaining it know assembler
code I hope that's okay so the first
thing when we execute that constructor
is we actually allocate the object in
memory you probably know that we have a
hidden class system behind all of that
because JavaScript in itself is a very
loosely typed language and to really
optimize for for certain objects we need
to have a more precise type system
behind it so we invent our own types and
call them hidden classes and we just
give that new object a little bit of
slack so in this graphic that would be
four slots that are available directly
in the object so there is no indirection
going on here you don't have a packing
store where the actual content will be
stored it's directly in the object that
also serves as an identity so let's add
the first property that would be X we we
add it and since we now modify the
object layout we actually added a new
property that can be ax
we also need to transition the hidden
class so it's now a new type in our type
system and we remember that transition
so whenever we start from the first
hidden class at X we'll go to the next
hidden class and as I mentioned before
we store the value directly in the
object so accessing it is just taking
it's just loading one word out of the
object no indirection second step
obvious add a new property transition to
a hidden class again so if you think of
this transition chain or transition tree
that you get on the on the on the right
hand side you can imagine what would
happen if you suddenly add these
properties in a different order you
would end up with a different in class
in the end so that would be one point to
avoid now let's repeat that with the
follow up down there so we get two
objects both have x and y and now we
have this fancy modification of the
object that comes right after the
constructor so how would we deal with
that so every second object gets a set
property okay we can just add that no
problem we still have slack in the
object so both objects are actually over
allocated we allocated too much memory
for those objects and at some point when
we have enough of these objects we
decide to basically freeze T the T
transition tree we say okay your
application has allocated enough objects
they are probably gonna look like this
most of the time so we are gonna freeze
that state and say okay those are those
are the classes two hidden classes that
you're gonna work with now we actually
want to get rid of the slack that we
have at the end of each object and we
can do that we just shrink the objects
the problem is every point that you
instantiate with the point constructor
can either have two or three properties
and we don't know how many so we need to
keep around at least three slacks in
each newly allocated
check and that means for half of the
object we waste that memory it's really
wasted so that's probably bad if that's
a hot object meaning you have like a
million of those objects floating around
in memory that would be pretty bad so we
hopefully understood the problem now how
can we fix it well fixing it is easy
just use two constructors meaning you
come up with to transition freeze or
transition chains and both Maps can be
optimized for their object size so that
fix is pretty easy and either so I left
the implementation of those to construct
this point one point two and point three
out
you can either implement them directly
which means you have some duplication in
there you could use some frameworks that
are out there like the prototype
framework all types of inheritance you
could even use you from within point
three you could call the point two
constructor by using point to call this
and pass the arguments through that
would all work the object layout would
still look like this important thing is
use two different constructors tell the
VM that you actually are dealing with
two different types here so I said we
should measure it I hacked this pattern
into a ray tracer which deals with about
600 points 600 thousand points and up to
three wasted stack as select slots in
the in the objects and keeps them alive
in memory and that's improvement that
you get out of that and those are forty
percent so forty percent less memory
that your application consumes which is
quite ok I guess so now since if you
don't want to to to to think through all
of this every time and and come up with
the actual representation that your
object is gonna be in memory I will give
you a few best practices that you can
follow
and that will hopefully allow you to
write applications that are both
extremely fast and slick memory
consumption wise so first thing is try
to initialize all properties in the
constructor and as I mentioned before at
all the properties in the same order
because otherwise that would screw up or
our hidden classes and avoid object
layout modification after the fact so
after the constructor has come up with
the initial object layout now this might
sound like I'm taking away a little bit
of freedom from the from there from the
expressiveness that you have in
JavaScript but let me tell you a story
about that so I went into this I went to
this pup recently and that the entry
they had to sign and it said this pup
serves food that is good cheap and
served fast you can choose 3 you can
choose 2 and that's kind of this kind of
reminded me of this so you have
performance speed only one hand then you
have memory footprint on the other hand
and then you have the expressive power
or the freedom that JavaScript gives you
and I'm not claiming that those three
are actually all the time mutually
exclusive but knowing about those three
points in the triangle understanding it
and knowing where you're located in this
triangle might help you to write better
applications ok so let's move on to the
second example array representation so
far we only talked about named
properties now it's gonna be about index
properties so again we have something
that is used as a constructor or that
that used as a factory to instantiate
arrays and again it's a hot method
because it's executed several times
there by the array it repeats it
produces is a hot object and might make
up a bulk of your heap so the first
thing we do here is we actually
instantiate a new array
for Aries we want to have an object it
represents its identity that would be
the small box at the top that also
stores the length so how many elements
how many index properties do you
actually have another array and we over
reserved the backing store again so we
again have like four entries that we can
fill up after the fact without resizing
the actual packing store so we can do
that we add in index property with the
name zero we add the index property with
the name one and now we add another
property that's actually a double value
so the packing store is intended to
store integers or small integers
actually so now that we store a double
into it we actually want to have an
efficient representation of that packing
store efficient performance wise that
means we actually want to unbox those
doubles in that packing store that means
we have to change the layout of that
packing store and we do that it's now
taking 64-bit words and that packing
store is able to store doubles directly
in them so as you see the 0.5 is stored
directly into that packing store that
means we have to convert all the
previous small integers into actual
doubles now that conversion takes a bit
of time takes additional memory but that
doesn't matter that much because the old
one is no longer reference and can be
garbage collected so and next we store
an object and the true value in that
packing store that's represented as an
object and that means the work we just
did most bogus we have to go back to the
old representation again 32-bit and now
we actually need to box the 0.5 to
double value which again means we have
wasted a few cycles by converting back
and forth allocated a new backing store
again and collected by a bunch of hidden
class transitions that track those
transitions so if we generate lots of
these arrays
it's gonna get gonna have a bad
performance and also you see there are a
lot of packing stores which actually
contain the same the same values so that
doesn't look very efficient neither
performance wise nor memory wise so what
would be a possible fix of that possible
fix would be to not use this strange
construct at all but use an array
literal with an array literal b8 can
basically infer the optimal
representation of the backing store I
locate that right away and the most
important thing we can share the backing
store between the Aries and those
backing store is now becoming a
copy-on-write backing store that's what
the cow should indicate that means we
can share the backing store as long as
you don't modify any anything that's
stored in it as soon as you start
writing to one of those backing stores
it will be copied and modified so all
the other areas will still share the
backing store and this change should
give you a performance boost and the
memory boost awesome right you can have
but best of both worlds and again there
are a few easy things to follow here
which should allow you to avoid this
kind of trap the most obvious one is if
you use the Eric if you're able to use
area literals try to use array literals
they're really awesome we can generate
highly optimized code for it and we can
immediately come up with the optimal
representation in memory for it
pre-allocate small arrays to the correct
size so that basically means pass if you
know the size ahead of time pass it to
the constructor and most importantly try
to use arrays for to store only one kind
of element in it so especially try to
avoid mixing object values with double
or integer values okay the last thing is
about execution context so javascript is
a functional language
and what that means is that on one hand
you can have so one thing is functions
are first class object so that means you
can pass them around as in variables you
can have nested functions inside each
other and they have a proper lexical
scoping so that means the inner function
can reference any variable that's
declared in the outside function so what
does it mean in this example we have an
auto function may closure with two
variables in it large value small value
so obviously large value is going to be
the bumpy one we have two inner
functions in it and closure and both
reference some of the auto values and
then we call this function a closure
several times so what does this actually
mean since the inner functions reference
variables from the outer functions we
need to preserve that execution
environment in some way so it means it
needs to be stored in memory and the way
we do that is we have a context object
that's actually in heap object that's
allocated on the heap and we put the
values that are basically gonna survive
the execution of the outer function in
there so arguments can be context
allocated in this case the size argument
because it's used by a nested function
so should the nested function in it
escape that outer closure we need to
preserve that execution environment same
thing applies for variables they can
also be context allocated they are also
going to be put into that context and as
I said this context is going to be
referenced by the nested function so
this context is the execution context
the execution environment for those
nested functions so they are gonna keep
it alive until as long as they itself
survive so what does that mean if one of
those functions dies like the init
function it's gonna go away but the
context is still alive because it's
referenced by the closure function which
escaped the outer function and
large value can be some huge objects and
huge array which is basically the bloat
in your application and you want to get
rid of that so how would you fix that
easiest solution just get rid of that
large value context allocated variable
move it in today into the inner function
that's the easiest way thereby you got
rid of the context allocated variable
and the closure function will no longer
keep alive the bloat so again I wanted
to measure this and measuring this
giving a percentage here is just is just
pointless basically most of the
application developers will just
consider this to be a leak so
understanding this construct
understanding this way that we ate
context allocates variables and that
functions can keep alive whole contexts
might allow you to fix severe memory
memory leaks in your application so here
are again the basic best practices the
first and most important thing is you
should be aware of context allocated
variables so you should be aware that
these things exist and ensure that what
closures so basically closures that you
generate often have us have a small
outer context and move variables as deep
as possible into the nested functions
thereby about avoiding those leaks so we
just got rid of all the bloat and
hopefully this allows you to to write
applications that that that don't
introduce memory bloat that are
performant after all and hopefully this
might also apply to other virtual
machines because so although all the
examples I gave are highly highly
targeted for for v8 so they
they discussed how how v8 represents
these objects in memory but I guess the
same same optimizations could be applied
in other VMs I cannot judge that but it
should allow you to drive all of your
engines safely and have a free highway
like this so with that I want to thank
you very much for listening in so I hope
I could convey some of the basic
concepts how v8 come comes up with
representations of objects in memory and
how to avoid some booby traps that are
hidden in there not intentionally if you
want to know more ever ask me now
because we have yeah actually we have
lots of time and you can also find me in
the break during the breaks at the
Google booth or contact me directly so
if you have questions shoot I've got a
question about hidden classes
you said you prefer if people would
create instance variables in
constructors yes that said also work if
you do something like object of
prototype dot variable name equals
something or other so if you if you
store an and property on the prototype
of an object that means it's actually
gonna be stored in a different object
that's referenced through the done the
proto field as I learned yesterday and
so whenever we access that property we
have to follow that down the property
field and then access that object but
the representation of that object same
rules apply there so how you come up
with that representation is again
follows the same rules so probably it
the prototype object that you use for
this object is gonna be shared among a
different among several objects so
most of the time the prototype objects
aren't hot in a sense that they that
several of them exists on the heap
they are just hot because they are used
often so they should have a performant
implementation performant memory
representation but if you waste some
space in there it's probably not that
important
Thanks so I was I want a one at the
example where you had two different
representations so at this point he and
usually if this object is hot it's it's
used very often and yeah and yet it's
much much faster if it's monomorphic so
my general advice would be to say only
have one car that has three fields and
if you don't use this deep field just
but undefined and you will be just fast
and I mean it's 32 bits okay yes you
obviously understand the problem at hand
I hope I could teach that underlying
general underlying problem to more
people but knowing about this trade of
either waste space or have a monomorphic
object brings you forward and a huge
second question was functions function
you have to run through the whole
function to to see what where those are
captured or in the nested function yeah
why not also see if the init function
itself is actually captured itself or
leaves the scope so in this case it's
called from within the constructor so
you know it's not going to capture any
variable yeah so you could just say okay
I see you drive I look at all the code
and see it but it requires escape
analysis because you need to find out
whether that function escapes are not
well but you're really looking if
something is kind of I mean you have to
see if large values inside the init
function so you just keep tracking the
unit to so it doesn't seem that
difficult you just I mean if it if n it
is used in a non calling function
context okay then just say we need to
capture everything in there but that
doesn't look that difficult it's not
really a difficult analysis no it's not
maybe it's not a difficult analysis but
the problem is you need some optimizing
compiler for that and layout of the
context you need to get them right the
first time so when you have when you
didn't optimize the function yet or
otherwise transition that context layout
somehow if you optimize a function
because you already created some
instances of the
function object they escaped into your
hip they're floating around and now you
decide to optimize this whole mess this
whole make closure thing and you come up
with more with a better representation
but there is already the bad
representation out there so if we could
if we crank shift everything then we
would be smarter about that but then
start a performant would suck so again
classic trade-off
one more quite detailed question you
were talking about allocating and
assigning all the properties and
constructors so that you can presumably
allocate the precise amount of space and
the object itself how accurate can you
be in that can you can you really
determine precisely how much to allocate
or will you ever have to spill to so
it's not right the perfect scenario
forum from a VM implementer point of
view is if you just have simple this
assignments in the constructor so if you
construct it looks like this is this is
this is we just look at that code see
during parse time so now optimizing
compiler we see the layout there in the
code and just boom come up with the
optimal representation and when the in
line when when we optimize the function
boom in line that know how it looks like
so that's the optimal way but that takes
away a lot of freedom from JavaScript
eval I was asking about the more
complicated case where you might have
some branching or whatever which you
know yeah the one solution we we use is
this objects like tracking so we overall
allocate all the time like this and
after we have observed fixed amount of
allocations we shrink the objects and
heal their size if you want so that
gives us the most flexibility even if
you have non simple constructors okay I
think that'll be it for now give a hand</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>