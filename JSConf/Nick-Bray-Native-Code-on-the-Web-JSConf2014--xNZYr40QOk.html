<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Nick Bray: Native Code on the Web? [JSConf2014] | Coder Coacher - Coaching Coders</title><meta content="Nick Bray: Native Code on the Web? [JSConf2014] - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Nick Bray: Native Code on the Web? [JSConf2014]</b></h2><h5 class="post__date">2014-06-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-xNZYr40QOk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">we need native code on the web right now
you can write applications in any
language you want as long as it's
JavaScript so this is a funny thing to
complain about as this is jas conf but
if you think a look at the larger arc
right now javascript has a very
privileged position on the web and all
other platforms usually have a way that
they can call out to C or C++ or some
other language and this creates a lot of
lost opportunity costs such as
integrating with existing libraries or
making it easy to port between cell
phone applications and the web and
things along those lines so before we
get into the Nitty Gritty of native code
it's worth remembering why we love the
web the web is secure and by secure we
mean that you can point your web browser
at nearly any website run the
application and not worry that will
upload your financial information to
some arbitrary website so cat videos no
theft that's a good thing the web is
portable you can view it on any computer
in the operating system as long as
there's a web browser you can view it
from your cell phone it's it just runs
everywhere there's a web browser this is
great it's ephemeral so you don't have
to install anything you just point your
web browser go you don't have to
uninstall anything you don't have to
have automatic computer clean up or
anything like that that's all done in
the cache
and the web is well not very compatible
with other platforms it's kind of it's
an own Island so the reason this is is
because of all the things that make the
web good so the web is secure well this
doesn't mean that native applications
are insecure it just means that they
have an entirely different definition of
what this means so on the web it assumes
your application is running on behalf of
where you get it from whereas when you
run your native application it assumes
it's running on behalf of you so the
native application can access your
financial information because it's you
and native applications are typically
compiled down onto the machine so they
aren't they haven't traditionally been
built for portability and you typically
install these so we'll get the plugins
in a moment but if you have to install
something on the web you lose ninety
percent of your user seventy ninety
percent of you users right there so if
we want native code to work on the web
it has to behave like the web it has to
be secure portable and ephemeral we've
tried this so everyone remembers NPAPI
flash java activex some people even even
tried to hack the browser in order to
get this working and these ultimately
these approaches fall down because it's
JavaScript its web content which calls
into native code and then the native
code tries to do its best job pretending
it's just as secure as JavaScript but
ultimately there are security exploits
and you only get security that's as good
as the weakest link in the chain so gen
2 is people finally learn from the pain
and said why don't we try to do things
which behave as if they are web content
they're secure portable ephemeral so
there is portable Native Client which is
in chrome and allows you to take a
portable binary essentially and run it
inside your web browser and then there's
Emscripten which compiles native code
into JavaScript and this is one of the
main reasons that this is going to be
talked about at JS conf is because it
concerns JavaScript and what the future
of JavaScript could be to support this
kind of workflow and a lot of you have
probably heard of as MJ s and this is
actually
what happens after em scripting gets a
hold of it is it describes a specific
format that M script and generates so
for this talk I will be talking about
Emscripten but in your mind you can
wildcard that too as MJS if you wish
pinnacle portable Native Client works
like a traditional compiler is you take
a bunch of C++ source files you pass it
to a slightly modified version of llvm
and it produces a portable executable
this portable executable is a
serialization of lv M's internal format
then inside the browser your web page
says hey I want to embed this portable
executable so chrome grabs it downloads
it and then looks at it and says hey I
can't actually run portable code you
know my processor isn't portable it's a
real processor so then it goes and
translates it into what the local code
is and it does a few tricks to make sure
we can verify the code is safe so at
runtime you get a set up that's a little
bit like this is that there is a Knakal
process running these specially
generating machine instructions which is
your native code executing and then when
one is interact when it wants to
interact with the web page it does
postmessage so javascript is sitting
there can send messages back and forth
and one of the issues is that you don't
have direct access to the dome so the
dom is very much single threaded only
accessible by javascript and it's very
jealous of this fact so you typically
have to have some glue if you want to
modify the actual web page an
interesting thing is that when you have
an apple process it can only talk to the
browser it cannot talk directly to the
operating system and this means that the
browser notion of security is preserved
so you can't access an arbitrary file on
the disk but you can get any Earl that
JavaScript would be able to get and the
API that this done with is called pepper
and it's essentially functionally
equivalent with what javascript has in
terms of xml httprequest WebGL it's just
a different language binding for that M
scripting on the other hand takes the
approach where it says here's some C
code and I'm going to do some
transformations on it so it's actually
semantically equivalent JavaScript so
this is an add function which is pretty
dup a little bit to use pointers so we
actually see some memory operations in
the output but it's more or less what
you'd expect
if you kind of squint through all the
cruft in there there's a load from
memory another load from memory and then
it adds together so you'll see there's a
lot of or zeros in there and these are
bitwise operations where you're doing a
bitwise or with 0 which if you know how
or works that should be a no op you know
or with zero equals what you put in but
the trick is is that JavaScript coerces
anything you or with 0 into a 32-bit
integer so if you have a string or if
you have a double it'll mangle it until
it looks like an integer and then you
can do operations on it so this is what
azimuth is they've essentially smuggled
in type annotations to language by
exploiting the semantics of JavaScript
really weird corner cases another thing
to pay attention to is that a memory
access where you're just saying hey I
want this address in memory is
transformed into an indexed operation in
index operation into a typed array so if
you're familiar with the ray buffers and
typed array views that's what's going on
the bottom is it's taking a pointer and
because the array view the indexing
isn't bite for bite instead like if it's
a 32-bit integer it's indexing four
bytes at a time you have to drop the
lower two bits of the address divide it
by 4 so that turns a pointer address and
do an array index interesting
consequences of this is that the address
you look up isn't exactly the address
you'd normally get a native code usually
it doesn't matter but there's a few
corner cases we're dropping the lower
two bits can bite you there's also the
question of null pointers so see
typically says the the pointer 0 is in
some ways equivalent to null or
undefined in javascript is it just means
there's nothing there and you should
always check if it's know before you use
it but if you use null in this case it's
like well let me get address it data
address 0 oh here's the data at address
0 so it doesn't complain usually with
native code it will kill the process or
something along those lines at runtime
when you use I'm script it looks like
this is your compiled code is actually
running inside the very same thread as
the rest of the JavaScript code and when
you want to call out of the compiled
code it's just calling a javascript
function so it's a very quick
synchronous bridge so with a little bit
of wrapping you
get synchronous access to the dom and
both the compiled code and the j s code
has access to this big array which it
says is equivalent to the native
machines memory the consequences of this
approach is that your native code is
sharing the same thread as javascript
which means that it has to obey the same
rules as javascript it can't block you
have to periodically relinquish control
and there's no other threads so this
means that if you're porting to use on
script and you have to potential e spend
a lot of time refactoring your code so
that it behaves like JavaScript it's
asynchronous callback driven and for
some native applications this is a step
too far so a lot of the stuff we see
nowadays that's being compiled to the
web is the stuff that works easily but
there's still a lot of stuff we haven't
been able to do because of the blocking
and threading issues this leaves you
with the dilemma is you can go pinnacle
and you say hey it has threads it's a
little bit faster it's closer to what we
expect there's fewer gotchas but on the
other hand if we go the unscripted
approach it runs everywhere javascript
runs and in many cases it's easier just
to synchronously access the Dom you
don't have a synchronous post messages
so it's a dilemma is we have to not yet
perfect solutions and what can we do it
turns out that these solutions are
actually closer in many ways than you'd
expect they're both built on top of the
lvm tool chain and they both are trying
to produce portable native code so a lot
of the tricks you have to do to get
portable native code working they're
both doing the same thing so I thought
why not create a polyfill that provides
pinnacles interface to M script them so
if you're willing to get rid of your
threads and you're willing to make sure
your programs asynchronous then you can
take the same code base and compile it
using both technologies and I call this
pepper jazz because it's ajs polyfill of
the pepper interface abstractly that's
fairly straightforward but actually
seeing into action these are Native
Client examples SDK examples this is a
ray traced earth that's doing this on
the CPU there's no GPU involved
and here's the pinnacle version of the
same thing you don't notice many
differences the one difference of course
is that if you go to the pinnacle
version over here you can turn on more
threads and it's very hard to see on the
VC but you do get a speed up when you're
doing that and you know there's other
cpu examples where you can just crank on
the threads see it go faster exactly the
same code working with them scriptum but
there's corner cases like this is if
your GPU bound it really doesn't matter
how fast you are so exactly the same
application mostly driving the CPU so in
terms of performance is Emscripten
actually does very good especially with
numerical kernels so things like earth
it's usually within 1 X you know it's
like twenty percent slower whereas when
you have more structured code you're
kind of in the two to three X range in
terms of performance so the performance
is mostly there it's more an issue of
developer time and structure how much
time are you willing to death how much
time are you willing to spend 2d thread
your code well why would you want
threads so I've been pounding on this is
that it's structure is modern developers
they want to target as many platforms as
possible that you know they want to run
on cell phones they'd like to run on the
web but it's all a return on investment
issue is how much time are you willing
to get that next platform and support
that next platform if that I if that
cost is too much you just don't do it
there's throughput we'll see in a moment
that if you have more threads you can
just crunch more numbers and do more
calculations there's also latency so if
you're doing audio or rendering or
real-time stuff throughput is kind of
the equation but you want to get it done
is kind of the question but you want to
get done as fast as possible so you
never want have dropouts in your audio
you never want to drop frames in your
real time application there's also a
trend in Hardware where we're getting
more and more cores and an individual
core can run code about the same speed
as it always has and if you want at your
overall application to run faster you
have to take advantage of the parallel
resources in your hardware I should
clarify before I go on
kind of using the definition that the go
programming language has done for
concurrency and parallelism is that
they're not the same thing so
parallelism is about doing things at the
same time so if you have multiple CPUs
you're running things on multiple sea
views that's parallels them whereas
concurrency is really about dealing with
the conflicts that arise when you're
doing things that interact so even if
you're running on single CPU you can
think in JavaScript you have problems
with concurrency when you load a bunch
of files and then they may come back not
quite in the order that you expect so
you have to deal with the Oh they've
resolved in different orders let me
order them then let me go on things
along those lines whereas parallel ISM
you get that when you actually load the
file so well the system is actually
grabbing the bites off the network
that's parallelism but it doesn't
interact with JavaScript until you get
the event back and that's concurrency so
what if we changed how the browser
worked a little bit what instead what if
instead of just running everything
inside the main thread we spun up a few
workers so a web worker is essentially a
thread but you can't interact with all
the other threads the way you'd want to
with native code because you can only
communicate through messages so what if
we just gave it a big chunk of memory
and said this chunk of memory can be
simultaneously read and written to from
all of these different workers and then
you provide some mechanisms along the
lines of locks and semaphores to make
sure that you're never reading or
writing from the same memory at the same
time instead you're passing ownership
back and forth between the threads so
this should horrify a few people in this
audience is that shared memory is known
to be hard and a lot of the design of
javascript has been shared nothing
instead of dealing with all these
concurrency issues the only way you can
communicate back and forth is over
messages so this is the downside of
shared memory is it kind of is going
another direction at saying if we really
want native code on the web we have to
deal with the issues of shared memory so
people will often say well there's all
these other ways we could do it and I
don't have time to go through these one
by one but always comes down to theirs
thing missing and usually what it comes
down to is that whatever solution we do
has to be incremental an incremental
evolution of JavaScript and it also has
to require minimal changes to the native
code and there's very few solutions
which solve both those for instance you
say well why does JavaScript have to
have anything to do this why are we
compiling to JavaScript why not just use
pinnacle well that's another technology
stack and getting other browsers to
adopt it is much harder than
incrementally evolving java suit
javascript so i think in the future
we're going to see a convergence is that
what's happening in m script and what's
happening in pinnacle will start to look
similar and similar but we potentially
have to evolve javascript to get to that
point so how do we prove that this all
works well I put together prohibition
apapa a fluid simulator and I'm wiggling
with my mouse here and it's tiled and
everything like that so what's happening
is underneath all this there is a grid
of velocities and this is a
visualization of the velocity grid right
there and as you swirl it around with
the mouse the fluid flows with it and
this is a grid it's a two-by-two grid of
image data essentially in velocity data
and every step it's doing a lot of
calculation to move it forward so this
is all cpu driven this is one of these
things that you think could be very
easily paralyzed and so i tried to do it
with the existing workers api's so
here's a version where i'm splitting it
up into multiple workers and one thing
we'll get back to is you'll kind of see
although it's very hard you'll have to
squint is that the velocity buffers when
I draw into it the lines are now kind of
lumpy as they aren't as smooth as they
were the first time and we'll get to why
that was but this is running on multiple
workers right now it's in fact running
on four workers and if you look at the
actual bottom graph you see virtually no
improvement in fact you'll see a lot of
spikes popping up and those are due to
garbage collection pressure because
you're copying things to the worker
every time well what if you can reduce
the copying so this version says that
instead of copying the same data to all
four workers you copy it once and say
here's a read on
buffer that everyone can access so it
reduces the number of copies and you'll
see that a lot of the spikes go away so
as it turns out the big win from not
having to broadcast the same day that
everyone is not actually the cost of
copying the data it's the copy of
cleaning the data up afterwards so read
only memory gives you a performance
boost due to being friendly for GC what
if we go a step further and say have
shared memory and instead of using
postmessage talk back and forth we use
traditional native mechanisms like
blocks to coordinate between the threads
so at this point we see actually see our
first performance improvement and as it
turns out this is due to communication
or there's anything else so when you
have a lock that allows you to
communicate with the other threads much
quicker than postmessage does we'll get
into the actual performance numbers when
we in a future slide so this is what's
going on behind the scenes is that it's
doing a bunch of computations you don't
have to know exactly what these are but
like the effect stages through moving
things around the fuse velocity that
simulates viscosity and then it has to
make sure that there's no fluid
appearing from nowhere or disappearing
so make sure that the pressure is equal
at all times and then it'll draw how you
paralyze this is you take the
computationally intensive stages and you
move them out to a worker so you're
doing post message out the worker says
thank you for the data does the
computation sends the results back and
you periodically have to resynchronize
back I mentioned that some of the lines
become blotchy and it's because as soon
as you start paralyzing it there's these
gaps that open up on the main thread and
these gaps are potentially places where
things like Mouse events can fire so I
did a lot of beautiful abstraction i use
promises i said here are all the things
the fluid simulation is doing and then I
changed the backend implementation
detail and suddenly events started
firing in places I didn't even think
about that they'd fire so this is a
concurrency bug is we're dealing with
unexpected events in places we didn't
expect so the great irony is when
dealing with shared memory my
concurrency bug that I ran into was
JavaScript
when you actually look at the speed-up
shared nothing in read-only memory they
give modest improvements and then we
start using these fast synchronization
primitives you can actually start to use
all the cores so on eight cores only for
XP dup so that's fifty percent
efficiency so it's not quite where we
want to be and there's other things that
need to be done but this is a kind of
quick hand waving hack to show that
shared memory does work and it does give
you a parallel speed up in performance
improvement I'm going to skip these
slides for the sake of time but the
message or the the lesson learned is
that the main thread is actually more
special than you'd expect so the workers
aren't entirely independent with the
main thread and if you block the main
thread you can for instance prevent a
worker from ever creating our from ever
being created so when you initially
create it it creates a stub and it also
launches off an earl request to get the
script that's supposed to run inside the
stub so if you block the main thread the
script itself is never loaded and the
worker never becomes active and there's
similar issues where if you block the
main thread while workers doing
something the console log gets proxied
through the main thread to wherever the
console is and this means you'll lose
output if the main thread is blocked so
for programmers you shouldn't worry
about this but in terms of the browser
implementation it turns out there's all
sorts of complexities we're blocking the
main thread will kill you and this is a
problem for running native code because
it's a blocking API another thing that
freaks people out about native code is
data races and this is a classic
textbook I took CSI took operating
systems thing as you say I have these
two threads they each have two
instructions in them and I'm going to
run them at the same time what happens
so one thread assigns the value one to a
so assume that a and B are both 0 to
start out with so one thread assigns one
to a then prints be the other thread
assigns to to be and then prints a so
what's the end result if you look at the
inner leavings of these threads you get
six possible results it can print to it
can print one then one it can print one
than two if one of the threads runs much
faster than the other ones you get a
zero than a one
or a zero than it too so this is the
worst thing in the world is you got two
threads to instructions six possible in
our leavings we can deal with that I
wide so it's all worse than that is that
the compiler and the CPU there's all
sorts of things down the stack which
will try to make the code run faster in
one of the normal things they'll say is
well you're signing to a then you're
printing be these two operations are
totally unrelated so I can reorder them
as I wish and the other fed will say the
same thing is assigning to be than
printing a no relation I can reorder
them so instead you have 24 different
operations and some of them will produce
things which are intuitively silly like
one you can print 00 which never should
happen because by the time you hit the
other print you would have thought that
the other thread would have assigned to
what you're printing so there should
never be a second zero and you can
sometimes get 20 again these are
physically unrealizable but it gets
worse is for optimization purposes
either the CP or the compiler can
duplicate instructions it can remove
instructions it can transform the
instructions so instead of 24
interleaving there's actually
effectively an uncountable number of
inner leavings that can occur with these
threads and even worse is different
threads may not agree on what the inner
leavings are so if the memory operations
aren't dependent they can say hey a got
assigned to then be and the others I
know you got assigned to you then a and
not every computer will run the same way
so different CPUs will show some
orderings but not all of them and
different compilers will show some
orderings not all of them and this is
especially a problem for JavaScript
because the JIT actually behaves as
multiple co compilers so as you run it
will recompile the code and potentially
reorder things in different ways every
time it optimizes the code so this is
hopeless write it when it comes down to
it if you have a data race your program
is broken so you'll see a lot of people
they'll squint and say okay there's a
data race there but it'll be okay and
the answer is no is that the compiler
the CPU is going to do the worst
possible thing in some cases and you
can't reason about it so you must
defensively not have data races in your
program
well this would be a good argument
against native code on the web right
data data races are often but really
this is about concurrency is we're
talking about doing interacting things
at the same time and if you don't
account for these interactions your
program is broken this also occurs in
JavaScript and I think one of the things
that will be learning over the next five
years is that concurrency is a bigger
problem for JavaScript than we currently
understand things like Earl requests
coming back in the order we didn't
expect is we've dealt with a synchrony
with promises but if you have to promise
chains their inner leaving with each
other and odd ways how do you deal with
that what primitives do you use and
right now this is mostly put upon the
programmer to deal with so this is a
wicked problem but it's a generically
wicked problem and so can we do better
is there a way that we can eliminate
data races and having thought about it
for a while I can say no not really is
if you want to emulate a platform if you
want to be compatible with a platform
you also be have to be compatible with
their bugs some extent and what this
means is that JavaScript may have to
have a shared memory api for compile the
JavaScript which you probably shouldn't
use otherwise and that scares people so
where is this going is there anything
certain at this point there is nothing
certain there is going to be a bit of a
discussion / war for the soul of
JavaScript whether we want to support
native code on the web whether we're
willing to expose shared memory if the
ultimate gain from it is supporting
multi-threaded native code so you can
just mash together everything you can
mash see with JavaScript it's not just
mashing different web apps together
anymore I got through that faster than I
expected but if you want to know more
there's websites for Knakal and script
in try pepper j/s appspot com for some
of the examples I was showing tweet at
Native Client one of my co-workers a
troll he'll enjoy it and email me if you
have any thing to talk about and I think
we have four minutes and we might
actually be able to take questions for
the first time ever so anyone curious
about anything ok so the question is are
there potential optimizations where you
can just copy stuff into shared memory
and
has a pointer to workers and that's
essentially what the fluid simulator was
doing is that it had this grid of data
and it was saying each of these threads
you're responsible for calculating the
next version of this data for this
specific sub square so is it was
essentially handing the pointer off to
the worker and you know kind of a reason
of memory and said process this and give
me the result so for the non shared
memory version what it was doing it was
actually copying out that chunk and
sending it over and it was a little
worse than that because postmessage
takes about a millisecond to do a full
round-trip you know it has a high
throughput but potentially also high
latency and because of the high latency
when you're actually doing the fluid
simulator like every update your having
to iterate about a hundred and twenty
times on a specific calculation called
the Jacobian so if you do that all over
postmessage then that means you're
taking about a hundred and twenty
milliseconds just for communication
which obviously doesn't work so instead
you have to do things like actually send
it more data than it needs it says
ultimately you're responsible for this
little square but i'm going to give you
data for this much and you're going to
calculate a region that's about twice as
big just so you can predict what your
neighbors are doing and you don't have
to communicate so when you look at those
numbers where you see no speed up what's
actually going on is you're having to do
pretty much twice the computation and
all the workers just to avoid
communicating because communicating is
so slow so when you're talking about
avoiding copy by passing pointers to
workers the big win is actually
communication speed is on modern
processors copying isn't too bad as long
as you don't have to GC afterwards and
if you can't avoid it you get an
additional improvement but the big
improvement is with synchronization
speed aha so why are we backwards
looking why are we worried about all
this legacy code well this is often
brought up in these wars about should we
have shared memory or not and my answer
to that is that people are still writing
new native code every
you know everyone talks about native on
mobile so if we're talking about
compatibility with native code we're
really talking about can mobile
developers easily port back and forth to
the web you know can we make the web as
a last bastion of not being a walled
garden you know if you want to be really
political about it or something like
that so it's about compatibility with
different platforms one other thing else
and people are saying well why don't we
provide an eye slits API you know why
don't we say that native code just gets
web workers and you have to send
messages between the different threads
in native code in how are you going to
get people to do that you know that's a
huge change so you're still asking for a
world where people have designed for the
web first is they have to say well I am
taking on these constraints where
everything goes in web workers and I'm
not using any library which happens to
use a thread so there's a fairly
hilarious discussion I saw on the M
script in IRC or someone's like I can't
compile this library it's saying not
finding win threads H or something along
those lines and then the person is like
well you can't have threads and they're
like I don't care if I have threads I
just want the library to work so there
there is certain mash ability things is
you just want to put the libraries
together and have it work and not worry
about the underlying things so requiring
a massive rewrite of everything that's a
bit of a non-starter thanks Nick
bye</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>