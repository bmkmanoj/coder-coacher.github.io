<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Jenna Zeigen: On How Your Brain is Conspiring Against You Making Good Software - JSConf Iceland 2016 | Coder Coacher - Coaching Coders</title><meta content="Jenna Zeigen: On How Your Brain is Conspiring Against You Making Good Software - JSConf Iceland 2016 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Jenna Zeigen: On How Your Brain is Conspiring Against You Making Good Software - JSConf Iceland 2016</b></h2><h5 class="post__date">2016-09-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XNfpnCLbRmc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everyone and welcome to my talk on
how your brain is conspiring against you
making good software so uh as was
already mentioned I'm an engineering
manager at digital ocean which is a new
york-based company that tries to take
the cognitive load out of managing your
infrastructure i'm also an organizer at
a vampire j/s which is a jazz family
conference in manhattan and that's uh
organizing a conference is a lot of work
a lot of things go into it so just take
a few minutes or a few seconds to give
round of applause to all the organizers
and volunteers cuz yeah they're awesome
so yeah I'm also zeigen vector on
Twitter so if you want to tweet
questions at me while I'm up here try to
answer them as best as I can once I'm
not up here anymore I've also tweeted
out the link to my slides that interests
you right now so before I was a
JavaScript engineer and way before I was
an engineering manager I studied
cognitive science in University
cognitive science of talks about a lot
of things like thinking decision-making
attention vision consciousness and my
personal specialty human language
processing but if you were to ask you to
sum up what I learned in all those four
years into one concise sentence it would
be that humans are predictably
irrational this predictably irrational
phrase was coined by a psychologist
named Dan Ariely who in fact has a book
by that title but what does this mean
that we are predictably irrational it
means that we employ predictable tricks
patterns and shortcuts that allow us to
make more efficient decisions to have
what's called cognitive economy but this
fast thinking often causes us to deviate
from rationality in our judgments to
make what to other eminent scientists in
the field Amos Tversky and Daniel
Kahneman have have called severe and
systematic errors and these errors are
called cognitive biases which is a
phrase that you
might have heard of a few times but this
is a JavaScript conference and not a
cognitive science conference so what
does this have to do with code right
well my job as an engineering manager is
to make sure that my team which is
comprised of humans is happy getting
their work done getting along with each
other growing as individuals and as
programmers and it's also my job to grow
my team to make it the most successful
my team is like my product so I've
started to think back to my cognitive
science years and I'm trying to figure
out especially how these cognitive
biases and other quicksilver mushy human
brains affect us as we're making
software in the environment that were
making the software in because software
isn't just about code it's also about
humans software isn't software if
there's no one using it I think so yeah
I try to think about these cognitive
biases because even the most calculating
software engineers is a human and
therefore subject to these cognitive
biases no matter how much they think
that they are immune to the
rationalities of humankind so I'm going
to talk about these things and first I'm
going to talk about logic so one of the
fundamental underpinnings of programming
is logic in programming we have f
statements all statements bullion's
ternary operators but computers can only
do what humans tell them to do and it
turns out that humans are not very good
logical thinkers what are the tools that
psychologists use to test this is called
the categorical syllogism we have one
right up here on the screen so a
categorical syllogism is a logical
argument with two premises and a
conclusion and scientists will ask
humans hey does this conclusion follow
from the premises so I'll give you a few
seconds to answer that question for
yourself
so when this was presented to
participants eighty-one percent of them
said yep the conclusion follows from the
premises ten percent said something else
wrong and only nine percent of people
got it right um so that's not great and
reasoning about complex if-else
statements isn't much better so a
psychologist damn place in came up with
the task involving four cards in which
every card has a letter on one side and
a number on the other side and
participants were asked to evaluate this
rule if a card has a vowel on one side
it has an even number on the other and
then asked the participants what cards
need to be flipped over to make sure
that this real checks out so formulate
your own answer so only four percent of
people got the right answer four percent
which is to flip only the a and the
seven over if you're stumped about why
this is right remember that the rule
says nothing about what has to be on the
other side of consonants so what does
this mean for testing our code properly
right if we can't come up with questions
to test rules that we hold to be true
how are you going to test our code and
what type of bugs are gonna arise from
this right but luckily there's some hope
which is that we get much better about
reasoning about concrete examples so
some other scientists adapted way since
for card task to test a concrete rule
which was that if a person is drinking
beer they must be over 19 years old and
in this case seventy-three percent of
people got the right answer so an
improvement but like still not great so
when we inevitably make a mistake in our
code logical or otherwise because after
all we are humans we're gonna have to
end up debugging our code and as
computer science elaborate e brian
kernighan said debugging is twice as
hard as writing the program in the first
place so why exactly is debugging so
hard I think there's some cognitive bias
ezel will help or not helping us to
debug well one of them is a confirmation
bias which is that we have a tendency
to search for interpret favor and
remember information in a way that
confirms our pre-existing beliefs or
hypotheses we also give
disproportionately less consideration to
alternative possibilities so an
experiment to test this Wayson did it
again and so for instance they gave a
trio participants a trade-off numbers
like 246 and told the participants that
the trio couldn't form to a specific
rule and their job was to figure out
what the rule was by asking if other
trios also informed the rule in this
case is actually pretty simple that the
numbers just have to be in a sending
order but people ended up having trouble
especially when they asked only
confirming questions and not
disconfirming questions if you were to
say like oh I got the rule it's like
does 6 8 10 apply like yep you would
probably just keep going down the same
path but if you're like I'm gonna try
something different one to a million and
they said yeah that also it works then
you have more insight into what the rule
actually is but we tend to scrutinize
disconfirming evidence we try to find
flaws or ambiguities in in this evidence
blaming say when you're like when it
relates to code a bug in the library or
it was someone else's code that has the
bug in it and even when the facts are
clearly stacked up against the belief
that we are holding true we often throw
out those disconfirming facts especially
when the issue is emotionally charged
such as when your code has a bug in it
we also tend to be rigid in how we
approach problems so if you write the
wrote the code you're going to be rigid
and stinking thinking through the the
problem and it's going to be hard to
think outside the box and squash the bug
especially if it's on a conceptual level
I know I'm guilty of substituting the
single equals four triple equals and
even that type of bug is hard to find so
when the bug is on a more conceptual
level it's that much harder to find and
squash and we even sometimes tend to
block problem solutions based on past
experiences because we have an inability
to see problems from a fresh perspective
I think a great way to get around this
is to pair on squishing bugs so
you get that extra set of eyes when
you're particularly stuck another thing
that's so frustrating about debugging is
that sometimes it feels like there's no
end in sight but you're just searching
and searching like why is this not
working it's frustrating then there's no
light at the end of the tunnel and this
is because we often have no idea when
we're going to solve a problem even the
30 seconds before we end up solving it
and so to test the scientists give
subjects in sight problems kind of like
word problem brain teaser type things
and as they solve the problem the
scientists ask them as the participants
to rate their progress in terms of
warmth so how close do you think you are
solving this initially they gave ratings
of one to two and then their warmest
reading abruptly spiked when they got an
answer whether or not it was correct or
incorrect breaks are also more important
than you think when you're trying to
solve a problem and I know when I'm
trying to squash a bug i'm like dead set
on trying to solve that no breaks until
i finish it but breaks are actually
really good and scientists think that
this is because it helps you forget
misleading hints so to test this like
how it just gave participants some
puzzles to solve as well as misleading
hints the control group had a minute
without breaks to try and solve the
problem and the experimental group had
30 seconds or interrupted for a short
bit and then had another 30 seconds the
interrupted group actually did better
and it was found as a group were
actually less likely to remember the
misleading clues suggesting that maybe
these two things were correlated a
creativity is also a kind of you know
kind of like feels like it's involved in
squashing a bug or in problem solving
but what exactly is creativity well
scientists think it's really actually
nothing special it's just when the sum
of all your experiences memories
training and motivation come together in
the right way to give you the right
tools to solve the problem all right so
now that we are writing our own code and
finding the bugs in it and maybe there's
some people helping us we've entered
into this realm of working with other
humans and maybe even trying to read and
other people's code but this is hard
because again we tend to think about
problems in fixed ways when you're
reading someone's code kind of like
you're getting into their head right
you're like you're seeing how they solve
the problem and that is unlikely to be
exactly the same way that you would have
solved the problem therefore it's harder
to understand what they're doing nefer
makes it that much harder to read the
code um also we tend to use other
people's code when we're using libraries
but y'all might have heard of the not
invented here syndrome which is that
we're kind of averse to using things
that we didn't write and cognitive
scientists have called this the IKEA
effect it's a fairly new phenomenon so
scientists ask participants to assemble
ikea furniture build lego contraptions
and fold origami and then they were
asked how much money they would pay for
their creations as well as for experts
creations participants were willing to
pay the reasonably safe amount of money
for their finished amateurish
dilapidated paper cranes as they were
for beautifully folded professionally
folded origami cranes and while this
particular experiment was mainly about
money I think it's it's very to
extrapolate to look value in general
like how much we value other people's
code versus how much we value our own so
like that's why we don't want to use
that library that has been battle tested
and seeing the bugs have been fixed
through lovely open-source processes
that have been used in in ways that may
be similar or different from the way
that you're going to use it so working
with other people maybe you're on a
software team and therefore you probably
have to do sprint planning or something
or like tell someone how long it's going
to take you to finish that bit of the
project you know my job as an
engineering manager is to make sure that
my people get their work done in a
reasonable amount of time but there's
something working against me which is
that we're really bad at making
predictions about how much time it's
going to take to do something
and this is called the planning fallacy
so an example of this was some
psychologists asked 37's like students
how long they thought it was going to
take them to finish their senior theses
and the average estimate was about 34
days but the actual average time that it
took these people to finish their papers
was about 56 days with only about thirty
percent of people finishing in the time
that they predicted this phenomenon
occurs regardless of if people know that
past tasks that were similar also took
them longer than they expected didn't
really matter and this also really only
happens for our own tasks whether we're
working by ourselves or in a group for
other other tasks to other people's
tasks we show a pessimistic bias we
think it's going to take them longer
than they say and this is part of a
larger bias called the optimism bias
which is that we think that bad things
are more likely to happen to other
people than to us this is seen in 00
wide array of situations not just
planning our software projects so people
tend to think that there are like less
susceptible to crime than other people
or less susceptible to the whims of the
stock market all sorts of things so yeah
we're not really great at that we're
also often so worried about wasting time
that we've already spent and invested
resources in that we don't consider like
the cost that it's going to take to
continue doing something that's like
slogging so this is called the sunk cost
fallacy and I think it's contributing to
us wasting a lot of time and things that
are just taking a really long time so
once you've been through that sprint
planning meeting that took like three
hours you probably have to go back to
your desk and start working maybe in an
open office so the person like right
next to you is on a Google hangout with
a person right next to them so there's a
lot of noise and you know this isn't
really the best for productivity but in
the grand scheme of things we're
actually pretty good at filtering out
unwanted stimuli and this is called
selective attention scientists like to
study selective attention by doing
what's called a dicot
listing task with shadowing so
participants have to to speech dreams or
sound streams going into into both of
their ears so in one ear participants
will will get a stream of speech that
they're supposed to repeat back and in
the other ear they get speech music
something they're not supposed to pay
attention to that and when questioned
afterwards participants generally have
very little recollection of any semantic
content that though they weren't
shadowing so the purple well that
contrast is off so yeah like a switch
from English to German goes unnoticed
like you could tell them things that
they don't want to hear they won't
remember but physical attributes of
sound are are remembered so people
generally are able to recall if the
unattended channel is speech or not so
like they're in your office there could
be like music playing you'll know that
there's music playing but maybe not
listen to the lyrics but when you're
listening to the lyrics you're probably
not going to be able to focus that much
on writing code but if there's something
salient in the and the speedstream that
they're not listening to like their name
or some like not safe for work words
people usually notice them and this is
called the cocktail party effect so this
suggests that selective attention
requires both ignoring like active
ignoring and active paying attention and
so just because we're good at selective
attention doesn't mean it's good for us
we're putting in like active mental
effort to blocking out things that we
don't want to be paying attention to
which means that there are less mental
resources going towards the stuff that
we actually need to be doing so we can
only pay attention to so many things at
once mostly one thing and we have a
limited supply of mental resources and
we often don't have the budget to do
more than one thing at once so you're
unlikely going to be able to keep
writing that difficult algorithm if
you're trying to listen in to that
conversation happening 10 feet away
between your engineering manager and
your product manager that if the project
you're working on that with that
algorithm is going to get scrapped
tomorrow not going to be able to
concentrate
and this is because we are sometimes
helpless to the processing power of our
brain because our brain just does things
automatically in an attempt to be
efficient so if you had an email account
any time around the early 2000s this
might look familiar and this is actually
real science it's called the Stroop task
and if you're not familiar with it the
idea is that you're supposed to say the
color that the word is written in not
the color not the word itself and the
leading theory about why this occurs is
called automaticity so all reading is an
automatic committable process that we
don't really have to think about very
much but recognizing a color isn't
automatic process so while reading
doesn't need controlled attention it
uses enough resources to reduce the
amount that we can then dedicate to
saying what what color the ink is all
right so as I said before software is
actually about people and this lovely
phrase comes from the amazing people at
and yet and so when I heard this it kind
of like changed the way I thought about
software and about engineering
management like it's not just about the
code again I said this in the beginning
it's also about the people and without
humans was supported trading software um
so now we're gonna start to get to
villach human side of all this right so
something that's getting in the way of
us being productive on our teams I think
is that relatively unskilled people
think that they are better at tasks than
they actually are this is called the
dunning-kruger effect and a funny story
it was inspired by the case of a dude
who robbed two banks after covering his
face with lemon juice since lemon juice
can can be used as invisible ink he
thought it would cause his face to be
invisible on the security cameras which
is like unfortunate i guess um and this
is part of a larger phenomenon called
blue Sri superiority which is that we
tend to overestimate our own skills and
abilities so we think that were like
higher
elegance we're going to be better at
performing tasks and tests we think that
we have like more desirable traits and
characteristics than other people but
sort of example of this was in a survey
of faculty of the University of Nebraska
sixty-eight percent of these teachers
rated themselves within the top 25% for
teaching ability and more than ninety
percent or you to themselves as above
average but like that doesn't math uh
like fifty percent of people have to be
below average that's just how it works
and like well I'm like all of you are
below average in something like I'm
below average in height uh like doesn't
mean that you're bad at what you're
doing just below average so like how is
this getting in our way right so you're
not gonna make good software if you
don't realize how much more you have to
learn if there's ways you can make your
software better but you're not really
open to learning them because you think
you're the best your software isn't
going to be good um and there so there's
the flip side of this which is that
skilled people often underestimate their
abilities and think that tasks that are
easy for them are easy for others so if
you've been doing this for a while you
might forget what it was like to be a
beginner you're not gonna have empathy
for the beginners on your team that are
actually integral to your team they're
going to ask questions that are
important to making good software going
to ask things that you're not really
thinking about anymore so if you if you
dismiss their questions they're not
going to ask them any more and then your
software isn't going to be as good as it
could be but this this can also manifest
in a different way and if you attended
the last talk an imposter syndrome you
know what impostor syndrome is the the
short of it is that people sometimes
think that their accomplishments and
their achievements are the result of
luck timing deception like they pulled
the wool over someone's eyes they don't
deserve what they have when in fact they
probably do and some studies suggest
that this is particularly common among
high-achieving women but across the
board even
of the best programmers I know suffer
from imposter syndrome so we're working
with people and we're working with the
team so how do we assemble the best team
and how are these cognitive biases
getting in the way of us assembling the
best team possible I think one of the
things getting in the way is that we
tend to favor members of our own in
group so and this is getting in the way
especially with those like referral
bonuses right you you get a lot of money
for referring people in your social
circles that you think you're good
programmers but if our social social
circles tend to look like us you're just
going to refer them so if i were to
refer people who looked like me my team
would just be a bunch of white women and
that's not good either so we want to not
do that so another thing getting in our
way is called the fundamental
attribution error so people have a
tendency to attribute situations to
other people's character rather than to
external factors so a classic example of
this is like you're driving down the
street being a law abiding and driving
the right speed limit and then all of a
sudden someone like rushes past you and
you're like ah what a jerk they're like
breaking all the laws and they're
causing a dangerous situation on the
road but maybe in fact they're driving a
loved one to the hospital and they're
they're not really thinking about laws
they're just thinking about their loved
one in the back seats so if you were in
that case you would know you would know
to have empathy for that person and it
has nothing to do with they're not like
a jerk actually so this also happens on
a larger scale something called the
group attribution error so people have a
tendency to believe that attributes of a
group member reflects the entire group
so I thought this was well explained by
this XKCD cartoon so unloved on the
right you see two dudes and it's
actually on the left nah I'm below
average in which direction is which so
on one side you see two dudes one who
apparently is not great at math
and his friend is saying why do you suck
at math on the right we see a dude and a
woman and the woman apparently is not
good at math and the guy is saying wow
girls suck at math so why does this why
is this kind of true um but studies have
shown that the the group attribution
error is stronger and perceptions of
groups that are viewed as more too
similar to once owned and this doesn't
really happen with perceptions of our
own groups so decisions made by people
in our own group are the result of
structural constraints but decisions of
other groups are the result of their
attitudes so intact perhaps it's not
that certain groups of people don't want
to be programmers maybe just maybe there
are structural forces making it harder
for them to do so something else that I
think is getting in our way is called
the availability heuristic and this like
the popular example of this is that like
why people are so afraid of plane
crashes which is like we hear only about
plane crashes and not successful plane
trips so there are those examples of
unsuccessful plane trips are more
salient in our mind and therefore like
the plane is going to crash so I think
this applies to to our program and
communities and that like if we are
surrounded by people who all look a
certain way and if the the prominent
members of our community the main
contributors to open source and the
people who we see on stage I'll look a
certain way we're going to start to
think that there's the people in our
community and those are the only people
in our community and those are the only
people who can contribute to open source
and the only people who have good ideas
to talk about on stage which is not
necessarily true something else that's
also getting in our way is called the
representativeness heuristic which is
that essentially that we find we think
that categories are relatively
homogenous so if someone is a software
engineer and expect them to have the
traits that we associate with the
software engineer and vice versa and
this heuristic leads to several by
sees such as something called base rate
neglect so diversity in kahana man ran
an experiment in which they gave
descriptions of a group of people so 100
people and 70 are lawyers and thirty
percent are 30-year engineers and they
found that participants often said that
someone who sounded like an engineer was
more likely to be an engineer even
though the probability was against that
because there were 70 lawyers and 30
engineers I've seen this come true at
programming meetups both it's built
happened to me and to my friends where
we're at a programming meet up it's very
likely that people at programming
meetups are programmers but people have
come up to him in like are you a
designer are you a recruiter like no I'm
at a programming meetup of a programmer
it's like not good Oh so um might it be
able to tell them kind of talking about
diversity here um so like why is
diversity important for assembling good
team and creating good software well so
i mentioned that creativity is all about
collective is about associative memory
so when you have a diverse team you're
going to have a wider array of of
experiences of backgrounds of interests
and therefore you're going to have
better collective associative memory and
therefore you're going to be more
creative you're going to find better
solutions to problems that's going to
lead to better software so what can we
do about all of this right so first off
like don't feel bad your brains are like
literally programmed to do this because
like back in the day we were just
supposed to like escape predators but
now we are sitting at computers thinking
all day so it's a little different so
like the quicker that you can think the
quicker you're going to get away from
that tiger that's chasing you and you're
going to have more cognitive economy so
this thinking fast system is called
system one in the literature and the
thinking slow system is called system to
in the literature and if you might have
read a book or heard of a book by this
title
making fast and slow by Daniel Kahneman
so like what can we do about this right
like we're as I said we are literally
sitting there and thinking our job is to
think and we usually take a really long
time to think through very hard problems
so if we just take that same amount of
time and apply them to things that we
might not think about as much just take
another hour to make those hard
decisions then we're probably going to
end up making better software that more
humans can use and we're going to end up
making these things with happier humans
so thanks for listening that's me and
all my emoji friends you can find my
slides at that link tweet at me it's
like and vector and thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>