<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[JSConfEU 2010] Felix Geisendörfer: Dirty NoSQL | Coder Coacher - Coaching Coders</title><meta content="[JSConfEU 2010] Felix Geisendörfer: Dirty NoSQL - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>[JSConfEU 2010] Felix Geisendörfer: Dirty NoSQL</b></h2><h5 class="post__date">2013-06-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NSY3y8-ktIE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right um yeah thank you for coming
and listening my talk is titled 13 oseco
how simple as your database it's
basically about writing your own
database in noches and why it's maybe a
really stupid idea but maybe some parts
of it or not and yeah just a little bit
about myself I'm an OTS contributor I
picked it up right wins mailing lists
were still pretty small 30 people I have
to start up with imma cofrin edit
transload it we do a video uploading and
encoding as a service one of my bigger
open source projects with node is a
driver for my sequel which is pretty
crazy talking to the binary protocol and
other people are binding the native seat
driver for node but this one is
completely built in notes that
everything is non blocking it's not
using any Z code you don't have to
compile it and I hope I can get some
performance pretty close to whatever she
can deliver and I'm also a source of one
of the libraries so you can use a note
to talk to couch TV and so I have a
little bit of experience with working
with databases as a user as a also of
client libraries but I'm not necessarily
an expert writing databases so if at any
point you think something is completely
crazy and stupid please let me know so
we can filt out it's a good stuff from
the bad stuff all right ya SE on that
I'm really happy to be here so volcanoes
this time get defeated places channel by
channel men here and I hope it's not
showing up again first of all i'd be
interested in what everybody's using
these days I mean we hear a lot about
people using no sequel but what about
this room who's using a no sequel
database in general that's about half of
the people with no sequel database
couchdb that's a bunch of people are
Redis a bunch of people's well Mongo
anybody crazier Reich or other stuff i
haven't mentioned Reich okay anything
else totally out of the ordinary okay so
Cassandra apparently it's not
represented and goose using
a sequel based database that still be
most of the people with my tickle or my
sequel that's a bunch post crew the same
people also i think some people
restaurant choice yeah anyway but good
to know but i think there's still a lot
of people using sequel and a lot of
people using no sequel my general
opinion about it is just because no
sequels all the cool hype and stuff
today i think most of the applications
people build these days until they get
hit so hard that it becomes a scaling
problem what database technology you
choose you should really look at your
data it's a relational or not and if
it's relational I mean Facebook's it
scales my sequel it's possible so but
nevertheless I like to play with the
cool stuff as well and he comes
presentation on dirty basically as idea
behind dirty is said I really like
couchdb when I first played with it i
really liked writing my query code in
JavaScript having JavaScript views I saw
that was really neat and more
interesting way to get at your data sand
queries and at the same time I haven't
really used it much but I looked a lot
at it and learned a lot from it it's
Redis which is also very interesting key
value store trying to solve a different
class of problems but it's basically one
of the fastest ones out there it's
basically you can imagine it as
memcached but with this back end so when
you restart your cache server it's not
going to be all gone but as some people
are also starting to use it as a
full-blown database um so let's talk
about a little bit of the design choices
in this library so now I'm working on
the biggest one of course is set its
build on noches having is an unlocking I
also wicked fast v8 JavaScript engine or
big wins for anybody trying to write a
simple database how big is the win you
can see here it's 150 lines of code
compared to a couch TV or read us which
each way in it about 16,000 15,000 lines
of code my sequel by comparison has a
code base of 1 million lines of code but
it's really hard to tell from the
reproach
it's really hard to tell from the
repository how much if it is a bunch of
crap that's not even executed when you
run a database and how much it's
actually used so I'm not going to put
that up but yeah basically 150 lines of
code for me it's a design choice because
I'm going to talk about it further but
this library is meant to only solve a
very specific class of problems and then
show solutions to other classes of
problems by taking yeah tricks and stuff
that I learned writing it but it is
minimal on purpose but I think it's
useful even with the minimal way it's
structured so another design choice is a
really simple of file format the file
format is actually new line appended
chasing so whenever there's a record
written to disk it stores one chase and
entry it has two keys the first one is
named key and holds the value of the key
and the second one is Val which also
value so the value can be anything can
be string and object anything is that's
chasing zero realizable and saying goes
actually for the key um so what's good
what's bad about this status you can
already guess it's not going to scale
forever that's going to you're going to
hit the point we're loading your
database is going to take forever
because and you cannot really seek to a
specific point so that already limits
the scope of this project drastically
but at the same time if you're starting
out using in technology like this can
you imagine a sweeter database format
for eventually migrating to something
else I think it's really easy you could
probably do it in a bash script so that
that's a design choice and I'm pretty
happy with it because I think it works
well for what I'm trying to do with it
and also works well for bigger systems
with bigger goals like gratis they're
doing the same thing they have a more
optimized data format but also in depend
only luck with no indexing whatsoever as
far as far as I know and this was
probably the most interesting choice
there's no networking this is an
embedded database which has downsides
but it also has a lot of upsides as you
can see it's really easy to get started
you basically install the code you get
this little module called dirty which
you can require and it returns a
function which actually basically some
functions that runs the constructor of
it and so the first parameter pests
entered is the name of the database file
so do you want to access and there you
go you have the database object you
can start setting he's on it getting
keys on it and a lot of pewter wizard
first of all you don't need to write a
client library every new database that
comes out basically requires people to
go out and write new client libraries
would be it read as couchdb which is
smart they're using HTTP or mongols they
all need native clients that's a lot of
code that needs to be written on the
server side to support the clients
asking questions and delivering those
results but it's also a lot of work on
the client side and every other language
that you want to use it in it's not
going to work so i had to benefit
there's no delay on setting and getting
keys and there's also no issues with
networking in general no connection
issues you don't need to also indicate
because your file system issue
permission system you build on top of
that um yeah here's another example that
shows how easy it is to use you
basically set a key give it a value and
then once you have a bunch of keys in
your database you can use DB for each to
iterate over them and that's basically
how you queried there's no filter
function per se but you could create an
array above so for each line which
basically captures all the data that you
hit a right over and that makes it
really minimal you've already seen most
of the API on this project that because
i can type them in and change them
however i want them and a lot of people
doing benchmarks do that but what's
actually even worse as they try to
publish benchmarks of benchmarking
against other databases and it is really
difficult to get this right i think yan
who's not here has a really nice i'll
take around it most of these benchmarks
that you see will compare apples to
oranges one database might just a whole
lot more an incident has it has a whole
lot more guarantees and what's happening
is in another so benchmarks are really
tricky and unless what you want to spend
as much time as writing your project
takes and doing the benchmarks properly
and also getting to know all your
competing databases you shouldn't do the
comparisons and draw conclusions from it
you should if anything look at the
underlying algorithms and see if they're
suitable for your problem but anyway
standalone it has a pretty good
performance if you call a get operation
you get 50 megahertz which is 50 million
get operations per second out of it I
don't know why you would need that but
where this interests
since its v8 primitives underlying
object types in the v8 engine are fast
enough to pull that kind of stuff off I
mean I have to be v8 number at the
bottom it's like 160 to 170 megahertz to
get keys from an object and I think that
makes it really fast engine and maybe
fast enough to write bigger systems and
this one is because once you start doing
more algorithms more iterating over data
in more complex database that's going to
be a bottleneck if you're really crazy
enough to write a database in JavaScript
if you write an season well you almost
writing native processor comments
there's not a whole lot you need to
optimize anymore but here you need to be
careful that your bottom like is not the
language and it may very well might be
then the set operations also very fast
not quite as fast that it can run at
five megahertz v8 that's 12 megahertz
the performance is pretty much lost
because I need to do two operations
when's that is called I need to set the
object key of the key value pairs that
I'm writing on the object and then I
also have an array which is basically a
queue of all the keys that still need to
be written to disk so I push into that
array and I sat on this object so these
two operation is what cuts the
performance in half but then again find
me this that can do five million inserts
a second I it looks pretty hopeful that
the language primitive here is not the
bottleneck for pulling this off now
maybe more realistic or interesting way
to look at it when you're actually
flushing to disk because obviously the
numbers before I'm not flashing to this
was basically putting stuff in as fast
as possible and then well secure for the
disk right would flash eventually but
these are actually numbers for flushing
items to disk and if you're using pure
numbers as a key in value pairs you can
do about 200,000 these chasing records
the second I think in my set up by
benchmarks this machine though your
numbers may vary a few times but
probably not an order of magnitude
the main bottleneck is serializing to
chase me and well on the other way also
deserialising from it another number
next to it is if instead of writing
Tristan number as the key value pair but
you use a 256 byte string you get around
70,000 records per second so what I
really like about these numbers is that
it really looks comparable to what other
systems that are performing similar
operations can do like read us basically
when you go through the network they
have benchmarks of being able to set and
get around a hundred thousand keys a
second and so you can tell that memory
access is so so much faster network is
actually slowing red ass down while red
is a setting and getting keys it's
basically idled processor time it cannot
the network is not fast enough to fill
out your cpu speed which i guess you
should know but that's really
interesting thing to know about
databases like some of the stuff is just
loss of physics I mean your light is
only going to go to so far or so fast
and your electricity and there's nothing
else you can do beyond set so actually
the design choice of embedding a
database into your process where you can
share memory no inter process
communication your networking might be
an interesting one for certain stuff oh
I had one number I forget basically when
I runs the same operations without
chasing serialization the numbers change
from left to 2500 hurts and to 400 two
kilohertz sorry not hurts kilohertz on
the other side so its adjacency
realizing is holding it up quite a bit
like 10 times and that's a for each loop
this basically is used to iterate or
reserve all the keys and all the values
in the database that's probably the
biggest bottleneck right now it could be
much faster busy what it does it's doing
a four bar in and then calling a
function on every object that it meets
and that is sub-optimal because first of
all it's blocking so while you're eating
over your data set you're not doing
anything else and second of all you
can't stop in
between for war in is basically
everything or nothing so one of the
things I'm probably still going to do is
whenever a key is being set and I'm
going to maintain an additional area
which lists all the keys and then I can
iterate over all the keys much faster
and I can also choose to only partially
iterate over the keys that i have that
will make the set performance a little
bit slower probably cut it in half again
but at the same time for each can become
non blocking and can become much faster
but I didn't have the time to do it yet
it makes implementation a little bit
more difficult oh and yet as you can
already see this implementation hits the
wall at some point my design goal with
this database is to make wonderful
database for less than a million records
so basically if you're new to note I
mean how many people have played with
node yet in this room all right not
everybody so if you're new to note and
you just want to get started as quick as
possible and get like a little type
project going I want this to be the
database of choice that is easy swelled
in that will work and you can even if
your little project takes off it can
even scare for a little while I mean a
lot of applications are say i would say
i don't know more than half of the
applications that run on the web right
now will never need more than 1 million
records it's only it's really successful
once and we are lucky when we get to see
scaling problems but i think this
database is really easy to migrate from
because it doesn't do anything special
that other databases can do but it does
it really fast for the lesson 1 million
record market but yeah basically after
that you're hitting the wall I mean
you're for each new biz clocking I might
fix it but your queries are going to
take a very long time iterating through
all of that you're going to have to
start in doing indexes yourself
optimizations yourself which might be
fun you you might be able to push this
much further but at the same time not
everybody wants to write its own
database code but I think that's the
next part I think maybe noches has the
possibility of writing something like
couch to be in it it has some non
locking I oh it has excellent networking
and it has a lot of other really good
parts in the stack and very fast
interpreter so what's the rest of my
talk is but looking into the
possibilities of actually taking note at
building a more
advanced system out of it send dirty
dirty is just my interest in building
such systems but I wouldn't have the
time to build something compatible to
are compatible comparable to CouchDB
aratus that's going to be a big laugh
effort but what I'm exploring is it's
possible that's the v8 engine allow you
to do it does not allow it to do it
let's have a look again sir it's a
problem we up against that's the
internet traffic cross over time I
started from 2000 and as you can see
we're going to need to think of
solutions for the data problem very
quickly because the data is growing
exponentially the number you just saw is
there's 22 exabyte per month every month
going through the internet right now
it's 22 billion gigabytes I had no idea
what that actually means but one exabyte
is about 50,000 years of DVD quality
video I had no idea so much porn exists
but apparently apparently it does and
yeah ninety percent of the internet
traffic in 2013 is projected to be video
so not all of its going to be data data
in terms of what we still on a database
but it's still going to be a lot so what
is one of the things that I really like
about my little key value store said
might make an impact on solving this
kind of data problems I think one of the
things is flexible guarantees with most
databases you make one big trade off
most of the time either you're
guaranteed said when the database says
the record is written it's really on
disk and it will stay there or it says
well I has it on my list of things to do
and I'll eventually get to it but if my
power is being cut off the record is
lost forever and has a big problem
because I think a lot of applications
actually have mixed needs they have data
that needs to be really transactional
you say it's stored it needs to be
stored and a lot of other stuff you
don't care if you lose a record here
there and what you can do with nodes
thanks to non-blocking i/o is you can
set your key value pair and as soon as
you said it it's written to the object
you can access it again that's the
console log record written to memory
down there and then you get a call back
when it's actually flushed to disk so
you can get both events you can get okay
it's ready to be worked with part of a
query
and it's ready to this so if you reboot
me it will still be there I think that's
really interesting concepts that is
would be really difficult to pull off
with any other embedded database
technology well by the way what I also
wanted to talk about how this actually
works internally so right mechanism of
dirty works that whenever a record has
written it starts flashing it to disk
right away and then if there's more
records written with the set function
and the disk is still busy flushing the
first record it cues them all up so
basically the when the first record is
written to disk it looks at the back
loss lock of maybe 1,000 items and says
okay now I'm taking all of these
chunking them to get them to long
tracing string and writes that so all
your rights are pretty much instantly
which with red us I think depend only
lock the I don't know I think they have
two mechanisms now but I think one of
them was to basically do it every one
second or three seconds or something
which you don't really have to you can
use a queue when the disk is busy or
write to disk when it's doing nothing I
think this say have field change yeah
okay so that let get it better um
alright memory and disk high prints I
think one thing I could really imagine
this kind of databases to do is to be
mixture of a database and your
application so you might have some basic
libraries to do data solve data kind of
general data kind of problems for you
but then you can also build memcache
basically into it you don't have to
clear your database and query an awesome
memcached instance just to keep
something very fresh and hot you can
actually have your database do the
caching itself and you can't really do
that with other databases that easily
because as a databases they don't know
about your data but if you use about
your specific knowledge about your data
replication I think you could build up
really nicely replicating data base with
no chairs just because it's perfect for
streaming I mean streaming is one of the
main points of why node exists every
other that technology kind of was fast
before and was kind of usable but none
of them made it really easy to
stream and still do something else at
the same time request responses where
looked at at a singular event you get a
request he process it is that a response
but there's nothing in between with note
streaming is really easy and also
another thing that's really easy with in
regards to that it snowed could hold an
incoming connection if a replicated key
or if a not yet replicated key is being
requested what that means is some of
your clients rights to one of your
database servers in the cluster and then
another client goes and asks another
instance of the same database class sir
for that key but the key has not
replicated yet well note could actually
say if I get a request in for keys that
does not exist I wait for three seconds
if it still comes in my answers a
request as soon as I can meanwhile I let
the connection hang I think said
something where you could build really
small systems that don't have to take
the eventual consistency trade-off
there's a lot of our systems take just
by saying yeah we'll do eventual
consistency but we can also hold a query
for three seconds if we have a hopes
that it's still being successfully
executed in three seconds later web
services you could also use no chess to
act as a proxy for different database
beckons because I don't believe one
database is ever going to solve all your
problems and fix everything especially
when you go to a certain scale but it
would be really nice to have a unified
interface for your business questions
that your your clients are asking and
your cloud that's going to answer and I
think no chairs could make a really nice
clue in between maybe some oh no
database or maybe not talking to a couch
to be talking to rat us back end and
just shifting this data together but
also knowing about your business
problems combining the data properly
doing good cashing it kind of makes it
act as a layer in between and you could
even like query third-party services if
you're building something really big
that depends on a bunch of other
business processes somewhere else your
database could directly take that into
account as well um yeah so that's the
basic thing and I think there will be a
lot of questions about this kind of
crazy experiment I hope so we're period
good idea soon but i'm also open to hear
any that's a really bad ones
okay yeah you just put an if statement
and say if I under such a question
properly if DD
basically says when you get and set
there's no I Oh happening with with
dirty it's clearly in memory and the
only iOS that happens it's actually flat
flashing the record to disk eventually
well there's no network interface you
have no other way of getting at the
database from the outside right so baby
yep no i think i had i didn't have 50
million records in the database because
there's a problem with v8 right now be 8
caps you at one gigabyte of heap usage
one gigabyte is plenty to store 1
million records memory usage on sisses 1
million keys have an overhead of that
around 27 megabytes that's if you choose
store numbers as key value pairs and so
the rest is going to be filled up by
your data whatever lengths you keys are
going to happen to your data but that
get benchmark was also just 1 million
maybe 1 or 10 million records and the
keys and sibelius where numbers so that
was the only thing going on I can
actually show the code for the benchmark
yeah but the main point of the benchmark
was to see okay you can get a key which
is cutting performance in half at this
speed they're still pretty accessible
acceptable for having so many function
calls I mean the 10 million function
colt so that's pretty good and one
lesson maybe to be learned from that as
if you're writing note code was a ton of
callbacks and you're like and all those
functions are going to slow my coat down
now you'll need a lot of functions to do
that a lot of function calls yep what
function ya know for each it's not the
native JavaScript for each it's yeah I
think that was 1 million records and
it's basically using for bar in which
i'm going to replace with the array list
of keys i think yeah
oh yeah you shouldn't use you shouldn't
try to evaluate this against Redis
unless you're planning to have a very
small project yeah but no it's not
there's no query abstractions because
all of that stuff I think it's the main
thing that databases out to get wrong
but because it's a hardest part and
everybody likes it their own way all
right all right um if you want to
download it if you're already using note
you probably have NPM the package
manager so it's NPM install dirty dirty
by the way the name comes from the fact
that this database violates a lot of
good practices that you would think when
driving a database like a chasing attend
the only thing it's kind of crazy but it
works well for 1 million records so it's
dirty hex that gets to chop down for
really small stuff I also mentioned
startup i'm working on trans so did we
do video uploading and encoding it's all
noches based if you're interested in
that chat me up about it and yeah
lossing be careful and don't hit the
wall
hey thanks everybody</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>