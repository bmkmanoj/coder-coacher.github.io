<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[Reject.JS 2013] Astro - Bitford: A streaming BitTorrent client for Chrome | Coder Coacher - Coaching Coders</title><meta content="[Reject.JS 2013] Astro - Bitford: A streaming BitTorrent client for Chrome - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>[Reject.JS 2013] Astro - Bitford: A streaming BitTorrent client for Chrome</b></h2><h5 class="post__date">2013-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-O3MZDAZMYk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi I'm Esther oh and I am concerned
about the internet turning into a TV 2.0
and I don't mean this by convergence it
would be great if old media is being
replaced by Internet but what worries me
is concentration on very few service
providers and there's one area where
this is very very evident under this
video on the web there are two reasons
for this one is search Google always
tries to lure you into YouTube which is
different with BitTorrent because they
are nice BitTorrent sites and the second
reason is traffic video data is huge and
if you've got a broad audience your
traffic demands are high and in
infrastructure so it's worse to look
away from classical client-server
systems and that's why today I want to
talk about a fan site project of mine
called bit fort and I'm going to start
with two related project of mine then
I'm going to introduce you to the
BitTorrent protocol then I'm going to
explain on the the application model I
choose and then it's time for bit for
itself and I hope the demo is going to
work out the majority of this talk will
be about the lessons I learned during
development and then I've got a few
platitudes about the future so in 2010 I
participated in the very first not
knockout contest which went over weekend
and our idea was already to bring toric
to stream torrent data to the browser
and that works like this you take a
torrent file you upload it to the web
server which is implemented in nodejs
and this takes care of the disemployment
stupid torrent protocol requests all the
data in order and streams it directly to
the browser where can be embedded for
playback that work didn't work out that
were because the time frame was very
limited like then was just one week and
and in general
it's a bad idea to do bitter end without
any uploading so this year I learned
angularjs and I did a little tool to
help you share files
it creates torrents files completely in
the browser
it runs client-side so no data is being
sent to any server about what you're
wanting to share I use digest J's for
sha Wan hashing and that year the two
megabytes per second on this laptop
which makes me very confident about
doing more BitTorrent in the browser so
why use BitTorrent because it's fast
Pearse not only download but also upload
and this is contrary to the classical
client-server concept the more people
that are downloading the faster it
actually gets for everyone also because
there are more than just the publisher
who uploads data the publishers actually
save bandwidth and because there are
more hosts that upload the
infrastructure is much more redundant
BitTorrent also features intricate
integrity checks because you cannot
trust random peers that send you data
more on that later so how does it work
you've got a torrent file you can
download from the web or send as an
email attachment they are very small and
you put it in your BitTorrent client now
that client is going to contact the so
called tracker to obtain addresses of
other peers who share the same data and
when you've got these addresses you can
connect to the other clients to actually
share the data and this is called the
wire protocol so these torrent files use
a so-called PN coding which is
structured data format and what they
contain is information about the layout
of the data you want to download which
is like file names and file sizes but
uninteresting as because the the data is
treated as one contiguous chunk which is
divided by the so-called piece length in
this case it's 256 kilobytes which can
be individually checked for their sha-1
hashes which are in this byte string now
if you take the value the encoded value
of this info key you get a you and you
hash that with sha-1 you get your
so-called info hash which is the
identifier for contacting new tracker
for talking with other peers and that
means you can exchange tracker URLs
without creating a different torrent it
will still be the same the same swarm so
that makes it very great for
peer-to-peer distribution of static data
and especially when I'm talking about
streaming here this is not about
BitTorrent life or BitTorrent sync which
is a new system for live streaming and
synchronization but unfortunately they
are neither open-source not openly
specified so that's very sad this is
only about classical BitTorrent here so
the wire protocol is about requesting
chunks of 16 kilobytes this is not about
transferring the whole pieces at once
but always about 16 kilobytes and
because this is such a small piece of
data you need pipelining
and this is my formula for this this is
basically you need to know how many
pieces you have to request all you have
to have requested at a time my formula
is based on a simple bandwidth delay
product over half a second
with the current download rate why half
a second is pretty much for today's
internet connections well I need to have
that download rate go up in the first
place
so let's get to bid fort now it's
available on github and currently
implements the tracker requests which
classically run over HTTP but nowadays
UDP trackers are much more popular
because for the amount of data you're
exchanging UDP is much more lightweight
peer connections of course because you
want to exchange data and there is a web
worker process for hash checking the
data in background because that's quite
CPU intensive as I don't want to keep
all data in RAM at at all times or I
need persistent storage to disk and
because browsers feature great audio and
video playback capabilities nowadays I
want to try media streaming so the
application model I need it because I
want to do TCP connections chrome
packaged apps which give me more api's
and there are three flavors of this one
is the classical extensions which are
intended to augment your browser with
new functionality and then you've got
packaged and hosted apps which have a
different set of api's and they are made
to resemble native apps the difference
between those is that packaged apps are
installed locally and hosted apps are
always loaded from the network so that's
not very private friendly so the API I
needed is the chrome socket API which is
unfortunately only available to apps so
extent I couldn't do an extension to
implement deterrent on the other hand I
would really like to open a tab instead
and you offer a new window but it's not
available to packaged apps and also
there's this integrated download manager
in chrome but the API is way too limited
anyway
so another problem with the API is how
do I intercept for example a I click on
a torrent fire so I can actually start
download
the data not only the torrent file which
is not possible using these api's
there's a Chrome extension for embedding
so using PDF GS and I saw one pool
request that does it like that they
intercept HTTP requests check the mime
type after mime type matches they
redirect to their own viewer to the PDF
GS viewer which then loads the PDF file
for display so this may be a way of
doing it but it's it's really not nice
so and that's where you get to demo time
now I'm not heading over to to pirate
pay or something but incidentally I run
a legal BitTorrent site if you do it's
called the claw fork if you do know any
podcasters tell them to sign up all they
need to do is add their podcast feeds
and then it's fully automatic from there
on so let's look for for some video
content like this and then we start it
for I made the UI a bit bigger and what
we can see here is that it has already
connected to a few peers oh great we've
got ipv6 and what it's doing it's the
requesting data randomly or based on
rarity among the peers we could or
originally I implemented this to request
data in a linear fashion but if there
were multiple clients that request data
in a matter in a linear fashion then
this distribution would become very
uneven and the whole system would suffer
so this is surprisingly fast but if I
now press play data is being requested
at the very front because that's what
the media element is requesting and it
works
and seeking works to and I seek there
and it's now loading from there
all right let's get to some lessons
alert so I need to do TCP connections
and therefore I need TCP client sockets
they are available on Firefox OS two but
what's not available on Firefox OS is
TCP server sockets so I'm restricting
myself to Chrome right now because it
wouldn't make sense
implementing peer-to-peer applications
without having server sockets I also
need you to p sockets because of the
tracker protocol and the future I want
to implement distributed hash table
tracker replacements and the utorrent
protocol so that is critical although
bitter end is a binary protocol and I
really don't want to get swim swamped
into in unicode strings and to me very
important is ipv6 I've been using this
for like eleven years now because it
fulfills the actual the original promise
of the Internet and that is full
end-to-end reach ability if you've been
looking for a killer app for ipv6 look
no further
it is peer-to-peer so chrome socket
implements this or provides this there
is no nice wrapping but just methods and
the Americas socket IDs which reminds me
of the POSIX file descriptors but the
API is either inference so it does not
block which is nice and you always deal
with every buffers the foundation for
type arrays which is binary safe so I
created my own wrapping which has a few
helper methods for connecting out with a
client socket for creating a server
socket that handles incoming connections
with car back and because I do not want
end users on a desktop to configure port
numbers I've got some guessing and
retrying logic there too
the trend is about high-bandwidth of
data so I needed flow control and that's
why I replicated the the pause and
resume logic known from node.js streams
and on the outgoing side I've got the
drain event that is only emitted when
there's no further ID pending so in the
future we will have a nice encapsulation
that is being standardized as the raw
socket API which is quite misleading
because this is not about raw sockets
but about TCP and UDP so now that we can
connect to peers we need to think about
network stream processing these
BitTorrent packets come in in a TCP
stream but they are said packetized so I
need to find packet boundaries and why
the chrome socket API provides or
accepts a buffer size when reading I
still want to be able to process a very
content contiguous stream because one
day I would like to implement the method
stream encryption over the TCP stream
and there's this utorrent protocol to
which uses UDP so my approach is this
yes and kind of scheme to to concatenate
every buffers which is blopps and the
fire-eater api but it's really slow and
in general it is a good idea to avoid
copying so i'm taking a very very old
idea of a buffer list that encapsulates
a race of buffers and I'm just rotating
data through that buffer I appended to
the end and consume it from the front so
I've got this optimization with the
buffer size for the
but that could that makes it much much
faster but that could break the the
network streaming requirement so now
that we've implemented the the
BitTorrent protocol I need a strategy to
to download for streaming purposes and
well what I want to do is when you go to
youtube you just click and play and
ordinary the torrent clients just load
till the end and then you play they do
this with some standard techniques like
just requesting a piece from one pier
that has two reasons one is data
locality those data is being transferred
in 16 kilobyte blocks which which is
really small and it's much more fun to
do this on as as D then on rotational
media also if somebody sends you crap
and the hash check fails you can much
easier isolate the liars that send you
crap
so the exception to this is the
so-called endgame mode when you've got
just a few pieces left that are cute at
very slow uploaders you can also request
those pieces at these chunks at fast
uploaders and this is what it for does
all the times or I can complete pieces
faster even before we're getting into
endgame when the download is finishing
also a few clients to hash check only
when all the data is available which is
really a limitation because we are
living multi-core now and we want to
detect detect corrupt data much earlier
so we do this in the background with a
WebWork process and that allows us to
be sure that this data is valid and we
never deliver a corrupt data to the
media element so now that data comes in
we need to store it away and this took
me really long to get right our
requirements random access to the 16
kilobyte chunks for writing and reading
for uploading and I don't want to have
it all in RAM to avoid memory pressure
because having an eye on RAM would be
much easier so my first approach was
using the provided file system API which
was very naive the provided sandbox fire
system is not the real file system which
would be useful to the user to the end
user but in a paid database on the file
system and you cannot only iterate our
files but to satisfy the requirement of
random access you can read certain
slices with offsets and lengths and if
you create a writer you can seek to a
position and right there but I was still
getting quite a lot of Fayette hash tags
and as it turns out this does not seem
to support sparse fires that are that is
files that have holes in them that are
not yet written
so my second approach was like this I
keep the contiguous data together but
whenever there is a hole I create a new
fire and looked like this in the in the
progress graph but I was still getting a
lot of strange data races and this
traffic was that API was a multiple of
of the network traffic that was coming
in so I restarted this from scratch and
try it indexeddb which is another
asynchronous API so it's nice it doesn't
block like local storage and all the
examples talk about putting binary data
in there
seemed like a good fit the down side of
this is you still because this is not a
contiguous chunk of data that you can
access anywhere the excesses need to be
aligned along the 16 kilobyte limits and
something that was really important for
me especially as a developer I would
like to be able to free up disk space if
the application crashed or something and
I need to find stayed a term so next to
be provides three levels so this
database the object store and the actual
keys and values and only at the very
last level you can enumerate what else
is there to clean up so now comes the
fun part
streaming into media elements there's an
API for that called the media source and
what you do is you create a media source
attach it to the media element here and
then you can just feed data into it but
these source buffers need to be aligned
with the segments of the media container
so that would mean I need to implement
like oak mp3 mp4 matreoshka and I really
this does not the duty of this program
why do we have to care because browsers
deal with death documentation already
when you load data when you load a video
from HTTP from local hard disk whatever
attention cheesy mean picture ahead we
can open TCP server sockets so I just
went ahead took 20 minutes to implement
a web server and localhost and we pass
it off to the media element and
problem-solve that just works
that should probably be replaced with a
was a proper small web server so you can
open it up to the network so you can
perhaps pass the stream to a chromecast
device something like that seeking
support if the the user seeks in the
media element then the browser just
sends HTTP range headers and we can pass
that to the pieces requesting logic
all right that's almost it I've got a
lot of future ideas most importantly
user experience I really need head there
because right now it's unusable and also
the esses problem of handling the
torrent files the user clicks on and
registering for example a protocol
handler for the magnet things although
because I run this bit loft site I want
to integrate feed syndication and that
will enable technology called broad
caching and it was this will make it
much more self-contained you just get
your feet with data and click on
download and play and will just work and
I really I'm really looking forward to
to see Firefox OS image so I'm waiting
for more Network api's to become
available there and it TCP server
sockets and UDP sockets perhaps that
will come with the with the
standardization of the raw socket API
and there are other more BitTorrent
features I would like to implement like
proper upload scheduling getting the
data from HTTP for more robustness if
there are no peers magnetic links are
really nice because you can share
torrents with just a short string which
fit for example in tweet and the meta
information data is being shared among
the peers with the bio protocol the
distributed hash table eliminates
trackers as a central point of failure
and the message stream encryption is not
for privacy with random peers but is
very important for applications when you
have the packet inspection and internet
providers
throttle you it is required in some
setups also what I found a really good
idea is the utorrent protocol which is
which has delay based packets packet
scheduling even before year buffer bloat
problem was recognized so it's much more
friendlier to to other streams in the
network and that will improve on
BitTorrent reputation so to finish up
peer-to-peer in the browser is possible
and if you do not need to rely on TCP
sockets but you can use web RTC then you
don't even need a packaged app but can
do this in an ordinary web page and that
will allow us to get rid of the cloud
because peer-to-peer likes some some
trust you don't have a central server
you can trust we need security and
really we really need faster crypto API
s and as I mentioned we need more ipv6
and we need unmetered bandwidth because
nobody is going to share if they are
watching the download volume so thank
you for listening and this way I can
phone find the software</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>