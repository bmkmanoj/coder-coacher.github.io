<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[JSConfEU 2010] Stoyan Stefanov: Performance Patterns | Coder Coacher - Coaching Coders</title><meta content="[JSConfEU 2010] Stoyan Stefanov: Performance Patterns - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>[JSConfEU 2010] Stoyan Stefanov: Performance Patterns</b></h2><h5 class="post__date">2013-06-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FDCSXQV3Q48" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good evening everyone it's really
exciting to be here great crowd great
conference so let's talk about
performance a bit about me I put a lot
of effort in this life obviously and I
just keep it it's a long flight from LA
right so you've probably heard that
there's Mark Twain attributing this
quote to the British Prime Minister
Benjamin Disraeli saying that so he
reportedly said that there's three kinds
of life lized the damn lies and
statistics so I think the same can be
kind of applied to a performance because
it's it's kind of easy to to read and
follow performance advice out there but
um things that are usually not that
simple or maybe something that is is
good or has been true for a while who is
no longer true or it doesn't really
matter and so let's talk about this
thing so first we talked about the
understanding the problem with
performing some benchmarks and then give
some just some pointers and ideas so the
thing is that we are chasing moving
targets all the time because browsers
come out to come up with new versions in
most excellent JavaScript engines and it
is great for us libraries also change so
John racing in one talk said that he
read some advice that you know somebody
was saying in jQuery you shouldn't do a
but you should do B instead because a
slower and beats faster and so he was
kind of I don't know why wouldn't you
use a right so he he came and optimized
whatever was supposedly slow and
committed a new version so it became
actually as fast if not faster in
certain browsers so this advice was good
for an or maybe just a few days so she
different browsers different libraries
so one example of advice that is
floating around
the string concatenation people from
Microsoft has talked about it a lot how
it's it slower to concatenate strings
but it's it's faster if you obtain
everything to an array and then join the
array at the end so this this was true
in in ie6 but is no longer 397 and eight
and and it all kinds of depends how big
are the strings how large is the array
which browser and so on a lot of
conditions for this to be true so it
reminds me of a book by terry pratchett
were in this world they were saying that
we have to do some objectivity in
literature we cannot just say you're
kinds of stuff so you're allowed to say
that the pen is mightier than the sword
only if you explain that not only is
true is the sword is very small and the
pain is really sharp front so a bit
about benchmarking so that's the the
most common pattern maybe when people
are doing benchmarks you take the start
date you do some crazy repetitions and
do something and then take the end time
so kind of a problem with that is that
you're not actually releasing the thread
you're taking the end time right after
something is completed but does the user
see anything especially when it comes to
dumb operations so maybe these are
performed in memory but nothing is
painted on the on the screen yet so the
user is not really seeing any difference
so when you start taking the end time
with a just a set time time out of 0
then then you're releasing the thread
and taking the end time you're letting
the browser finish whatever painting and
rendering and get a much more realistic
figure about what the user is
experiencing so will be about the zero
time out so there's no such thing as a
zero
right when you say time out of 0 you're
actually saying executed as soon as
possible and this figure can be
different in across different browsers
and for example zero time out is about
15 milliseconds in IM so that's that's
also kind of important to to have
whatever your benchmarking to be long
enough take much more than 15
milliseconds because if you do a test
and say all this one took 15
milliseconds the other one took 16
milliseconds then it's probably it'd
just be ice clock is not picking up
quickly so you're actually you have no
idea which one was better and it's
always good idea to do enough tests it's
usually 200 rounds of the same test to
get the statistically significant result
and then it's also important to filter
any outliers will you have some too big
figures or too small so there's several
ways once you have run a whole bunch of
runs in a test to consider what you're
going to do with the results and the
most common the thing that people do is
taking the average which is not really
descriptive of anything because it's a
made-up number right it's an average of
a phone number of runs so it's the
easiest thing is to do to take the
medium basically just sort the array of
all the results and pick the value in
the middle because it's it's actually a
real test and or if you're going to take
the average it's a good idea to filter
the outliers basically sort all the
results remove the first quarter in the
last quarter so something like this
right when you're going to sort all the
results in your total weight of the
beginning in the end because these are
kind of outliers so if somewhere have
been
in doing this test for for Firefox right
how long it's just nothing just a time
out of 0 to see how much it takes so the
median value is exactly 10 seconds then
the average is kind of different in the
average after filtering the outliers and
so you can see that sometimes because I
was maybe is crawling or opening far
above something that took the a little
bit more time than usual so if you take
the average without filtering those kind
of values it's probably not getting a
realistic value so about benchmark so
well because we're developers right we
build website so i don't think it's our
duty to benchmark different browsers
right we can leave the browser vendors
compete with their benchmarks and just
leave it to them because when your
application around seen in one browser
right that's the browser you have to
make it as fast as possible in this
specific browser you don't care that it
might take much less time in some other
browser in the actual time values are
really not important you don't care if
some something takes 50 milliseconds or
a hundred it's usually the best idea
that i found is that you have fun you
have a problem and you can solve it in
different ways let's say you can do a or
you can do B and the question is which
one of them is faster and is it really
consistently faster across browsers and
how how much faster it is is it just ten
percent twenty percent or is it
something that is you know five times
faster or 100 times faster and I think
for most applications unless of course
you're doing some some games and stuff
like this for most applications you only
need to worry about big differences when
something is taking really read a lot of
time so I just wanted to give a shout
out to Jas perf calm
if you have seen this website it's
really nice and just built with with
that idea in mind that you have fun you
can just test the different cases right
so you can do a B or C D you can do a
lot of tests and it's a community-driven
project you can see you get a static URL
then you can share people can clone the
test and into something on top of it
modify and so on and then at the end the
results are sent to browser scope so you
can ask your friends or whoever to to
load it in people from the community
that will load the site in different
browsers then you get a nice statistic
or how this thing behaves in across
browsers so that's about benchmarking so
how about the real life because
benchmarks are already made up cases
right and they're not real applications
so there's always a risk that you'll be
making benchmarking the wrong thing or
if you decided is faster than B you have
to see how relatively how important that
is so the best way is to just profile
writing in Firebug we have the profiler
you can sort by how much time everything
takes you have the functions so you know
where your time is spent the same in web
inspector and the cool thing here is
that it in addition to that it also
gives you the time that the time it
takes for JavaScript to execute and
gives you the rendering in painting time
and also recalculating styles and that
kind of stuff something that was missing
probably year two years ago had no idea
what's what's going on with the
rendering can
at the painting that's similar tool
there is a speed tracer for for chrome
Chrome extension and this is for I die
no trace Ajax edition really cool it
gives you the normal network waterfall
but in addition it also tells you how
much CPU you need how much time
javascript takes and also ND in your
rendering painting recalculating styles
so the thing about it it's so detailed
that it can be kind of hard to figure
out at the beginning it just gives you
so much data tool to work with so what
I'm trying to say I guess is that we
should be picking our battles right
because there's this line of thought
that says that anything you do sub
optimally is a disservice to the users
only love our users they're just guests
to our pages so we have to treat them
well and it's just a disservice to to
send more bites they need it or or do
something that is not optimal but this
assumes that you have indefinite
resources to work on that on speeding up
and and also the results are diminishing
with time so if you what kind of the
time you spend optimizing and the effect
that you get it's something like this
with just a little bit of effort you get
really beneficial results and then from
there you put more effort than the
results are relatively small so the
other side to that is that you don't
have indefinite resources right as you
have a bunch of people for for working
on this website so in a way if you spend
too much time micro optimizing or and
nano optimizing then this is also a
disservice to the user because you could
have done something else instead like
make the site more accessible or user
friendly implementing new features
so let's talk quickly about how to speed
up just just some pointers right so when
you talk about speeding up JavaScript
you you can think about two sides of it
first is to load that JavaScript on the
page and then once it's loaded to make
sure that it runs as quickly as you can
so the loading I'm pretty sure you're
all familiar with the Yahoo best
practices right but I just felt obliged
to to just list them out right reducing
the number of requests combining script
g zipping minifying setting the far
future expires header and if you have
the budget use a CDN so this is most
likely to give the biggest benefit right
so once you you've done all those basics
then you can move to other stuff for
example to load the JavaScript
asynchronously right because a
synchronous is good the users are seeing
some sort of progress they see something
is render than JavaScript kick seen kind
of enhances the page and they have the
perception that something is is going on
and the page is responsive and the
application feels snap here so the
problem with JavaScript of course
especially in not the latest generation
of browsers is that JavaScript blocks
all the other downloads so if you have
images and so on the browser will stop
all the parts you know downloads until
it finishes with JavaScript and the
easiest thing is to just move the
JavaScript way at the bottom where
there's nothing left to block right and
just allow images to load meanwhile so
now you have to kind of newer attributes
for script tags differ and acing so the
first is been around since forever in IE
it's an IE innovation so you basically
when you when you say script before
you're actually saying that it's okay
not to load that script right away you
don't
needed it can it can proceed with the
other downloads but you want the order
of the different scripts to be
maintained so the async is the new html5
attribute where you just say you know I
don't care when it's loaded loaded when
you can and then you have a callback on
low tool to execute whenever let script
arise so in terms of timing the
difference crypts I mean first they
maintain the order and then they will be
executed in order that they appear on
the page before the dump content loaded
event and all these synchronous scripts
will probably not be in any particular
order whatever arrives first will be
executed but before the load event so
meanwhile before all the browser start
supporting the new tags you can you can
load this influence JavaScript using a
dynamic script at and in this way it
doesn't block so another kind of related
technique is to use the HTTP Chung
encoding and kind of flush part of the
page as soon as something is ready so
that allows you to allow the browser to
start downloading components before
everything is is downloaded so it's
really easy to do that in PHP in every
every server sign language you have
something like this where you can say
okay this is the my partial content /
whatever you have to the browser and how
this is it's used across a lot of big
sites but in my opinion it's not used
enough so we should be using more so
this is the google search page so as
soon as you type something and hit enter
they they're still not ready with the
search results but they will just flash
the header as soon as possible so that
you have the feeling that oh it's
responding right away right it something
happened so you have
this feeling of control and you you know
what's going on on the page so meanwhile
they're working on the search results
and in the second chunk they're sending
all the search results and in the last
final chunk it's they just load the
javascript which if you don't get the
last chunk you still have a usable page
you can click on it if you follow the
links with if you have a slow Wi-Fi
connection you can still use the page
although it's not in in in the state
that it's the most beautiful in usable
so something like this happens where you
have the first the first chunk is
containing just the header and stuff
then you have the full body of the page
and then in the end either with the
script tag or asynchronously you load
the JavaScript so unfortunately I think
we're kind of lacking the tools to
figure that out so I can show you
something it's really ugly and kind of
buggy but there's this tool that I did
chunked view right that allows you to
hit a page and then then she see the
different chunks in that page so you can
see those this is the google search
results page right so you can see in the
the unzipped encoding at the end so you
see how in the very last chunk you get
you get the the external javascript
being over there and it's mainly just
JavaScript like all the content is
loaded so this is kind of interesting
you see all those data URI images right
the baby your eyes is a good way to
reduce the number of requests and its
really really important so important in
fact that
it's kind of interesting what Google are
doing so let me show you if you so if
you load at page right there's no other
than the spry there's no additional
image requests right and the page has
images right so they're all in line in
India HTML response so there's no you
don't benefit from the caching but it's
so important to reduce the number of
requests they are willing to send more
bytes in the in the results just to have
everything faster and something kind of
interesting is that if you disable
JavaScript you don't get any of those
images right so the kind of crazy thing
that you do here is when you load the
page you have a placeholder for those
images so this is a 1 by 1 gif included
as a data URI and repeated even so only
they don't make any other requests so
it's repeated for every image here on
the search results so you have this one
by one gift which it at the very end
right with the latest chunk whenever it
arrives it contains the URL the data URI
for the actual images so what they do is
just get that and replace the one by one
gift with with the real image I thought
it was kind of interesting and really
showing how how important it is to
reduce requests so if you're if you're
on a slow connection and you don't get
any of the images that's fine really Oh
mostly care about the results so there's
different ways to go to inject script on
the page the most common is probably
appending to the head sometimes you
might if you don't control this document
let's see if you're creating a widget
and you want to load in a third party
website and you don't know what's going
on there then you can access the
document element and get its first child
up in there then or you can use the body
because document body is pretty much
always defined even if you don't have a
body talent or that's something that
I think now we'll go on a little is
doing they'll get the first script
element on the page because in order for
any script to execute there's got to be
at least one script tag right so they
they find that script tag and and use
that as a hook so it's not completely
foolproof right because you can have
JavaScript without any script and if you
have let's say body onload and then in
line a bunch of scream but that's pretty
much ridiculous so talking about HTTP
chunking writer the flushing and so on I
just wanted to make a point that it's
not only for HTML so this is the google
instant so what they do here is because
when you're typing your you're probably
not paying so much attention on the
search results but you're looking at the
search suggestions first and see if any
of the suggestions will match what
you're what you're searching for so they
do two flushes they flush the
suggestions first and then the whole
body of all the results no it's owing in
whatever request they make and because
it's easier to just get the search
suggestions as opposed to all the
results so they do again to improve the
perception of speed just load as soon as
possible the suggestions so it's
something like they have a bunch of when
they maker because they have a bunch of
did kind of delimited with a comment
this sort of JSON objects delimited with
comments like this it kind of resembles
what big was they were talking about on
their blog calling it multiple
multi-part xhr requests all right way
you don't need the whole response in
order to to start working with with a
partial response so yeah this is the URL
to to my chunk view too if you want to
experiment it's kind of horrendously
slow but I guess until you get out into
it into the different tools that's a
nice way to peek and see what others are
doing oh so some some more stuff coming
in with html5 is the thing and the
prefetch attributes so link prefetch has
been around
for quite a while in Firefox button loud
like now it will be making its way to
html5 so this is a way to improve the
performance on the next page so while
the user is reading an article or typing
you know in a login screen or something
then the browser can start prefetching
resources that are needed on the next
page so currently you can you can do
this and we'll see just a pattern but
that it is really nice and easy way to
do it the other thing is the pink
attribute that is added to href so
because a lot of people want to track
clicks all right so when you click on a
link you want for advertising or
statistics and so one you want you to
know what what did the user click there
so currently the the most foolproof way
is to do a redirect so instead of the
actual link you link to a page that logs
and then redirects the user but that's
kind of a bad experience because always
redirect takes time so we did a study
with area 1 on average that any any
redirect on average will take at least
100 milliseconds but it could be slower
right some kind of thing may be
happening or if your redirect fails then
you actually don't see the page and also
for the other ways when you when you
click on a link is to send a beacon
right new images are see to something
but the thing is that there's a certain
amount of loss of click loss which for
for advertisers in for some statistics
are unacceptable let's say five percent
beacon loss so that's why they do some
crazy stuff like they send the beacon
and they will do a really big loop just
to slow down the user slow down the
browser to kind of increase the chances
that this we can all be sent correctly
so with a pink attribute that solves it
really pretty easily the user clicks on
the link and then the browser knows it
has to send beacon to up this ping URL
and it would take the time whenever is
appropriate for the browser
the beacon that you have confidence that
it will be sent so this sort of pattern
before when you preload stuff one
problem with preloading for the next
page is that whatever you pretty low
it's still going to be parsed and it's
going to be executed so if you pre
loaded CSS it might even change the page
or if you provide a JavaScript it's your
place to be parsed and so on it might
even the script that you preload might
expect that it's running on the next
page so it might throw an error so you
have to make sure that your script works
both ways but anyway it's it's a waste
of time to be to be parsing and
executing stuff that you don't need so
one quite easy solution is to use a new
image SRC and just request that but the
thing is that in in fiber what kid
images have different cache they are
kept in different place than the scripts
and styles so whatever you look if you
load a script as an image then it's not
going to be cash so for those you can
use an object tag and set its width high
20 in this way it's loaded and cash but
but never execute it so once you're done
loading that's where pretty much most of
the most of the benefits of speeding up
the application will come but then let's
talk a bit about some some micro
optimizations right so I think when you
when you talk about the runtime
performance kind of two ideas that you
can keep in your mind is that if you
work with local variables as well as
possible that's a good thing and if you
can avoid doing the same thing twice or
more than that that's great so just a
general guideline and let's see some of
those so you know the global variables
are evil we should go with you as far
inside of the function so for example in
this case when you have nested functions
and then this Ward 3 right
so if you don't have it then the engine
will will look up the scope chain find
this other a anything sound fine found
it will go to the global so so if you
can if you can avoid this going up the
scope chain that's a good thing and it
also helps minification because most of
the terminus is out there will not
rename any global variables because it's
not safe to do so so when you use local
variable it can be safely minified to a
shorter name one kind of pattern here is
when you if you use some sort of module
pattern right and inside there you have
you need to access the window object the
document maybe some other module or
something that I've seen people do is
pass all those tough to your to your
module at the beginning right when it's
defined so here you have access to the
go to the global object have a reference
to the document and so on so the thing
with that is that it can kind of quickly
turn into an anti-pattern right if your
module gross and you don't have nice
cold folding and stuff you just end up
scrolling up and down up and down to see
okay what was that horrible and using
local variables is especially true when
you when you deal with Don and we'll
talk a bit about that so we're using
reusing stuff as much as possible so for
example a common thing that that is
needed in in applications is to sniff
the browser features right so you don't
have to do that every time so once once
the script is loaded it's it's
impossible that this the engine will
change while your program is running
right so once you've sniffed that you
have support for our event listener is
not going to change throughout the life
of the application so it kind of makes
sense to do this sort of branching when
when the code is loaded or maybe the
first time that it's cold right so you
basically sniff whatever the browser
supports and then
define the function on the fly so this
browser sniffing is done only once
another thing is to use some sort of
memorization when you have we have a
chance that some some expensive task
will be repeated again you the same
function will be called with the same
parameters it'd be easiest thing is to
just because functions are objects right
so you create a new cache property to
your function and you know just use the
parameter or maybe serialize the JSON
the folder parameters and store that
result for later so one problem with
that is that your cash is kind of
visible it's accessible so you might
delete it or somebody else or if you
redefine this function or something like
that so other other approaches is to use
a closure right to protect your cash and
also an interesting approach would be to
store that in in an offline calf right
now they have session storage local
storage you know that if especially if
chances are that you're doing something
expensive that it's not going to change
for the next page or even for the next
visit it might be a good idea to to
store this thing in an offline cash
precompute some stuff for later and I've
seen people even do use offline caching
to the store and their code like Jesus
CSS and JavaScript in the cache because
idea for the study was that about half
of the users will always come with an
empty cache so the cash is not that that
relevant relate so if you can if you can
store it offline it's a good idea even
Google Gmail they they posted something
about doing something like this and even
when you have a new when they have a new
release they will just send a patch a
diff whatever change in the new release
and they apply the patch locally and
then update their offline cash so so
writing to the offline cash of course
has has the price of its own but it
might be useful for some cases
so an example of using the memorization
in a in you know a closure right so
there's many ways to do inheritance in
JavaScript so this this is kind of a
popular classical inheritance pattern
with your child constructor inherits
from the parent in the way to do that is
to use a temporary function and set its
prototype to the parents prototype so
every time you call that function in
actually creating the same function
again so it kind of makes sense to put
that outside and just create it once and
then create a return a new function that
uses that already created f then I have
a test case again this is something like
a nano optimization really because you
rarely need to do all that inheritance
tough but just an example of how you can
use to closure to store to store your
your whatever you want to cash right so
it's a bit faster between anywhere
between twenty and fifty percent across
browsers it's not something insane on
just an example same thing with when you
when you have regular expression objects
that you will end up creating over and
over again not in a look like this but
you know in several calls of the
function kind of makes sense to put that
regular expression outside of whatever
is repeating right so if it's a module
then you put it in a property of that
module or your object so you don't you
don't have to recreate that object every
time again not a huge benefit but just a
way to go and reuse as much as possible
so another thing is to always cash the
length in loops right so that's a common
way to do loops which suffers from
several problems so first if j is lint
will complain about the use of IE + +
right and then
if you subscribe to the single bar
pattern and then you define all your fun
Oh your voice at the top you would
probably change it to something like
this and then the next step will be to
to catch the length right in and take
the length of that array that you're
iterating and compared to it instead of
checking the length every time
especially true when you work with HTML
collections right so yeah you have yet
another way is to take the length and
then count down to it right because
comparing 20 / sorry but those are kind
of valiant micro optimization so the
probably the biggest thing that you have
to focus on after making sure that the
scripts are loaded as fast as possible
the first start first place to start
optimizing is the DOM and I just want to
give an illustration how bad things are
so if you do some some crazy long loop
and then you update the innerhtml off of
some element you get every time like in
this case fifteen thousand repetitions
you read the value once and right at
once so a better ways to go loco right
and use use a local variable and then
once you're done with it just appended
or update that that element wants so you
have only accessing the dome twice so
this is ridiculous example of course but
the thing is that's what what I meant
when when I want to talked about
comparing a would be right just to see
how bad it is so it's it's really bad
across all the browsers right anywhere
between it's it's not one hundred fifty
percent it's 150 times slower in a so
this is something that is worth
considering right instead of trying to
optimize twenty percent or something
this is you know hundreds of times
faster and it's it's kind of important
to understand so this is my slide with a
special effect to understand why why it
is the problem with the dorm right
because you have because the dome is
implemented separately from the
JavaScript engine and it makes sense
right because you don't
necessarily meet the dome to run
JavaScript applications or in ice case
you can use another language like did
this crypto to work with the same dome
right so if you think about going from
JavaScript and accessing something on
the Dom it's it's like a toll bridge
that's a Microsoft really nice
comparison so you're crossing the bridge
and it's a toll bridge and you have to
pay every time you cross it so this is
the special factory and then you across
the region and you pay the penalty so
you do that every time so the important
thing to remember is the dome is slowing
if you want to start somewhere that's
the place to start just one last thing
because i had patterns in the title so i
thought maybe people we some of you
might be expecting to talk about design
patterns so let's just quickly go over
that proxy design pattern like from the
book of four so on so Brendan I talked
yesterday about proxies coming to do I
comma script which is nice but we might
meanwhile you can implement it yourself
for certain tasks so what do what is the
proxy pattern is that when you have one
object that acts as an interface to
another so instead of one of your
calling the other one method it goes
through a proxy so you have something
like this where this is your the object
that wants to consume the so-called real
subject and but it doesn't access it
directly but it goes through a proxy so
that's nice when you have for example
the client wants to initialize that real
subject but it may never use it right so
it says cause some sort of init method
and the proxy says ok it's done but it's
actually nothing was done yet because
chances are that it might never be used
so then when the client actually wants
that we are subject to do something and
then the proxy was saying okay I guess
that's needed so it will talk or both of
the methods like this so for example
let's say you have a list of videos and
you want to play each video and you have
to make an HTTP request to get more
information about that video
and any chances are you might probably
expand all of them or make several
requests so it's a good idea the most
important thing when optimizing web
applications of course is to minimize
the number of requests so instead of
going every time through consuming that
HTTP object that you have created
somehow that's all the transport to the
server all right you can introduce proxy
in between and it might even something
as simple as just a minimal 100
milliseconds timeout something that the
user will not feel but if chances are
you have to make several requests in a
in a quick sequence then it makes sense
that the proxy will will combine all
those requests send them once get all
the data time which will be much faster
than making the separate requests and
you can even add some sort of caching
right so if if you're your client wants
to request the same video right the
second time the proxy will serve it from
the cache as a no that's my last slide
just to kind of try to summarize is
whenever you you try to approach a
performance project or or you want to
apply some best practices or advice out
there you should always ask why is it is
it true it's the relevant how is the
experiment down I know just you know
just question then the next thing is to
make sure that the script is loaded is
quickly and s asynchronously as possible
remember to touch the dumb wisely and
and for the micro nano optimizations
kind of the tool that lines to to work
with locals as much as possible
especially in the dome and then reuse
don't don't create the same objects or
same properties twice so that's all
ahead I'm hope I'm okay with the time
right
yep yes oh yeah</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>