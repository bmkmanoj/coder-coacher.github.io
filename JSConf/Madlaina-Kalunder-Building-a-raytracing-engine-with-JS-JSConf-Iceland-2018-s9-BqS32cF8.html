<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Madlaina Kalunder: Building a raytracing engine with JS | JSConf Iceland 2018 | Coder Coacher - Coaching Coders</title><meta content="Madlaina Kalunder: Building a raytracing engine with JS | JSConf Iceland 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Madlaina Kalunder: Building a raytracing engine with JS | JSConf Iceland 2018</b></h2><h5 class="post__date">2018-04-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/s9-BqS32cF8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone it's really packed in
here thank you all for coming as when I
saw I said my name is milena I am from
Switzerland and I'm a game designer and
currently a full-stack developer at art
illogic we are working on a toolkit in
JavaScript to provide 3d models for
interior spaces and also api's for
spatial analytics so what we do is we
want to make 3d models accessible for
every web developer that would like to
integrate this in his daily work as I
studied game design I'm really excited
about games you might see there I love
to play games I love to collect retro
games and I also love to make games
which usually includes working in 3d I
also really love travelling as I see it
as a resource for a lot of inspiration
especially for storytelling and finding
new ways of designing and I also love
creative things and music and a lot of
other things especially Iceland I've
been here two times already for a long
period of time
I have not seen anything so you
definitely have to come back why should
you as a web developer or JavaScript
developer be interested in doing 3d on
the web as we might already know most of
you guys sorry folks as might everybody
know that that VR is coming and 3d on
the web is very accessible at the moment
and we're also challenging browsers like
show Eve was explaining before to
actually support 3d on the web there is
lots of things you can do to enhance
your product for example this is a
screenshot from what we are doing we are
having semantic 3d models which we can
then analyze with machine learning for
spatial data and we can actually also
use machine learning to
propose you how you should furnish your
apartment which is pretty cool so you
can see your new house already before
it's actually being built or you can
make a really cool small games on your
browser on your website integrated it
with all the native web environment
things that you have and you can make
them work with each other which is
really cool you can also use it to
enhance your infographics or to make
your data more readable with enhancing
it with the third dimension so you can
also use animation time and the third
dimension to show something you would
like to do with your data I think this
is pretty interesting and you should
definitely think about how to use it
most developers that would like to start
with especially web VR have been coming
to me and asked me how do I get started
with 3d why is it that it's so hard to
get started for these people and this is
what I would like to talk to you about
today I would really love that you come
out of this talk and you have this
little toolbox with things you have
heard before and you feel more motivated
to start trying it because at first you
will be overwhelmed by all the new
terminologies you're gonna encounter
not only have you have new things to
learn but you're also gonna be a movie
screen designer
you're gonna be a narrator you're gonna
have to learn how to do UX in 3d you're
gonna have to learn about 3d modeling
how to light a scene properly etc etc
that's a lot of things to learn I would
like to talk to you first about the
physics of light so here you see it's
very simple scene we have this little
apartment it works okay and we have we
see a computer or standing on a desk we
have a chair we
a window and outside we have the Sun
which is primarily the source of light
which makes us see everything but how
does it actually work so every light
source for now we're talking about the
Sun is emitting race of electromagnetic
waves as soon as these rays are hitting
an object they are going to interact
with that object so either the object is
absorbing all the light in that case a
lot of energy is being produced or parts
of the ray of the Sun are gonna be
bouncing off and reflecting on different
surfaces until that light energy is used
up I already said that the lecture
magnetic waves consisting of different
frequencies so that means different
frequencies are different colors if one
frequency is absorbed the other of two
frequencies are going to hit our eye the
retina of our eye therefore creating
this color in our eyes and we can see it
different materials react very
differently which I'm going to talk
about the differences afterwards but
there is three major things as I said
already its absorption reflection and
transmission of light we could say this
here a little bit more graphically
imagine you have a perfect mirror which
is even it's not possible even if we
polish your surface very well you're
never going to have it but theoretically
a perfect mirror will reflect all the
light rays uniformly this we call
specular reflection then we have diffuse
material like cloth and like wood and
other things that are not so much
reflective so it's gonna take the race
and bounce them back in a very chaotic
way and you have propagated light so
if you have glass or water the light is
not only gonna reflect it's also gonna
transmit through the solid creating
these really cool effects so with this
is of course not everything that defines
a material but as we can see in this
illustration these three components make
a lot of our real-life materials and
it's never just one component that is
there in one material for example if you
imagine about if you imagine you have a
wooden floor that is not polished the
the rays of light are going to bounce
back chaotically but if you then put a
polish or finish on it's going to be
very shiny from specific angles and
that's what I really want you to think
about when he gets started with 3d
because that's what a lot of people get
wrong or just don't think about because
why would you so how do we now translate
this into computer graphics I would like
to just go back to a few centuries back
where the first cameras were appearing
and these are called pinhole cameras so
you have a light-sensitive film on the
back of a box with a little hole inside
and only one ray of light per angle is
allowed to pass through that hole
creating then the color on that spot of
the of the film and we are also using
this technique in the render engine
technique called ray tracing and that's
what I'm gonna talk about however if you
imagine again the Sun it's not only
shooting one ray at the time it's like a
really really big energy source and it's
shooting down all these billions and
billions of race at the same time and
most of these rays are never gonna hit
our eye they're never going to hit our
camera or whatever specifics
but that we want to look at so what
computer graphics are doing is they use
technique called backwards ray tracing
so we are tracing the race but instead
of going from the light source we're
going from our camera through the pixel
that we want to trace and we should
array into the scene and we look at the
first object that we're going to hit at
the closest one from there we're going
to see we want to see if this one object
is in shadow or if it is in light okay
so if the object is actually lit we're
going to use the color of the of the
material that is defined at that space
basically multiplying it simple
simplified set multiplying it with the
color of the light intensity of the
light if the object is in shadow we're
just going to use we're just going to
use black for now as for shadow this is
very simplified but now I also talked
about these other things that called
like transmission and reflection so how
are we handling this in ray tracing
imagine we want to see where if we have
a transparent material like glass we
would like to see what can we see
through that glass and what is reflected
on the surface of that glass so on the
impact point we have to calculate the
different race that we're going to trace
one of those rays is going to be the
reflection ray and one of them is going
to be the refraction ray it's a bit yeah
not very nice that the names are so
close and from there these rays we're
going to do another check if they are
hitting a next object so if the
reflection ray is hitting this red
sphere it's going to be red at that
points but the refraction rays hitting
this green sphere and so we have to
calculate together if we want to have to
pixel their red or green from the impact
point of the secondary race we're going
to trace to towards the Sun and see if
these points are in light or not I want
you to have a moment to look at this
code
everybody get it can you come here and
explain it to me because this is how I
feel about my own code after two weeks
of not looking at it so yeah what you're
looking at is a basic implementation of
a ray tracing engine that can do
reflection reflection and reflect
refraction with geometry primitives of
spheres and I'm not sure if planes as
well I think only spheres and this is a
common challenge and young people who do
computer graphics is how to make the
most compact ray tracing engine that can
be fit on a business card so this
actually compiles and I think that's
pretty cool but let's take it apart a
little bit so what we want to do is we
want to define our geometry primitives
and for now we are just going to talk
about the sphere because the sphere is
one of the most easy shapes to calculate
an intersection and for that we need a
center and radius and we want to have
the material because as I explained
before that's the most interesting part
and we're going to make an algorithm
that will calculate our intersection
from that if we are successful we're
going to return both points that are
intersecting with the sphere because
usually you will have two of them so the
the distance to the the closest one and
the distance to this to the further away
one then we're gonna start our main
function and we're going to define the
geometries and again for simplification
our light source are also going to be
spheres just with a different material
that actually emits light for that we
can test afterwards we're gonna have a
buffer for our canvas and we're going to
go and Traverse through each pixel and
for and we're gonna trace for each pixel
one ray that's what we did before right
then in the trace function I want to see
again
shoot this is the primary ray that we
talked about before and we want to see
which is the closest object so we're
gonna we're gonna test the Ray against
every object in the sea and as a result
we get the nearest one back if we don't
have one hit at all we could just return
the background color because there is
nothing there and there will never be
something there that's the really cool
thing about ray tracing you actually
test against the whole scene if there is
an object there and it's a transparent
or a reflective material we're gonna
have to to shoot the secondary rays for
each of those and we do this recursively
until we are satisfied and usually you
don't want to do this endlessly because
it's gonna take forever so we're gonna
decide how often you want to do this
recursion and at the end of that you
will test against the lights and see if
these points are in shadow or not then
you're gonna use a fernell algorithm to
see how you should calculate the lights
together or the results of the colors
you're getting I'm not going to explain
that right now but it's very interesting
to look at and if it doesn't fall into
this that means we are hitting a light
source or a diffuse material that is not
going to reflect any different points so
we can break the recursion there I did
not make another slide for this because
I think it's clear and this is the
result that we are getting from this I
think it's very interesting to see that
from this rather simple algorithm we
already get really cool effects like we
can really see the spheres that are
close to each other
reflecting each other we can see shadows
and we can also see what's behind the
camera which is pretty cool
and this is something that you do not
generally see in games for example or in
different render engines and why is that
we're gonna get to that later on
so this was really easy I think but now
we want to really go realistic because
we said before there is not one ray per
pixel usually the Sun shoot so many rays
that make up one pixel of your image
there is so many things that come
together we want to have soft shadows we
want to use multiple light sources how
are we going to compute these together
how are we going to decide on what is
more weighted which pixel should be what
and we really want to have this physical
correctness which means that we have to
basically bounce the array forever until
it hits the light source by itself right
now we're just making it a shortcut
because we just test if it's if it will
be hitting the light or not if there is
something in-between or not this is
going to use a lot of computational
power ray tracing is really old
technique it's from the knife from 1984
was the first sake graph conference that
was taking this as a topic and since
then we are still not there where we
have real time ray traced and she is
that are engines that are working it has
a lot to do with this that you cannot
make shortcuts to make it look good
you have to have a certain amount of
samples unless you're gonna have a
really otherwise you can have a really
noisy scenery so we have a lot of new
light sources in the room that are also
casting Ray's I would like to just very
briefly introduce to you rasterization
technique this is the most common
real-time render engine technique that
is being used and it's just as ray
tracing just it's just as fundamental
this technique it has been around
almost the same time because when
ray-tracing was introduced the
computational power was not good enough
or not strong enough it would have taken
them forever to render one frame of an
animated movie for example so what's
interesting about rasterization is that
it's also trying to solve the visibility
problem it's also trying to find out
which object object is laying in shadow
or what's the color of it but it's doing
it in a very opposite way of ray tracing
while the ray tracing is going from the
eye or from the camera into the scene
rasterization is going from the objects
or from the scenery onto the screen due
to perspective projection so we take all
the numbers and all our points and all
our vertices everything and we project
it onto the screen for this we it's
currently using triangles which is also
a rendering primitive the cool thing
about triangles is you cannot subdivide
it anymore it's already you cannot make
more areas out of it and the areas is
always planner so we never have like a
perspective warp or something which
makes it really cool to then project and
test what we then do with it with the
triangles that are mapped onto screen
space is something that also shown has
been talking about before we were
rasterizing each pixel for each triangle
that is visible and we mapped their sea
value so how far it is away from the
camera so that afterwards when we color
it in we know what's on top of each
other and if you have transparency then
we have to consider the C buffer because
that's how we're going to put it
together which also tells us that the Z
buffer is basically so a transparent
object is basically just look through
with a different
our value which does not have this
refraction rays that are kind of warped
around in the scene so here in this
image you can see two basic
implementations one basic implementation
of rasterization and the basic
implementation of ray tracing and you
can already see the difference I think
while rasterization has come a really
long way if you have played any 3d games
recently or if you are working with VR
you're gonna know that it's not going to
look like the image up there so there is
a lot of simulations of real physics
happening in restoration but generally
this implementation is also really a lot
of work to do to simulate these physics
but they are doing a pretty good job the
only problem is still transparency I
think so just a quick overview of the
two ray tracing is mostly physically
correct if you put enough effort in it
it has very high details very nice side
effects that you don't have to think
about you get the soft shadows you get
the inter reflections you get the
caustics but it's very computationally
heavy so we are going to use a lot of
computation time to render frames and if
we ever want to do this real time we're
gonna either have to break it down or we
have to make cuts and restoration is
super fast it's really only one
transformation basically from your world
world coordinates to your screens space
coordinates there's a lot of tooling and
hardware support so your GPU and your
computer is designed to do a rasterize
ation it's not designed to do ray
tracing and and most of the like Pixar
and most of the rendering people I know
they're still rendering ray tracing
with CPUs because it doesn't matter to
them if there are three times faster or
not in what matters is that they have to
change all their their tools and they
have to change their engines to be
supportive of GPUs for just a little
benefit so you have the physics that are
not really correct you have like an
approximation of what you can do and you
have quality loss due to that so this is
kind of the point where I hope you are
all oh god how should I even get started
it seems very complicated so I would
like to introduce you a frame toolkit
and a frame is a web toolkit where you
can really easily get started with
making your own 3d scenes and if you're
a fan of HTML you're gonna be really
happy because this is what its gonna
look like so you can define with HTML
tags we basically define everything you
define your scene you define the sky you
can put sources and if you want to use a
sky texture if you prefer to use a sky
color then you can put a color then you
have this geometry primitives as you
have usually boxes spheres cubes
whatever planes are also very prominent
and you can also define the lights and
that's where we come back to the
beginning because with this components
you're gonna make or break your scene if
your lightning is good sorry lighting
it's good you're gonna have you can
really achieve a lot by just having
three or four or five different objects
in the scene and the best part of a
frame is that it comes with webviewer
integration so you don't have to do
anything you just lean back you import
your wife controls or every major
headset is supported or so mostly
every major headset controller is
supported so this is what that example
would look like once it is but that did
not look very good I mean the background
does but the foreground so it's still
the big question in the room is how do I
get my 3d models and that's where also
we come in so for example this is gonna
be in your head of your HTML you load
all these external components they're
called a frame components and I think
the open-source community is really
doing an amazing job here because you
have all these really cool components
like a frame orbit controls you have
people that are building environment
presets for you so you can just import
them and say I would like to use this
preset and then afterwards you can
always use animation of each attributes
to to change your scene the way you want
and you can if you don't like HTML you
can do that with JavaScript so you can
just edit edit your HTML attributes
programmatically to make them animate
and this is how you're going to use the
a frame components that are made by
external parties for example if you can
load a 3d i/o furniture of your choice
you can position it because position
attributes are just generally used for
each object and you can you can have
your camera rotating around that object
and you had this really nice background
that you loved so much and you just want
to lay in that bed and with the VR
headset yeah so this I think it's really
cool and you should definitely try it
out because there is so many amazing
things that people are doing with this I
would like to share with you like a few
tips and tricks this would just be a
talk on its own but this is what I have
been asked most of the times again how
do
get my 3d content should I go now and
start to learn blender because that's a
pretty frustrating tool to learn
I know it's I've worked a lot with
blender but it's pretty powerful however
you don't have to do that because some
people like my coworker Thomas I'm
writing
inspector plugin for a-frame so a-frame
has a 3d inspector where you can
manipulate your scene drag around things
try out your values that you then can
pour it into your HTML file and you can
use this inspector plug-in to get models
from for example Google blocks I just
try it out
scale the models have fun with it then
lightning not lightning why do I always
say lightning lightning it's gonna make
or break your scene so I think it makes
a really big difference and if you're
interested in this I have hi motivations
to write blog posts about this topic and
then for the end is content optimization
we are people that work mostly with the
web and with different devices so if you
start working with 3d for a project
think about what is your target group if
you want to use 3d on different devices
at the same time keep in mind that you
might want to design it differently for
whatever you want to do if you want to
do a fast-paced game then you have to
maybe not be so detailed but if you want
to do product like you want to have a 3d
scene of your product to try to sell you
might want to be more detailed on that
so you should be thinking about loading
your assets progressively that means you
could have your textures in different
sizes or different formats depending on
what your device is capable of doing and
you should design for level of detail if
there's an object in your scene that
you're only gonna see two pixels don't
make it have a million polygons please
and these are all the lessons that we
have for free from game development also
one other lesson that we are actually
doing or that I was working on is we do
use ray tracing for calculating light
simulation for static scenery so the
parts of our scenes that are static we
use a ray tracing engine to calculate in
the clouds
what is our realistic light and then we
put it back into the rasterize ation
with the real-time stuff so this is also
really cool workarounds so one two
takeaways and then I'm done models
materials and lights do matter and this
one is mostly for myself
I love ray tracing it's really cool but
are we ever gonna have it real time
Nvidia is having really cool demos on
this but it's still a question that is
unanswered thank you very much for
listening if there's any questions
please ask me any time and this is
started so scratchy pixel is amazing
resources for any computer graphics
pioneers that would like to get started
and really try to engine-out themselves
a frame is the tool that I have been
showing you if you just want to play
around and 3d i/o is what we are working
with to provide you with the models you
need</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>