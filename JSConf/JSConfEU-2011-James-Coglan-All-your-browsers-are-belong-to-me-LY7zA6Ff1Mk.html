<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[JSConfEU 2011] James Coglan: All your browsers are belong to me | Coder Coacher - Coaching Coders</title><meta content="[JSConfEU 2011] James Coglan: All your browsers are belong to me - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>[JSConfEU 2011] James Coglan: All your browsers are belong to me</b></h2><h5 class="post__date">2013-06-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LY7zA6Ff1Mk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so yes I'm going to be taking all of
taking over all of your browser's for
fun because I can a little bit about
myself i'm james i like doing stupid
things with ruby and javascript and i
wrote a bunch of open source stuff that
you might have heard of and most
important thing about this talk is that
there is audience participation as you
as i'm sure you'll have seen me tweeting
for maybe weeks and if you have a
macintosh computer that's one of the
ones that's got this all apple but and
firefox a recent firefox so six or seven
i need you to open it and go to this URL
and then don't do anything then click on
anything thanks line into anything you
just have to open that URL and the
reason why it will become clear shortly
and keep your volume off for now so some
backstory why am I doing this this is a
band called The Flaming Lips this is
something sorry
never got that okay turn your sound off
thank you awesome so yes this band
called flaming lips they're mostly
famous these days fulfilling stadiums
with balloons and confetti and lots of
weird noise and but back in the 90s they
released this album called zai rica as
Erica came on four discs that you were
supposed to play at the same time
they're assuming that people had four
stereos lying around and the idea was
that like a this gave the user some
control over listener rather some
control over the sound but also took
advantage of the fact that CD players
aren't perfect their clocks all track at
different speeds and they don't track
constantly like the same CD player
doesn't maintain constant time very well
so all the samples on these discs we're
kind of getting an out of sync with each
other and you'd get interesting effect
and like the gaps between tracks would
be different on each machine and so
they're kind of using multiple outputs
to do something interesting this is been
called Boredoms from Japan they're a
noise rock band they're extremely noisy
and they have a7 neck attire they have
this array of things that I don't know
what they're called that this dude beats
with sticks in this picture there's at
least one two three four well it's
actually 77 drum kits this is a show
that put on on 7th of july two thousand
seven in brooklyn they got 77 drummers
from a bunch of alternative rock bands
and played a bunch of their material and
it was this crazy mix of kind of like
just chaos and then when they all
actually stopped deliberately drumming
together it's just this tremendous is
that this giant robot marching to turn
has incredible I've only seen them with
seven drummers but that was staggering
so I assumed this was just I'm surprised
the earth than blow up
skip forward a few years I'm seeing a
hack day in san francisco and i'm kind
of tired of glowing together web
services and i want to make some music
so I you know I'm kind of looking around
for people who know how to do synth
stuff because I know nothing about it
and I'm not getting anywhere with that
and then I think hey there's a bunch of
other computers here what if we could
make them all make music and so I put
together this really simple little synth
and it was monophonic it had really
basic controls can do very much but we
got a room full of computers to play
happy birthday to one of the organizers
and it sounded just about recognizable
but yeah it worked so I want to go away
and do something more sophisticated
something where you know you could
record stuff play loops play chords do
effects and that's what I want to show
off today I had to confess when I
proposed this talk I didn't know what it
was going to turn into I just wanted to
get hundreds of laptops together and am
but I've learned something by building
this I hope you guys will get something
out of it too so that is where this
project came from and so I'm going to
try to do a demo and if if this works
I'll be tremendously surprised because
it has a very high chance of not working
at all so let's just take those down
yeah if you guys could like refresh your
browser's Ashley because it's probably
 up ready
yeah oh well
we'll refreshed okay okay so i am just
going to try and get a couple people to
play this one sample forgot a couple
people playing laughs
yeah key turn your sound up now
if they start buzzing just refresh
Oh
I feel connected
I'm not sure this is thinking of
terribly ye
alright so a few of them a kind of
synced up so you can do those stuff like
bringing more samples no it's gonna pick
that up okay so it turns out it sounds
terrible but nevermind I'm thanks
everybody for helping out of that this
is what happens when you don't have
hundreds of machines at home to test
with anyway ok sound off so yeah aside
from it being at an incredible failure I
have learned a few things while building
this so the first of which is how do you
generate sound in a browser this is
stuff that spinning Firefox for a while
it's just coming in to WebKit and chrome
and you can program out programmatically
generate sound so how do we do that well
sound is just waves right and it's
represented in the exact same way
digitally you just have to produce big
strings of numbers and write them to
something so this is a really basic
sound wave this would produce just a
constant
yeah all right Kyle so this produces a
constant pitch constant volume just pure
a single note with no effects no no
change in volume no nothing and
synthesizers work by taking these waves
and modifying them and you just with
some really basic modifications you can
make some really interesting sounds so
one thing you can do is use a low
frequency wave to change the volume this
is called amplitude modulation and it
makes the volume oscillate up and down
if you want to replicate kind of more
realistic organic instruments so the way
the luck if you hit a piano key or you
strum a guitar the note will trail off
over time so we modeled that is that you
play what's called adsr envelope so the
sound where you have a tack time which
is how long it takes to ramp up to full
volume if it decay time which is how
long it takes to trail off to their
sustain level and the sustained level
says how loud it is while you're holding
the key down and then there's a decay
time that says how long it takes to
trail off to silence and just using that
you can do some quite interesting things
so how now we know how to model sound
how do we make browsers spit stuff out
so Firefox has this audio object which
you make a new one of those and you say
I want two channels left and right and a
40 44 kilohertz sample rate which is a
standard sample rate used in digital
audio which means that you have to
generate 44,000 data points per second
for the sound waves that you're
generating and then you just make us
that interval loop there like every 10
milliseconds say it takes the current
time and you get your sound generation
stuff to give you a time slice which is
just a big array of floats which is just
a little you know slice of the wave
function for that interval of time and
then use the mosrite audio function and
that actually writes it to the speakers
so within your your your models for
generating sound this is basically what
what sine waves is doing is it models
things using
subjects and you cannot unload for a
time slice and what that's going to do
is it's going to take the current time
and the interval you want to generate
and the sample rate figure out how many
samples you need and then just build up
an array and by just going over every
little time point in that interval and
calculating the value of the way for
that point that's a big array and just
returned it and then to figure out the
value of a note at any particular time
there's a bunch of mass that I'm not
going to dwell too much on and also I
feel like after and judgment talk I
should reduce the size of this
tremendously there's a bunch of math
just to calculate what the values the
wave is at that time but we have a
problem right and imagine that you
assigned a sequential ID to every little
bit of data that you're right to an
audio stream what you want is a just
continuous uninterruptedly IDs going
through with no no sections repeated no
bits skipped but as we know JavaScript
timers are tremendously accurate if you
can you can say that you want to loop to
fire every 10 milliseconds but it will
never actually do exactly that right
sometimes there'll be a bit late
sometimes a bit be a bit early and the
code that we had her head here that's
just getting the current time to figure
out what the kind of starting index of
your your slices so what that's going to
do in practice is it like we might write
a couple of loops have just you know
uninterruptedly the first one we do
naught to nine and then we do 10 to 19
and that's fine but then the third
iteration starts a bit early so we
repeat a bit of the last one and what
that ends up doing to the sound is this
which sounds really really horrible if
you and if you implement your sound like
that you'll get kind of an overlay of
white noise on top of on top of the
sound so what you did to fix that is you
just maintain your encounter right each
iteration of your loop you increment the
counter of how the big your interval is
it needs that at the current time but
then you've got another problem right
because you basically introduced your
own idea of what time is which is
potentially going to differ and drift
from real time as you go on so that
means that anything you timestamp in a
synthesizer like when user input happens
what the duration of a note
is what frequency is all that stuff you
have to base it on your counter not on
the built-in date object because they
will differ and you know the the
playback loops won't quite join up
probably so that we can model sound we
need a way of doing user input and it
turns out this if you are if you've
already got away that you're modeling
sound waves this is pretty easy right
you just figure out a way of mapping
keyboard input two frequencies which you
can pick whatever you like for sine
waves I'm just saying like like pick a
key like a major and just take all the
notes in that key and just match them
sequentially onto the onto the keyboard
so when a key is struck you go what
what's the frequency of that key you may
can you know with that frequency and you
time stamp it with the current time so
every note has one of those envelopes
that showed a second ago that decides
how its volume varies over time how it
picks up our trails off and so you need
to you need to tell it when it was
pressed and when the key was lifted so
that it knows what that envelope looks
like and when you pick a key up all you
do is you look up the note that that key
code last generated and time stamp it
with a key up time and then it the
volume RL off a recording works in much
the same way so instead of storing all
the audio data that we generate which is
huge volumes of numbers which would be
expensive to transmit in store all you
do is you record the user input because
you can completely reconstruct the sound
from the user input so in this case
instead of making you notes all you do
is you just like record some events
right you say at this time this key was
pressed with this frequency on this
channel and the same for Kia and what
that gets you is just some information
that says how long the recording was
which means how you know if it lasts
eight seconds that means you like every
eight seconds you restart the lip and a
list of events that says like which
which keys were pressed at what times
and what frequencies those map T so then
for playback all you have to do is like
in your timer loop every time you hit a
multiple of the recording generate
duration you just schedule a bunch of
these events 22
play the notes in the right sequence so
now we can play stuff on our own
machines but how do we get that to other
people right so the setup that I'm using
is I'm running node on the server with
express for handling web requests so
that deals with the you know saving and
retrieving the Jason for these
performances it deals with serving you
the pages that you can see and i'm using
faithful pub/sub and that's all backed
up with a reduced database and you have
a really simple JSON representation for
performances so performance is just an
array of channels each channel has a ton
of settings all those little sliders
that you could see those all represent
parameters that can change how the sound
works so a channel is just an object
that has all those settings in it and it
optionally will have what the settings
touching the keyboard are and whether
there's a recording on that channel so
you can live it so all the browser is
doing is it's taking that sending it to
server service rubs it in Reader's so if
if all your domain objects have a to
Jason method you can just really easily
use xhr to save and retrieve these
things and you can use phaser pub/sub
channels to to get updates so every time
that you change a little setting that
saved it to the server and then the
stove is going to use Faye to push it
and to all the people who are listening
so this brings me to the kind of main
thing that I learned which you've
already seen a demonstration of timed
kind of hard to get right yeah it's just
nasty right as you can see like sinking
clocks is just hard that didn't work
very well it works I've seen it work
okay on smaller scales as smaller groups
and I have no to get some quite good
numbers out of my clocks but it doesn't
always translate into good music and if
you've always over the top for me so
invoke Stephen Hawking for this this is
a problem that cutting-edge science has
right now there are people disputing the
fuss than light neutrinos because they
think
the guy's got their clocks thanks wrong
so how are we going to sing the clots
well it turns out there's an established
way of doing this in UNIX it's called
ntp the network Time Protocol and that
uses timestamps that have a 2 to the
minus 32 second resolution which I don't
know how useful that is in practice it
turns out that's 10 orders of magnitude
smaller than the the lifetime of the top
quark which is so unstable that it
wasn't observed until nineteen
ninety-five in a custom-built particle
accelerator so I don't know how useful
that is but it's a lot more useful than
what we have in JavaScript land which is
just milliseconds which are I mean even
even that you know the millisecond
counts that you get are just you know
inaccurate you see this with timers and
you can't he doesn't even go down two
microseconds or anything but it turns
out like for some cases that's that's
good enough right the the kind of the
lesson that I took from from Zurich is
that stuff doesn't have to be perfect it
just has to be interesting and whether
it is interesting is a function of you
know you can't go to outside the Ranger
it just sounds like noise but it also
doesn't have to be perfect so we can use
this and this is basically what ntp does
and you have a client and the client
goes i want to sing my my clock with a
with an upstream server so what it does
is it creates a message and it puts a
timestamp teaser on that message that's
when the client sent them at the the
message to the server and when the
server receives it puts his own time
stamp on at t1 to say i got i got this
message at this time that's going to be
in a different time frame to what the
clients using because their clocks are
synchronized yet and then the server's
going to hang onto it for a certain
amount of time there's processing there
needs to be done that it's not sent back
immediately so puts another time stamp
on it to say when it's sent it back to
the client and that's t2 and then when
the client eventually receives the
message back it puts a final time stamp
on it t three now if you didn't have a
network latency to take care about the
difference between the two clocks would
just be t1 minus t0 right the client
says the server I think it's this time
the server goes is actually this time
and you just send that straight back but
we have networks and they have latency
and that can be you know hundreds of
milliseconds seconds depending on you
know where these these things are so how
we actually calculate the offset is that
we know the total elapsed time on the
client side that's t3 minus t0 and we
know how much time the server took
holding on to the message at t2 minus t1
and assuming those clocks run at about
the same rate over a short time span you
can just subtract those two to get the
the network round-trip time so you
calculate that you have it and you take
it and you subtract it from the
difference between t1 minus 20 and that
tells the client and what the what the
difference between the clock says so we
can use phase pub/sub channels to this
right we can get browsers to send
messages to each other so the client
could publish a message to the time
channel with its t0 whatever it thinks
the current time is and then the server
could can listen on that channel and
process it which we'll see in a second
and the client will also have to
subscribe to a channel where it can pick
up the responses from the server so
clicks a unique ID and it listens on a
channel that contains that unique ID so
when it gets a message back from the
server it can look at the timestamps on
that message and do the kind of ntp
algorithm stuff to figure out what how
much it should adjust its own clock by
so on the server side the server's
subscribe to the time channel so it's
going to receive those messages that
clients publishing and and it's just
going to go okay well I'm going to
return you the t0 that you gave me and
I'm going to attach my own t1 and t2 of
whatever those are so it's pretty simple
but it basically relies on on on your
network being reasonably responsive if
you have highlighted see if you have
noisy latency if you have asymmetric up
and download speeds between these two
people that throws the algorithm off
right it just gets stuff wrong as soon
as you have noise when it tries to
figure out what the round-trip time is
it's going to take half of the total
time and if there's a symmetric up and
download
these that's not gonna be a right thing
and the greater latency that you have in
your network the higher that margin of
error gets and you just get out of sync
by 100 milliseconds seconds in some
cases so we're kind of thinking that we
have a model like this right web
browsers can send messages to each other
and they're kind of communicating
directly but that isn't really what's
happening they actually going virus
server right when you use any pub/sub
service the browser standing message to
a server and the show is going to
forward it on somewhere else so that's
already kind of you know latency that we
haven't thought of giving our mental
model of how this works but it's even
worse than that because these machines
are probably going to be on a Wi-Fi
network depending on what your Wi-Fi
hardware is like that can introduce huge
amounts of noise to your network
connection I tried this out at home
using Wi-Fi and putting an ethernet
cable to my router and the amount of
latency the Wi-Fi introduces is horrible
so that's more noise and every one of
these lengths introduces introduces more
latency it introduces variability and
that all adds up in a really horrible
way so to make this thing kind of
unusable so we can t have a system like
this where we have one master which is
the browser being used by the performer
and we have a bunch of listeners so all
you guys in the audience the guys at the
bottom and my machine is machine at the
top and you you're all asking me for the
current time so you can sync your clocks
what if instead we use the model like
this right we've run a clock on the
server the server can sync with the
master and then all the clients will
sync with that clock on the server so
that kind of made a it removes some work
from from the master machine because
it's not having to deal with all these
incoming messages which is helpful
because any extra work that the
browser's trying to do while it's
generating audio is just interference
right if you update the UI if there's
expensive computations going on and it
gives it less less bandwidth to deal
with making audio
it makes the sound choppy and that's why
in that interface for example there
isn't like I want to have am like a
progress bar that would track how faster
if through a recording air like if I
record on one channel and then I want to
record something over the top of it I
want to make sure I'm in time so I want
to see how far along we are just adding
that made it completely unusable all
those little updates of the Dom made the
sound really choppy and this hottie is
and so if you introduce this the browser
does less work and it also means that
the the there's less there's less
network distance basically between the
clients and the thing they're trying to
sync with and the important thing in
this kind of situation is not that
you're all synced up with the performer
but you're synched up with each other
because that's what is producing the
sound and it turns out if you go to this
model depending on your network I've
seen tenfold improvements in in Sinking
like I've got and like hundreds of
clocks on my machine synced within a
millisecond using a pub sub server on
the other side of the planet but it
turns out that this can also introduce
instabilities right you can get jumps
when the server if the server gets
behind the performers computer it can
kind of jump forward it can jump back
and it turns out that this particular
model is just really bad for producing
music you get like even if the numbers
look really good out of your clocks the
sound that comes out of your speakers is
just noise so that about wraps it up
you've got a synthesizer or beer one
that didn't work terribly well its top
to bottom JavaScript client-side and
server-side and to sort of find a level
of easter egg this funky little logo
that I made for it is also JavaScript
it's just written using the canvas
element and a bit of math so thank you
all for listening
can have questions hey everybody's just
baffled okay
first of all I didn't think it was a
failure i thought i was totally cool the
demo yes yes here was really good you
should whatever he is going on are you
hearing a mix i was hearing pockets of
of good and then pockets of just oh god
I really no I thought I was cool it was
cool at all so cool when two people
playing different things like that would
change how would you do bud vet sorry
how do you do bug that um how would you
mean if you if it's not you what it was
like I've been trying to figure this out
like whether it's possible for a client
to tell that it's doing a bad job
because all it has to go on is whether
it's clogged to some type properly right
you could do some stuff like detect that
you hadn't received any messages for a
while and maybe tell her to shut up if
that hadn't happened but it's it's it's
kind of tricky to get clients to shut up
if they're not behaving properly and
yeah I did welcome
we go thank you okay thanks guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>