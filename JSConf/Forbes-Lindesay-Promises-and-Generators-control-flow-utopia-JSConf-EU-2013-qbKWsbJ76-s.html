<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Forbes Lindesay: Promises and Generators: control flow utopia -- JSConf EU 2013 | Coder Coacher - Coaching Coders</title><meta content="Forbes Lindesay: Promises and Generators: control flow utopia -- JSConf EU 2013 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Forbes Lindesay: Promises and Generators: control flow utopia -- JSConf EU 2013</b></h2><h5 class="post__date">2013-10-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qbKWsbJ76-s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">you
hi right I'm going to be talking about
promises and generators so a lot of
stuff I'm talking about it's very new so
it's very experimental it's getting into
the latest browsers but you're going to
have to enable some flags so if you're
in Firefox nightly I believe this has
just been added it's in Chrome with a
flat if you go to the flags and you can
use it in node with the - - harmony
generators flag and mice the slides are
available for this so if you want to
follow along or whatever you can get
grab those now so I'm going to start off
not really talking about promises not
really talking about asynchronous stuff
at all but talking about how you
represent a sequence so if you've got a
sequence of numbers so here we're
talking about the integers this function
returns the first n integers as an array
and that's really nice for representing
finite sequences arrays work great for
that but the integers aren't really a
finite sequence really they're an
infinite sequence but we can't have this
function returning an infinite sequence
as an array if we try and do that just
replace the condition there with true
this is trying to create an infinitely
long array so this count function is
just never going to return we're never
going to get into that for loop and
we're never going to log any output I
should just note that for oov there is a
new construct but it just loops over the
items in an array or in a sequence or it
supports a much wider range of
collections than say using a for a
traditional for loop so the next version
of JavaScript has built-in support for
these infinite collections and they it
works using it by making the function
lazy and only only executing as far as
it needs to to return the values that
are actually used so what happens with
this count function is that the function
is executed only when we request the
value so initially when you call count
none of the code inside the body is
executed then the for loop requests the
first value from count and at that point
it executes as far as that first yield
keyword and when it gets to that first
yield keyword it returns that value and
we get to use it in the for loop
but it pauses the function so it saves
the entire execution state of that
function and then when we ask for the
second value it resumes that function
from where the yield keyword was and
continues around the loop a second time
so this is really useful for infinite
sequences like this function represents
all of the integers and we can still get
back to the semantics we had before we
can just write a simple take function
that takes any infinite sequence and
takes the first n items out of that
sequence and this would work for
integers but you could equally pass the
Fibonacci sequence as an infinite
sequence and because it's because of the
lazy nature of it we could pull off the
first 5 items the first 10 items as
needed and we can reuse this and we
could have more complicated conditions
as well it doesn't have to be the first
n items it could be all the items up
until an item that matches some
condition for example so that's really
powerful for maths and sequences and
things and later I'm going to show you
how it can be really useful for
asynchronous programming as well so to
get back to the original point of
asynchronous programming I'm going to
follow through a simple example say we
want to write a function that reads a
file and passes it as JSON and returns
the result it's a fairly simple thing
and it's a task that I'm sure many of
you have had to do at some point
especially if you're writing server-side
code would you write jar if you write
client-side code you can think of this
as just making a web request and then
parsing that is JSON nothing I'm talking
about is really specific to note the so
this function is really about as simple
as it can can be to accomplish this
functionality it takes a filename it
reads that file with utf-8 encoding so
it gets a string back and then it passes
it as JSON and returns the result if at
any point one of these methods froze an
error if the read file operation froze
an error or the JSON pars operation
frozen error then it's going to bubble
up the stack and we can handle that at
some top level where we know
or information about how we should
handle it so all of the errors propagate
nicely the results return nicely and
it's a really simple function to read so
we we can make that asynchronous if we
don't make it asynchronous it's going to
block the program and nothing else is
going to happen if it's a client side
app and you do synchronous i/o then
you're going to be freezing the
application nothing's going to happen
for a while if you're doing a server and
you do synchronous i/o then you're not
going to be handling any other requests
for a while so you're going to
effectively the this server will appear
to be down to everyone else so we can
make this asynchronous just by taking a
callback so we add a second argument to
the read JSON function that's callback
and we then also pass a function to our
FS read file we then say if there's an
error we call back with the error and if
there's not then we call back with null
as our error argument and the result as
the second argument this isn't a lot
more complicated than then the first
function we wrote but I wanted to show
you today that this isn't sufficient
this code is a long way off a complete
implementation of read a Sun and we can
do better so this is conflating the
input with the output it's kind of a
subtle point and it might not seem like
it's important but it turns out to have
lots of effects down the line so we're
going from our really simple model of
having arguments as inputs to functions
and some return value as the result to
now having this additional argument that
represents how to how to send the result
back that callback isn't really an input
to the function it's just part of the
mechanics it's relies on pure convention
that we that we passed the error is the
first as the first argument and the
result as the second argument and that
we don't do weird things like call the
call back multiple times so that can be
real problem later down the line it also
won't work with control flow primitives
it's really difficult to do an
asynchronous operation in the middle of
a for loop using this kind of technique
it's just not going to work you're going
to
you can't pause the for-loop while
executing this asynchronous function
this currently doesn't handle errors so
this has a major flaw if I try and read
a JSON file that turns out not to be
valid JSON that exists so the filesystem
read succeeds or the web requests if we
were on the client but where the
json.parse bit fails and frozen error
that error can't be caught anywhere it's
going to be thrown into the global scope
because we're not handling it so that's
simple to fix we just have to use a
try-catch so now we've wrapped the the
bit that does the JSON parsing in a
try-catch and if there's an error we
call the callback with an error this
still conflates the input with the
output it still won't work with control
flow primitives but it does handle
errors in JSON path so we've got a bit
of a win there we have a might a
slightly subtle of floor though we're
handling errors in the callback twice so
if if the filesystem Reedus succeeds the
JSON path succeeds we call the callback
but then that callback frozen error
we're going to callback call the
callback again when really what we
should do is just crash the application
so if you can you can see this in action
if we were to do a read JSON with a
callback which froze an error and
increment some integer each time so you
can see here that n should be
incremented once but will actually get
incremented twice and this seems like a
slightly obscure example but this could
manifest itself with additional log
messages if you're logging the error or
really weird behavior if you're actually
doing something with these errors and
handling them properly so we can fix
that all we need to do is make sure that
we're not calling the callback inside of
the try catch so this code makes sure
that the only thing we do inside the try
catch is pars the JSON and then we
actually call the callback outside of
the try catch now this fixes the bug
we're still conflating the input with
output we're still not working with
control flow primitives but we are at
least handling errors now this was a
this this code might seem like a weird
bug you might think I'd never write code
like that but a very popular library
Jade has had this exact bug for several
years and it was only fixed about a
month ago so these these bugs are
happening in real code I'm not making
these up and it's afoot so now we've got
this fixed function this this function
works it's an implementation of read
JSON as I'd expect to see it in a
typical nodejs program but it's a far
cry from that simple function we started
with this is the real semantics we want
to express we want to express these
semantics and just the additional bit of
information that the file system reads
should be asynchronous so we need
something simpler we don't want to talk
about error handling because the error
handling we're asking for should be the
default anyway so imagine for the moment
the asynchronous methods still return
values asynchronous functions are still
going to return something these values
obviously won't be something we can use
directly because they're going to have
to return this value synchronously but
they're going to execute asynchronously
so we don't know what that value
represents yet but we can somehow await
it we can somehow say tell me when this
value is is settled tell me when we know
what this value actually represents so
we have such a value in JavaScript it's
called a promise there are a number of
implementations of it Q is extremely
popular I maintain my own promise
library called promise and PM installed
promise if you're using node and
so promis represents the result of an
asynchronous operation it can be in one
of three states loosely so it can be
pending or it can be fulfilled or it can
be rejected so every promise starts out
pending and then transitions into either
fulfilled or rejected
and once it's transitioned into one of
those states it's immutable it'll never
change back to being pending it'll never
go from fulfilled to reject it or reject
it to fulfilled so we can implement read
file in to return a promise based on the
built in nodejs FS read file function so
we start by saying we're going to return
a new promise and we give the promise
constructor a function that represents
the asynchronous work we're going to do
and that function gets given a full film
function and a reject function and we
use those inside the method to control
the result of the promise so we do the
read file operation and if the refile
operation fails we reject the resulting
promise and if the read file operation
succeeds we fulfill the resulting
promise
so having built that we can use the done
method to await the result of a promise
so this is how we could build our read
JSON function so this read JSON function
again returns a new promise with these
fulfill and the reject parameters
available it does the read file and when
that's done it tries to fulfill with the
JSON with a JSON pars result failing
that it rejects with the exception and
if the read file operation fails it
rejects with the exception so done takes
two arguments the first of which is an
unfulfilled callback and the latter is
an unregenerate of waiting for the
promise to fulfill it doesn't complete
the input with the output anymore we're
now returning this value so you can see
the arguments through for both the read
file
and the read JSON functions are back how
they should be they're just the input
read file takes a filename and in
encoding and read JSON just takes the
filename we don't have that additional
parameter it's still not going to work
with control flow primitives that
requires language support it does still
require a lot of extra work to handle
errors so we've still got that try-catch
in there which is a bit pointless it's
nothing to do with our hand our actual
application business logic so we really
want to get that out we have at least
made a slight win though
and the this double handling of the
callbacks is how it is dealt with for us
the promise libraries all promise not
not to throw an exception when you call
fulfill which means we're not double
handling any errors we don't need to
worry about that at least we can do
better when you start it out I bet many
of you used for each when you when you
had one array and need another ray that
was based on that first array and I bet
most of you now use map in a lot of
cases where you'd have used for each
when you start it out so map lets you
transform each of the items in an array
and get a new array without having to
manually construct that array yourself
we have a similar system in promises so
done just lets you extract the value of
a promise but we have a method called
then which lets you transform the
promise into a new promise that's based
on that first promise so using that we
can rewrite our asynchronous read JSON
function just as read file filename
encoding then json dot parse so here
what we're doing is the then method is
creating a new promise based on the
previous promise so if the previous
promise is rejected then by default this
new promise this child promise gets
rejected as well so that propagation
happens automatically we don't need to
handle that anymore and the unfulfilled
if there if unfulfilled so that the
first method
the pastor then is a non fulfilled
handler if that if that method frozen
error then we reject the resulting
promise that happens automatically for
us so we don't need this try-catch
anymore and if the if that method
returns a value then that's used as the
result that's what the promise is
resolved with so we don't need any messy
callback stuff anymore we're just
dealing with the pure simple business
logic now here we have a function that
takes a single argument and passes that
single argument to another function and
returns the result so we can simplify
that a little bit by just passing
json.parse directly note that I'm not
calling JSON docpods there I'm passing
it as a function as the argument this
doesn't conflate the input with the
output we're returning a promise from
all of our functions it still won't work
with control flow primitives yet but it
handles errors and it handles them
really gracefully we haven't added any
extra code to handle those errors they
just bubble up the stack just like they
would in synchronous code so we can
still do better though this is still
this is still a really simple example it
doesn't have any for loops in it it
doesn't have try-catch it doesn't have
while we want to be able to get back the
ability to use those control flux
control flow structures to manage our
code so what if we could await a promise
somehow what if we could pause a
function mid execution and wait for the
promise to resolve well as way as I
mentioned at the beginning of the talk
we have a method for pausing a function
mid execution because that's what yield
does so with an async helper we can make
yield effectively wait for a promise to
resolve and return the result so at the
top there you can see our original
synchronous JSON function and at the
bottom you can see our asynchronous JSON
function and you can see all that
changes is that we add the keyword we
add the async function the async wrapper
the star which denotes a generator
function
and they yield to tell us that we're
going to wait for that promise to
resolve this doesn't complete the input
with the output this will work with
control flow primitives this handles
errors and it remains looking
asynchronous it has just enough clues in
there but I can read this code and know
instantly that it's going to be doing
something asynchronous we have the async
keyword that tells us that function is
the function as a whole is asynchronous
and we have the yield keyword telling us
exactly where that asynchrony is going
to happen so we can use this to do
things like a sequence of operations we
can read one file then read another file
just by doing multiple yields and then
we can use the result because promises
are first-class values we can fairly
easily do the same thing in parallel
just by starting in both operations and
storing the promise that for each of
those operations in turn and then having
started both operations we then wait for
them one at a time which leads to the
actual IO happening in parallel and
since the IO bit is the slow bit that's
really what we want like I said it
worked with control flow it with the
normal control flow structures so we can
do this inside a try-catch if we have
some asynchronous get key method we can
put it inside a try-catch and have some
handler in the catch block we can use it
inside for loops say we have an upload
method to upload a document and we want
to upload multiple documents one at a
time we can just loop over the documents
and upload them one at a time a
synchronously so the result of this is a
is a promise so this function is a
function that returns a promise it's
asynchronous in its own right and it's
using these asynchronous methods
internally if we wanted to do a parallel
one one option would be to start off all
the operations in one at a time and then
wait for them all to complete one at a
time there are helper methods in most
promise libraries that mean that there
are easier ways you could do this
so I want to talk about how it works
under the hood like initially that can
look like a lot like magic I don't know
my my first reaction to this is that
seems like a lot of magic but it's
actually relatively simple so yield of
some expression is itself an expression
yield evaluates to something and a
generator can be manually operated using
the next method so you can take a
generator and rolling using a four of
loop to loop through it you can manually
say give me the next value
give me the next value give me the next
value so say we have a simple generator
here this generator yields ten asserts
that the result of yielding 10 is 32 and
then returns 42 we can execute this
manually first of all we call demo which
instantiates the generator this returns
an iterator or generator and we can call
next on it and that moves the point the
control flow pointer to that first yield
expression it returns us the thing
that's been yielded which in this case
is the ten and something that a Tanner
and a done property that tells us that
it's not finished yet there are there
are potentially more values to yield
it's not the end of a function and it's
not a return keyword we can then use d
dot next again to move to carry on but
if we like we can feed it a value to
return from that yield so by fielding it
by feeding it that 30 to there we're
able to inject that value into the
function and that becomes the value of
res inside the function hence the assert
path since the result we then get is 42
which is the result from the return and
the done property is true because it's
the last operation if we call D dot next
again it's going to throw because that
function is done it's finished so we
can't carry on using it
now generators were created with this
use case in mind as one of the possible
use cases and as a result we have this
really helpful method afro now fro takes
an error it doesn't have to be an error
you can pass it like 10 if you want to
but I'd strongly recommend you use
errors
whenever you're throwing things throwing
errors gives you stack traces throwing
anything else doesn't so we can use
yield inside a try/catch and we can make
that yield throw to invoke the catch
operation so again we start by calling
demo instantiating the generator we then
call next to move it to that first yield
we get back the result that's yielded so
that's the 10 and the fact that it's not
done we can then call throw and throw an
error into the generator so that will
cause the yield expression to
effectively throw that error and cause
the catch block to be executed so that
allows us on the one hand to represent
fulfilling so this is promises being
fulfilled by injecting values into the
yield and we can represent promises
being rejected by injecting insect
exceptions that are thrown into the
yield so we can put this all together
and we get this surprisingly simple
function so this is a function wrapper
it returns a function when given a
function first thing it does is call
that function to return a generator and
that's going to be a generator that's
effectively an an a lazy sequence of
promises so we start by moving to the
first yield we get the first promise
that's yielded and we attempt to handle
it so handling it says if it's done then
it must be like a return keyword or the
end of a function so just return the
result otherwise we've been yielded a
promise we've been given a promise that
the function wants us to resolve and
give back the result of so we call then
on that promise and if it's if that
promise is fulfilled
we call generator dot next with that
result which lets us inject the
fulfilled result back into the function
and then we handle the next iteration
the next yield the next yield keyword if
the promise is rejected it's very much
the same story but we're throw so we're
now injecting that exception that throw
into the function as it's running and
continuing where we left off and if the
function inside doesn't have a try-catch
then that'll bubble out as an error if
it does have a try-catch though it'll
just get handled and and it can carry on
and there it might it might have a
try-catch that then awaits other
promises later on so generators are a
big win I don't think anyone I haven't
seen many people denying that they're
fantastically useful for controlling
your asynchronous code but there are
people who dispute that generator that
promises are the right tool for the job
for interacting with generators so I
want to give you some examples of some
of the other things that people have
done to try and manage their
asynchronous code I'm only going to give
you examples that work with the native
control flow structures because I'm not
really interested in anything that
doesn't but I haven't chosen difficult
or bad examples I just want to give you
a feel for what else is out there
and why I think they're not really
sufficient so streamline has been around
for a very long time streamline lets you
replace all of your callbacks with the
underscore character and then act as if
all your sync functions are synchronous
now this is fantastically clever but it
does this by read by compiling your your
code into some monstrosity that actually
handles this so that cross-compilation
needs to really ugly code and really
ugly behavior and it has a few other
issues so it works for control flow
primitives like I say that's great
it handles error propagation properly
but it's conflating the input with the
output again again we've got this
parameter
there's not really a parameter it's just
about how we return the result
that's the underscore we have to pass
everywhere that's not too much of an
issue
it also looks entirely synchronous
though
when you read that as a JavaScript
developer its natural to assume that the
function there is synchronous there's no
keywords that imply that this is doing
anything asynchronous and that to me is
a huge problem for maintainability and
it compiles to pretty ugly code and like
it or not sooner or later you're going
to end up trying to debug that code and
that is not code you want to be
debugging so suspend this is probably
one of the most ingenious libraries I've
seen in the last year so this is a way
of using pure callbacks nodejs style
callbacks with generators so it gives
you a callback to use everywhere let's
this resume you pass resume to any of
your asynchronous operations that you
want to yield on you then yield and it
yields until resume is called now this
is very clever
it works for control flow primitives
that handles errors it's conflating the
input with output but it has a really
major flaw it's really not doing what it
looks like it's doing so FS dot read
file is still the nodejs style read file
here it returns undefined so you're
yielding undefined and waiting for that
resume to be called so if I put the FS
read file on the previous line and
yielded some random value say 10 or 42
it would have exactly the same behavior
the yield value is ignored what that
means is that when you refactor it you
get really surprising results you can't
do parallel operation for example you
can't say read this file and store the
pending operation read this file store
that pending operation and then yield on
each one because then you've got a race
to see which one calls resume first
because it's the ordering of calls to
resume that determines which yield goes
with which resume so for me that that
cleverness there is too much cleverness
it's not doing what it looks like it's
doing and therefore I wouldn't want to
use that
next library it's very popular by its by
Vision Media TJ it's called Co so the
idea here is your asynchronous
operations also become lazy they return
a function that takes a call back and
then you yield that function that takes
a call back as its only parameter and Co
will handle calling that function for
you this works with control flow
primitives
it handles errors it can't do parallel
operation as easily because it's lazy so
you can't just start those operations
and then yield on them because they
won't actually start until you yield on
them
you also can't share or cache the
asynchronous operation so I frequently
cash promises as part of like database
reads and things caching these won't
help because you'll end up still
executing the function and you another
time for every time you ask for the
value back so it's a neat abstraction
it's one of the best of the of the worst
but I still wouldn't wouldn't recommend
it I'd still say promises are a lot more
useful a lot more powerful also this
offers you know help today
so using this method offers you no help
when you don't have generators it's only
a help when you've got generators so to
wrap up promises let us turn this read
json function which is 90% error
handling into a read json function that
just has the business logic and that
simple then method to indicate that
we're doing something a synchronous
generators let us turn this nested read
file operation with with multiple calls
to then which is about as simple as I
can write that that specific code in
promises into something that looks a lot
more like what we're used to seeing the
multiple operations one on each line
with no need no need for indentation
just to create that that asynchronous
control flow
I've been Forbes Lindsay thank you for
listening you can find me on Twitter
github I have a blog I maintain loads of
open source projects I work at Red Gate
and the slides are online if you want to
grab them thank you
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>