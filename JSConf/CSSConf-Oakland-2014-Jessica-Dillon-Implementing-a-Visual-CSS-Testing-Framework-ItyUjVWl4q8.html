<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CSSConf Oakland 2014 | Jessica Dillon: Implementing a Visual CSS Testing Framework | Coder Coacher - Coaching Coders</title><meta content="CSSConf Oakland 2014 | Jessica Dillon: Implementing a Visual CSS Testing Framework - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CSSConf Oakland 2014 | Jessica Dillon: Implementing a Visual CSS Testing Framework</b></h2><h5 class="post__date">2015-06-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ItyUjVWl4q8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks for having me here this is song
right but second okay today I'm going to
talk to you about implementing a visual
CSS testing framework using automatic
screenshot comparison to catch style
regressions my name is Jessica on the
internet and Jessica in real life and I
work at a company called bug snag here
in San Francisco bug snag is an
exception monitoring tool I'm a software
engineer they're working primarily in
Ruby and JavaScript but our stack
includes lots of languages including
node and go we're currently hiring so
please get in touch if you're interested
in working at a super small company for
developer tools so back to this whole
implementing a visual CSS testing
framework thing what am I even talking
about well at bug snag we decided we
wanted a way to automatically take two
screenshots of our website at different
times in our app for example since we
use get let's say we had a feature
branch that we just push to commit to
we'd want to take a screenshot of what
our home page looks like on that branch
and a screenshot of how our home page
looks on production or what's currently
running on master with those screenshots
we want to spot those differences and
produce some sort of diff image that
highlighted the difference is why would
we want to do this you ask well as we
all know writing reading and code
reviewing CSS can be pretty intense and
even more intense to refactor at bugs
nag we decided to do a huge
organizational and code style refactor
of our CSS and we wanted a way to test
that our site look the same despite
changing all of the code unfortunately
as you can tell that didn't really
always work out for us we went through
many iterations of refactoring and we
realized we needed a tool to help us out
and test our pages automatically so we
went on a hunt for a way to test our CSS
we wanted to know if there was a tool
already built that did what we wanted
without knowing exactly what it is that
we did want we first stumbled upon one
of Facebook's open source libraries
huxley and Huxley's read me it says
watches you browse take screenshots
tells you when they change which sounds
amazing it's exactly what we wanted but
I noticed it hadn't been updated in over
a year which wasn't promising but I
decided give it a shot anyway
after a good while of fiddling around
with Huxley it ended up being a little
bit too buggy for us although I did hear
somebody talking about it did work for
them so I'm happy yes but for us at it
would have random failures randomly
wouldn't take screenshots and I started
realizing it wasn't exactly what I was
looking for in a CSS testing tool anyway
I kept looking and it turns out there
are a lot of frameworks that do some
sort of CSS testing they all work in
different ways some take screenshots
some aren't even visual I definitely
recommend checking some of these out and
seeing if they fit what you're doing in
your apps before trying to build your
own but I really started thinking about
it what was I looking forward to CSS
testing framework what would fit the way
bug snag is built best I decided I
wanted a visual way to test my CSS with
screenshots rather than writing out
tests describing the visuals this is
where I need a disclaimer at bugs nag
our web dashboard is written in rails
this mix with the fact I wanted to test
to take screenshots affected my
decisions in what frameworks I wanted to
use we also use get for our source
control bug snag and we use it the
github way what that means is we have a
master branch which is always
deployables ready or it should be and
whenever we want to create a feature we
branch off master until it's ready and
then we were jit back into master
considering the tools we had at our
disposal and after taking a look at some
of the screenshot libraries their source
codes I realized that there actually
wasn't that much code going on in them
so I decided why not i'm going to write
one myself which is always a bad idea I
came up with a process of how I thought
I wanted my tests to work number one I
wanted a way to somehow automatically
visit pages of our site so the test
would in an actual browser hit each page
of our site on a local server once the
test visited the page I wanted the test
to take a screenshot of that page the
important bit for the screenshot is that
I'd wanted to take a screenshot of the
entire page not just the current view
port of the browser for example if a
change happened below the fold of our
site but we weren't taking full-page
screenshots we wouldn't be able to
capture the diff down there next I need
us I need somewhere to store these
shots and I need a way to upload and
download these screenshots from that
storage area so using get every time I
made a push to a branch I'd upload a
screenshot of the current state of each
page including our master branch and if
I had a screenshot already uploaded to
our storage area from our master branch
I need a way to upload my current
features branch to that storage area and
download my already uploaded master
screenshot from that storage area I then
need a way to make a diff of my
screenshots I'd want to diff between a
screenshot I took on master downloaded
from our storage area and the newest
screenshot I took on my future branch so
if i have the previous screen shot i
took which would be the current commit
commit on master vs my branches
screenshot i need a way to mark the
differences between those two
screenshots visually so in here it's the
header finally after i have just for all
my screenshots i need a way to view the
diffs even though i'll have a place to
upload them i did an accessible way for
everyone on the project to view the diff
screenshots depending on the commit so
now we have a plan we can start building
out our framework or on these things
that we need we need a way to write some
specs that will automatically run after
each push so we decided to use our spec
our spec is a testing tool for the Ruby
programming language we already had our
spec for our tests in our rails app so
writing these tests with our spec made
sense we wanted to be able to write
specs that look just like this where
we'd be able to navigate to a local URL
and save a screenshot of that page we
also wanted to these tests to be
separate from our main tests we pulled
out these visual specs into their own
r-spec tag that way these specs wouldn't
run with our main specs when we're
running the sweet locally unless we
explicitly asked it to this also made it
so we could break out our specs on our
CI we want on our visual specs to be
separate for a few reasons number one
our local build speed if our tell if our
local tests were bogged down by waiting
for visual specs that would become a
huge issue by having them broken out we
get iterate on our mains
Beck's faster and be able to push out
more often number two is speed with our
CI tests we wanted our main specs to
still be fast on our CI so that we could
merge non-visual pull requests without
waiting for our visual specs to finish
CI or continuous integration is a way
for us to automatically run our test
suite when we push things to github and
after our specs run on our CI we're able
to see if our build or is passing or not
I also learned that github just released
a new feature where you can split out
your build so thanks github so now we'll
be able to split out our visual specs
from our main specs here and so we can
quickly see which build is passing or
failing or still running without the
builds being combined at bugs now we
used build box for our CI build box
allows us to add steps to our tests that
way we can run our main specs first
apart from our visual specs and when
they're separate our visual specs don't
slow down our main specs and we converge
non-visual pull requests without waiting
for our visual specs to finish next we
needed a way to visit pages and take
screen shots with our r-spec tests for
that we decided to use selenium selenium
is a tool for automating browsers for
testing purposes we would need to use
specifically their webdriver API this
would allow us to drive a browser
natively on a local or remote machine
and more specifically this provides an
API between us and the browser to use
selenium we need to use the service like
soft labs or browser stack since we are
using a CI it doesn't just have browsers
built-in on the server we'd either have
to set up our own virtual machines for
these browsers or use one of these
services so we ended up trying browser
stack before our visual tests we need to
start our proxy to browser stack and a
fork trail server and then we need to
make an instance of our selenium
webdriver and then of course after all
of our tests we would terminate these
services we also had to allow but web
mock web mock is a library for stubbing
and setting expectations on HTTP
requests in Ruby this is to run what
real web requests in order to use our
local servers and upload our screenshots
to get our browserstack proxy running we
would just bought a new browser stuck
process and terminate the process using
its assigned PID and to get our rail
server running we would just spin up a
new rails process at four three thousand
unless one was currently running and
terminated the same way as our browser
stack process to set up our selenium
webdriver ways have to pass with the
capabilities we wanted like the browser
information and a URL to hit which was
pointed up our browser stack setting up
our silentium driver was easy but when
we were setting it up we did learn some
interesting things about taking
screenshots with different browsers with
our web driver we wanted to hit pages in
a trail browser and be able to take
screenshots of the full page not just
the current viewport unfortunately this
feature only works in firefox which is
not ideal since internet explorer and
chrome didn't work we couldn't really
transform this framework we were making
to be used for browser compatibility or
anything like that although this was an
ideal for our purposes right now is
we're factoring tool Firefox works fine
after writing our tests for static pages
such as our homepage we quickly realized
that we'd have an issue with the dynamic
data on our dashboard with dynamic data
you can get false positive diffs because
data can change between the viewing
times to combat this we set up picture
data for our r-spec tests and manually
adjusted any other data not covered by
fixtures using selenium JavaScript
support so that we don't get a false
positive diff okay now we have our test
taking screenshots we need to figure out
a way to make a diff between two of our
screenshots a magic worked perfectly for
this despite having literally one of the
worst sights I've ever seen imagemagick
did exactly what we needed imagemagick
is a tool to convert edit and compare
images image odjick has a command line
compare tool that with very various
options enabled allows us to shell out
and produce diff screenshots based on to
other screenshots for example when we
make a simple change to the Heather to
the header I tragic would spot those
differences and produce a screenshot
like that Emma Dragic has a lot of
options you can pass to its compare tool
and we take advantage of a few of these
options in order to make it work let's
go back to those options we use for a
second and go over how they actually
work with what we're doing
image objects compare tool from their
website mathematically and visually
annotates the differences between an
image and its reconstruction or in my
turn terms takes two images and provides
a Jeff compare lets you provide a metric
that outputs to a standard error a
measure of the difference is between
images according to a type of given
metric here we're using pae where PA e
stands for peak absolute we can use the
peak absolute to find the size of the
fuzz factor needed to make all pixels
similar so if we had screenshot 1 and
screenshot to that are pretty different
it would end up producing a diff like
this and our Peaks peak absolute
measurement would be outputted as
needing a huge fuss factor to make all
pixels similar the fuzz factor can be
important in case we want to ignore
pixels which only change by a slight
amount we might want to ignore small
changes in case of false positives for
example I've had false positives before
because gradients rendered slightly
differently between two images we don't
actually use this output right now but
it would be important if you wanted to
make an assertion in your tests
meaningful like actually have a failure
if a diff was produced we didn't end up
doing that because it doesn't
necessarily mean something's wrong if a
diff is produced it just means
something's change a few times when we
were running our specs we notice that
dips weren't even being produced we took
a look at the screenshots and realize
that they were different heights or
sizes for some reason like if we made a
change to accidentally remove the footer
Emma Dragic wouldn't let us do a default
compare on these images so we had to use
a sub image search sub image searching
is required to have compared search for
the best match location of a small image
within a larger image this option will
produce two different images or two
frames is what they call them the first
is the diff image is which is the one
we're going to be using and the second
would be the match score image match
score image isn't really important to us
but it's an image that's a smaller image
containing a pixel for every possible
position of the top left corner of the
given sub image the search will try to
compare the sub image at every possible
location in the larger image this can
make sub image searching very slow as
you could guess the smaller
some of the sub images the faster this
search is that being said this option
doesn't take effect unless you have two
images that are different sizes this
doesn't happen very often to us so the
amount it slows down our visual specs on
CI isn't really meaningful to us
especially since those specs aren't tied
to our main specs another fun thing we
ran into is sometimes our screen shots
were completely different like
completely different and imagemagick was
not into it in fact it just wouldn't
even give us a diff because the images
were so different without an option
called the dissimilarity threshold which
I find kind of weird this thrush will
determine how different two images could
be in order to dip them it's he faulted
2.2 so I just made it one and it seemed
to do the trick the only caveat as you
might get as you might have guessed is
doing dips on completely different
images can slow down your test by a lot
like our previous issue with some image
searching this doesn't seem to happen
much and since the tests are separate
from our main specs we weren't worried
about it plus the arguments aren't very
exciting just where our current
screenshot is located where our master
screenshot is located and where we want
the diff to save to okay now that we're
done with that stuff we had now that we
had our screenshots in our diffs we
needed somewhere to actually throw the
screenshots online and be able to grab
them back out with our rails app so we
decided to use AWS AWS or Amazon Web
Services offers cloud storage and has a
ruby API so we'll store and retrieve our
screenshots from one of their buckets we
ended up using a naming pattern of
commits sha area of site page name and
image type so for example we could have
a commit show of a 1a 1a 1a very
realistic I know where we're on our
marketing part of our site on the index
page and we're uploading the diff for
that page the image types could be the
current screenshot we took the master
screenshot we downloaded from s3 or the
diff we made of the two screenshots
viewing the screenshots from an amazon
bucket was far less than ideal so we
decided to set up our own custom viewing
page in our admin dashboard we created a
page that listed out our current
branches with our last three commits
and when you would click through it
would show you by area all of your
screenshots and dips which is our end
goal we did it however our tool is not
perfect right now it's certainly better
than what we had which was nothing but
right now all of our tests pass whether
or not there's a diff the only failed
there's an issue executing the test it
could be interesting to make our
assertions mean something like fail if
there's a diff we need to think more
about that because a diff like like I
said earlier it doesn't necessarily mean
a failure to us and the future it might
also be nice to account for 0% diffs so
maybe we shouldn't upload a diff image
at all if there's no diff between images
this could save a space on AWS bucket as
well speed up our tests because we're
trying to upload for your screenshots
and it would make our admin dashboard
less noisy we also think it would be
nice to automatically link these two a
github pull request so when a diff is
created maybe automatically attach it
onto its relevant pull request this
sounds a little tricky because maybe we
don't want to create that much noise
every time we push but it's an idea
something we need to think about another
thing is that we currently only diff
between our current commit on a branch
and versus our most recent commit on
that sir so when we push a new commit to
our branch it'll diff versus the last
thing that we push to mash to master
this way we know what's changed between
the future I'm working on and what's
currently running in production it would
be nice if we could dip on master with
the current most recent commit and its
previous commitment so that way in cush
in case you push a visual change
directly to master which don't do that
you could still see a dip for it it
would also be nice to see a diff between
the previous commit on the current
branch as well like if you push to
commit to your branch that changes some
stuff visually you might want to see a
dip between those two regardless of
what's happening on master it also
really love to get this hooked up to
more browsers that would really enable
us to make this into a backwards
compatibility tool as well as an
automatic browser comparison to make
sure things aren't messed up in IE
thanks that's all I have and feel free
to ask me questions after a few
interesting
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>