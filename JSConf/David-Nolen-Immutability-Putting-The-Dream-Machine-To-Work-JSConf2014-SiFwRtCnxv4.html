<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>David Nolen: Immutability: Putting The Dream Machine To Work [JSConf2014] | Coder Coacher - Coaching Coders</title><meta content="David Nolen: Immutability: Putting The Dream Machine To Work [JSConf2014] - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>David Nolen: Immutability: Putting The Dream Machine To Work [JSConf2014]</b></h2><h5 class="post__date">2014-07-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SiFwRtCnxv4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi so my talk is called
immutability or putting the dream
machine to work so I've been a front-end
developer for eight years now I was at
the New York Times for four I recently
left to join up with a company called
cognate echt their consultancy and they
also have a database and a cognate act I
think we believe that a lot of software
is far too complex and there's ways to
achieve a lot more simplicity in the
type of systems that we write one way to
achieve simplicity is through
immutability
by embracing immutability so content
tech stewards closure and closure script
I'm the lead maintainer of clojurescript
those languages emphasize immutability
we also have a database product called
date Tomic which is a immutable
relational database I'm not actually
going to talk about any of those things
today or only we'll only talk about them
a little bit the thing that I really
want to talk about today is the dream
machine so if you have not seen this
book or encountered this book this
should be number one on your reading
list if you are involved in interactive
computing in any way shape or form this
was recommended to were recommended by
Alan Kay as one of the best histories of
how interactive computing came to be it
will make you laugh it will make you cry
and if you have anything with you eyes
it will fill you with a sense of wonder
so JCR Licklider was a psychologist who
at the time realized that there was not
a serious enough perspective on the role
of human psychology and human factors in
computing systems also a lot of people
didn't believe interactive computing
systems would be of any utility
whatsoever and he really paved the way
through
to make sure that research institutions
were you know putting the time and
effort into discovering the results of
you know interactive computing so he is
most famous for two essays one of the
famous ones is called the man computer
symbiosis
so Licklider basically predicted my talk
fifty-four years ago I was going through
this paper for the actually the first
time two days ago and he says something
very specific which I'm going to talk
about quite a bit today this talk is a
bit of a little bit of history a little
bit of data structures and a little bit
of examples so in this paper he he sort
of lays out what are the types of
hardware and software things that are
going to pave the way for interactive
systems he saw computing as a way to
augment the human intellect so he says
in this paper the tree memory scheme is
inefficient for small memories but it
becomes increasingly efficient and using
available storage space as memory size
increases the attractive features of the
scheme are these number one the
retrieval process is extremely simple
given the argument entered the standard
initial register with the first
character pick up the address of the
second then go to the second register
and pick up the addresses of the third
if two arguments have initial characters
in common they use the same storage
space for these characters and I'm going
to actually talk about this quite a bit
here we have several people that
benefited from the culture that
Licklider created John McCarthy received
considerable funding he is the inventor
of Lisp artificial intelligence
interpreters functional programming
garbage collection all things that are
critical for doing anything that you
guys are doing today he was a
mathematician at the time using
computers was extremely difficult
he believed that computer actually
programming the computer itself should
be a real-time interactive activity you
can thank him for console the
interactive console that's that's
definitely due to John McCarthy to his
right is Ed fredkin he was a Caltech
dropout at nineteen went to the US Air
Force was a fighter pilot and then when
he was very young was pivotal in in
hacking these early computers to do
impossible things to build interactive
systems
Ede fred can also invented the tree and
that spelled TR IE and that's what we're
gonna talk a bit about so Alan Kay is
another important figure he also
benefited from the culture that
Licklider created Alan Kay what well
understood
John McCarthy's ideas he built an
interactive programming language but on
top of that he sort of erected the
edifice that we are all familiar with
today around object-oriented programming
as well as blazing the trail around what
we consider modern user interfaces so
here's an image that I think is very
inspiring a big goal of his was that
computing should be simpler that it
should be available to people at a very
young age
here are some boys and girls and they're
interacting with a live small talk
programming environment and they're
doing things that you know we're I mean
they were very lucky right they were
they were they were experiencing the
future of computing when most people
were still doing basic right there's a
really great article I recommend reading
this is an article that I found on the
Atari archive it's more its Marion gold
Goldeen Marion golden and she was 11
years old and she was lucky enough to
experience a Xerox Paul out Xerox Alto
and small talk and she describes when
she's like 12 years old what it was like
to program one of these machines so she
she but directly benefitted from the
dream machine she's actually has for
years been a UI programmer at Apple and
she went off to do this because of her
experiences with the small talk
environment anyways you can fire up a
small talk environment today there's an
open-source one called squeak it's quite
cool if you open the system browser
which uncovers the entire internals of
that system you will encounter something
which is very familiar to JavaScript
programmers model-view-controller trig
Vereen Skagen Adelle Goldberg and others
at Xerox PARC invented NBC what 35 35
years ago
longshadow people are still talking
about this stuff I would actually argue
we haven't really advanced much beyond
it but that's okay because at an
abstract level NBC is a sound separation
of concerns we want users to be able to
interact with their domain we want to
have in
we do visual representations at a domain
and as programmers we want to coordinate
that abstract domain and those abstract
visual representations such that the
user has a pleasant experience but I
would argue that implementations leave
much to be desired that's having worked
with a variety of mbc's over the years
and that's because they're erected on
top of stateful objects you have
stateful models you have stateful
controllers and you have stateful views
and so the crazy empty idea that I'm
going to throw out as I think that
Licklider was correct if you build your
user interfaces around trees really cool
things happen so trees so this is the
data structure part of the talk I'm just
gonna reuse some slides because these
slides are amazing they were done by
Zach Hollan at hacker school he's a
facilitator there he put these slides
together for strange loop and they're
just so good there's absolutely no
reason for me to come up with my own so
regardless of whether you like
functional programming a lot it's not
very important but all these ideas apply
if you like object-oriented programming
but we need to at least understand how
these data structures came to be and why
functional programmers like them in
order to understand how we might use
them if we prefer the object-oriented
approach so functional programmers they
like immutable values they don't like
stateful objects and when you change
something you just return a new value
and as JavaScript programmers you guys
are already well aware of this you have
numbers in JavaScript they are thank
goodness
immutable strings you're lucky not every
dynamic foreign language had add
immutable strings you have immutable
strings so what functional programmers
want is that yes we know that if you add
one and one and we get to that doesn't
doesn't change the other ones right so
functional programmers also want this
behavior from collections so if I had a
key value to a map I get a new map and
the old map is not destroyed so as
JavaScript programmers you're extremely
used to destroying data on destroying
the past and we don't have to do that
and I'll demonstrate how this can be
done and so this is where the term
persistent comes from not persistent in
the sense of like you're going to record
it to a database but persistent in the
sense that you're not destroying
previous values and they're very fast
and this is actually relatively a recent
development Okazaki talked about purely
functional data structures but that
you know they're there okay and they
work they have good paper complexity
bounds a man named Phil Bagwell who was
EPFL where Scala was invented he did
initial research in the early 2000s and
how you could have really
high-performance persistent data
structures and they were further
modified by Richie key and actually it
was really closure that showed that they
could perform well on modern hardware
but they might that might sound really
advanced but I wanted to show you that
it's not scary oh I bet almost everyone
here in this room knows what a linked
list is and linked lists have the same
properties that we like about trees so
in a linked list here's a list with four
things in it and we store it in a
variable X well I can cons some value
onto the head of that and I can store
that in a variable Y and now I have two
values right and they share more than
50% of memory right they represent two
distinct values but they share more than
50% of memory I can take the tail of X
and cons e onto that now I have three
distinct list values and they all share
more than 50% of their memory so this is
a scalable idea this idea is called
structural sharing so sharing structure
gives us space efficiency but less
obvious is that actually gives you
computational efficiency so you if you
use structural sharing you can do these
immutable values and you can update just
a part of it and it will be efficient so
Phil Bagwell innovated this space again
he came up with this thing called the
array map try sort of tree hash array
hash array map tree rich Hickey took
that and modified it quite a bit in a
very clever way and he invented
something called the bitmap vector tree
so I know that everybody here knows what
an array is so a bitmap vector tree is
like an array it's its high-performance
random access and you can append to the
end quickly as well so the way that they
work as data lives in the leaves
it's a prefixed tree remember Licklider
was talking about this in 1960 it uses a
prefect as a prefix tree to find a
particular value and it's but it's done
in a bitwise way to make that more
visual so in in the in the tree of a
persistent vector you have an array of
arrays so at the root you have to pick
some fixed size say four and then every
element of that points to
an array which was also the same size
and then those arrays point to more
arrays that are the same size finally
you're gonna hit a leaf node where you
have actual values okay this sounds kind
of interesting but how the hell do you
look up anything in this so imagine we
wanna get the hundred sixth element so
we can do this really cool trick that
represents a binary number we can use
bit masking to find that thing so we can
bit mask off the first two bits this
tells us to look at look at index 1 we
can bit-bit mask the next two bits that
get takes us the next level
look at index 2 bit mask again finally
it says the value you're looking for is
that index 2 and that's 106 so if you
know anything about modern JavaScript
engines array accesses and bit shifting
is about as fast as you can get this is
going to do this is going to be the
engine optimize this in pretty wild ways
which I will show that - but what about
update so this is where the structural
sharing comes into play if I want to
update for example I want to replace 106
with the string foo how much work do we
have to do we only have to clone the
arrays on the path that changed all
other paths that weren't involved in the
change don't need to be updated so
that's how much work we have to do to to
update that thing and none of the other
nodes are going to change they all stay
the same so this is where the the
structural sharing we saw with linked
lists happens with trees so you're
probably thinking well the for this
seems like a weird number to pick for
the length and of course after empirical
testing it turns out that 32 is a really
good number on modern hardware you do a
bunch of tests and 32 works out the best
in terms of how expensive is it to
update versus how quickly we can look
something out ok just to give you a
sense of how good a such a wide
branching factor is 32 to the seventh
power that's 34 billion elements on a
64-bit OS with a 64-bit VM where the
values are 64-bit if you do that in a
regular JavaScript array that's 256
gigabytes of RAM I don't think anybody
in this room has a laptop with that much
memory to update something in this data
structure only requires seven array
updates to access anything at most you
need seven re accesses and
operations okay so that's a lot of talk
let's see some let's see some numbers so
this is a recent bill to v8 I'm I've
exported all the functionality and
closure script by a library called Mori
which is available on NPM as well as for
the browser if you want to do that so
what I do is I build an array and I add
one mill I just push 1 million elements
to when I time that and then I do this
with a persistent vector and I just
calculate the average well it looks like
83 milliseconds on this particular
machine and then we have an average of
about 288 for persistent vectors so it
should already be shocking because it's
this is not an order of magnitude slower
right this is about a little bit more
than three times slower that's already
cool there are many applications that
could benefit from these data structures
that don't need just the craziest amount
of perf I'm going to show something a
little bit crazier so we've been doing
persistent data structures for seven
years now enclosure enclosure scripts
we've gotten more and more clever about
what optimizations you can do so you
guys might be familiar with object
freeze so of course all all of our data
structures are already from effectively
frozen but we have a corresponding
operation called thumb rule it's called
transient but we imagine it's like
object thaw and we can get in oh one
time a mutable version of the persistent
thing and we can also make a persistent
again in oh one time so how does a
transient vector compared to a immutable
array it's faster to build a persistent
vector than it is to mutate a mutable
array so that's pretty crazy to show
that this is true on on engines other or
not faster but the performance is about
the same or not so bad for other
JavaScript engines this is a recent
build of JavaScript core it's not it's
not significantly slower right so we but
we have we have all this all these
magical properties that arrays don't
have and we can achieve their
performance of mutable arrays okay so
that's that's awesome so this is this is
because so many people have been
building the dream
machine forest right just so much
research has gone into optimizing
dynamic programming languages and I got
really excited because recently WebKit
sort of kicked up the notch again I felt
like things were stagnating a bit with
their FTL JIT which is a fourth tier and
that tier is going to absolutely love
the type of code that's involved in
doing these kinds of data structures so
there's more excitement to come nick
bray talked on thursday about opening up
the door to shared memory parallel ism
so closure skippers already ready for
that clojurescript data structures are
already locked free so you can do
parallel operations on them without
locks okay so hopefully you're excited
about trees and you're convinced that
maybe Licklider had a good idea in 1960
so I want to see well what does this
mean for interactive programs so I built
a library five months ago called ohm
maybe some of you heard of it
it it basically marries are the suite of
tree based data structures with react
and it turns out that these are a really
good pair and let's talk really briefly
why so we can now represent our
application state as one giant immutable
value and then react says oh well you
can apply a function to that and we're
going to compute some virtual Dom which
is another value and now if I update my
immutable app state and I get a new
value I can apply that function again
and react will produce some new virtual
Dom and the way that react works is it
applies a very clever differing
algorithm on the on these two virtual
Dom's and then that creates a minimal
change set but what's fascinating about
this is that what happens if we flip V 1
and V 0 for free react will give us the
reverse change set right for free so
this means that we can do undo redo
trivially you can you can jump to an
arbitrary point in time you can also do
things it makes actually computing
Delta's faster you can do it makes that
which makes synchronization simpler for
example if you want to roll back your
app state on an error you can just jump
back to the previous application state
the snapshot you don't have to manually
reconstruct what your app looked like
before the error occurred lots of cool
stuff it's not just about undo and redo
which some people get confused about
ok so let's so I it's it's most fun to
show an example that I did not write so
I
I said I did a version of to do NBC with
ohm and I said I think I can do undo
pretty simply and I was able to do it
and non-invasively I did not change any
of my to do MVC code I did in an
external change and it was five lines of
code to add undo over the entire state
of the to do MVC application so this guy
at Ableton this guy Jack Scheidler said
well maybe maybe David know is pulling
my chain here is this this is actually
really work for a less trivial thing
than to do NBC so he decided decided to
build a 64 by 64 pixel editor the pixel
surface the frame is represented as an
immutable vector and that's 4096 values
in there that represent pixels so let's
see this guy in action so I can I can
select a color here and then I can you
know start drawing some things on the U
or let's resize that on the right you
should see the history accumulating I
can go over here and I can click undo
and click redo I can I can scrub and you
see the preview on the left oops
to do that and I can you know I can I
could you do this forever I've done it
you know I've done like 200 levels of
undo and the app is still responsive
good memory usage it doesn't slow down
so that's pretty cool
so how complicated was him was it was it
for him to actually implement that
functionality this is the entire code
for undo redo the preview as well as
exporting it as an animated gif these
are very simple functions it's about 60
lines of code this is a nightmare to do
in a mutable system if you've ever tried
that before it's not fun and how much
memory does it use so if you took an
array and you cloned it 100 times and
you because you wanted to preserve the
state of your app of your frames and you
updated one pixel it takes about 1.7
megabytes to do this if you do the same
thing with a persistent vector and you
snapshot at 100 times you randomly
updated a pixel each time it takes 2
tenths of a megabyte it's almost an
order of magnitude memory savings to use
persistent data
pictures for this okay so we're nearing
towards the end so I I use closure and I
use closure script but I also do a lot
of JavaScript but I understand that a
lot of people don't want to do closure
script Lisp is still too crazy for a lot
of people so I spent some time about two
years ago exporting all of closure
scripts data structures as well as the
entire standard library for interacting
with them in a library called Mori
if you want to experiment with like what
type of user interfaces can we build
given the availability of really fast
really expressive persistent data
structures I highly recommend checking
it out I've tried for the most part to
follow conventions that are exist in
lodash and an underscore or what have
you but it does a lot more I mean there
are a lot of data structures we have
sets hashmaps
sorted sets sorted maps the persistent
vectors I talked about and some other
things as well
and I actually there's a lot actually
there's a lot of cool possibilities here
around sweet Jas and Mori people have
done some experiments where by using
sweet Jas macros you can instead of
having arrays becoming arrays you can
create persistent vectors and if you
have a little object literal syntax
instead it will produce a a persistent
hash map so that's it hopefully that
didn't take too much time well thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>