<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Princiya Sequeira: Web based 3D Camera Simulator for Perceptual Computing - JSConf.Asia 2015 | Coder Coacher - Coaching Coders</title><meta content="Princiya Sequeira: Web based 3D Camera Simulator for Perceptual Computing - JSConf.Asia 2015 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Princiya Sequeira: Web based 3D Camera Simulator for Perceptual Computing - JSConf.Asia 2015</b></h2><h5 class="post__date">2015-12-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vgWonzhZIww" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so imagine this you grab your device
open an app do some doodles midair watch
your art appear on the screen is this
the future no it's right around the
corner and when you get to learn to
build something like this you will call
all of this amazing I am Prince iam and
I love JavaScript so
I am from Bangalore and I work for all
education startup called guru ji
learning labs I work on lodges building
back in solutions yeah I participated
the early morning today in this Jays
party I was not sure because it was
before my talk and I was already nervous
but yes thanks to y'all lovely audience
I think I just got lucky
ok so the way we interacted with
computers on a large scale was stuck in
place for roughly 20 years from mouse -
keyboard to joystick it is game over
today it is the era of gestures today's
gamers can do everything from slice and
dice and fruit ninja to quest for a
dragon and Skyrim from these early
successes in 3d gesture-based
input we now see high growth market
emerging across multiple industries so
this is what I am going to boil with for
the next 30 minutes so by the end of
this talk the such as computing
augmented reality virtual reality will
no more be alien to Yan any technology
enthusiasts can start getting their
hands dirty with these latest cool
technology you get to learn to build the
next generation of natural immersive
intuitive apps hands and finger tracking
facial recognition gesture analysis 3d
scanning the list goes on and on now let
me tell you the best thing you wouldn't
need a hardware that is a 3d camera or a
motion sensing device to test out the
SDK
Auto Bell a hello one sample I shall
tell you some secret to test the SDK
merely through JavaScript go and scold
3d objects explore outer space or gain
some magical powers okay so let's get
into the basics for the stock 3d camera
a type of camera with two or more lenses
with separate image sensors a film frame
for each lens 3d cameras give you the
visual ability to perceive the world and
the distance of an object in
three-dimensional perceptual computing
the ability for a computer to recognize
what is going around it
more specifically the computer can
perceive the environment and the users
in that environment
augmented reality direct or indirect
view of a physical real-world
environment whose elements are augmented
by computer-generated sensory inputs
such as sound video graphics etc here a
view of reality is modified by a
computer as a result the technology
functions by enhancing one's current
perception of reality
by contrast virtual reality replaces the
real world with a stimulated one
augmentation is conventionally in real
time and in semantic context with
environmental elements so we need to
know more about these motion sensing
input devices here are the few ones
which I have tested out for the SDKs
statutory warning here these are just
listed in alphabetical order I am NOT
representing any of these companies so
virtual computing augmented reality
virtual reality isn't new devices like
these intel's realsense leap motion
Microsoft Kinect has been around for a
while you can control these devices with
a wave a wink swipe and a smile with
these you can scan real life things like
a piece of art a child's toy all your
own face and create a digital 3d version
the technology behind these is around a
webcam style added as a peripheral
device it enables users to control and
interact with their computer without the
need for a game controller through a
natural user interface using gestures
and spoken commands these devices
feature an RGB camera depth sensor and
multi array microphone this technology
could vary across devices because leap
motion doesn't support wise or facial
recognition Kinect and real sense does
so let me tell you the motivation behind
this idea few months back I was
preparing for my talk on perceptual
computing and I was supposed to give a
demo on intel realsense JavaScript SDK
this SDK works only on Windows two days
before my talk windows in my laptop
crashed yes I did not have a backup of
this code and panic mode turned on this
is when I thought of this web simulator
by the way when I was preparing these
slides I used Google Docs
I didn't want any sort of laptop mushafs
hacking in a foreign country I also
thought that would be nice to conduct
workshops seminars for a larger audience
who would be intending to learn a new
technology but wouldn't be having the
required hardware C or real sense
motion or a Kinect that is well this web
simulator is very helpful when idea
clicked and started wondering how is it
that an external motion sensing device
interacts with the computer natural
question all these 3d cameras are
connected through a USB port and the 3d
camera SDKs access the 3d camera through
the USB port okay so far so good we have
one thing in common that is the USB port
now all these SDKs have one thing
another thing in common for that
applications that is JavaScript is the
primary language and in addition there
is another thing common which is used to
transmit the data from the camera to the
computer and this is done using
WebSockets so this is my secret these
SDKs create a WebSocket which is part of
the whole application and the secret
behind the simulator is creating nodejs
based WebSocket server which replaces
the default one used by the SDKs that's
it that's the secret so far the
simulator for my simulator I create a
noches WebSocket streaming server and
replace it with the default one which is
used by the SDKs so let's try to
understand what a WebSocket is the
explanation might seem too technical so
to put it simple data can be sent
between client and server the WebSocket
specification was developed as part of
the html5 initiative and this introduced
the WebSocket JavaScript interface here
is some code for a WebSocket
implementation to connect to an endpoint
just create
a new WebSocket instance the first line
they're providing the new object with
the URL that represents the endpoint to
which you wish to connect as shown here
one thing to notice here is that to
whoever is new to WebSockets
a WebSocket connection is established by
upgrading from the HTTP protocol to the
WebSockets protocol during the initial
handshake between the client and the
server which is why the URL begins with
the ws and not whether HTTP for secure
it would be WSS before connecting to an
endpoint and sending a message you can
associate a series of event listeners to
handle each face of the connection
lifecycle as shown here so we have a
bunch of event listeners like an open on
message on clothes on error as well we
can include that now to send a message
to the server from the client simply
called
send the last orbit the last code
snippet here and provide the content you
wish to deliver after sending the
message call close to terminate the
connection as you can see it really
couldn't be much easier just do this
WebSocket implementation and we can test
out the 3d camera SDKs so I am uploaded
the code here and I will share my slice
shortly
the last windows crashed with a teach me
this lesson and since then whenever I've
been working I make a backup but my
github reputation is quite bad I am sort
of a new one to the open this
contribution
yeah I have told myself that I need to
be active and do more sort of these
contributions so coming back to this
code I have worked
demos uploaded for real sense and leap
motion and I'll upload the code related
to connect shortly so to pick a few good
snippets which could be the starting
point for y'all to get started
couple of things here each SDK has its
own comfortable ways of receiving data
leap motion what it does is captures the
frames from the controller writes the
JSON data to a file and sends this JSON
output over WebSockets so the JSON data
is pretty big and it looks something
like this it's a huge one so Lee portion
what it does is captures the frames from
the controller the leap motion
controller writes this JSON data to a
file and sends this JSON output over
WebSockets so a leap motion expects a
pre-processed json input whereas
realsense on the other hand expects the
raw image frames over WebSockets the SDK
then processes this data and performs
facial gesture recognition algorithms
which are part of the SDK the difference
to be noted here is that leap motion
expects the WebSocket server to process
the raw data and generate meaningful
JSON output like this whereas realsense
takes only the raw data from web socket
and the SDK then processes this raw data
the complex facial gesture algorithms
are part of the SDK independent SDKs so
this is from realsense dot JS file after
you have downloaded the realsense sdk so
you can search for socket in the file
you can search for the keyword socket
and the file and you'll find something
like this so here we have socket URL
which is an array and it tries
connecting to these a bunch of for
WebSocket URLs this is how you make a
WebSocket server call as we already
discussed so instead of HTTP it would be
our WS and then you can associate any
port number the last few lines I am
showing you all the WebSocket methods
and the event handlers so this is
exactly what appears in the SDK on open
on message on error on closed special
thing to note here is binary type which
is set to array buffer this needs to be
done for WebSockets when you saw it sent
raw data because the real cells expects
the raw data over the web sockets which
is then processed by the SDK this is
what you'll get from leap dodges after
you have downloaded the leap motion SDK
pretty much similar to the previous one
expect except the data comes pre
processed that is in JSON format here
and no array buffer setting is needed
for WebSockets so as I told this is this
could be the main difference while
trying out the different SDKs the
realsense expects raw data which you why
you'll have to set the array buffer type
to binary and the leap motion uses the
JSON output pre-process to JSON output
so this is how you are right on OGS
WebSocket server now after no J's put
javascript firmly on the back end and
angularjs made us realized that client
business logic needs to be moved
entirely on the client-side
possibilities for JavaScript were
endless javascript phones robots and
whatnot here uh no J's based WebSocket
server has been implemented for this web
simulator the port number as you'll see
and the second line there is changeable
we need to replace this value with the
port number used by the SDK so the leaf
motion on default the port number was
six four three seven or six four three
six or intel's realsense it was the five
digit number the clients per a represent
us the SDKs
the connect to this web server this is a
client-server model so Aaron
this server is written in node.js and
the clients are one of the 3d camera SDK
so architecture looks something like
this
it's a client-server architecture
wherein the server is this noches
WebSocket server and the clients could
be the SDKs plus it needs to be one of
the browser which actually detects the
native camera now in html5 we can access
the native camera using getusermedia and
so once you turn on this sdk you so the
server will be listening it's a node.js
server and you open a HTML browser
wherein you have some code which will be
the client which has the getusermedia
which captures the user flames that is
which captures the frames from the
native camera and then transmits this
binary data for your sense or rough
processes it has a JSON and sends it to
the WebSocket server so since this is a
client-server architecture this camera
client sends data to the web socket and
this web socket in turn sends this data
to the client to the next client which
is our SDK that is it could be the real
sense or the SDK so that's all you
capture the input from the native camera
process it and give it to the SDK so
once these SDKs get the data it's now
quite easy to test these SDKs go through
the code or do some manipulations use
some gestures or use some keyboard
controls instead of gestures one thing
is this simulator right now doesn't
replace the holes or Hardware simulator
that is it's not able to identify depth
but if somebody gives you or what
exactly the depth information comes we
can just tweak these values and then
maybe lights we can build some other
applications say or just your controls
not your head or like wave and then
change ppts or do some cool animations
on the sly
and so on that is exactly what sleep
motion or the real sense does so now
we're coming back to my code I need to
assemble all the code and make this as a
universal simulator right now it's three
different versions sitting for like real
sense if motion or Microsoft Kinect so
lastly you can go and Skutt some 3d
objects explore outer space and gain
some magical powers okay
I still have some time and if you all
have any questions y'all can ask me I
would be happy to answer here or I could
take it offline give you show you the
demo what I have you could also tweet me
at Lindsey and ask or yeah I would thank
Jess can't Asia for giving me this
wonderful opportunity to come here and
present here I hope I didn't bore y'all
I was not sure what to be shown on the
slides or how much of the demo needs to
be shown so just to prevent any shots of
mushafs I don't have working demo but
yes I have a working demo but I've not
included part of the presentation
because the gestures of svehla getting
to Ori when it came to the light but yes
I have some cool just obeys the demos or
like swiping based demos y'all can come
and check it out I'll be present here
today tomorrow
please come and feel free to bother me I
would love to and yeah any questions
Thank You Prince Ian thank you so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>