<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sam Richard: Domo Arigato Mr. Roboto | JSConf EU 2015 | Coder Coacher - Coaching Coders</title><meta content="Sam Richard: Domo Arigato Mr. Roboto | JSConf EU 2015 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Sam Richard: Domo Arigato Mr. Roboto | JSConf EU 2015</b></h2><h5 class="post__date">2015-10-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pKtG4dO-9Tw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Good morning everyone, so I am talking today
about cognitive computing, the name of my
talk is Domo Arigato, Mr Roboto, I do not
speak Japanese, I copied that straight from
Wikipedia, I'll talk about cognitive computing,
my slides are 
available online, ‘snugug’ is the bit
that's important, that's where I'm on the
internet, Github, Twitter, you can find me
there.
So let's talk about the world of cognitive
computing, shall we.
This is Pepper. Pepper is a robot, built by
Soft Bank a Japanese company, pepper is designed
to be one of the worlds first human computer
interactive Android type things. It's using
the power of cognitive computing to make this
interaction between humans and computers a
little bit easier something not like the programming
we do everyday.
If we talk about cognitive computing we should
probably define what cognitive computing is.
So cognitive computing is a new field of computing,
the types of problem that cognitive computing
can solve are unlike any problems we have
been able to try and work on before. It's
for working with human complex problems, so
the type of problems that were normally used
to be solving in computer science are not
really human complex problems, being problems
that really require a human to solve, usually
things that can be solved with just maths
or just data analysis, but cognitive computing
aims to be able to solve problems that otherwise
we wouldn't be able to do. It does this by
using machine learning and artificial intelligence.
So not a single path towards a cynical solution,
but rather, single solution, but rather a
problem is tick solution to problems. It's
a very different way to thinking about computing
than we are normally used to it. It works
with human natural input and output, so think
instead of putting in numbers and getting
numbers back or putting in key word searches,
think rather putting in long form text, like
whole webpages and being able to answer questions
on whole webpages without converting it into
anything, or speaking into them computing
and getting things back, or having the computer
understand audio, video or images and being
able to output audio, video ipages, other
forms of long form text. This is the type
of problem solving and the type of solutions
we can do with cognitive computing it's why
it's the new type of computing and problem
solving, I think it's really cool and lends
itself to new types of applications.
Yah, what does that mean, I bet you have all
used a cognitive application, if not today,
recently. Who here has used Google Now, or
Siri, they are all cognitive applications,
they are called the personal assistant, it's
one of the patterns that we find at Watson
that people use all the time. Let's breakdown
what that personal assistant cognitive application
is. It's speech in, speech gets transformed
into text. That text is then run through usually
what we call a natural language classifier
to figure out what the subject of the
sentence is or the subject of the text is
pool out the individual pieces, then runs
the business logic underneath it to figure
out if you are talking about the weather and
you have your location, what is go and find
the weather application, then runs a Speech-to-Text
to transform that into synthesized speech
and tells you what it is, or if you are doing
a Google search or web search it will go and
find what that is and possibly pull back here
are the results for you, or look in alpha
and pull out the individual pieces, these
are all different types of speech input and
then business logic and output. So not everything
inside of a cognitive application needs to
be cognitive or fit the cognitive paradigm
the application as a whole becomes cognitive
when we provide it, when we use these types
of cognitive input and output to work with
it.
That's what I want - yeah. So... let's talk
about, let's see what some of these examples
are. Let's play a little bit. I like pepper
dancing, pepper is fun. So, the first application
that we're going to talk about is this little
thing that I built, a little tiny Chrome extension,
using Watson's text analysis tool. What it
does, it's a Chrome extension for Github,
whereas you are typing it analyses the speech
that you, the actual long form text you are
writing in the comment box if it finds the
text is negative, if the content of your text
is negative, it switches the comment submit
button from green to red, if it becomes angry
it disables the comment button, right! That's
pretty fun! {Applause}.
So it's also about this, one of the reasons
why I'm talking to you about this, even though
you might be able, you might not think well
this is probably really super expensive and
probably something that I get access to because
I'm Watson, this is built with a single publicly
available API that you can go and use right
now. Watson isn't the only group doing this,
we happen to have a whole lot of cognitive
APIs that you can use right now by searching
the Watson developer cloud, this is one called
tone analyser, what winds up happening here,
as you type on key up, the Chrome extension
sends all of your text off to a little tiny
server I made, that runs through tone analyser,
comes back and tone analyser splits your text
into one of three different tones, happy,
negative or angry. If negative is one or above,
I tell you that you probably shouldn't send
that and if angry is one or above I disable
it. Usually you are angry and negative, but
you can be negative without being angry, that's
why it's kind of that three layer thing.
So this is the first type of cognitive application
you can build. The second one gets a little
bit more complex. So, this is something I
wrote called 'Babel Fish', those of you that
don't know, it's the weirdest thing in the
universe, you put it in your ear and it translates
all speech into other speech, it's from hitchhikers
guide to the galaxy, Watson as three, Speech-to-Text,
language translation API and text to speech
API, when it's combined you can create a Babel
fish, I will use media to get text input,
it will run through the Speech-to-Text algorithm,
it is then going to translate that text using
text or language translation, then going to
spit it out in that native language. Unfortunate
German isn't supported, but French is. What
I'm going to do is say English and go to go
to French, I'm going to do it not on my speaker
notes... hello JSConf. Live demos are always
fun! {Laughter} {French} close...! {Laughter}.
{Applause}. I guess JSConf isn't something
that Speech-to-Text understands, so let's
try something else. 'The breakfast this morning
was fantastic'... {French} that's a little
bit better I think.
What do the APIs look like under the hood,
is the way that - what you get back from Speech-to-Text
is you get a confidence meter. This is where
cognitive applications sort of differ from
normal APIs that you may wind up working with.
Speech-to-Text is a little bit iffy it's working
of probability, not confidence, you get the
translated text but you also get a confidence
meter from 0 - 1, 0 to 100% basically. That
is going to tell you how confident it is in
your results. The first one not so confident,
this is pretty confident, this is more or
less spot on. Then language translation does
a one-to-one translation. Translation happened
between different domains, you could have
- right now there is a news domain and a medical
and a travel domain, but one of the great
things about this is because cognitive computing
is based off of artificial intelligence and
machine learning, you can learn, you can train
it, you can have it understand your specific
domain, if you wanted to create, let's say
a food application, you could train these
APIs, you can train cognitive systems to understand
the domain of food. So you don't have to know,
necessarily, what a croissant is in English
or French, you don't have to know what the
words are, but you are able to translate them
by training the applications with APIs I'm
using a standard news domain. Text to speech
synth sizes text in one of a variety of different
languages, that just takes what ever text
and goes straight off, so it's cognitive input,
human natural input, with language translation
which is trainable to understand the different
domains you are working in, then text to speech,
a human understandable output, it makes a
new way of working and interacting with your
user, there are only really three APIs being
used here. The final bit that we have is a
little bit more fun, it's cognitive computing.
So, the first example that we showed is something
that you can build today with a single API,
it's a simple example of what cognitive computing
can be, one API, one natural language text
input, goes off to server, comes back, you
do stuff. The second one a little bit more
complex, three APIs being used, one turns
speech into text, then it does stuff in the
back ground and gives you speech out. Be able
to hold full conversations with other people
that you otherwise couldn't. That's also available
as three public APIs, this a little bit future
state, it's available now, just not as APIs,
Watson is built on what we call Watson Discovery
Advisor, it's a system for understanding connections
and being able to find connections between
things you wouldn't otherwise be able to see,
in this case food. So what we have done here,
we have ingested all of the recipes that bon
appetite magazine has written. We have ingested
all of thinkers, like artificial intelligence,
machine learning and deep learning, kind of
do its thing on them, what you get out of
this, you get food pairings or recipes you
wouldn't otherwise know or be able to see.
So one example of this, when we talk about
food and we talk about cooking, normally the
food and the recipes that we have, those ingredients
go together {sirens outside}, I guess the
police don't like me talking about food! {Laughter}
So food and recipes they generally go together
and the ingredients in recipes generally go
together because they grow together. They
come from the same region of the world
but things like apples and olives don't grow
in the same place but it turns out that when
you look at the types of recipes they are
used in and their chemical compounds and how
other things relate to those 2 ingredients,
apples and olives turn out to pair really
well together, even though it's something
you would never think to pair together because
they don't grow together. What cognitive computing
and what Chef Watson is able to do is able
to find these underlying connections.
It also have applications in other things,
think law enforcement, we have this demo where
we ingested all of Wikipedia, and you ask
it questions about Wikipedia like what are
the planets in the solar system it's able
to actual what all the planets are with all
the evidence and all the confidence. You can
actually trace back all the evidence and all
the different pieces that connect together
this is how cognitive computing is a bit different
than normal key word search you can actually
see the full evidence tree of how got somewhere.
Let's build a recipe.
Chef Watson, starts with ingredients. Someone
yell out an ingredient.
Bacon!
Bacon. It starts to think, we know it has
bacon, it makes some suggestions for us of
other types of ingredients that are known
to pair well with bacon, smoked turkey, some
navy beans.
Soy sauce.
Dark soy sauce, dark soy sauce. Undefined
dumplings. Yes! {applause} {laughter} I 
think chef has decided to pair Bacon with
more Bacon. {laughter} {applause} anyway,
so cognitive computing and specifically chef
Watson it goes beyond just ingredients we
can talk about dishes and styles as well.
So let's choose a dish. Let us do a bacon
and soy sauce bloody Mary. How about a Caesar
salad? Get rid of the bloody Mary. Maybe it
won't do a dish or a style, back to school.
{laughter} there we go, so back to school
bacon dumplings. {laughter} if we load this
up, we wind up seeing is we wind up getting
a brand new recipe that has never existed
before. So chef Watson didn't go do a search
on the internet to find back to school bacon
dumplings, what it's done it's used the that
training of all the recipes and used the training
of all the different ingredients and the chemical
compounds of all the ingredients to build
a new recipe for you a new human output recipe
for you based on other thing that, but this
has never existed before. This is kind of,
to me the power of cognitive computing it's
being able to not replace humans, but empower
humans to find connections and be able to
interact with computers in ways that they
would never have been able to interact with
before. In ways you wouldn't have been able
to see or use before.
The best part about this for me anyway, I
am a little bit biased because I work for
Watson but all of these APIs that we have
are for free, Chef Watson you can go play
with right now, and we're not the only company
doing it. Which is awesome. Artificial intelligence,
deep learning the foundation of cognitive
computing has got too point where it's coming
out of research for the first time ever the
APIs the ability to dive deep into our data
beyond what we think of as deep data, beyond
deep understandable content is something that
is available for everyone to start using and
everyone to go play with now. Which to me,
means a big win for the future of applications
and the future of our work and I have I would
have been better had it worked the first time,
yes. To me that means it's a big win for us,
it means it's a big win for users, like we
said I am part of the design team I am an
engineer, a UI architect on the design team
at Watson. To me what this provides is away
for us to design the next generation of applications.
Screw your JavaScript frameworks, use whatever
one you want. To me that's not what matters
I appreciate I am a JavaScript conference
I just gave an entire talk not talking about
JavaScript, but this is what is important.
Our users are important, cognitive computing
and cognitive applications will provide us
with the means of producing the next great
user experience, not react not angular, not
ES6, they are tools to build them but cognitive
computing is what will let us actually create
them thank you. {applause} Ok can I have the
slides back again? Those are the links, the
link to slide deck, links to all of the source
code for the first 2 applications are available
online, I am snugug that's my website, that's
Twitter, that's the slide deck again. All
the links to everything are available online
including all the source code for all the
applications. Thank you. {applause}</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>