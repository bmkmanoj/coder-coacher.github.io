<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[JSConfUS 2013] Luis Montes: Post Modern Game Input Devices | Coder Coacher - Coaching Coders</title><meta content="[JSConfUS 2013] Luis Montes: Post Modern Game Input Devices - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>[JSConfUS 2013] Luis Montes: Post Modern Game Input Devices</b></h2><h5 class="post__date">2013-09-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bN71Voq5x1U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I just wanna kind of start off here
with how we take keyboard input so this
example is actually from our game engine
but it the same concept applies when we
do something like hit a left arrow key
for holding it down we know that in our
iteration of the game loop if there's
something pressed like a left arrow
we're going to like move a character or
we're going to do something because we
know the state so outside of the game
loop we have events happening events
firing such as key presses so we're
going to save that state or if there's
multiple key presses all of that sort of
thing we want abstract so keyboards
pretty simple and I'm just going to move
on from keyboard mouse is as simple as
well but it's a little more involved now
that we have touch devices right
everyone has a least a phone with a
touch device with a touch screen on it
and when you have touched devices you
could have multiple inputs right you
could have multiple points so the
easiest thing to do is that if a game
you're you have a game that supports a
mouse and you're moving things around on
the screen you could just grab the first
point and again we sort of abstract that
in our game engine we take the position
in the mouse if it's a it's a touch
device will just take the first one and
like I said emulate that to mouth so you
only have to worry about mouse and
that's fine um however there's a lot
more things you can do than just moving
a single finger on screen so we want to
handle that so one of the things that we
did with the game engine was we
incorporated at a library recently
called hammer j/s which is really cool
because it it does a lot of the stuff
that we didn't want to do there's a lot
of math involved in things like pinch
zoom and swiping and and all these
gestures but again these gestures don't
happen the same timing is our game loop
so we want to do is is listen for a
gesture such as swipe and then put that
somewhere that our game loop is going to
pick up and maybe deal with and and
throw away or whatever but that way we
can abstract that it's just a it's an
ambi module or pull it in we we build it
into the game and we're good so it's the
real real quick demo on how that works
when we have here's a bunch of isometric
zombies if we're moving a mouse around
we're told in something on-screen you
know every iteration we can go towards a
point no but if we want to do a gesture
such as a swipe we want to do that once
and throw the event way and so this is
all this is doing its just swiping and
throwing the zombies around the screen
okay so cool gestures okay well that's
why so we got gestures we got masks we
got keyboard that stuff's all cool but
gamepads right we want to play with the
play game with it with a joystick or a
gamepad and this is still prefixed but
we can get from the navigator a list of
game pads now these actually work really
well with in a game loop because we're
not we're not sending event data from
from the controller we're just modifying
well the API is just modifying the state
of the controller so when it's plugged
in and we grab the first one off of that
off that stack refers a player one from
all the buttons and things that will
look when I did show you they'll will
just check the state so I stole this one
directly off of HQ and off of html5
rocks there's just a generic controller
and first demo fail
first it will fail this works really
well usually until you go in front of
everybody and tried to do it Oh wrong
sorry okay imagine that there was a
picture of a controller here on the
screen this isn't really all that big of
a deal but all we're doing is we're
checking each button state from a one or
a zero if it's an analog joystick and
we'll get a 0 to 0 1 a floating point or
to negative 1 depending on the axis so
so that's fine that all that that
stuff's all cool but I i call this
postmodern game input devices because
all that stuff is sort of the current
state right i mean the gamepad api is
new but that's what we're used to
playing games with as those sorts of
things so the first one I want to do
there's been a few of these demos come
out lately is using a phone as a gamepad
right go to iTunes or Google Play grab a
nap but there is an app for that and
it's just called a browser like don't go
and install anything so let's see here I
gotta time this just right or or you
guys can really screw me up because I'm
showing a QR code ok also there's a
bitly link if you guys really want to
mess with me while I'm doing a demo so
sort of what if you guys were in Remy's
talk earlier he was taking orientation
events from a device i'm in this case
this is pretty simple box2d stuff and
all i'm doing is applying torque to the
wheels based on the orientation that i'm
headed in also it's really easy to get
the thing stuck so why not just omit
event like a button to flip the vehicle
over now the the reason I had a QR code
and a bitly link was so that i can make
sure to join the same web socket the
page goes to a web socket just grab some
random ID the phone has to go to that
same go to that same web socket so that
we got controls so ok cool we've got
we've got web sockets phone controller
so we're going to need a gamepad we just
use our phone okay thank you but you
have to use your hands that's like a
baby's toy right we don't want to use
their hands for this what I want to do
we want to maybe use the camera to track
our face now I'm not going to deal with
this one this was actually pretty cool
this is of course if you're a unicorn
you're going to catch doughnuts so a
company called be real software they did
a google hangout app where it's tracking
your head and you catch doughnuts in a
hangout so this isn't a w3c spec it's
just an API I don't know the magic
behind it actually but it's pretty
straightforward when you're creating a
google hangout a google hangout
extension we've got events that we can
have gun to the track event that that
gets passed into this event here that
the track event object has all the
things that you'd expect like your noses
XY your eyes some of that type of
information so that you can do all kinds
of crazy stuff in the Hangout so face
tracking would be cool if that was just
a speck and we could just use it for
other things but kind of anything to
play around if you're into doing hangout
apps ok we want to talk to a browser by
talking to a browser right like why why
wouldn't we just do voice rec why
couldn't we just tell the game what we
want to do so we have something for that
and this is actually expect the web
speech API of course prefix right now
all we have to do is create one of these
web speech recognition objects and we
can do some events on that now this demo
is very dependent on how well the
internet connection is working here so
let's see if I can do another demo fail
here
aah aah sorry aah I allowed it on the
last machine oh by the way just like
with it web RTC web speech you have to
run it on HTTPS or you're going to get
that allow every time and this is a
little bit worse because look it's
taking my voice here why don't I do the
demo first and then okay up right up ah
there we go okay so it worked sort of
left left well this isn't perfect right
it's a neat concept we can talk to the
things we have a few issues one of them
being that like it has more on an HBS if
it doesn't we have to allow it every
time we have to allow every time we want
to take speech input also this is very
network dependent because it's really
just sending waveforms back up to Google
servers where they're translating and
sending events back and there's a little
bit of bugs and some of the way the
events work but theoretically we should
be able to do voice rec using a standard
API to move things around on a screen
and okay so so cool we have web speech
okay now these are we're going to fun
and probably more reliable 3d tracking
so everybody see that new xbox one thing
they're like it's not a don't think it's
a peripheral I think it's part of it now
Microsoft has kinect which takes 3d data
in um there's also leap motion which is
right here now i really like late motion
leap motion school first of all it's
just this cool little little device here
but what leap motion is doing right and
if there's any hardware manufacturers in
the room or anybody working on a cool
project their driver is a is a WebSocket
so well their drivers a bunch of code
but they give you a WebSocket when you
install their driver and
and mad when it's running okay let's see
if this is right okay the the localhost
should have should have a web socket
emitting data from this thing so this
actually takes in a bunch of a bunch of
image data and the web socket is going
to give us back just the things we're
interested so what you let's see here
let's look at the first one so okay cool
so it's working all I'm doing here is
taking x y and z data in the form of
point ables so the what the local web
socket gives us as soon as we connect to
it it starts streaming of all this
position information it also gives us
some things like like the palm and the
javascript library that it there's a
javascript library on github that leap
Motion's putting out gives us a bunch of
other things some other event we could
smack down on I think it's a little bit
more difficult to do like a wave thing
because we have all the fingers stacked
up it's looking at in this way but butt
smacking down on it works a bunch of
other of other gestures I'm encapsulate
look stuff pretty well for you so we
just have to make a connection to the
late controller and then every frame
that the thing gives us in this case I'm
putting it on the on the game so we're
keeping the state of those pointa bowls
now this is also important when we
consider our game loop is going to end
60 times a second this thing is capable
of emitting data I think 120 frames a
second so we don't need all of those
positions and I'm pretty sure we can
control how much data is coming off the
thing but what's important is that we
just want to save the state I didn't
given point when we render so the demo
moving my hands around on it I'm just
saving the state of each point of all
four fingers in that case and just
drawing them in my draw loop in my game
okay what would be slightly more useful
is actually in a game if we if we were
to do something out this game in
particular it's a pretty simple game
everybody's played breakouts and what's
cool about this particular breakouts is
anybody you to do NBC
to NBC is like a well I can't talk and
do this at the same time up to do it
yeah I'm going to fail to do NBC is
really cool because it's a list of a
bunch of different NBC implementation so
you can figure out which NBC or envy
star or envy whatever API that you want
to use that things still going just die
okay good breakouts is like the to NBC
of html5 games so check that out Matt
grierson a great job putting that
together our open source engine is one
of the ones on there so if you if you
want to get into and just kind of see
which game engines for you go check that
out okay so let's see here I'm running a
little head so cool that's cool right
but we all want to wear the things and
you guys probably know where this is
headed next right we want to wear our
computers won't have them right there in
our eyes so what are we going to use
project glass actually this thing is I
know it's goofy but this is really cool
some of the stuff that's happening in
here okay not only like everything to me
is the heads up display right awesome
having a heads-up display um there's a
bunch of really cool sensors in here
there's a wink sensor you know there's a
touchpad on here so there's all kinds of
stuff on here that I want to use and I
want to you know do game stuff with and
the default way of doing interaction
with this guy is using what's called the
mirror API now your glass talks to
Google servers makes rest calls out to
some other service there's some o op
involved you can get a twitter
notification all that stuff is cool but
it doesn't really help me to move
characters around the screen so much or
to get characters from here or do
multiplayer up here or any of that so I
want to do more real-time applications
so i put together something called face
which is basically websockets using a
java library one of the things that I
like about what Chris and others are
doing with no
durand with fermata is that I don't
really want right and CEO and writing
JavaScript and if you have this firmware
on an Arduino you could connect a serial
port and you could use stuff without
Arduino and JavaScript well similarly I
don't know how many of you want to write
in Android and in Java but I'm trying to
do some of that for you by just exposing
a bunch of this stuff that's in glass to
a web socket so I go to this application
there's a little launcher well one other
thing there's a USB port on here and put
in debug mode so you could side load
android for or four things there's a
couple of web socket implementations in
Java pull those in put up a heads-up
display so we can kind of see what we're
doing and go to this application I could
send messages to it ap R stands for
azimuth which is orientation this way
pitch is this way and roll and of course
error message is a couple of buttons to
do some navigation with and that channel
ID you can imagine that channel ID is
what I a WebSocket I want to connect to
or I'm going to connect to a web socket
I must say go to this channel and I'm
putting in my eye so when I do this down
what you guys can go to that one and
screw me up because I could see what the
channel isn't here I didn't want to for
the type of allocations I want to build
I didn't want to go to a third-party
server I just wanted to go to some node
server so glass here is running this
face application talking to know doing
web sockets off to some other client or
multiple clients or whatever you want to
do and since I have that running I can
see what the channel ID is in here let's
see here umm this is a really cool 3j s
demo that I just took off the 3gs site
but I wanted to do a little bit of
integration with data
from the glass so what's up um so that
you guys don't put in the channel and
screw up my demo alright so we've got
some orientation events right do we have
orientation events yes we have
orientation events okay um but like I
said I like putting these things
together right i like i like that we
have WebGL and we have web sockets and
we got one of these so why not put them
together peacock right okay so why not
take the events on to take our
orientation events do a little bit of
WebSocket integration here and and
expect that bluetooth is going to
transmit stuff back to the anyway so get
the concept connect all the things
WebSocket wow that's weird
anyways I'm guessing there we go all
right cool all right okay no for that
all right I am actually that's really
about all I got um I just want everybody
to connect all the things right connect
all the things web sockets are your glue
right all these devices we plug them in
we talked to node we bounce stuff around
we do stupid disco demos with WebGL and
3gs and that's in any questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>