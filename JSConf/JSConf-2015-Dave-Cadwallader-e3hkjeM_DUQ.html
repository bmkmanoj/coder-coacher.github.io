<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>JSConf 2015   Dave Cadwallader | Coder Coacher - Coaching Coders</title><meta content="JSConf 2015   Dave Cadwallader - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>JSConf 2015   Dave Cadwallader</b></h2><h5 class="post__date">2015-09-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/e3hkjeM_DUQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so we're gonna learn how to draw a horse
it's real easy okay check this out for
five steps step one draw two circles
step to draw the legs it's really coming
together now here see check draw the
face draw the hair add some small
details and you got a beautiful horse so
something's a little bit missing here
between step 4 and 5 and a lot of
technology is like this when it comes to
read me files or instructions or
technical blogs that kind of paint this
really rosy picture about how easy
something is especially you know
integrating this technology with this
technology I'm going to give you the
step-by-step guide I call things like
this the the troll read me when they
when they leave out the really nasty
nitty-gritty details of stuff that
you're going to get stuck on it give you
some little getting started guide like
this you know just NPM install this and
then super easy and that's it and and
then you're like right out of the gate
you just like get smacked down and you
run into some problem and you go google
it you go google the error you find out
there's like thousands of other people
who have had this problem and there's
you know 500 different possible
solutions for the problem and so your
next step is like great I'm already
going off on this forked paths like
which which road do i choose and it's
really frustrating and so I work for
Walmart labs and we kept running into
stuff like this with regards to our
end-to-end testing strategy when it when
it came to automation and it it really
sucked so I wanted to share some of our
experiences there so that's me and my
boy up there and me not him work for
Walmart labs and when we create common
infrastructure on my team where the core
web team we create building automation
tools that other teams use to build out
everything about ww1
marcom that that everybody uses so we we
we try to support them with with common
tools and infrastructure especially with
regards to automation to make it so they
can spend more time doing fun stuff in
less time doing tedious stuff so we
follow the test pyramid which you may
have seen before it prescribes that you
have a whole lot of unit tests and that
you rely on unit tests as your bread and
butter for for for quality control unit
tests are fast they're reliable they're
predictable they hopefully our are
pretty consistent when they pass and
fail and very easy to run on a dev
machine see I machine service tests
we're not really going to talk about
today but just testing an HTTP endpoint
on a server to make sure that it's it's
giving you the response you expect and
then at the tip of the pyramid just like
the sweets on your food pyramid in
moderation but still have them there are
the are the UI tests or the end-to-end
tests and these are generally at the tip
of the pyramid because they're generally
thought to be slower they're more hard
to maintain their brittle but for a good
testing strategy especially with with a
site as complex as something like
Walmart it's really necessary because
when you have a bunch of unit tests that
are written by separate teams there's no
matter how good you are there's always
going to be gaps between this test in
this test especially if it's going
across two different functional areas
there's always going to be missed
assumptions between between teams
between developers between different
parts of your stack and end-to-end tests
are a good way of just making sure that
none of those gaps wind up being a
showstopper so n 10 tests should also be
cross-browser so everybody should
understand what browsers they have to
support and which ones they don't have
to support because there's a lot of
browsers that we're really hoping are
going to die off IE 8 and friends as
soon as possible but there's still a
depressingly large number of customers
using these old browsers and we know
that if we stop supporting them we would
lose X number of dollars so it's a huge
pain to test them all it's a huge waste
of human time to run through the same
scenarios over and over
on all these different browsers and
because it's a pain to test it means you
all know what I'm talking about like did
you test it on ie oh yeah I did last
last month maybe and QA people you know
are the same way right there they're not
they're not physically going to have
enough time in the day to run all their
test cases continuously in all the
browsers we have to support so things
are going to slip there's going to be
times when maybe it's a week or two
weeks since anybody actually fired up
ie8 and ran through all of the scenarios
to make sure everything still works and
because of that if somebody finds a bug
in ie8 the first question we often ask
is well when was the last time it worked
in ie8 well I don't know I tested it I
think three weeks ago perfect let's look
at all the commits in the last three
weeks and figure out which one caused a
regression in a legacy browser that
sucks nobody likes doing that but what
can we do about it right so automation
everybody says that's it I'm going to
sit down I'm going to figure out how to
automate all this stuff so I don't have
to do it by hand anymore awesome how
many people have said have said that
before that's it okay yeah see you know
what I'm talking about so pretty much
every cross browser end-to-end testing
solution relies on selenium at its core
so this is a great tool open source it
has drivers for every major browser that
give you deep hooks into the browser to
control it with with puppet strings to
tell it you know to behave and do any
kind of user interaction that a user
would do click this fill in this form
navigate here it has an API that's over
HTTP HTTP it's not the most friendly API
to work with so there's always a lot of
rappers on top of selenium that people
use and and there's a lot of companion
tools that go along with it a lot of
services like sauce labs this is a
diagram of sauce labs which we use to
outsource the tedious task of
maintaining a farm of different browsers
there's browser stack there's there's a
whole bunch of other ones but there's a
whole ecosystem around this because
people really
this kind of stuff to work but when you
start putting all these pieces together
companion libraries for selenium
external services to manage your
browsers as a service it starts to look
like this it's a big rube goldberg
machine there's so many points of
failure that it's hard to keep track of
them all and guaranteed anybody who
starts down this path sooner or later is
going to run into test flake so when we
talk about test flake we're not talking
about the tests that developers
themselves are writing being flaky we're
not talking about bad application code
we're talking about something in the
system in this big complicated system
failing for really no good reason at all
creating false positive results sending
developers on a wild-goose chase when
something fails only to realize five
minutes later this thing that I've been
chasing is now passing unexplained you
know for no good reason and I just
wasted all that time so see also waste
everyone's time with this one weird
trick developers ate this so anybody
who's tried to implement an antenna
testing solution has probably had the
best of intentions but has wound up
frustrating a whole lot of people if
they try to get them to use it just a
quick plug for a really awesome podcast
if anybody hasn't checked out Rebecca
Murphy's TTM podcasts definitely check
it out it's all about front-end ops and
this emerging discipline I was on I
think episode 4 talking about some of
the same stuff in more detail but the
the really cool thing to hear was was
everybody else on the interviews before
me she asked them if they if they were
doing end-to-end testing and they said
we really want to but it's just not
really worth the time because it's just
so flaky it's so frustrating so you know
this this this was really actually good
to hear because it lends a lot of
credibility to this fight that we're
trying to fight even on Google's own
google testing blog there was this great
article called just say no to more
end-to-end tests like I thought this was
click bait because it was such a you
know like bold title here but like
they made some really really good points
but my favorite line here was that they
it compared end-to-end testing to going
to a movie with your friends that you
all wanted to see and then you all
regretted watching afterwards like a
good idea that just failed in practice
but they talked about a lot of good
points in here they talk about n timed
tests being slow unreliable flaky and
that they don't isolate failures so at
the end of the day while they have the
best intentions they end up just wasting
more time than they save so we said all
right we're going that we're going to
roll up our sleeves and we're going to
really fix this right we have what we
have a team of people we asked for some
time to like focus on this for a few
months so we got this right so we
decided we're going to create an
end-to-end testing solution that's going
to work for dev and QA alike so so
non-technical people should be able to
write tests there shouldn't be a high
barrier to entry should be fast enough
to run as part of our CI system and no
flake absolutely not acceptable we want
to win the hearts and minds of
developers and QA and we're going to
have no tolerance for false positives so
for the first goal of of having tests
that are simple enough to write for for
QA as well we picked a companion library
a nodejs based adapter called Night
Watch it's one of the more popular ones
there's a lot of them that are really
good that talked to selenium through a
node API to make the the API a little
bit more palatable to work with a Night
Watch is awesome and we made some really
great progress with it right off the bat
we were taming these browsers we got a
sauce labs subscription we had a huge
collaborative test writing effort
between developers and QA and we were
rocking we were getting just every green
checkmark we saw we were thinking of
we're saving this many hours of manual
time and and QA is loving us and
developers are going to love us because
we're going to catch these regressions
sooner rather than later so we started
running these tests just you know
hundreds of them every hour and all the
time and increasing our browser matrix
more and more going back you know
testing IE 8 9 10 11 Firefox last couple
versions chrome
are a mobile emulators everything was
golden and every now and then we'd see
something like this would be like Oh a
test failure great our tool caught
something in the wild let's go let's go
fix it and then five minutes later Oh
past that time okay well just a little
glitch nothing to worry about and then
like 10 minutes later oh that one failed
okay nothing to worry about you know
we'll just kind of like sweep that under
the oh okay and then oh no why is it
passing now and so we we got really
really quickly like the old 8020 rule
right like we got really close to this
eighty percent mark of being super happy
and then we were just like ah like we
were so close to feeling like this was a
complete solution and in the end we have
the same problems with flakiness as
everybody else despite trying to design
with overcoming these very specific
flaky things from the beginning we still
got burned by this so let's look we
thought okay we need to change our
mindset here we've been we've been we
need we have this realization like whoa
we okay we've been trying to think of
end-to-end tests like unit tests like a
predictable environment that we can
control but but in reality they're
they're nothing like that at all so we
came up with this little metaphor of
soup a can of soup is like a test result
when you're hungry okay i'm hungry i
want to have some soup for lunch i want
to be able to test my code i want to run
this test and I want to get a test
result back a binary pass/fail which is
which is like reaching and getting a can
of soup so stick with me here with a
unit tests it's like going and grabbing
a can of soup from your own kitchen
cupboard you're controlling the safety
of your own house it's very safe it's
quick and easy it's right there you just
have to reach right there and grab it
and so that's why everybody loves unit
tests they're predictable they're easy
end to end tests are different so n 10
tests you want your can of soup first
you have to get in your car next you
have to drive through a zombie
apocalypse
on the way to the grocery store who
knows what's going to happen when you
get to the grocery store a store might
be overrun by zombies and once you
actually grab your can of soup you might
have to like fight to the death on your
on your way out to try to get home so in
this metaphor the the lurking zombies
are all of these things that we have
encountered as being sources of test
flake there's bugs in the web drivers
themselves this this goes back to that
troll read me thing it's like none of
the none of the read Mees for these
things talk about all of these common
sources of flake that like everybody
quickly discovers the web drivers
themselves have bugs ie driver it's like
five percent of the time when you tell
selenium to click on a button it says
that it did it but it didn't really
click it oh well flaky network so like I
said everything runs over HTTP when
you're set when you're doing hundreds
and thousands of tests per day and you
have these really chatty selenium
clients talking to these remote servers
across different networks and data
centers inevitably you're going to have
some some packet loss here and there and
just one little drop to packet here and
there can just make a test blow up or
timeout and there's nothing you can do
about it and then sometimes the services
themselves might have bugs or outages or
you know a vm just fails to spin up and
a test fails and we we tried to you know
treat these things like a whack-a-mole
problem where we just deal with each one
at a time but even months into this
project we were still hitting new
problems that we had never seen before
and we you know some of these problems
were super obscure we would google them
and we'd find you know one person with a
post you know from 2006 with the same
problem and then no response were like
like that XKCD comic what did you see
but we really quickly realized this is a
losing battle so there's going to be new
problems every day we can't possibly fix
them all but what do we do did we just
give up we had this this moment where
you said what if what if we could just
make all of these flaky tests not flaky
anymore without actually fixing the
dividual problems this was a very like
Morpheus moment here how can we make the
tests not flaky without actually fixing
anything so we had to go back and think
about some more geeky stuff here so from
the point of view of the consumers of
our tool the developers who are going to
be running these tests and the QA people
who are going to be writing these tests
the notion of a pass/fail or a can of
soup in this metaphor is an axiom in in
a mathematical proof it's a premise or a
starting point of reasoning a premise so
evident as to be accepted as true
without controversy if we broke that
axiom we've lost everybody if nobody
trusts our tool to be accurate they're
not going to use it they're not going to
pay attention to it when it breaks and
so we had to make it so that this axiom
was true no matter what and making it
true was actually more important than
how we made it true this is where things
get a little bit scary we did some dirty
stuff really dirty stuff duct tape and
rubber bands like don't look under the
covers stuff to make some of these tests
pass we figured out okay if an assertion
fails the first time let's just try it
again and see if it passes the second
time and if it fails that time let's try
it again like a few hundred milliseconds
later and see if it passes that time we
found out like hey that seems like a
really ugly hack but that makes tests
past fifty percent more at the time than
it used to then we had these like IE
driver bugs like oh that click thing
that said it clicked but didn't work
what if instead of using the buggy
selenium driver for click events what if
we actually inject jQuery into the page
if it's not already there and actually
do a jQuery click event and that
smoothed over like another twenty five
percent of the tests so we're kind of
like addicted to this to this like new
sort of like fighting dirty kind of kind
of method for dealing with our zombies
but we were we were making huge progress
and we're starting to see fewer and
fewer of those false positives
so this is where we kind of had this
major breakthrough where we were gaining
momentum and we were smoothing over all
these bumps in in kind of non optimal
ways but the momentum that we were
gaining was much more important than how
what we had to do to gain that momentum
and we started thinking of this in a
different mindset that not all problems
require precision solutions sometimes
you just have to smooth over the speed
bump to move on so we kind of ended up
with something like this instead of
getting in your car to get to the
grocery store you get into this you get
into this armored convoy this is this is
this is the the tool that we built and
it's going to get you to the grocery
store one way or the other is it
overkill yes no question about it is it
is it computationally expensive all the
stuff that we're doing no question
making the test run slower with all
these retries and things yeah not going
to argue with that but does it fix the
Reliant reliability problem hell yes it
did anybody watch The Walking Dead so
when they come to a zombie do they're
like they say Oh Sam be yes I'm dead now
no they drive like sometimes they just
drive through herds of zombies and you
know turn on the windshield wipers and
like they get to the other side right so
that's what you have to do in today's
world of end-to-end testing to get to
this point so we're back at this point
now we're getting tests running we're
going days and weeks without seeing any
false positives and when we do see a
test failure we don't even have to
investigate it anymore ourselves we can
just send this directly to the to the
developer who owns the test and say hey
check this out looks like ie9 is broken
when you try to view your cart and it
used to be that we'd be shaking in our
shoes whenever we'd have that
conversation because we'd be worried is
it going to turn out to be our problem
and then we just pissed off a developer
because there we're going to waste their
time but now it's like oh thanks man
like you just saved me from having to
pull an all-nighter when we when we
launch next week
so we're back to this point where we're
making great progress we hit our speed
bump we do what we have to do to smooth
it over and we're there we've got a
reliable and to end test suite running
on our complete browser support matrix
it's made out of kludgy duct tape and
rubber bands but it works so the next
thing we thought we started we started
hearing like hey this is cool like have
you guys thought about opening open
sourcing this and we were like nobody
nobody wants to like open this can of
spam and see like what's in there you
know it's like okay this is helping us
but like we're not we're not proud of
what's going on in there we thought this
is not suitable to release right because
just because that's that's kind of the
mindset of development as a craft and
like you know you create these small
lightweight tools you publish them on
NPM their elegant they solve a tiny
little problem in like seven lines of
code and this was like a monstrosity
that we created you know it was it was
good solid code but the things that we
did to make it work just felt felt dirty
so you know did we feel like we were a
bunch of clever engineers like yeah we
thought like we were shoveling and
we got the job done but at the end of
the day we're shovelin but then we
thought okay we thought about our
journey and this is where we ended up
but what would have happened if we
hadn't thought about that whole axiom of
truth thing and and pushed on no matter
what and how many others must have tried
and given up how many other individuals
how many teams how many companies got
thirty percent seventy percent eighty
percent of the way and wasted so much
time trying to make it work and then
just gave up because they couldn't find
an elegant clean solution and how many
more people in the future we're going to
do that and then still we started
thinking about what's the responsible
thing to do and what if we could take
all of that wasted effort in the future
and actually add it on to the point of
after like after the problem that we
solved of making tests not flaky anymore
what if we could have people
contributing to other more interesting
parts of end-to-end testing after that
because we had started moving on to
cooler problems ourselves we realized
okay we have these tests running but we
don't have a good way of going back and
historically looking at trends about
what passed when and who broke what and
which browsers were failing together so
we forked the jQuery test swarm project
which already had a really nice
dashboard which they used for keeping
track of their unit tests cross-browser
for jQuery and we made this work with
our end-to-end tests so we were running
builds at regular intervals every hour
two hours and if there was a failure we
could get a very narrow slice where we
could say up and ie8 regression was
introduced between twelve o'clock and
one o'clock today and that gives you a
very small number of commits to go and
look at and then when somebody claims
that they fixed it we just wait for the
next iteration of the build to run and
then we can see oh sweet everything is
green again after that we implemented a
massively parallel test runner so
instead of just running these tests one
at a time on each remote browser we
could run 10 15 50 tests at once so we
could compress down the total time it
takes to execute this entire matrix of
tests from an hour to an hour and a half
into more like 15 or 20 minutes and that
gave us the freedom to run these these
builds not only just at a regular
interval but actually as part of our
pull requests verification we use it we
as github internally and so it gives you
that nice border around your merge box
that says all good to merge or you know
hey you failed the build so now we can
have our remote sauce labs cross-browser
builds actually contributing to that to
that safety check of saying to a
developer whether it's cool to merge or
not so remember that Google criticism
about just say no to end to end tests
because they're too slow well because we
smoothed over that speed bump and we
could move on to cooler problems we got
to actually tackle that problem and we
found a pretty good solution for it so
it's no longer hard to isolate failures
because we can run this on every
pull request now we had this nagging
feeling about what about the flake right
what are we sweeping under the rug when
we're retrying what if there's
legitimate issues in the app code maybe
a timing issue maybe there's something
that in the app code actually fails two
percent of the time and are we just
sweeping that under the rug so we
started actually looking at the data
that we're collecting through tests form
we've got a big database of historically
all the tests we've run how many times
each test has retried what user agent it
ran with and so we can start producing
graphs like this it's kind of hard to
see at the bottom but we've got a list
of all of our use it's you know browser
vendor version and operating system so
we can sort and start seeing what are
our biggest problems here we can see
that we've got the most tests flake
we've got like you know nine point seven
percent retry rate for our iOS
simulators so this could be a problem
with the simulator itself this could be
a problem with how our code is working
in a responsive scenario but it gives us
a narrower window to look at instead of
just giving up and saying oh the tests
are flaky what do I do we can say yeah
but they're more flaky on this browser
than this one so that gives somebody who
wants to investigate a little bit more
to go on we can also slice by the test
names themselves so if we start to see
particular groups of tests that all test
common features that are failing more
frequently together then that's a
feature that a developer should should
look into so Google and and and some of
these other companies that have tried
this we're all we're all trying to
summit the same mountain together right
but because a lot of them got really
stuck on the flaky part they never got
to research the more interesting things
and we're at the point now where we're
researching the sources of the flake and
starting to narrow down this problem
that seemed just totally insurmountable
before so we're going to open source
this right now we have a code name
called Magellan because we're a large
company we have to we have to run all of
our open source stuff through a lengthy
review process and the name is likely to
change but look for this to be open
source soon what Magellan actually is
is an end-to-end test runner that hooks
into other libraries such as Night Watch
or WD so it's not a replacement for
Night Watch or protractor or all of
these but you can think of it as a test
runner runner so it's it's a commander
for your fleet or a conductor for your
orchestra and it does a few very
specific things it smooths over test
flake but gives you insight into what's
flaky it's a massively parallel test
runner that compresses down your your
runtime of your sweet and it gives you
beautiful reporting tools like we saw
from our tests warm fork so that you can
make sense of it all so we came to think
of this as instead of shoveling as
being like something we should be
ashamed of this is shoveling as a
service not as a service on a server but
as a service to your fellow developers
and to your community I've never
actually like coined a hashtag before
but I want to see this trending on all
of the stuff that you've done that
you've kind of been like a little bit
ashamed of but like would really be
useful to everybody because it solves a
problem even if it's a messy problem
shovel that and and do it for the
benefit of everybody else so how do we
how do what are that what are the core
tenants of shoveling 101 momentum
is is greater than perfection so getting
stuck on shitty problems is demoralizing
it's unproductive and there's no point
get that momentum smoothing things over
is better than giving up so I'll think
of all of those eighty percent solved
problems that never saw the light of day
because somebody just couldn't do it as
cleanly as they wanted to that's a shame
there's so much wasted effort they're
useful is better than precise so if you
can help someone else smooth over a bump
it doesn't matter how much duct tape and
rubber bands how much dirty stuff you
have to do to get there if you can be
useful to somebody else and package that
up they can get over a speed bump but
they wouldn't have otherwise been able
to do an open source is better than
closed source if you built a tool like
this you think well maybe i'll release
it one day when i can polish it all up
no release it when it's useful even if
it's only marginally useful and so in
some small way
so you can follow me at geek underscore
day if you want to be notified when when
Magellan is out in the wild or whatever
it's called at the time if you want to
check out the podcast on Rebecca
Murphy's show check out TTL podcast com
we talked for a long time about
everything that Magellan does in a lot
more detail and for real use this
hashtag shovel that thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>