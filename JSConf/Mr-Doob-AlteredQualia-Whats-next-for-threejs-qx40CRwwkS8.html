<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Mr. Doob &amp; AlteredQualia: What's next for three.js? | Coder Coacher - Coaching Coders</title><meta content="Mr. Doob &amp; AlteredQualia: What's next for three.js? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Mr. Doob &amp; AlteredQualia: What's next for three.js?</b></h2><h5 class="post__date">2012-10-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qx40CRwwkS8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">first of all out of curiosity from the
audience who knows what reader giasses
you can return who doesn't know what
trilogy is - okay like anyway like
everything introduction for those guys
but then I were gonna dazzle it into
technical stuff but hopefully people are
gonna be able to follow with all this
so 330s is a it's a library which aims
to make the process of 3d concentrated
fatigue concentrate on create a 3 a 2
for the web much easier the color is the
way it has been built the core is not
attached to the runner so we have the
same scene graph in one side some of the
abilities but you can plug any vendor
that you want you can render that data
in whichever one you want these are ours
they have like a WebGL room their
cameras render as we hear and the dumb
renderer whichever you is you when I add
another one issues after you is
obviously written in JavaScript we have
some tools written in Python which is
mainly for like building the library and
minifying and compressing and things
like that we also have like a nodejs
builder but we really haven't really
used it too much house house it's
awesome
github and it's released under the MIT
license so this is this was you can see
this was like a state of the art of
canvas render like through the Jade like
two years ago like we were able to have
like a cube with different colors on its
face and with a fake shadow which is a
plain even like even two years ago I
think Thomas
canvas it on its own but the canvas API
didn't really have anything like no one
had really done much stuff with it so
even if with this implicit like people
were like impressed with it for some
reason I like you know in the past or
something shortly after we had like I
had that thing that keeps hitting weak
we started doing this project they would
in a downtown that it served like a
excuse for like improving the the canvas
renderer a lot like we had to add a lot
of features to it
even even if the actual music video that
we did we didn't use it that much we
were only is it for like some birds on
the homepage and some trees on some
putts but it was really really useful
like he was really like a Kickstarter
for the camera we had we had like so
many features thanks to this in the same
way we did this I think was six months
after that we work on these another
music video that in the same way it
itself as a key it's good excuse for
like implementing lots of features to
the render and this is more or less how
it is where we are now this is some this
is some notes about this raffinate so
this is the graph of comets and github
and as you can see this was small as a
pea Oh mm mm um when I was may put it on
github you can see more or less my
enthusiasm how he was going down a
little bit but I think this is more or
less when we were working on the
wouldn't wouldn't something website and
then there's a gap which is you know you
finish a project and then you retire for
like maybe some weeks and then this is
when a also qualia joining and solitude
submitted some commits and it's created
like interesting phenomenon that we
somehow found ourselves like fighting to
see who was committing most under to the
library and it kind of from then on we
had the same pattern now it was more
less here like we were working on this
wrong website on than we did the first
like the base code and we put in more
and more features and then another gap
which is like another project and then
from then on it's like more random this
is from then on it was this like
community driven enough development I
use it doesn't really depend and a
slightly just more like people whatever
they come in and they use put some
comments and then we just try to see
where we're gonna go with this so up
until now they were like about
140 contributors about 4,000 commits
55,000 lines of code
the library minified is about 100 whites
and gzipped it's about 100 kilobytes
which is something I somehow care about
I always wanted know I'd say was like a
good limit to have as a g-sib library to
don't go higher than 100 Kuwait's would
we keep fighting and we are all
determining 95-99 and no it's somehow
interesting but we'll see how it goes
it features a really really really bad
accomodation this is the first complain
from everyone that comes in it also like
from time to time we get some classical
developers the turbulence a like I'll be
surprised that you guys don't have any
any taste at all and this is because we
have like about at this point we have
but 175 examples those examples really
serve as a kind of unit test like in
whenever we change the feature in
Reverse feature a feature we check those
examples of the relevant that are using
that feature we see we've written
something and at the same time those
examples we keep them updated all the
time on like even in the dev channel
brandish they're all the time updated so
you want to learn how something is wrong
again you only had to go to the examples
and see see how this we also make sure
that the the repository doesn't have any
dependencies so you can just download
the whole repository I mean you can
start hacking around you can display
with all this and but you need to bear
in mind that if you are like and always
if you're using from you need to execute
wrong with the allow file access man
files you know that you'll be able to
see some of the demos because it loads
3d meshes with JSON or other formats if
you have any questions or you to play
with that this is also we recently move
all the questions from the github we
move them to a stack overflow and so far
seems like some people is helping rot in
there like some there's some people that
try to help the people whenever they
have some
some problems and so we have a three
three today's as a channel on freenode
so this is how the API is currently I'm
not gonna get dive or like detailed
whole theme but you know as a part of
the reason that we don't have like a
good documentation is because we having
like moving a little bit the API we have
username and some things and it's you
know it is it's also laziness but it
takes some time to change the API and
also update the documentation and we
don't want to put comments and let's
talk about that and okay so this is how
like how you create a camera nowadays we
have mainly two terminals like
perspective camera graphical cameras
different kind of transformations the
view then you create a like a sin which
is what you're gonna be like you can
just think about it in a film in a film
way just assume what you're gonna be
putting all the stuff on that we create
like a cue geometry we load the texture
we have some utilities so like this will
do all the edges are loading and
everything new image and it will then
which we use that texture which is
pretty much like a gift like you can
load in any website and we create a
material using that texture and we then
create like a mesh that was going to use
the geometry that weakly with the cube
with my children and we add that to the
scene because we're using this foam
material if we don't have any light in
the scene we're not gonna see it so we
need to put a light in the scene and in
this case we are copying the position
from the camera into the light so it's
gonna look like you're pointing the
light into what you're seeing and then
finally we create a renderer in this
case we're creating a WebGL renderer
which we are enabling entirely so it
looks that's nicer and the only way to
the only connection to the Dom in this
case is like every render has a dump
limit inside which is just like a canvas
and you can add that as a function of
any node or any part on the Dom you can
also pass a canvas that you've really
created to the constructor but this is
the usual way that we usually do it
and then for an amazing we recommend
using requestanimationframe and in this
case we're just like changing the
rotation on the X and the y-axis and
every frame we are after that we're just
rendering the dot scene from that camera
so we end up with this super amazing
cube super amazing straight and you see
do you kind of see what's the difference
with all these like I'm the first one
but I'd like really really like a big
fan of vanilla J's but you want to see
how what's the code for doing this cube
created with WebGL like this money like
this you know it's some trailer like you
get all this uniforms you create all
this ending the texture I think done
that is the cute like here you define
all the vertices even more all these all
these all the drawing stuff and this is
even considering that that code is
already using some utilities for doing
so next is show a little bit some of the
things that we have been working for the
last year thank you so here is a scene
that we will be able to render it with
WebGL entire from some time ago maybe
maybe a year ago and it looks pretty
decent there are three dynamic lights
func illumination specular highlights
and I went mapping but the question is
can we do better like a lot of times
people and see they see that geo then
was they're telling it's looking like
rendering from the 80s are from the 90s
and the answer is yes of course we can
look to the eternal inspiration for the
advancement of the computer graphics
which are computer games so we use some
techniques from the computer game
developers such as using gamma corrected
rendering pipeline replacing a dog
shading what else is more physically
based rendering or for example using
nice-looking but cheap Trender
approximation of the subsurface
scattering for example used in half-life
2 by using wraparound lighting
here is how this thing can look when we
use exactly the same scene but we are
using more advanced rendering models
it's running at a 60 frames per second
it's looking much more realistic now if
you play games a lot of times people are
complaining that the textures are not
looking okay
and often the trouble is not the quality
of the images but is how the textures
are being interpreted on the graphics
card people are complaining that
textures are looking blurry here how we
can improve this
fortunately WebGL standard has
mechanisms how to be getting newer
features via WebGL extensions and here
we try to evolve our render to be
incorporating new features that are
available in the WebGL as soon as they
as they become practical to be used for
example anisotropic filtering for having
a nicer and crisper textures just
recently landed in the stable browsers
so we modified our texture uploading
algorithm to be able to use and is a
tropic filter in K for example you can
see on the on the right side is all the
way of using trial and error filtering
then if you check how is the texture
changing positive are the horrors in
there is getting blurriness well if you
use anisotropic filtering the textures
stay sharp
exactly the same image but it looks much
better when we use more advanced
filtering now another very how to be
getting higher visual quality of the
rendered images is to be adding more
surface details and here we take
advantage of another of the WebGL
extension it was coming quite recently
to the stable browser is to be using
standard array it's extensions which
allow us to be doing high quality but
mapping this is example like what we
have been able to do like state of the
art of 3js rendering one and a half year
ago with both me and we to do we have
been trying to make it look as good as
possible and that's what we have been
able to do but with more modern
techniques that's what we are able to
achieve in the browser running
60 frames-per-second very high detail
exactly the same model just use more
advanced techniques and also browsers
have been catching up and they've been
adding more features so you just have to
wait and future will come now it's
important to be able not to be having
images that look nice but also we want
to be running as fast as possible and if
you already have a WebGL that is running
directly on the on the graphics card we
are able to take the advantage of
hardware acceleration not just for the
computation of the shading but also we
can try to upload computation of the
simulations to the graphics card and
here we use another of the recent
features that we are able to pass
floating point textures which we can use
to pass the data to the graphics card in
an efficient way so for example it's
useful for particle simulations there if
you have been doing particle simulation
just on the JavaScript we have been able
to have like tens of thousands of
particles here with folding post
textures we can have a million particles
running on the GPU CPU is almost squired
it's just put the shaders on the GPU and
then everything is done in the graphics
card
another simulation that we can offload
to the graphics card is animation of the
characters so for example we are having
hardware accelerated scaling where
either we can be having like a lot of
very simple characters it's it's about
400 buffaloes which are animated
entirely on the GPU or we can try to
have the less but much higher quality
characters with high details which you
probably familiar from
it's again right there at the 60
frames-per-second running in your
browser now it's it's important but to
be having nice images and running fast
but if you want to be doing more
complicated applications you are going
to want to be putting more and more data
inside so for example when we have been
starting we have been doing almost
everything was having a representation
of the other models in the JavaScript
down to the things like every vertex was
JavaScript object but we soon we found
out that this takes really really a lot
of memory so we tried to be using more
efficient memory representation of the
geometries and for example we are using
just type at our eyes that we
initialized from the from the JavaScript
but once we upload it to the GPU then we
can just completely forget about the
JavaScript part and then we are able to
get crazy savings on the memory both on
the memory and on the initialization
time of the other models here is the
example of 160,000 geometries that it
initializes instantly and and it's also
running fast because the layout in the
memories is more friendly for the for
the graphics card now a big part of the
of the models is not just geometries but
also the textures if you are doing
classical web developments you are
mostly concerned with the sizes of the
of the textures which are going over the
wire but if we are doing 3d graphics
programming no matter how small is your
JPEG or PNG or gif it's going to be
expanded to the full sized image on the
graphics card memory and very soon you
are going to be running out of the GPU
memory so for this game industry
developed compressed textures which are
uploaded compressed to the to the
graphics card but then they are
uncompressed directly just in the time
when vendor they are going to be used
for the rendering so for this we have it
just very recently
implementing support for compressed
textures we don't have yet any a nice
beautiful demo but you can get quite a
large savings on the GPU memory card
which means that in the future you will
be able to put
more each Vitra warts under the WebGL
applications now it's important not just
the sizes that are being on the runtime
but it's also important the sizes of the
models that are going over the internet
it's if you check in with our games even
simple indie games are like hundreds
megabytes gigabytes so if you are used
to the web that you click on the
something and it's immediately available
it wouldn't work if we would have a
large sizes of the models and here we
have been trying various approaches
where we started from the simple JSON
and here you have been quite lucky
because a whole web stack is made to be
to be working with the gzip so so we
never actually have to be looking on the
side of the uncompressed model because
anyway if you are saying you are going
to be using gzip for transferring all
your data but even here if we are using
the data formats that are knowing about
what's inside the data we know that
these are vertices and we can we can
truncate some of the precision and it's
still going to be looking okay and we
are able to get like five times smaller
gzip sizes here is for example this is a
model that that we have been speaking
about and it's its high detail model
that that itself is similarly sized like
if it would have a1 PNG just just be the
screenshot of the of the image and for
example this is a fairly detailed model
that post geometry and and and the
textures we have we have a Becky
illumination this is 700 kilobytes and
you see that it's not instantly and here
Ricardo will tell about what's next in
the pipeline so most of those things
that he has been talking about those
those that that those things are already
like on the library you can use that is
not something that is works magically
but you have holes or you can you have
API to use all these stuff some of the
things that we have been experimenting
with has been like more renders like
this there is people that still rely on
cameras render because WebGL is still
an explorer this little listen welcome
likes if I is not enabled by default or
like iOS it doesn't work at all so those
people still want to have some 3d
graphics on the web so they use the
cameras renderer and Department the
cameras render is it just is a hack on
top of each other like for doing like
many things like we do like really crazy
things that you will be laughing for
today's the problem the problem with
that is that for instance canvas the
canvas API the cameras vector API has
unserious enabled by default and there
is no way to disable that that creates
problems like the when you throw two
polygons you will see like a line in
between it like if it was Y from a
solution for that what we do is expand
each polygon like a little it's a
overlapped so we're talking with some of
the people that cannot define that can
expect like would see if it was possible
to reuse like the the WebGL stacked in
the same way that you can enable or
disable actually see it but they use
tell me like oh what's the use case and
I was showing like ideas when heart is a
3d stuff and they Tommy argue it will
WebGL for that okay so at that point I
were like okay so what's what's what's
the solution of what what kind of thing
to come which felt like this one I was
wondering like is it possible to what do
we happen if we still use the cameras
run ever with canvas API but we don't
use the vector of API we used like they
much data API so you get a buffer you
get a like a type array which is just
like all the pixels in the buffer and
you draw the triangle speaks of a pixel
like no it's it sounds crazy but this is
how the 3d was done 20 years ago say you
know I was just curious to see how it
was gonna be him how he was gonna be
performin or not so the output is not
exactly the same because I happen the
problem with this kind of render is that
it takes some time to implement the
features but this is how it was the kind
of thing that you can do with cameras
renderer like in this foot in this case
I don't know you can see which will go
to the light so so in this case it's
technically the same thing as in the
other demo even if they looks different
we're just trading triangles and we're
doing a crazy big map and doing three
pixels and then somehow it's carrying
that and we're using that as for like
painting each triangle with different
colors on each corner and this is you
know six frames of second and in this
machine which is pretty powerful sorry
and these are on an iPad this is about
one frame per second so what we have now
is just this one which is the technique
is the same thing again it doesn't look
the same but the bottleneck it's not
unpack relating the light the bottleneck
is on rendering those triangles and we
can see that this one is 60 frames per
second which is quite an improvement the
problem with this is that we don't we
cannot well we can do until this in the
long term but I wouldn't want to do that
but the thing is on an iPad the p1 as I
said it was one frame per second and
these girls are like about 10 frames per
second it's still not good enough
like it just tends 10 frames per second
but you know Alice is just all or
something that maybe they improve the
separate performance and we'll see where
it goes but at least we have some
options this is of course this is not
something that really I can make it that
fast like when I'm lucky that German
Geico well a demo seeing I called Rick
helped a lot to make this the way the
render is done and also there's a lava
lake eater of that help on making that
II didn't like to making that's like
double check the cuts to make it that it
to make sure that it was running fast
and so we're gonna be developing this a
little bit and then hopefully at some
point we'll be able to have like render
that is feature tool features the
cameras render and you can use you have
an option but so far this is all we have
right now then another renderer we
didn't have enough is the CSS 3d render
which I don't know if any of you have
play with the CSS 3d but it's a little
bit like kind of WebGL in a way you have
to all do all your mattress is native
mattresses all the transformations and
rotations and it can be a little bit
like
cumbersome so
at some at some point I was wondering
what it will happen in for what what
about doing him and early through the
year so you only do the same thing like
it's create a plane and add it in the
scene and then just move the camera
around so this is what we had so far so
the closing of this is that although
such as iframes that are loading like
some effects from my website for as you
can see it's still interactive so that's
something in instance that even with
WebGL you are not you cannot do easily
because you cannot use the website as a
texture for a module but uh you know
with CSS 3d you can use do this these
kind of hugs
so it's again it's a is really limited
actually maybe I can other you can see
anything I could just creating these
css3 the illustrating an object that you
just add a div into it and then we do
other like that the render will do all
the you so much it is for you it's so
it's really limited to whatever you can
do with dips but you know there is still
like you know like like the sequel is
lay them on ugly so someone to go from
Google that you can release enough stuff
but without having to deal with css3 the
syntax we can use move the camera around
and you think about it and so far for
the last few years we have been doing a
lot of work like kind of creating
resources and and and doing a lot of
code that basically makes the developers
happy have we Google have we we had all
the artists on the side like without
being able to do anything because the
artists won't be able to to play with
all these unless they learn to code so
for the last some months we have started
doing an editor for all this so so the
way one of the the main benefit of this
is that what you see here this is what
you see here this is already the WebGL
render so you can already preview how
how your model is you know look in this
thing so for instance let's see we can
load anyone any model that all the all
the formats that we support like we have
like an obj loader we have like a colada
loader you can use the rock and out them
and we can load us as much as we can and
here you can start playing with the the
usual kind of API in a visual way like
like the three three years API turn
instance you can load the color you can
use light which of course it doesn't
look too really thick
but we have this specular map which does
all the magic for us here and now we
have something which you would look at
the head it looks a little more
realistic and we enable it you know you
can salute like tweak more or less how
you want it to look and let's see the
thing of those color Pickers is that on
Windows they are not real time but on
OSX and chrome wise they are real time
so you can be change the color on you
see it on the model real in real time
but I guess at some point I will just do
our own widget cities works in any
platform so the cool thing of this is
that the artist can just come here use
tweak all those you know it's like like
unity3d
kind of thing just load up the models
put all the materials and all the other
you know just to really see control how
how you want it to look and then we
still have to add these like then you
will be able to export these or you can
just compose the scene and use X for
this for the for the programmer and the
parameter is gonna be like adjacent load
and it's gonna look exactly like the
artist wanted oh yeah
and of course this is right into the
repository so this means that this is
also MIT license so it will be like
interesting like this this I can see
this being as a good base for someone if
someone wants to be like like a game
like they are building a game and they
want to have like a level a level editor
they can use hack around it the tool and
two dependents that they want to do
whatever you want to do and at the same
time if someone wants to add a pile at
the bottom so they can use how to encode
editor that executes some you can just
hide whatever you want and add some sins
of the some objects to the scene you can
saturating like procedural sins and you
can just play with it visually with what
you are creating and yeah we think we
think it has a lot of potential and we
really are curious to see you know weird
in the same way like in the same way
that we build like footage as we were
not sure I mean we we build it because
we donate it but then people come in and
they say oh what about having this like
art that's interesting but the same
thing here like what is building because
we think it's something that we need and
we'll see how people solve it like how
people what they suggest and how the
whole thing evolves so with that over
that's it thank you very much
we have any questions
oh my gosh why'd you have to be over
there
can because you said at the beginning
that the whole library is about 400 K
right the minified bill okay and but can
we like build it without for example
canvas and dam renderer only WebGL stuff
and it will be smaller yeah there if you
go to the what is a folder called tools
tools where we have the Python build and
it includes some JSON files that though
you can just run the Builder using any
other JSON files and though JSON files
are just the files the list of files
that you wanna include is there isn't
wiki or some of the wenching like when
you are doing the list which one goes
first but you can just try thank you
well oh man my mind is blown thank you
guys so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>