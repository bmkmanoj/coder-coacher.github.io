<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Mariko Kosaka: Making a Robot Eye with JavaScript - JSConf Iceland 2016 | Coder Coacher - Coaching Coders</title><meta content="Mariko Kosaka: Making a Robot Eye with JavaScript - JSConf Iceland 2016 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Mariko Kosaka: Making a Robot Eye with JavaScript - JSConf Iceland 2016</b></h2><h5 class="post__date">2016-09-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sMUj1LXDrBI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you
hi um that's my twitter handle if you
have any questions right at all go if
you want to message me want to complain
about the content you can do so on there
so I want to start with a story and just
for the second imagine this is a
classroom in high school I took a class
that is really hard to translate it into
English but it's something a line of
music appreciation or sound listening
and you know not only we listened to a
lot of music and learn about classical
music history we also watch a lot of
movies we alter the sound wave
artificially to sound the conversation
more softer or more sharp and think
about if that changed how we thought the
conversation we're going we also
discussed about iconography of the
jacket cover on the Lee code and
everything so this was the first time I
realized that there's a certain pledges
thing as nonverbal communications the
communication that your eyes or your
ears or just getting some kind of signal
from light or the it will wave on the
air and somehow we or just analyzing it
without even thinking and doing certain
kind of communication and this was
really fascinating to me so I studied
communication in college and also a
visual anthropology and my first job out
of college was a online video sharing
community site and now I woke as a web
developer making text editors but making
of clinical applications or websites or
designing a system to me was always
creating a means of communication for
humans to me it was never about
connecting a two computers or two
programs together so can't day we are
surrounded by non verbal or visual
communications or sound communication
really how many of you have like all of
these application in your pocket like
there's so many applications that use
sound elements so many applications that
use picture element we are all
surrounded by it and even as a
programmer this is a really exciting
time that a lot of research on image
processing and computer vision is
happening this is the example of doing a
style transfer which is a way to use
machine learning to analyze the picture
and apply the style and technique so
painting into another picture you might
also know the deep dream from the google
lab so even in the Lee search field the
exciting thing is happening so
discovering this type of communication
was really fascinating to me because as
a human eyes whoa this is really big
picture like us looking at this picture
how many green circle in this picture
one how many yellow squares are in this
fixture one yeah this is interactive one
so like you can just tell me so like you
eat last programmer thinks that like you
know really like to write a logic and
like really like flexed logical thinking
muscles but when you're looking at it
and then like when I ask you like how
many yellow squares are there you don't
need to think about like if else
statement you just like there's one like
you don't even think or you don't even
know that you were thinking in your
brain and this is really interesting and
frustrating when you are trying to make
an application that deals with visual
element so I want to show you one sample
that I'm hey last year i made a
application let's call sweater if I I I
work as a software engineer on my day
job but on my side on my side project I
really like to create a tools and um
program to design a textile and this was
around Christmas time so I wanted to
make something fun something people can
just do so I'm a ugly sweater generator
or in British term I guess Christmas
jumper generator you can just upload the
picture
then I will make it into a sweater foam
to me this is not even perfect because I
see this image and in my mind there is
like a vivid image of like me should be
extracted more there is clear border
between clear border between here in the
background and my hair but when I do
applied it to the text align there is no
border here and like how do I even tell
my program where is me and where's my
background and got me really interested
in this topic of Miss processing and
computer vision when you google computer
visions you would probably find some
kind of libraries may popular one is
open CD and there's a whole bunch of
document about how to use it so many
back so many blog posts about a tutorial
of using this library my main
frustration was that all of them were
about how to talk to this API how to use
this tool that's doing something that I
don't understand and none of them
explain what actually this library is
doing and then you know as I mentioned
there's things like very trendy topic in
lasers like deep deep learning and deep
dream that you almost started feeling
like it's just like something that like
via links to research facility it's just
like really over top of my head and I
can't really understand like I don't
know so when we were looking at object
from human I we can immediately identify
certain attributes like colors of the
object height of the object name of the
object that's commonly known in the
society but the problem with computer
vision is they don't look at that object
a look at digital representation the
digital photo of the object and this is
a photo of the object is really just a
whole bunch of bytes and bits in there
so the robots or the computer program or
computer whatever you want to call is
just looking at that number and my
question
is how do we tell that person that lava
how to lead that like us humans do with
these orange attributes and another
question is that is it really like Alli
Leigh difficult thing to do that you
have to help PhD or can I just use it
what can I just do it in the platform
that I'm really most familiar with and
the language that are most comfortable
which is JavaScript and the answer is
yes you can use canvas element and we'll
get to that but before we get to that I
have a announcement not disclaimer
announcement I consider myself as a
translator I it's not really between two
different languages but translator in
the sense of providing different
perspective I have a tendency to draw
all over the technical documents I have
tendency to use a lot of analogy to
explain certain concepts so the stuff
that I'm gonna do today my look
unfamiliar or weird and I'm sorry if
that's the case but I really think that
there is a value in having different
perspective not just only having one
traditional way of describing computer
science but having a different
perspective in this field so I'm gonna
do that so image as i mentioned digital
image is just a bite that computer is
looking at so like how how can we look
at that number ones and zeros and matrix
e thing so i made a special image so
like if you like stir yourself in the
center and then the craft right down and
then go cup and then just like focus on
the center for like 10 seconds then you
will look start to look at this like do
you see it you see the zeros and ones no
no no no it's not like that it doesn't
look like that you have to write a code
so as i mentioned i use the canvas
element canvas is a HTML 5 element that
let you write a tough draw a picture on
your browser using javascript so it's a
perfect element to do this job
to create a canvas is just as easy as
creating any other kind of ACM element
just clear to element in canvas or you
just type it in the canvas tag and
reference by ID and you need to specify
size of that and I'd like to think this
process as for this day's as like you
reserved certain piece of land somewhere
but you don't know where it is yet you
need to know because you don't know like
whether this land is in Iceland and
speaks mysoline language or this is in
New York in the middle of like heist
skyscraper so you need to give some
context to this piece of plan and you
exactly give the context but I doing get
context you specify what kind of context
you want i'm using 2d context but you
can also specify WebGL to do the GPU
programming but at this point you know
exactly what kind of language and what
kind of method that you're getting out
of this context once you have the
context you can draw amazing do this by
through the context so contact start
draw image and pass a image into it
we'll put a digital image into canvas
element and now your javascript king in
track to interact with this fixture in
order to get that data whatever the
computer is looking at there is a method
called get image data and then you
extract the data out of the canvas so
let's look at what in this data element
this is what image data looks like just
imagine you have a three by three ed
tiny pixel that's just like super and
lowers into this screen and the left
left of it is what looks like if you
call get a nice data and then get the
data out of it it's just a JavaScript
object certain attributes are very
obvious width and height is a width and
height of the image with a pixel unit
and then there was data and there's
whole bunch of numbers that you need to
understand but this is ingredient what
constitute this picture so in order to
understand what this data is the way you
need to under
than what's in a single pixel if I drew
the single pixel which looks really big
in here I also gave eyes to kind of I
humanize it a little bit so that you
like you know get familiar with pixel
underneath the pixel is full values
first three you can think of it as a
different colored of light bulbs red
green and blue and a force one will get
to it but you can control how blight
each color of the light bulb is so if i
turn the red light bulb all the way up
and turn off green and blue then your
pixel becomes red if you do the other
colors you know slightly greenish and
you can start mixing the colors in lgb
space if you have same values for each
of three you always get gray different
shades of gray but you always get gray
and this always get grey comes important
later in this talk but you can see that
right the force number is opacity so
this is purely for software to know if
some images are overweight how much
should I brand it in to lender it on
your screen so you can see I have
slightly less paucity and you can play
around pretty much you specify lgb a on
your CSS it just comes in four numbers
so so now this data start to make sense
I Pat it by just a chunk of four so that
it's easier to lead and from top left
corner to the bottom right corner each
pixel has four numbers for them so let's
do the same thing here that first pixel
because it is a first for it should be
top left corner hopefully let's see
let's make it into green so I turn off
all the rape red light bulb which is our
first value and then I turn the green
channel all the way after 255 and then
turn off the blue and update and then it
should turn into agree so this is how
the most basic way you edit a digital
image and we will deplete do that for
all of the pixel from now on now kind of
thinking this one-dimensional array data
in two-dimensional space is a little
hard but what leading made sense to me
was when one of my mentor explained to
me the way this this way so when you're
writing a letter to somebody in your
head you don't need to think about ok so
this paper fits 20 characters so I'm
going to think about 20 character first
and then for next sentence i'm gonna
stick like a mother 20 character know
your blend is thinking just like stream
of data and then when you put it onto
the paper you just unconsciously going
up I lined out of space not a lie
another face another line so in a way
that the what's in your head is the data
that you see and they miss data and what
transfer to the paper is what you are
looking at on the screen as a texture so
now we know how to get to the data and
how to get to the pixels and how to
change the color of the pixel let's do
something fun I hope it translates well
on the screen but let's do something
like image filter the Instagram filter
if you research how to do the image
filter you look at you discover the
squiggly functions that's called a plump
I can't even pronounce Oh basically
master and a whole bunch of maybe glass
but it's like always a grey and like
black I like to think of it as like
introducing a social construct to this
like pixel social world because it's
really just setting a rule that all of
the pixel follows for this texture so
like age group who's allowed to use
playground certain days you have to go
to school you have to start paying tax
once you go through to school like all
of those things you just define it and
then you apply it to all of the pics
pixels so here is a function that's
visualized in a data visualization in
the case that you're not applying a
filter you were just like getting image
in and same image out it looks like this
so let's say your light bulb is
illuminating the red light bulb is
eliminating 181 the output of it is
always 181 and you know it doesn't
change anything and I colored it in the
gradient of red green and blue just to
specify that all of the three lights are
going through this function so if you
have a 1 pixel then you do the same
thing for three times for each channel
all of them follow the same who'll but
then like you know changing the
brightness you slightly change those
carbs so in this case let's say blyton
all of the pixel so there's a 72 161 so
that's what like 73 is like all of the
pixel that go seeing gets more blatant
and then comes out the contrast is
similar to brightness but it's changing
a slope of the curve so here is a high
contrast it is here is a low contrast
image in no contrast case input is so
from 0 to 255 you haven't altered
anything on the input side but the
output is limited to in this case 56 to
190 200 so it slightly lose the color
that's possible and it doesn't have to
be straight line there is this thing
called posterization and it's basically
glue p'ing the pixels together based on
the number so in this case any pixel or
any any data that has 155 to two or
three all gets 192 and this way you get
this pollster eyes effect of color is
limited and it's kind of fun to do so
now that we know how to get the data how
to change the color how about changing a
structure of the picture like blur and
sharp image to do that you need to do
some kind of mass called corner
convolution which I feel like it sounds
like a yummy cereal but I'd like to
think that as
thinking about a social graph of the
pixels we introduce a social construct
but then you know within the social
construct of the world you know it has a
lot of relationship in it and you need
to think about those things so here's
one pixel that we want to change the
color to change the structure of this
image you the pixel has a sounding
friends and in case of blur let's think
about it you want to blend it in as much
as possible to your neighbors so you lay
yourself and your neighbors equally and
you get the other ways color of all of
the nine pixels and then you change your
color to that average color in the
bigger picture so let's say you see here
is a distinct red line going across you
do that mass for each single one of the
pixel going through and result of that
is blurred image so this is a box floor
that we just did let's see how r / this
is original blurred orginal blurred but
in reality though like not all of your
friend is like equally important right
you have a best friend and you have a
distant friend so in that case you can
use something like Gaussian blur or you
can make your own matrix that you want
to introduce in Gaussian blur case they
use normal distribution so you're closer
friend gets laid it higher and then your
distant friend which is on the corner
get high elated lore and it's slightly
edged preserving way of doing the blur
and if you ever wondered why SVG filters
you have to type Gaussian blur that's
because the type of matrix that got the
SVG filter uses is a Gaussian filter
sharp on the other hand is the opposite
you don't want to blend it into your
friend you want to be unique like you
you really want to stand out in that
case you you laid yourself the center
context or later so really high while
you don't want to get the inference from
your friends like late at zero or you
even want to like learn opposite like if
you're doing the saying that I'm gonna
go the other way so like you Nick lady
negatively and then that produces a
sharped image so here's always no sharp
and slightly maybe you can see it right
so if you want to play around all of
these filters I have a library that's
called graph ejs that let you easily try
out those Salters I kind of designed it
thinking like underscore but for image
processing so you can pass any of the
image data and then you specify the
parameters and you get an image data
object out which is the processed
version of image so if you want to play
run you can look at those so now that we
know how to get the data how to eat the
data how to change that and how to
change a little bit of structure let's
think about neighborhoods because much
like the city is consistent of many
different neighborhood based on whatever
that reviews that we carry the image has
interesting parts of the image important
parts of the image and they're not
interesting parts or differently
interesting parts of the image so how
can we get that information out of this
image in order to do this you need to do
like plea processing for like two things
one is upscaling and one new fresh
holding and let's go through those two
so that we can define neighborhood so
there is a little let's grayscale it as
I mentioned all the pixel have sweet
values gray scaling is the way to think
that how bright each pixel is you don't
care about the color of the pixel you
are just interested in how blight are
you're like what's your important like
the true self inside so how do we do
that because we have three numbers how
can we do that well we can take very
naive uploads you're just picking one so
in this case I picked green and just use
that all over and it didn't work the the
bottom half disappeared because the
green channel on the bottom half objects
turn on happens to be 0 and 0 so it just
Talent down so how about like if we
average it out it's getting there it
looks like gray scale image but here is
a problem for us the human eyes die
Green Square it looks like much brighter
than the one on the blue one but in this
average grayscale image those are two or
same if you look at numbers it makes
sense because both of them have same
amount of numbers in the pixel why
because our human eyes are heavily
biased towards one color which is green
so when you look at it even with our
thinking you feel like green it's
blighter you you feel like green is
valuable and you need to this proposed
interesting question of like we alter
our code so that it works with our
cognitive bias which is doing a loom
according so the recording is the coding
that used in the TV industry it's
basically giving a privilege in each
green channel while not really giving a
previous on blue and the red channel and
then output of that looks slightly like
natural quoting coil for us is not your
not natural in the numbers but natural
for our eyes okay we got through the
gray scaling another one it's a
threshold once you have a grayscale you
got little three channel thing you will
now only have information about how
blade that pixel is but you want to get
down to more more smaller number so you
the gray scale is the image that
contains a number from 0 to 255 so 256
shades of gray threshold eng is the way
to make the image into just black and
white and nothing in between so in this
last case we have a let's see if i want
to extract this light bulb corner then i
would just slightly alter this and then
here threshold it so anything that's
below 153 gets zero anything a Papa gets
to 55 and you get black and white
photography so once we have that and we
kind of isolated the
object that you are interested in the
picture ended up like this well let's
just imagine that picture end up like
this so we kind of like grayscale did
and adjusted the threshold and then
isolated it so how can we tell computers
how to identify what's in it because
I'll humanize it's easily you can tell
there's a two white lesions in this
image and the shape of the image like
which is larger and which is smaller but
in computers case remember it only knows
is it black or white they don't have any
idea about the shape so how can we tell
computer that so it's still computer
that which is called labouring so
computer goes to reform the top left
corner and then finds first white pixel
and then says okay I found a white pixel
its label at one go through another
second color and then find another one
and then ask the questions same question
it's white is it any way connected to
the pixel that I'm already identified no
so label says to this one is interesting
it's the ask the same question I found a
white pixel is it connected to anything
that I already identified as a human
eyes it's clearly connected to other
white pixels but remember at this point
computer doesn't know rest of it it only
knows the past though so it says okay
it's not connected I kind of a level
three next one it's now clearly knows
that it is connected on the top and left
side and it says okay I'm gonna label it
one but taken note that three was also a
possibility and then do the same thing
and then come back to that knee mode
labels we that was like you know come
back and then the eval evaluators pixel
and indeed it is connected to label one
so you get one so now at this point
computer knows there's two interesting
place in this picture however what they
don't know yet is where it is or where
the border is so we need to find the
edge of each object how do we do that
kind of the same
computer finds the first white pixel
again and because it is the first one it
defines as a border and then it does a
slightly different thing going through
the edges so it asks is the left side of
me white no so move on is the left
bottom side of me white it's white so
okay so I move on to that and label that
as a border so do the same thing is it y
know is it white no is it why yes so do
that and then now computer knows where
the border of the interesting part is so
at this point our robots or computer
knows looking at this or like give the
data of this nose hmm let's see I think
about the question that they can answer
they can answer there's three
interesting parts in this picture they
can if I ask like where is that yellowy
part of the interesting part they will
point to the middle if I ask like other
color will point to the other one but
what they cannot tell is like a question
like which one is round or which one is
triangular and at this point you can
think of many ways to label or like find
that information you can go into machine
learning and just try to train the level
to like by giving them a lot of
references or you can go into using a
lot of a skip in my mind a lot of
geometry masks to try to find out the
shape of the image so for now I'm
running out of time so let's do one
quick demo of how to find a circle in
this image in order to find circle there
is a very simple mathematical function
that you can apply and it's called
circular shape factor the calculation is
for pi times area / circumference it
sounds like math but we already know
those information area because we
labeled it with one or two rays so we
already know how big each of the object
is and so conference is the edge of
objects so we labeled it so we know the
lengths of the circumference so we all
have a number that we can just put it
into this formula and get number out
this shape factor returns one if the
object is completely circle and as the
object move further away from the circle
the number goes down so if I were to try
to find a circle then you can just learn
this function and then just kind of set
the / hold up if the value comes out of
this is 12.9 then I'm gonna say this is
around so I have a one quick demo that I
need which is to find circles so here I
have two socks I organized a meetup in
Brooklyn Kobuk enjoy us and for our to
universally we made a JavaScript socks
and also I have my own socks that is
slightly similar patterns it's like you
know different shapes and then one shape
is circle and one shape is triangle so
let's see if I put it over there and as
I explained the you can see the original
picture glace killed one and how i
extracted the threshold let's ask our
lobo if this is a JavaScript socks and
it says it looks like a job as good
socks and then let's give try and go on
and let's say if it says so not so you
know same thing and interested and it's
just know this sucks is not just powered
because I applied the function saying
like a circle is a triangular and you
know you can see and the threshold the
object that comes out of the threshold
is certainly rounder than this one which
is clearly triangle I have to click on
it it would be great to kind of not do
that in automatically detect but there's
a challenge in browser see as I
mentioned there's so many much going on
like you know even the demo that was
like tiny there's so many pixels and
there's switch on also of each of them
so so many so many so many months are
going on that browser gets really
unhappy if you're doing it in your
thread so I'd suggest that you just
investigate using something like web
worker and I like to think what worker
is like International Space Station to
us the browser Dom that is the arse it
is something that we want and it is
something that we created we communicate
data over it and do any math and
scientific research over there and you
get the data out but the International
Space Station does not belong in the
worse so it doesn't have access to DOM
no access to window so you can only
communicate over data well you might ask
like how about service workers the buzz
word well I like to think service worker
as like UFO which is a similar thing
it's in the space but there is so many
leg up work that browser provides like
background sync and push notifications
that you are not controlling in
wolfwalkers case in the life cycle of
your application you create a worker you
terminate the work or you control what
the web worker is doing service worker
same idea don't have access to dom don't
have access to window but um it is
something that you don't know how it's
doing on the back so the best part is
that it's really easy to start you start
a new worker and then start launch the
survey station you import scripts if you
want to use outside library because
again I mentioned you there's no access
to window so even if you might already
have underscoring application you have
to install it again and the worker side
and then in between worker and main
thread you communicate by using method
post message and listening to the all
message event and then once you're done
with it you terminate and don't you
control entire lifecycle of workers so
here's an example of very image
processing heavy app that I made that is
not Walker door I guess I'm doing a
bunch of blur operations and it is just
completely freeze the UI and not doing
anything and once it's done and it comes
back all of the quick events that was
accumulated just like thought I ran
so this is not nearly good a good user
experience so this is a war curved
version which animation doesn't get
blocked you can actually see that I am
applying a blur function again and again
and again you I works and then now it's
processing and it comes back as a
processed image so it actually works
faster too so I encourage you to
investigate what's possible inside of
the browser it's really easy to say oh
like you should use C because it's bare
metal and it's fast but us we are web
developers I hope you also some kind of
web developers we deal with users and we
deal with users intentions and cheating
on the user's a text users actions so we
can create much meaningful interaction
by just using what's available and
browser not even going into creating
another app or anything browser has so
many potentials if you get inspired by
this talk and want to investigate more
have a two recommendations book of
shaders if you want to go into WebGL
encoding patricio and gin or artist
based in New York that created a book
that is also Illustrated and explained
in the different point of view another
one is a machine learning for artist
Jean teaches a machine learning class at
art school so he has a he's clean
decoded entire semester Warsaw of
material and then put it on to github
and you can watch it and its really
interesting creative use of machine
learning inspired by those 2 i'm
thinking of turning these contents into
some kind of online book so if you are
interested maybe I cannot guarantee when
it's done again my 1200 is that I have a
googly eyes on my bad so if you find me
come talk to me and if you want to have
Google you guys I have extra ones there
is a two links to my projects and love
friends and thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>