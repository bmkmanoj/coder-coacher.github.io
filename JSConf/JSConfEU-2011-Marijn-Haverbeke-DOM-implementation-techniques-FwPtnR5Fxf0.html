<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[JSConfEU 2011] Marijn Haverbeke: DOM implementation techniques | Coder Coacher - Coaching Coders</title><meta content="[JSConfEU 2011] Marijn Haverbeke: DOM implementation techniques - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>[JSConfEU 2011] Marijn Haverbeke: DOM implementation techniques</b></h2><h5 class="post__date">2013-06-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FwPtnR5Fxf0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm going to talk a bit about the way
browsers implement and optimize the
documents object in the layout thing and
drawing their off as multi mentioned my
name is Madhava Baker I work for Mozilla
but not on any of this stuff it's
actually I expect there will be several
people in the room who know more about
this than I do they're free to correct
me at any time you might know me from
one of these things the book and the
software code mirror which is an editor
the difference the code editor that runs
inside the browser I like to start by
making a claim that the dome is actually
a great platform then we can be very
glad to have that probably half of you
have already moved on to know jazz and
are doing early server-side work or
something um but the general grumbling
that's often happening about the browser
platform is partially justified but we
have a very very nice and powerful
platform in the brochure and you
decoratively define and create your
documents then you have a full view of
these documents that you can from your
scripts manipulate and inspect and all
that is is by now heavily optimized so
that it's actually amazing how fast
things are being handled by the browser
so say you have a document big complex
document like almost every single
website that we're looking at nowadays
the first thing of course is the browser
parses the HTML that comes in applies
the styles that come back to applying
styles later but let's think about how
the drawing happens it's a tree stays
process I guess this is smaller than I
intended right um
first the browser builds up which
usually called a render tree or a layout
tree the instead of the document
hierarchy notes are organized by spatial
relations so it resembles the Dom very
much but if you have for example
absolutely positioned elements it is
moved up to the actual parents that
determines its position which is the
first parent that's absolutely a
relatively position if you have a fixed
position stuff its most all the way to
the top of the document because the
position of these elements is not does
not depend on the position of other
elements display none stuff is removed
from this tree all together in most
browsers so you get a tree that
corresponds very closely to the actual
rectangles that are appearing on the
screen and their dependencies in
positioning and sizing the next thing is
the layout in this tree this layout tree
is walked in a way that signs every
single visible note a size and a
position so a rectangle somewhere in the
coordinates page of the document if you
have inline elements they might end up
with multiple rectangles if they get
line broken each line gets its own
rectangle this layout in is mostly a top
down process and now it gets a width
that it's allowed to take it lays out
its descendants so in line stuff gets
line broken gets put next to each other
until you reach the end of the line then
it moves on to the next line block
elements gets just put under each other
an output of this process for each note
is a half which is then used to lay out
its siblings and
anything further down the tree so I said
mostly top down some things complicate
this tables mostly need multiple bosses
because table cells are adjusted too
well the size of the tables the width of
a table cell depends on its siblings so
they'll have to be laid out once to find
their maximum hey through maximum width
the width that I want then the actual
width is deidre mind especially if you
have deeply nested tables it can result
in a lot of going up and down the layout
tree in order to fix an actual layout
for each table cell which is one of the
reasons people hate tables I guess final
step is drawing this whole tree which is
basically organizing it in the index
order running over it and bleeding
everything to the screen i'll come back
to optimizations of that process later
and layout entry once is actually not
that hard the thing is that we have come
to expect to be able to change this tree
constantly and have it consistently
relay out in a performance fast way it
already starts during building of the
document when something is loading slow
it will often be rendered before it's
fully parsed the browser sparse
documents incrementally building up this
tree as they are running through the
HTML text for quick loading pages this
happens once and then you get a layout
in a draw for slow loading pages only
how the page will be loaded and then you
already want to draw something to the
screen so you get this partial Dom tree
is laid out and then later on the
parsing process continues adding notes
at some point real layouts it throws it
again maybe continues until it has parse
the whole document there's also things
like for example the hover pseudo class
when you're moving your mouse through
the documents at any point styling can
changed which can if you write specific
CSS rules can change the actual size of
elements can cause real layouts of
arbitrary parts of the document and of
course Crips tends to change the DOM and
expect that it will be immediately
reedus played in the correct way so if
we have a small demonstration document I
can demonstrate layout dependencies
between nodes if I were to add a little
inline notes somewhere in this document
well one thing is clear this paragraph
that I'm changing has to be line broken
again it might drop down another line
and thereby change it hate causing the
next paragraph to be shifted down but
for example the title and the sidebar
and the paragraph above it are never
affected by a reflow of this paragraph
so the browser should optimize this and
don't actually even touch these these
notes during this reflow also this
paragraph down here it might move down
but this never has to be realigned
broken its width chain it width doesn't
change so it's a very fast process it's
just moves down a bit if it doesn't
actually happen here but if this would
cause this paragraph to get a different
head if there were more things below say
a further then those would also depend
on on the size of of this paragraph even
though they are not siblings of your
children of this paragraph so it's a
kind of in order dependency everything
that comes after it goes out in an
inorder work of the layout tree might be
affected by a size change of this
specific node
so what that means is that manipulating
things that are positioned absolutely
which is out of the tree is typically
crazy fast because there are no
dependencies on other parts and there
are no other parts that depends on
absolutely positioned knows similarly
changing things like a color or CSS
transform or visibility hidden didn't
cause any real layout it causes a redraw
of this node but the rest of the
documents doesn't change position or
size depending on this node so that's
sufficient on the other hand changing
adding or removing things especially in
big documents in the flow of the
document can be arbitrarily expensive
one thing that's a very important part
of how brush optimize this is that they
reflow a document lazily they try they
don't immediately when a script touches
something they don't immediately
recompute a layout but they mark all the
notes that might potentially be affected
by the change as dirty and then when the
script finishes in the optimal cases
only when the strip's finishes do they
relay out every single dirty note
usually if the script makes a bunch of
changes there's a huge amount of overlap
in the layout work that has to be
repeated so if you only do it once
you're saving yourself ninety-nine
percent of the work one interesting case
here is that scripts can read layout
information for example through
properties like offset top or computed
style that with if you're doing getting
your script you're forcing a layout if
the note that you're reading is dirty so
the worst case is a loop that's changing
the DOM and then reading
layout information from the dome again
it will be forcing a layout on every
iteration and you can make huge huge
time savings by somehow rewriting your
code to not do this to minimize layout
round trips for assembling code mirror
at some point this editor there was code
that was building a line number bar on
the side by I wanted to ensure that
there were enough line numbers to cover
the actual health of the contents so it
was adding an out checking the health of
the line number bar if it was high
enough it stopped if not it added the
next note this could take for a few
thousand lines seconds of freezing the
browser completely by rewriting it to be
a little more clever like checking
computing the amount of notes it needed
in advance and just adding them without
reading it it took three milliseconds I
think so you can really get order of
magnitude increases by by being careful
about it even if it means building up
big data structures to catch some data
that you don't want to read during your
dom manipulation a very important aspect
of drawing is of drawing a dom is making
as much use of the hardware of the video
hardware as possible because in almost
every current machine drawing things to
video hardware is much much faster than
drawing in software this comes starts
with simple things like if you're
drawing something with a blue background
you using the video hardware tube little
blue rectangle instead of letting all
the bits yourself but it gets much more
advanced for example at Mozilla is
currently moving towards I think other
browsers are doing similar things but I
don't know the details is a system that
detects it divides the rendering tree in
two layers wear layers are things that
have a fixed relative position to each
other in regard to scrolling and to
animation so that for example in a very
simple document everything has a fixed
position compared to each other if there
are no fixed background your fixed
elements no internal scrolling diffs
then the whole document is basically one
picture that doesn't move accepts for
script changes or style changes so you
can render this to an off-screen buffer
and then just let the video hardware
blitz as you're scrolling blitz this
buffer at different different positions
and this is probably the fastest way to
do scrolling because there are no round
trips to actual Dom elements happening
you don't need to walk your tree and
draw the elements individually you just
build up this buffer once and I'm bladed
this even works for more complicated
things so you have a fixed background
you're scrolling transparent notes over
that if you create a layer I'm not sure
if Mozilla does this at the moment if
firefox is at the moment but it's
something that they're hoping to do you
can create a layer that's partially
transparent with an alpha channel and
just bleed that over your background
during scrolling which is still a much
much more much much faster than building
up your tree note by note as you doing
your your scroll another thing is of
course 3d transforms see as a 3d
transforms are pretty much defined as
video card operations so you draw your
buffer and then once and then you let
the video card handle the
transformations which is why they are
often faster than 2d transforms even
though they do almost the same thing one
thing i glossed over before is that
before you can do any layout or
is that you need to resolve all the
styles for every note there's actually
non-trivial because there are usually a
lot of styles and a lot of notes and
matching a style style rule against an
actual Dom node is not a trivial
president might require walking up the
Dom tree to ancestors it might even
require backtracking if you have long
chains of ancestor rules the naive
algorithm would be have complexity to
the number of notes times the number of
rules so if we look at some nodes and
rule counts of some popular size you're
saying that if you do an algorithm like
that for example Twitter would require
10 million rule matches um which is
doable I guess 10 million isn't that
much but which would definitely be a
waste of resources so there's actually a
pretty simple trick to to greatly reduce
the amount of raw matches that have to
be done I think most browsers do it I
know WebKit and Firefox do it like that
I expect most do something similar it
involves buckets say you have you index
all your rules after you're loading your
your style sheet by the rightmost
selector of the rule each rule ends up
in one and only one of four buckets if
the right mode selector has a has an ID
then it ends up in the first buckets
indexed by ID it was a class its index
black claws into the second bucket if it
doesn't have closer ID it's indexed by
tag name in the third bucket if it has
neither of this tree then served in the
last bucket which is actually a list
another hash table now if you need to
find all applicable rules for a specific
note if first you check whether it has
an ID if it does you look and
I did bucket for each of his classes you
look in the class bucket you then always
look in the node name buckets for
fetching all the rules that apply to
this node name and you always have to
walk over all the notes in the last
bucket because they can't be
meaningfully indexed this cuts down the
amount of rules that you have to look at
by several orders of magnitude so then
you have to once you've found all
applicable rules you have to sort them
by by relevance by specific specificity
CSS defines that a scoring scheme for
rules we're more specific rules take
precedence over other ones so there's
always some sorting involved is multiple
rules match in general you want to
minimize the amount of rules that end up
in this rest buckets so well did I guess
only pathological style sheets have a
lot of these because you don't typically
define something for all hover elements
or only by attribute selector but I
guess you could do that and yeah that's
something to to be wary of also helps a
lot to use for example the parent
selector the greater than sign instead
of simply the ancestor selector and
social selector requires a walk all the
way to the top of the Dom tree to
determine whether something matches the
ancestor select the apparent selector
only requires a single step but yeah on
the whole my experience is that is
actually pretty rare to write something
that has a serious problem with style
matching on a modern browser that was
all I'd like to answer questions or
receive Corrections or feedback if
anyone has something
work test alone you said that you were
saying that 2d transforms are slower
than 3d transforms okay I'm wondering
why because until he transforms our
layers the same as 3d transforms but
those layers depend on a renderer
implementation right sorry yes these
transforms and how does that apply for
example on Android and the old androids
you have an amateur implementation at
left on top is the same as using
transforms because translate and
translate 3d I only met to those
functions on the render implementation
and I was wondering why you said that
you transfer eyes overall are faster
than everything you guys at fact I've
been wondering the saying I've been
trying to get an answer to that last
night because I figured this question
would come up and I didn't get a
satisfactory answer if someone here
knows I'd love to hear it my current
interpretation is that it 2d transform
requires the actual like polygons the
actual parts of the individual elements
to be drawn in the transforms way being
more precise than drawing them in the
untransformed ynn letting the hardware
treat that as a texture that it
transforms but I'm not sure whether this
is correct ok sorry does ok well I got
the answer but I was only asking for
well I wanted to clear up and 3d
transforms a lot faster on the overall
and they are faster on different
implementations on a GPU layer right and
it depends on how to render itself and
that is running in the background
process the render tree is scared of
course if you don't have 3d hardware and
for example you can use some left top
and Z index which is the pre bleh out
property and its overall faster than
using 2d transforms or 3d transforms
because her they are only the same
function but maps
yeah okay if only wanted to create up
okay hey thanks anyone else guess not
okay thank you for listening</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>