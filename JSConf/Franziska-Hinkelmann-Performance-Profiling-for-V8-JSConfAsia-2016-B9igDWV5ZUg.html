<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Franziska Hinkelmann: Performance Profiling for V8 - JSConf.Asia 2016 | Coder Coacher - Coaching Coders</title><meta content="Franziska Hinkelmann: Performance Profiling for V8 - JSConf.Asia 2016 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Franziska Hinkelmann: Performance Profiling for V8 - JSConf.Asia 2016</b></h2><h5 class="post__date">2016-12-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/B9igDWV5ZUg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so we started off today with GPU
programming and we're now moving on to
compilers nice um my name is Francisca
hinkelman I'm a software engineer on the
chrome v8 team I'm also a node.js core
collaborator and I talk about profiling
v8 I think we can all agree that
javascript is incredibly powerful like
not only in what it can do but also in
how fast it can do it it's amazing that
the JavaScript a scripting language you
can run enterprise note service and you
can run websites with these huge complex
frameworks like a Facebook website or
LinkedIn or YouTube and all that was a
scripting language and the performance
of JavaScript or the possibility to run
such huge applications with JavaScript
of course comes down to the JavaScript
engines the virtual machines that take
your source code and turn it into an
executable machine code make your
website dynamic um so in this start
we'll look at v8 that's the JavaScript
engine in chrome and what it does to
make JavaScript so fast and how you can
profile these optimizations so to put v8
into context the eight is not the only
JavaScript engine the the major browsers
all have their own JavaScript engine we
have check of our core that is in
Microsoft edge you might have heard kind
of talk yesterday we have JavaScript
core and Safari
we have spider monkey and various other
monkeys and Firefox and we have v8 in
chrome if you're familiar with nodejs
that also runs with a JavaScript engine
your default node comes with v8 but you
can also build it with Jack Krak for
electron refer talks about electrons and
status chromium and nodejs
it has a v8 instance and then there's
other engines that are smaller if you
took yun talks there they are very good
for IOT devices because they're much
much smaller they are not as fast as the
big ones but you can fit them on your
little micro controllers so duct tape or
javascript are examples there in in
order to talk successfully about program
about profiling in this talk will look a
little bit of some of the internal key
concepts of v8 so I'm hoping to give you
some insight into this black box um what
we eight is doing under the hood how you
go from source code to really fast
machine code and I'll show you some some
tools how you can profile v8 so not
profile JavaScript on a higher level
that would be probably more useful if
you want the first performance gains but
really down at the low level compiler
level JavaScript engine the the tools
I'm showing you on the one hand they're
tools that we use internally at v8 so if
we want to make it faster if we want to
figure out why something slow what is
slow yeah those are the tools we use and
then we change we ade internally to make
it faster but of course you can also use
these tools to compile to profile your
code and maybe make some changes there
to gain performance if you've used the
chrome dev tools you might have seen
there is a profile tab so you have two
console and you can inspect your HTML
and CSS but there's also a profile
profile tab where you can record
CPU profiles or heap snapshots and when
you do that for JavaScript or you can
also do it for node.js server
application you you start your app you
load your website you start recording
after while you stop it and then you you
get a profile of which functions are
being run a lot so I did this year for
compiling some typescript
you see which function is spent
time being spent on but one thing you
see he unfortunately is this little
exclamation mark which of course means
some kind of trouble in this case the
function is related to gets a warning
from the profiler saying not optimized
and the reason is optimized too many
times so the next 22 minutes I want to
dig into what does this optimization
mean what are we trying to optimize and
why is this not happening or possible in
this case so let's start with some
fundamentals I guess um javascript is
dynamically typed it's not statically
typed like C++ or what you have arrest
it's dynamically typed that means the
types of your variables can change all
the time and the compiler only
influenced at runtime what what kind of
object or type it has it doesn't know
that when I just sees the Swiss code um
here's a very simple example it's an
object defined as an object literal X is
1 and Y is 1 do you know what the
properties of this object are I mean
it's it's very obvious x and y clearly
our properties but are they do the only
properties know this object also gets
all the properties of the object
prototype or if you change the prototype
it would get all the properties of that
new prototype ok so we figure out
properties are x and y and everything
from the prototype chain can the
compiler rely on this information
no because you can at any time delete
properties of an object so this object
that you have can change all the time
and only at runtime can the compiler say
yes it has an X yes it has Y or not and
of course you can also add properties so
this type information is not available
up front it's it's dynamic and the
compiler always has to infer it and so
since Java Script is dynamically typed
what all the modern JavaScript engines
do those that care about performance
those that we use under browsers not
necessarily on the smallest IOT devices
is so-called just-in-time compilation so
we compile as we execute a program in
C++ this is very different if you've
ever done any C++ it is clearly ahead of
time compilation because you actually do
two separate steps you first compile it
and you add a little bit and then you
get an executable that you can run
there's no such thing in JavaScript you
you just run it I mean you might
transpile it first depending what you
use but there's no separate compilation
step from the execution but for
JavaScript because we don't have any
type information anything can change all
the time we need to do just-in-time
compilation
I'm gonna look at this example a lot
it's it's super simple it's a function
that I called load and all it does it's
it's accessing a property you wouldn't
even put that in a function usually
because it doesn't do much but it's just
return object that x given a parameter X
and obviously you do property access all
the time in JavaScript even if you do
console dot lock console is your object
and blog as your property so it's just
everywhere you can't do without property
access and this looks super simple you
have it all the time it looks very
harmless you know what it does but if
you think about it carefully what are
all the things that could happen here as
to return value well as the compiler
tries to get the value object at X um
first of all if you put an undefined as
a parameter it'll throw a type error the
object might not have two property X so
it would be undefined or it might be
that the object itself doesn't have an
own property X but somewhere up the
prototype chain X was defined so the
compiler would have to look up
recursively the prototype chain until it
finds X object might be a proxy so we
have to call it to get handler
and X might have been defined and Eggman
script SiC style as an exerciser script
where you have to call the get function
so you can have any kind of arbitrary
side effects so for the compiler this
very simple object at X is is a lot of
stuff it has to worry about um this is a
snippet from the ACMA script
specification don't be worried about
reading all this but this is how the
ordinary get us what they call it is
define and you can tell this is quite
involved for just a tiny little object
that X down here so since we have
property accesses everywhere on the
program we eight needs to do a little
trick because we can't afford to do
these steps every time you do a console
that log or any kind of access so let me
show you what you do so here's the
simple load function and we call it with
this very simple object that is just a
regular object no changes on the
prototype chain it has one property X
and it's an integer so when we when the
compiler encounters is this call of load
well we do implement correct atmosphere
JavaScript so the compiler has to follow
these steps on a specification which is
quite involved and eventually it figures
out okay it's a value to script I have
to return this value which is at a
certain offset of this object okay so we
found object at X and now what we do is
we cache this information and what we
are caching is we're caching for these
kind of objects this is how you get the
value so we're not caching that specific
object and the 5v caching objects that
look exactly like this simple literal in
this case we know the value for X is at
a constant offset to our object so
that's some v8 internal that we know
where it's stored but but we know any
object that looks like this so just one
property it's called X and it's an
this is how we get to the value if we
needed and we associate that cash with
the call with this property access so
when we later in the program called load
again we're calling it now as a
different object this one has the object
X is 17 and not 5 but they look very
much the same if you think about the
shape of these objects so when we do
this again and we get to this property
access um well we're being smart now we
check the cache first to see if maybe we
have already figured out how to do that
um and we realize yes we have exactly
these kind of objects we have an entry
full objects that look like this in the
cache so let's just get the offset
because that is where that value is and
we Furr can forget about these 10 steps
that otherwise we'd have to do ok and um
these caches the the former name is
inline caches we shortcut them to ICS
so if you have a look at the 8 source
code there's a lot of ICS everywhere you
have an IC associated to every property
access not to the function or the object
but every single access so in this case
you have two completely separate inline
caches for both these lines even though
it looks the same and it's the same
function and what you store in an IC is
the keys a shape of objects and the
values are the fast path how to get that
value so in our case we're storing what
the object looks like and we had to get
to 5 or a 17 over my axis and when I say
shape of objects internally we call this
map of an object and sometimes it's also
referred to as a hidden class so since
JavaScript doesn't have classes or
didn't have classes until es6 those are
very different we call it we give
objects internally such a hidden
internal class ok so this is one way how
we speed up the aid to do property
accesses faster that would not be
yet to have a reactor immigrant in any
reasonable time what what any modern
compiler has these days is at least two
compilers a basic one and an optimizing
compiler in v8 we have actually two
optimizing compilers at the moment the
referred to as crankshaft and turbofan
if you've ever come across that um and
so how that works is when you first run
your program the basic compiler is
trying to compile your code very very
fast but too very naive machine code so
it might not be super fast when you run
your first executed but after a while
the basic compiler says well this
function here that is executed all the
time we should really speed this up into
better machine code so the optimizing
compiler takes over and recompiles a
so-called hot function into better
machine code so you have more work
because you have to recompile again but
you get much much faster codes when you
run it a lot it's worth it
and so if you combine optimization with
these inline caches that's where you get
a big big jump in in speed okay so I
hope you still with me it's early um if
if I lost you a little bit now would be
a good time to get back um I'm gonna
show you no actual machine code for a
simple function like that so think about
it you write JavaScript source code with
cool frameworks and lots of stuff and
everything's changing all the time
everybody can put modules up but when
you compile it you get down to machine
code that's basically the same for
decades and I think it's really cool to
see how like the the high-level stuff
what it ends up with in in machine code
um so just to recap
the JavaScript engines they compile
JavaScript code down to machine code and
I want to show you some machine code now
still for this load example so this year
is optimized for scene code for the
simple load function that returns object
at X and it might look like a lot I mean
it's a full page of code but for like
low-level machine code this is really
not much and I'm gonna show you what it
actually does so up here it says um call
stack check this is where we entered a
function we just have to make sure we
don't have too much recursion recursion
and we can still have space on the stack
so this is where we start the function
the next thing we do is a check nonce my
sews my is the aide internal language
for a small integer we distinguish
between small integers or objects on the
heap anything that's an object must be
on the heap if it's if it's a smile you
can check the hidden class of it or
anything so this is just a backup check
basically making sure we we do deal with
some kind of object internally and now
the what the function should do now is
get object that X and return that so
what we do in this optimized piece of
machine code is a so called
check maps and I said map is our word
for internal class or the shape of the
object so what this optimist machine
code is doing now it's comparing the two
maps of the parameter that you passed
into the function so that object has a
map it's comparing that to the map that
we saved in the inline cache when the
basic compiler ran this before and if
those are the same just like in our
example before if those are the same
then we can do the cheap fast property
access which in this case is a load
named fear you know I'll just load this
field at the specific offset and be done
with it return it now if those map
checks
if if we call the load function with an
object now that looks very different
then the map check would fail we don't
have the same as that what we had on the
cache and we have to jump when we end up
down here which says the optimization
bailout so you run your code you fill
your cache eventually you decide let's
make really fast machine code you use
the information from the cache to make
this machine code like it's hard-coded
in there it says check the map at
exactly this address and now when you're
running this code when you put objects
in that are very different from what you
are expecting from something you can't
handle in the inline cache then you end
up in addy optimization so that's where
the optimizing compiler says I can
handle this and you go back to the basic
slower compiler okay so um I said here
we make one map check because we had
exactly one object in our cache so we
only compared to this one object um
that's why we distinguish different
states of inline caches so we have if
there's exactly one entry we call them
monomorphic if there's a handful like up
to four entries we call it polymorphic
and anything more as mega morphic and if
you want if you can you want your code
to have mostly monomorphic
or maybe polymorphic caches but avoid
the mega morphic um so here in this
example that I just showed you there was
one map check because the cache that we
assumed the cash was monomorphic if our
cache is polymorphic and then we
generate this optimized code um it would
look like this which is exactly the same
except that it has four map checks in
there we would compare against these
four entries that we have in the cache
now if it's mega morphic we can't keep
going on with all these branches and we
have to do computationally more
expensive things so that's why you want
if possible always objects of the same
shape
at the property accesses so same game as
before we are checking but if it matches
one of the entries in the cache then we
can just fast jump and return if it
doesn't match any one of them we're back
to this deoptimization
okay
and um you can actually try all of that
you can just take chrome that you have
anyways and if you started from the
command line be behind chrome just put
this flag - those J's Flags equals and
then put the v8 flags that you want so
for this case if you put print opt coat
print optimized code you can also do a
print code comments that gives you
exactly this output so you start Chrome
put this behind it open a website and
your console will go full with like
output like this oh these flags okay so
we care about what the state of the
inline caches is and if you want to dig
a little deeper in what's going on in
your application we have a nice little
tool for it ice the icy Explorer wenjian
where you can explore the states of your
inline caches you generate the output
like I just said put the flags behind
chrome and then load the file here and
you can group your inline caches very
nicely by different keys you really do
want to use this tool not just the
editor because here was compiling some
type script and it's a million entries
this is very nice if you get this
grouped for you you can sort by
different things like here for example I
sorted by a code location and I drill
down on the function that I saw earlier
that had the exclamation mark so I can
see exactly okay what is happening at
the property accesses in this function
so nice little tool to see what are the
inline caches doing because they affect
the speed and the optimizations there's
also a nice overview if you want to see
which functions are actually being
optimized that micro
kyla and any functions d optimize if you
do tres opt and trace d upped you get
this information so here if we run an
example that calls load eventually if
you run it often enough you'll see
optimizing the function load so the
optimizing compiler recompiles it
generates machine code similar to what
we just saw and then if you keep calling
it and eventually call it with very
different objects you will see D
optimizing evicting entry from the code
database so what's what's happening here
is um in this optimize machine code that
I showed you when the map check didn't
work out we jumped all the way to the
bottom and said bailout the optimization
and what we aide is doing here it's
deleting this optimize code because it
figured well we optimized it but it
doesn't quite work so we throw it away
we start over with the slow basic
compiler for this function again so you
don't want to see this too much when you
profile your app because it slows it
down so back to this original problem
where we saw the exclamation mark
warning not optimized optimize too many
times um now we have a better
understanding of what's going on here
we have this function is related to
there are things like property excesses
in it we run this function with the
basic compiler we put entries into our
inline caches and eventually we optimize
it using the information from the inline
cache but then we run it with stuff that
doesn't match what's in the cache and we
D optimize it and we run it again and a
slow compiler eventually say oh let's
optimize it again and then we do this
ten times and eventually the compiler
says no point in optimizing this because
generating the optimized code of course
costs performance let's just not
optimize this function anymore I give up
so this is where this exclamation mark
comes from and so by by looking at the
CPU profile looking at the inline caches
looking at optimized machine code
so non-optimized code and looking at the
original JavaScript code it's possible
to figure out what kind of changes to
make to get rid of this optimization the
optimization optimization do you have to
mutation thing so when you make those
changes you profile again you don't get
the exclamation mark anymore
okay um general warning as always with
optimizations be very very careful only
optimize if you really must if you have
performance problems and then if you do
optimize make sure you really measure
and find your bottlenecks don't blindly
optimize don't say oh I've heard
something about optimizing compilers
gonna start changing because here I can
tweak and in my cache or something you
just introduce bugs and make your code
really hard to maintain that's just the
usual optimization um but in this case
specifically I would almost advise
against optimizing for things like that
because those are v8 internals they're
not agreed upon by the ACMA script
committee to be like this and they
change internally like every commit that
we make every canary version you get
every night things might have changed we
might have figured a better way to do
something so when you did micro
optimizations for something that is true
today it might actually be negatively
affecting your performance tomorrow and
then obviously it's just we ate the
other JavaScript engines work very
differently so if you write your
JavaScript code in a specific weight and
they're only faster and this one engine
but probably not in the other engines so
I hope I was able to give you a little
bit of an insight into this black box of
JavaScript engines what they do from
source code to really fast machine code
if you want to play with any of this
yourself and see what uh what's my app
doing in general or what a little code
snippets doing you can always just use
chrome started from the command line - -
- J as flag
equals and in some things we looked at
was a trace of trace deopt print opcode
or trace I see if you're familiar with
node you can also start a node server
and put the v8 flags here just put them
right behind node and if you were more
adventurous you can compile a v8
yourself and get d8 then it's the v8
debugging shell and run that with all
the flags um if you use d8 you have the
advantage that you don't get the
overhead of things that happen in the
browser or things that happen in node
before your function actually starts up
and if you want to explore your inline
caches the ICC Explorer is distributed
with the v8 source code there's a link
to it um if you have any questions or
feedback or performance questions please
find me during the breaks and feel free
to reach out with Twitter or email thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>