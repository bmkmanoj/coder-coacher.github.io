<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Jonathan Martin: Async patterns to scale your multicore JavaScript elegantly. | JSConf Budapest 2017 | Coder Coacher - Coaching Coders</title><meta content="Jonathan Martin: Async patterns to scale your multicore JavaScript elegantly. | JSConf Budapest 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Jonathan Martin: Async patterns to scale your multicore JavaScript elegantly. | JSConf Budapest 2017</b></h2><h5 class="post__date">2017-12-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/726eZyVtC0Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning thank you for coming out to
my session on elegant pacing patterns
and different functional programming
techniques you guys can use right now to
help scale your JavaScript up to
multiple cores if that sounds a little
bit crazy and you're thinking wait a
minute javascript can't even do this
hang tight
we'll get there so I'm Jonathan Martin
or you can find me at nibbler on the web
one of the awesome calligraphy artists
do this and spell this out so if you
haven't already checked out their booth
by the way you should check it out
they're really really good at what they
do and I'm an instructor in web
developer for a consultancy in the USA
it's called big nerd ranch big nerd
ranch develops web and mobile apps for
our clients and we also teach developers
to do the same through intensive
five-day Bute camps mostly in the US and
then also we fly out to many of our
clients around the globe we also teach
developers to our best-selling
programming guides so maybe you've seen
some of these before especially in the
iOS and Android space and we have a
front-end web development guide as well
outside big nerd ranch I'm also a
digital nomad which really just means
that I leverage technology to work from
anywhere in the globe
so some of these areas might be where I
might be working any given day this
isn't quite the norm yet I'm working up
towards this so over the last three
years this lifestyle in particular has
really helped me to nurture my love for
landscape photography so if you don't
like JavaScript or multi-threading which
seems unusual since you came to a Jay s
comp you can go look at pretty pictures
instead for now I'll assume that's not
the case since it is a Escom so when I
was accepted it comes to speak here at
Budapest I was pretty excited so I
started to piece together my travel
plans for speaking here in Budapest I'm
slightly obsessed with the two to-do
lists so I started listening out the
things I need to complete before I could
give this talk in Budapest of course I
need to fly out here be a little bit
hard to give it over hangouts internet
connections in Alabama are the slowest
in the u.s. also I'd need to put
together a slide deck so I need to work
on those I'd probably need to get packed
for the trip I just some phone calls I
need to make before that true
and probably on the flight I should read
a book and at least some time before my
session I needed to take a shower so
lists are great and but to really start
knocking out leads to dues of course you
need to figure out well what order am I
gonna do these in what's gonna be my
plan for completing these so I could
just naively go from top to bottom and
complete them one by one in that case I
probably would have never made it out
here since I didn't actually have the
slide deck finished until a few minutes
ago so I probably would never have flown
out here and so I wouldn't be here so
that's one strategy I could use I could
go from top to bottom finish these one
by one but we're human we don't actually
finish things this way we tend to do
more than one thing at a time so for
example some of these things could
happen at the same time you know maybe
on my flight I could work on my slide
deck if I was able to stay awake for
that flight so if I were smarter when
writing my to-do lists maybe I could
encode constraints and preferences so I
could better plan how to tackle this
really onerous to-do list for example I
could encode my constraints as arrows
which show that some things logically
have to come before others for example I
have to pack before my flight and I have
to fly before I can speak I also have to
work on my slide deck but really that
can happen any time before I get my talk
so long as it happens before then I
could work on it before or after my
flight now some of these things also
can't happen at the same time for
example I can't make a phone call while
I'm on the plane and I can't read a book
while I'm in the shower as awesome as
that sounds together these describe my
constraints and preferences for how I'm
going to get ready for my Jas comp talk
software also deals with to-do lists of
its own and the problem is twofold we
need a way to model constraints and
preferences for how work gets done and
we need to figure out the optimal
solution that satisfies all those
constraints and preferences and the way
we solve these two problems is a
defining characteristic of many
different programming languages
including Java Script now before I hop
into the body of this session I want to
recap some terminology briefly
in particular we're going to toss around
the terms concurrency and parallelism
parallelism excuse me
concurrency just means that two or more
computations have overlapping timelines
with each other in terms of execution so
for example task 3 begins before task
two and task 1 but before task 3
completes task 1 and task 2 will already
begin computing so that's what I mean by
overlapping timelines now how you
achieve that concurrency is really up to
you there's a lot of different
strategies you could use one example is
you could switch really quickly between
working on these three tasks so in
particular and software we could use
multi-threading to do this a single CPU
core can really only do one thing at a
time but by quickly switching we could
have these overlapping execution
timelines context switching makes it
seem like we're doing three things at
the same time even though we aren't
there's another way we can do this we
could have three separate machines or
CPU cores and dedicate one core per task
this specific form of concurrency is
often called parallelism
so to summarize concurrent programs can
run multiple pieces of code
independently of each other and
multi-threading and parallelism are just
two execution strategies for running
code concurrently so how we write our
code our choice of style isn't really
going to very much based on our choice
of do we write it in parallel or
multi-threaded so for this talk
I'm not going to distinguish between
them I'm just going to collectively
refer to it as concurrency so after this
point you don't have to remember any of
those crazy things we're just always
going to talk about code being
concurrent which just means two or more
things to our more functions perhaps are
running at the same time now some of you
gave me a funny little wink when I said
something about multi-threading in
JavaScript in the same sentence
so note in front-end developers alike
are commonly trolled by the classic
question how do you scale a JavaScript
code base since it's single threaded a
little bit of a loaded question but in
fact not only is it multi-threaded
javascript is highly concurrent by
default Thanks
to the event loop but it shields us at
the same time from many of them
multi-threading woes and synchronization
primitives you might be familiar with in
other languages like semaphores mutexes
locks etc so for example each of these
web api calls seamlessly fires up a
separate thread for a total of four
threads you have the main Orchestrator
thread which is where you write this
code and then you also get these three
others in the background for free that
are powering these different api's so
how on earth does that actually work if
javascript is multi-threaded how is it
that everything seemed like you is
running on one thread which means that
there's only one call stack and there's
one thing happening at a time so how can
you write your code in such a way that
it looks like it's singles write it but
it's actually taking advantage of
multiple cores well that's where the
event loop comes in now in 30 minutes I
can't actually do full justice and
explaining the event loop so let me just
give you a quick recap and just keep in
mind that I'm lying to you quite a bit
so it's grossly inaccurate I'll forward
you guys to a slightly better
examination of the event loop near the
end so in the middle of this slide we
have the call stack and the call stack
just helps us keep track of what is
currently executing you might think of
this and if this is your main javascript
file and the pages just started up you
might think of this as the main function
if you have a callback executing then
you could imagine that callback is on
the call stack so on the far left we
have the built-in web api's
and these are natively implemented for
equivalency this could also be the node
api's node works the same way it also
uses the event loop and then finally on
the far left we have our source code
that we've written we've loaded into the
browser and now we're going to start
executing it so the first line is
performing an ajax request and it
executes a function called parse once we
receive an ajax response second we're
using the set timeout api to schedule a
refresh function to run in about five
seconds or so and finally we use the
indexdb api to make a database query and
invoke a function called render once
that query has completed so how is the
JavaScript runtime actually going to go
about eval
awaiting this code some of these
operations for example will take a while
in Ajax requests might take a few
hundred milliseconds or it might take
several seconds depending on the
connection yarn so javascript is going
to evaluate these in a very specific
order and so let's just to build up our
understanding of the event loop we're
going to walk through this ourselves so
as soon as that fetch function is
invoked you can imagine that that's
currently on the call stack and it fires
up a natively implemented web api in the
backgrounds but it doesn't just fire up
the fetch API it also passes along a
function or callback to invoke once that
fetch API receives the Ajax response now
while that fetch Web API is running in
the background
the runtime will advance to the next
line and go ahead and execute it without
waiting for the Ajax request to finish
this is how we think of asynchronous
coding in JavaScript the set timeout API
also fires up a native web the API and
passes along a callback to execute once
the time is up it's a very similar
behavior so indexdb works exactly the
same way it fires up a native web api
and it passes a callback to execute - in
the indexdb web api so now what we're
out of source code to execute there's
nothing on the call stack in most
languages this would mean that your
program is dead it's not running
anything however we do have those native
web api is still crunching some code for
us in the background and so let's say
that when the index DB query finishes it
will alert the JavaScript runtime by
pushing that render callback we gave it
on to a queue it's very imaginatively
named the callback queue now this
doesn't yet run our render function so
the event loop is actually just a
mechanism that checks to see if there's
anything currently running in other
words is there something in the call
stack and if there is something in the
callback queue if there's nothing in the
call stack and there's at least
something on the combat queue the event
loop will pop off that first callback
off the queue and push it onto the call
stack which means that now our render
function is executing now while that
render function is executing it could
take a while another way
I might finish its background work
perhaps our Ajax request so that web api
will immediately push the parse function
onto the callback queue however this
time there is code already on call stack
being executed
so that parse function is actually just
going to stay in the callback queue this
behavior is called run to completion it
guarantees that the currently executing
function will not be interrupted by
another callback which in a nutshell
means you don't have to worry about
thread safety now when that current
function on the call set takes a long
time to finish this is what we call
blocking the event loop you can just
imagine that if the event loop keeps
trying to figure out hey can I push
something can I push something yet can i
grab one of these callbacks and start
executing it it's blocked until the call
stack is empty now during this time our
timer API might also finish and it just
pushes the refresh function onto that
callback queue and waits to be executed
once that render function finally
finishes executing the call stack is now
empty which means that the event loop
can pop the first callback off the
callback queue and push it onto the call
stack which means it's being executed
that's what's currently being executed
and of course once the parse function
finishes the call SEC will again be
empty so we can push that final refresh
callback and then execute that to
completion so in summary while our own
JavaScript code looks like it's single
threaded and in a way it is actually
single threaded meaning there is only
one call stack and only one function
running at a time the native background
Web API is that powered JavaScript can
be executed on separate background
threads seamlessly it's not even
something we have to think about now not
all of the async Web API s use separate
threads but the mental model holds and
it helps explain why no js' and
javascript in the browser can perform so
much work concurrently while appearing
single threaded makes it very easy to
reason about again this was a highly
inaccurate version of this I hope that
sets the stage at least for the rest of
the session but you owe it to yourself
to watch Phillip Roberts
talk on the subject it's called help I'm
stuck in an event loop
you can check out this link bitly event
loop help really great talk and it's
only 20 minutes so the event loop is
great but in nodejs you can pretty soon
hit a scaling limit with a single
process despite the many background
threads so at this point many developers
typically turn to something like nodes
cluster module or PM 2 but turning to
multi-processing 2 soon
negates many of the single process
benefits we enjoy and the predictability
of having a single call stack in
JavaScript now luckily a single
JavaScript runtime thread can actually
orchestrate an amazing amount of work
but to write code that all that will
scale easily and doesn't look like a
bunch of promise dot all spaghetti will
need to exercise a few patents so in the
remainder of this session we're going to
cover these three different patterns and
recipes that you can use both in your
node.js and your front-end web
applications to write scalable
performant code that remains elegant and
actually scales to multiple cores we're
gonna do that also without any
third-party libraries no frameworks or
fads just plain old JavaScript yes
2017 specifically so the first pattern
is coordinating concurrency with async
if ease you probably haven't all heard
of and seeing if ease so async if ease
should bring up some interesting ideas
so when you do more than one thing at a
time you usually need some ugly
pipelining to describe how those
different tasks are related to each
other so here's a concrete example let's
say we're building iTunes in the browser
and we're beginning to write the code
for importing mp3 files into our music
library in the browser the user might
import these files by dragging and
dropping them into the browser this is
not a theoretical app by the way all the
technology for this exists if you're
interested I'll show you guys a demo of
basically iTunes in the browser and
working with mp3s some cool blog posts
and stuff so we might imagine if we're
writing this mp3 importer there are five
steps to import a song first we need to
read in the mp3 files contents we might
have a file object and so we might need
to read that in to some sort of binary
data type enjoy
script then from that we might want to
parse out the song's title the album
name and some other useful metadata in
most mp3s this information is encoded in
the beginning of the file it's a format
called ID 3 if you're interested in how
to parse that data and working with
binary data in JavaScript check out the
blog post it's bitly slash mp3 - parser
now unfortunately id3 metadata doesn't
usually include the songs duration so
we'll actually need to calculate
ourselves and we can do that using the
web's audio api and once all that
metadata is extracted we're going to
auto create a new album in the database
if one doesn't already exist by that
name and then we'll finally create a new
song entry in our music library using
all the information from those previous
four steps so my first solution when I
was coding this up looked roughly like
this very much the code corresponds
exactly with those steps we read in the
file in this case we're reading it in as
an array buffer which is JavaScript
binary data type and then we parse out
ID 3 metadata this is a library of god
on github you guys can check out and
it's just using a lot of those binary
files and then we're calculating the
duration using some audio api's in
particular this is audio context and
then we're creating entries in the
database for the album and then for the
song now you'll notice that async and
await makes this code really nice we've
got a lot of asynchronous stuff
happening here and all we have to do is
put in a weight in front of every line
that would return a promise this gets
rid of all the dot then callback so this
looks really nice there's a problem
however we're actually blocking too much
anytime you see a weight just realize
that no code below that away will
execute in other words we're kind of
hamstringing JavaScript's pattern of
just going line by line by line without
pausing for a breath so unfortunately
we're actually forcing more things than
necessary to execute one after another
when in reality they could be executing
in parallel or I should say concurrently
but if we wanted to execute some of this
code concurrently you know
squint at this and try to figure out hmm
some of these things yeah they can run
in concurrently but to do that you have
to sacrifice those really elegant awaits
here's one way we might do that we could
use promised doll to block further code
until the file reader and the parser
have finished before computing the
song's duration or importing in album
not only does this uglify the solution
quite a bit but more disturbingly it's
still a suboptimal solution if the file
reader for example finishes before the
parser there's no reason the import
album couldn't already begin doing its
work the problem is it takes a fair
amount of work to figure out the optimal
grouping of which tasks can be run in
parallel and any time you switch any one
of these steps from asynchronous API to
an async one it completely changes that
optimal solution which means you're
going to have a lot of code sharing
you're gonna have very large get discs
so luckily there's another way that we
can model these kinds of concurrency
relationships so what if we modeled each
chunk of code as a dependency graph for
the runtime to evaluate just like we did
with my to-do list for coming to speak
at J's conf to accomplish this we're
going to use a pattern called the async
immediately invoked function expression
it's an elegant pattern for managing
concurrency on a single thread now most
of you have probably already seen async
functions something to keep in mind is
that in async function when invoked
always returns a promise no exception
even if there's an error it's just
returns a promise that rejects so the
return value from an async function
invoked is always a promise so in async
if e is just you creating an async
function an anonymous one and you invoke
it so the async Afiya allows us to group
together sequential code into a single
unit we might call a task and then
immediately invokes it a task can depend
on other tasks as a source of input but
it produces a single return value as its
output which means that this async if e
is going to return a promise that
resolves to the results
now the task local variable that you see
is also going to be a promise so if
there's one thing you should take away
from this talk it should be the async if
you design pattern it kind of resembles
a task in a task runner like a gulp like
gulp or a makefile
so if it helps you can think of async
appeases sort of like those different
tasks in a task runner now if we
refactor our mp3 importer code into
multiple tasks here's one way we might
break it down so first when we read in
that file this just returns a promise
just for naming conventions I might call
this the read task and then the meta
task would just run that parsing code
now you notice in every single one of
these tasks all these operations depend
on the very previous line in other words
there's no line in any of these tasks
that doesn't depend on everything before
it we've tried to separate that out into
these small chunks now each task is an
async iffy so it returns a promise which
evaluates to the functions return value
at the very end the thing that kind of
kick starts this process is when we're
awaiting the song import task which is
sort of the top level task that calls
all these others so with multiple tasks
we're just leveraging local variables
and concurrency by default to
essentially create a dependency graph
which the JavaScript runtime will
optimally evaluate for us no matter how
complex it is so if we were to break
these down you could imagine that this
is the dependency graph that we've just
modeled but we didn't actually have to
type this out ourselves we didn't have
to explicitly define that execution
order just by wrapping sequential chunks
of code into a sink if ease we modeled
the constraints and let JavaScript
figure out how to satisfy those
constraints again there's tons more to
the async if you pattern so definitely
check out this blog post to learn more
bitly slash async - if II leave that up
just for a moment so our second step to
creating elegant scalable code is to
define execution preferences async
ephese allow us to define those
constraints how things have to execute
but a lot of times you
to say how would we like these things to
be executed how would we like to
prioritize them in particular how could
we throttle how many things are allowed
to run concurrently with functional
programming so our mp3 importer right
now runs as fast as possible which is
fabulous
but this is a browser so we need to be
considerate of the CPU which is after
all a limited resource so a syncope has
led us to find those execution
constraints how could we declaratively
define our preferences for how that work
gets executed on the CPU for example in
our application if a user drops in a
very large collection of mp3s by default
we might either import all these songs
one by one which is not so cool or we
might import them all at once now your
solution is great in particular if we
started importing all of them at once
we might get this really irritating
progress bar behavior like this where it
jumps from oh I'm importing the first
one and then 20 seconds later it jumps
all the way to the hand since all those
songs started importing at the same time
the progress bar is basically
meaningless to the user and it will
often lock up the browser also not great
so instead what if we said well we only
want to import a few songs at a time and
then we'll queue up the others for
import once another song finishes
importing so only importing a few at a
time so in many threaded languages you
can accomplish something like this with
semaphores semaphores are an object that
represent a limited resource and you can
acquire and release access to it to
basically throttle how many times or how
many people are trying to use that
semaphore so for example the CPU is an
example of something a semaphore might
represent it could be a database or even
network i/o at their extreme we could
limit it to one client at a time which
we would call a mutex now in an
object-oriented paradigm we could
initialize a semaphore object with the
maximum number of concurrent clients and
use a wait to acquire a spot in the
queue before we execute our code and
then once a spot opens up we do some
things
and we release our spot so another
client can execute some code so here's a
sample object-oriented solution to
creating a semaphore and it just tracks
functions that are waiting to be
executed and whenever a spot opens up it
executes the next function in the queue
so this is very standard cs20 101 type
solution you would probably write for
semaphore unfortunately there's some
really brittle boilerplate with an
object-oriented solution for a semaphore
in particular we could easily write code
that will acquire a semaphore but never
release it
perhaps we throw an exception which will
blow up the rest of the function so now
that some before will never be released
so instead here's a functional
programming version of that same
semaphore and instead of returning an
object it's going to return a
higher-order function that wraps up
other functions with a call to acquire
and release so you can almost think of
it as it I can take any function and
I'll prepend it with a choir and then
suffix it with dot release so use this
functional sum before we can invoke it
with an async function now there's no
way a semaphore can be acquired but not
released now we're actually only one
step away from turning this into a
really elegant higher-order function
that doesn't even force us to think
about semaphores at all so let's suppose
that we want to limit how many times our
import mp3 function is called and we
want to limit how many times it can be
run concurrently so in other words if
you call import mp3 four times right
after each other say we only want to
allow two instances of that function to
run at a time and then it would delay
the third and fourth invocations until
there's a slot left until one of those
first two invocations is finished so we
could think of this function we might
call it limit we could think of it as a
decorator or higher-order function and
it takes an async function that usually
runs with unlimited concurrency and it
returns the same function but now
composed with throttling behavior so
this example would take our mp3 importer
function and return a new function that
looks exactly the same but only allows
two instances
function to run concurrently so in this
example song 1 and song 2 will
immediately begin importing but song 3
won't even begin importing until song 1
or song 2 finishes meaning there's a
slot in the semaphore the limit function
it turns out is really easy to write
with a semaphore we built it's just
three or four lines of code but the key
takeaway from this is that instead of
focusing now on managing this abstract
semaphore object we're focusing on
creating functions with new throttling
behavior it's really elegant and cuts
down on potential bugs from trying to
share a similar object throughout your
codebase and it preserves your existing
API so that way if you want to throttle
concurrency in your codebase you don't
have to refactor your code or change any
of your api's again there's a whole lot
more we could dive into here so feel
free to check out the source code in
particular for the semaphore if you want
to play around without a bit on github
but the final component of this talk is
how can we create our own long-lived
async tasks with a web worker cluster so
what do I mean by this
so the browser comes with a huge
selection of async api's that we use all
the time
these api's are natively implemented
there's not JavaScript code behind in
Ajax requests so for example the fetch
on index DB abis are all natively
implemented and they use promises and
other asynchronous mechanisms like
callbacks now under the hood the browser
handles this by managing a dedicated
thread pool that's ready to crunch those
async api's for you whenever you try to
use one of these async api's but what if
you could create your own how would you
create your own native async api's for
your own long-lived async operations
that maybe they take up a lot of time
and you don't want to block the main
thread
for example maybe we want to move our
mp3 importer off the main thread which
is also rendering the UI maybe we want
to move it to the background so that way
it won't lock up the UI if it takes a
particularly long time to import some of
these mp3s
well web workers are essentially that
there are standard web api for creating
background threads so to create a web
worker we just invoke the worker
construct
and give it the path to the JavaScript
code that will execute with its own
dedicated scope and with its own event
loop it's completely isolated from your
main thread now to communicate with a
worker you can only exchange messages
this is a really important concept those
of you have maybe tried elixir or some
of these high concurrency high fault
tolerance type languages are probably
already familiar with this concept of
exchanging messages basically it means
the worker must be listening for that
message and handle it as part of its own
event loop cycle so in other words
messages are received asynchronously now
the main thread and the worker thread
don't have to both block to exchange
that message they just send and check
for messages whenever they're ready to
now the basic web worker API is not
exceptionally elegant if you want to
have a two-way conversation between the
worker main thread it can really quickly
turn into this really ugly callbacks OOP
so what if web workers looked more like
an async web api call where we invoke it
and we get a promise in return that
resolves to the workers end result that
would make it really trivial to move CPU
intensive computations to a separate
thread so we don't end up walking the
main thread so you can imagine there's
probably a lot of use cases for this up
until cryptography was added to the
browser standards cryptography would
have been a really common use case same
for doing any sort of 3d graphics maybe
game rendering maybe you'd like to move
these to the background off the main
thread but you don't have to completely
rewrite your code base to take advantage
of it so in particular we're going to
take our mp3 importer and move it into a
worker and treat it as though it were a
natively implemented async web api to do
this we're going to create this
mysterious cluster function to make the
web worker API a little bit more elegant
for our use case and cluster is just
going to spin up a bunch of web workers
in the background for us and these web
workers will handle the task of
importing mp3s so a functional
programming the implementation for this
cluster is actually really terse so this
code has a lot of stuff at the beginning
basically it figures out what's the best
number of web workers to use usually
that's how many virtual cores you have
so it creates these different workers
and it put
some in an array to keep track of it's
basically a pool of workers and each
time we try to invoke that cluster it
grabs a worker from the pool that's
currently unused and it forwards along
some data so this would be us invoking
cluster we pass some argument those
arguments get forwarded to the worker
once the worker finishes and replies
with the result
it adds itself back to the pool to say
hey I'm not currently working on
anything you can use me for a different
computation and the overall promise will
evaluate to that result the code for the
web worker itself is really short it's
an infinite loop that just receives data
from the main thread it does some work
and then it notifies the main thread
when it's done with that computation by
the way this isn't just for the browser
you can use a popular facade library to
write web workers in node as well with
the same API and under the hood it uses
native multi-threading so this isn't
just for the front-end browser so you
could imagine moving all kinds of CPU
intensive operations with just a few
lines of code you can actually get with
fewer than this if you write a little
utility function you can imagine moving
all of these into web workers so a
little bit long time so the TLDR from
this really is that javascript in the
browser and node.js is highly concurrent
out-of-the-box so things like async
appease can help us define those
execution constraints thanks to the
event loop we don't have to even worry
about thread safety or re-entrance e or
a lot of these other things you might be
familiar with with language like C or
Java and functional programming patterns
keep us from making a mess of things
just for the sake of that threading it
all happens pretty seamlessly for us and
if there isn't an async Web API for
something you need maybe its 3d graphics
related or cryptography related just
write your own web worker and treat it
like a native async web api
so next time you're told just remember
you can always bet on JavaScript to help
you leverage multi-core machines and
crunch there to do loops through to-do
lists so you won't soak your favorite
book in the shower like I did so
my timeshare on this room CPU is up so
if you like pretty pictures and travel
stories you can hop to my landscape
photography site yellow scale.com or you
can find me on twitter as at nibbler
thank you so much for your attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>