<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Iliyan Peychev: HTTP 2.0 and QUIC - protocols of the (near) future | JSConf EU 2014 | Coder Coacher - Coaching Coders</title><meta content="Iliyan Peychev: HTTP 2.0 and QUIC - protocols of the (near) future | JSConf EU 2014 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Iliyan Peychev: HTTP 2.0 and QUIC - protocols of the (near) future | JSConf EU 2014</b></h2><h5 class="post__date">2014-10-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qyexqwG6fGI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody my name is Jillian I am
working a software engineer for a la
based company called by frame and today
I will talk about HTTP two dot zero and
quick protocols of the very new feature
which will replace the protocol which is
currently used by world wide web HTTP
1.1 so first is that question why do we
need a new version of HTTP protocol what
is wrong with the protocol after all
it's used by world wide web since 1990
right it's it works pretty well it's
very simple actually browser sends a
request to the server and server
response this is it very simple but if
you check this chart which which is just
for four years you see that there is not
only one request and one response there
are actually multiple requesting
response about 80-90 for the top 100
sites according to HEV archive so this
comes to tell us that the web has
changed drastically it's a web platform
it's not more platform form for reading
different cross linked documents and
because of that we have to admit that
HTTP 1.1 has issues those issues are so
big that unfortunately we need a new
version of the protocol and those issues
are so many that i will mention only
three of them the first one is that it's
very lotensin sensitive right imagine
that we have a server in LA and our
client is right here in Berlin all those
requests should go
from Berlin to LA then get back this is
very expensive and rotten see and
protocol is very latency sensitive right
apart from that the specification is
huge the original specification has been
replaced by about 10 different fc's for
message syntax and rotate for semantics
in content and so on there are optional
parts like HTTP pipelining which are
sometimes implemented sometimes they are
not and more like buggy proxy servers so
this is the key what and secures and
bandwidth is not everything if you check
this chart from I guess most of you are
very well aware of it already on some
point how fast is your net is your
internet at home for daily browsing
doesn't matter if you have about five
megabits it's pretty much enough i'm not
talking about streaming of watching or
downloading huge video file for daily
browsing what matters is the round-trip
time it for every 20 sec 20 milliseconds
as you see the page loading time
increases so we are stuck by latencies
what could be solution it's obvious that
sending one requesting more turnin
response is not enough so what could be
the solution one possible solution could
be HTTP pipelining Right since that's
exactly its purpose instead to send one
request to the server and waiting for
the response browser sent three or more
requests in waiting for three or more
response sounds very good in theory but
fortunately it's not like this that's
not the solution so why not
it's not because by the specification
the server must sent its responses in
the same order that requests were
received so this is it in fact the
entire connection remains first in first
out and the head of line blocking can
occur what exactly this means imagine
that we have three requests in the first
of them is required some heavy database
requests on this on the server right the
rest the rest of those could be just one
xone JavaScript and one CSS file they
will be blocked there are more buggy
proxy servers which partition implement
or not properly implement HTTP
pipelining and as a result in most
browsers HTTP pipelining is disabled or
not implemented at all so keeping that
in mind what could be what could
browsers do what can they do in order to
improve the performance there is no way
except to achieve multiplexing by
audible by open multiple connections to
the servers and that's exactly what they
do so this is the one side of the
question the net the second side of the
neck on the next site is that developers
as well creative people they implemented
a lot of work around so code
optimizations most of you will be very
well aware of them they are creating
images sprites sharding research
sharding resource in binding
concatenating files combo services
pre-loading resources when the user is
idle reducing cookie size or even using
cookie freight domains exactly for that
purpose using link is that import to
pack components into multi-part document
and so on in fact a whole industry has
been created to deal with those issues
sites have been created performance
groups in the big companies like Google
what Yahoo have been created but if you
are a regular web developer in you and
you want to make you
sites faster as soon as you read all
those guidelines you start looking like
this why should i do all that why is
that needed and if you also got tired of
all that then say welcome to HTTP to
that 0 and quick protocols HTTP to dot 0
which will replace 1.1 is currently on
draft 14 it's being actively developed
it's not yet finalized probably it will
be this year maybe the next one and its
purpose or its objective is very simple
to fix the issues in version 1.1 but
without breaking the web sounds very
ambitious and this protocol is actually
based on speedy which has been developed
by google in 2009 the for the very first
draft of HD video dot 0 version 0 was
based on the latest specification of
speed so going inside to the protocol
how browser switches to that new
protocol there are two ways from HTTP
and HTTPS if we switch from HTTP we use
the very well-known HTTP upgrade
mechanism however this means a roundtrip
so that's why it's better to look for
another solution and if we switch from
https to http 2 dot 0 an application
layer protocol negotiation extension is
being used which avoids this drawback
the protocol has many exciting features
and those I will note some of them the
paint difference with version 1.1 d that
it's binary protocol it's not text one
so for browsers it makes huge difference
for us it makes that if you use telnet
to log to some server to lodge in
to some server that won't be possible
anymore but because it's binary protocol
it's much easier a parser to be created
if you are no GS developer and you want
to create your own server it will be
much easier for you to create a binary
part of a parser based on the based on
this binary protocol you want there
won't be needed to deal with drink
delimiters with drinks at all on a very
low level browser on several exchange
frames and each frame belongs to a
stream if there is a frame which does
not belong to stream that's protocol
error what is really important is those
streams are multiplex it right we have
one single connection but multiple
streams they are multiplexed and they
also have priorities this is really
important if you as you know every page
there are some resources which are
critical for rendering the page and
there are others which are not CSS our
critical JavaScript could be critical if
the page requires javascript but the
images usually are not so now we can
balance with those different streams
something which we were doing for years
he was called resource inlining now it's
on the protocol level and it's called
server push again if I have a knowledge
a server I can I can check if the if the
browser allows server push and to push
my critical resources when the first
page when the page is being loaded right
instead to to put everything on the page
and to deal with with caches and
something like this this is what we have
to emphasize one connection to the
server that should be enough and not six
connection per domain a small most
browsers do now some of them actually
open more than six connections but in
general this is not good for no one
neither for the browser
nor for for the server you open the
browser you have to deal has to deal
with memory way to balance those
connections that's not good now just one
connection we go back us to the point as
it should be as I say it frames on the
though that's the that's one the very
low level and this is how a frame looks
like we won't take a look on over all of
this one by one I will mention just you
of those the type of the frame and
stream identifier every page has stream
identifier so as I said this would be
protocol error there are about 10
different frame types currently in the
latest draft like data frame which
convencer betrayed data associated with
a stream there are frames which deals
with headers some of those are related
to stream priority some of them are
related to promises to push promises
this is what this is ready to serve a
Porsche some of them are they purpose is
to reset the stream just abort the
stream I don't want to see it anymore
and those frames are grouped in streams
so streams by definition is logical be
directional sequence of frames which the
frames which are being exchanged between
the browser and the server so one one
single connection can have multiple open
streams like in this example you may you
may see that we currently have three
streams stream one stream to in stream
for so there are all some free they all
contain some some frames and they are
multiplexed one stream may represent an
HTML page another stream may represent a
javascript file or third one some style
but they are multiplexed and they are
being prioritized by the browser
so going to priorities each stream has
priority that priority is specified by
the browser and what is important is
that priority can be changed runtime so
the exact order in which frames are
delivered can be further optimized the
priority is an optional 31 bit value and
stream with priority 0 has the highest
priority right streams also have
dependencies and like in this example we
have two streams B and C which depend on
a so if we have another stream called D
and it just has priority it will have
the same value as B and C however if we
say that d depends on a then B and C
will start depending on dicho another
key part of the protocol is rated to the
headers as I said we cannot break the
web right this is the deal so HD be 00
is stateless protocol tool nothing has
changed here the client still has to
send data to the server however there is
a big difference the headers in version
2 dot 0 are now compressed this is the
big difference just a few words about
the compression it's stateful it's not
stateless which means that a single
compression context for the entire
connection is used and the Werdum is
specially designed for the protocol it's
called H pack header compression for
HTTP too because of some evil guys who
applied attacks like crime and bridge so
we have a special specially designed
compression algorithm for the protocol
going back to what we know very well
server push we did that for years
nothing new here I guess all of you some
applied some o embedded some resources
to the page CSS or JavaScript or SVG
image or whatever so here this is the
this is the different server
preemptively sense resources to a client
in association with a previous client
initiated request so if I'm requesting
index HTML on the server side me as
JavaScript developer who works on his no
GS server I can push the critical
resources which are needed for the page
to be rendered right there is a there is
a trick here the client explicitly must
allow it so on the server side when we
implement our service we have to check
if that is a lot otherwise that could be
rosete stream or something else a client
cannot push a client which means the
browser it cannot push resources to the
server only the server is allowed to do
that so very briefly this is it HTTP two
rows right because now as developers we
have full power to apply different kind
of optimizations different than those
which we were currently doing or we can
apply more we can get some every stick
from how the user behaves with our page
to to push resources to optimize our
pages in different way this is not yet
because now we have because the research
continues we have another protocol also
started by Google research by Google
it's called quick quick is a natural
extensions of speedy and HTTP 20
research this is also multiplexing
Sport protocol but there is a big
difference this protocol runs on top of
UDP it doesn't run on top of TCP ask
speedy and HTTP 20 does they don't this
protocol runs on top of UDP because it
runs off UDP the browsers can not use
those out-of-the-box features which are
available in TCP right so that those
should be implemented on application
level so why should we do that because
it's very hard to update TCP it's
everywhere it's on servers routers it
needs a bit needs years until it's been
updated but now we can apply the results
of those of the research how to improve
the web on quick Google apply to their
servers apply to Chrome and now
everything is clear if you can use you
can see how quick works right now in
your browser there is a flock you can
enable it if you want I actually do it
to see how is it going so that's not the
first time when people are trying to fix
the issues on using UDP people haven't
slept those years and there were already
existing solutions like HTTP / DT OS
that's one possible solution those are
two different protocols after all sctp
provides among other things stream
multiplexing right DTS provides SSL
quality encryption and authentication
over UDP stream so why not use those
those protocols the answer is very
simple because roughly four round trips
are needed to establish an HTTP / DT OS
connection you can imagine how expensive
you again with the example of Berlin
client and la server that's too
expensive in contrast the goal of quick
is to perform a connection as to
judgment with zero round-trip time
overhead this is the goal quick has all
the benefits of speedy and HTTP 2 dot oh
but there is a big difference there is
no head of line blocking in quick as you
can imagine the link of only one packet
causes the entire set of speedy streams
to pass speedy HTTP two streams to pass
because tcp only provides a single
serialize stream interface but in quick
when a single packet is lost only one
stream is being delayed we can
illustrate that with an image and here
is how does it look like here we have
three streams with red green and blue
color and if a packet in the stream
marked with red red color is being lost
the rest two streams are not being
affected here we can compare how quick
behaves vs DC p+ GLS for repeat
connection it's 0 milliseconds
round-trip time right for tcp trust us
it's 200 milliseconds for new connection
quick is 100 milliseconds for TV plus us
is 300 milliseconds that's too much as I
said because this protocol is on top of
UDP the many of the out of the box
features in in tcp are now not available
so they have to be implemented on
application level so quick also provides
encryption which is comparable to TLS
but with more efficient handshake it has
reply attack and I peaceful spoofing
protection and it also has something
very important in order to minimize all
those round trips which pin which really
decrease the performance there is
forward error correction which means the
price of additional packet for example
we can restore a packet which has been
lost so
the server won't have to send this
packet again a really cool feature for
us like is especially for us who use
mobile phones if we the data
communication channels are not defined
by IP plus port but by night but by an
ID so in this in this room there is
Wi-Fi and if you leave the Wi-Fi zone
and in go outside of this building for
using mobile internet that one that
won't be so bad because the connection
continues so all this sounds very cool
very exciting and I wanted to see what
is the current status of those two
protocol where we were going how are we
going and especially for this
presentation I created a small side
which is which has the really cool name
HTTP two rows com so it consists from
two pages on the first page we have on
the first page we have some some III
presents actually an online shop with a
few CSS JavaScript and images and the
second page i have a few web components
they are supposed to be the future of
web development so i wanted to see if if
we serve the content the different
protocols it will make some difference
so from my point of view that site is
like open source platform for testing
different optimization strategies for
HTTP 0 there is a this is the idea same
content but serve the different
endpoints via HTTP https speedy and HTTP
do that relic oh isn't it I don't have
quick end point yet because there is no
production radius server not that there
is HTTP to dot 0 production server I
implemented this on not GS so I had to
build a version of note with LPN support
but it currently
on each page we can see the load time
for each page so we can compare and
because this is a this is because we
have great tools like webpagetest bark
now we can check what is the difference
how I intentionally did not apply any of
those dark workarounds we were doing for
years I did not create any sprite for
images there are about 30 images I did
not create any sprite I haven't
concatenated any single file I wanted to
start with with something simple and see
how does it behave right if we if we
avoid all that on top we can implement
further optimizations so this is what
HTT what web page test shows us
waterfall when we use TLS HTTPS this is
the waterfall you can see how does it
look like you can also see that the
browser Chrome opened six connections
this domain and now for each connection
we have initializing we have SSL
negotiation which is expensive tcp needs
to eat three round-trips right so this
is not so good six connection you can
imagine how much time we are losing for
all those connections and here i have a
waterfall again with web page test which
represents HTTP to waterfall without
server push on the server i haven't
pushed any of those resources i just
relate on the browser to do its best
currently only this only works on
cannery it doesn't work on Chrome I hope
in a few months that will be available
in Chrome too but for now we have to use
cannery and apply a special flag if you
go to Chrome flux you have to to enable
speedy / 4 which is the internal name of
HTTP 24 cannery but now it works it
supports draft 14
which is the latest one so that's really
cool here you can see that the browser
did created only one connection to the
to the server not six this is the big
deal so all those resources were
multiplex it and then to the browser via
just one connection this is huge
improvement but I wanted to see how does
it behave if we if i push some resources
so here is the waterfall what currently
webpagetest shows we probably that will
change because if you open candidate dev
tools you can see all those resources
but in webpagetest it looks like I made
only that the browser made only one
request to the server which is index
HTML or slashed but not actually I
intentionally pushed old CSS JavaScript
in images file when the browser requests
index HTML page so again we have a
connection view it shows only one
connection not six if I if we have to
draw the line I would like to say the
following if you remember the
workarounds which we did to speed up our
sites for years all those workarounds
ask yourself how HTTP to the dough will
affect the way you develop an optimized
web applications for you or for your
company thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>