<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Stephan Herhut: River trail. Parallel computing in JavaScript. | Coder Coacher - Coaching Coders</title><meta content="Stephan Herhut: River trail. Parallel computing in JavaScript. - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Stephan Herhut: River trail. Parallel computing in JavaScript.</b></h2><h5 class="post__date">2013-01-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IcYsiVEIPhA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Steffen Harris from inter labs and
I'm here and I'm quite excited to be
here today to talk about River Trail
which is the project we do it inter let
me and my colleagues and it's about
bringing parallel computer to JavaScript
so we really want to bring the pro
compute power you have in today's
hardware to the web to JavaScript and
y'all got phones today so that's where
you have pearl hardware you will have
pearl harbor in your laptops in your
desktops it's everywhere but how about
concurrency in JavaScript what's the
state of the art there so when I started
looking into this I took a look at
javascript and what concurrency you have
and one thing I realized and I found
that really interesting is that
JavaScript developers in a way are
really good concurrency engineers
they've right concurrent programs and
the reason for that is that you have
this cooperative multitasking kind of
model in your browser where either your
browser engine is running and rendering
and driving the UI or your script is
running so you cannot have both running
at the same time and this forces here as
a programmer to write these asynchronous
callback style applications where you
decompose your program into small pieces
that can run quickly enough so that you
get this impression as a user that
actually the browser and the scripts run
at the same time so you are kind of as a
developer aware of how to write
concurrent programs however you have one
nice thing in JavaScript it's fully
deterministic and that really makes your
life as a developer a lot easier what
fully deterministic means is that whilst
your script is running nobody else is
changing the world so you as a
programmer can rely on the fact that
only your script is actually
manipulating your data and that gives
you a very comfortable programming
environment because you have no
concurrent side effects and you don't
get the nasty things of concurrent
programming you don't get debt logs you
don't get life logs all of these issues
do exist of course there's a slight
Cabot here because in the end there is
no concurrency
the browser because what your JavaScript
engine does it fully sequentialized is
your program there's only one script and
only one event running at every single
each time and this of course is a
problem moving forward because having
all this pearl hardware how are you
going to exploit it if you cannot write
concurrent programs and typically when I
put up the slide and say hey there is no
concurrency in JavaScript there's
somebody shouting say hey what about web
workers we have web workers they give us
tasks Yeah right true you have web
workers but they are for a very specific
kind of concurrency if you look at how
web brokers are done is they are very
very heavy weight so what you can do you
can spawn a thread which typically
spawns an operating system thread and
then it can run some operation and you
sync it all up again but spawning and
syncing is very expensive so you
probably will only do that if you have
sufficient workload to make up those
costs again also web workers have this
actress model of writing concurrent
programs and what that means is that
when sexually you have to completely
disjoint on script engines running and
the only way they communicate is via
messages this is all nice this is all
great if you have a kind of concurrency
in your application that does not
require a lot of shared State so if you
can decompose your program into two
parts while you only send tiny little
messages between them you can use web
workers but as soon as you have to share
big pieces big chunks of data the hell
breaks loose because the communication
costs quickly eat all the benefit you
get from concurrency and that's not the
kind of concurrency I am interested in
here so I'm not talking about cause
brain heavyweight task parallelism what
I want to talk about here is data
parallel programming so what's data
promo programming I will give you my
very personal very developer centric
view of what date above programming
means for me so if you write a data
program where the tip that you do is you
have a piece of data and then you
specify independent computations on
pieces of that data and the really
important part there is you never
actually say that it is concurrent in
any way you never say is bonded
read you never say run this concurrently
all you do as a programmer you express
that these computations are independent
all the concurrency is implicit and
that's a quite powerful approach because
what you can do you can massively over
subscribe your resources so think about
an example like map where you have a
thousand array elements and you apply a
function to each of those elements with
the right function you can execute that
concurrently conceptually you have a
thousand threads you can run
concurrently but nobody with the same
mind would create a thousand operating
system threads so you over subscribe
your resources in the end you have a
runtime system that will figure all this
out for you because your runtime system
knows how many cores you have whether
you have simdi units maybe you have a
GPU so the runtime system can decide how
to execute these threads as a programmer
that's a very very nice place to be
because you don't have to care about all
the heavy lifting all you do is you
express your program in a way so that
you can say here at runtime is my code
look at it and figure out how to run
concurrently so let me show you some
code this is or should at least be valid
JavaScript so what it does is you take
this little array here with four
elements and then you apply map to it
the function I pass the map is this
little increment here so if you look at
it as a developer you can instantly spot
hey this can be run concurrently because
this increment operation doesn't affect
anything else apart from computing the
result it's completely side-effect free
I could do this map in parallel you as a
programmer you know that the JIT doesn't
and that's what we want to change we
want to give the programmer means to
tell the JIT that this function actually
can be run in parallel and that's what
River Trail is about River Trail is
about bringing data perl programming to
javascript and the important thing here
is bringing it to javascript designing
it for javascript so we didn't want to
do yet another data parallel programming
model there are sufficiently many out
there what we really wanted wanted to
create a data perl programming model
for javascript specifically designed for
javascript and to give you an idea what
that means for us what designing for
javascript meant when we did this work I
want to share some of our design goals
that we used when we designed retro and
the first one which probably is pretty
obvious if you read it is that we wanted
rivotril to look like JavaScript and to
behave like JavaScript it sounds simple
but actually that's probably the thing
that most influenced the design of river
trail on the end because we did not
deviate from this goal even for
performance reasons we always stuck to
the fact that it should be like
JavaScript so all called you right when
you use rubber trail still it's just
JavaScript there is nothing new to the
point that we even have a library
implementation of river trail that's
completely written in JavaScript it
completely adheres to the semantics of
JavaScript the only problem is it's not
concurrent also we had this rule of no
surprise so we wanted the system
whenever we left what jobs could
traditionally did whenever we introduced
concurrency to behave in a way that
developers would expect our second goal
is we wanted to keep the deterministic
execution model because that really
makes concurrent programming so much
easier so we designed the system that
you do not have race conditions that you
do not have debt log however there is no
magic things you simply cannot change
our that floating point operations can
introduce non determinism if you do
reduction operations so this limits of
the hot where we cannot change but other
than that we've designed the system so
that it is termina stick as far as it
could be and lastly and this is probably
the most important thing if you look at
your betrayal as a web technology we
wanted it to be as safe and as secure as
javascript is so River Trail is no more
secure than JavaScript but importantly
it's not less secure either we still use
a fully managed one time we still have
no pointers whatsoever and we do full
bounds checking there are no overflows
sober betrayal is really suitable as an
open web technology
so this is the design this is how we
wanted river gel to be let me need to
tell you a little bit what roofie looks
like and it will start a very conceptual
level so road trail has three components
that it's built off we call this a three
pillar approach because the API really
rests on these three components that's
all you need to understand first we have
a new data structure that's parallel
array and you can think of this
essentially like a JavaScript array
there are some very important
differences that make concurrent
execution a lot easier first of all
parallel rays I immutable and that means
as soon as you've created a parallel
array you can know language change its
values they're really simplifies the
implementation of an optimizing but
it helps developers as well the reason
about their code to understand what it
means but it's run concurrently the
second thing we've decided is pearl rays
are dense so JavaScript arrays have this
property that they can have poles now as
I said we want to do data pro
programming and in that kind of context
the data really induces your computation
so if you have holes in your array that
means that for certain elements no
computation will happen we just think
that's very difficult to understand and
obviously as implementers it makes
implementing it easier as well if you
don't have holes and lastly parallel
rays are homogeneous and what this means
at least is that if you have a nested
array then all the elements of the outer
array have the same length so you can
think of a prole array like a 3 by 4
matrix for example you have three outer
elements and each of them is a 4 element
array again so we have this homogeneity
requirement and again this comes from
the fact that your data induces your
computation if you have irregular shapes
it's very difficult to understand and
think about what's actually going on so
once you have the data structure you can
actually create it that's the parallel
the code you write you just take an
array-like w anything that has a length
on some properties parser to the apparel
array constructor which creates a
mutable version of it and fills all
holes what the pro
raised her well is it has six methods
and we've chosen map combined reduce
can't filter and scatter as the
perimeters we want to support because
these are the basic skeletons for
parallel computation in a day to pearl
setting there are more maybe you could
choose a different set but we believe
there's a sufficient to write most kinds
of applications also it's important to
note here that we've deliberately chosen
these high level primitives we've
deliberately chosen something like
reduce and the reason for that is we
wanted to have portability across
hardware platforms if you think about
reduce for example you really implement
that quite differently depending on
whether you run on a GPU or on a
multi-core where they have simply
instructions or not having that at this
high level allows us to retarget the
code dynamically to the different kinds
of architectures we run on so this is
truly performance portable as far as we
can make it and lastly we have the
concept of nine elemental function so
elemental functions are typically the
things that actually do the compute
workout if you think of a map the
elemental function is the function that
takes an element from the source array
and computes the corresponding element
in the result what's very specific about
our elemental functions is that require
them to be side-effect free and that's
what makes concurrent execution possible
in the first place we even go to the
point that if they're not side-effect
free you will get an error either
statically or at runtime so really
enforce side-effect rhiness but I want
to reiterate here once more they are
still written poorly in JavaScript
there's nothing new there so you just
take your existing JavaScript functions
coming back to my increment here this is
what it would look like now you know
called parallel or a top map you still
give it the same increment function as
before but now the JIT knows that this
function is side-effect free or because
you promised him to be to be so victory
by calling a parallel radar map as
opposed to narrate of map and this
enables concurrent execution ok
increment isn't really a good example
it's kind of boring so I wanted to do
something more sophisticated a little
bit to do that I need to give you
slightly more insight into the API but I
wouldn't won't go any deeper than
this slide I talked already about the
constructor form so you create a pro
array by passing an array-like value to
a pearl or a constructor there are
different constructor forms for
different kinds of things like a canvas
or more generic instructors but this is
the only one I will use in my example
and then you have certain properties the
length property everybody will know that
ever used in array it just gives you the
length of the outermost axis of your
array as our apparel arrays are
homogeneous we can give you some more we
can give you a shape and the shape is
essentially a condensed description of
the whole structure of your nested array
think again you have a 3 by 4 matrix
that would have a shape three four so
the shape property gives you a vector
that describes the whole shape of the
Ray that comes in handy if you want to
write code on multi-dimensional arrays
as I said we have a set of methods for
parallel compute and the one I want to
highlight here is combined so combined
takes takes two arguments a depth and a
function and what it implements it is a
parallel map with an index so you can
think of it it just as map the first
argument this depth tells the runtime
how deep you want a trade so if you have
a matrix and you want to iterate on
every element you would use a depth of 2
if you have a matrix and you want
iterate in every row it use a depth of 1
so it's kind of the nesting of your
looping construct the second argument
here is a function and again it's an
elemental function and in the case of
combined this function is called with
the indices of the current element also
what we do is during the execution of
the elemental function this is bound to
the sauce pearl array and that really
allows for a very compositional style of
programming so this is all you need to
know this is all the API you need to
know let's do an example I've looked
long to find an example they actually
kind of fits on a slide and in the end I
decided for edge detection which is a
nice image processing filter and it has
the property that we've implemented demo
and it's it's an on our website so if
you look at it so you don't need to
understand the full code here you can
later look at it scrutinize it what I
want you to concentrate on really as the
computation
workload here so if you look at that
it's JavaScript there's nothing new
there so how do you do edge detection
well it's a convolution style
computation so to compute one element of
the result you have to look at all the
neighbors in their sorcery and then you
compute to wait sums of those neighbors
and that's essentially what this follow
puters it looks a bit complicated
because it has to do boundary conditions
if you if your element you looking at is
the boundary of your image because then
there are certain neighbors just don't
exist but in essence you just compute
it's running some of the current element
that's this this year at the two
positions x this so go matrix and the
solar matrix here is just a closure
bound variable again it's just
JavaScript you have all the features of
JavaScript at hands you can use closer
bond variables you have this will
function everything you want so if you
not trust me that this is the edge
detection for a single element how do
you lift this to an entire array well
you can write that obviously in
JavaScript today and that's one way you
could write it down so first you need
some image data right you compute your
gray scale image data from the canvas
element whatever you fancy and then you
have this for loop nest that essentially
iterates over your gray scale data and
looks at each and every element and then
calls the edge kernel function on it you
have to do some allocation of the result
and all these things but that's
essentially the pattern you implement
you have a nested for loop and get it
right over all the elements again as a
clever programmer if you look at this
code you will instantly see yeah that
can be run in parallel because I know H
detection has no side effects however
your jit won't know so how do I tell the
JIT I use a river trail primitive so as
before you'd first take your gray scale
data you create a parallel array out of
it which makes it immutable fills all
holes and checks its homogeneous and
then you call this combined method with
the depth of 2 because you want to look
at every single element of your
2d image data and your edge como as the
function in this now tells the JIT you
can execute this concurrently so it's
one thing to design a language and to
say okay you can write all these cool
things the other thing is to actually
make it happen so we implemented a
prototype for all this which comes as a
Firefox extension so how does this work
how do you compile this kind of code let
me quickly give you a view Nigeria so
here's your initial setting you have
your JavaScript engine which is running
your script and use the developer have
pulled a call it to combine into it so
what we do is at runtime we intercept
that call of combining and we pause your
script and instead start our compiler
which is completely written in
JavaScript as well so our compiler runs
inside of the JavaScript engine and the
compiler will just look at your your
kernel function your elemental function
and do a couple of analysis and
representation changes so first we do a
type inference and we've really dramatic
drastically specialized to argument
types under a sizes that's one thing
that gives us good performance so once
we know what the Rays are in the game
what their type are and what their sizes
are we do a representation analysis and
that's nice because as soon as you know
that something is an integer you can
vary a lot more efficiently select
elements using it as an index that's
just an artifact of how the JavaScript
semantics work as a next step we do
static memory allocation and the reason
we do that is because we just were too
lazy to implement a full-blown
concurrent elevator so instead we
allocate a looking steadily on the here
finally we do a bounced check
elimination because we're
representational is we already computed
the bounds of all local variables were
possible so we just used that
information but the last the most
important step is we create opencl code
so why opencl well this is a prototype
so when we did this we didn't really
have the time to implement a full-blown
compiler back end we didn't want to
implement a compiler that takes the code
to binary we didn't want to implement a
compiler that has a complete runtime
system for concurrent execution so what
we did instead is we reused an existing
opencl compiler but there's really no
reason why this should be
mended on top of opencl as a matter of
fact as soon as you leave the opencl of
sphere and implement this directly you
can probably do a much better job
because opencl is quite a straitjacket
that's not very well suited for
javascript anyhow so we end up with
opencl so we've taken your edge colonel
with compiler to open CL what's next so
far everything is written in JavaScript
and all this runs on probably every
browser that has a compliant JavaScript
engine but we need to execute it now
somehow and that's where our Firefox
extension comes into play what that does
it hooks up an open CL runtime to the
Firefox browser and it allows us to
actually execute that opencl colonel on
multi-core CPUs possibly using simply
extensions and in the future maybe even
on GPUs so once we've made that jump
into the opencl stag and your chrome has
been executed we have a result we inject
that back into the original script that
you had written as the result of
javascript operation cleaning up all the
stack we've created and resume your
kernel that's in its essence how we
execute rivotril program in our
prototype and you might say okay now
that's quite some effort you go through
here why do that why do i change my code
why do you write this complicated
prototype compiler it's a very simple
answer and let's be so we've done this
demo which is a particle simulation and
the rendering is done in WebGL but the
compute model behind it is completely
CPU pod so it's a big o n squared
algorithm that computes the physics and
we see using it for quad core Core i7 a
14-fold speed up I've decided not to
show the demo life on stage here today
but instead I just ask you go to the URL
install the extension to Firefox see for
yourself if you have a Mac that's all
you need to install because Matt comes
with opencl pre-installed if you have a
Windows machine you can download the
internal until opencl SDK and take a
look right away so go to the URL tried
it yourself see the speed ups
there is kind of a super linear speed-up
here because on a quad core you get a 14
type speed up part of that is due to us
having a better chip because we know a
lot more about the code and our compiler
only supports a subset of JavaScript but
a significant fraction really is
concurrency so if you try this in a dual
core or quad core you will see the scale
so here's the status quo here's where we
are we have this open source
implementation as a firefox extension
it's on github you can download it you
can play with it we have some pre-built
binaries for Firefox 10 we have a
sequential library so in case you do not
have Firefox you can still run the demo
it will just be significantly slower
because it's not accelerated we have
created a draft specification that goes
beyond our prototype and that
specification is available on github and
since this morning it has been promoted
to the actor script wiki as the data
parallelism strawman so we're heading to
acma to get the standardized to get this
discussed to get this adopted also we
have created the first implementation
for spider monkey which we use to play
with the API because that allows us to
do the full implementation of the actual
API without any limitations the
prototype may have however why I'm
really here today what's the point of
this talk is your engagement it's one
thing to design the language extension
it's one thing to do a prototype but the
important thing is is this good for
developers does this work does this
solve your problems so take a look play
with it come to me and we'll be running
around here for the next two days and
talk to me give me your experience we
really are interested in developer
feedback so I have a couple more minutes
to talk and this is really the status
quo this is what we've done so far but I
thought this is jas phone so maybe I
should talk about something that we're
cooking right now so let's go a bit
beyond the status quo in roseville and I
have to say this is really this is
latest news right
the soup we've been cooking a little but
there may be a raw ingredients here it's
not fully done yet how this work then
started I was reading this blog post by
a Yenta offered and he kind of talked
about how can we bring simdi to
JavaScript and that it's kind of the
next point here and at Apollo program in
view one and he's really interested in
sindhi for his audio applications
because he has this very fine grained
data parallelism that he wants to
express but cannot do so today and we
can really recommend this blog post
because it's great survey of the design
possibilities you have if you want to do
simdi in javascript you have raw sm
blade right thick inline assembly you
write some javascript code and then
there's some inline assembly in there
that tells how to do Cindy yeah you will
have pretty good performance but that
won't be portable and it for sure won't
be safe you can have standard intrinsic
so that gives you kind of some kind of
portability at least if you have the
same vendor of a hardware because they
kind of stick to the intrinsic for a
while but still if you have different
hardware vendors it's still not portable
and we still don't need to talk about
safety you could create Java specificity
our JavaScript specific intrinsic and
that would mean that you have intrinsic
that work across all hardware but still
it probably wouldn't be safe because you
would be still at the assembly level
essentially or you could create kind of
generic intrinsic that lifts it up to
the JavaScript level which would then be
portable it's safe but maybe you get low
performance and has last design choices
you just create a vector matrix API
because that's what you typically want
you want to do matrix vector multiply to
just Hotwire that into the browser but
that doesn't really solve the problem it
just solves the problem for very
specific set of applications so I'm most
interested in this generic approach
because I think if you do something on
the web it needs to be safe and needs to
be portable so I started thinking about
this and we discussed it a little and if
you think about simdi one thing to
realize this
it's nothing more or less than
small-scale beta probe ism so why then
can't we use River Trail which is good
at coarse-grained data parallelism to
express Cindy where's the problem so I
sat down I thought about you know some
Cindy intrinsics how do you write them
in River Trail and it turns out you can
actually quite neatly express them so
right here we have the standard add
intrinsic switch takes two vectors and
produces the element by some as a result
and you can write that as a road trail
one-liner so you take your vector a and
then you apply map to it with this
function I have to admit for brevity
I've used the arrow syntax here which is
not really part of JavaScript yet
multiplication you can write the same
way even shuffle which is a very common
vector operation you can easily express
in Revit well it's no longer a one liner
or it's a long one line but it's just a
comprehension constructor which takes
the the source array B and shuffled it
into the result ok so these are some
intrinsic but how do you write entire
programs so that look at matrix vector
multiply so how do you multiply a matrix
with a vector well you take each row
that's what this map here does it's a
map on the Ottomans dimension so you get
a row and then with that row you
multiply each element with the
corresponding element of the vector
that's what the internet does the
resulting vector you then reduce using
cloth at the end the outer map will
produce a vector which is your result so
if you have a clever jit it might see
that actually the input data it's all
these nicely for element thingies it's
all very small and the programmer told
me it's a pearl array there must be
something concurrent going on here and
hey this mad I can map it to assume the
intrinsic so if you have a clever jit
you can compile this kind of code to
Cindy code
well the harvesting isn't really good
here because of all the operations only
one map can be done in simdi well that's
a problem of simply because there is no
intrinsic for reduce but the season
cindy programmer he knows well i just
rewrite my coat slightly i use color
major psytrance post the matrix and now
if i do this index map on the outside I
get a column and I multiply that column
with a corresponding element of the
vector and then I do a vector reduction
on the results the result is still the
same but now I can do two of these maps
in parallel I can do Stu simdi
operations so why did I show you all the
sim decode I just want to give you a
feeling that with River Trail you could
actually write simdi codes and that's
that's a first it's a really a step
forward because right now a programmer
cannot bright simdi code at all however
there's no magic dust if I just shown
you it's still the programmer who has
two brightest in decode the programmer
has to choose the day layout so it's not
as nice and easy as coarse grained data
parallelism but it still it enables you
to write that code also this is probably
performance portable in theory but
whether it happens in reality is still
an open question because Cindy really is
different or different platforms and
probably the JIT implementations would
differ too so one jit might detect a
pattern where's the average it might not
and the final question and that's again
a question for you here can we encode
sufficiently many patterns so do you
have an application where you would
really like to have some Cindy code in
there but you have to use some C++ today
do you have these codes and can you
express that in River Trail
that's the URL go look play</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>