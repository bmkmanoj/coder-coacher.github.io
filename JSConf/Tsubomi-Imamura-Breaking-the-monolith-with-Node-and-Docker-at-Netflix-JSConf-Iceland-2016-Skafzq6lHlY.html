<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tsubomi Imamura: Breaking the monolith with Node and Docker at Netflix - JSConf Iceland 2016 | Coder Coacher - Coaching Coders</title><meta content="Tsubomi Imamura: Breaking the monolith with Node and Docker at Netflix - JSConf Iceland 2016 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tsubomi Imamura: Breaking the monolith with Node and Docker at Netflix - JSConf Iceland 2016</b></h2><h5 class="post__date">2016-09-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Skafzq6lHlY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi how is everybody I'm glad everybody
knows Netflix so I'm to Bobby imamura
senior software engineer from netflix
today I'm gonna share our journey how we
migrated from you I data API Mona less
to well isolated microservice in nodejs
darker cantina so why did we have a UI
data API model is from the first place
to understand that let me start by show
some business background about our
company you probably already knew we are
video streaming company what you might
not know is we have over 80 million
subscribers worldwide we stream our
content more than 125 million hours per
day so that stuns a lot of traffic to
manage now user can view our content
from hundreds of different color device
each device has its own performance
characteristic and form factor so we
need very different kind of data to
render each you I screen now the
question is how do we fetch the internal
paula deta to render it GUI in the past
we built a java data API server that
will have exposed all the internal power
service and we will have all different
kind of rest endpoint here so our your
client can make multiple requests to
this comment java api similar to fetch
the internal holiday dough but there's a
problem here most of us are you our
developer here we all know orchestrate
multiple rest api request is cuba's am
and not performing from the client
device so we improve our Comment our API
server you will take the responsibility
to orchestrate and fail the request to
our internal potter service now our
client device has full control of the
request response cycle we can just make
a word request to fudge the internal
pallador back that's awesome
oh oops did I skip so however the data
returned is in generic format it's a
one-size-fits-all device so that music
means every device will fetch data that
has some puddle and belong to render its
screen you also need to pass it that's
not very efficient so we decide to let
our UI developer to write new idea
endpoints crib inside this Java server
so inside this you are data endpoints
crib that we can write business logic to
transform the internal pollinator to the
format that fits individual device now
UI developer has full control of the
data returned back to the client and
also all your developer doesn't like to
write type the language like Java so we
let them right groovy script for this
endpoints cliff and we can upload the
Google script to a host of java 7 wrong
time and compile there now the benefit
of having this architecture is we get a
service infrastructure oh you are
developer that I have to write a server
or managing the server wrong time in
production and we have good operational
insight already building without Java
server so UI developer has good
visibility into the data endpoint script
d right and we have a dedicated packin
team they were managing the server
dependency for example conquered or
groovy version and all our i-team has a
consistent development workflow they
have the same script to upload their
goofy square and we have an atomic
deployment workflow because all the data
in points crib are deployed together
with just our server so it's awesome
however over the time we realize there's
a problem with this architecture our
developer workflow is inefficient
during implementation cycle we need to
constantly contact switch between
JavaScript and groovy script and also
when we do in code iteration we need to
upload the groovy script to a hosted
testing environment each upload takes
two to three minutes or maybe you are
longer we have 200 you I developers
every one of them does this 20 to 30
times a day this workflow really slows
down our developer and add low pressure
to our testing server an even worse we
have very limited visibility into the
testing server environment the only way
to see anything is the traditional
printing annotation so you can see our
developers in here now and also it's
very difficult to reproduce a production
problem inside the local machine to
debug because we don't have a server
setup from the first place and even
worse we figure out that we have
long-term issue here the problem is
inside data endpoint square we have 1000
10 points crib and hundreds of update
every day all this crap are running
inside the Java server without isolation
a bug inside one set of data endpoints
crib could bring down entire you are
data API fleet now if one set of data if
you ask web is taking too much cpu or
memory you will stop all the other you
are data API web so we can scale them
independently and also it's difficult to
identify which data import script is
taking that much resource because all
the operational metrics is combined as
even worse now it's also complex to
offer research platform we need to load
it runs on the API into memory compile
and warm them before we can start to
serve production traffic so the server
style time takes 15 minutes we can't
scale our server fast enough to handle
the large trafficking
crees you feel the eternity when you try
to start up your server and also we have
hundreds of different kind of scrip they
are all loaded inside the memory now
even the largest amazon instance can run
such server and at this point you can
see all you advice need to make requests
through this java data API server to
fetch internal parody de so this server
is a mano less and also it's critical if
this server goes down the UI give us can
search any data which means you can
watch your video that's a bummer so it's
important that we make this you are data
API server resilient and performing now
at this point we know the pro and cons
of our monolithic data API server we
want to decouple our UI data endpoint
scrip from this monolithic a server and
make a resilient we clock feedback from
our different UI team and to see what's
their ideal next generation you I did if
you have loved one our developer want to
continue have the benefit as we had in
the old architecture however they want
to fix the issue that you have let's see
what's our developers ideal development
workflow we want to continue
half-civilized infrastructure our UI
developer doesn't want to implement
server or configure the server we want
to continue have easy environment setup
on the top of that we don't want to
contact switch anymore and we wanted to
have our code reflecting to the server
instantaneously because we are impatient
we just want to relo and have things
happen and we want to run a local server
so we can attach a debug onto it we want
to reproduce a production code inside
developed local machine precisely to
debug problem now let's see what our
production go we like the operational
visibility into our you
api server and our java server has
already integrate with our netflix
existing infrastructure for example or
personal dashboard a loading system
discovered crime so that's a nice
feature we want to continue have that
and we want to have countable deployment
workflow so what's on top of it is we
want to get wrong time isolation and we
want to scale different kind of data API
service independently for example our TV
you are team has long tail device some
old version of data if your service
monthly just need one server to handle
the traffic however the latest version
might need a lot of machines so how do
we achieve all these goals here's our
solution run no geoserver inside docker
container javascript is a language or UI
developer a familiar with so normal
context switch between JavaScript and
groovy script and using dunkle continued
we got process isolation to reproduce a
version of server become easy just
viewed a version of server code as a
docker image and deploy anywhere now
also style of time become fast now at
this point we got an empty darker
container how do we build our new server
has the same feature parity as we had in
our Java server we know we wanted to
have operational visibility an
integration with existing there for the
netflix infrastructure however all UI
developer wants to have civil
infrastructure they are great fry and
developer but they might not have
specific knowledge about building a
server we obviously don't want to put
the burden to have them write a node.js
server startup code like this to fill in
the gap here we decided to view the
common know Gia's platform so we will
write comment suicide the code in this
problem for example server startup
location error handling matrix
population and this load balancing
so all your developer can focus on
implementing business logic without
worry about silverside concern now let's
see how we view this nodejs platform we
use verse 5 framework to build our own
OTA server response already building
with operational matrix so it has good
debug ability we have been used
ratifying our website for a couple years
so it's well tested in production and
also it's one of the fastest no Jerry
server it's lightweight its specific
phobia dressed API service so we only
need a minimum set of dependency now
let's see how will allow you our
developer to create server out we use
red fire in raw module to let our
developer to create some around
declaratively in JSON format this way
our UI developer doesn't have to know
response pacifica a p.i and you make
rotation easy and also this role
configuration file become a single place
where we can find out what kind of API
is inside our no GL server it can
prevent real collision this is an
example of the role configuration you
can see search is the route past get is
the raw method the value of source is
the entry point square now what is the
entry point square by yourself this is a
pseudocode for our search service we
will write business logic to fetch
search data and transform the data to
individual device format in this
middleware function now what's important
here is we will export this middleware
function here in the entry point scrip
this is the contract between the usual
encode and plop the platform now I just
mentioned something called connect style
middleware function what is that in no
geoserver we use a middleware function
or an array of middleware function to
handle a request
the middle function will take input of
request response after and next call
back in the end of the function we will
invoke the next call back to change to
the next request handler now in most of
the case we will have very complicated
business logic so we will export an
array of middleware function in the
entry points clip the platform going to
take this middle functional ray a
injecting to ratify server by doing so
our UI developer can focus on
implementing business logic and the
platform will take care of server-side
bootstrap code now how does our platform
publish matrix we use verse by audio
longer plugging to publish matrix into
server log this whole bunch of texts are
requests log so what's important here is
you can see in a bottom of the screen
that read texts a unique request ID and
we also publish request header so these
are information we can use for debug and
most importantly will measure request
latency for each middleware handler now
we can easily find out where our server
is spending time at this actually is a
production of class has performance
issue I can easily find out the rest I
walk around handle is the one take the
longest time so I can be very targeted
to keep up my performance issue here we
also want our server to be resilient so
the platform will handle common system
level error for example if our upstream
server is doing a deployment we might
get a network error so the platform will
retry our network error using
exponential back-off algorithm we also
use res file requests expiry plugging to
time our requests when the clients no
longer interesting while request expiry
is important it can improve the server
performance now in some case our service
can get d dust the event queue will be
filled in with a lot of requests that
nobody is carrying about so using the
request expiry flogging we can quickly
discard those
active event and starting to serve
active request a young another scenario
I'll upstream server can have long
latency when a data come back to our
note a server the client has already
turned out so we don't want to waste
extra CPU cycle to parse and render the
data and send it back to the client so
the platform works also kill the middle
we're here now we can easily stand up
the data API service using on top of the
node.js platform the next step is we
want to be the tooling to make it easy
for our UI developer to set their
environment I have a consistent
development workflow we have introduced
darker into this workflow it's a new
technology that can add learning curve
and most of our developer are used mac
or windows as their development Shing so
they need the VirtualBox to run local
docker container that can add network
complexity so if all this our developer
wants to manually install into their
local dev box that can take a day or two
this is a too painful that's why we
decided to build tooling to streamline
our developers workflow the tooling will
encapsulate darker complexity and make
it easy to install build deploy a docker
container now this is a common workflow
for mac OS users starting to work with
our newest aqua container platform we
only need is full step first is set up
it's obvious we install the darker
VirtualBox node npn another related
software into developing local box he
will set up the darker server to work
with internal dhaka registry next up we
will generate a simple call repo using
human generator now even you develop on
board they can quickly start off with
their endpoint script just by changing a
working sample and a lot of time after
we build our code it might take a long
time for us
the cic d pipeline to push the code to
test our products are men so in this
initialization step our tooling will
create a cic d pipeline for our
developer now well we're ready to test
we can build a local image the tooling
will handle nesting of darker image you
will pull the node.js platform image
from internal dhaka registry and build a
data API server image on top of it the
final step is to employ a continued
locally a tooling will start an ode to
node.js server running inside the docker
container and create by man between the
host a pre-poll into the darker Cantina
now I just said something about by month
what is it it's a filesystem mounting
between hosts file system and the log
taco container why do we need it
remember our developer wants to have
fast code iteration they want to have
their code reflecting side the server
instantaneously however a docker image
is immutable we don't want to review a
new image every time when people change
code so using this by mom we can achieve
the code change instantaneously the
tooling will watch the file system and
the change can be reflecting side the
docker container and server is restarted
now a change can be reflect in a couple
second in compared to previously a
couple minutes and remember we need to
support hundreds of different device a
UI developer needs to test from
different device to their local data API
so it's complicated to set up the
network for their local development
lemon and the tooling take care of that
it will make our local data API server
discoverable by a common routing gateway
now our developer can test their local
data API from any device with an
internet
now how do we get a better debugging
method now since we have a local server
running the tooling world set up port
forwarding on VirtualBox a gyro the
remote debugging now developer can
choose their favorite debugger to
install no inspector and use our
favorite chrome dev tool to debug server
side issue as well our developer no
longer needs to write console the log
over the place inside their code and
stirring a testing server now we have a
very efficient developer workflow now
how do we solve our production problem
remember we have we need to achieve
long-term isolation and skill different
kind of data API service independently
in the old architecture or our you are
data API service is running inside the
same java more no less we want to
decouple them out from the Java server
each logical set of data endpoint script
is running inside at all no Jade server
by doing so we can scale them
independently and monitor their
operational matrix separately and also
because the Iranians are different
node.js server a bug inside one set of
data API service wouldn't affect the
other when a client make a request to
the no geoserver the node.js server will
make another request to a remote service
layer which has all the internal prodded
atta exposed there this June we have
viewed a search service using this new
architecture and integrating to our
website we are ready to test it in
production when the production coming to
mind our developers immediate reaction
is what happen if I'm on call how do I
debug a production issue that's critical
we don't want our UI developer to worry
about production matrix the platform has
already build original matrix in mind
the notary server has integral with
Netflix or personal dashboard atlas
ulta lewis is a tool will aggregate
different kind of operational metrics
into you I dashboard and it's also an
open source now when I know dear server
make requests will publish variety
matrix into outlets for example will
publish request-response count so we
will know the historical obvious of our
server we can make inform the decision
if we want to scale our server up or
down we also aggregate the request
latency and request q-dubs so we know
our server performance and we measure
server figlio count and time i'll count
and we can set threshold on the error
rate so we can alert our developer and
we have silver restyle count if our
server continuously restarting that's an
indication of severe problem inside the
data endpoints cliff we also publish a
flawed system level metrics for example
cpu or heap use it so we can be alerted
if there's performance or memory leak
going on in production in some time imma
get a 500 error for a particular request
so I want to see the error log I however
we don't want our I developer to take
the trouble to log into production
server until the server log and also we
have hundreds of different colored
server we wouldn't know which requests
were coming to which server so we view
the tooling to aggregate a server into
ink we allocate the server log into a UI
tool now our UI developer can call it a
server log through this UI to real time
at this point we have good visibility
into a node.js server is that enough to
debug a production issue actually it's
not we have a distributed system the
first step to this debug a production
issue is identify which stuck in the
requests segment has problem we
has come in you will come to a routing
gateway the Gateway wore out the request
to our no Jo server then no geoserver
make requests to a remote service layer
finally we fetch the internal holiday de
wouldn't be great if we have operational
metrics for each individual request
segment so we build distributed request
treating tool to measure request latency
and status for each individual local
segment now we have good visibility into
entire Netflix API ecosystem at this
point we have all the tooling available
for us to debug now we are ready to test
in production with full scale however
any new architecture could cause
unexpected issue we have over 80 million
subscribers we don't want to test a new
architecture while in impacting our
subscribers to experience so we decide
to run shallow traffic what is the
shuttle traffic here when a device make
a request to our routing gateway it will
duplicate the request when go to the
mono list data API server the other go
to the new notice taco container
platform now only the monolithic data
API server will return the data back to
our client the note G of stalker
container platform will only return the
data back to the routing gateway and the
data is dropped there this way we can
test our new architecture without impact
customers experience at this point we
have slayed our data API more or less
and make it each data API service
running inside it's all know Tiesto
Cantina in production we have achieved
long time isolation we can scale a
different calendar if you have service
in apparently we have reached
operational insight into our notice
server during development we have much
efficient developer workflow we can
reproduce a production problem in
developers local machine precisely to
debug issue
this architecture improvement has made
big impact to our business and
developers workflow thank you for coming
to my talk if you are interested in
working in node.js or darker Cantina
feel free to reach out to me after the
talk and our company is hiring if you
are interested please what look for our
job website thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>