<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Michael Poltorak Nielsen: Alternative Smartphone Interactions based on Sensor Data | JSConf EU 2014 | Coder Coacher - Coaching Coders</title><meta content="Michael Poltorak Nielsen: Alternative Smartphone Interactions based on Sensor Data | JSConf EU 2014 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Michael Poltorak Nielsen: Alternative Smartphone Interactions based on Sensor Data | JSConf EU 2014</b></h2><h5 class="post__date">2014-11-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/q20W5dWHTas" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">right thank you as I said I'm going to
talk about alternative smartphone
interactions so you can hear me all
right and back good basically it's about
sensors in this guy when we move the
phone smartphone about you pick up a lot
of data add instead of using touch and
keyboard input and there's a hole over a
whole range of data we can utilize
utilize to augment how we work how we
interact with smartphones today I'll get
back to that in a little while this is
me I'm a huge American football fan I'm
a Broncos fan this picture was taken
Super Bowl night just before disaster
struck I was still happy but yeah some
of you know what happened I work at
state skeptical as of what did you say
yeah exactly it's a library this is the
book tower 16 stories of books I'm a
front-end developer working with search
engines for the library and also a lot
of smart stuff um just a quick rundown
this is university research library and
national library which means that state
procedures in all then mark keeps a lot
of stuff as you can see both physical
and digital my demo today is going to be
performed in the search index of 1
billion books and articles hopefully
that works as you can see we save a lot
of stuff mostly for preservation and
cultural region
okay all right
so just going to my speakers actually
five minutes too long but I have this
Android watch with me so I'm going to be
checking that and once in a while so
mobile javascript sensor api's and
events okay just going to this is the
can I use web page maybe some of you
know this is essential if you work in
cross browser cutting-edge development
you can look up any feature on its web
page and see which browsers supported
I'm not going to go into that but I'm
just showing you it because it's it's a
really good resource okay these are the
the sensor device the sensor events and
api's I have identified as relevant and
existing at the moment in modern mobile
browsers there's a just obviously the
touch screen for touch events the
geolocation event coming from the GPS
gives you location motion from the
device orientation and device motion ap
is they fire when you when you move the
phone about in space the device
orientation then coming from the
gyroscope and the device motion is from
the accelerometer so the subtle
difference in those two the getusermedia
they get user media and stream avi is
for access to camera for inter device
communication and then there's the web
speech API for recognizing speech and
the last three ones are well a bit I
don't know odd but proximity is how
close an app to this to the phone gets
readings on that ambient light how much
lights lightness in the room you can get
a reading of that Earth course battery
status I don't know how interesting
interesting that is but
okay i'll just show you the demo search
engine oops so so hopefully this works
as expected just need to do one more
thing it now remember this is a live
demo so anything can go wrong actually
now I just need a bit of tweak here okay
good this is quicktime recording on the
iphone sending it back to the mac that's
the best way I found to get a mobile
phone on the screen so I'll just perform
a quick search and now I'm live
searching on mothership index of 1
billion records and hopefully it yields
a result yep so that's a search result
for you it's a really basic search
Indian it's one that I built for this
purpose I can switch views see a little
more information and the full view and
and go back and I can scroll up and down
and I can favor it an item if I like to
fairly basic but it works so let me get
back to side thumbs the demo search
engine so I I'll be taking a closer look
at the touch event device motion event
and the web speech API em touch event
three types chaat start church end and
touch move it's fairly basic let's show
you on demo here
oops just switch to my touch part of the
demo so now you can see over here this
is a bit small isn't it over here on the
lock can you read the lock okay great I
don't have to do anything so if you you
can see that certain very finger I put
on the screen there's a reading like I
can I can fit five fingers on my screen
I don't know how many tribal six I know
if that goes well but as you can see
every time I I am I press the screen a
touch event fires and you can see it
over here containing information about
the church event there's a lot of stuff
in there but on basically it's the
position on screen and the target
element which dumb elementa died did I
did I press with my finger then there's
a church list containing an array of
such events for each finger so basically
this is you can access any data about
what happened on on the screen and this
is just this fairly basic stuff so what
can you do with it this is the the
dollar one touch gesture recognizer for
2d gestures and it's a little JavaScript
library they could be used to to pick up
gesture so just showed here to this is
the life website so she does it that's
the cameras here and if I if I draw a
circle the code x it up as a circle
if I draw a rectangle gets picked up as
well so this is this is I won't go into
this this this code up here little
symbol library being able to pick up
just just to to justice on screen so
I've put this this into my demo so
hopefully now I can also pick up some
advanced movements on on the touchscreen
so let's see now what happens so now I
just now I draw a circle I pick it up is
seamless that's a circle up here and I
can do a triangle and a line right human
and so on so giving a given al an input
an array of touch events this this code
picks up or recognizes basic shapes
which is a good thing perhaps but i'll
show you how that can be used later so
now for
the device orientation event this is
when you move the phone about a device
orientation event is fired yielding
three parameters there's the deck gamma
gamma is the measurement of the left to
right tilt of the phone beta is front to
right tilt and the Alpha rent is that
the compass direction of the phone and
she's think of this turning this way
just also show you that on the phone
this is that website that shows a
chilled OOP tilt the phone to the left
you have I had the negative gamma
readings to tilt it to the right of
loops I'm sorry Rhoda positive gamma
readings and I told it forward I have
positive beta readings and backwards
negative and so on and of course if I
you can't see it on the screen when I'm
turning the phone hours and i said in
the compass directions or have a alpha
reading
yeah so what I did was use try to use
this data coming from from the device
orientation event to to create a higher
order gesture and as this code shows is
this reads the change in the gamma
values a positive change yields a tilt
right event and a negative gamma chains
is a tilt lift event and i'll be using
that in this search engine a little demo
in a little in a little while oops so
just show you how things look so I
switch to
and I choose my motion so now you see
data about the phones position in the
room and I move it about you get
readings and as you can see oops website
down so left
oh no I know
this is not supposed to happen
I'm just going to don't see sorry about
that I say that this is a live demo
things go wrong and they did now let's
see me hello this is new way to demo and
we're back I hope come on
Yeah right
yeah okay now to speech the web speech
API picked up speech and recognizes
words in what I speak it's actually it's
a web service the back end of this
features a back end sorry it's a web
service provided by google which is also
why it's only available in chrome on
Android for the moment it used to be an
iOS but but apple pulled it for some
reason maybe something to do with Siri
we don't know I'll just demo it in in
the desktop Chrome version it works on
android phones but it was too much
wiring to get it all set up so I'll just
switch to this speech part and speech
recognition to fix at hello computer hey
something you see get a reading well
it's not perfect but that's better so
this is this is the fun part it's always
yeah see you have to speak in whole
sentences that don't don't make breaks
and don't well you know let's see what
happens now oh that's fairly ok so now
I'm going to do something oh that's
probably why I will pull pulled it from
iris and I'm just going to do one more
thing that I never thought I would do on
in a presentation so I ready yeah
well ok so let's let's put all this
together in in the search engine and see
how we can augment the way we use it
this is
what we're going to do without you okay
so all together I do a search again
so now this is the same search result as
we saw before just augmented with with
the new did with the gestures and I just
show you if I tilt tilt the phone two to
the right it switches view I do it again
switches again to the next view tilt the
phone to the to the left and it goes
back and back and tilt the phone forward
it's Scrolls down I don't know how if
you can see it but it does and if I to
look back it's cause up it's ok so now
also I've if hopefully I'm scrolling
down to the button if I make a circle on
screen it's supposed to scroll up to the
top because it has picked up a circle on
screen yeah what did you see that I'll
just do it again this is quite difficult
because the screen is scrolling as I'm
doing but I'm drawing a circle and the
search result goes back to the top also
if I do a line right hopefully it
switches view no it doesn't yeah it did
so this is picking up the 2d gestures
that we saw early on so this is a
combination of two and 3d gestures and
and it tends to get messy because things
get picked up mixed together so if i
scroll up sometimes it also turns to the
medium view and so on ok i just also
show you how to control the search in
inducing speech so this is now the
search enables the speech enabled search
engine so I say search for computer and
its search for computer
down I sit down level
down yay it's scrolling down down this
is I never speak like this and enters
down it's almost in German accent down
down yes Oh home hey it's going to the
tub I guess a medium medium extended
small yeah okay it works in if you very
articulate
so how much time do I have clearly we
can we can augment the traditional
paradigm with these these things but I'm
not that the big question is of course
is it useful you look quite sometimes
it's it's easy to speak to the two to
the phone it's something you do with the
phone normally but but somehow you look
silly when you when you when you try to
reset command your phone it's search for
people look at us if you're a bit also
you disturb other people if you're if
you're talking to your phone all the
time and doing stuff and as we saw it's
it's very difficult to decode the speech
that about to be mistakes about to be
mistakes when you speak to the phone as
you saw then that it just the gestures
both 2d gestures and 3d justice they
lack a common language we don't have a
way of a common set of interactions or
gestures that mean something in it so
that that's that's a challenge also
they're quite hard to to do on screen as
you saw if you have a scrolling search
result then you have to draw a circle or
a triangle or something in it it's it's
not very easy to to interact with also
3d gestures that are quite hot to code
and two separate noise and different
interactions from each other so that
there's a this really a lot of
challenges involved involved
but I guess as as always it's very
important that you valued any new
features and you test them on users and
in this case I I really couldn't see any
of these ideas getting into our
production search engine perhaps perhaps
our own perhaps perhaps this except this
the scrolling down that subtle tilt you
can do it with the phone that that
that's that's okay for me I think that
that could work but drawing circles on
the screen seems a bit off so as always
and you do such me kill your darlings
this is the best advice I probably can
give when when dealing with these things
cutting-edge speech and Sri do this just
so yeah that was it thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>