<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Jad Meouchy: Load testing your node application | js.la January 2017 | Coder Coacher - Coaching Coders</title><meta content="Jad Meouchy: Load testing your node application | js.la January 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Jad Meouchy: Load testing your node application | js.la January 2017</b></h2><h5 class="post__date">2017-02-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/j7a-7cUvQ0c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">how's it going everybody
real quick plug for codes
they actually just hired somebody who
graduated from code Smith it was a
couple months ago it worked out great so
highly recommended yeah so today we're
going to talk about load testing which
is also known as denial of service
attacks so anytime somebody asks you hey
can you beta test my app you can say
yeah I actually can do more than that I
can help you destroy it so a little bit
about me my background in coding since
the original Gameboy and I've been doing
startups pretty much my whole working
life I actually met my first investor at
a racetrack we did 200 miles an hour
without helmets on so I know he was a
risk taker and so that was kind of a
good profile and we meshed and anyway
started a company so load testing of
course what is load testing Dave gave a
pretty good introduction to it but
basically it's about finding that limit
and then pushing past it and seeing what
happens so we try to simulate all kinds
of user activities some normal some
abnormal and apply stress on the
application or the REST API or whatever
it is until that moment at which it all
just comes crashing down and sometimes
it degrades nicely and smoothly that
never happens for me it always just sort
of flips a switch and then it just
absolute meltdown
sometimes it takes the database down
with it so all kinds of fun stuff with
load testing but we're definitely going
to we're definitely going to learn a
little bit more about how to use it I
guess effectively and how to use it in a
way that can actually help things move
forward instead of just taking them down
so in looking at what happens under load
you have a couple different things
depending on who you talk to talk to us
talk to the engineers the developers and
all of that then there are technical
limits you know does it does it crash
okay it crash well how quickly can it
come back up if you take down a database
under load it could take a second for it
to come back up for various reasons does
the experience of the app degrade nicely
or does it again just sort of melt down
does it start errors start popping up
pages start taking really long to load
depends on what it is rest api website
whatever or an app you know mobile app
but there are a lot of things that can
happen technically but then when you
look at and talk to the business guy
there are much more serious impacts
like you know what does how many
customers can we handle if we get more
customers than that and then the site
crashes do we lose the last half-hour of
orders which could you know be a lot of
money especially when you're handling a
large volume of users so for example if
something were to crash on Black Friday
and you lose oh let's say half a day of
orders that could be that could be a
quarter of the orders for the whole year
so obviously you need to make sure that
doesn't happen and then assuming that
you can figure out what happens how much
does it cost to actually fix it and
reinforce it and get it ready so some of
the goals that we're gonna focus on or
some of the I guess the intent of load
testing really is to gauge performance
to assess reliability to figure out
scalability whatever that means that can
mean a lot of different things to a lot
of different people and in some cases it
can mean capacity planning so figuring
out how to handle that volume how to
handle those spikes in traffic are we
prepared are we confident in our system
you know when we test a little bit on a
local machine does it already start to
exhibit strange behavior under load and
so you put it on a production system and
then it's just yeah it's just not going
to happen so some of the metrics some of
the magical numbers that we're going to
track with all of this latency that's a
big one and that's a good indicator as
you'll see in a graph a little bit later
on requests per second this is kind of
one of our magical numbers is how many
actual users simultaneously are really
requests simultaneously can we take now
it's possible for users to generate
multiple requests per second then that's
probably a problem in the app shouldn't
be doing that but response time how long
does it take when they hit a request to
the REST API tour whatever to the to the
website how long does it actually take
for a response to come back and again
you want to get that in a nice sweet
spot and when it starts to degrade
you're gonna see that response time just
slowly climbing up until it hits
infinity percentiles that's probably a
little bit more specific in terms of how
you actually look at these different
numbers now I wanted to throw out just
some ballpark numbers for requests per
second and latency now again everybody
is gonna have their own opinion about
what these numbers should be I would say
that for a mid-sized cloud instance
on Amazon like a medium or something you
should probably expect somewhere around
a thousand requests per second for
whatever it is and maybe 20 millisecond
latency 30 millisecond latency so when
you're doing all your load test you
start looking at the numbers and you're
not hitting that with the medium or
maybe a slightly above medium then you
should be concerned so we'll also take a
look at some product services
I should be getting paid by some of
these companies there's one in
particular although it's I guess an
open-source project so it's the one I
really like and I'm gonna show you how
to use it but here's some of the other
ones here's some of the paid ones which
has anybody used any of these by the way
quick show of hands okay a couple people
loader blitz so stuff so as to I don't
know Microsoft Microsoft's is actually
decent I hate to say it it's it's pretty
good
so flood I haven't used that one yet but
we tried a bunch of the others and we
had mixed experiences across the board
so we looked at some of the libraries
that were available Apache bench which
is kind of the I guess original
workhorse I mean everybody used to use
that back in the day for simulating
traffic and then artillery which is a
little bit more modern but a lot of the
same concept we really like artillery
that's what I'm going to get into on
this one and then W R K which I guess is
yet another flavor
I hate Apache bench I hate it with a
passion it's so confusing so difficult
to use artillery is just great though so
we're going to talk about artillery and
not a pat revenge so it supports
multiple protocols scriptable extensible
has a lot of different ways of looking
at metrics and a lot of different
metrics also its integratable into a
bunch of stuff so it's really know D
really gulpy adjectives that you know
work in this audience and it's pretty
good performance I mean definitely able
to take down pretty much every server
with it so that works so to install it
quite simple quite straightforward and
then to test it artillery dyno
I don't know sure they have some
dinosaur thing sure
so another thing that I would say that
he does not come with out of the box or
at least it didn't when when we were
testing and using it were like real time
monitor
of your app so looking from inside the
application or inside the API what's
going on I'm in crash reporting also so
figuring out if your thing does crash
and burn how did it crash was it you
know file system related network related
something else CPU a memory ran out of
memory which is a common one so figuring
out what exactly happened artillery is
not going to tell you that it will just
destroy it it's up to you to figure out
how it broke so fair warning about that
so this is probably the simplest test if
you mess with these numbers a little bit
you should be able to put a lot of
stress on whatever is at my app comm so
replace that with your friends app comm
and this specifically will put 10
virtual users every second making 20
requests each for about 60 seconds so
for about a minute it'll do a small a
little bit amount of load here's a more
detailed one and so you start to put
them into scriptable files and this is
where you can start to put them in a
version control you can start to roll
them inside of your code repository etc
etc you can set up these scenarios where
you have sort of a scriptable behavior
almost simulating what a user is doing
and how they're doing it so you can
start to put in specific requests to
specific URLs you can also have it if
they're phases term is how you can have
it ramped up in number of users ramped
up a number of requests you can simulate
a little bit of people you know entering
pinging a few services here and there
and then all of a sudden a lot of people
hitting it and then you have flow which
is again more of the setting up of the
scenario so this is kind of the nuts and
bolts of how to set it up but this
actually this script right here that you
see up there is probably the simplest
representation of actually making a load
test so it's quite easy so I'd recommend
if nobody is doing it or if anybody
isn't hasn't done it yet you should
probably give it a try it's really quite
easy at least it's easy nowadays and you
can really simulate a lot of user
behavior some of the best practices and
anybody can agree agree or disagree with
this have a little warmup period so
that's something that doesn't really
make sense logically when you think
about it I mean it's it's an application
it doesn't need to warm up necessarily
when you think about it in a production
environment maybe you're warming up your
caches you're warming up I mean I guess
you could be physically warming up the
machine as its first booting but anyway
virtual machines never mind so then you
really want to ramp it up then you've
got your cruising period where you've
got a fairly moderate amount of load
which is maybe at your breaking point
and then you don't always see a crash
test in a lot of load tests I always
like to add one it's just very
satisfying to just finish it off you
know you start it up and then you just
take it down so yeah in this particular
instance a couple of the numbers maybe
the ramp up period is a hundred users
every second cruising is maybe a hundred
users for a good twenty minutes and then
crash is like a thousand users for you
know for a minute straight and that'll
probably take it down so this is kind of
what happens when you run artillery you
know you put it in there you're putting
your services your paths and all of that
and you actually run it this is what
it's outputting
so pretty not pretty there are many
different ways to report on what's going
on so we'll step through a little bit of
the terminology on this one and what
you're actually looking at but at the
end of the day you can generate charts
and stuff with it which we have one of
those coming up and those are actually
pretty the other this thing whatever but
anyway so scenarios launch scenarios
completed a number of requests for
second latency codes this is a really
important one so these are the HTTP
response codes let's say your load
testing a REST API and you're getting a
lot of 500 or 502 s or something like
that your web server is starting to act
a little funky maybe you're getting
timeouts
where does that 504 I don't does anybody
know it's VP codes in here 504 okay good
so if you're getting a lot of 504 is
then you're probably starting to reach
that limit so then you've got requests
completed if that's a good thing the
more you see of those the better so okay
let's look at it on a graph this is a
little bit more interesting and so what
we've got here is response time is in
green the green little boxes throughput
is blue so that's sort of what your what
you're handling and then you have
failures in red so if you look closely
at this and you look around 128 that's
meltdown it is finished it's over it's
not coming back up but if you look back
a little bit so you're almost looking at
this and then reversing time if you look
back a little bit you can actually see
that there are indicators that this is
about to happen so conceivably you could
add some sort of intelligence into your
application that when you start to
measure this kind of failure condition
you could either throw an alert you
could execute some other script you
could target an auto scaling piece of
logic or something like that you could
really start to react or preempt the
crash now that's perhaps a little bit
maybe it's not realistic in practicality
but it is certainly possible and so if
you add those hooks in there and you
have a little bit of awareness or
intelligence in the application you
might be able to prevent it from
crashing under load so if you look back
over under 32 so probably around what's
between 16 and 32 is where you start to
see B be latency and the response time
is climbing up a little bit you know
it's been pretty steady up until that
point but now you have your minimum
response time is starting to creep up so
and it never really recovers it never
really comes back down and then around
64 you start to get these 500 errors
whose HTTP errors and then of course
just crash and burn at 128 so this is a
good way of just looking at visually
what happens to an app as it hits load
or what happens to a REST API so this is
what your friends web logs will look
like after you load tested for him so or
her when do you actually do this this is
certainly contentious but you have beta
testing periods that's probably when I
would recommend doing it maybe
pre-launch you do a heavy duty load test
you could even load test your production
system we do that sometimes we try to
take down our own live website people
well my business partners don't really
like that but what are you gonna do
major product releases right before a
product release we'll try to do the same
thing maybe on holidays when the the
user traffic is down down low you know
there's always that one guy who's up
until like 9:00 p.m. on Christmas on
your app when you're trying to do a load
test so you just you know give them a
little Christmas present
sharing the site with 10,000 virtual
users as we load tests or January
deployment so that guy you know whatever
too bad for him he'll come back they
always do so what do you do next in
terms of load testing and and where do
we go from here
well some of the other capabilities of
artillery back to the commercial for
artillery is you can load in external
data so you can have a CSV file which
may be a bunch of product IDs
maybe you export that from your database
and you load it in here you just kind of
specify a link to that CSV file and then
what it'll do is it'll pull a random
number from that file a random lion and
pull a random number out of it and then
be able to plug that in to the link so
if you remembered back a couple slides
to where we show that llamÃ³ file with
the configuration of the test you could
just specify you know product ID dot
whatever or API slash product slash
product ID and then say hey and use this
CSV file and then you can have somebody
else kind of updating the CSV file or
whatever and you've built that load test
you can step away you don't have to come
back to and it'll always sort of plug in
those values from that list and be able
to test against actual
endpoints with actual values where this
comes in handy is when you have a
production environment and let's say a
dev environment or a staging environment
where you have maybe different product
IDs so you want to do some testing but
you don't want to accidentally hit and
test maybe the live server or something
like that so you have different Product
ID sets anyway replicating user behavior
you can look back through web logs or
something and start to piece together
how somebody traverse through your
application and then you can load that
into those scenarios and those phases
back in that ya mole or JSON file so you
can actually simulate what real user
activity was or in some way now this
probably takes some scripting but you
might be able to take a web log as an
input and then create a load test out of
it so that you're replicating almost
like a groundhog day what happened that
day and and if it was a day that your
thing crashed I mean that it's almost
like playing back history again and
again and you can watch them and you can
make a few adjustments play it back and
then really solve it retroactively Lee
so kind of exciting in that regard
with being able to actually apply this
practically to some problem so you can
also start to integrate it with with
OAuth and with that whole flow so it has
the capability of incorporating custom
headers and headers generated at runtime
etc etc very nice with regard to that so
automating it with continuous
integration so let's say you do a commit
to the repository you could conceivably
execute a load test right then and there
I'm not sure I recommend doing that
because if somebody's committing and
they don't really realize what's
happening as a result maybe you have a
somebody on the team who's a little
commit happy one night and just commit
after committee met them and of course
you're taking down your server every
time if you have that crash scenario
built in they're monitoring live
activities so that's something I kind of
mentioned at the beginning is figuring
out what is actually happening inside
via the application not necessarily
what's happening at the load tester so
the load tester is simulating a client
pretending to be some regular user but
then you also have of course the
application itself so you almost want to
watch on both sides you know it's like
being on both sides of a battle and you
want to see how it's going down so those
are pretty much that's where I would
take load testing and that's where I
would recommend taking load testing when
you want to take it to the next step and
of course it gets even more complicated
than that but that's pretty much that's
load testing in a nutshell and using
artillery very easy to get into and very
fun to watch as something just comes
crashing down that you spent six months
building so thank you very much
any questions there are a couple answers
for that number one is you could do it
one day and then there's site crashes
them you see you know we really should
have load testing so we can see that
coming just cover your tracks and delete
your log files but no I would say that
if there's no way that they can't
understand the concept behind it the
concept of stress testing I mean it's a
fundamental engineering concept there
are entire disciplines of physics and
engineering built around stress testing
and fracture points and all of that and
people do it for building bridges so you
can make a bunch of silly analogies to
them like hey before we build this
bridge and install it between us and the
customer we should really take a bunch
of vehicles over it and see and make
sure it doesn't collapse but I would say
the number one thing just tell them that
there's money you know that if we crash
and we lose a bunch of customers or
customers are unhappy we lose a bunch of
transactions it's gonna cost a lot of
money and it's really cheap now if we do
it some combination of these anecdotes
will perhaps influence somebody but I
would probably just do it and then ask
for forgiveness afterwards questions
yeah
so the question you're asking is if
you're sending a request over to your
server and the response is a little bit
dynamic how does it your gonna be
writing some code for that yeah I don't
think that that's necessarily one of the
primary use cases it's probably more to
see how that end point would respond but
I see what you're saying I mean in terms
of following user behavior if you wanted
to make it let's say pick a random item
from a list that comes back and then
visit that item I believe there's some
level of randomization for picking out
responses in a JSON responds in a JSON
response and using those as variables in
the next test
it does have some capacity for that but
you may end up having to write some code
oh the graph oh they actually have it on
their website
no that's say there's a specific
reporting tool that they have that will
create those sort of load graphs I can't
remember the name of it it's linked from
their website so that that's probably
there so you've got the JSON output that
it that it produces you've got the text
output that I showed on the screen what
these reporters will do and if you've
ever used something like mocha or that's
a testing framework that also has these
sort of pluggable reporting tools that
the normal output is really kind of ugly
and texty and console e and when you
want to show it in a pretty graph you
need some kind of translations so it's
just JSON output that you could graph
with anything really but they also
provide some graphing tools some
reporters so it'd be a custom reporter
visual graphing reporter and they would
have it on their website linked
yeah I mean I would run it on inside of
a sandbox to run it on a localhost now
the trick with running it on a local
host is you're probably gonna want to
have two machines or two virtual
machines I would say that you don't
necessarily want to run the load tester
on the same machine as where your actual
app is or where your service is the
reason being you can actually run out of
network handles depending on your
operating system you can run out of file
handles because you you may only be
getting a number that's about half of
what your machine is capable because the
load tester itself is using quite a
number of resources to hit your server
so that's what I would say is you you
will probably end up wanting to have two
machines next to each other or again
load testing you know your friends
machine I mean having them load test
yours something like that but yeah in
terms of avoiding production environment
make a copy of a production environment
do it on there any other questions Oh
same person sure yeah let me run back to
it real quick
well that's believe that's response time
so it is going up I mean it's kind of
impressive that it's even responding at
that point so I think that are you
talking about the blue line okay
yeah what's happening is it's not really
capable of delivering any more
throughput so you have a little spike
there around 128 where the server
seemingly recovers for a second and it's
able to queue up a lot more requests but
then that queue of requests overloaded
again because it's still kind of
crippled so it hasn't fully recovered
from the load that it's experienced up
to that point so that's why you want to
do this continuous load on it that kind
of a test because you will see it it
could take five minutes of load for
something to eventually dip down and
crash it may not be very straightforward
it may not crash instantly it could take
a little bit and that's just a side
effect of it could be memory allocation
it could be just never able to really
catch up and then it just eventually
sinks but yeah that would explain that
is it it just kind of crashed and then
it seemingly recovered and then it's
trying to stabilize maybe at a lower
point but it'll probably just crash and
come up again for a second in the crash
again okay
DDoS attack is probably going to come
from a lot of different machines and
it'll probably have a lot of different
kinds of attack patterns so I would say
in structuring a load test or
understanding the difference between
them a load test will look like a load
test unless you try really really hard
to make it look like a DDoS attack and
to make it look like a DDoS attack
you're gonna have to use a lot of
different machines probably from a lot
of different places in the world so now
you start getting into network
configuration to where that's going to
be a big variable I would say that this
load testing that well we would use it
primarily for is testing a service in an
isolated environment testing it in a
sandbox what we're testing is not a
network configuration we're testing the
server response code the API the REST
API whatever it may be we're testing how
that handles load not necessarily attack
patterns of DDoS that is a kind of a
separate topic I would say more more
towards security or a network
infrastructure less about code
optimization you can always optimize
your code to avoid that what I would say
is one of the things you do with the
preventing DDoS attacks is you'd
probably start to look at patterns of
traffic and start to throttle down the
network side of it prevent those
requests from ever getting to the server
and this would be more for well what
happens to the requests that actually do
get through what is that failure point
no we have we haven't been doing that
that's the next step really so once we
figured this out and we get our app
seemingly working then we put it on you
know production hardware and then all of
a sudden you know we realized that oh
well now we have to deal with Network
optimization so yeah that's the next
step that would be part two is now that
you've done this and you think you're
done you're actually not done we've
tried a bunch of those different tools
and they all have their pros and cons we
ended up doing something that was
effectively reporting through WebSockets
to a central ops dashboard that does the
reporting built in at bat so it's not
necessarily the most conventional it may
not even be the best way to do it by any
capacity but we effectively have a live
connection between our servers and kind
of behind the scenes ops server and once
that connection is fuzzy we don't really
care what happens to the machine at that
point if it can't report its logs then
it's going down and we kind of reroute
traffic around it anyway so
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>