<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Curtis Chambers: Being Uber with Node | Coder Coacher - Coaching Coders</title><meta content="Curtis Chambers: Being Uber with Node - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Curtis Chambers: Being Uber with Node</b></h2><h5 class="post__date">2013-01-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2Y4EZZFnumo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Curtis with uber I'm the engineering
manager uber this is being over with
note do you anybody here know what Ober
is or has used it before yeah we got a
big fan right there
a couple here for everybody else we'll
talk about my thing works Oh what is
uber just so everybody knows what we're
talking about this but basically it's an
iPhone app and Android app you can also
do it with SMS but basically you press
single button that green button there
and magically a car shows up a black
town car it's fancy it takes you where
you want to go and it's automatically
billed to your credit card no tipping no
cash it's just like magical service and
people that use it love it they go nuts
over it and anyway where you can use it
right now we're in San Francisco we've
been in San Francisco for almost a year
and as of two days ago we launched in
New York as well so we're pretty excited
about that it was kind of stressful
doing that while trying to prepare this
talk so and actually we're about to
expand as TechCrunch to said Seattle
Chicago Boston and DC so if you know
anybody there that needs a job or if you
live in any of those cities we're coming
here soon try it out so yeah anyway the
the real goal of this talk is to talk
about how we went from an old terrible
lamp based system to a node-based system
and it was kind of a huge pain to do and
it's still concurrently huge pain but to
go into that I want to talk a little bit
about the story of node and how it came
about
so our co-founders Travis and Garrett
we're basically sitting around and
they're like you know it would be really
awesome if I could get a car on Friday
night because the cab situation in San
Francisco so terrible I just want to
push a button on my phone and have a car
show a private driver maybe we could
share this driver with a bunch of our
friends and so basically they sort of
had this proof-of-concept built out that
was just like can we make it so you can
push a button and a driver shows up
and so it was like built on a lamp stack
a very basic proof-of-concept not you
know it scalable anything like that it
basically kind of looked like this it's
like the phone just talks to PHP and
mice equal stores all the data about the
drivers where they are all this and that
this architecture is cool when it's just
you and a driver or maybe a couple of
your friends and a driver but suddenly
you have you know we decided to release
it to the world you know anybody can get
their own private driver with with uber
and so when then you have a ton of
phones and PHP like there's a ton of
Apache processes going on which can
cause some issues when you have let's
say a hundred drivers on the system and
thousands of clients you know one driver
is dispatched to two clients two clients
think they have the same driver all
right that's the same thing but there's
a lot of like concurrency problems a lot
of race conditions you need as a
dispatch system you need one solid
process that knows about all the drivers
all the clients can connect them
properly so this architecture doesn't
really work very well so in order to you
know move from this to something that
that made more sense like we started
evaluating solutions what's out there
how can we build a dispatch system that
doesn't have these issues and isn't sort
of kind of hacked together and we
thought node would be perfect for this
single threaded you know it has all the
objects in memory it knows where all the
drivers are all the clients are there's
none of these double dispatch issues it
connects one driver at a time so a
problem is this is live and we already
had like tons of people using it so we
can't just turn the system off build a
node one and then turn it back on again
this thing's going 24 hours a day
there's cars going 24 hours a day
there's people wanting rides all the
time 5 a.m. 3 a.m. whatever so we went
component by component to try and fix it
so basically the first thing was
dispatch that this PHP was doing a lot
of stuff that wasn't dispatch related
you know like at the end of trips it
calculates affaire it does various
things and looking them up so first we
abstract it out all the non-essential
dispatch functions to a Python API and
so basically now
dispatch was very simple very basic
connects clients and drivers still had
issues but we patched the issues so it
was kind of this ghetto-fabulous
solution of like it'll double dispatch
but then reverse it on one of them and
then it'll come back and it it's a
nightmare
so then we you said oK we've got that
out of there maybe now we can slide note
in and actually I don't have a slide for
this but we slid a little node what we
call connection notes in between the
phones and the PHP layer to basically
kind of it manages all the connections
with the persistent connections with the
phones and then tells PHP dispatch like
what to do what to do in that regard and
so then it allowed us to also like put a
new dispatch in the backend and have our
connection node setting it to both new
and old dispatch which then allows us to
test the system live we have two
dispatchers running one of which is real
one of which is a test one make sure the
same things happen and so then now you
can have like node here now this box is
somewhat misleading there's actually a
lot of different components here there's
the connection node that I was talking
about all the phones talk to that you
know there's a ton of different
instances of it it does request
management and make sure that once the
phone sends a request it eventually gets
to dispatch or gets to the API or gets
wherever it needs to go has built-in
retrying things like that there's the
dispatch server which is a node which
maintains in memory all the drivers all
the clients everything that's going on
so there's actually a few different
tiers inside of that node but the
problem is we needed like this is sort
of a master slave system here like on
the dispatch side because we can't have
like five different dispatches all
serving up drivers you know it's we need
the single threaded nosov node but still
need high availability so actually each
of the the dispatches see realises its
state or I guess there's another slide
here which basically separated this into
like a real-time system and a historical
system this is everything that's
happened in the past versus node is
everything that's happening right now
where everything is at the moment so
anyway we serialized things out to Mongo
so that basically should one of the
dispatch servers fail it can pull the
current state of the
of the master dispatch server back into
one of the slaves in it then takes over
as the master so anyway in order to
accomplish this what we call no requests
left behind we built a few components
ones called request manager another is
called slave master which may or may not
be politically correct and then we also
have Mongo rapper now I talked a little
bit about these one thing we found that
was difficult to with note is it's a
process constantly running and we get
hundreds of requests per second from all
of our drivers phones if we need to push
out new code and restart it we may or
may not lose one of those requests and
so we built request manager so that we
could basically tell node like hey I'm
gonna shut down and restart because I
have new code and it would finish
serving up all the requests that had
gotten while blocking all the others it
would return a 410 gone message and so
basically it would say you know I'm not
accepting any more requests but I'm
gonna still fulfill all the ones that
have already come in and then basically
once it's cleared out that entire queue
it then restarts itself and so we now
have a deployment strategy that doesn't
ever lose any requests that come in the
slave master is an interesting component
basically it as I kind of described
before we have this dispatch system but
there could only be one master and that
one does all of the dispatches but we
need these slaves here in case something
happens to the master and so we built
something that's kind of similar to
MongoDB replicas sets but not quite as
sophisticated or basically there's a
pool of them and if the master ever goes
down the slaves elect a new master and
within milliseconds we've it reloads its
state and so again we don't lose
anything and if if any of the
connections on the tier above it you
know sent one to let's say the slave
accidentally it would say like I'm sorry
I'm not the master this guy is and then
it resends the request so those two
combined make it so we basically never
lose any requests coming in now Mongo
wrappers just sort of a helper thing we
built so that MongoDB was a little bit
easier to interface with and in a node
because if you've used the MongoDB when
you know you have to make a connection
and then you insert the collections if
it fails it has to reconnect and you get
this asynchronous night
where you're tabbed in like you know
eight times just to handle a single call
so anyway I'll show some brief examples
of these modules we're thinking about
open sourcing and we just need a
genericized a little bit so so request
manager is very simple and your
constructor of like your server you just
start up a new request manager it
listens on a port let's say 9000 and
anytime that the server receives a
request it doesn't the request manager
and it creates a context with the
request the body that it just received
as well as the response object and then
our server let's says say processes the
message of that that's all the code you
need to basically use request manager
that's all we added to our server and
now we have the ability to restart node
without ever losing any requests which
is awesome it's really that's it and
it's pretty basic
the next piece the slave master piece
there basically is a like array of
servers you know this is like a snippet
of our configuration file let's say
listens on the port publicly then
there's the request manager port as well
as the slave master port so all the
masters and slaves talk on port 8000 and
- they're constantly talking to each
other to make sure that they know who
the master is that everything's cool and
this is again is really simple all we
did is say new slave master I am server
1 let's say or server 2 and here's the
list of all the servers and there's a
callback so basically when I become the
master I need to load in data from Mongo
so that I can take over as the master so
that's pretty much all that was - we
built all these components after we
built the dispatch system just a
bullet-proof it and we built them in
such a way that only took like three or
four lines of code to basically make it
bulletproof in that regard so and then
Mongo wrapper again really simple works
with replica sets or just a host port
pair passing the replicas set the
database you want to do there's a retry
limit or retry interval
you know in case Mongo goes down which
in a replica set would be kind of a
highly unlikely but you never know
one of the things that manga rapper
provides that we added was journaling
now Mongo does journaling on its own but
it doesn't journal when it's down
because it doesn't exist so we have our
own journaling that basically writes to
the file system all the queries that
didn't make it into Mongo and so there's
a backup directory there how long it
retries and restores and then basically
anytime we need to insert update remove
from Mongo it's as simple as a one-line
call and it handles all the reconnecting
the Mongo you know making sure that
requests eventually gets there no matter
what so yeah that's a Mongo rapper
component we also built a serializer
that serialize a state to Mongo but I
didn't really write that cuz it's very
specific to our use case but these are
some of the things that we we think
about open sourcing I'd be curious if
anybody would like these components
because then we'll definitely work on
that open source it maybe get some
people to contribute to them but they
actually made our whole architecture
like completely bulletproof we don't
even care anymore when servers go down
that used to be our nightmare on Friday
nights like out of the bar I get these
email notifications it's just you know
the entire architecture originally was
running on one server which is never
gonna be a good idea so there's a few
other things that we got from moving
things to node like kind of ancillary
benefits to our tools that are actually
really interesting we can now share
these JavaScript objects between both
the client and the server now most of
our app is you know our client is on
iPhones on androids SMS it's not a
JavaScript client but we have a lot of
internal tools that are JavaScript like
monitoring tools the big one that wired
did a story about us recently and they
talked about this as well as The Wall
Street Journal is called God view and
God views basically what we do while I
watch this all Friday night now like
it's amazing it's just so much fun to
watch it's a live real-time Google Maps
interface of where all the cars are
where they're going who they're picking
up what they're doing and so we built
this before and just hand coded it up
we had our intern last summer coded up
in one night and but now we can actually
make god of you a little bit more
maintainable I'm thinking about
rewriting it with now Jay
I just learned about that yesterday or
two days ago at Jay s Kampf you know
basically saying to the to the note
dispatch like hey give me all the
clients and drivers I'm just gonna draw
them on the map here and so we have a
lot of internal tools that are now made
easier to implement because of note you
know we don't have to maintain a
separate PHP code base with all these
objects and a separate JavaScript code
base and then we also have the Python
code base and it's just out of control
we've we've basically now just purely
JavaScript and some Python as well so
some of the other cool things we've been
doing with some of this data is uh heat
maps we've been trying to find new and
interesting heat maps to display or what
we call data porn team we have like
several PhDs that that work on mining
our data so that we can make the whole
system more efficient this isn't really
node related but it's just kind of cool
to look at and it's an it's like really
intense data analysis so for example
this is San Francisco all these points
are points where the drivers were when
they accepted a request and it's kind of
cool how it just outlines the cities and
you can see where where they wait when
they're about to go pick up people all
over the place and then there's things
like this this is Manhattan this is
where people have opened our app and
tried to get a car in Manhattan so this
is like basically the demand heat map of
Manhattan for people that want an uber
car and then there's other ones that
we've been doing some more intense data
analysis about like how long it takes
for our cars to arrive so we have heat
maps like this which is that's basically
San Francisco you can kind of see the
outlines of the streets and basically
how many seconds it takes for our car to
arrive once you say I need a car and
we're actually really good in various
areas of downtown obviously out in this
burbs we're not as good but there's not
as much volume there so it kind of makes
sense so these are kind of some of the
problems that we're solving node has
helped us make a really cool scalable
distributed architecture the CEO and I
had a peer-to-peer content delivery
network before called red swoosh so
we're really good at building
distributed like fault tolerant reliance
systems and so we're taking that that
knowledge and basically bringing it to
you know an on-demand car service that's
going to be in every city in the u.s. so
and then again like we said we have
teams of people doing this amazing data
analysis as well so yeah if you want to
read more about some of the data
analysis we do we publish it to our blog
this is the link to see the two posts
that we've done so far one was a we
analyze we could take the weather data
and correlated it analyze the effect of
rain on demand and it turns out rain is
amazing for our business I used to love
sunny days now I don't anymore
so that's why you know why we're going
to Seattle so anyway if you want to
check out some of our data post we have
this we also have one that shows how
we're actually cheaper than cabs despite
being more expensive if you value your
time at all that's a really interesting
post especially in San Francisco where
cabs don't really show up so yeah so
check that out this is we're doing some
really cool stuff and we're hiring so if
anybody needs a job let me know come
find me
so that's pretty much it short talk the
question is how big is our deployment
right now we're powering it on just six
servers like I said we've got actually
that's not true
we have 10 servers but yeah we basically
have at least three of each component in
the like so basically there's like the
connection no tear the dispatched here
the API - and like we have at least
three nodes of each tear some have more
some have less and it just depends on
demand but we have we don't have the
elasticity of demand problem that a lot
of people have that's why people go to
ec2 because they never know when they'll
get demand spikes and need to spawn up
new servers we don't really have that
problem because we control how many
drivers we have and drivers are the only
thing that generates significant demand
on our system so you know if we if we're
gonna hire thousand new drivers we know
about it well ahead of time and can you
know work on that so you local
deployments engineering wiser
what do you oh we haven't really seen
that is something we need to do it might
make the request slightly faster our
biggest issue right now is like ATT like
getting 3G connection every driver has
an iPhone in their car and that
how we know what's going on in all the
cars and you know AT&amp;amp;T in San Francisco
New York are legendary for their
unreliability so hoping the Verizon
iPhone can fix that a little bit it's
not super extensive I mean it's
basically like there's a client object a
driver objects like a trip object like
there's there's these basically
JavaScript objects that we then use to
then plot like God view and things like
that but you know there's not a there's
not a ton I mean we're actually just
embarking on rebuilding all of our
internal tools using backbone and so
with that I think we're actually going
to have a lot of interesting tie-ins but
really gotta be is the only thing right
now that shares between the client in
the server so oh that's just kind of
like a super crazy backup like if if for
some reason it never gets inserted after
days and days and it's kind of like dump
the queries here and so will eventually
go back and look and see what what never
got inserted into the database so um
yeah it's just like where queries go to
die basically anything else yeah we used
the Mongo native DB module we just
extended an open source the node logger
module which I think just got renamed to
n logger
we also use I think node settings really
basic stuff we wrote almost everything
we have by hand we basically just
brought in logging brought in settings
and then the Mongo DB interface and it
oh we also used the o3 module for XML
parsing because again the the proof of
concept system used XML and so now we're
like working on getting everything to
JSON but again when it's a system in
flight and you have to wait for people
to upgrade their iPhones you know
upgrade the app on their iPhones so we
need to accept both XML and JSON
requests from there so no no only Python
does that we use sequel alchemy for that
so else
cool thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>