<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[JSConfEU 2011] Mathias Bynens: Using jsPerf correctly | Coder Coacher - Coaching Coders</title><meta content="[JSConfEU 2011] Mathias Bynens: Using jsPerf correctly - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>[JSConfEU 2011] Mathias Bynens: Using jsPerf correctly</b></h2><h5 class="post__date">2013-06-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/RLbAKxCAdI8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">nobody casco and I just fronting web
developer from Belgium and about a year
ago by make this website called Jasper
much shorter time I heard used it before
Ken's death at home again who's Jasper
to create valid performance test cases
and focuses on other parts so just to
write rehydrate Jesper black market
which is my spaghetti code with PHP
server okay everybody the day that just
were first watched I also saw at the
National GS projects for stocks you need
a JavaScript benchmark a library and
originally I just took out with night
working on wearable but yes it was
priority word I threw out everything
else at identities and I add my own
stuff to it and that's what I mean
Matchbox yes so it was really just for
specific and it was not much of a chair
of the book was hashmark library the
other open source is hoping that if you
see a hand over time and luckily someone
stepped up performance later which is
calculated Elton and he made a much more
awesome alum bug fixes he had more
features and he made a generic lie
buried at work across different
environments and the best thing about
that crazy process for you can get
support from Brussels and also screw
this guy so we have the vision we have
benchmarked ES and then the final
ingredients for jasper is a browser
scope which is the project that we're
using to store the results based on your
browser so after you run a test we
gather those results and we store them
so I can show you a nice little table or
a chart which contains all the
information of the tests that have him
run by other users and the browser scope
guys actually had to Twitter API for us
so that we would be able to
automatically create new tests with them
for every new test case that's created
on GS perv so thank you browsers cope
now here's some quick statistics they're
not all that interesting but the main
thing to remember here is that ever
since jasper first launched there are
about well almost 57 new test cases
added every day and I mean I think
that's a lot of test cases and that's
all very good news but there is a
problem with that the problem is that
about sixty-eight percent of Allah
Jasper test cases is broken according to
Jean Jacques Rousseau and well it's true
mistakes are very easy to make and it
kind of sucks because Jasper allows you
to easily create test cases but you know
even the tiniest little mistake that you
make or the tiniest a typo in your code
will just render the test invalid and
results would be meaningless and was it
not william shakespeare who as written
it would be unwise to take all jesper if
results for granted
he was right this would be very nice if
we would be able to just browse Jasper
and you know look at the results and
make a decision based on that but
unfortunately it's not that simple
because there are too many mistakes that
are made and I've written about
benchmarking pitfalls before together
with John David Dalton again if you're
interested you can just read the article
build proof JavaScript benchmarks the
link is at the bottom but the main
topics there are that there are a lot of
inaccurate millisecond timers in
different operating systems and browsers
and of course if your bench marking code
in JavaScript you will need to work
around that to still get an accurate
result I probably don't need to tell you
that browsers have books so if those
books affect the way your benchmark
codes you will need to work around those
bugs as well and maybe one of the
biggest problems with benchmarking is
that you will need to have statistically
significant results if you don't do
statistical analysis on your results
they're not completely meaningless but
you know they're not as it should be and
this really sounds self-evident but if
you want to run a test and you later we
run the same tests on the same browser
in the same device with the same
settings the same everything you're
going to want to get the same results
right and it makes sense but even the
bigger browser benchmarks like sunspider
and Kraken they still don't get this
quite right so if you run the same tests
twice in same browser sometimes will
tell you that your browser is faster or
slower than itself so no results they're
not really as meaningful as they should
be another thing to consider is that
there are browser plugins and add-ons
that may influence the results for
example Firebug in Firefox is known to
disable the jets and Firefox so all
JavaScript that you'll overrun will run
much slower and on GS perfect right to
one you if Firebug is enabled to try to
detect it and show a warning but it's
still up to you to disable Firebug and
rerun the tests because for example it
wouldn't be fair sure to compare the
in chrome and you would compare the
number of operations per second that you
would get from Jasper with the number of
operations per second that you would get
in Firefox with Firebug enable that
wouldn't be a fair comparison at all of
course Firefox is going to be slower
that way another thing to consider is
that you should always test in all the
browsers that you're planning to support
there's no point in creating a test case
and just throwing a test and say Safari
if you're going to support all browsers
all the way back to ie6 everybody is
different every JavaScript engine is
different so it's very important to test
in every engine that you're planning to
support and well maybe the biggest
problem of all is that a lot of tests
are incorrect or make assumptions that
aren't quite right now when we look at
the six bullet points we can divide them
into groups and the first one or three
things that benchmark yes and this
Jasper takes care of for you so good
news is you don't have to worry about
these three things again the bad news is
that you will have to worry about these
three things these are things that
Jasper cannot enforce on you so you will
have to take care of it yourself in the
end it's you who has to write the test
and run them correctly so please do that
correctly now let's see what's the most
common problem with tests and their own
fair comparisons incorrect tests suck so
let's see what we can do about them here
are a couple of quick hit hints and
quick tips that you can use to make
better test cases in Jasper so the
function declarations that you will use
in your test they should go either in
the preparation code or in the setup
code so on Jasper if that looks kind of
like this you have this big text area
where you can enter all the JavaScript
that will be executed first time in the
global scope so if you have any
functions that you want to declare just
do it there don't do it in a test body
itself only the bare minimum should go
inside of each test body so ideally you
would get something like this see it's
really concise I'll see I've seen people
include the entire jQuery source in the
test body itself and
that's not how Jasper perks yeah well a
good example of the test case is this
one this is the preparation code that we
saw earlier this is how what it will
look like when the test case is finished
so you get a syntax highlighted view of
the code you got a nice little table
with all the different tests in them and
then there's a button that allows you to
run the tests and results will look
something like this depending on the
browser of course I won't just prefer
sure which one is fastest and which one
is slowest here's another common problem
i made this test case regarding
Fibonacci numbers so I found a couple of
functions that allow that we you pass an
argument which is an index and then it
returns you the Fibonacci number with
that index from the sequence and you
know I run some tests and turned out
that the first solution that I found
what's much much much faster as you can
see the second option is about
ninety-eight percent slower and that's
kind of a big difference so yeah first
reaction would be yeah okay let's use
first one it's much faster but long
story short you got to make sure the
methods you're comparing actually do
exactly the same thing if they don't
it's not really fair comparison and
depending on your use case that may or
may not be a problem so if there is a
difference in the different function
that you're testing please be polite and
mention it in the description of your
test case because other people will look
at it and it's best not to confuse them
so in this case I investigated a little
further and I noticed that the first
function only handles indexes up to 1474
while the second function allows a nexus
up to 1476 now that may not be much of a
difference but depending on your use
case it may be so it's important to be
aware of it and also a later found out
that the first function you know the
super fast one starts to earn inaccurate
results starting at the index 76 so
again depending on your use case that
may not be a problem if you're just
getting an approximation but maybe it is
and then you still have to use the
second function even though it's lower
so that's something to consider another
thing is you have to make sure that
really testing or to intended to test in
a good example of that well a bad
example of that is this test case the
title is jQuery ID versus native get
element by ID so you would expect the
best case where you would get an element
based on its ID using jQuery versus
using a documented get element by ID but
when I looked at the test it looked
something like this as you can see what
this is really testing is how long it
takes to bind an event handler either
using the dumb 0 window download or by
using jQuery and calling the load method
which by the way I don't think load
works the way the other things it does
because load is used for IX stuff in
jQuery so really whatever is inside of
the event handler here it doesn't really
matter because it won't ever get called
during the tests so even if you know
even if the second test would have a
super slow event handler it won't matter
in this case and you can tell because
good results are the same the last
result of course is a little slower
because you're making a call to jQuery
there but this test is kind of rubbish
another thing to consider is that when
you're using variables across tests you
need to make sure that you reset them
whenever it's necessary for example this
test case here they're trying to compare
if it's faster to do a plus equals B or
if it's faster to do a equals a plus B
which both do the same thing and
honestly I would expect both to be
equally fast and it's a very micro
optimization anyway the problem with
this setup is that in the preparation
code a is set to 2 and then the test
starts running so by the time test one
starts a equals 2 and it's a commented
all the time but by the time test one is
finished and has two starts running a
will be a much higher number it will
have a much higher value so that may or
may not make a difference in results and
in fact in Opera
discrete from opera and there it does
really make a big difference as you can
tell the second method seems to be
thirteen percent slower but it's not
actually slower just because the number
a has much higher starting value for the
second tests so it's not a fair
comparison the fun thing is that if we
rerun the same test afterwards so after
we get super high values for a we run
the test again we get a completely
different results so now we see that
both tests turn out to be equally fast
so whenever that happens on the Esper
there's something wrong with your test
case we're on the same test twice and
get different results something is wrong
that's a red flag another good idea is
to never introduce randomness in your
tests I saw this test case here and as
you can see inside the test body the
author used math dot random to generate
random numbers then round them down and
then do some other stuff with them the
problem with this is that there's always
the chance that you get numbers that are
slightly faster to ramp down in one of
the tests so you'll never know if
actually the function that you're
testing is faster or if it's something
else that's influencing the results so
if you want to test with different
numbers that's great but just add
multiple tests to the same test case and
don't use random numbers another pro tip
is never just asynchronous stuff
synchronously it sounds logical but a
lot of people make the mistake for
example at this test case
as you can see we're testing through
different functions in a set amount in
the same set them out and they turn out
to be both as fast even though the first
so the test one function it's supposed
to be fast while this test tube function
is supposed to be super slow and of
course they're equally fast for Jasper
because you're testing something is
synchronously that's testing something
synchronously that's supposed to be
asynchronous the set timeout it will
yeah it basically is no operation test
initially the functions will be called
eventually but they will be called
outside of the test loop so it won't be
times so in this case you get it seems
like their boat as fast but it's not
really the case if you want to do a
synchronous test here's a good example
of doing that right so jess perf has
this checkbox for every test that you
add this isn't a synchronous test well
if it is just hit the check box and then
all you need to do is you get a deferred
object for free and you just need to
call resolve on that object and then the
test will finish so for example in the
html5 spec the minimum set timeout value
allowed is four and that wasn't spective
or so I decided to figure out which
browsers already support this feature so
the idea is that if you would use the
zero as timeout it would still use for
instead so i created this test case see
the only thing that's different is
timeout value that's always increasing
by the way that last value is really
weird with some browsers have an issue
where if you use this value or a higher
value it will still use zero or four
instead it's really freaky so I added
that to the test this is a good example
of an a synchronous test
it also really helps if you learn the
difference between preparation code and
the setup and the teardown sections so
Jasper looks something like this right
these are the most basic fields where
you can enter your alter details and the
title of the test case but here's the
interesting part so you get a
preparation code for HTML I like to call
this the preparation h fields and
there's also feels for JavaScript and
all you need to know is that this code
will be inserted into an HTML document
so the JavaScript that you enter there
will be evaluated in the global scope so
if you were to create a new variable in
the preparation code for JavaScript it
would become a global variable the
difference with setup and the teardown
test is that they run same scope as the
actual tests so whatever code you enter
here it still won't be x same as the
same as the preparation coat it only
times but they do run in the same scope
which allows you to do all kinds of
crazy and cool stuff for example there's
this test case that multi made a couple
of weeks ago and well the setups like
this he as you can see he clear eighths
some global variables here and for
example the I variable is using that in
the tests in a used them in every test
so that's not a problem because the same
scope lookup is done in every test but
then for example if you look at the boo
variable he's only using that one in the
first two tests so those first two tests
they have the performance penalty
penalty of a scope look up while the
other ones don't so it would be slightly
better and slightly more fair if you
would were to change the test and use
setup code instead so all let me change
this we move to variable declarations to
the setup code and this way the variable
those are created in the same scope as
the tests themselves so no scope lookups
and no performance penalty for the first
two tests and I think this is a slightly
more fair comparison again this may not
make much of a difference in every
browser with in some browsers it does
and in some situations it does so it's
better to
do it this way another example of using
these advanced features is the dumb
cleanup for example when you're testing
how long it takes to insert a new
element into the Dom you could do it
like this without using setup you could
just use a preparation code could create
a new container element so a reference
to development and a variable called al
and then we just use that variable in
every test the problem with this setup
is that test code is repeated
potentially millions of times so this
would add a lot of elements to the Dom
all right so the problem with this setup
is that the test code is repeated
potentially millions of times so this
would add a lot of elements to the DOM
and things might get slow the thing is
you're only trying to test how long it
takes to insert the new elements and not
and you know it may be faster if the dam
is already huge it may be slower if it
down is already huge if you're inserting
new elements then so ideally we would
reset the container element every would
clear it of all its children and we can
use the tip code for that so the setup
code will be run for each test batch so
right here we're just clear the inner
HTML which will effectively remove all
child elements however we can fill
optimize this test case a little bit
because we are only interested in how
long it takes to insert key element into
the DOM and right here we're still
creating the diff and the P element in
memory so that also gets timed and
that's also going to influence the
results so if you want we could simplify
this into something like this where we
basically we create the elements in set
up code as well and then the best
buddies themselves are as small as
possible and you're only really time how
long it takes to append the new elements
and as a bonus by doing it this way it
will always reuse the same elements
rather than creating new ones every time
so there's only ever going to be one
child element in the container element
this way so it's much better
another of pro tip is that benchmark
jess is used on Jasper and there are a
lot of advanced settings that you can
use that Jasper doesn't even have a user
interface for so if you can just go to
the documentation if you read through
the API there's a lot of cool stuff that
you can discover and tricks that you can
use on GS curve for example i created
this test case to test how long it takes
to remove a child element and so let's
see we want to test how slow it is to
remove an element from the dump I've
only added one test and all that's
happening there is an element gets
removed that's it the problem is we need
enough elements so we can remove them
because we don't know how many times it
tests will be repeated because J
benchmark Jess will automatically
calculate that for us now the thing is
we can actually get the test count by
using this in the setup function this
will refer to the current benchmark
instance and every benchmark instance
gets account property which refers to
the number of times the test will be
hydrated so this way we just if you just
look at a setup code here just adding as
many child elements that we need so
exactly the right amount so that's
thought it was pretty neat of course
there's some other stuff that may mess
with your results that we didn't cover
here unexpected browser features for
example opera suddenly decided to start
cashing the query selector all results
and of course if you're testing if
you're creating a benchmark for query
selector request select the row Oprah
has a huge advantage so ideally you
would have to work around it by using a
different selector every time another
the interesting is that code removal of
course that's a very hard to predict and
you know if there's if you're getting
weird results you know some that code
might be in there of course there is
much more but the idea is that if we all
help each other if we
test case that's incorrect in some way
just leave a comment or four kids and
improve it just so others can learn from
it as well that's it from are there any
questions
hmm well yeah well the question was am i
planning on adding new features through
GS curve the answer is that there's a
lot of things on my to-do list and one
of which is adding a search go to the
Browse page and you will get back all
this cases but I checked it last week
and it was about an HTML document of
about two and a half megabytes so it has
got my gosh there's a lot of test cases
on there so I really need to do
something about it and the quick fix was
to just limit the Browse page to 2050
latest tests so that's what happened now
but i'm planning to add a search
functionality to it soon I think there
are another couple of other things lined
up there but there's a github repo if
you check my user account matches
balance on github there's a repo for
Jasper com there's no code inside of it
yet I plan all open sourcing the PHP one
day but uh I'm a bit too ashamed of it
right now so need to clean it up a
little bit the repository has an issue
tracker and all my to-do items are being
tracked there so if you have any
suggestions you're free to just file a
new ticket and I'll see what I can do
any other questions
oh if you have questions you can always
fin either me or Jay Dalton or there is
also this twitter account of GS work
itself and its jsb RF because someone
will guy named joy / supply she has the
other account so if you have any
questions just other just mentioned JSP
RF in your tweets and we'll try to get
back to you as soon as possible any
other questions yeah okay thank you very
much for listening</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>