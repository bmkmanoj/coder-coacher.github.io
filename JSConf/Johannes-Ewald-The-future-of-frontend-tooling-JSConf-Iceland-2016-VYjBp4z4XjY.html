<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Johannes Ewald: The future of frontend tooling - JSConf Iceland 2016 | Coder Coacher - Coaching Coders</title><meta content="Johannes Ewald: The future of frontend tooling - JSConf Iceland 2016 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Johannes Ewald: The future of frontend tooling - JSConf Iceland 2016</b></h2><h5 class="post__date">2016-09-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VYjBp4z4XjY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi welcome everyone who are few things
that front end development has become
more complex in the past 45 years okay
you're not alone I think 2015 was the
year of JavaScript fatigue and the term
was coined by an excellent article by
Eric Clemens it was published in
December 20 2015 and it was about the
explosion of libraries and tools that he
had experienced when starting with react
and he certainly right so I try to
collect all the truths it's just a small
collection we have custom languages we
have linters we have bundlers we have
many fires we have def troops to support
our development workflow we have task
runners we have Tom libraries routing
libraries state libraries and of course
we have package managers to install all
these things so a lot of tools and but I
think this was in the end of 2015 but
now it's 2016 so we in the future right
there are a lot of exciting new
technologies coming up like HTTP two or
es2015 or web components and the browser
support is getting better each day so in
modern browsers so how do these new
features change the way we work and do
we need even to even eat these tools
that I've mentioned before but it become
natively available through the platform
and that's actually the topic of my talk
it's about the future of front and
chilling and my name is Johanna say but
i founded a company in Germany with my
friends it's called Paragon and this is
my twitter handle and yes it's 3m
because 2n was already taking yeah and
we do also a lot of open source we are
very passionate about all source I think
every company should do more open source
and I'm also happy to be a member of the
web pack core team and now we do weekly
meetups and talk about a new stuff in
backpack so let's explore these new
technologies and we start with East 2015
modules because I think they are really
great and you probably have seen them
already if not I just show it to you you
have an export statement and you can
import stuff and directly and it's a
real nice syntax it avoids naming
collisions and I think that's one of the
biggest parts that has been missing to
JavaScript and actually it looks pretty
similar to come and guess what we are
used to write in nodejs so it looks
almost the same but actually there's a
big difference there are two important
differences so in common j/s you can do
dynamic imports like this one where you
require just a variable you don't know
what the path will be it will be
determined on ranch I'm so it's totally
valid but you can't do that with is 2015
modules this would be a syntax error if
you import a variable you need to name
the exact half up front and another
difference is that with come on Jas you
actually get a copied value so if you
import a number you get a copy of that
number and if you import a function you
get a copy of the reference to that
function so in this example when I
increment when I call increment and the
number will not actually be incremented
incremented in maine j/s because i got a
copy and with is 2015 you get life
values which means that you get the
actual value into the module scope it's
like like it has been defined in the
extra scope so that's a real difference
and you could not
really do that without the native
support these properties make is 2015
modules less flexible than comment yes
but they are also the foundation for
three shaking and three shaking is let
me explain that so for instance if you
have a module that has a value and we
have two functions increment and
decrement but we only use the function
increment so we don't really need to
include the function decrement and with
tree shaking and is 23 modules we are
able to resolve that because we can just
just by looking at the source code we
know that the function decrement is
never called so we can just remove it
from the code and this is called tree
shaking so the static nature of is 2015
modules makes it possible to trace all
the exports that are actually used but
with a static model system how do we
load things on demand that's still
important especially in the front end
and so there's another tool it's called
system import so system import all
things and that's a way to load
asynchronously and in a dynamic way and
to load modules into the program it
looks like this where you call system
import and you specify the module and
you get back a promise and of course
this could fail because network is down
or something or the money could not be
found so we have also to handle the
error but unfortunately things aren't
finalized yet so that's because system
import is very platform specific and
many things need to be consistent
considered so system import works
different in node then it works in the
browser so it's hard to get these things
right and that's why the tc39 decided to
exclude
is 2015 and it is now currently
specified as separate loader standard so
once we can load more is natively in the
browser do we need tools like browser
fire or web pack anymore well to answer
this question we should take a look at
another technology first and this is
HTTP two and I will not talk about all
the new features of HTTP true there are
a lot of creatures like header
compression but I don't think this would
be another talk so I just keep my focus
on features that are important for the
front and tooling so first feature HTTP
two is a binary protocol you know HTTP
one is a text based protocol so requests
and responses are actually streams and
you screams can be divided into frames
and frames can be interleaved so now we
have multiple requests and responses
simultaneously on a single TCP
connection and this actually eliminates
HTTP one's problem of head of line
blocking where you had to wait for the
response to be finished to send the next
request and this actually invalidates
some of our best practices like bundling
multiple resources into one file to
avoid requests or domain sharding where
you put your assets on different domains
great so let's get rid of all the
bundles and just include our development
files well not so fast there are
problems first one tree shaking when
there are no bundles who is doing the
tree shaking we still need a tool that
figure out all the dependencies and
resource all the imports and then that's
the tree shaking on a moral code the
second problem is minification we also
need to minify the HTML CSS and
JavaScript we still there we also have
compression and choose the compression
is better if the
choo-choos the compression is good at
removing repetition so when we have a
big file it's more efficient if we then
compared to compressing many small files
so it may be still a good idea to put
all the files into one file probably and
the last problem is the round trip the
browser can only discover additional
dependencies after the response has been
received and passed so I call this the
A&amp;amp;D problem like the client says oh give
me HS and services here we go oh I see
now I also need pjs no prop here you go
sorry do you also have CJ s so it goes
all the way like this and that's where
another feature of HTTP comes into play
it's called server push and with the
server push we are able to push
resources proactively to the client so
now when the when the client tries to
request that file it is instantly
available available and can be cashed so
then yeah so what do we need to provide
sort of push and for instance we could
use a dependency tree like if we have
index HTML we have an index.html and we
know this index HTML imports or requires
a style sheet and it requires JavaScript
we can put that into one chasing file
and just let us serve a handle that
manifest so this is actually a proposal
from google it's called the push
manifest proposal and then for we have
this dependency tree for each file for
instance for the app CSS there's also an
else statement that imports the image so
we have to do that for every file
and how do we get this depends tree so
there are two ways to do that we could
analyze the traffic using the referer
header and see where the requests are
coming from or we could use a tool like
a bundler that figures out the
dependency graph the dependency graph is
the data model where you say oh this
fire requires this file this file
requires this file and so on okay so
great let's figure out the dependency
graph and push everything to the client
oh not so fast there are still problems
the first problem is responsive images
we need information about the client
because we don't want to push
high-resolution images to small screens
for instance the second problem is the
cash we don't know what the client has
already cashed so we cannot just push
all the things to the client because
maybe it has it has cashed it already so
we don't want to waste that precious
bandwidth and there's a proposal for a
proposed solution for this it's called
cash digest the next problem is
authorization so we need to make sure
that we don't push confidential
resources to the client so push
basically requires the same of a
relation flow as requests and we can't
we can't push resources from third
parties or so if we are using a CDN and
our own server we see the end can't push
just push a resource to the client there
must be one initial request first and
the last problem is prioritization
because if we just push all the
resources without prioritization it
actually harms performance so for
instance if we have an HTML file like
this where we include a main CSS and in
the main.css there is a phone face
included and we have two heavy images
now CSS and fonts a render blocking and
images or not but if you just push
everything to the client the images
would waste our precious spent if so the
initial render would be way slower than
with HTTP one because we are wasting
bandwidth on images but we should push
the style sheets and fonts first and
that's why hcp provides a way to weigh
each stream and pause resume and pencil
extreme but a good implementation that
takes everything into account is very
challenging and complex and actually
with HPV one with the head of line
blocking it actually prevented this kind
of wrong prioritization because if we
had an HTML file like this we knew
exactly in which order the files are
requested so maybe the head of line
blocking was not so bad at least it was
predictable what will happen so in this
case we can even include dimensions to
the image so the image layout is already
rendered and the browser chest needs to
actually render the image but it already
can build the layout of the page then as
next and last technology we have web
components and the vision of web
components is you can think of web
components as reusable user interface
which is that I created using open web
technology they are part of the browser
and so they do not need external
libraries like jQuery or dojo an
existing web permanent can be used
without writing code simply by adding an
import statement to an HTML page I've
copied that from the Mozilla developer
Network but actually web components is a
bit as a fuzzy term because it refers to
four different technologies we have HTML
templates we have HTML custom elements
we have the shadow DOM and we have HTML
imports and actually custom elements
HTML imports and the shadow Dom have
already gone through several revisions
which makes it really hard to find
up-to-date information when I was
preparing the talk it was very confusing
for me too and I was not sure if this is
the current draft so and even Mozilla
Microsoft decided to post development on
HTML imports entirely because they
thought that the es lo de spec has too
much overlap with HTML imports so yes
this spec is currently paused but let's
start with HTML templates they provide a
way to define HTML fragments that are
parts but all interpreted so these
templates are inert which means that no
markup is displayed no styles are
applied no images are loaded no
javascript is executed and the inner
contents of the templates are invisible
to selectors so it's just an inactive
part of the page and we can get that
into the drum by importing it into the
drum and now we get real Dom nodes and
then it will get active the second part
is custom elements it's in a JavaScript
API to register custom implementation
for arbitrary elements and the current
draft looks like this we define a class
my button that extends the HTML button
element for instance and we have
lifecycle hooks like connected callback
disconnected call that it looks a bit
like a react component and then we can
register the element by calling custom
elements that define and we can even
extend built-in texts like the button
and like this the next part of the web
components back is the shadow DOM and I
think this the heart of the web
components and the
most it's difficult to polyfill this
because it's encapsulated in heitz
elements styles and events behind a
single element and it also describes how
content of the documentary is trans
cluded into the shadow tree it's a bit
complicated and I will not go much into
detail here but it's looked it looks
like this where you attach a shadow Dom
it's like encapsulated part of the DOM
and that's where all the styles and all
all the texts are just encapsulated and
last part is HTML imports where you can
import other HTML documents into the
current one including all the templates
styles and scripts so for instance if we
have a link tag here and we import blog
post dot HTML all these styles are
immediately applied to the importing
document all the scripts are executed in
the important documents context but all
the HTML needs to be appended to the
dome via JavaScript great so let's get
rid of all the frameworks and just write
native web components well not so fast
the first problem I see is the data flow
with web components data is usually
provided as strings by attributes on the
shadow host like this in this example I
think this may work for simple
components but not for more complex ones
like higher-order components and I don't
really want to write code like this
where you have to write a chase and
attribute value the second problem is
it's still very imperative so with web
forum frameworks we get a declarative
way to to describe Dom manipulations but
with web components it's just like
manual Dom manipulation and where
imperative way so personally I don't
want to go back to that kind of style
and they are self-contained which sounds
nice but my encapsulation is a good
thing true self contained web components
from different sources may not be
desirable so for instance we may end up
with different versions of react angular
and ember on the same page and I don't
know if we really want that and the
second a fourth problem is global
namespace it's like the mistakes from
the past where we always have to care
about conflicting namespaces and to
prefix all the stuff so hmm imports
don't really solve that well we may have
a fly flash of unstyled content if we
fail to deliver the implementation of a
custom element fast enough the browser
will display the custom element is HTML
unknown element which is not not good
and last but at least we don't really
have a path for progressive enhancement
so web components are defined via
JavaScript and if something goes wrong
our web app will be problem and of
course that's also the case with a
single page application frameworks but I
think Universal javascript is a good way
to always fall back to server side
rendering if something goes wrong on the
client so I still think we should keep
the idea of progressive enhancement
alive okay so the conclusion will is
2015 models change the way we work yes
of course finally we have a universal
module format for JavaScript it's a
great sin tax it avoids typical problems
like namespace conflicts it enables tree
shaking through static analysis so I
just have i can write choose that reads
the code and understands what what the
code is importing and then we can remove
all the unused stuff and i think it's a
good idea to encapsulate platform
semantics
into a separate lower spec so we can
define all things for the browser in a
in the Lotus back and for node and maybe
whatever need JavaScript environment
will come up we'll hdb to change the way
we work yes of course by new streams
invalidate former best practices we have
to rethink all of them again we have a
more fine-grained control over
optimization and so approach provides a
new way to deliver resources separately
but in order to leverage streams and
server push we need to weigh in control
these streams we need sophisticated
server implementations and we need tools
that feed these servers with relative
information about our web app and of
course we need careful and hopefully our
automated testing to check if the
performance is still good and went up we
should stick to all that best practices
where appropriate so we should not throw
all the way well that components change
the way work yes they provide new dawn
parameters for future frameworks they
make the platform itself more
customizable and I think that's a good
idea to explain the internals of the
browser true to ask developers and that
we can extend the browser but I think
they don't provide choose to actually
compose a more complex web app so we
probably still will be using frameworks
they don't provide ways to deliver these
compliments companies efficiently
especially with HTML imports I don't
know and I think they can also make the
platform or fragile because there's no
path for progressive enhancement so how
will front and develop and look like in
the next year's and this is of course a
biased view my biased view and you may
have a different opinion on that so you
can come to me and talk after the talk
and we can discuss about that I think we
will use tools like Babel post CSS and
and that expose hackable abstract syntax
trees and that provides plugins and
presets for instance Babel and Eastland
have have and posters as they have a
common way to extend the features so
Babel for instance if you don't apply
any plugins it will do nothing on the
source code you have to apply plugins I
think we will be using languages with
explicit exports and imports that avoid
name space in collisions we had them too
long and I think we want to get rid of
them and year's 2015 models are a great
way to do that and languages that allow
static analysis that our truths can
understand our source code and optimize
it for us I think we will be using
languages like chase X that embed other
languages into is 2050 modules because
then we get things like tree shaking for
free and we really use bundlers that
compose is 2015 modules and tree shake
and use parts and now we have these
syntax and these languages that can be
analyzed statically we can create rules
that analyze the critical rendering path
and optimized for it so we don't have to
do that by hand and optimized for the
first meaningful paint and I think that
a universal javascript is a good idea
where we can always fall back so even if
the client does not have enabled
JavaScript or if something goes wrong
the site will still be usable so I
really think that server side rendering
as a fallback strategy is a good idea so
let's go and build these new things
thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>