<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Matthew Fowle: Laying New Web Infrastructure | Coder Coacher - Coaching Coders</title><meta content="Matthew Fowle: Laying New Web Infrastructure - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Matthew Fowle: Laying New Web Infrastructure</b></h2><h5 class="post__date">2013-01-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fjBj_zquKIM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">ah
so the issue i was having with chrome
and this chrome extension that i was
writing and it's monitoring all my pages
is that I really wanted to calm it while
doing this and you very quickly hit a
connection limit when you have 100 some
tabs open each tab is individually
trying to make a connection to the
server and there's really no wait to
share that when my plugging into yours
that I just have to pay attention to
what I'm doing um so yeah I hit this
connection limit pretty quickly and I
really really thought that I've always
seen the connection limit is one of the
forefront problems in HTTP and the the
idea of being able to pull for data and
listen for data this comment idea
doesn't really scale and this is
something that I desperately wanted to
address and there is a working group out
there that addressed wanted to address
this issue the hanging request issue hi
by working group realized the comment in
the way that we were trying to deal with
the large amount of connections was
simply not working not scaling and was
kind of a hack there's HTTP is a
pipelined request response model and
there's just no way to deal with
responses that don't get back to us I'm
going to do a quick little tour through
some of what these people thought was
important and of course the screen is
absolutely tiny ha
so let's just look through the high by
mailing list and see some of the issues
that people thought was important and
this will just kind of be a really quick
retrospective on where what sort of
issues people were talking about at the
time when high by was made so minimal
eventing was one of the first ideas that
came up I was just a random thread
saying how do we get just talking to
bait ah one of the anyway there's a
bunch of people chipping in saying how
do we get information on the page what
do we do with all these widgets it's a
similar idea how do we deal with this
particularly in the context of our two
connection limit however many
connections we have how do we get data
onto the page in some sort of push a
sort of fashion we have one particular
opinion Greg Wilkins talking about how
multiplex multiplexing is the way that
this is going to be done and in general
this is a this is one particular way for
how connection sharing might be dressed
how we might be able to get around this
this is just from some random java.net
article but it really has i think many
of the core ideas and many of the ideas
that are talked about here i think are
items that well they are the particular
means that i use to implement my own way
to address this connection limit and the
idea really is to have some sort of pool
being run by this is particularly
talking about server sent events which
is another way of sending data to the
browser and the server sent events plan
you have a TCP connection that is
talking to each individual page so this
doesn't address the two connection limit
but this particular article is saying
well we can just have a pool some sort
of managed pool that's shared and then
from that shared pool we can designate
and send requests where they need to go
this is probably the best post I have
seen on the list James look here Jamie
look here I love this he's just talking
about what's required from multiplexing
how people would have to what's going to
be required to share a pipe to get a
pipe
a pipe that everyone can use together
and he's not specifically he doesn't
address the earlier points about the
connection the shared pool that's spoken
of here but in terms of how a shared
pool would be implemented and what needs
to go into a shared pool and how it
would work how we're going to route that
data this is just dead on and so it
seemed like a good challenge to be able
to try and get something working with
this to try and get some sort of
asynchronous HTTP Live running so I
wrote a very simple little system the
back end is nodejs implementation and
it's a message router it allows it's
simply a back-end for the backend server
it's a front-end proxy and it
multiplexes connections over HTTP and so
let's look at a test page this is the
test case the only really interesting
thing that's included here is piped xhr
j/s and that's my implementation of my
pipe system to be able to multiplex and
get a synchronous HTTP as you can see
the test case is pretty simple let's
open an exit xmlhttprequest let's get
some data and then do something to then
when we're done we're just going to
change with the page says a really
simple idea is your pipe got xhr
overload it does that is exactly what it
does it overloads xml httprequest and so
you get it very simple easy to use code
and yet behind the scenes nodejs is
routing all of these requests through
itself there's random useless logs it
doesn't really sit anything interesting
but that's not-- j/s in action so yeah
like hit it we have this data you can
see that what we're asking for is
resource study text you can see a
resource text is fulfilled through it
goes through there's a bunch of
different the seasons
goes through a bunch of different
filters and it gets to the x-pipe filter
and the x-pipe filter is what implements
the x-pipe routing then we'll look at
this take another view of this data and
look at what's happening so here's the
request being sent out when the request
is sent out it creates its own pipe it
just generates its own random ID for
this pipe and then the pipe and then the
response back to it when it gets the
data back we can see that the pipe this
message is tagged with a pipe again and
there's now a sequence with it the
sequence will just increment each time
this particular pipe is used so it's
just oops
it's a delay filter in here so I can
just this will make a request hang for a
little bit it'll just wait for a while
and then I'll be like oh here's your
data back we're still running good I did
not clear what I wanted in
well rather than try and demos the point
of what it's doing is it's creating
these individual pipes and this these
identifiers these tags on the messages
these headers give it a multi a way to
address each message and so rather than
have a request-response framework now
what we have is we have HTTP sending
requests out HTTP asking saying here's
this request and then when the response
comes back the response can be to any
message it's not necessarily going to be
in response to the message that was
originally the a message that is a reply
is not necessarily going to be to the
given message from which it was
requested so you're basically instead of
opening up a dedicated common connection
for every one of those xhr objects
you're opening up one comment and you're
basically piping all these other ones
through the single connection I eat yep
that is that is exactly what's going on
it's all be multiplexed and the way that
that is done mouse where are you hi all
right so this is weird i don't have the
splash screen need to do more than one
but not one to one so right now you just
you went from there's no way to have
multiple down to one could you do by yes
yes the idea is to take as much
advantage of the existing pipelining
system as possible so you can issue a
large pipeline of requests and then be
able to get them back as in whatever out
of order system you want and so kind of
the model for this is uh we'll have like
a couple different web pages open here
and then the magic that runs all of this
there's a very simple implementation of
a shared router excuse me a shared
worker shared workers are in html5
creation and the shared worker the
center item here is talking to each
individual page and what happens is when
you look at the xmlhttprequest when this
happens the proxy is talking to the
shared worker it's sending the
xmlhttprequest to the shared worker and
then the shared worker on behalf of the
page issues the request over to the
server and so this is going to be our
node.js server
dude I can't draw that's no secret each
character / awesome and yes um so it
talks to node and then node goes a node
goes off and does whatever a sink in
asynchronous processing it needs to with
this request that does something fancy
asynchronous and then at some point
later back in time it comes back that
the the data comes back and it will come
back node will send it out over whatever
particular TCP connections or whatever
HTTP connections are open and again it's
decoupled so it's not necessarily going
to be the same same item back and then
it will get routed back to from it's
over to its original destination and
this allows this common having this
common shared workers really kind of the
key it is very much I mean this idea is
really dead on we they were talking
about having a to handle the per server
connection limitation a shared worker
which shares a single event source
object can be used and so it's not a
single event source object it's the
shared worker is making a crap ton of
XML HTTP requests but it's getting when
I'd ever whenever it gets a response its
using that tagging do I still have
anything in do i do still have some data
yeah
it's using each messages individual tag
to route it back to the worker really so
the shared worker that's yes it's an
html5 thing yeah client-side okay so
that's how I can talk to everybody yes
yeah the shared worker is really the key
thing here that makes all of this
possible is the fact that we can have
this delegated responsibility for
actually making these connections in a
common place for all pages so really a
the idea for that was talking about
earlier this Chrome extension that I'd
written where I have every single tab
every single tab I have open and chrome
is issuing a comment request to my own
server well that was having that shared
worker allows me to share that one pool
of resources shared the shared worker as
a shared resource pool that's really
that's all I've done it's really simple
it's been really fun the shed work is
today cash the caching I have not yet
implemented I do want to implement
caching but I have to re-implement
caching at the in an application level
so there is work required there I'm just
wondering if it was normally if you pull
down some cogency cash it mm-hmm
there's no module for that that's I'm
repurposing the there's an app for that
hahaha very good um that's it if anybody
has any question any more questions I'd
unicode yeah uh code is up and it is a
see get booty where's calm / huh see its
particular about this actually Shh oops
and / the project is pi player I'm
laying new pipes for the web
infrastructure I don't know if it's
better yet but uh it allows me to run
300 gamma connections so so start there
Oh back to what I was trying to ask
earlier I'm sorry you've got one shared
worker yes is there any benefit or is
there even any capability to have five
shared workers the whole it up a
thousand connections I don't think
there's really a benefit you could if
you wanted to you could isolate the
pipes like if for whatever reason you
wanted like I don't know high security
your low scary a or B you could run
multiple shared workers and talk you
need to does it create one shared worker
for each target location like my
question is if I wanted to talk to five
different servers five different shared
workers no you each shared worker is
capable of doing all of the routing for
all of XML HTTP in flight and so it will
the shared work role gracefully degrade
if you're not running the pipe layering
system so you can access / calm / org
and it will still go through the shared
worker out to / get back and then get
routed back to the page there's no need
to run multiple shared workers it's it
is the new xmlhttprequest it fully tries
to emulate it in every way possible and
there's just one shared worker is the
model it was designed in that will run
power and route messages into and out of
it for where it needs to go so it's a
progressive
it is a progressive enhancement ability
back yep presumably common style stuff
in the back I'm working that's one of
the things I really would have loved to
demo one of the other big influences for
all of this has been reversed HTTP and
all the various push systems I'm really
a fan of l shift Tony Tony G Tony's
named Tony G he had this L ships had a
pretty good project called reverse HTTP
where they did a pretty good job of
taking like second life mark was it the
second life guys have been doing in
verse HTTP for a while and he took that
up and he wrote so it's there's like a
registration system on one side of it
where you're it's pretty crazy but he
wrote a really nice reverse HTTP system
has a bunch of interesting features and
that was a big inspiration and so the
piping also there was a sequence because
you can see this story is that it works
it works today everywhere it works
better with new technology hring pi
using a limited amount of pipes if you
have a limited pipe space it will give
you much more bumps if your server it
will give you a much wider pipe
utilization if the server has those
pipes available there still I mean if
the if the shared worker doesn't have an
x-pipe and doesn't have a sex sequence
it doesn't know where to route it and it
can only use native dumb xmlhttprequest
it can't use any of their progressive
enhancements so you're still going to be
stuck with whatever ajax limitations you
have common limitations you already have
speaking of progressive enhancement like
by going through that shared router
would you be able to also like negotiate
with the client if it does WebSockets
that kind of thing or negotiate with the
server that you can drop down to the
lower level but HTTP um I don't have any
lower levels this was all really built
to extend an embrace HTTP i really think
ish HTTP is the bee's knees so I that's
all I really that was my only real goal
this is something I was curious about I
mean there's obviously good there's even
though I also haven't had a little love
affair with their shitty foods there is
a lot of requests or header overhead
that you get we can get rid of it there
is definitely headers that you can get
rid of with WebSockets I I tend to abuse
headers is shown up here so I it I
haven't done anything with that I want
to actually back up a little bit to the
reverse pipe speaking to that one of the
features that is implemented in the
process of being implemented and what I
would have liked it not quite ready for
demo time yet but uh there is a based
off of the reverse HTTP work there is
sort of like an opera unite esque
reverse router so that like their this
page right here whatever that yeah this
page right here actually has an address
on the internet well it has an address
on the internet basically I guess yeah
so that I could issue a web hook I could
go to pub sub hubbub hook hook up this
page and say you know pub/sub
pubsubhubbub you need to notify my IP
address you need to notify my web server
whenever you get this data then the web
server will route that over to this page
so you can have web hooks in your web
page and that's like web hooks I think
are a pretty fantastic solution to being
able to do reverse and push and it
really works well because it's a great a
sinkers it's it's a very a synchronous
technology and it avoids the like long
polling
notion altogether of comment it's like
yes you can just run comment on this and
be naive and it will multiplex your 800
connections down into you know two pipes
one pipe it doesn't matter one HTTP
connection but the real that's that's
still a hack there's no reason to keep
those connections around just when you
get data send it over the pipe send it
back this pipe and that's also really a
very trivial implementation there's X
sequence which just grows up as you use
the pipe and again this is just
identification for each message so that
the shared worker knows where to route
it there's also that the inverse of this
is X our seek an XR seek is just that
reverse pipe when messages get are being
asserted to the pipe and the pipe has no
requests there it's it's data being
uploaded this is actually a x-pipe x
seek chris zip thank you a lot of this
idea came directly from dojo and x seek
they have their own x seek they don't
have india yeah they have x ID and x
seek yeah or the exige ID which I've
just identified so you can order your
transfer yeah it's a it's a few requests
if he's not order right yeah so that's
exactly it x seek was introduced to be
able to as I'm going to repeat x equals
introduced to be able to reorder HTTP
requests when they don't come in and
order in order and this is just saying
well rather than putting them into order
will will you know rii devise the order
it's a different it's a it's a different
rendition on the same idea I can't
precisely pin it down verbally for
exactly what it is but it's a similar
sort of ordering concept and that's
that's the implementation if I can't
walk you guys through most of it again
html5 on the client side is really what
powers this and then the backend is
awesome cool node.js code Thank You Raya
that's it any questions anyone else I
think we're done thank you all so much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>