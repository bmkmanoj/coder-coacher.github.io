<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Andrew Miadowicz: What does Chakra do with your JavaScript? | Coder Coacher - Coaching Coders</title><meta content="Andrew Miadowicz: What does Chakra do with your JavaScript? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/JSConf/">JSConf</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Andrew Miadowicz: What does Chakra do with your JavaScript?</b></h2><h5 class="post__date">2012-11-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OqnMmoF2GqM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yeah and I'm here to talk about chakra
in case it's not such a household name
as v8 chakra is the JavaScript engine in
99 9 10 and in april of this year at JS
convey you multi suggested that I come
and talk about chakra I got really
excited because even though we've been
working on it for about four years we
really haven't spoken publicly very much
about the internals and then as the talk
drew near I realized that I have 30
minutes for it then I thought oh crap
I'm going to have 30 minutes to tell you
about what we've been up to in the last
four years and then it occurred to me
that one of the best things I could do
is shift over here too let's see if you
can see that will switch over to my this
way this way there we go will fire off
our command line JavaScript host and
I'll just run some JavaScript and will
spit out the machine code that we emit
and then I can kind of walk you through
the details of it and no letter probably
feel about 30 minutes of our time maybe
a little bit more so maybe it's not such
a good idea so instead of dancing you
with my compiler voodoo knowledge I will
instead try to amaze you with my fancy
animated slides let me take that one out
of the way alright great so chakra Oh
focus there we go start working now
there we go under the hood in 30 minutes
or less let's see how much I can show
you some way started the project four
years ago in sometime late in 2008 we
obviously wanted to rewrite the
JavaScript engine to be faster so we
ripped out the old JavaScript engine
from ie8 we added JIT compiler obviously
the main goal was to make things faster
but at the same time we didn't want to
sacrifice security and we didn't want to
sacrifice in a bit of interoperability
as it turns out adding a jit to any
process is a very juicy target for a
potential attacker we will take some
performance hits in order to maintain
security will dive in this a little bit
more and then second we wanted to be
sure they were absolutely compliant with
the ACMA scripts spec so you know and I
the dark days of ie8 and before you have
to deal with all kinds of quirks
such we are to be sure that that's not a
problem in ie9 and and beyond so you
want to be sure you write script once
and it runs consistently on all the
browsers yeah and even our view of
performance is somewhat more nuanced and
balanced we want to be sure that we we
are really good on page load because
that's important as well as on just the
raw execution and really what I want to
tell you about this kind of the story of
building chakra why was built they were
was built what's different about it then
in some of the other engines and then
what is new and I 10 since we're just
about ready to ship it publicly
officially so we'll dive under the hood
a little bit there so let's start with
security oh by the way I promised some
assembly in my intro there will be some
of that so that's a quick preview of
what we're about to see I'm so security
I'm when you add a jit to the process
becomes a very potentially juicy target
for for an attack we want to be sure
that our engine is not the source of
exploits in the browser if you think
about what the JIT compiler does it
basically writes a bunch of data in the
memory and then points the CPU and the
data and says run that stuff and if your
attacker that's almost exactly what you
want to do you want to be able to write
some malicious code and then you want
the the processor to run that for you so
if you can get ahold of the chunk of
memory where where the JIT compiler
emitted some code and then you can write
your own stuff in there you pretty much
own the process so we take a number of
steps to make that as difficult as
possible for starters the most important
thing the most important mitigation that
we have is we actually lock the pages
that we write our code to so we mark
them as not executable sorry nan
writable but executable which means no
one else can write to that to those
pages any more data after we've
generated code that minimizes the window
that anyone can have to try to modify
things after we've written them to that
piece of code and then we also make it
difficult to figure out exactly where
the code is emitted first we use some of
the operating system mechanisms the
address space layout randomization but
then we also randomly layout where the
function start so we add some no ops in
the beginning sometimes there are no up
sometimes there are interrupt
instructions
we actually emit some random no ops
within the body of a function just
randomly sprinkle them throughout which
again makes it that much more difficult
to figure out where where the code lives
and then it turns out that if you write
JavaScript you actually have control
over some pieces of the data that we
will write out if you imagine when you
have a constant say a value 12 somewhere
we say in VAR x equals 12 that value has
to be encoded somewhere and then it
turns out that it only takes 16 bits to
encode an instruction in assembly on at
least in those processors so technically
speaking if you can have a constant that
is 16 bits or more you can put
instructions directly in the indie code
that we admit so to to take that control
away from you will actually encode those
60 bit 16-bit or more values by
extraordinary so that's what you see in
here and then on top of that we do a
couple of other things we actually cap
the amount of code that we will generate
just to be sure you cannot fill the
entire memory with with random code and
then jump somewhere there or write to a
random location and then one actually
comes to allocating pages we also
randomized those allocations so all
these things combined make it very
difficult to own the code that we omit
in any way and the first part that I
mentioned the locking of the pages is
actually different between chakra and
any of the other engines and does have
some implications like we we ourselves
are not able to modify the code after
you wrote it out so that's one of the
cases we will take some performance hit
to get that security and that's
something that differentiate is from
from others the other thing I mentioned
was the compliance spec compliance akma
script is a well-written spec but it's
every spec it leaves some little nuances
kind of up to interpretation so we
believe that it's important to have a
suite of tests that can empirically
verify that we all agree on what the
spec says so we worked with Google and
with others to create the test 262 which
now has some 11,000 different tests that
verify compliance Lakmal script and up
until about two weeks ago we were
actually passing all of them but then
sometime two weeks ago a few more out
were added to deal with the utf-8
encoding and
turns out there is a some there's a bug
in the unknowing OS in some weird
sorting algorithm that affects us so
we're now failing one test but we're
still actually doing quite well when it
comes to the pass rate and again we're
committed to making sure that that we
stay compliant with the spec so with
more tests are added that actually
expose issues that we might have we'll
make sure we fix them and the good news
for you is generally speaking all the
other browsers are also converging on a
very high pass rate so you can really
count on on your xmas crypt compliant
spec I mean script to run in all the
browsers in the same way okay great most
of the talk will be about performance
though and I did say that we care about
page load why do we care about page load
well even though the web is evolving and
the apps are getting more fancy and more
sophisticated most of the people still
experience the web is a bunch of pages
that they navigate to and their
experience is primarily affected by how
quickly those pages load and since
JavaScript execution is oftentimes on
the critical path of that we try to make
sure that we get out of the way as
quickly as we can so that dictated that
we kept an interpreter in chakra we have
a compiler but we retain the interpreter
so we can start executing your code as
fast as possible so here's a quick
little diagram of what we do with your
code when we see source code we pass it
through the parser we produce an ASD
then we feed it to a byte code generator
which generates bytecode which then we
start interpreting as fast as we can and
please do appreciate my pulsating
interpreter right there but the main
point here is we believe generating
bytecode is faster than then compiling
to machine instructions so in order to
give you as fast startup as possible we
will get to the interpreter first and
we'll start executing there but we do
more it turns out most of the sites
bring in a bunch of JavaScript libraries
out of which only a small portion is
ever executed and even a small smaller
portion is executed at startup so it's
important that we don't spend all the
time parsing all the code and generating
the bytecode for all the stuff that is
never used so we do instead is we defer
parsing of anything that is not
immediately executed so we actually wait
until you call a function before we do
all the all the work that is required
there's a caveat there
requirement of the spec is that we parse
everything for syntax errors but that's
a relatively quick pass so you know the
FIR loading of your code is still a good
idea because we will have to parse all
of it at least for syntax errors but
generally speaking all the hard work is
deferred until it's absolutely required
and we try to do even more we try to
preserve some of the information that we
have between one page load and another
will actually keep track of the
functions in JavaScript that got
executed to make sure that we parse
those right away and we defer everything
else and then I'll tell you more about
Windows 8 applications at the end but
for those written in JavaScript we
actually even cache the bytecode so we
don't have to parse or generate bytecode
at all which helps us greatly on startup
for those so page load is important but
of course we care about executing
JavaScript as fast as possible to for
the larger apps so we start an
interpreter and as we interpret we
collect there we go profile information
basically data about what types of
parameters variables properties we saw
it's kind of similar to what v8 does and
what Firefox also does and then we feed
that information when the function is
hot enough to start compiling into our
jit compiler along with the bytecode for
the given function now what's different
in chakra is that we've bet heavily on
concurrency we believe there's a trend
in in hardware to having more and more
cores so you want to take advantage of
them as much as possible so in this case
our jit compiler runs concurrently on a
background thread and if you have
multiple cores you can get the
compilation while you're executing the
code so we can continue running your
code in the interpreter even as the JIT
compiler produces machine code for a
given function and then when that
machine code is ready we will swap it
back in and i will continue executing
just the machine code not interpreted
anymore so that minimizes any pauses
that might be introduced on the UI
thread by compilation everything is done
on the background thread and then the
other component of the system the
garbage collector is also designed to be
run concurrently as much as possible
most of the marketing and the sweeping
that we do leave a mark and sweep
collector is actually done concurrently
well there are some portions that we
have to do on the UI thread I won't get
into great detail of that but for the
most part we do the bulk of the work
concurrently so if you have three cores
and if you need to compile and garbage
collect and run your code concurrently
we can do all that stuff as long as you
have enough course and we believe we can
actually expand that relatively easily
to paralyse over more cores of those
become available so that's the key
aspect of our architecture there is
different from from other browsers and
then that the rest of the talk I'll
spend talking about the changes we've
made in ie10 particularly our jit
compiler because we've changed it quite
dramatically so you may or may not know
that in ie9 we we were able to generate
machine code only for x86 if you rent a
64-bit version of IE 9 you're actually
running in the interpreter only in i-10
we added machine code for x64 and
forearm as well so in all these cases we
have full JIT compilers now and then we
change the general philosophy of our jit
code that we omit I'll talk about that
in some detail but we we kind of adopted
a similar model do you see and other
browsers today of generating optimistic
code and then if things go wrong then
we'll just bail out and we read it if we
need to and that gives us a number of
other benefits we can generate faster
math both floating point and integer we
can do function inlining and we can we
actually have a number of other
optimizations are just strictly from the
compiler land and we also added support
for typed arrays that's not really a
compiler optimization but it gives you
if you really want access to native data
that is critical alright so the
optimistic profile based jet what is
that beast now if you're hanging out in
the in the bubble room this morning you
probably have seen much of that
explained but for those who are in there
I'll cover some of the basics so in ie9
the code that we would omit looks kind
of like this graphically we basically
try to handle all the nooks and crannies
of the of the JavaScript semantics so if
you have a plus B you know maybe two
numbers that you have to add by maybe it
is two strings I have to concatenate or
what have you we were trying to handle
all these cases which meant for
everything
other than integers we'd have to call
into the run time to do the operation
get back the result and then try to
continue which oftentimes men that we
have to call back into the runtime and
back and forth so for for integer
operations we were generally pretty
pretty good but for certain other things
we were not in 90 10 we're doing things
differently so we will collect the
profile that I mentioned before so now
we know that we primarily operates a on
floating point numbers so we'll generate
the code that is specialized for those
which typically results in a much
shorter and more compact and more
efficient code but then we have to check
that the conditions that we expect are
still true so if now he passes a bunch
of strings we have to do something else
so that's their little diamond on top we
check the conditions and if they turn
out to be false we have to bail out so
in our case bailing out means
transferring the state of execution over
to the interpreter and then continuing
that function in the interpreter when we
call the function again we will reach
re-enter the digit code if the
conditions are still not met will bail
out again if that happens sufficiently
frequently we will decide that it's time
to reach it that code with a different
set of conditions maybe it's a more
generic code again that is a little
slower but if that's the data you gave
us that's what we have to work with so
generally speaking our code adapts over
time to the data that you pass us great
and I mentioned that gives us a chance
to generate more efficient code but
first a little bit of a background why
that even matters you probably are well
familiar than JavaScript variables are
dynamically typed so at any given point
say a in this case could be a number
first then the floating point number are
straying that an object then even a data
a piece of date and we have to deal with
all the different values so typically
they were encoded on the heap with some
form of a type tag and then the value to
tell us how to deal with those those
types of values and they have to be
allocated on the heap and then the
garbage collector when they're no longer
used has to collect them all which has a
high overhead of course when it comes to
memory and then this also means that
that up the basic operations are quite
inefficient so if you just take this
simple a plus B plus C
you kind of break it down into
individual operations you have to add a
and B and then add the result to see and
then return that it turns out that it's
this lengthy sequence of things that you
have to do so you have to get a type of
a type of B then the value of a in value
of B then based on the types we have to
decide what to do maybe it's adding two
numbers maybe it's concatenated strings
then finally we have to execute that
operation get the result back stick it
back on the heap and only then we can
return it that's very inefficient in 99
we we employ the same trick that most of
the modern engines now do and that's
kind of a common thing in dynamically
typed languages we we use number tagging
if you're not familiar with it the idea
is generally pointers are aligned to a
certain boundary so the least
significant bits typically three or four
are always zero so we can stick a one in
one of those bits and then use the rest
of the bits to indicate to actually
store the value of the integer it's like
in this case the number 3 can be encoded
directly in the register or on the stack
that helps because we don't have to
allocate it on the heap and grab it from
a heap every single time so in 99 we
were using that in ie10 on the 64-bit
platform we have more bits available so
we can stick floating-point numbers and
large integers also directly into
registers on a stack so that helps with
the math operations there are so long
sequence of steps but each of those
steps is a whole lot cheaper so if it
comes when it comes to grabbing the type
we just have to check for that one bit
we don't have to go the heap to get the
value we just have to remove the bit
that's also cheaper then we know what
operation to do just add two numbers and
at the end we just have to tag the
number instead of sticking back on the
heat great so there was better than the
you know and I ate but night n we can do
much better than that because now we
don't have to worry about all the other
conditions that we might want to handle
so that's just an example of an
operation a set of operations that we
will do from the SunSpider benchmark
this little loop right there basically
translates into that assembly do you see
on the right and if you well versed in
assembly you can get an idea that's
probably there's just about as tight as
it can be that's the something that a
c++ compiler wouldn't
be particularly ashamed of generating
for the same kind of code so it's quite
efficient with a one little exception
over there we have to check for the
overflow which is just required by the
semantics of the JavaScript operations
and if overflow happens you will notice
will actually bail out of this code and
and will try to reach it so that make
that makes integer math much faster for
floating-point math this is even more
important because previously you always
have to box the floating-point numbers
back and forth another example from
sunspider and again if you look at the
instructions on the right it's basically
just floating point operations on
registers so it's quite efficient a
couple exceptions there we actually take
a register spill this move SD that is
marked in red our linear scan register
allocator has some limitations in this
case it shows to spill this register and
then there's also the overflow check but
again generally speaking for local
variables for parameters they can
generate very tight and very efficient
floating-point and energy map there are
some limitations to it when you start
sticking those values into properties or
or extracting in front properties we
still have to box them or or tag them
and it turns out that you do actually do
a lot of operations on properties so
property access is also important and we
did a lot to make it faster in 99 we did
even more in ie10 I'll cover some of
that in the next few slides so generally
speaking it as a background which may be
obvious javascript objects just bags of
properties so traditionally you never
knew if you wanted to grab property X
you know when you were to find the value
of that property you always have to do a
dictionary you look up get the value and
then the same thing next time around
inline caches are typically used to help
that what they really are or just a way
to store to remember some information so
if you remember the object that you saw
before and know where to find property X
next time you could do it faster alright
so in ie9 we we added inline caches and
for the inline caches we have to keep
track of shapes of the objects or
internal classes as they're called in
the eighth and we kind of typically call
them internal types so here's an example
of a constructor that creates two
different objects and just gives an x
and y
properties and shapes are basically
sequences of properties that are added
to an object so we follow the evolution
of an object and then we associate a
certain shape with that object so here
the shape would be X Y and the bubble
indicates that it's the right from a
certain prototype if then you create the
second object b2 which follows the exact
same code path it'll have the same type
or shape and then subsequent accesses
the properties of those objects will be
monomorphic meaning the objects will
have the same shape and we can do quite
well in ie9 for for those types of
objects here's just a quick example if
you now call this reset method in a loop
which then tries to set x and y 20 we
have an inline cassius o ciated right
here with that instruction and the
inline cash remembers the type and
remembers the slot at which we found
property X last time it starts zeroed
out there is nothing there and this is
roughly the code that we would omit for
to access that property you don't have
to understand all of it the key thing
here is we check the type or the shape
of the object against the shape shape
that we remember in the inline cash
right now they don't match because the
cash is not initialized so we have to do
a slow look up but after we're done we
store that information in the inline
cash and so next time around when you go
through that loop and get to this type
check it succeeds and so if it succeeds
we have a fast way of getting them or
setting the value of that property we
just made those those three instructions
so that works really well if the shapes
match but in JavaScript you can throw
additional properties into objects
afterwards and in this case if b2 got a
property see now it has a different
shape so we have two different objects
with different shapes and so access has
become polymorphic and a 99 there are
some limitations to how fast you can be
with the polymorphic properties because
we only remember one type at a time so
here is the same example with with those
two modified objects and we started off
the same way we populate the cash but
then on a second iteration of the loop
when it comes to this check we remember
XY what we have now is XYZ so we the
types don't match and we have to go down
that so basically in the worst possible
case if you were just flip-flopping
between two different types we would
always go down the slow path and our
inline caches weren't particularly
helpful it turned out that uh for the
most part the accesses aren't exactly
alternating like that so most of the
time you're still hitting the cash but
there's a some performance overhead of
polymorphic properties so night n we
actually added two polymorphic caches
that can keep track of virtually
unlimited number of types so our
polymorphic property access is much
better and then we took advantage of the
optimistic code generation to get better
property access using object type
specialization I will explain that and
then we generally streamlight our object
layout to make them thinner and
requiring fewer allocations and then
some of the compiler optimizations added
also apply to those and so here's an
example on the left hand side it would
be the code that we would generate a 99
to add the values of those three
properties and on the right hand side is
what we do at i-10 so 99 you see that we
execute the same sequence of operations
for every one of those those property
loads we checked the type of 0 every
single time even though it's the same
object oh so it seems redundant it turns
out it wasn't trivial to eliminate but
9010 we did get smarter we just omit
this check once and then subsequent
property loads we just know exactly
where to find x y&amp;amp;z once we know the
shape of of 0 and you notice those
bailout instructions there on the light
on the right those basically mean that
if we're the objects shape does not
match we have to jump out to the
interpreter and we have to deal with it
there and we will recompile the the
function later so this is great that
actually is more efficient where you get
the biggest bang for the buck is when
that type of instruction is executed in
the loop with the loop invariant code
motion we can detect that the object o
is now changing and we can hoist all
these expensive checks outside of the
loop we run them once and then in the
loop the execute multiple times we avoid
the overhead in this trivial example it
turns out that x y&amp;amp;z also don't change
so we hoist the loads of those and since
they don't change the plus operations
are also redundant and they can be moved
out of the loop so
this trivial example the loop itself
becomes quite trivial but then if you
were to insert a function call into that
loop we would have a problem because it
turns out in JavaScript function calls
can change half of the world so the
function calculate for all we know could
be changing the shape of o may be
removed property X or something and so
now we have to execute all these checks
and all these loads on every iteration
of the loop so function calls tend to
kill most of the optimizations than any
of the engines can do and that's why
function inlining is such a critical
piece of of every video of every
JavaScript engine today so if you can
inline calculate we can see inside that
we can prove that Oh still doesn't
change and XYZ still doesn't change so
all these things can be still hoisted
outside of the loop so not only do we
eliminate the overhead of the function
call but we get to retain some of the
other optimizations that we did before
so in lining in ie10 is also a great
benefit and so yeah so better math
better property access a function
aligning those are the critical pieces
that we added in i-10 and it kind of
covers the basics of the JIT compiler
and I am I about five minutes left I
only want to mention a couple of
additional things I alluded to this
already you may or may not know that in
Windows 8 we actually took a big bet on
JavaScript and HTML so we can build
native applications in Windows 8 using
web technologies they're not running any
kind of a web control or anything like
that they're actually native apps that
have access to all the native API and in
fact several of the apps that we ship in
box with windows 8 are written in
JavaScript and HTML so if you ever
wanted to stretch your muscle flexing
JavaScript muscles on a different
platform use definitely encouraged to
try to grab the windows 8 and then try
to play with it we think it's an
interesting opportunity and it's
definitely we believe that it's where
the future is and we want to support the
platform the web platform as a way of
developing apps for Windows 8 and then
my last cheesy slide for the day are we
done of course we're not there's a bunch
of other things that we'd like to do
there are some things that are not as
efficient as they as they should
but there is also a bunch of trends that
we kind of follow that you want to make
sure chakra is a great engine for so of
course as es5 gets more adoption there
are certain things we like to optimize
as Ahmed script 6 is evolving we also
want to be sure that we first comply
with the spec second that the
implementation is fast html5 games
certainly an important target for us
Windows 8 apps of course you want to
make sure that they run very fast and
then other things your web workers are
an interesting trend for instance maybe
more concurrent compilation they more
concurrent garbage collection as in
order to handle concurrency in advanced
apps and so on and so forth the bottom
line is we want to be sure that chakra
is a great platform for building the
kind of apps that you want to build
today and tomorrow and with that I think
we have about three minutes left so I'm
happy to take questions you can also
grab me with by email or Twitter thanks
but I was I had a quick question you
said that you just in time compile in 64
bit but I was under the impression that
data execution protection was mandatory
for 64-bit applications so which would
make the memory not not executable how
do you get around that no there's there
is an API that a process can call to
make a piece of executable or data
executable and we call that API but what
we what we make sure is that the window
of of time that you have to potentially
override the code that we omit it before
it's locked up is minimal it's just
really the time between we copy the
buffer into the right page and we lock
it
so so my main question is can you
actually see the generated code on a
normal chakra not on some custom build
no you can't set an internal tool that
that basically host chakra in a
statically well if you were able to
build a checked build of chakra than yes
all the switches for dumping the output
are there but that's not what we should
I have a question about the the inline
caches yeah so since you can't actually
right into the memory once it's been the
code has already been generated where do
you actually keep yes that's an
excellent question i forgot to mention
that specifically so inline caches are
implemented differently on different
engines in some cases an inline cash is
actually a snippet of code with directly
hard-coded values in our case that
cannot be because we need to be able to
update the cache so for us a cache is
just a piece of data that that our code
references so we have our we hard code
the location of the inline cash in the
assembly that we omit but then the cash
itself is just data and is not protected
so we can override it that make sense
all right um so you mentioned bytecode
caching for Windows 8 apps so you
compile the bytecode and you put that in
the store and we down with that does
that work for or am I am I correct and
how that works and why don't you do that
for caching JavaScript and i-10 right so
it's actually slightly different than
that we regenerate bytecode on the
target machine when you install the app
we schedule the byte code generation
sort of in the background and whenever
that is available we will start using
the bytecode until then we can we can
still run from source code there's no
limitation there so the bike go is not
in the store strictly speaking it sits
on the machine we did contemplate
putting it in the browser and it's so
very much a question that we're
considering it's a little harder in a
sense that you don't have a moment when
the app is installed in the box and
certainly JavaScript can be you know the
JavaScript that you load can be changing
more frequently than then the app that
is installed in the box but there's
nothing technically you're making it
impossible and we certainly are
contemplating that as well if
will windows phone 8 be running chakra
true well windows phone 8 windows why I
guess we'll get I 10 yes okay that
didn't answer the question uh what what
do you mean by chakra to you mean they
would run the same JavaScript and yeah
okay sorry any the question all right
let's see that's it thank you very much
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>