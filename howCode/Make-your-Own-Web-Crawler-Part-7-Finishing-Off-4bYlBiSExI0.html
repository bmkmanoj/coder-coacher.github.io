<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Make your Own Web Crawler - Part 7 - Finishing Off! | Coder Coacher - Coaching Coders</title><meta content="Make your Own Web Crawler - Part 7 - Finishing Off! - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/howCode/">howCode</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Make your Own Web Crawler - Part 7 - Finishing Off!</b></h2><h5 class="post__date">2016-07-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4bYlBiSExI0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so in this part what we're gonna be
doing is returning our title our
keywords in our description if we were
able to get them from our function so
the way we do that is you just say
return and we're gonna return some JSON
so we're gonna return a JSON string so
we're going to use the to JSON opening
brackets the first thing we're gonna
return is called title and it's going to
be equal to our title box Lee so we said
title and we actually want to surround
that and quote because if we weren't to
do that I guess I wouldn't be valid so
we're gonna put a comma there our next
one as descriptions we'll just add a
description in quotes again the colon
goes outside the quotes and then so well
the way it works is you have double
quotes code on double quotes again and
the other double quotes we will put in
our description if we have one and then
in the final one we will put in our
keywords if we have any and for
description we actually want to make
sure there's no new lines in it because
they can mass about with the JSON so
what we'll say is STR replace I will
just remove the new lines by replacing
them with nothing in the description
string so that should be it so let's
just run this again and as you can see
for Google and YouTube we got titles for
the pages that didn't exist we didn't
get anything because the changes didn't
exist so what we're gonna do is we're
just going to append a new line on there
to make it easier to read and we're
going again and you can see we have
kugel and we have a blank one then we
have YouTube then we were black one and
that matches up with our links you can
see we have Google a length that doesn't
exist
YouTube another length another like
another link and none of the other links
actually exist but what we're not doing
is we're not following the links that
are collected by these pages so what we
need to do to get the quality
indefinitely it's just create a simple
for each loop so tinier for each already
crawled as site which essentially just
means refer to every item and already
crawled a site I will just say follow
links site I will just pass its site
which is just one of the links in our a
so as you can see here each one of these
links will be referred to a site and our
crawler will go through all these links
and it will append them to our crawl
array so if I just run this now what
you'll see is we got the original pages
this is the first page of spent crawled
now we're on Google Images this was a
link that wasn't actually in our
original set of links you can see we
have Google Maps Google Play Google News
we have Google books people shopping and
you can see it's it's just doing it on
its own no it's finding links on pages
that we didn't tell it about that's
exactly we want from our crawler you can
see it's on Google business now it's on
Google's privacy policy and eventually
it'll actually leave Google altogether
and it'll start going to other web sites
so what we're getting here is a slight
bug and that's what we're gonna fix in a
minute you can see it's just going to
Google sign in Google Google sign it
over and over and over again it's just
gonna look like this forever
that's because the way our crawler works
is it creates a list of links just I'll
start following those legs but if the
first leg on the page is the link it's
already on it's just gonna keep going
back that same link over and over and
over and over again so the way we fix
that is we create another array just
call it like crawling or something it
doesn't really matter and then in here
every time we add a link to already
crawled we add another link to crawling
and what we do here is we just change
this from already crawled to the
crawling around because that's what
we're living through and then we above
that will use the array shift function
to remove the first link so this means
it's not gonna keep on back and back and
back to the first link over and over and
over again so we just say array
shift to remove the first item off the
array I would remove it from crawling so
let's just run this again and see what
happens so again we have the first page
you can see these are the links on it
whoops expects parameter one to be array
we need to make a global array as you
can see we just didn't add it into the
function so that should be that problem
fixed run it again so once again we're
on the first page now and now we're on
Google Currents we're on different pages
and none of these pages were in our
original set of links so I'm going to
let it go for a minute I'm just gonna
see how many links we can actually
collect in this time
okay so that's probably enough so you
can see these here blank ones are links
where it would have got a 404 error in
my original sort of prototype before
this series I had functions for checking
the headers of requests to see if it was
a 404 request which would mean that the
page wasn't fine and then therefore he
wouldn't crawl it but it slowed the
crawler down significantly
and all having an aunty item means is we
got an empty item in our JSON we could
easily correct that and with whatever
you know program we're gonna use to
upload the JSON into our SQL database
now we could easily fix that with
whatever program we use to upload all of
our data into a database so before we
finish there's a couple of things I want
to do the first one is obviously I want
to add the URL onto the end of the JSON
so we're just gonna create another item
call it URL and this one is gonna be
equal to whoops
link so it's going to be URL I don't
know if we just run it really quick
we're gonna see the URL of the page
and you can see these are the holding
URLs here and the last thing you want to
do is you want to I put our JSON to a
file so within the finder on the
computer this is the page we're working
with this was our test page for the
links to check a little weird types of
links we can get and this here is pages
JSON it's a blank page that we're going
to put our output of our crawler into
and what we're gonna do is we're going
to pipe the output of this command into
that file and then we can actually open
it up because I have a Chrome extension
which means I can view the JSON and it
look it'll be really easy to read so
let's just run that nice week the way we
do that it's really simple we just say a
PHP and exit our PHP to run the file and
any and if I just run it I you can see
here's all of our I put so any output
that we get is going to go straight into
that file so let's clear this again I
run this before I run it I just want to
put I created on sign and I want to say
pages dot JSON so that just means take
you out post it you would have said to
the terminal which it means we're not
gonna see anything and send it to this
file so let's just do that let's hit
enter you'll see we get nothing in the
terminal because it's all being sent to
the file something
terminal anymore if I click pages dot
JSON you can see it's actually filling
up already you can see I can scroll down
and the lines are just getting longer
and longer if I look at the pages yes on
five you can see it's eight kilobytes
now open it up again it's still a if I
leave it a bit longer it will get longer
and longer and longer you see now it's
nine kilobytes and it'll just keep going
and going and going so we've probably
got enough JSON now so I'm just going to
press ctrl C on the keyboard and that
ends the script that ends the program
good appear just a JSON it's 117 lines
long and it is sort of hard to read like
this so what we're gonna do is we're
gonna go to Chrome and we're going to
open pages dot JSON in Chrome so as you
can see this isn't really what we want
to be looking at it doesn't look
formatted or anything at all so the way
we fix that is first thing I need to do
is just run it through our web server so
I'll say localhost so this is running
through the local web stuff in the
computer now it's not being displayed
it's just a file so I have an extension
in Chrome which will format the JSON for
us but it's a minute it's not 100%
perfect JSON so it's not actually able
to parse it so the way we fix that is I
just need to come into our file and must
manually change it I just need to say
and creating a rag call it whatever I
want I don't you need to give it a name
I create a JSON array using the square
bracket and I closed YES on array with a
square bracket but as you can see if I
go back here we don't have commas
separating all the items so we need to
put those in as well or else we're not
gonna have valid JSON so after each item
we just put comma here we'll just delete
the contents of pages of JSON I'm gonna
run it again so we've just run that
again and as you can see now we have the
commas we need at the end and now we
have more correct JSON it's not perfect
yet we just need to put in these into an
array the last one we did it delete the
last comma and then close off the array
and if we load this die again we have
almost perfect JSON you see this title
has a new line in it earlier on I said
new lines can mess up the JSON so we do
need to go in here copy this and just
put it in title as well have key words
and we once again run this and if we
take a look now we just refresh and see
nothing's changed it still doesn't look
good
it's not formatted but now we have the
commas and we don't have any new lines
so this should work 100 percent we just
delete the last comma put a square
bracket in we've got a JSON in an array
and we have all of our items separated
with these curly brackets now hopefully
you will have formatting so here we go
here is the formatting of all of our
items you can minimize it or whatever
you want this is the raw output that we
get but this is the parsed version which
is well way easier to read and you can
see it tells us the title of the
websites if it's an actual website you
can see here there's no title keywords
or description business web page doesn't
exist and we might want to at some point
sort of include something like that into
our crawler so we don't have all of
these and web pages that don't exist but
as you can see here there's the title
there's a description
there's no keywords in this page but
there's the link to the actual page we
just crawled there's a title again we
could change things about the title we
could trim it which would remove all of
these starting and closing spaces we've
a probably couple of problems here with
the character encoding and again we can
look at that in a future video maybe but
by and large this is a web crawler it
works it'll crawl any website you want
you can confine it to one website you
can make a crawl entire Internet if you
want it does anything you want so that's
it for this video don't forget to Like
comment favorite and subscribe and I'll
see you next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>