<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Philly Code Camp PWA Service Worker Code | Coder Coacher - Coaching Coders</title><meta content="Philly Code Camp PWA Service Worker Code - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Love2Dev/">Love2Dev</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Philly Code Camp PWA Service Worker Code</b></h2><h5 class="post__date">2018-03-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JGVTlKzXyCw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody this is Chris love the
owner of love to death and I just wanted
to you go over the service worker in the
Philly dotnet code camp progressive web
app yes we're getting close to the code
camp and I need to get some more content
out there explaining this now we'll be
going over this in one of the sessions
on Saturday but I wanted to give a
preview
maybe entice you to come to my session
if you're gonna be there anyway so here
we are I'm looking at the code for the
service workers I thought I would walk
through the actual code before we kind
of step through part of it and explain
some things well first off I'm using you
strict so we can get the enforcement of
better syntax and I've got a recent blog
post I made about what you strict is if
you're interested I'll put a link to
that in the description below now the
first thing that we do is call the
import scripts method and if you're not
familiar with this maybe you haven't
done a web worker or haven't done a
service worker before this is how you
reference external scripts to use inside
your service worker and I have found
this to be extremely useful and also
kind of a pain in the rear at the same
time and the problem is that the files
don't necessarily get updated as
frequently as you would like and that's
because the browser cache headers are
honored things like that so there's been
a lot of debate about the cache busting
on this but I just wanted to bring that
up as a concern because just because you
change your serviceworker to force it to
reload does not mean these files will
get updated so you just need to be
conscious of that and if you're trying
to debug problems where you do update
these files that you do have to
unregister the serviceworker in then
re-registered is the best way I've found
unless you're going to do some sort of
cache busting which I'll go over some
other time but basically like the Hat
make the filename of hash or
query string parameters things like that
all those kind of cash busting kind of
techniques anyway so what I am using
here is a local forage which is a little
library that I found it's not little oh
it's small it's just it's
well-documented but you can't use local
storage and a service worker because
it's not asynchronous so that's one of
the reasons why I have migrated all my
client-side data storage to indexdb
however the index DP index DB API is
rather complex and honestly personally I
don't really know how to work within
sticks I've always used something like a
local forage and the reason I use local
forage is because it gives it an API
that looks like local storage but it
makes it promise based and that makes a
huge difference so that's what I do I
use local forage a lot of times to
persist off in index DB and it makes it
nice and simple next is mustache again
I've got a article I recently posted on
how to use mustache but it's been a
staple of my client-side rendering for a
long time but I've in recent years have
been migrating a lot of stuff to node
server-side rendering as soon as the
data is updated and I use my stash there
as well but as we'll see in the
serviceworker wiki we can also use a to
render things inside the serviceworker
you can remember a serviceworker is a
proxy between the browser and the server
but you could actually use it to be to
serve a lot of purposes that a web
server would do to actually render stuff
on demand and that's essentially what
we're gonna do if we're offline and I'll
show you what happens there as we go
down through the code here and in the
last external library and when he uses
the sessions library this is the same
library that I use in the client-side
code to manage storing things in the
Internet of local forage in a indexeddb
through local forage so it's the same
exact library and I'm able to use it in
both places because the library is
designed
so that it doesn't have any UI
integrations or dependencies it's really
I think a repository or service I forget
which way that would really be called in
a computer science philosophy kind of
thing but basically it's the way to
manage the session data and local forage
is the data abstraction layer or thinks
right anyway it's the interface to the
data layer so anyway all right Oh
where'd we go so next I declare some
constant variables
I always declare a version number and
you'll see why here in a minute
makes managing cache is easier so I
always give the name of my caches here I
like to append a version number here
that way if we new went to upgrade this
service worker version as you'll see in
a minute I can clean it up very easily
and delete legacy caches next is a list
of URL assets or files if you will that
I want to have pre cache which means
they as soon as the service worker loads
or gets installed these will be added to
this pre cache cache and they'll be
available all the time
now the only thing I'm not doing here is
pre-caching all the sessions now I did
that intentionally so I could show you
how to do this technique for a site this
small meaning that there's you know
there's 65 pages and these pages are
relatively small there's only one image
I think for the entire site - which is
the logo this is a very simple site and
honestly like I said I'm going to
replace the font awesome reference with
a magnifying glass image so we can get
that out so these files would go away
I'll minimize the find just the CSS I'm
using so that will go away so in the end
this is going to be super small and that
so I could technically pre-render all of
the individual session
files or URLs and make those available
and I can also pre-render just the
content interests and use the technique
that I'm going to show you here a little
bit later that's because this this is
really a small site I mean 65 pages may
sound like a lot it's relative but the
actual amount of data is really small
and there's some cool things that I
could probably do to make that I just
cache the entire thing locally but I'm
gonna be rendering things a little
dynamically if we're offline which is
kind of cool so you all ready now let's
go through some of the handlers this
gets into the life cycle stuff life
cycle I've got like a couple hours of
life cycle content in the course so this
is obviously going to be a real quick
one but there's a couple of steps that a
service worker goes through when you
register the first is the install event
triggers and that's when it is first
registered and normally what you do is
you set up your pre cache I select the
primary thing you do and set the install
event handler this is where you cache
those assets upfront that you know we're
going to be needed all the time and the
other thing I'm doing is I'm skip I'm
calling the Skip waiting this makes the
service worker immediately available and
again this gets into the lifecycle
concepts I'll talk about this some in
the session on Saturday but like I said
I've got about two hours worth of
content in the course alone just on the
serviceworker life cycle so I am calling
caches I'm creating I'm opening in cache
the pre cache here and what I'm doing is
I'm adding all of those URLs that were
in that array up there this will just
take care of touching those and stuffing
the responses into cache for so that
they're gonna be available now the next
event that triggers is activate this is
actually when the serviceworker
becomes the active serviceworker that's
because the serviceworker when you
register it doesn't immediately take
over for a lot of different reasons
now the Skip waiting will make it
immediately active but there is a kind
of a process to get there and that
process honestly it's not gonna be that
long if you do the Skip waiting but
anyway so this is a separate event and
typically the thing you
you do here's you kind of go through and
clean up caches if and this is a
standard routine to kind of loop through
all the caches and here I'm checking to
see if the version number matches with
the current one if it doesn't then we
delete the cache and get rid of it that
way we don't like take up a lot of
excess space we don't need it that kind
of stuff now there are some other ways
that need to get that you would want to
do to kind of manage your cache and
validation I kept it simple in this
particular application now in the
workshop I'll go over a lot more about
the cow and validation we'll try to go
over some of that in the session on
Saturday but I don't have enough time to
really cover that in earnest that I was
going to talk about it I did write an
article on perf planet
this past December and I'll try to put a
link to that in the description as well
it's not in here so it's not that big a
deal but anyway this activate event will
only get called once in the life cycle
of the serviceworker and the same goes
for the install event those are only
gonna get called once once the
serviceworker is registered and become
active these events will not trigger
again until you replace the
serviceworker
and then it'll go through that service
workers install and activate event all
right so here's the workhorse of any
surface worker is the fetch event
handler now you could also have push
event handlers and background sync
that's very outside the scope of this
session or this uh this application but
basically any time a request is made to
the network this fetch event handler
will fire up and intercept it don't
worry it's not gonna really slow down
your response time effect it will
increase especially if you've got things
cached locally it's just what you really
want
now you're gonna respond with and you're
gonna respond with this promise kind of
thing that's going on so and it don't
hear the returns now I'm not gonna go
into the details of that but basically
the event is going to have the request
object that defines how you're
requesting it's going to have the URL
the headers all that kind of stuff
associated with it first thing you're
going to do is you're going to check all
the caches to see if you already have a
response match the
first response for this request that is
found it will be returned and here you
want to check if he actually got a
response if so then just return it
you're good to go nothing else needs to
happen now I'm using a pattern it's
basically called cash falling back to
the network with an offline fallback
okay and that's a long name but
basically it's what's going on so the
next thing we're gonna do is we're
actually gonna make the network call and
this is we're gonna actually make a
batch here and we're gonna pass in the
request there again you got a cut a
request object and you can just pass it
on to again we should get a response
from the network as long as it's ok
which means it's status 200 just be
careful here if you're doing other
things maybe you get a status 204
different kind of responses especially
two in response to post and put some
deletes and things like that you just
need to be careful about how this how
you handle these responses here I know
it's only gets and I'm only looking for
it okay's so I am good there next I
don't know why but at least locally I
get to I get it all the Chrome extension
requests go through here too and that
causes problems and so what I do is I
just I don't want to cache those
responses so I just I just bet a fault
try to not cache those responses you
know what I probably should do is just
do HTTP and HTTPS or whatever in here
that's probably going to be a cleaner
way to do it because it would there's
probably other things I gotta do now now
that I've got the response I do want to
cache that response
now you can't cash the response and
return it to the client so what we do is
we clone it and this creates a deep copy
of the response and I cache the copy so
what we do is we open up the dynamic
cache and then we get a reference to
that cache and we put the request and
the response copy into that cache and
you have to put both because it has to
be matched up because when you check to
see if there is a response in the cache
that's going to look for the
Qwest as the key and it has to match up
now if this request excuse me is to the
same URL that has different headers that
is a different request because that can
trigger a totally different response for
example if you used a different content
type
maybe form body versus Jason but you'll
probably want to cache the post but that
would be the case here as well you would
do they would potentially create a
different response so you could have
potentially two different responses
cache to the same URL but because a
header is different then that could
trigger a totally different response so
now we've cached it we're gonna return
the actual response back up to the
client and all things are good but what
happens if you're offline and this is
gonna happen a lot on phones because
cell your connections are intermittent
and this is one of the things that we
can really make our applications shine
well if the network is down then you
should fall into your promise catch
handler here now here I'm checking just
to make sure that it failed to fetch
because we could have some sort of other
strange exception thrown so I just did
this is a little gate and I'm also
checking to see if the request was for a
session and this is just because this is
a simple application I can do it this
way so basically need to do this I need
to add that to it sorry guys but
basically if there is a session included
in there then what we're going to do is
we're going to go through a routine to
render it on the client this is this is
kind of an advanced technique so what
we're doing is effectively doing what I
would normally do on the server side I
just basically took that logic and I put
it in the serviceworker and I can do
this because I have all of the data
locally and if we go back up if you saw
this but
I cashed the templates to actually
render the individual data so I can I've
got the template for like the list and
then I've got the session detail page
template here as well now that's not
going to be the full page what it is is
just the template to render the the main
content in the page and that is what we
do so this is gonna get a little
detailed here I probably should have
refactor to make it a little cleaner but
it works and I'm fine with it
so I've got a method to just parse out
the slug which is gonna be the last part
of the URL and it's just a simple split
thing I won't go into that but I've got
a method where we go get the main app
shell which should have also been pre
cached up here or somewhere trust me
it's there oh here it is yeah so these
are the three HTML files like I should
highlight that but that's okay all right
and as soon as we get that markup back
the end we go and we go get the session
template I know I could have probably
done like a promise all kind of thing
here it's not my strong suit when I get
into that part of promises so this works
okay so when that when the session
detailed template is found then we're
going to get into just like we did in
the build script if you watched that
video I just dropped the session
template into the app shell and make the
entire app shell a single page that
we're going to merge stuff in again the
reason why I do that is so I can set the
unique title descriptions meta tags in
this particular case but there may be
other fields in your header that need to
also get set to be correct next I'm
gonna call method where we get the
session by the slug and that's going to
call into our our session library to
extract and then we're going to filter
the array I'm gonna go into that just to
save time but if we do get the actual
session object back
and I also should be checking to make
sure that we did it's actually exist I
just assumed well
anyway and then call mustache dot render
pass in the template here and the actual
session data which is an adjacent and
that will give us the entire page back
and here we're going to build a custom
response so what we do is the response
is the the actual markup and then here
are all of the options and this is going
to include the headers and we really
don't need to get too fancy with this
just need to set the content type to
text HTML and that should be good enough
for this and what we're going to do is
just follow our our process again we're
going to clone the response that we just
built we're going to add it to our
dynamic cache and just like we did above
and then we're going to return the new
response to the client and that will
make it all work the way we need to so
that's a quick run through of the
progres
progressive web app and the
serviceworker and the advanced little
advanced technique there to handle the
offline mode and what we want to do is
actually go look at this and if we do
that we go into and we see I make it an
offline and if I go into the details
here we actually step into this one to
show you that this is where we step in
and if I hit f8 to make it render you
can see that the detail page actually
renders and all is good to go
so there we go that's the the magic of
the serviceworker and handling offline
mode</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>