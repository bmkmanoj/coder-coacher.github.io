<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[Hands in Games] by Dan Song and Kai Hübner | Coder Coacher - Coaching Coders</title><meta content="[Hands in Games] by Dan Song and Kai Hübner - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/BeMyApp/">BeMyApp</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>[Hands in Games] by Dan Song and Kai Hübner</b></h2><h5 class="post__date">2015-07-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SofBxCyrOQY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay all right thank you very much thank
so Intel and organizers to invite us
here and also thank all of you I hope
you're not very hungry right now I also
like to thank actually the previous two
speakers because they did the great
introduction to our topic today yeah all
right so my name is Stan and I was about
my colleague Kutner and we are a
co-founder of a stockholm-based tech
company called preachy and today we will
talk about hands our hands engage a
little bit background about ourselves so
yeah we are the hipsters and hikers of
the company and actually kind i share
quite many similar backgrounds we both
PhD though we are in different fields
biomedical engineering I did
neuroscience to study hall brain
controls our movement and high did
pigeon in computer science and robotics
and then we met here at kth in Stockholm
and we were doing research in robotics
in intelligent robotics walking on to a
big ego projects and then later we have
some industry experiences we're using
computer vision technologies to
different applications like sports
broadcasting and Toby no eye tracking
technology well actually what we are
doing at crece is based on what we did
our research at kth primarily about we
want to teach the robot to use the
robotic hand interact to interact with
the object in the world and the how do
you do that the robot is equipped with
like is this playing yeah it's equipped
with the 3d 3d hammer no cameras on the
height and then it looks around the
environment and find the objects and
then it forms some kind of 3d
representation and they use their
robotic hand
to decide how to grasp the object so
that it can pick it up but to interact
with the environment is not just to
picking up things the most important
thing actually is what you do afterwards
you'll pick up something to do something
so actually what we're focused on or we
have focused on your research is to
study how to link this intention what we
want to do afterwards to decide how the
robots should put a hand around object
for example if you want to do a pouring
task you want to pour some water out of
this cup or if you want to drink with
this cup you don't want to grasp this
object from the top but if you want to
give this object to another person then
you want to maybe expose the handle part
so that the other person can't reach it
so the important thing actually is the
intention and what we did is to consider
this intention consider the objects and
also consider what kind of hand the
robot has so sometimes the robot has two
fingered hand sometimes it looks like a
human hands like this one so we'll
consider all this constraint and design
we have an algorithm that looks like
that functions like a human brain to
decide what kind of grasp should be
applied on these objects so well maybe
you have a question mark in your head
why we are here I'm talking about
robotics but this game conference but if
you think about it actually the Avatar
you cannot play a game without alberta
so if you have avatar and the
opportunity to interact with the game
environment and avatar actually is just
like robots we want them to interact and
how to incorrect for us we interact with
the world with our hands this is our
fundamental tools to interact and we
also want about her to do the same so we
have the unknown research to teach robot
to interact with object in the physical
world but we want to we have actually
added bleachy have successfully
converted this technology in our
to the virtual world so that we can
teach the Avatar just like a robot to
interact in the digital wards the
digital object that you create it in the
game environment so that's why we call
our technology virtual grasp so I've
been talking about how to apply it in
the game world let's look at how it
looks like in the games inviting 2003 in
second life second life Linden life and
you see that this art is clearly want to
want to interact with the the object is
this is the I think this is the cash
machine and you see that the the body is
very rigid the hand is very rigid and it
doesn't really do those things as you
expect so well it doesn't even do as
good as our robots that are shown to you
of course you can say that it it's like
more than 10 years ago and the things
should improve and let's look at it to
solve none and I think a lot of games I
mean you are all famous use a stick
you're all hardcore gamers probably and
a lot of games is to actually the author
is just grasping some and a weapon a
fixed set of weapon whether it is the
knife of his a gun and then all the hand
motion involved in this games is like
create kind animation so you do
animation once then you apply it over
and over again on the same object in the
same way and it will become very
interesting if actually in some games
you do want to interact with many
objects like this one Skyrim so you need
to interact with hundreds of objects in
the environment but what happens is the
hands still just follow team there
doesn't really do things like you do in
the real world objects just magically
disappeared and do the things that you
want them to do so wouldn't be great if
you actually can allow this our talk and
do things like what you do in the real
world but it's quite difficult and then
now we're talking about just last year
things I created and happen so much in
turn in turn
the hand interaction in the game world
why why is that it the technology and
the computation power has evolved very
much but why there is still no hands
interaction oh I would like to show this
small fun picture in fact the same
problems also exist same answers also
exist in the general animation industry
okay with no for animated films no
matter if it's 3d animation like Pixar's
animation oh it's just the traditional
2d drawings I don't know if you have
ever tried to draw your own hands if you
just grab a pen and try to draw on the
paper your own five fingered hands you
will notice this is extremely difficult
objects to draw and if you'll notice
that in these images there are something
in common is they have only four or
three fingered hands it's not five
fingered hands why is that because hands
is the most complex mechanics structure
on all of it among all of the different
butter patio in our in our body so it's
extremely difficult to animate this is
actually a very famous image in
neuroscience I don't know if you have
seen it it looks bit ugly but this is
the different body parts of this image
is drought in the sites that is
proportional to how much power
empowering is needed to process it so
maybe since we're in the game conference
this is more fun this is the this
lecture the buck is a huge hand glitch
but the finally it seems that the game
engine behind fifa 2014 also things like
the human brain they know that hands is
really difficult so let's come back to
animation you probably all of you know
mix amo they provide the animated like
the animation database and also rigged
of our tarts to developers and if you
just look at
different options ways and without hands
without with hands you have 65 total
number of joints and almost triples when
you don't have hands so what this means
is that if you want to animate hand it's
create an enormous amount of effort for
you to do it so this is the example of
someone try to animate this FES handy
hands from unity asset store and you see
that you have to manually to encourage
individual Jones and the move the object
inside it so that you create a realistic
hand animation or in fact the hand
doesn't even move so much just grasping
this object and with all this effort
what did you just H Eve it's just one
single hand grasping one single object
and one single way so you can imagine if
you really are in the interactive more
interactive scenario you really want to
grasp all kinds of objects probably
using different kind of hands if you
have multiple avatars and then you
wanted to grasp things in a different
way because you want to change the way
your grad speedily now to do something
and what happens is like this you will
fewer patients instead of helping them
so what I want to show here is when you
have when you want to really do
interactive narrow in real time with
your hands grasping different things in
different ways the effort of animation
will grow exponentially so it's really
impossible so what the developer what
you will choose to do in this situation
is just to ignore it and that somehow
explains why nowadays there are still no
hands so if you like I think that people
have been talking a lot about virtual
reality if you have a headset the visual
is fantastic it's really impressive but
when you see some interesting object in
front of you what you immediately want
to do is to raise up your hand
and you will not be satisfied by just
flipping things around with your hand
you want to grasp it right you want to
play with it and the eve of the play and
they play this again when you interact
with object when you really want have
immersive experience suddenly you see
your hand is sticking with object and
this immediately agree Greek the sense
of immersion so you do want to have a
natural interaction isn't it right so to
summarize the problems i think it's
virtually relevant to you guys who
develop games i want to have fantastic
games out there it's really difficult
and time-consuming whenever you want to
involve the hands interacting with the
objects and especially when you want to
develop a game that involves realist I
mean a real time interaction with any
kind of objects with any kind of hands
then the result is over non-realistic
and the third one would be more like a
question to you guys don't you think oh
do you think liking hand hand
interaction the game will restrict the
evolvement of the evolution of the games
so if you look at this example the tomb
raider franchise so we see that the
computer I mean the computer graphics
the technology has evolved for the past
20 years we're in a very very impressive
state so from the very pixelized avatar
like that ridgid to really real human
look nice hair with facial expression
but what is missing is really no hand
interaction it it sounds like it appears
like nobody really cares about hand
interaction is that really true as a
question really we can discuss about it
later yeah but I mean maybe you don't
pair but certainly there are somebody
cares and somebody who is really the
industry leader and has great impact on
the involvement of this in
three so this is the quote back into
2009 of six or seven years ago so it
said is that that improvement to
software and have higher computing
computational speed has make it very
realistic environment and then make very
refined faced motions but hand movement
of for example is still at a very crude
state so the problem is there and people
want to solve it it's not that it's just
being hidden well in the recent example
we all know about virtuality and there
was a television interview of Palma
floppy and he said that the the moment
you where the goggle you would like to
interact with the board just like you do
in the real world so what if we have
something to realize this ambition we
can enable everyone to easily use our
hands as a font which is the fundamental
tool for us to interact with the real
word also to interact in the virtual
world so that somewhat close the loop
and we have this technology called
virtual grasp and our ambition is to
solve this problem not only for you guys
at the game developer and we also wanted
the Famers to experience this fantastic
to the hands for ourselves so here is a
little video demo with this virtual
grass technology so you can interact
with any object in front of you in the
game word in realistic way you can grasp
whatever way you want you can play with
the dice like this you can write grip
with Bob and even cleaning them up so I
think my colleague Kai will talk a bit
how we do this
introducing and also for the previous
speakers of Intel and also the VR talk
so that we don't have to talk so much
about we are anymore but so how does it
work to add this a bit more because I
mean I was here last year and I felt
there were a lot of game developers how
many game developers are are here
actually how many of you Oh quite a lot
okay so then I don't have to leave I
actually have something to talk about so
how does it work when we talk about
robots as Dan said to go back a bit in
the loop here everything starts with a
task the robot has to know what to do
before actually looking into its own
hand and trying to see the objects that
are around the table interpreting the
world and interpreting this information
and then finally actually do something
with it that's like the process usually
in robotics in gaming it's often a bit
the other way around I mean when we talk
about hands and interaction it often
starts at the motion controller you have
some kind of input some kind of
controller and you try to steer the rig
your hand rig in a way so there are two
things here to put out one thing is that
you actually miss quite a lot of
contextual information when you just
focus on the motion controller and the
rig and the other point is that you
start at the other end somehow you start
that the motion controller and not at
the task at the intention so you could
say everything starts with an input
that's what all the people say when when
you want to talk about hands and games
and we say that actually everything
starts with an attention you want to
pick something up you want to interact
with objects in different ways and
there's where we start
I mean the one question is I guess we
had a lot of PR systems here today
already on the slide but when you want
to start with putting your hands into
into game you can use real sense as we
as we saw we actually have a the earlier
realsense camera here it was a
perceptual computing SDK that when you
could use 3d camera leap motion and my
oh I don't know if you know this one is
like my graphic sensor to measure
signals in your arm you could even use
Sony move for example or regular game
controller or for Toby people an eye
tracker to just have some intention
about how how do you interact with games
so there's all this big mass of things
in almost every new month something else
comes up and I think of course you would
ask what's the best of course Intel is
the best but I mean it depends clearly
on the application I mean you have
gloves you have 3d cameras you have game
controllers and maybe even when two of
you talk to each other you have
different preferences like I mean do you
need finger tracking in your application
do you need feedback the or do you want
to have like convenience of a regular
game controller and I'll skip that one
because what you have there or maybe I
go back a bit because then when you as a
game developer have to decide that means
you have to program your game for
specific game controller and your game
will maybe only support part of the
users so then somehow the user base is
defragmented for you because you need
something for each particular hardware
peace and with virtual grasp the our
goal is actually to provide an intention
based as I said before
tension is a password or keyword here
device agnostic which means that you
could use any kind of device to actually
give an intention to the system all of
these devices here or just your mobile
phone for example to give some or you
could also use speech text whatever if
you just tell the other or you can use a
mouse keyboard click on something
because the main thing is is a software
solution for hand animation and hand
animation can be used in different ways
games applications about what we are
currently doing how we are working at
glitchy is that we are currently working
on customized experiences with project
partners to deliver first use cases and
what we notice actually that while in
gaming as you might understand you don't
necessarily today see the need that when
you have a shooter okay you put you pick
up your gun in one way but with upcoming
virtual reality for example you might
want to interact freely with objects and
that's why we're currently seeing on
working together with so-called series
games companies series games are games
that are not for entertainment but for
example like simulation education or
rehabilitation so we are currently
working on a project like this one where
you have a glove the haptic love it's
not this Gloria hard this is just an
example where you have some visual
feedback on the screen of a hand that
actually interacts with the objects in a
natural way while the patient actually
cannot but maybe for you is more
interesting the mid term solution that
we are aiming for for next year is to
implement a scalable plug-in solution
for the regular game engines unity
Unreal Engine havoc but also animation
studios and we are thinking about
similar model like an exam which you
might know that you have some web-based
business model where you can just
download a plug-in and
and I mean you as a game developer to
have your object maybe you have hands
maybe of not so we can support you in
without dragging tools and the plan is
to provide some kind of freemium model
for indie developers to bring this out
so this is currently our core team done
and me you know and you cope is our CEO
his country's lying on the beach
somewhere in Italy but we also thinking
about extending our team currently we
have to master thesis proposals one more
in the technical so if some of you are
interested also in some other technical
task contact us but also in the
marketing side we currently have a
master thesis mainly into the health
industry but also be our we want to
analyze the market so to finish up I'd
like to thank all of you also the
organizers for organizing this great
event you are all sponsors if you have
questions you can ask done at me or send
us an email and i also finally want to
invite you to stock on the our meetups
next round which is in a month from now
which we are also organizing and this
time we will have an exhibition so no
presentations but like very local vr
companies around 10 a dozen will show
them latest and greatest and i think
it's already booked out but i think if
you sign up we may be split the event
into two so that we have two different
patches ok that was it thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>