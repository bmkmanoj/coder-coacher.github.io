<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>[Ultracode Munich #4] Presentation &amp; demo of the Perceptual Computing Parroteer | Coder Coacher - Coaching Coders</title><meta content="[Ultracode Munich #4] Presentation &amp; demo of the Perceptual Computing Parroteer - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/BeMyApp/">BeMyApp</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>[Ultracode Munich #4] Presentation &amp; demo of the Perceptual Computing Parroteer</b></h2><h5 class="post__date">2013-11-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Mxj6QTUd-sw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and with that's why i always take two
drones with me we don't get the
connection by now and so i tried to
build this and practices i think then
i'll start with the presentation itself
I'm sorry and no can do this
I think it's this computer and it's not
drone itself
okay maybe it's just dry
sorry for the interruption but maybe it
works now it has what it has was before
yeah we got some bandages
I got a picture so this is great so now
I put this away again and put oh so now
I'm going to show you what what stealing
the drone is like to start I put my
hands up here doesn't have to be too
close to the camera it doesn't have to
be too far away but this distance is
ideal so I have some some space to move
my hands up and down left right and when
I want to start I was an object I can
use
life
moving to the left until your right
putting my hands
again so if I want to
yeah and of course you always have to do
a three turn around because everything
ok
all the land of the world's got some
just it again and this is all done using
the perceptual computing escape okay so
let's get
Oh
so this was the challenge itself and
what we were building is called the
parousia project Elliot's basically it's
a basic content side ah da are in itself
so we can steer normal off-the-shelf
product using at the SDK the drone
itself costs about 300 euros it's
available everywhere normal places where
you would get electronic social media
mark is a fine place together and how do
we connect to the drone we have to do
some soap ad network so we have to
connect to some UDP or TCP surface get
some binary stuff out of there
interpreted we want and then we can use
the data we get so this is pretty low
level and what he basically did to get
around the lower and stuff and gets to
the language where we wanted to was to
implement the wrapper so basically when
you
this wrapper which is open source you
can also download it you can just say
take off to drown or you can get enough
data out of it by using a listener or
picture listen
so that everything you want you get it
was normal a normal childhood ok this is
the Nautilus normal control normal use
wasted room so you can use it in UCL a--
a smartphone you can hear by putting it
this way that way you can move to the
back onto the front if I flake dominant
and moving it up and you can do the
other and Direction volatile this is
really this was cool three years ago I
think but today we got wait when cooler
heads annotations so our idea why we fb
fr the sexual computing had not want to
implement it using the perceptual
computing SDK okay the features of our
presentations of course that it's
hands-free so we don't have to do
anything using a mouse using the
keyboard or using a touchscreen up
everything can be done with your hands
and you don't have to to put them
anywhere so
we also know that the complete
turnaround so every direction can be
controlled every direction that this law
can access can be controlled so they all
want to go back right and so on and so
on and we use the gesture recognition
that was provided by any such a
computing SDK so basically these gesture
first then just just you can easily
access using just the standard ok and we
of course we also use the all the stuff
we would get out of the SDK so basically
the hands the point where the happiness
at the moment we can get it out but I'm
going to see a little bit later as we
get into the code um as you may be so we
got a reference point here so when we
start drawing everything is calculated
from that my favorite spoon so and we
start at this point and we move our hand
forward from this point and a drum class
fault if we will move it back this way
it goes backward and the same as done
using
the height so this is something you'll
have to know because if you move away
from rolling back in maybe the drone
flies a little bit backward because it's
the data reference from the reference
point is only deleted when you land okay
and oh what we basically needed was some
smoothing because it is really difficult
back then with the perceptual computing
SDK version 2 to get precise values and
so we got to them shrunken it and the
differences in the in the valleys that
weren't acceptable so the drone was
flying it was a bit a little bit quirky
and this this wasn't the way we wanted
to do it so after the challenge we
implemented some filtering we tried out
different filters so we did some calm
and filtering reach right bilateral
Center in which we basically use now and
also simpler stuff but what's the
commenter that it's really a good way to
steal drone because it's because of it
it's reactive and still it's gets smooth
pretty well okay which tools they were
use basically this is the Santa to stack
I wouldn't I would like to use
use Java as a programming language you
use the native bindings of the
perceptual computing SDK so you can just
compile them from the standard SDK if
you download it I using the make file
and then you've got natives library a
dll and you can embed it into your
application as a long drawers if the
media's get we always do by now may even
as adults system you can see and we
didn't use greater for this one and but
this is just like convention because
we're much more used to mail them than
we are to cradle this will I think this
will change it with interview an excuse
oh oops I forgot we implemented it so
that we can use it using eclipse as well
as IntelliJ the only thing we need test
java's X sub Forge which I yeah I think
it comes negatively with netbeans so we
can also use netbeans for bed okay let's
talk a little bit about the architecture
we try to implement some best practices
were used to add work
because yeah we really think that these
practices are important so clean code is
very important to us basically we are
using meaningful names we're trying to
keep classes no longer than let's say
150 lines of code nice it's no longer
than 10 15 maybe a little bit less but
around that we and we also try to do
some separation of concerns so and on
top level you see these five modules we
have need to control which is basically
just the view which is this which is the
job at X window you can see when you
look at this red screen and we also got
it for the leap motion there are a
little bit difference away I'm gonna be
two versions of it and on on the bottom
side we've got the enter perceptual
library which basically means that where
we created a wrapper for this library
because everything in there is a little
bit see style and we can don't want to
do it these styles and we implemented
some
the usual stuff you would like and you
also get a picture and as an integer
array and this is really better than the
standard version I think and then does
the drone API which is basically there
for stealing the drone itself so this is
the rap i already talked about and the
leap perceptual this is khaliq motion
version again the same thing we would
use reddit essential SE que version but
this time for the other camera yeah and
everybody gave you will see that we got
some more abstraction layers and trying
to build stuff that is really reliable
so we also use dependency injection for
this this was done using juice
frameworks and basically the same stuff
here as we saw in the android talk and
we could also implement some other
dependent objection here but this is by
far most likely one I think and standard
implementation of the GS edges are 330
so we're like you use it
whenever we can yeah I'm try to also
keep the complexity at a low level so
there's not the cyclomatic complexity of
the code is pretty low I think okay and
also there's better things we built in
that we wanted to have there is these
are not the architectural and patterns
but peasants we would like to see in
perceptual computing more and more so
and let's they have a mode whenever we
step out of the picture and our hands
were like this when we stepped out and
the drone goes in to have a look it
doesn't just fly this direction until it
crashes against the next one this was a
really hard way so it's really fast time
it did exactly this this was hot tuna
and and what we also have a metaphor see
violence moving so we user gets a better
experience out of this flight SI
experience and with 12 we got a lot of
false positive regarding chester rear
edge detection so who then was let's say
free real values that
fifteen thousand fake values and not
really realize again so gesture
reassurance was a real problem back then
but by now it's really really robust
worships we brought with us nice stuff
with it okay so this is the base this
will avoid concepts of our presentation
and what I'd like to show you now is
some code and I'll get right to it
i'm also using IntelliJ so basically NYC
was real cool thing for me
is it good enough
can you read it
presentation tell jay i think it's you
and you and the boo scream
then
yeah yeah we can do this but I say this
is really this a bit difficult to read
it by now so I don't want to waste any
more time ok so then mail most important
project for you a perceptual computing
SDK is the end of conceptual package so
it's a multi-module project here and the
reception is all about and getting the
coordinates out of the SDK for the main
kaun so we got
how to you and first of all the scepter
controller which we you will use if you
want to get anything out of it and as
you can see there's a picture component
of detection per phone another gesture
conformity these components are there
for forgetting those things I want to
get out of there and so under component
within the picture component we got for
example trying to see this one I think
it detecting components easiest one and
we got this one and here what we are
trying base achill e implementing as the
query features and the process features
very features just means that you have
to ask the SDK what you want so in this
case i want the query q node method so I
want a keynote object which are passed
to it and least the cable sell it for me
after we will get to the process
features section of the party and when
we gotta we get using the methods get
smooth
get word in it we get the coordinates
out of the note itself and this is
basically it everything else is just
filled ring and everything you want you
don't want to do yourself basically and
and if you want to get events out of it
we just have to add a listener to this
component which is delegated by the
perception controller so every time we
act the gesture listen and weep yes this
what are we getting a gesture to see
like call it a gesture theta or
something like that how does it whenever
the the sdk detects a half ok the same
thing applies for the gesture at the
picture let's see what it can process or
the main object does is it mainly just
very strange it's just like that that
runs on your machine and frames and what
it does is it requires a frame at first
the computing stuff you have to do if
you do it for itself then I go through
all the components i got and very their
features then I call restrain after
release frame all the Geo notes are
filled all the data I want to have is
mixed up with what's the values i want
to i want to get and after that again
call process features which then can
call the listener add can invoke the
business which are registered at the
objects yeah and this is the main stuff
so if you see here we got the filtering
so i have i implemented a lot of filters
and try to get our that's the book
of them sorry for the best form of
bilateral filter because it lets you and
it recognizes hard edges and these hard
edges are then not filter whereas rather
kiss noisy actions are unfiltered out so
if we got smaller and small steps and
then as a big change in data the big
change is not filtered out whereas small
changes are smooth this is a
okay and if you want to use it finally
we go in today to put inter control
module and there we have the drone input
controller and this remote controller
gets all stuff we need so it has a on
gesture method which it implements using
the gesture listener there's a
coordinate listener and all the business
we need and then if directly and dharmic
a 3x2 the things we have here and starts
the drop if we have a thumbs up gesture
this is patrolman would control out
there for combining all this stuff okay
so that's the basic architecture of the
drone if you want to fly for yourself
I've seen as time after the pizza and
entering you can these wider so you
don't have to touch a keyboard whether
it's right I have just one person yeah
first you said it's tense</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>