<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Streaming with Hadoop | Coder Coacher - Coaching Coders</title><meta content="Streaming with Hadoop - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/BeMyApp/">BeMyApp</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Streaming with Hadoop</b></h2><h5 class="post__date">2016-06-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GQ-LGBHfphQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon good morning and evening
wherever you're joining from welcome to
a Duke with the best my name is Andrew
sought this can give presentation here
on stream processing meets I do and I
think you know hopefully set the stage
for what to hear the rest of the day as
other presenters talk about how to talk
about stream processing and really kind
of where things are heading everything
is being recorded so you get a chance to
go back and listen to it again if you
like possibly have access to the slides
I'll have trouble being able to answer
questions during the presentation just a
way the chat is set up so at the end
we'll leave some time for questions I'll
talk for about 40 minutes 45 minutes or
so and then have some time for questions
at the end that we could get to all
right so give it quick outline here to
score what kind of an introduction kind
of way I look at it is this pre-2012
error if you will 2012 2015 it's kind of
like dawn to this new error related to
streaming and Hadoop and then 2016
unforward this brave new world that we
find ourselves in a little bit about
myself again my name is Andrew saltus
I'm a principal data engineer at
shutterstock so I'm going to stop them
involved in having fun outside of sort
of stuck sometimes ramble on Twitter
admittedly I'm not about everything i'm
eating or little nuances here and there
but some things that I find interesting
and sometimes perhaps not as much as I
should have finishing up writing a book
for Manning titled streaming data that
kind of covers I wouldn't say everything
we're going to talk about today but
really goes over building those larger
data pipelines and what's involved in
building a streaming data pipeline I've
been dreaming about streaming since
sometime around two thousand eight kind
of first built a real-time analytics
solution sometime early 2009 had
deployed storm and production around
2011 right after it was open source in
building a system that we were doing
about a billion events a day so it's
kind of fun time with storm back then
then I fell in love with spark when feel
baumgartner jump from the edge of space
in october fourteenth 2012 so kind of
those crazy things remember it I
remember the environment i was working
at webtrends felix jumped largest amount
of traffic ever seen analytics systems
at the time had a lot of trouble
processing the data and that weak spark
was released with its own standalone
resource management so we started
playing with it and one thing led to
another and it was the love affair that
began then and I think it's accurate to
say to that I lived in a or I do live in
a fairly up lacrosse crazed family so
not working or playing and someone sort
of lacrosse ball around somewhere taking
in an event since my home office here
out on the edge that I'm talking to you
from today actually I wish it's not but
it would be great if it was see a couple
things just kind of get things started
you know watch streaming this is a great
quote I think from danis Andy of sequel
stream without stream processing there's
no big data and no internet of things
it's really interesting when you think
about it i think you know depending upon
your slant you could argue is that
really true is there really no big data
and we're still going to collect
everything you know is there no internet
of things we're still going to collect a
whole lot but it's what we do with that
and it's really been able to process
that data and i think it does capture
that in this quote if you look at some
of the things we could do when you do
stream processing you have operational
efficiency so one extra mile per hour
for a locomotive on its daily route can
lead to two hundred million dollars in
savings and that's from norfolk seven of
what they've done you can predict
machine failure something that GE does
with a predicts platform that's a stream
processing platform they monitor over
5500 assets from over 70 customers
globally and then this very interesting
architecture where it's a hybrid on-prem
cloud that they have these plans and is
manufacturing environments with GE
hardware that is collecting data in the
manufacturing center and sending it to
the cloud for analytics so you're going
to predict the failure to turn when
something needs maintenance known as an
example a single gas turbine produces
about a terabyte of data every hour
tremendous amount of data so think
together we face a problem that's a
shared problem that we have to figure
out how we're going to solve going
forward and it really kind of boils down
to this if you had today a byte of data
was equal to like gallon of water you
can fill an average house in about 10
seconds by 2020 you'll take only about
two seconds that's a tremendous
difference in the amount of water
flowing and really seem out the data
that's flowing through a lot of it comes
from Internet of Things or is folks from
GE like to call this industrial Internet
I have a little sensor tags this ti
smart tag it fits you know so about the
pack about the size of a book of matches
it has ten sensors on it Nikki do I our
ambient temperature humidity as a
barometer as an accelerometer gyroscope
light sensor whole store things cost
under thirty dollars size of a book of
matches and they're going to get smaller
this is graphic I love that's from
McKinsey 2015 report they came out with
they identify these nine settings that
they look at where the inner two things
iot is going to have an impact and where
we're going forward some of it is far
from even happening yet but they look at
here we look at things like home du inch
or donation security that being worth
about 200 to 350 billion dollars
security
offices looking at factories the
operations and equipment optimization
being 1.2 to 3.7 trillion dollars in
retail automating check out on work
sites human health and fitness it wasn't
too long ago that you know no one knew
what a Fitbit was no one had it
president united states now his watch is
a Fitbit so it really wasn't that long
ago if you're a runner and most recent
version runner's world right on the
cover how do we go from being like Fred
Flintstone to Fitbit in just a handful
years amazing all that data that's now
flying all around us a look at outside
logistics and navigation and then cities
smart cities and public health
transportation really you look at
everything around you and they peg this
at these nine different settings of
having an impact of three point nine to
eleven point one trillion dollars per
year in the next nine ten years it's
quite impressive so it's look kind of a
pre 2012 kind of what the state of the
union was kind of what was going on you
know where things are happening you know
you kind of have this you know it's
making of a perfect storm you know they
had Hadoop it's been a ruse around long
before then you know the Google paper
came out in 2003 MapReduce was
simplified data processing came around
2004 I do became a sub-project in 2006
this is you know a long time right yahoo
had hadoop running on four thousand
nodes in 2010 with over 70 petabytes of
data that they were processing facebook
had 2,300 note clusters he'll hive pig
those graduated and HBase was around by
then as well so in 2010 we had a lot of
the stuff
right for some people working in the
space it's like we already have this
huge way of managing data with these
massive clusters but it really wasn't
you know sort of sage trusted in an
enterprise fashion right it really
wasn't until Hadoop became a little bit
more mature that people felt okay
putting more and more their data in it
in a more traditional enterprises you
know we had Cassandra you know around
back then and then 2010 you know you
have that version point 6 of Cassandra
where there was support added for Hadoop
MapReduce all right so you start to see
this right where you had Hadoop you had
MapReduce that came around so you have
all this batch processing every kind of
replacing batch processing a new way to
process data right with the smarts right
of taking the code and moving it to the
data all of a sudden became a very
powerful paradigm and it is a very
powerful paradigm even today lehigh
Cassandra with this way of getting quick
access to data a more real time and then
right on a 2,000 time time frame all of
a sudden so how do we get data out of a
Duke faster well we have Cassandra
Cassandra support how to do MapReduce
and have this real-time world so kind of
this how do we get back to having you
know the old lab and oltp worlds how do
you get back to having to work loads on
one platform kind of the you know
Nirvana if you will so that was all kind
of going on you know before two thousand
twelve leading up to that you know that
in 2011 you know storm was released
around September 2011 is so the first
you know stream processing if you will
for the masses and there were people
doing stream processing before like I
said I was involved in building
real-time systems before that that we
were processing streams of data you know
we were gluing things together ourselves
for building a lot of it but it wasn't
as well i would say generalized as you
find with storm right so for whatever
knocks people have against storm you
know hats all
to Nathan for really kind of showing
people how to get started and taking
that unusual step and laying that ground
working and right around there you get
Kafka that came out so you got to have
this perfect storm of people these
technologies of people are starting to
collect more data there's tweets flying
around everywhere there's a lot more
clickstream data there's Cassandra out
there more people adopting Hadoop storm
comes out so they have a way to hook up
to this Twitter stream of data and start
consuming data or another source of data
that you may have very easy to plug into
and then Kafka's there as a place to
drop it off to and you still kind of got
these multiple worlds right you gotta
have this hadoop world you kind of got a
little bit of Cassandra you got
streaming happening with storm and with
Kafka and you're kind of stuck right and
towards the end of 2011 you know Nathan
Moore is going to coin this term of this
lambda architecture you know and how do
you kind of how do you bridge this world
right how do you get back to that you
know I think this is you know a graphic
that he has come out with in his blog
post about that right and it was really
this new data coming in storm processing
it and then go into Cassandra or it
could have been anything else right this
is generic architecture just happen to
be his idea and then querying it and
then in the bottom you have Hadoop going
to elephant DB which was just another
data store that provided access to data
efficiently for read-only so I know like
Nathan a coin that's right to be this
lambda architecture e of the speed layer
and the bachelor in a really kind of
continues to go back at that you know
original thing of you just want to know
and especially now and as the world goes
forward they really want to know what's
happening now and what happened one look
do 3-4 months ago right so you see that
elephant DB route is again that's in
front of a dupe of a dupes not fast
enough that's not necessarily a dupe at
the global you know thinking of all of
it but it's how to get data inquiry ado
fast nuh still wasn't there still wasn't
there right and as we talked going
forward we'll see kind of where it is
but even then not there but you would
push data out to something called
elephant DB or another system and you
have a general query she kind of a
streaming and then underneath kind of
you know the Hadoop so we saw how we try
to the first collision of Hadoop and
Cassandra not a lot of uptake the
implementation you know it worse you
know not kind of the best experience and
then you split again you have kind of
this storm route streaming data that
maybe go right into Kafka or into
Cassandra and they got the Hadoop brush
or it says to pass time so I kind of set
the stage for where things start to go
you know I think kind of this time frame
of 2012 2015 now I really kind of call
this like this dawn of this new error of
all of a sudden you know the lights come
on a lot of people like aha you know now
we could do this you know and you get
back to this all the data looking at the
data right it's interesting you know
approximately one percent of data from
an oil rig I may have 30,000 sensors is
actually examined one percent I and
normally today we're using this data for
anomaly detection and control but not
optimization of prediction or the
greatest value arguably lies alright so
this from the Stila mckinsey report of
just how to use it data it's this stream
processing that's going to allow us use
this data ice is very interesting i
spoke with with someone last sir that
works for a energy firm and a utility
firm in missouri and i was talking to
this young lady and she said that really
kind of scared because they're so used
to collecting data once a month they get
one record from your meter and they had
this whole warehouse set up and they
know how to process it and life is grand
but now they're deploying smart meters
and for residential customers it was
going to be a meter reading every 15
minutes and instead of being this meter
structures are used to it was going to
have a whole bunch of clear data about
what else is going on in your house or
what's using energy let's give every 15
minutes from once every 30 days and for
commercial customers is going to be
resending data every five minutes she'll
scare what do you do with this data how
do you process it how do you make sense
of it and it's a stream processing but
again we need to store it and that's
where I end up with a doob so how do you
get these worlds together and it's just
growing growing if you look at this
including smartphones and computers it's
currently estimated we have more than 9
billion devices connected in the world
Mackenzie pegs it in the next decade of
being somewhere around 25 billion Cisco
they also include a lot of other devices
that are kind of behind the scenes if
you will for most people a lot of
networking gear but they're looking at
about 50 billion devices so it's
somewhere in the middle Mackenzie may
look more from what we see or what the
consumer see and Cisco looking down at
that lower level but there's a lot of
people that work at that lower level all
right you see a lot of stuff of storage
networks or software-defined networking
and a lot of these things happening that
are driven by some or a lot of data to
process you know so what do you get in
this time frame you know it's 2012 2015
and we'll go through each of these a
little more detail you know yarn another
resource manager on dude it's really
kind of become like a data operating
system better file formats and sequel
and a stream processing invasion just
look at yarn at first so this is
important were thing to do a good job of
kind of laying this out and you can plug
in different technologies here where
there's a script or the sequel but it
he shows how you have yarn as data
operating system and you have ETFs
underneath it and you really look at
this whole thing is this Hadoop
ecosystem and you start to see products
that now come out that our yarn native
applications things like spark run on
yarn storm running on yarn obviously
hive and pig and everything else
starting to run on yarn so you start to
have this as this data operating system
almost the containerization if you will
for the tools that we work with and for
the data tools that you may or put in
the future and it kind of forms this
huge ecosystem and it termed as the
Hadoop ecosystem when you look at some
of the better formats and how do we get
closer to what initially was tried with
Cassandra and MapReduce of getting back
to having everything in one and we keep
on back to that we were there we tried
it we diverged again with the storm
route and kind of lambda architecture
and a lot of energy a lot of push to go
the other way and get back there and it
comes from both directions it's coming
from we go back one slide it's coming
from a bottom-up of getting faster and
better file systems and it's coming from
the top down of these different tools
you put on top spark storm and others
that will see that fit into those spaces
just making her do faster with file
formats you know out came or see you
know or see put together by Gordon works
and Facebook as an optimized row column
or format to make querying on a doob
faster yet another column or format
driven off of the Dremel paper that
Google came out win again the idea a
more optimized file format query data
coming from HDFS and then a new entrant
that cloud errors put out there is
called kudu and if you haven't seen that
it's very interesting and they were
looking at
totally changing how Sorge is done and
driving things to be much faster and
they like it to be that type of storage
that you could write data very quickly
and read data very quickly all right
they're looking to fill in the gaps in a
Duke storage layer as I said everyone's
been stitching things together this next
one in this next list here of making a
Duke faster with sequel right sequels
Laguna franca of business all business
users knowing people try and come up
with different dialects different ways
of query and data when it comes down to
it sequels been around for a really long
time people understand it it describes
what you want to do there's extensions
to ER to support things like streaming
you take a look at the Apache calcite
project there's a lot of tremendous work
going into there to support sequel
streaming so a lot of work going into
sequel and with that you see all these
projects that are everywhere right we've
had high for a while now but you see
things like presto that came out of
facebook so and looking at being able to
use that very high of critics andhra
query different data sources for again
fast access to data you have kailan you
know that's from ebay providing sequel
interface you know over a stores data
and HBase but wants to be an OLAP tool
so now you got these pieces of cubes
sort an H base so trying to provide fast
data access to data stored in in Hadoop
Apache Phoenix project they know built
on the top of age face so you got more
you got spark has sparked sequel ornella
sudden it's like wow I could use sequel
to create anything you have a patchy
drill that's out there another just one
apache tahoe designed for low latency i
think god apache hawk this used to be a
pivotal screed clump product don't
tabaci foundation and then you impart as
another this is going to leave the data
in Hadoop and now let's get back to that
paradigm we have with MapReduce where we
move the code closed to the data Apache
Hawk and apache but Ana Paula do just
that all right they try and get the code
close to the data and query there so it
becomes really interesting and I think
if you were to read the description of
some of these and I'll read you one of
them you know in a class by itself only
Apache blank combines exceptional MPP
based analytics performance robust NC
sequel compliance Hadoop ecosystem
integration and manageability flexible
data store format and all Navy in Hadoop
so you read that and like that could be
any of these products everyone's after
that same goal right everyone wants to
get sequel on a dupe at speed with data
moving at speed so streaming data that
we can now query with a language that
everyone knows and get access to what's
happening now and what happened in the
past let's take a look now at the
pressure coming down to the top of this
stream processing invasion this is the
same thing again so Nathan kind of
kicked it off which storm back in 2011
and got people really thinking about it
in a generic sense but since then this
2012 forward you know you've got Apache
spark it spark streaming yeah Apache
fling which came out and you look at
these you look at just these two right
here and they're trying to bridge both
those worlds as well apache spark is
batch and streaming and some people say
it's not really streaming it's kind of
micro batch because it has these
increments and so forth is true that's
fair but what is real time you know in a
lot of people's worlds if you could
execute something every half a second
would you still consider a streaming
flow of data a lot of cases that makes
total sense and is
very applicable and you don't need it at
less so works just fine apache flank
same thing there are consistent
streaming just like storm always a
constant flow of data but they're also
going after batch so now you had this
Cassandra Hadoop attempt to put the
workloads on the seam nodes and try and
processing together to now you've got
the frameworks above spark and fling for
example that are now saying hey we could
do this at this layer of we have batch
and then we have streaming so now you
kind of get both together with again one
API and possibly using sequel Apache
Sansa Kafka has become the predominant
tool of choice to stream data through a
pipeline and plain an intermediary role
Sansa boxes right on top of that it
provides tremendous ability for you to
process a stream of data through Kafka
and again the sequel as i mentioned take
a look at apache calcite and you'll see
the secret work going on there that's
being driven by the sums a team to have
extensions that's equal to support
streaming you got a patsy s4 which came
from yahoo they got Apache apex which
said data torrent product that was
donated the Apache foundation an
interesting one the ebay release pulsar
and this is interesting because it also
provides the UI as well so you get a
full suite if you will of the stream
processing and DUI as I said you know
there's lots of nos sometimes against
storm Twitter ran with it for a while
they've released Twitter heroin which is
their replacement for storm of just the
problems that they saw on some things
they want to overcome and just the next
generation of where that's going and
then something that's really exciting is
this google data flow so again we start
at the bottom with a doob everyone's
putting their data into Hadoop or
sometimes into s3 and processing in a
doob you have data
the data operating system of yarn and
you got all these tools that have been
developed from storm spark flank Psalms
ax and s4 and apex all these do stream
processing always slight twist a lot of
them understand sequel not all the same
level all have different api's google
released data flow which is an open
source product now and as released as
apache beam and has that available to
the masses as well in their hosted
environment that you can do stream
processing and it has a slightly
different twist and we'll take a look at
apache be may not talk about that here
in just a couple of seconds now kind of
enter this you know new world we've got
all this stuff that came about you know
from starting into thought you know
pre-2012 with a doob and cassandra
coming out there and trying to help do
it Cassandra being the tool of choice
for storing streams of data and where to
put them because you could write very
fast you could read very fast really
kind of works in that world very well
yeah a storm coming out coffee coming
out and then also this explosion in the
last handful years with all different
streaming tools and now we're kind of
left would we have this huge mass of
tools to choose from with a huge spark
or storm or fling or Samsa or apex or
what do you use and how do you move
forward you know cuz this new world if
you will and there's tools that have
come out since you have like Apache gear
pump another take on streaming you know
I think you kind of start to see this
streaming refund meant you know this is
a real-time streaming engine that
they're inspired by some of the changes
that you've seen in the aqua framework
and aqua streams and trying to push that
and they thought that they could improve
on what's come before it all rights you
see this improvement and just you know
what we're gonna do it slightly
differently we're going to leverage acha
and we're going to do something a little
bit
and they handle people are after do as
far as exactly one semantics dynamic
topology updates so really kind of
learning from that past but they
maintain storm compatibility apache beam
is the donation from google of data flow
to the apache foundation and this I
think is very interesting in where
things will go as we go forward beam
aims to be the consistent API across
streaming platforms so they want it to
be and as it is today in his beginnings
is a framework that allows developers to
be really productive without having to
worry about the data platform in a
streaming platform you're going to use
it take what we have today of all these
tools that are out there and even though
they kind of speak sequin some of them
have different degrees of support for it
even if you're not using sequel all the
api's are different it's kind of like
the old days of doing programming
against Oracle or sybase or sequel
server or informix without using
something like jdbc you know back in the
you know earlier times it was you used
Oracle's tools you wrote against Oracle
code or you wrote against sequel server
and maybe used their native stuff or you
wrote against a different database there
was no consistent way and are there are
companies back to n that would sell
tools right into the folks that grew up
in the native world of writing C+
applications against databases you had
tools like roadway to get access to
databases you had the advent of Java and
you had jdbc and all of a sudden it was
like hey I could just switch out which
database on top I can do from a property
and as long as I follows an CC hole I'm
good to go and it doesn't matter to me
what database I'm using you know in the
streaming world today is kind of like
the original relational world of my gosh
if i am using apache spark
and now I want to switch to flank it's a
completely different API is some of it
the guys that have the gals on youse
guys that just in general but the folks
behind a patchy flank I've been really
good at shrine keep the I the API close
to what you see was far but there's
differences for sure and it's not the
same tool so there have to be
differences for them to have an API that
makes sense for their tool set so really
different and then storm completely
different than both of them apex
different sounds a very different some
of these tools are conceptually
different they all have different api's
they'll have their version of sequel
support of various degrees and it really
makes it hard and you almost face this
lock-in of either if I go is spark that
is really hard to switch the flank and
you're either end up in this analysis
paralysis of which tool do you choose or
you jump in with one you're like okay
that's it we're using this and we can't
switch or you just use sequel and you
may be only touching on the surface of
what the tool is so Apache beam aims to
change that and I think as we go forward
and you look forward that is we were
heading it's gonna have to happen that
we end up with a consistent view of the
world right we're going to need
developers to be productive in the same
person I had mentioned earlier that I
talked to you last summer that works for
utility company that dealt with all this
data that's now gonna be flooding their
environment we were talking about
sparking about spark streaming and her
comment was you know I don't I don't
need to hire I can't hire all these
people to write spark code you know I
need people to work at a higher level
right so I think you're going to have
that jdbc equivalent for streaming and
that is gonna be a patchy beam or
something to be really close to it you
know it is very based on data flow if
you look around and look at google data
flow and also
take a look at some research rich in
with Microsoft that's on timely data
flow everything moves towards doing this
and the beautiful thing about being is
even today you could write a single
application that runs on spark runs on
fling or runs in Google's cloud on their
google data flow so you could use beam
to do that and again the idea similar
jdbc write a application with a
consistent API and then you can run it
on a different runner when it comes time
so really helps helps to close the gap
and be able to understand the tools and
helps to make developers more productive
so it's a very interesting thing apache
quarks is brand-new donated apache
foundation from IBM and this is also
another direction you'll see things
moving ok so i think of this two things
you take away of where the world is
heading besides the fact that we're
going to continue to see more and more
data everywhere and we collectively have
a massive problem to be able to solve
and a lot of fun honestly all right what
a fantastic time to be involved in this
world of being having access to all this
data flying everywhere it's nirvana
right that beam that provides at jbc you
got course that takes this approach of
saying you know what we're gonna reach a
point and it's not too far out there
where we cannot move all the data to a
Hadoop cluster to a central processing
facility to process it we have to do
analysis closer to the data because it's
just going to be too much data to move
corks is that direction all right it
solves that problem of where you have
all these in terms of things being
pushed out to the edges and we want to
extract meaning from it we're going to
need to process data at the edge not in
one central place
and quark is and their site is I think
it's like age it's quick dash edge I
think you know it Apache it is
processing is out you get in the stream
at the edges we're going to have to get
there and beam again we're going to need
to collectively as a community build
that out work towards building other
runners how do you make it so that puts
down to solve a streaming problem that
my company is facing and I could use
apache beam or whatever the next
incarnation that takes that idea and
runs forward is but I could take that
concept of I write once and I run it on
any streaming platform and I could
decide do I run that in my cluster that
is my local and local i would use more
as being your analytics data data center
if you will or at the edge and allow
that to be one API we got to get to that
point and there's one other thing we're
going to need you know this is all still
talking at the UI right or sorry at the
API at the developer side the next thing
the person I talked you told me was
besides having people to write code I
need better tools right this is a
pipeline design snapshot from stream
says it I don't know if we'll end up
looking like this this is just what
stream sets has but it's like this right
if you remember before you start to use
so many dupe tools if you ever worked in
a data warehouse before and you know the
pre-2000 time frame you dealt with ETL
tools you may deal with ETL tools today
they have a gun away people still use
enough if you grew up in a Microsoft
world you know they have sequel server
integration services it is drag and drop
build my pipeline you know build my etl
is what you've done with data warehouses
for decades
we need to get to that point from
streaming as well stream sets is one
take and they have other there's other
companies going in that direction as
well of where do we go how do we go
above it imagine being this tool vendor
and how you have to worry about how do I
have developers to put in support for
spark how do I haven't put in support
for samsu or for a flank or for patchy
apex or for s4 or you know for quark how
do I do that that is a monumental you
note a statue and a development hurdle
of how did you that man josie pye's
again you put beam underneath this Wow
imagine what you could build you have a
consistent way of thinking about a
streaming processing platform and you
can change them out for whichever one
meets your needs but you think about it
you develop against it in one way
building tools like this will become
much easier and when we start to have
tools like this move forward and the etl
vendors start to look and do this right
they're all supporting spark now right
spark is the undeniably the poster child
for etl and rightfully so the stuff
that's gone on is fantastic it is
amazing and it's a pave the way for a
lot of other tools but it becomes this
amazing etl product and as you have
vendors let's start to plug into their
you get tools like this and then once
you can take a tool like this and go
back to the person I had a conversation
with in Missouri that works for utility
company that now wants to be able to
process a stream of data and doesn't
have an army of developers from an AP
eyes but has business analysts they
could stitch together a workflow to
process this data that's coming
this is where we have to go it has to go
towards this direction of having these
tools of having this common API of
processing data on the edge and I think
as you listen to the rest of the
conference today you're going to hear
some amazing talks on how to do more
stream processing how to solve very
critical business problems processing a
stream of data there's a lot of rich
things happening in these lower levels
the innovation in spark in flank in
Psalms ax at that stream processing
level innovation is far from over there
is so much still yet to tackle and do
and the exciting thing is where ever
your passion lies whether it's at that
low level file system with kadu whether
it's at yarn below it and doing resource
management at the file system we could
do above it at the data processing layer
with spark or the old lab tools that you
saw or more the sequel tools or it's
above that yet at Apache beam or it's
above it at the stream sets we have this
entire stack that collectively we have
to solve and is tremendous of work left
to be done and a tremendous amount of
innovation to be had at all levels of
that stacking greatly appreciate your
time again names and result is you can
reach me out on twitter feel free to
connect me at LinkedIn I work at
shutterstock if you're interested in
these types of technologies we are
hiring feel free to go to
shutterstock.com careers or ping me
directly either way works would love to
continue the conversation and I'll go
ahead and stop the screens are now so I
could answer any questions if we have
them
ah
thanks for being on the answer out loud
that's a great I should have done that
let me take this next one here you
mentioned many tools are very
substituted leaning towards processing
large amount of stream data what tools
are best replication such as simulations
that generate a lot of data current
stimulation looking for tools equivalent
to cluster operating systems for time
tific computing such as slum torque bd's
Sun grid etc and I've apologized for not
speaking I don't know why I just took
the typing and it's a great question I'm
not a hundred percent sure of some of
the tools in a simulation world I
haven't used some of them but I would
think if you're able to stream that data
to anywhere and I could even be over a
network socket you can use something
like spark for that you can hook spark
up to a socket and easily get data off
of it we could do a variety of things
with it you'll have the same thing and
be able to consume data from flink or
the other tools as well to get data off
of a network socket in any way that you
need to you take this question see here
it says out you know where the
difference between batch processing and
stream processing and comparable so
that's processing is data that's at rest
so you're going to go and look after
this conference is over someone could
take this transcript and they can look
and figure out what was the sentiment
what were the questions you're
processing stuff in a batch after the
fact and on a scheduled basis so
Knightly hourly daily monthly in a batch
the stream the stream processing is as
the data is moving as
is fine as their tweets that are
happening what is the sentiment of users
right now as people are browsing a site
what are they doing right now so extreme
is as the data is moving never it rests
and the batch data at rest so in
projects that I work on so I'm going to
ask projects that work on em the tools
that I use spark they've done a lot of
simple storm a lot of stuff across with
JPM stack stuff lately with some stuff
with rust just because I tend to it's
going to be surprising as I love things
that are streaming related I kinda have
this need for speed yeah and have really
been fascinated with rust lately as far
as getting closer to meadow and doing
things faster processing data coming in
off a network faster now and look into
bride these tools the entire Hadoop
ecosystem and use a variety of projects
across a variety of tools across all the
projects involved in now there's a
question of are we able to do real-time
data processing it we certainly are and
people are for sure and regardless of
where that's happening whether that's
happening on a vehicle of where that's
happening whether it's click stream so
it's soft real-time if you will you know
I click on a page and how fast until
you've actually analyze it yeah
sometimes that's you know it's within
seconds but you look at the world of
what's happening in automotive and super
computers that are on board and
processing data happening right then
okay so if you look at that there is
doing analysis on the data source in the
car of what's happening next question
here we're currently valuing that dupe
ecosystem see how to serve the needs of
traditional patch warehouse which is on
teradata financial service organization
sage the financial services organization
transaction transactional data itself is
growing like anything I can only imagine
so how and where we take a look at real
time processing verse fast processing
as in what could be good business use
case to start as example so financial
the first thing I could think of from a
stream will be fraud right so you think
about fraud right off the bat that be an
easy one to look at what types of fraud
decisions to be made how can you watch
the stream of data and determine what's
happening how could you figure out
what's going on he's a certain activity
what are people doing that would be an
easy one to do you could also then go
and don't know how this works in the
financial services world as far as
regulation but if I'm not using my
credit card and I'm walking around my
phone well you start to know a lot about
me and you probably know a lot of
merchants on visiting so there's a lot
of opportunity there I think you can too
great with the merchants and provide
them access the tools about
understanding their customers a
questionnaire how can spark be used as
an ETL equivalent it's a great question
at your own sparge and spark and batch
and spark has full support for java
scallop python and our and so anything
that you could express in spark and
obviously anything you can express in
scala in java and python you could
execute in spark whether it's a machine
learning using ml lib whether it's doing
processing and our whether it's doing
graph processing or whether it's just a
computation that you want and you can
run spark in batch mode so if you have a
Hadoop environment and you're using a
schedule like say you see you can
schedule Lucy jobs that have a spark
component to it that you could have a
spark tasks like it's executed and do
whatever work you need to of reading
data stay from a raw input source in
HDFS and transforming that data and
writing it to tables that may be at hive
or writing it out to a relational data
store that I've been involved in
projects that have taken data process it
and spark that was coming in from in
Hadoop process
in spark and export it to seeker so
spark kind of sits in that middle i wish
i had the diagram and yet don't yeah
there's one you could find if you look
at some spark presentations you'll see
the sparks in the middle and it has
input and export from everything it is
very easy to connect to data sources
both to ingest and to push data from
spark is summers the different layers
and data processing starting from kudu
to stream data certainly so you got kudo
at that bottom layer right and this
would be start of two layers okay so
let's imagine that at that bottom layer
with kudu is down here I'm really gonna
have to we have kudu and data at rest so
that could be coo do it could be
Cassandra it could be over CEO Park it
although keep in mind or C files park if
I levels they are right once read a lot
so you can stream data into them okay
kudu is a way to incremental changes
HBase they would make a lot of progress
or two to try and allow you to write
faster okay so you need something you
can write quickly if it's a stream to
them process later so there's innovation
that happen bakudo and then you have
things where you have stuff like cover
we're extremely dated through and it's
not resting so if you look at that you
have data at rest with cuda or HDFS
somewhere Cassandra some data store and
you have data that's still moving like
Kafka virtually still moving right we
know that it actually gets persisted and
you need that but it's moving at a fast
enough clip that it appears to not ever
be at rest above that you have these
stream processors there you have storm
spark you have flank you have Samsa you
have s for you have apex you have core
you have all those layers there above
that and google data flows there's plow
above that you have things like Apache
beam which is going to be those AP is
arguably at that same level as a stream
processing off to the side you have all
these supporting libraries
you know there's more machine learning
libraries that plug into these data
tools okay but above it you'd have a
patchy beam where you have this common
API and then above that you'd have the
ETL tools and the ways to either
visualize in a dashboard which is very
powerful or to construct all these
pipelines of how do you process that
data from below hopefully I think I
answered your question next question how
do you think the adoption lack thereof
of streaming platforms by Hadoop vendors
such as Hortonworks Cloudera map are
into the production supported stack
effect the survivability of the nest
extreme technologies and more conserve
IT environments they look at an
implement and well supported stack and
move on so everyone supports spark now
you could get spark on Wharton works you
could get it as part of HTTP it is
shipped as part of it you could get it
as part of that era you could get spark
as part of Cassandra analytics from data
sex so they're being supported and they
are being pushed forward you could if
you weren't using one of those vendors
but say hosting in the cloud you have
access to this via data bricks having
spark in the cloud and their cloud
offerings so you don't have to worry
about it yeah you have google with their
data proc where now they host spark in
the cloud as well as well as their
stream processing with data flow so
there is support for it for sure there
is support across the vendors for spark
for flank for storm yeah it's being
pushed and available in their
distributions
your next question here is spark in
Scala a good career move for a software
engineer hoping to get into data science
field there's a lot of data science
access there there's a lot you could do
I would say is spark in Scala a good
career move for data engineer hoping in
the data science probably more important
than the language is going to be
understanding some of the tooling that's
out there if you look at are
predominantly used for data science so I
think that's a good regression to look
at you can see everything that's
happening there python is an extremely
popular tool set for data science yeah
spark his full support for it so that's
another reason to go ahead and look that
way spark and I you process it could be
very powerful for data science I look in
spark I would not shy away from flank I
look at some of the stuff you could do
from our Python Scala there's nothing
wrong with learning that you know one
language on JPM it's pretty easy to pick
up another one last question here I know
we have another presentation is going to
start in a moment hi I'm a student very
interested in jobs related field under
big gate environment which skills that
do you think or must have I would say
start understanding that stack
understand the play of a Duke understand
stream processing understand what you
could do with it there's lots of data
out there that you could start to
consume it's very easy to take spark or
flame hook it up to the twitter stream
start consuming data there's lots of
things to do reach out to me i can point
you in some different directions as far
as data sets as well if you're
interested or some project ideas there's
lots you can do i appreciate your time I
know about to go over here thank you
guys very much enjoy your rest of the
afternoon morning or evening</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>