<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Random Forest Algorithm - Random Forest Explained | Random Forest In Machine Learning | Simplilearn | Coder Coacher - Coaching Coders</title><meta content="Random Forest Algorithm - Random Forest Explained | Random Forest In Machine Learning | Simplilearn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Simplilearn/">Simplilearn</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Random Forest Algorithm - Random Forest Explained | Random Forest In Machine Learning | Simplilearn</b></h2><h5 class="post__date">2018-03-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eM4uJ6XGnSM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to random forest my name is
Richard Kirchner with simply learned
that's w w simply learn calm today we're
gonna be looking at random forest one of
the many powerful tools in the machine
learning library before we dive into the
topic let's start by looking at a few of
the uses for random forests currently
today is used in remote sensing for
example they are used in the ETM devices
if you're a space buff that's the
enhanced thematic mapper they use on
satellites which see far outside the
human spectrum for looking at land
masses and they acquire images of the
Earth's surface the accuracy is higher
and training time is less than many
other machine learning tools out there
also object detection multi-class object
detection is done using random forest
algorithms a good example is a traffic
we're trying to sort out the different
cars buses and things and it provides a
better detection and complicated
environments to very complicated up
there and then we have another example
Kinect and let's take a little closer
look at Kinect Kinect they use a random
forest as part of the game console and
what it does is it tracks the body
movements and it recreates it in the
game and let's see what that looks like
we have a user who performs a step in
this case it looks like Elvis Presley
going there that is then recorded so
that Kinect registers the movement and
then it marks the user based on accuracy
and it looks like we have prints going
on this one from Elvis Presley to prints
it's great so marks user based on the
accuracy if we look at that a little
closer we have a training set to
identify body parts where are the hands
where are the feet what's going on with
the body that thing goes into a random
forest classifier that learns from it
once we train the classifier and then
identify the body parts while the
person's dancing and it's able to
represent that in a computer format and
then based on that is scores the game
and how accurate you are as being Elvis
Presley your prints and your dancing
let's take an overview of what we're
going to cover today what's in it for
you
start with is what is machine learning
we're not going to go into detail on
that and we're gonna specifically look
how the random force fits in the machine
learning hierarchy then we're gonna look
at some applications of random forest
what is classification which is as
primary use why use random force what's
the benefits of it and how does it
actually come together
what is random forest and then we'll get
into random forest and the decision tree
it's like the final step and how it
works and finally we'll get some Python
code in there and we use the case the
iris flower analysis now if you don't
know what any of these terms mean or
where we're going with this don't worry
we're gonna cover all the basics and
have you up and running and even having
doing you some basic script and Python
by the end let's take a closer look at
types of machine learning specifically
we're going to look at where the
decision tree fits in with the different
machine learning packages out there
we'll start with the basic types of
machine learning they're supervised
learning where you have lots of data and
you're able to train your models
there's unsupervised learning where it
has to look at the data and then divide
it based on its own algorithms without
having any training and then there's
reinforcement learning where you get a
plus or negative if you have the answer
correct this particular tool belongs to
the supervised learning let's take a
closer look at that what that means in
supervised learning supervised learning
falls into two groups classification and
regression we'll talk about regression a
little later and how that differs this
particular format goes underneath
classification so we're looking at
supervised learning and classification
in the machine learning tools
classification is a kind of problem
wherein the outputs are categorical in
nature like yes or no true or false or
zero or one in that particular framework
there's the KNN where the in n stands
for nearest neighbor knave Bayes the
decision tree which is part of the
random forest that we're studying today
so why random forest it's always
important to understand why we use this
tool over the other ones what are the
benefits here and so with the random
forest the first one is there's no
overfitting if you use of multiple trees
reduce the risk of overfitting training
time is less
overfitting means that we have fit the
data so close to what we have is our
sample that we pick up on all the weird
parts and instead of predicting the
overall data you're predicting the weird
stuff which you don't want high accuracy
runs efficiently in large database for
large data it produces highly accurate
predictions in today's world of big data
this is really important and this is
probably where it really shines this is
where why random forest really comes in
it estimates missing data data in
today's world is very messy so when you
have a random for us it can maintain the
accuracy when a large proportion of the
data is missing what that means is if
you have data that comes in from five or
six different areas and maybe they took
one set of Statistics in one area and
they took a slightly different set of
Statistics in the other so they have
some of the same same shared data but
one is missing like the number of
children in the house if you're doing
something over demographics and the
other one is missing the size of the
house it will look at both of those
separately and build two different trees
and then it can do a very good job of
guessing which one fits better even
though it's missing that data let us dig
deep into the theory of exactly how it
works and let's look at what is random
for us random for us or random decision
forest is a method that operates by
constructing multiple decision trees
the decision of the majority of the
trees is chosen by the random forest as
the final decision and this we have some
nice graphics here we have a decision
tree and they actually use a real tree
to denote the decision tree which I love
and given a random some kind of picture
of a fruit this decision tree decides
that the output is it's an apple and we
have a decision tree to where we have
that picture of the fruit goes in and
this one decides that it's a limit and
the decision tree tree gets another
image and it decides it's an apple and
then this all gums together and what
they call the random forest in this
random forest then looks at it and says
okay I got two votes for Apple a one
vote for lemon the majority is apples so
the final decision is apples to
understand how the random forest works
we first need to dig a little deeper and
take a look at the random
and the actual decision tree and how
builds that decision tree I'm looking
closer at how the individual decision
trees work we'll go ahead and continue
to use the fruit example since we're
talking about trees and forests a
decision tree is a tree shaped
diagrammed used to determine a course of
action each branch of the tree
represents a possible decision
occurrence or reaction so in here we
have a bowl of fruit and if you look at
that it looks like they switch from
lemons to oranges we have oranges
cherries and apples and the first
decision of the decision tree might be
is the diameter greater than or equal to
3 and if it says false it knows that
they're cherries because everything else
is bigger than that so all the cherries
fall into that decision so we have all
that data we're training we can look at
that we know that that's what's going to
come up is the color orange well goes
mmm
orange or red well if it's true then it
comes out as the orange and if it's
false that leaves apples so in this
example it sorts out the fruit in the
bowl or the images of the fruit a
decision tree these are very important
terms to know because these are very
central to understanding the decision
tree and when working with them the
first is entropy everything on the
decision tree and how it makes this
decision is based on entropy entropy is
a measure of randomness or
unpredictability in the data set then
they also have information gained the
leaf node the decision node and the root
node we'll cover these other four terms
as we go down the tree but let's start
with entropy so starting with entropy we
have here a high amount of randomness
what that means is that whatever is
coming out of this decision if it was
going to guess based on this data it
wouldn't be able to tell you whether
it's a lemon or an apple it would just
say it's a fruit so the first thing we
want to do is we want to split this
apart and we take the initial data set
we're gonna sit create a data set one
and a data set two we just split it in
two and if you look at these new data
sets after splitting them the entropy of
each of those sets is much less so for
the first one whatever comes in there
it's gonna sort that data and it's gonna
say okay if this data goes this
direction it's probably an apple
if it goes into the other direction it's
probably a lemon so that brings us up to
information gain it is a measure of
decrease in the entropy after the data
set is split what that means in here is
that we've gone from one set which has a
very high entropy to to lower sets of
entropy and we've added in the values of
e1 for the first 1 and E 2 for the
second 2 which are much lower and so
that information gain is increased
greatly in this example and so you can
find that the information grain simply
equals decision II 1 minus e2 as we're
going down our list of definitions we'll
look at the leaf node and the leaf node
carries the classification or the
decision so we look down here to the
leaf node we finally get to our set 1 or
are set to when it comes down there and
it says ok this objects got into set 1
if it's gone into set 1 it's gonna be
split by some means and we'll either end
up with apples on the leaf node or a
lemon on the leaf node and on the right
will either be an apple or limits those
leaf nodes or those final decisions or
classifications that's the definition of
leaf node in here if we're going to have
a final leaf where we make the decision
we should have a name for the nodes
above it and they call those decision
nodes a decision node decision node has
two or more branches and you can see
here where we have the five apples in
one lemon and in the other case the five
lemons and one apple they have to make a
choice of which tree it goes down based
on some kind of measurement or
information given to the tree and that
brings us to our last definition the
root node the topmost decision node is
known as the root node and this is where
you have all of your data and you have
your first decision it has to make or
the first split in information so far
we've looked at a very general image
with the fruit being split let's look
and see exactly what that means to split
the data and how do we make those
decisions on there let's go in there and
find out how does a decision tree work
so let's try to
understand this and let's use a simple
example and we'll stay with the fruit we
have a bowl of fruit and so let's create
a problem statement and the problem is
we want to classify the different types
of fruits in the bowl based on different
features the data set in the bowl is
looking quite messy and the entropy is
high in this case so if this ball was
our decision maker it wouldn't know what
choice to make it has so many choices
which one do you pick Apple grapes or
lemons and so we look in here we're
going to start with add rate a training
set so this is our data that we're
training our data with and we have a
number of options here we have the color
and under the color we have red yellow
purple we have a diameter 3 3 1 3 3 1
and we have a label apple lemon grapes
apple lemon grapes and how do we split
the data we have to frame the conditions
to split the data in such a way that the
information gained is the highest and
it's very key to note that we're looking
for the best gain we don't want to just
start sorting out the smallest piece in
there we want to split it the biggest
way we can and so we measure this
decrease in entropy that's what they
call it entropy there's our entropy
after splitting and now we all try to
choose a condition that gives us the
highest gain we will do that by
splitting the data using each condition
and checking the gain that we get out of
them the conditions that give us the
highest gain will be used to make the
first split so let's take a look at
these different conditions we have color
we have diameter and if we look
underneath that we have a couple of
different values we have diameter equals
3 color equals yellow red diameter
equals 1 and when we look at that you'll
see over here we have one two three four
threes that's a pretty hearty selection
so let's say the condition gives us a
maximum gain of three so we have the
most pieces fall into that range so our
first split from our decision node as we
split the data based on the diameter is
it greater than or equal to three if
it's not that's false
it goes into the grape Bowl and if it's
true it goes into a bowl fold of lemon
and apples the entropy after splitting
has decreased considerably so now we can
make two decisions if you look at
they're very much
less chaos going on there this note has
already attained an entropy value of
zero as you can see there's only one
kind of label left for this branch so no
further splitting is required for this
node however this node on the right is
still requires a split to decrease the
entropy further so we split the right
node further based on color if you look
at this if I split it on color that
pretty much cuts it right down the
middle that's the only thing we have
left on our choices of color and
diameter - and if the color is yellow
it's going to go to the right bulb and
if it's false it's going to go to the
left bulb so the entropy in this case is
now zero so now we have three bowls with
zero entropy there's only one type of
data in each one of those bowls so we
can predict a lemon with a hundred
percent accuracy and we can predict the
apple also with the 100 percent accuracy
along with our grapes up there so we've
looked at kind of a basic tree in our
forest but what we really want to know
is how does a random forest work as a
whole so to begin our random forest
classifier let's say we already have
built three trees and we're going to
start with the first tree that looks
like this just like we did in the
example this tree looks at the diameter
if it's greater than or equal to three
it's true otherwise it's false so one
side goes to the smaller diameter one
side goes to larger diameter and if the
color is orange it's going to go to the
right true we're using oranges now
instead of lemons and if it's red it's
gonna go to the left false we build a
second tree very similar but it split
differently instead of the first one
being split by a diameter this one when
they created it if you look at that
first Bowl it has a lot of red objects
so it says is the color red because
that's going to bring our entropy down
the fastest and so of course if it's
true it goes to the left if it's false
it goes to the right and then it looks
at the shape false are true and so on
and so on and tree three is the diameter
equal to one and it came up with this
because there's a lot of cherries in
this bowl so that would be the biggest
split on there is the diameter equal to
one that's gonna drop the entropy the
quickest and as you can see it splits it
into true if it goes false and they've
added another category
does it grow in the summer and if it's
false it goes off to the left if it's
true it goes off to the right let's go
ahead and bring these three trees you
can see them all on one image so this
would be three completely different
trees categorizing a fruit and let's
take a fruit now let's try this and this
fruit if you look at it we've blackened
it out you can't see the color on it so
it's missing data remember one of the
things we talked about earlier is that a
random forest works really good if
you're missing data if you're missing
pieces so this fruit has an image but
maybe the person had a black and white
camera when they took the picture and
we're going to take a look at this and
it's gonna have they put the color in
there so ignore the color down there but
the diameter equals three we find out it
grows in the summer equals yes and the
shape is a circle and if you go to the
right you can look at what one of the
decision trees did this is the third one
is the diameter greater than equal to
three is a color orange well it doesn't
really know on this one but if you look
at the value it's a true and go to the
right tree two classifies it as cherries
is a color equal red is the shape a
circle
true it is a circle so this would look
at it and say oh that's a cherry and
then we go to the other classifier and
it says is the diameter equal one well
that's false
does it grow in the summer true so it
goes down and looks at as oranges so how
does this random forest work the first
one says it's an orange the second one
said it was a cherry and the third one
says it's an orange and you can guess if
you have two oranges and one says it's a
cherry when you add that all together
the majority of the vote says orange so
the answer is it's classified as an
orange even though we didn't know the
color and we're missing data on it I
don't know about you but I'm getting
tired of fruit so let's switch and I did
promise you we'd start looking at a case
example and get into some Python coding
today we're gonna use the case the iris
flower analysis ooh this is the exciting
part as we roll up our sleeves and
actually look at some Python coding
before we start the Python coding we
need to go ahead and create a problem
statement wonder what species of iris do
these flowers belong to let's try to
predict the species of the flowers using
machine learning
in Python let's see how it can be done
so here we begin to go ahead and
implement our Python code and you'll
find that the first half of our
implementation is all about organizing
and exploring the data coming in let's
go ahead and take this first step which
is loading the different modules into
python and let's go ahead and put that
in our favorite editor whatever your
favorite editor is in this case i'm
gonna be using the anaconda jupiter
notebook which is one of my favorites
certainly there's no pad plus plus and
eclipse and dozens of others are just
even using the python terminal window
any of those will work just fine to go
ahead and explore this python coding so
here we go let's go ahead and flip over
to our jupiter notebook and i've already
opened up a new page for python 3 code
and i'm just gonna paste this right in
there and let's take a look and see what
we're bringing in to our python the
first thing we're gonna do is from the
SK learned data sets import load iris
now this isn't the actual data this is
just the module that allows us to bring
in the data the load iris and the iris
is so popular it's been around since
1936 when Ronald Fisher published a
paper on it and they're measuring the
different parts of the flower and based
on those measurements predicting what
kind of flower it is and then if we're
gonna do a random forest classifier we
need to go ahead and import a random
forest classifier from the SK learning
module so SK learn dot ensembl import
random forest classifier and then we
want to bring in two more modules and
these are probably the most commonly
used modules in python and data science
with any of the other modules that we
bring in and one it's going to be panda
so we're gonna import pandas as peedee
peedee is a common term used for pandas
and pandas is basically creates a data
format for us where when you create a
panda's data frame it looks like an
Excel spreadsheet and you'll see that in
a minute when we start digging deeper
into the code panda is just wonderful
because it plays nice with all the other
modules in there and then we have numpy
which is our numbers python and the
numbers python allows us to do different
mathematical sets on here we'll see
right off the bat we're gonna
take our NP and we're gonna go ahead and
see the randomness with it with zero so
in P dot random seed is sitting at a
zero this code doesn't actually show
anything we're gonna go ahead and run it
because I need to make sure I have all
those loaded and then let's take a look
at the next module on here the next six
slides including this one are all about
exploring the data remember I told you
half of this is about looking at the
data and getting it all set so let's go
ahead and take this code right here the
script and let's get that over into our
jupiter notebook and here we go we've
gone ahead and run the imports and i'm
going to paste the code down here and
let's take a look and see what's going
on the first thing we're doing is we're
actually loading the iris data and if
you remember up here we loaded the
module that tells it how to get the iris
data now we're actually assigning that
data to the variable iris and then we're
gonna go ahead and use the DF to define
data frame and that's going to equal PD
and if you remember that's pandas as PD
so that's our pandas and panda data
frame and then we're looking at iris
data and columns equals Irish feature
names and we're gonna do the DF head and
let's run this you can understand what's
going on here
the first thing you want to notice is
that our DF has created what looks like
an Excel spreadsheet and in this excel
spreadsheet we have set the columns so
up on the top you can see the four
different columns and then we have the
data iris data down below it's a little
confusing without knowing where this
data is coming from so let's look at the
bigger picture and I'm gonna go print
I'm just gonna change this for a moment
and we're gonna print all of iris and
see what that looks like so when I print
all of Iris I get this long list of
information and you can scroll through
here and see all the different titles on
there what's important to notice is that
first off there's a brackets at the
beginning so this is a Python dictionary
and in a Python dictionary you'll have a
key or a label and this label pulls up
whatever information comes after it so
feature names which we actually used
over here under columns is equal to an
array of sepal length sepal width petal
length petal width these are the
different names they have for the four
different columns and if you scroll down
far enough you'll also see data down
here oh goodness it came up right
towards the top and data is equal to the
different data we're looking at
now there's a lot of other things in
here like Target we're gonna be pulling
that up in a minute and there's also the
names the target names which is further
down and we'll show you that also in a
minute let's go ahead and set that back
to the head and this is one of the neat
features of pandas and panda data frames
is when you do D F dot head or the Panda
data frame dot head it'll print the
first five lines of the data set in
there along with the headers if you have
up in this case we have the column
header set to iris features and in here
you'll see that we have 0 1 2 3 4 in
Python most arrays always start at 0 so
when you look at the first 5 it's going
to be 0 1 2 3 4 not 1 2 3 4 5 so now
we've got our iris data imported into a
data frame let's take a look at the next
piece of code in here and so in this
section here of the code we're gonna
take a look at the target and let's go
ahead and get this into our notebook
this piece of code so we can discuss it
a little bit more in detail so here we
are in our Jupiter notebook I'm gonna
put the code in here and before I run it
I want to look at a couple things going
on so we have DF species and this is
interesting because right here you'll
see where I have DF species in brackets
which is the key code for creating
another column and here we have iris dot
target now these are both in the pandas
setup on here
so in pandas we can do either one I
could have just as easily done iris and
then in brackets target depending on
what I'm working on both are acceptable
let's go ahead and run this code and see
how this changes and what we've done is
we've added the target from the iris
data set as another column on the end
now what species is this is what we're
trying to predict so we have our data
which tells us the answer for all these
different pieces and then we've added a
column with the answer that way when we
do our final setup we'll have the
ability to program our neural network to
look for these this different data and
know what asset OSA is or a Vera color
which we'll see in just a minute or
virginica those are the three that are
in there and now we're gonna add one
more column I know we're organizing all
this data over and over again it's kind
of fun there's a lot of ways to organize
it what's nice about putting everything
onto one data frame is I can then do a
printout and it shows me exactly what
I'm looking at and I'll show you that
where you where that's different where
you can alter that and do it slightly
differently but let's go ahead and put
this into our script up to Det now and
here we go we're going to put that down
here and we're gonna run that and let's
talk a little bit about what we're doing
now we're exploring data and one of the
challenges is knowing how good your
model is did your model work and to do
this we need to split the data and we
split it into two different parts they
usually call it the training and the
testing and so in here we're gonna go
ahead and put that in our database so
you can see it clearly and we've set it
DF and remember you can put brackets
this is creating another column is
trained so we're gonna use part of it
for training and this equals NP remember
that stands for numpy dot random dot
uniform so we're generating a random
number between 0 and 1 and we're gonna
do it for each of the rows that's where
the length DF comes from so each row
gets a generated number and if it's less
than 0.75 it's true and if it's greater
than 0.75 its false this means we're
gonna take 75% of the data roughly
exists there's a randomness involved and
we're gonna use that to Train it and
then the other 25% we're gonna hold off
to the side and use that to test it
later on so let's flip back out over and
see what the next step is so now that
we've labeled our database four which is
training and which is testing let's go
ahead and sort that into two different
variables train and test and let's take
this code and let's bring it into our
here we go it's pasted it on down here
and before I run this let's just take a
quick look what's going on here is we
have up above we created remember
there's our deaf head which prints the
first five rows and we've added a column
is trained at the end and so we're gonna
take that we're gonna create two
variables we're gonna create two new
data frames ones called train ones
called test 75% and train 25% and test
and then to sort that out
we're gonna do that by doing DF our main
original data frame with the iris data
in it and if DF is trained equals true
that's going to go in the Train and if
DF is trained equals false it goes in
the test and so when I run this we're
gonna print out the number in each one
let's see what that looks like and
you'll see that it puts a hundred and
eighteen in the training module and it
puts 32 in the testing module which lets
us know that there was a hundred and
fifty lines of data in here so if you
went and looked at the original data you
could see that there's 150 lines and
that's roughly 75% in one and 25% for us
to test our model on afterward so let's
jump back to our code and see where this
goes
in the next two steps we want to do one
more thing with our data and that's make
it readable to humans I don't know about
you but I hate looking at zeros and ones
so let's start with the features and
let's go ahead and take those and make
those readable to humans and let's put
that in our code
let's see here we go paste it in and
you'll see here we've done a couple very
basic things we know that the columns in
our data frame again this is a pan to
think the DF columns and we know the
first four of them 0 1 2 3 and B the
first four are going to be the features
or the titles of those columns and so
when I run this you'll see down here
that it creates an index SEPA length
sepal width petal length and petal width
and this should be familiar because if
you look up here here's our column
titles going across and here's the first
for one thing I want you to notice here
is that when you're in a command line
well there's jupiter notebook or you're
running command line in the terminal
window if you just put the name of it
it'll print it out this is the same as
doing print
features and the shorthand is you just
put features in here if you're actually
writing a code and saving the script and
running it by remote you really need to
put the print in there but for this and
when I run it you'll see it gives me the
same thing
for this we want to go ahead and we'll
just leave it as features because it
doesn't really matter and this is one of
the fun thing about Jupiter notebooks is
I'm just building the code as we go and
then we need to go ahead and create the
labels for the other part so let's take
a look and see what that for our final
step in prepping our data before we
actually start running the training and
testing is we're going to go ahead and
convert the species on here into
something the computer understands so
let's put this code into our script and
see where that takes us
all right here we go we've set y equal
to PD dot factorize train species of
zero so let's break this down just a
little bit we have our pandas right here
PD factorize what's this factory is
doing I'm gonna come back to that in
just a second let's look at what train
species is and why we're looking at the
group zero on there and let's go up here
and here is our species remember this on
that we created this whole column here
for species and then it has Sat OSIS a
ptosis a ptosis atossa and if you scroll
down enough you'd also see virginica and
varrick color we need to convert that
into something the computer understands
zeros and ones so the train species of
zero because this is in the format of an
array of arrays so you have to have the
zero on the end and then species is just
that column factor rise goes in there
looks at the fact that there's only
three of them so when I run this you'll
see that Y generates an array that's
equal to in this case it's a training
set and it's zeros ones and twos
representing the three different kinds
of flowers we have so now we have
something the computer understands and
we have a nice table that we can read
and understand and now finally we get to
actually start doing the predicting so
here we go we have two lines of code oh
my goodness that was a lot of work to
get to two lines of code but there is a
lot in these two lines of code so let's
take a look and see what's going on here
and put this into our full script that
we're running and let's paste this in
here and let's take a look and see what
this is we have we're creating a
variable CLF and we're going to set this
equal to the random forest classifier
and we're passing two variables in here
and there's a lot of variables you can
play with as far as these two are
concerned they're very standard in jobs
all that does is to prioritize it not
something to really worry about usually
when you're doing this on your own
computer you do in jobs equals two if
you're working in a larger or big data
and you need to prioritize it
differently this is what that number
does is it changes your priorities and
how it's
run across the system and things like
that and then the random state is just
how it starts zeros fine for here
but let's go ahead and run this
we also have CL f dot fit train features
comma Y and before we run it let's talk
about this a little bit more CL f dot
fit so we're fitting we're training it
we are actually creating our random
forest classifier right here this is the
code that does everything and we're
going to take our training set remember
we kept our tests off to the side and
we're going to take our training set
with the features and then we're going
to go ahead and put that in and here's
our target the Y so the Y is zero one
and two that we just created and the
features is the actual data going in
then we put into the training set let's
go ahead and run that
and this is kind of an interesting thing
because it printed out the random forest
classifier and everything around it and
so when you're running this in your
terminal window on a script like this
this automatically treats this like just
like we we're up here and I typed in Y
and it printed out Y instead of print Y
this does the same thing it treats this
as a variable and prints it out but if
you were actually running your code that
wouldn't be the case and what is printed
out is it shows us all the different
variables we can change and if we go
down here you can actually see in jobs
equals two you can see the random State
equals zero those are the two that we
sent in there you would really have to
dig deep to find out all these different
meanings of all these different settings
on here some of them are self
explanatory if you kind of think about
it a little bit like max features is
Auto so all the features that we're
putting in there is just gonna
automatically take all four of them
whatever we send it it'll take some of
them might have so many features because
you're processing words there might be
like 1.4 million features in there
because you're doing legal documents and
that's how many different words are in
there at that point you probably want to
limit the maximum features that you're
gonna process in leaf nodes that's the
end notes remember we had the fruit and
we're talking about the leaf nodes like
I said there's a lot in this we're
looking at a lot of stuff here
so you might have in this case there's
probably only think three leaf nodes
maybe four you might have thousands of
leaf nodes at which point you do need to
put a cap on that and say okay it only
goes so far and then we're gonna use all
of our resources on processing this and
that really is what most of these are
about is limiting the process and making
sure we don't overwhelm a system and
there's some other settings in here
again we're not gonna go over all of
them warm start equals false warm start
is if you're programming it one piece at
a time externally since we're not we're
not gonna have like we're not gonna
continually to train this particular
learning tree and again like I said
there's a lot of things in here that
you'll want to look up more detail from
the SK learn and if you're digging in
deep and running a major project on here
for today though all we need to do is
fit or train our features and our target
Y so now we have our training model
what's next if we're going to create a
model
we now need to test it remember we set
aside the test feature test group 25% of
the data so let's go ahead and take this
code and let's put it into our script
and see what that looks like here we go
and we're going to run this
and it's going to come out with a bunch
of zeros ones and twos which represents
the three type of flowers
thus atossa the virginica and the verse
of color and what we're putting into our
predict is the test features and I
always kind of like to know what it is I
am looking at so real quick we're going
to do test features remember features is
an array
of sepal length sepal width petal length
petal width so when we put it in this
way it actually loads all these
different columns that we load it into
features so if we did just features let
me just do features in here things what
features looks like this is just playing
with the with pandas dataframes
you'll see that it's an index so when
you put an index in like this
into test features into test it then
takes those columns and creates a panda
data frames from those columns and in
this case we're going to go ahead and
put those into our predict so we're
gonna put each one of these lines of
data the 5.0 3.4 1.5.2 and we're gonna
put those in and we're going to predict
what our new forest classifier is going
to come up with and this is what it
predicts it predicts 0 0 0 1 2 1 1 2 2 2
and and again this is the flower type so
Tosa virginica and versicolor so now
that we've taken our test features let's
explore that let's see exactly what that
data means to us so the first thing we
can do with our predicts is we can
actually generate a different prediction
model when I say different we're going
to view it differently it's not that the
data itself is different so let's take
this next piece of code and put it into
our script
so we're pasting it in here and you'll
see that we're doing predict and we've
added underscore proba for probability
so there's our CLI F dot predict
probability so we're running it just
like we ran it up here but this time
with this we're gonna get a slightly
different result and we're only gonna
look at the first 10 so you'll see down
here instead of looking at all of them
which was what 27 you'll see right down
here or that this generates a much
larger field on the probability and
let's take a look and see what that
looks like
and what that means so when we do the
predict underscore prabha for
probability it generates three numbers
so we had three leaf nodes at the end
and if you remember from all the theory
we did this is the predictors the first
one is predicting a 1/4 so Tosa
it predicts a 0 for virginica and it
predicts a 0 for versicolor and so on
and so on and so on and let's you know
what I'm gonna change this just a little
bit let's look at 10 to 20 just because
we can
and we start to get a little different
of data and you'll see right down here
it gets to this one this line right here
and this line has zero zero point five
zero point five and so if we're gonna
vote and we have two equal votes it's
gonna go with the first one
so it says Soto so get zero votes
virginica gets point five votes
versicolor gets point five votes but
let's just go with the virginica since
these two are equal and so on and so on
down the list you can see how they vary
on here so now we've looked at both how
to do a basic predict of the features
and we've looked at the predict
probability let's see what's next on
here so now we want to go ahead and
start mapping names for the plants we
want to attach names so that it makes a
little more sense for us and this we're
gonna do in these next two steps we're
gonna start by setting up our
predictions and mapping them to the name
so let's see what that looks like and
let's go ahead and paste that code in
here and run it and this goes along with
the next piece of code so we'll skip
through this quickly and then come back
to it a little bit
so here's iris dot target names
and we if you remember correctly this
was the the names that we've been
talking about this whole time this
atossa of virginica versicolor and then
we're going to go ahead and do the
prediction again we've run that we could
have just set a variable equal to this
instead of rerunning at each time but
we're going ahead and run it again CLF
predict test features remember that
returns the zeros the ones in the twos
and then we're going to set that equal
to predictions so this time we're
actually putting it in a variable and
when I run this it distributes and it
comes out as an array and the array is
so ptosis or ptosis a ptosis a ptosis
atossa
we're only looking at the first five we
could actually do let's do the first 25
just so we can see a little bit more on
there and you'll see that it starts
mapping it to all the different flower
types the versicolor and the virginica
in there and let's see how this goes
with the next one so let's take a look
at the top part of our species in here
and we'll take this code and put it in
our script and let's put that down here
and paste it there we go and we'll go
ahead and run it and let's talk about
both these sections of code here and how
they go together the first one is our
predictions and I went ahead and did
predictions through 25 let's just do
five
and so we have cytosis a ptosis a ptosis
atossa that's what we're predicting from
our test model and then we come down
here and we look at test species I
remember I could have just done test
species dot head and you'll see it says
so ptosis Atossa so ptosis Atossa and
they match so the first one is what our
forest is doing and the second one is
what the actual data is now is we need
to combine these so that we can
understand what that means we need to
know how good our forest is how good it
is at predicting the features so that's
where we come up to the next step which
is lots of fun we're gonna use a single
line of code to combine our predictions
and our actuals so we have a nice chart
to look at and let's go ahead and put
that in our script and our jupiter
notebook here let's see what's go ahead
and paste that in and then I'm gonna
because I'm on the Jupiter notebook I
can do a control - you can see the whole
line there
there we go resize it and let's take a
look and see what's going on here we're
gonna create in pandas member PD stands
for pandas and we're doing a crosstab
this function takes two sets of data and
creates a chart out of them so when I
run it you'll get a nice chart down here
and we have the predicted species so
across the top you'll see this Atossa
versicolor virginica and the actual
species
it says Tosa versicolor virginica and so
the way to read this chart and let's go
ahead and take a look on how to read
this chart here when you read this chart
you have sat osa where they meet you
have versicolor where they meet and you
have virginica where they meet and
they're meeting where the actual and the
predicted agree so this is the number of
accurate predictions so in this case it
equals 30 if you add 13 plus 5 plus 12
you get 30 and then we notice here where
it says virginica but it was supposed to
be versicolor this is inaccurate so now
we have to to inaccurate predictions and
30 accurate predictions so we'll say
that the model accuracy is 93 that's
just 30 divided by 32 and if we multiply
it by a hundred we can say that it is
ninety-three percent accurate so we have
a 93 percent accuracy with our model I
did want to add one more quick thing in
here on our scripting before we wrap it
up so let's flip back on over to my
script in here we're gonna take this
line of code from up above I don't know
if you remember it but predicts equals
the iris dot target underscore names so
we're gonna map it to the names and
we're gonna run the prediction and we
read it on test features but you know
we're not just testing it we want to
actually deploy it so at this point I
would go ahead and change this and this
is an array of arrays this is really
important when you're running these to
know that so you need the double
brackets and I could actually create
data maybe let's just just do two
flowers so maybe I'm processing more
data coming in and we'll put two flowers
in here and then I actually want to see
what the answer is so let's go ahead and
type in Preds and print that out and
when I run this you'll see that I've now
predicted two flower
maybe I majored in my front yard as
versicolor and versicolor
not surprising since they put the same
data in for each one this would be the
actual end product going out to be used
on data that you don't know the answer
for
so that's going to conclude our
scripting part of this and let's just go
ahead and take a look at the key
takeaways with today's tutorial we have
solutions under classification so we
looked at where the random forest fits
in in the bigger model as far as
supervised learning and part of the
machine learning class and in this case
it's in classification and why a random
forest the three main points has very
little overfitting if any it has a high
accuracy and in my opinion one of the
most powerful tools is it estimates
missing data we saw that with the
missing color of the fruit we talked
about what is a random forest versus a
tree and then we went into how does a
decision tree work how does a random
forest work we put all those trees
together and then we took a look at some
basic Python coding in the iris example
that brings us to our conclusion and I'd
like to thank you for joining us for
more information you can visit WWMT
learn calm you can also click below to
ask more questions through the YouTube
interface hi there if you like this
video subscribe to the simply learn
youtube channel and click here to watch
similar videos turner up and get
certified click here</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>