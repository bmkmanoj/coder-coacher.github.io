<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Cloudlab Tutorial | Cloudlab Hadoop | Big Data Hadoop Certification Training | Simplilearn | Coder Coacher - Coaching Coders</title><meta content="Cloudlab Tutorial | Cloudlab Hadoop | Big Data Hadoop Certification Training | Simplilearn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Simplilearn/">Simplilearn</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Cloudlab Tutorial | Cloudlab Hadoop | Big Data Hadoop Certification Training | Simplilearn</b></h2><h5 class="post__date">2016-06-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FS4Pwf8iSq0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">have you been spending more time setting
up big data infrastructure and
environment instead of focusing on
learning now imagine yourself in a world
where you face installation and
compatibility issues difficulties in
configuring systems problems of rights
and permissions network slowdown or
failures have to download huge datasets
sounds like the Stone Age don't worry we
got you covered for you we introduced
cloud lab with cloud lab you can focus
on practicing the concepts you learned
in an already setup secure environment
it comes pre-installed with big data
components such as big hive scoop and
more which means you don't have to spend
time downloading and installing them or
have to worry about configuration or
compatibility issues you can access
cloud lab from your browser at any time
24 by 7 so all you need is an internet
connection and you are good to go simply
learn offers access to cloud lab for all
your projects and practice so you can
experience hassle-free advanced learning
so curious to know how to get started
with cloud labs it's really simple let's
show you how to login and navigate you
can go to simply learn dot-com page you
need to login to simply learn LMS using
login option on simply learn page on
login page enter your simply learn LMS
login ID and password once you log in
click on my courses and select bdh
developer course from the list of
courses scroll down on the bdh developer
course page and click on the lab access
tab once you click your cloud lab
account with login ID and password
details will automatically be created
now you will be able to access a unique
login ID which you will use to access
cloud lab below the login ID you will be
able to view the
access password to login to cloud lab
you can use hide and show option with
password tab it also provides you an
option of copying a password to
clipboard below the password details you
will see three console tabs of cloud lab
Ambari Hue web console if you click on
amber
it opens up a separate tab where you can
sign in using the same login and
password details as on the LMS
you
let me now show you how to use hew
following the same procedure as before
use the login credentials from the LMS
and you are in
you
now if you want to use the web console
click on web console in the LMS page and
enter the same login details
you
now let's look at how to work on Pig
shall we to use pig in cloud lab as we
saw before login to Hugh with your
auto-generated ID and password and click
Sign In go to file browser and click
upload and choose the data file to
upload to HDFS select pick tool from the
drop down menu of query editor the pig
editor is divided into three segments
menu code editor and inbuilt syntax
since you are already logged in cloud
lab to use hive upload the data set in
HDFS and select the hive tool from drop
down menu of query editor the first part
is the database panel on the Left which
contains information on databases and
tables the next important part of this
screen is the query editor at the top
Center where the query is written and
executed the next part in this hive
screen is the execution window at the
bottom here the result of the executed
query is displayed in the results tab
similar to pig and hive for HBase select
the HBase tool from drop down menu of
data browser HBase is no sequel language
in GUI you can create tables and upload
the bulk data set or you can add the
data manually click new table and a
create new table window opens here you
can give a name to your table and column
family
you can also add a column property or an
extra column family if required click
Submit it can be viewed on the window
with value similar to the existing
tables seen here you can execute the
query using the terminal or web console
log in with your credentials and the
command given here is just to perform a
health check to ensure that HBase is
running smoothly however you need to go
inside the HBase shell to perform the
HBase commands terminal is the most
power
we'll tool providing a command-line
interface to the underpinnings of OS in
Big Data and Hadoop course most of the
tools like MapReduce hive HBase
zookeeper scoop and others the terminal
will be used here I'm using a few
examples to show you how that can be
done now that you know all about the
cloud lab remember the most essential
fact about it it's just a click away
from you so what are you waiting for
just log on to cloud lab and practice
your way to expertise</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>