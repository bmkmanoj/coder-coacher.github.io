<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AWS Best Practices | AWS Tutorial For Beginners | Simplilearn | Coder Coacher - Coaching Coders</title><meta content="AWS Best Practices | AWS Tutorial For Beginners | Simplilearn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Simplilearn/">Simplilearn</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AWS Best Practices | AWS Tutorial For Beginners | Simplilearn</b></h2><h5 class="post__date">2017-09-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BCjJQgScL3Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone in today's session we are
going to talk about AWS best practices
so this is the agenda for today we will
talk about billing best practices we
will have a look at best practices for
ec2 which is the Amazon Elastic computer
cloud we will walk through best
practices for I am which is Identity and
Access Management then we will walk
through the best practices for s3 which
is simple storage service and then we
will have a general look at the security
best practices from the Amazon account
perspective as well as from the general
Amazon Web Services perspective now
let's start with billing best practices
so billing essentially is the core of
every company every company wants to
keep billing to the minimum and cost to
the lower side so one of the best things
about Amazon is that it gives you a good
way of controlling your costs so from
the billing specific side from the
billing console side there are a lot of
things you can do as a best practice and
also reduce cost so Amazon gives you
something called billing budgets now
this is interesting so they give you an
option to actually create a budget kind
of thing wherein you specify you want X
amount of dollars for the next budget
now whenever you hit that budget let's
say it's $200 you get an email
notification now these budgets can be
service specific they can be specific to
some service like ec2 so if you want to
have a billing alert when the ec2
instances of the account hit almost $200
you can create that one of the other
best practices from Amazon billing side
is to give limited access to I am
account users to billing so by default
Amazon does not allow billing access to
I am users but you can specifically
allow them if you have got some users
who look at the billing perspective of
your account now if you have a bill
which crosses ten to fifteen dollars and
it's not possible to pay using a single
credit card or debit card Amazon gives
you an option to pay using multiple
credit cards so as a best practice if
your bill has crossed a big amount and
you are not able to pay use
single credit card if you are good
enterprise it's always good to have two
or three credit cards added to your
account so that even in the case when
your one card can't fulfill the bill you
can have another account which
automatically lets you pay the bill so
that way you don't risk your
infrastructure your infrastructure is
always safe now one of the other best
practices is to have regional taxation
enabled in your account for every
country there's a different taxation
regime and the tax methodology and tax
rates are different so instead of
getting a notice from your income tax
department or to avoid being
non-compliant to taxes it's the best
practice to have the billing number so
every country has the specific unique
billing number which you can put into
the Amazon account and then it
automatically charges that or files
taxes from Amazon's behalf on that
number so at the end of the year when
you are doing tax filing you can easily
show that you have paid X amount of
money from Amazon so you don't have to
repay that or if in your country the tax
is collected at the end of the year in a
consolidated way you are more compliant
now let's say that an enterprise which
has got multiple accounts and Amazon Web
Services so let's say for project a you
have a different account for project B
you have a different account so you can
consolidate the billing of those if you
don't want to have a headache of having
multiple account billing you don't want
to have two separate credit cards for
every account so what you can do is you
can consolidate the billing of each and
every account into a single account that
would essentially give you a single
consolidated bill so you can also
consolidate your taxes there in that
case you can have a single cooperate
credit card which can have a lot of
limit their credit cards which give you
no limit virtually so you can use those
kind of credit cards now coming to ec2
best practices one of the best practices
from ec2 side is ami hardening so Amazon
gives you Amazon machine images which
are exact map shots of servers now these
machine images are used to spin up new
machines so these are like seat files
for new servers now you just can't have
a stock OS image and use that as a base
for your entire
infrastructure you need to have a
hardened ami now when I say a hardened
ami what I exactly mean is to have an
ami which has got all the security
practices implemented into it now as far
as the Linux OS is concerned an ami
which is hardened would have the SSH
port changed SSH password based logins
disabled security enhanced Linux set to
enabled if it's CentOS if it's Ubuntu
maybe you can enable the firewall and
only allow port 22 the next thing is V
PC port lockdown so apart from the
instant level firewall port lockdown you
should also lock down ports specifically
to IP addresses if not possible to IP
addresses then at least you should make
sure that in your V PC all the security
groups have got only the specific ports
which are required by that server or
application open to specific IP
addresses if you have to open something
up to the entire world make sure that
you have got adequate checks PPP inside
your application so you don't have a
malware user trying to do DDoS service
attack although Amazon has got a
required hardware in place to check the
DDoS attack but yes there can be still
valid amounts of attacks that go into
your application if you don't plan the
application correctly one of the other
things you should take care when you are
running instances on ec2 is that you
have private subnets for everything
other than the load balancer or the web
application tier now this is important
because you don't want anyone to be
directly able to access your rediff CCC
your database or your internal back-end
systems because most of these systems
for example let's say rediff don't have
authentication built into them so if you
have the port exposed anyone can go in
and pull all the keys now from an
application division perspective you
should make sure that the application is
divided into small micro services so it
used to be known as service-oriented
architecture SOA now the term has
changed and people call it micro service
architecture so the basic idea behind
micro service architecture is that big
monolith
applications are divided into small
chunks of application which are exposed
over as a service to the Internet to the
end users now this helps you to scale
them individually and one of the best
advantages you get out of such a micro
service architecture is that even if one
of the applications is down the others
can actually still function without
affecting this one now this is very
important because in today's ecommerce
world a single minute of downtime can
cost millions of dollars of loss so when
you have micro service architecture you
can scale vertically or horizontally
each micro service without worrying
about downtime you should take care
while designing micro service
architecture so that the micro service
architecture is independent at every
level one of the mistakes which happens
is that you have a micro service
architecture at the web server or the
application server layer but then you
have a common database so how is it
going to affect the micro service
architecture in any way I understand
that it's very difficult to have
independent database micro service
architecture but yes there are companies
who do sync ups of databases just to
make sure they have totally independent
micro services now in such a scenario
even if the back-end database of a
particular micro service is down the
other functionality can work take an
example let's say there is login
functionality which talks to the
back-end database and gets two data from
there let's say there is another
functionality which lets you buy stuff
both of them should have independent
databases and there should be a sync up
every minute or there should be pushed
based mechanism where there's sync up
only when they're in one of the DBS now
if you have both these micro services
having independent databases your logins
will still work even if your payments
are down or your payment's will still
work if your login functionality is
experiencing some degraded performance
you have stock images on Amazon that
Amazon provides you environment based
key or keys which are there for every
instance so every machine you launch on
Amazon has got a key you can't just use
the username and password to log in now
the advantage of key is that you don't
have to
provide clear text passwords but you
have to make sure that for every
environment so let's say you got a
production environment QA test
environment make sure every environment
has got a different key the reason is if
you have a single key across all the
environments and let's say you give a
developer access to one of the
environments you can automatically gain
access to each and every environment so
that's not a good thing right you don't
want developers to access production
environments now if you have 100 ec2
instances and you have users to manage
let's say you should make 10 users are
there on every machine which are 10
members of your dev team so it's very
difficult to create manually let's say
you also want to do password expiry and
a lot of intelligence stuff on these
users you can actually use something
called LDAP this LDAP is basically
centralized authentication system which
lets you authenticate users across
machines so you can change the password
for a user on one LDAP server and it's
reflected across all the machines so
let's have a look at I am best practices
so I am is Identity and Access
Management service of Amazon and it
allows you to have fine game controls
over the Access now as a best practice
for your teams you should have various
roles to find each of those roles should
be specific to what each member is doing
let's say you have a read-only dev role
assigned to your developers you can also
have dev ops engineer role which you
assign to your dev ops engineering team
members you can assign roles to the
finance team which has billing access
now this gives you the flexibility to
easily assign policies or attach
policies to various users without having
to manually do them this is useful in a
scenario where and you have a custom
role wherein you have a reporting
engineer which needs access to billing
to create reports of CPU utilization now
you can give them a specific access by
assigning specific policies you can have
new joinee Zoar freshers who have joined
your team have a read-only access so
that way they don't mess up the account
and they also have got full
access to the account so they can go and
they can see what the environments like
they can read but they can't change
anything so that way you safeguard your
account by any accidental mistakes by
those freshers or new join E's you can
have service specific access so let's
say you have an ec2 instance which
requires access to s3 buckets so you
actually create a role in I am and
assign that specific role to ec2
instances you can also have special
service specific roles now these service
specific roles have got access to
specific service of Amazon and you can
use this let's say in case you want to
give some developer access to some dev
environment of elastic beanstalk so you
can create a role which has the access
and the policies attached for elastic
Beanstalk read-only access to that
specific region so that way you can
control a specific service and specific
action now let's have a look at s3 best
practices s3 is simple storage service
and it's one of Amazon's most important
services it's one of the most used
services as well now in case of s3 you
should make sure that you have context
specific names now these names can be
the type of function that s3 bucket is
performing so let's say images and then
type in dev and then - region and then -
top-level domain so you have a unique
name so Amazon has a policy wherein they
have a single namespace for all the s3
buckets of the world which in other
words means that if you have a name
which is already chosen by someone in
the world of an s3 bucket you will not
get that name so obviously you will have
to have long names since all shorter
names would have been taken in order to
make that long name meaningful make sure
you break that into a specific context
so that when you look at that bucket you
already know this is what this bucket is
doing you should make sure you have
bucket policies for buckets which are
accessible by other users these policies
can be generated in the policy generator
or
you can create fine-grained self-made
policies for buckets which are very much
live and large and have got tons of data
you should archive them to glacier
because glacier gives you very cheap
storage although there is a retrieval
time associated with that but yes you
should make sure to archive the buckets
so if you've got some critical objects
in a bucket you should make sure that
you also save a version of your object
because you can go back to a previous
version of that same object now in this
case you don't actually lose any version
of that file you always have the
important version of that object from
security best practices never share your
root account details with anyone because
if someone has got root account details
of your account you can actually do
anything make sure people who leave your
organization you remove their access and
you don't keep them as stale accounts
you should also enable two-factor
authentication either with Google
Authenticator or some hardware device
access token which flashes a six or
four-digit random number so that it can
be added as an added layer of security
you also should enable iam login don't
give root access to even trusted users
so in iam you have a name and an ID
which shows you that this guy did this
at this time
hey once become an expert in cloud
computing then subscribe to simpler
Channel and click here to watch more
such videos turn it up and get certified
in cloud computing click here</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>