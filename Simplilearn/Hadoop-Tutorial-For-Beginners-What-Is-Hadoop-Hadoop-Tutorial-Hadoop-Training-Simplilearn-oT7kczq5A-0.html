<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Hadoop Tutorial For Beginners | What Is Hadoop? | Hadoop Tutorial | Hadoop Training | Simplilearn | Coder Coacher - Coaching Coders</title><meta content="Hadoop Tutorial For Beginners | What Is Hadoop? | Hadoop Tutorial | Hadoop Training | Simplilearn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Simplilearn/">Simplilearn</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Hadoop Tutorial For Beginners | What Is Hadoop? | Hadoop Tutorial | Hadoop Training | Simplilearn</b></h2><h5 class="post__date">2017-10-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oT7kczq5A-0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Hadoop helps to leverage the
opportunities provided by big data and
overcome the challenges it poses Hadoop
is an open source java based programming
framework that supports the processing
of large datasets in a distributed
computing environment it is based on
Google file system or GFS Hadoop runs a
number of applications on distributed
systems with thousands of nodes
involving petabytes of data it has a
distributed file system called Hadoop
distributed file system or HDFS which
enables fast data transfer among the
nodes further it leverages a distributed
computation framework called MapReduce
let us look at the difference between
Hadoop and traditional RDBMS in the next
screen by now there might be a question
that if there is so much of data then
why can't we just use traditional RDBMS
to address the question we will put
across the difference between the two
our DBMS systems process the data in the
form of transactions and concurrency
control ensures that data integrity is
not compromised at the time of data
processing in our DBMS the schema and
structure of the tables are predefined
before inserting the data and is
excellent when read and write are needed
to be performed our DBMS work on
expensive servers and failures are rare
in case of a failure the recovery
mechanisms are available in Hadoop the
system processes the data in the form of
jobs there is no concurrency control and
no predefined structure of database the
primary or unique keys can be identified
and modified at the time of
securing the MapReduce functions Hadoop
systems are good only when one has to
write once and read multiple times it
can be run on cheap commodity hardware
failures are common but fault tolerance
due to rack involvement is very high in
the next screen we will look into the
history and milestones in Hadoop Hadoop
originated from the nudge open source
project on search engines and works over
distributed network nodes in 2003 and
2004 Google released two papers that
provided insight into their success the
Google file system or GFS and MapReduce
simplified data processing on large
clusters the papers told the world how
Google performs large-scale data
processing in July 2005 nuts used GFS to
perform MapReduce operations in February
2006 nuch started a leucine sub project
which led to the era of Hadoop in April
2007 Yahoo started using Hadoop on a
thousand node cluster in January 2008
Apache took over Hadoop and made it a
top-level project in July 2008 a 4,000
node cluster with Hadoop was tested by
Apache the performance of that cluster
was surprisingly the fastest when
compared to the other technologies
implemented that year in May 2009 a test
revealed that Hadoop successfully sorted
a petabyte of data in 17 hours Hadoop
reached version 1.0 in December 2011 it
is completely open source and written in
Java in the next screen we will discuss
Hadoop core services and components
major components of Hadoop are Hadoop
distributed file system HDFS runs on
commodity machines
Charlo in cost hardware it is highly
fault tolerant and efficient enough to
process huge amount of data name node is
the brain of the system it stores the
metadata of the data blocks along with
location of data blocks if this name
node crashes the entire system is dead
secondary name node is the replica of
primary name node this is used to ensure
that even if the primary name node
crashes Hadoop system is not dead but
namespace image on secondary name node
can be used to restart the system data
node stores the blocks of data job
tracker scheduled client jobs and
creates map or reduced tasks and
schedules them it can run on the same
machine as name node or different node
tasktracker runs on data nodes its
primary responsibility is to run
MapReduce tasks assigned by the name
node in the next screen we will look
into Hadoop distributed file system
architecture architecture of Hadoop is
made of master and slave concept the
name node is the master and data nodes
are the slaves name node is the brain of
the system and is accessing client data
data nodes manage the storage of data
the data is split into files of one or
more blocks when a client needs a data
it first interacts with name node that
holds the metadata and replies back to
client with location of the data on data
nodes after this client starts
interaction with data node till the time
data requirement is completed let us
look into major organizations using
Hadoop in the next screen for reference
we have listed down details of a few
organizations that use Hadoop along with
the usage needs Amazon uses Hadoop to
perform next to real-time analysis
to offer its customers data-driven
products most of the support research
work like web search in Yahoo is done in
Hadoop AOL uses big data analytics to
perform sentiment analysis to understand
customer behavior one of the Hadoop
algorithms in Facebook is supposed to
analyze photos videos or forums to avoid
any obscene material Hey want to become
an expert in Big Data then subscribe to
the simply learned Channel and click
here to watch more such videos to nerd
up and get certified in Big Data click
here</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>