<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning Spark Tutorial|GraphX Spark Tutorial | Machine Learning Tutorial|Simplilearn | Coder Coacher - Coaching Coders</title><meta content="Machine Learning Spark Tutorial|GraphX Spark Tutorial | Machine Learning Tutorial|Simplilearn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Simplilearn/">Simplilearn</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning Spark Tutorial|GraphX Spark Tutorial | Machine Learning Tutorial|Simplilearn</b></h2><h5 class="post__date">2017-08-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/aL9c_mZpqx8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">today big graphs exist in various
important applications be it web
advertising or social networks examples
of a few such graphs are presented on
the screen
these graphs allow the user to perform
tasks such as target advertising
identify communities and decipher the
meaning of documents this is possible by
modeling the relations between products
users and ideas as the size and
significance of graph data is growing
various new large-scale distributed
graph parallel frameworks such as
GraphLab giraffe and power graph have
been developed with each framework a new
programming abstraction is available
these abstractions allow the users to
explain graph algorithms in a compact
manner they also explain the related
runtime engine that can execute these
algorithms efficiently on distributed
and multi-core systems additionally
these frameworks abstract the issues of
the large-scale distributed system
design therefore they are capable of
simplifying the design application and
implementation of the new sophisticated
graph algorithms to large scale
real-world graph problems let's look at
a few limitations of the graph parallel
system firstly although the current
graph parallel system frameworks have
various common properties each of them
presents different graph computations
these computations are custom-made for a
specific graph applications and
algorithms family or the original domain
secondly all these frameworks depend on
different runtime therefore it is tricky
to create these programming abstractions
and fine
these frameworks cannot resolve the data
extract transform load or ETL issues and
issues related to the process of
deciphering and applying the computation
results the new graph parallel system
frameworks however have built-in support
available for interactive graph
computation next you will learn about
graphics but before that there is a
quick pop quiz for you graphics is a
graph computation system running in the
framework of the data parallel system
which focuses on distributing the data
across different nodes that operate on
the data in parallel it addresses the
limitations posed by the graph parallel
system graphics is more of a real-time
processing framework for the data that
can be represented in a graph form
graphics extends the resilient
distributed data set or RDD abstraction
and hence introduces a new feature
called resilient distributed graph or
RDG in addition it simplifies the graph
ETL and analysis process substantially
by providing new operations for viewing
filtering and transforming graphs
graphics combines the benefits of graph
parallel and data parallel systems as it
efficiently expresses graph computations
within the framework of the data
parallel system graphics distributes
graphs efficiently as tabular data
structures by leveraging new ideas in
their representations it uses in-memory
computation and fault tolerance by
leveraging the improvements of the data
flow systems graphics also simplifies
the graph construction and
transformation process by providing
powerful new operations with the use of
these features you can see that spark is
well suited for graph parallel algorithm
in the next topic let's look at machine
learning which explores the study and
construction of algorithms that can
learn from and make predictions on data
this is the third topic of the lesson
in the previous topic you were
introduced to the graph parallel system
in this topic you will learn about
machine learning it's applications and
standard machine learning clustering
algorithms like k-means let's first
understand what machine learning is it
is a subfield of artificial intelligence
that has empowered various smart
applications it deals with the
construction and study of systems that
can learn from data for instance machine
learning can be used in medical
diagnosis to answer a question such as
is this cancer it can learn from data
and help diagnose a patient as a
sufferer or not
another example is fraud detection where
machine learning can learn from data and
provide an answer to a question such as
is this credit card transaction
fraudulent therefore the objective of
machine learning is to let a computer
predict something an obvious scenario is
to predict an event in future apart from
this it can also predict unknown things
or events this means that something that
has not been programmed or inputted into
it in other words computers act without
being explicitly programmed machine
learning can be seen as building blocks
to make computers behave more
intelligently in 1959 Arthur Samuel
defined machine learning as a field of
study that gives computers the ability
to learn without being explicitly
programmed later in 1997 Tom Mitchell
gave another definition that proved more
useful for engineering purposes a
machine learning computer program is
said to learn from experience II with
respect to some class of tasks T and
performance measure P if its performance
at tasks in T as measured by P improves
with experience II as data plays a big
part in machine learning it's important
to understand and use the right
terminology when talking about data this
will help you to understand machine
learning algorithms in general
let's begin with vector feature it is an
n-dimensional vector of numerical
features that represent some object it
is a typical setting which is provided
by objects or data points collection
each item in this collection is
described by a number of features such
as categorical and continuous features
samples are the items to process
examples include a row in a database a
picture or a document feature space
refers to the collections of features
that are used to characterize your data
in other words feature space refers to
the N dimensions where your variables
live if a feature vector is a vector
length L each data point can be
considered being mapped to a d
dimensional vector space called the
feature space labeled data is the data
with known classification results once a
labeled data set is obtained you can
apply machine learning models to the
data so that the new unlabeled data can
be presented to the model a likely label
can be guessed or predicted for that
piece of unlabeled data here is an
example of features of two apples one is
red and the other is green in machine
learning an object is used in this
example the object is the Apple the
features of the object which is Apple
include color type and shape in the
first instance the color is red the type
is fruit and the shape is round in the
second instance there is a change in the
featured description in the color of the
Apple which is now green as machine
learning is related to data mining it is
a way to fine-tune a system with tunable
parameters it can also identify patterns
that humans tend to overlook or are
unable to find quickly among large
amounts of data as machine learning is
transforming a wide variety of
industries it is helping companies make
new discoveries and identify and
remediate issues faster here are some
interesting real-world applications of
machine
learning speech recognition machine
learning has improved speech recognition
systems machine learning uses automatic
speech recognition or ASR as a
large-scale realistic application to
rigorously test the effectiveness of a
given technique effective web search
machine learning techniques such as
naivebayes extract the categories or a
broad range of problems from the user
entered query to enhance the results
quality this is based on query logs to
train the model recommendation systems
according to Wikipedia recommendation
systems are a subclass of information
filtering system that seek to predict
the rating or preference that a user
would give to an item recommendation
systems have been using machine learning
algorithms to provide users with product
or service recommendations here are some
more applications of machine learning
computer vision computer vision which is
an extension of AI and cognitive
neuroscience is the field of building
computer algorithms to automatically
understand the contents of images by
collecting a training data set of images
and hand labeling each image
appropriately you can use ml algorithm
to work out which patterns of pixels are
relevant to your recognition tasks and
which are nuisance factors information
retrieval information retrieval systems
provide access to millions of documents
from which users can recover any one
document by providing an appropriate
description algorithms that mine
documents are based on machine learning
these learning algorithms use examples
attributes and values which information
retrieval systems can supply in
abundance fraud detection machine
learning aids financial leaders to
understand their customer transactions
better and to rapidly detect fraud it
helps in extracting and analyzing a
variety of different data sources to
identify anomalies in real-time to stop
fraudulent activities as they happen
you've learned what machine learning is
and it's applications now let's take a
look at the role of machine learning in
spark the scalable machine learning
library of spark is called ml Lib that
contains general learning utilities and
algorithms including regression
collaborative filtering classification
clustering dimensionality reduction and
underlying optimization primitives you
will learn about some of them in the
following screens spark excels at
iterative computation enabling ml Lib to
run fast there are two types of API
firstly a primary API which is the
original spark ml Lib secondly there is
a high-level API which is the pipeline
spark ml spark 1.2 includes a package
called spark ml which aims to provide a
uniform set of high-level api's that
help users create and tune practical
machine learning pipelines you will
learn about the steps followed in the
general machine learning pipeline in the
next screen here are the steps that are
included in the general machine learning
pipeline the first step is data
ingestion
when a user ingests data it may not be
in the correct form and may require some
cleaning up and transformation which is
the second step this data is an input
for the machine learning algorithm in
the third step the data goes through the
model training the next step is the
model testing phase in the final step
the model is then deployed and
integrated the model feedback then goes
back to the users and reflects in the
user behavior during data ingestion in
the next topic you will learn about the
three C's or the techniques for
exploiting data in the previous topic
you learned about the applications of
machine learning and the role of machine
learning and spark in this topic you
will learn about the three techniques
for exploiting data
let's take a look at what these three
techniques are these include
collaborative filtering or
recommendations clustering and
classification you will learn more about
them in the subsequent screens let's
begin with clustering clustering is an
unsupervised learning problem with the
objective to group the subsets of
entities on the basis of some idea of
similarity it is generally used either
as a hierarchical supervised learning
pipeline component or for exploratory
analysis ML Lib supports k-means
clustering which is a clustering
algorithm it clusters the data points
into predefined
number of clusters you will learn more
about k-means in the screens ahead there
are various other models of clustering
that ml lib supports such as Gaussian
mixture power iteration clustering or p
IC latent dirichlet allocation or Lda
and streaming k-means let's move on to
classification ml lib provides support
to different regression analysis binary
classification and multi-class
classification methods the table on the
screen lists and explains the supported
algorithms for every problem type for
binary classification the supported
methods include linear SVM S logistic
regression decision trees random forests
gradient boosted trees and naive Bayes
for multi-class classification the
supported methods include logistic
regression decision trees random forests
and naive Bayes for regression the
supported methods include linear
least-squares lasso Ridge regression
decision trees random forests gradient
boosted tree and isotonic regression
explanation of these methods is beyond
the scope of this lesson let's take a
look at two examples of classification
in the first example you can see that
the classification always gives a yes or
no answer
by creating routes in case of a certain
product if the age of the customer is
more than 20 and if the customer is
female it is likely that the customer
will not buy the product the second
example is a sample random graph for
classification collaborative filtering
is generally used for recommender
systems the objective of these
techniques is to complete a user term
association matrix with entries that are
missing at present ml Lib provides
support to model-based collaborative
filtering in this product and users are
explained through a small set of latent
factors these factors are usable for
predicting the missing entries the table
lists the parameters that facilitate the
implementation of ML Lib let's begin
with number find as the number of blocks
that are used for parallelizing
computation rank is defined as the
number of latent factors in the model
iterations is defined as the number of
iterations to run while lambda defines
the parameter of regularization in ALS
implicit prefs explains what should be
used out of the variant adapted for
implicit feedback data or the explicit
feedback ALS variant alpha is a
parameter that is applicable to the
implicit feedback ALS variant governing
the baseline confidence in preference
observation even though there are
various techniques of exploiting data
which you have seen on the previous
screens there are some challenges in
machine learning machine learning is
highly computation intensive and
iterative there are many traditional
numerical processing systems that do not
scale to large data sets for example
matlab machine learning seems to be
disrupting software engineering
challenging its impact on real world
applications now let's move on to
k-means algorithm you have learned that
ML Lib supports k-means clustering which
is one of the most commonly used
clustering algorithms k-means clusters
the data points into predefined number
of clusters a parallelized variant of
the k-means plus plus method is also
included k-means pipeline pipeline this
table lists the parameters that
facilitate the implementation of ML Lib
k is the number of required clusters max
iteration is the maximum number of
iterations to run initialization mode
specifies either random initialization
or initialization via the k-means
pipeline pipeline method runs is the
number of times to run the k-means
algorithm initialization steps
determines the number of steps in the
k-means pipeline pipeline algorithm
epsilon determines the distance
threshold within which you consider k
means to have converged shown here is
the flow chart that illustrates how the
k-means algorithm works to begin with
the k-means clustering algorithm tries
to split a given anonymous data set
which contains no information as to
class identity into a fixed number k of
clusters initially the k number of
centroids which is a data point
imaginary or real at the center of a
cluster are chosen all centroids are
unique as each centroid is an existing
data point in the given input data set
picked randomly for each data point you
need to calculate the absolute distance
between the point and each of the k
centroids
the data point then becomes part of the
group of the centroid that matches the
data points minimum distance repeat
steps 2 and 5 until the centroids no
longer move this produces a separation
of the objects into groups from which
the metric to be minimized can be
calculated now let's look at an example
of k-means clustering
a telecommunications company wants to
set up three towers to cover the entire
population of a region and wants to
understand how the customers are
distributed here you can see an
anonymous data set the data needs to be
clustered the goal is to find the
cluster of data points using k-means
clustering as the first step choose K
random points as starting centers as you
can see three random points are chosen
these indicate the location where the
three towers will be located secondly
find all points closest to each Center
this is done by calculating the distance
between the points for example the data
points closest to the yellow point are
clustered then find the center or the
mean of each cluster if the center's
change iterate again you need to go back
to step 2 to find all points that are
closest to each Center these will look
different compared to the points in step
2 again repeat the earlier step 3 of
finding the center or mean of each
cluster if you find that the center's
change again you need to iterate again
continue to do this until the centroids
no longer move you are finally done
Hey want to become an expert in Big Data
then subscribe to the simply learned
Channel and click here to watch more
such videos centered up and get
certified in Big Data click here</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>