<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AWS Tutorial | Storage and Content Delivery | AWS Training Video | Simplilearn | Coder Coacher - Coaching Coders</title><meta content="AWS Tutorial | Storage and Content Delivery | AWS Training Video | Simplilearn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Simplilearn/">Simplilearn</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AWS Tutorial | Storage and Content Delivery | AWS Training Video | Simplilearn</b></h2><h5 class="post__date">2016-04-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PcDV3CQCV18" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome to this lesson of
storage and content delivery in this
lesson you'll learn 6 Amazon data
storage offers and elastic block storage
of AWS the multiple offers for data
storage from Amazon are Amazon simple
storage service or Amazon s3 Amazon
CloudFront Amazon Elastic file system or
Amazon EFS Amazon glacier Amazon storage
gateway and Amazon import/export in the
topic you will learn about one of the
most popular Amazon storage options
Amazon simple storage service or Amazon
s3 Amazon s3 provides safe and secure
object storage to developers it has a
user-friendly interface that helps in
storing and accessing any amount of data
anytime but to store and access the data
you need an internet connection and an
AWS account a file in the Amazon s3
parlance is referred to as an object the
object representation of a file consists
of the actual data portion and this
information is not visible to Amazon the
other part of the file is metadata it
refers to name value pairs that help in
storing information such as last
modified date and time content type and
other HTTP metadata Amazon even provides
you with the option to maintain custom
metadata Amazon s3 enables you to store
data in three easy steps select the
region where you want to store the data
create a bucket and then store the data
a bucket enables you to store one or
more objects as an account holder you
have the permission to create a maximum
of 100 buckets each bucket is a logical
container for multiple objects and each
object is identified by a key
the size of an object can be up to five
terabytes you can set accessibility
permissions for objects and buckets by
following the suggested terms and
maintain access logs to keep a track of
used buckets
after learning about s3 storage let's
see the steps to create an Amazon s3
bucket locate the s3 option under the
storage and content delivery services
click s3 to display the s3 management
console page on this page click create
bucket to display the create a bucket
select a bucket name and region dialog
box next enter a globally unique bucket
name in the provided space it is
recommended to name the bucket with your
own initials and the current date to
ensure uniqueness also confirm that the
bucket name does not contain uppercase
special characters or spaces between
characters in the space provided for the
region choose your closest location from
the drop-down list or you can choose
u.s. standard next click create to add
the bucket and display its name on the
Left panel at this stage if you click
the created bucket you will receive a
message indicating that the bucket is
empty next click upload here click add
files to select the required files
that's not all you even have the option
to simply drag and drop the files to be
uploaded now click start upload to begin
the upload process once the files are
uploaded the status is changed to done
to confirm if the object is uploaded to
the created s3 bucket simply select it
it is important to note that the box
towards the left of the name of the
object turns blue this indicates that
you have selected the object
congratulations you have successfully
completed the steps to create an Amazon
s3 bucket let's see the steps to manage
logging into Amazon s3 bucket AWS
enables you to get
detailed access logs for an s3 bucket
but to do this you need to enable the
logging feature for the bucket by
default logging is disabled for an s3
bucket let's see the steps to enable
access logs for an Amazon s3 bucket the
first step is to log on to the AWS
management console under all buckets
select the bucket for which you wish to
enable access request logs next in the
details pane click properties this will
display the property pane for the
selected bucket then expand the logging
item and then do the following first
select the enabled checkbox next from
the target bucket drop-down list select
the bucket name for which you wish to
enable access log request then an option
step is to enter the prefix for log
objects in the target prefix box for
this demo we will keep it as it is
finally click Save if you wish to
disable the access requests logs simply
clear the enabled checkbox and then
click Save
congratulations you have successfully
completed the steps to enable access
logs for an Amazon s3 bucket let's see
the steps to delete or empty an Amazon
s3 bucket we will begin with deleting an
s3 bucket the first step is to log on to
the AWS management console and then open
the Amazon s3 console here right-click
the bucket you wish to delete and then
select delete bucket
a confirmation message appears next
enter the bucket name and then click
delete the bucket and its objects are
permanently removed from AWS an
alternative to deleting a bucket is
emptying its objects doing this would
help you retain the bucket name its
settings and permissions now let's see
the steps to empty an s3 bucket
simply right-click the bucket you wish
to empty and then select empty bucket a
confirmation message appears next enter
the bucket name and then click empty
bucket the bucket objects and their
versions are permanently removed from
AWS congratulations you have
successfully completed the steps to
delete an empty an s3 bucket you have
the permissions to access AWS region and
use a bucket and its objects as you
select the desired region Amazon s3
automatically duplicates the object on
multiple devices and across multiple
facilities within the region this is
done to maintain 99.99% durability and
99.99% availability of objects the
low-priced reduced redundancy storage or
RRS helps Amazon s3 in duplicating
objects across a small number of
locations within a region Amazon s3
offers three storage classes s3 standard
for general purpose for active data s3
standard rare access for general purpose
and enduring but not much active data
and Amazon glacier for long-term
archiving Amazon s3 offers configurable
policies for handling data throughout
its development once the policy is set
the data would be migrated to the most
appropriate storage class and without
any changes to the application
the price of Amazon s3 is based on the
storage usage and the bandwidth used for
downloading objects also the total
number of HTTP requests like get put
post is calculated for the enforced
charges you can't use rest and soap
api's to connect to s3 and retrieve or
upload objects to encrypt the stored
objects use server-side encryption or
aes-256 standard you must consider
security issues whenever a data
transaction takes place that's not all
you can use ssl connections to avoid
security breaches while transacting data
in this topic we will learn about Amazon
CloudFront
Amazon Cloud Front is an economical but
a dynamic content delivery network or
CDN it enables you to enhance the
experience of users accessing both
static and dynamic content of your
website Amazon CloudFront
administers an association of edge
locations to store copies of frequently
accessed files in proximity to its users
for a definition edge locations refer to
the boundaries between locations of
major cloud servers when a visitor
requests the desired content whether it
is dynamic static or streaming Amazon
CloudFront
makes it available from the nearest
network of edge locations
this results in objects traveling
shorter distances thereby improving
website performance
but what about files that are not cached
Amazon CloudFront
continues to maintain connection with
servers that originally host content
files so when a visitor requests content
Amazon CloudFront ensures that the
requested objects reach the visitor
immediately Amazon Cloud Front supports
users requesting data using both web
browsers and mobile devices
unlike Amazon glacier the solution is an
ideal choice to distribute the
frequently access static and dynamic
content such as videos pictures software
products and dynamic web applications
over HTTP the two key advantages of
utilizing Amazon CloudFront
are its ability to scale according to
your requirement and the flexible cost
model with the former you don't need to
take the burden of managing high priced
web servers to manage your web traffic
needs instead you can start small and
grow as the traffic to your website
increases in fact the Amazon CloudFront
service automatically managed your
traffic load without your intervention
now the latter cost model there is no
minimum monthly commitment or a fixed
term contract to dynamically deliver
content using Amazon CloudFront
in fact you are expected to pay only for
the content you deliver using its
service in this topic we will learn
about Amazon Elastic file system or
Amazon EFS Amazon EFS enables you to
create and setup file storage to quickly
access files and with ease the system is
said to be elastic as it automatically
maintains storage whenever you create or
delete a file the amazon EFS service
enables storing Amazon ec2 instances it
is a file storage service and supports
the latest version of network file
system which is for commonly known as
nfsv4 protocol the
enables seamless working between latest
tools and applications and Amazon EFS
the Amazon EFS is capable of connecting
multiple Amazon ec2 instances this way
workloads and applications running on
multiple instances would still have a
common data source with Amazon EFS you
are charged only for the used data or
storage and it is an ideal choice for
organizations that seek solutions to
manage content repositories maintain
multiple development and test
environments scale performance of big
data applications and manage users
accessing data and shared data sets from
a remote location
in this topic we will learn about Amazon
glacier
Amazon glacier is an economical storage
solution to store data that would remain
forever but rarely accessed it is an
ideal choice for data backup and
archiving provides data security of the
highest level and offers flexibility in
both storing and retrieving data AWS
bills you for only the use data or
storage and current least price for
storing data in Amazon glacier is 0:07
cents per gigabyte per month maintaining
historical data can be a grief as it is
added to the administrative liability of
managing the scaling storage Amazon
glacier eases this hardship by providing
features such as capacity planning
hardware provisioning detecting and
repairing hardware failure data
replication and hardware migrations when
you preserve data in Amazon glacier it
is stored as archives this enables a
user to store a single file or a
combination of several files archives
are arranged in vaults which can be
accessed using the AWS iam service
Amazon glacier stores data in transit
via SSL and uses the 256 that advanced
encryption system AWS enables
organizations to store data in a
location that is convenient for their
businesses and organizations tend to
utilize Amazon glacier to support the
following use cases archiving off-site
enterprise information backing up media
assets storing research and scientific
data preserving digital data and
replacing magnetic tapes the Amazon
glacier archives offers an average
annual resilience of 99.999999 nine nine
nine percent the archiving service
maintains resilience by continuously
utilizing several facilities and devices
within each facility to store the data
the
Cass continues till the service returns
success on the uploading archives in
this topic we will learn about AWS
Storage Gateway the AWS Storage Gateway
service provides an uninterrupted and
secure connection between the AWS cloud
storage and your organization's
on-premises data storage devices or data
centers in other words AWS Storage
Gateway is a scalable and an economical
amalgamation of your office IT and AWS
storage infrastructure this amalgamation
offers widely accepted storage protocols
working in harmony with your current
applications minimizes latency or the
gap between request and response time by
managing the recurrently access data
stored in your physical locations and
stores data in an encrypted form in
Amazon s3 or Amazon glacier the AWS
Storage Gateway service is an ideal
choice to backup applications in an
encrypted form plan for disaster
recovery by creating a mirror of your
entire production environment and file
sharing within the corporate environment
there are three configurations that AWS
Storage Gateway supports Gateway cached
volumes gateway stored volumes and
gateway virtual tape library let's see
all of them in detail starting with
gateway cached volumes gateway cached
volumes enables preserving the most
accessed data and stores it in Amazon s3
this is an economical configuration and
users experience no latency while
accessing the data next gateway stored
volume is used when you need quick
access to your data the data is stored
locally on your device and in Amazon s3
so at the time of a disaster this backup
enables recovering the data locally or
from Amazon ec2 gateway virtual tape
library or gay
'we VTL offers a low-cost solution to
archive your data stored in a tape based
backup application in the AWS cloud the
VTL interface lets you create your own
gateway VTL by storing your data on
virtual tape cartridges in this topic we
will learn about AWS import/export the
AWS import/export service allows easy
transfer of considerable volumes of data
from and to AWS without using the
internet but physical storage devices
AWS utilizes its high speed internal
network to load the data on to the
devices and offers the following two
features that support the AWS
import/export service AWS import/export
snowball or snowball and AWS
import/export disk or disk let's learn
about each of them the snowball is a
cost-effective data transfer solution it
uses physically rugged appliances which
are protected by the AWS key management
services AWS kms to transfer petabytes
of data from your physical data centers
to Amazon s3 a single snowball is
capable of transferring up to 50
terabytes of data this data transfer
solution addresses challenges of high
network costs unending transfer queues
and most importantly data security
according to statistics transferring
large amounts of data using snowball is
five times cheaper than using a
high-speed internet connection so how do
we transfer large amounts of data using
snowball the first step is to create a
job in the AWS management console the
AWS team automatically ships the
snowball appliance to your premises
once the appliance arrives connect it to
the local network install the snowball
client to establish a connection select
the files and directories to be
transferred to the appliance the client
runs in
program to encrypt the data using 256
bit encryption and then transfers the
selected files to the appliance at a
high speed once the files are
transferred ship the snowball appliance
to AWS snowball becomes your ideal
choice when expensive network
infrastructure upgrades are beyond your
budget or capacity there exists huge
backlogs of data or your data is stored
in a location where high speed internet
connection is not available that's not
all according to AWS if the estimated
time to transfer a certain amount of
data using a high-speed connection is
approximately one week then you should
opt for snowball disk was the first
service offered by Amazon to transfer
data using UPS or mail this service
enables transfer of data from and to
your on-premises data center using
Amazon's internal high-speed network it
is an ideal choice to transfer small
amounts of data
unlike snowball which currently supports
importing data only to Amazon s3 disk
provides you the option to import data
to Amazon s3 Amazon EBS and Amazon
glacier in addition to this it supports
exporting data from Amazon s3 to your
on-premise data centers
in this topic we will learn about
elastic block storage of AWS Amazon ec2
instance storage is an ephemeral storage
provided with some instances ephemeral
refers to the fact that the storage is
for temporary use and will lose its
content when the system is rebooted
Amazon Elastic block storage or Amazon
EBS is used mainly in stateless web
hosts transcoding caching and
high-performance computing or HPC Amazon
EBS has two types of construction one is
magnetic storage it is persistent and a
type of slower and older elastic block
storage it provides up to 150
input/output operations per second or I
UPS the other type is SSD construction
it is again of two types general-purpose
I ops and provisioned I ops now let's
learn more about the SSD types
general-purpose IOPS possesses the
capability to provide 3i ops per
gigabyte of provisioned storage this
type of storage is used for small
websites and small to medium databases
provisioned IOPS enables the user to
provide I ops as per their requirement
it is used for applications and
databases where there is a significant
amount of traffic if the user wants to
take full advantage of the provisioned
IOPS then it should be connected to AWS
specified EBS optimized ec2 instances
these instances have a focused channel
of communication within the same
availability zone to EBS volumes
attached to the instance while creating
an EBS volume you need to specify the
size in gigabytes
moreover DBS provides you with the
option to increase the volume or storage
size at a later stage
but decreasing the size is ruled out if
the user wants to increase the size of
EB s volume is recommended to unmount it
from the attached server the change in
size cannot be done dynamically before
creating a new volume one needs to take
a snapshot of the drive the snapshot
represents a point and time image of the
volume this snapshot is stored in Amazon
s3 let's summarize the topics covered in
this lesson traditional storage data
centers have three kinds of storage
direct-attached storage network attached
storage and storage area networks all
the traditional storage system or
services differ in their performance
durability and cost Amazon s3 provides
safe and secure object storage to
developers Amazon CloudFront helps in
improving the experience of users
accessing both static and dynamic
content of your website amazon EFS
enables to create and set up file
storage to quickly access files Amazon
glacier is a cost-effective storage
solution to store data that is
long-lived and irregularly accessed AWS
Storage Gateway is a service that
provides seamless and secure connection
between your organization's on-premises
data storage devices or data centers and
the cloud storage AWS import/export
service enables the easy transfer of
large amounts of data into and out of
AWS using physical storage devices
avoiding the internet ephemeral refers
to the fact that the data storage is for
temporary use and will lose its content
when the system is rebooted
this concludes the lesson storage and
content delivery the next lesson is
compute services and networking
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>