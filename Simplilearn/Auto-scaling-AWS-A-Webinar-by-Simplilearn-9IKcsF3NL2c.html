<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Auto scaling AWS | A Webinar by Simplilearn | Coder Coacher - Coaching Coders</title><meta content="Auto scaling AWS | A Webinar by Simplilearn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Simplilearn/">Simplilearn</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Auto scaling AWS | A Webinar by Simplilearn</b></h2><h5 class="post__date">2016-04-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9IKcsF3NL2c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right everyone welcome to simply
learn webinar on auto scaling with EWS
my name is Raj and this is going to be
an exciting tour about auto scaling with
Amazon Web Services I'm a Solutions 8w
certified solution architect so and I
have a lot of experience on cloud
technologies so today we're going to
cover lore about auto scaling and so
let's not waste any more time let's
crack on with this so today's objectives
we gonna introduce about ec2 just a
little bit of introduction on ec2 and
then we gotta go in-depth on auto
scaling we kind of look into the
different types of scaling how have the
traditional IP that has been and then
we're going to look into auto scaling
then because good people into auto
scaling we're going to look into auto
scaling terminology which are launch
configuration auto-scaling
groups scaling policies after which
we're gonna have a demo and finally
we'll have Q&amp;amp;A in the end right so let's
go on so important thing about auto
scaling is the fundamental component and
this fundamental service that Amazon
offering which is nothing but Amazon ec2
easy to this Elastic Compute cloud this
is a service that offers v size will
compute capacity in Amazon Web cells so
you'd have servers ready on Amazon so
this is where easy to place an important
rule for almost all major components
that Amazon support for your hands so
it's flexible
you could run Windows or Linux
distributions if you're familiar Amazon
ec2 instances previously you know that
you could run a bindles or a Linux based
operating system that's scalable so it
has a wide range of instances from micro
to cluster compute so it's like one CPU
1b Ram to 1gb Avira to all the way up to
like 8 and 32 gigs it'd be CPU and 32
and more so you have these clusters
available and
this piece of the options that you'd get
we definitely have a brief look into
those when we are building our launch
configuration so remember that we're
gonna look into this scalability fact
over there then you have the machine
image so machine image is nothing but
the snapshot of an instance which has an
application bundled with it need not be
with the definition is provided it could
also be like you have a distribution a
Linux distribution that's there and you
want to build it so machine image is
actually a configuration from its new
instances can be created right so then
with easy to you also get full route and
administrative access there's no
restrictions you could do whatever you
want with your own server you are the
admin of that server you have full
control on that so again the next test
security so do the ec2 instances are
secured using firewall which is security
groups then these ec2 instances are
pushing a lot of information to cloud
watch which is the monitoring service of
Amazon so you wanna monitor a couple of
services that's there you wanna monitor
the CPU memory network usage if you have
a load balance and you want to see how
the performance of that of that is so
you use cloud watch to monitor that so
you wouldn't need a third party tool
that could monitor that so and basically
you know yeah ec2 is inexpensive so
there are three different variants a PC
- that's on demand which which fills up
at powers on VMs whenever you want
reserve this something that you would
book it for a longer period of time and
you have highest cost saving their spot
instances are nothing but that
fluctuates on price so you'd want to
purchase a large set of servers together
and probably you're running a massive a
big data analytics and you cannot afford
to spend money on compute instances so
that's where you use your sport instance
and finally you have a vm import so if
you want to transfer configuration in an
hour of ec2 so these are the features
that ec2 offers so do want to give you a
brief intro
action on ec2 ec2 is an elaborate of it
all together but this one page should
give you an idea about what ec2 is and
how we're going to use it so we're gonna
use easy to enough and setting it up
that you can auto-scaling so going back
what are the vertical and horizontal
scaling types that's there so if what do
you mean the vertical scale is that you
want to increase the type the existing
instance so in your terms if you have a
desktop on a server you are increasing
the memory of that from pogey to eight
gigs so within that scope that's
basically vertical scaling horizontal
scaling is you add additional instances
so you add and remove additional
instances so you have one server you add
couple of and more so that's horizontal
scaling you would want to choose between
them depending on your application and
your demand so that's vertical and
horizontal scaling and going back how
this traditional IT capacity usage
pattern has been so this first the on
and off pattern where this blue line is
how you're responding how the demanders
and the green line on top your capacity
you current capacity so the first is on
and off so you have a demand for some
period of time and you already have
built a real entre line which is your
base line capacities we probably
purchased a lot of servers anticipating
you have demand coming up so you have
the grey line which is the amount of
capacity that's there and you're the
blue line is where you actually use ages
so on and off is where you have a demand
and sometimes you don't have so that's
phase that's what pays over there but
path growth the second one well your
your growing business and there's a lot
of things coming up you need to install
more and more servers and at the same
time you need to deliver this as well
there's rapid usage going on so that's
the linear way of growing so then
there's variable peak this is where you
have no idea what's going on and even if
you have an idea okay I have a lot of
business comes in and these are the
applications this this department needs
capacity and you're trying to plan it
but
sometimes you don't Planet and you
there's a lot of underutilized hardware
there and then at some point you're
unable to meet the demand itself so
that's this peak when you know you're
not able to meet the demand that's
available that's made so you don't need
that so that's a variable pink that's
there then there is predictable peace so
you predict and you install a lot of
hardware inside your datacenter or
anywhere else and you don't utilize it
at all so it's basically you beer stink
resources so what happens so this is
what happens you have lot of wastage of
resources in capacity so you you know
utilizing with a lot of hardware on the
one hand on the other hand when you're
unable to deliver any capacity requests
the demand that is coming in you're
unable to provision server when you're
unable to provision storage you
basically losing your client or you
having performance issues or you having
outages so the poor service and wastage
of resources those are one of the key
concern and this was all about cloud
computing so cloud computing guarantee
is elasticity that's of elasticity
ensures that you could scale up and
scale down as and when needed right so
this this has been a traditional pattern
so I'm gonna show you a quick sneak peek
on how auto scaling works this is just
to give you an idea how this would work
but we're gonna go in detail but this is
how it is so you have an ec2 instance
which is group of servers you call it as
an auto scaling group which pushes the
data to cloud watch which is a
monitoring service
so cloud watch is actually monitoring is
watching the ec2 service and it's gonna
see whether something and I'll say
something because something could be a
CPU or a disk usage or network usage
it's actually watching what's going on
with the server is it having high usage
yes okay it's going to trigger some
alarms and then what it's gonna do is
it's gonna find out what is the scaling
policy that it says ok if I have it
scaling policy is not humid flowchart or
step step by step it says okay if I have
CPU usage more than 50 percent what
should I do
I should add another instance so scaling
policies is gonna do it okay let me try
to find out beneath me to instance find
out the launch configuration let me try
to bring it up so it brings it out and
then it adds to the auto scaling group
so you're expanding your capacity your
infrastructure automatically yeah
automatically so you know you don't have
a lot of manual work actually you don't
have any manual work so in the demo we
gonna demonstrate after this you would
see that we're gonna have a web web page
because you know I'm not building a
website for now I'm having a back page
I'll make sure that's always available
and how the instances are there so this
is a small sneak peek so let's go in
detail so basically it's automatic
resizing of compute clusters based on
demand right so we define the maximum
and minimum preferred instances so we
can define that this is the amount of
instances you could imagine you need to
imagine this is what my application is
my application needs at least two
servers at all times and if if I need to
add more I need to add two more on both
the availability zone availability zone
is nothing but a data center you could
relate that to be a data center in one
region so then you define as you saw in
the previous slide so when would you
scale out and scale n so when at what
point is it - you said you'd want to
scale out or you have a lot of incoming
traffic coming from users trying to buy
something so you won't want to add
additional instances based on network
usage and then these metrics are
collected by cloud watch and then it
pushes these scaling instructions right
so then you would run the auto scaling
it pushes these auto scaling
instructions hey let's power on more
servers we have a huge demand come now
right and finally this is
important auto-scaling this whole
function is free this one using the
servant absolutely free but you only
have to pay for the resources that's
used so when you power on that easy to
instance you'd have to pay for it you'll
have a page for the usage and whatever
that would turn out to be this is quite
normal
a nominal in my opinion you just have
you're not paying anything for the
service or the skilling service you just
paying for the the functionality of an
axe a functionality it's the services
you just paying for the instance is only
right so imagine this is your auto
scaling group and you have two instances
and this is pushing the usage and
metrics to cloud watch so cloud watch is
gathering this information and it's
having a little watch on all the
instances and it finds something
abnormal an abnormal high CPU usage or
high network usage you would have to
define it and it would stand scaling
instructions and say okay my CPU is high
I need to add one ec2 instance then
after sometimes you find out oh no I
have further web traffic traffic coming
in my sleep my workloads on these
instances are unable to handle them
looks like I need to add more so you
would it would add more automatically
until when so until you define in the
maximum movement the second bullet point
over here so you have to define at what
point you are okay to survive
economically because if you put this to
infinity you'd have hundreds and
thousands of servers booting up and that
means you need to pay for all the you
say that's happening right on the other
hand you would this is one way using
cloud watch so then you'd have queues
and metrics using the simply queue
service of Amazon if it's done based on
a queue and these queue would trigger
that based on certain actions cloud
watch will monitor that and based on
certain cues that that have been defined
it's gonna push Kaling instructions to
do something like add or delete an ec2
instance right so that that is also the
other way
expanding on auto-scaling further if you
find out it's the night time you don't
have any users coming in and probably
you don't want to the usage has come
down automatically
it's like close to 10% probably because
it's neither probably if they are in a
different time zone you could it would
send further usage and metrics
information to cloud watch and cloud
watch would monitor that and send
scaling instructions to delete or remove
the easy to instance so so easy to
instances would get terminated right so
this is how auto scaling would respond
so the red one red line that you see is
how auto scaling responds to current and
desired capacity so it would go in line
so that you don't suffer a outages or
performance issues or B availability so
you have never that problem and finally
and the most important thing you're not
investing any hardware in advanced so
you just bring bring out new instances
when there is a demand so that's how the
auto scaling work works here so some of
the terms that you need to know photo
scaling are auto scaling groups launch
configurations don't worry we're gonna
look into all these in details scaling
plans the way in which you should scale
alarm in the cloud watch alarm how it
pushes ELB or elastic load balancer
which is on top of these instances it
probably field having a web front-end if
you have a website in our example we're
going to use an e lb we're going to have
ec2 instances below the e lb so that you
have a single cname to connect to your
website and then instant metadata and
user data so this user data is the
configuration scripts that you send to
your ec2 instances when they boot up so
that you have a predefined configuration
so you need to automate everything so
let's get into that this a bit closer so
auto scaling group is a group of ec2
instances they're categorized based on
similarity right so you create auto
scaling group by defining the minimum
maximum
and optionally the desired number of
running instances so this is what you
define the group would be then launch
configuration is the auto scaling group
it is going to use launch configuration
to launch ec2 instances so this launch
configuration imagine this to be a
template that these are the type of
servers that I want to power off power
on so it could be an Apache server or a
Windows server and this is what I have
defined it to be right scaling plan as I
said is tells when to when and how to
auto scheme so at what point you are out
of scale and when I see that what should
I actually do right so that's that's the
scaling panel gonna look into this much
closer now so an auto scaling group
contains a collection of ec2 instances
that share similar characteristics and
are treated as a logical grouping for
the purpose of instance scaling and
management for example if a single
application operates across multiple
instances you might want to increase the
number of instances in that group to
improve the performance of the
application or decrease the number of
instances to reduce cost when the demand
is low so you can use the auto scaling
group to scale the number of instances
automatically based on the criteria that
you specify or maintain a fixed number
of instances even if an instance become
unhealthy right so you need to keep a
minimum number of instances running and
you don't terminate instances need the
desired capacity right and then you
ideally never start more than the
maximum number of instances now I said
earlier you don't want to pay too much
right and then balance this across
availability zones spread them across so
that you don't run into any of these
capacity issues or an availability zone
going down issues that might have happen
so launch configuration you determine
what is going to be launched so as I
said is launch configuration is a
template that an auto scaling group uses
to launch ec2 instance so when you
create a launch configuration you
specify information of the instances
such as the ID of Amazon machine image
then
since tying the key pair or the security
groups to the firewall and a and a
device mapping so if you have launched
an ec2 instance before you specify the
same information in order to launch
instance so when you create an auto
scaling group you must specify launch
configuration so you can specify a
launch configuration with multiple auto
scaling group however you can only
specify one launch configuration for
auto scaling group at a time right and
you can modify a launch configuration
after you have created so therefore you
want to change the launch configuration
for an autos for your auto scaling group
you must create a launch configuration
and then update your auto scaling group
with the new launch configuration so
when you change the launch configuration
for your auto scaling group any new
instances that are launched using the
new configuration parameters but
existing instances are not affected so
you'd use this on if you want to have
existing launch configuration and you
want to build out a new one you setup
them because you probably upgraded all
the instances to a newer version you
slowly push them off and have the new
ones take over they have it's basically
the ec2 instances and the type and size
it's there then the Amazon machine image
the security groups keys and stuff so
basically tells you the template for the
scaling plants scaling policy the setup
instructions for making such adjustments
what's going on just adjusted so you
always have to focus on scaling plans in
fact and of course everything is
important but scaling plans affects your
cost a lot so when does it scale and and
scale out so if design capacity in
greater than current capacity go ahead
launch instances if desired capacity is
less than current capacity please
terminate instances you don't want them
running right so that's how this game
plans are then so couple of important
thing to ensure your current capacity of
healthy instances remain within a limit
so never less than minimum right you
don't want to have one instance running
and I have keep them to probably on to
availability zones all right
make it three if you have three
availability zones in your regions
so manual scaling is when you modify
yourself you don't want to do that but
yeah it's possible you can add an
instance if you feel like you want to do
it and this is not a pretty to find one
so you log in to auto-scaling and say
okay I have to now let me make three
probably I know that we would have a
demand and then scheduled scaling plants
so where you know that during the day
you need four or five servers and
because this huge demand and there's lot
of users logging in but you know that
after say 9 p.m. and all the way till 6
a.m. in the morning none of users log in
so you'd want to cut it down between
between 9:00 to 6:00 a.m. so these are
scheduled instance of scheduled scaling
plans that you could also try and
finally the most important thing is
dynamic scaling this is what you should
be ideally using so that you save cost
and ensure availability at all times
so that's based on cloud watch matrix so
there it's gonna watch the matrix and
you define you do those actions based on
certain certain data all right so I'm
going to give you an introduction with
step scaling so um you always want to
think that if you sit goes hi let me
increase it but what happens next so
let's take an example here so on the
first one there's the first star let
starve that you see here this is so you
you have defined a CPU utilization to
trigger an alarm when it reaches 60% so
you have to find that so or chloro it
actually no it's that it cannot it's
going to note that but it's not going to
take any action and it's going to wait a
period to ensure that this alarm is
actually real it's not like it was just
a peak and it didn't go down so after an
evaluation period where it feels it's
gonna do another check and it finds out
hey it's still about 60% so at that
point of time it's going to take a
scaling plan so that's when the alarm
triggers and then a scale out action
comes in
skillet action is nothing but okay the
usage has gone up let's take an action
sir so it's gonna take an action to
bring out a new instance or to one or
two instance based on what you have
defined so they like you have to find
that if the alarm usage is above 60% to
make sure you add one instead so that's
that happens at this point of time so
and we am the instance comes up after
which you have a cool-down period the
cooldown period is when it's going to
make sure that no other because this so
it just came up live so it's gonna make
sure it wants to make sure that there is
no other instances accidentally being
powered on because there was an alarm
trigger at an early point of prime at
sixty and there was a response at
seventy so we don't want to accidentally
add more instances what this also means
is that between that period there won't
be nearly split alarms right isn't that
a risk yes that could be a risk
the reason is have a look at this so
imagine you have your alarm at 60% and
then you know as I said earlier you want
to actually monitor is it's really sixty
percent or not is it really 50% gonna
check back later after redefine so in my
graph you could see that it's one minute
interval so it's going to see that okay
let me wait for one minute and see how
the utilization is but in that one
minute what if the CPU utilization or
any other metric utilization then over
the roof so it went all the way to 90
and hundred and you have very bad
situation so that's a difficult that's
not an ideal situation to be art the
reason is so you were too late to
respond to your event and probably your
application or your website went down in
the mean one so there's something called
step scaling so step scaling defines
multiple steps in the same policy so
it's gonna take out the appropriate
scaling and it's based on a value and it
triggers there on right so step scaling
continuously evaluated and not there's
not like okay have do don't do this wait
for some time and then find a next
action so and there is no law
the alarms are kept continuously
evaluated even when the ec2 instance is
being scanned right so we have an
improvised version in this graph so you
get different alarms being triggered and
then there is granular level and then
you're going to take action there on so
this is I'm going to show you a small
screen shot how it is done so you take
an action at zero instances between zero
to fifty I don't want to take anything
touch there but I'm gonna add two
instances when it's between 50 and 70
and I'm gonna add four instances and it
something after 70 percent so this is
what you're going to do this is a
screenshot of how you would you do step
scaling right then there is termination
policy so that's where you define when
you want to terminate so you want to
terminate the longest burning instance
probably it's ideal when the termination
policy I want to tell you that this is
when you're scaling down this is when
the CPU utilization everything have fell
below say five percent or even 10
percent and the lot of instances so you
could actually get rid of them and save
cause your scaling policy should know
which one should you determine it so
that's where this policy is important so
it's going to terminate the longest
running instance because you know you'd
have memory leaks and different sort of
problems on the longest running instance
you'd get rid of the oldest level then
the oldest launch configuration so you
have it configurations to launch
configuration multiple configuration is
multiple launch configurations so you
use them you would get rid of the oldest
launch configuration and then the next
is which is closest to the full billing
our billing cycle basically but
important thing is it's going to ensure
that rebalancing of capacity across
availability zones that takes more
precedence than the above ones so that's
the most important thing an intro on
cloud watch cloud watch is a web service
that enables it monitor and manage
various metrics so it's not just limited
to the CPU network and others there's a
lot of metrics that you could monitor
and you could use this to define your
scaling policies
so an alarm is an object that monitors
is ceiling metric so the metric could be
network usage disk usage CPU usage so he
alarmed changes its state when the value
of the metric reaches the defined range
and maintains the change for a specified
number of units next we're gonna talk
about load balancing right ELB so
lb is something I'm gonna put on top of
your instances you can see that on the
figure on the right hand side so it's
autumn it automatically distributes
incoming application traffic across
multiple Amazon ec2 instances
application will have a single point of
entry right so it will you you won't
enter the ec2 instance web page you Pat
enter the ELB cname so it's not an so
I'm going to show you the cname that I
have in the ELB writes then you'd use
your ELB in metrics to scale your
applications so and then this connection
raining so to ensure that say an
application and NS you outer scaling is
planning terminate an instance so it's
kind of date for all being request being
pushed to the ec2 before it even thinks
about terminating due to a scaled-down
request ok so what's the benefit of auto
scaling it automatically adapts to
capacity on demand this we have seen
that in the graph it's gonna grow and
shrink based on the demand so we achieve
that we achieve elasticity he think next
it's not just elasticity right when you
define a minimum number of instances
what I was saying you seeing that these
are the instances that needs to be
available at all time in our example
I'll try killing few instances and PI to
destroy my fee two instances but you
know what the auto speeding is gonna do
it's gonna automatically power on more
and more not more and more more
instances to ensure it's available at
all times so you have fail ability as
well I'm going to talk about
bootstrapping here now remember that
you're building an auto scaling group
you need to do this
when you're sleeping in the ninth you
don't wanna log in wake up and add more
instances this
the traditional living you if you want
to do something where you can
comfortably go to bed without having to
log in and build up some build new
servers or a storage auto-scaling have
to be fully automated so automate
automation comes through various way so
you could use an Amazon Amazon machine
image which is snapshot of your current
application example in in this example
is going to be a web server so if you
could take a snapshot of that and make
an custom Amazon machine image you could
ask you long current configuration to
use your specific ami and build up new
configuration so that way you don't have
to configure your server each time you
build it up so that's a bootstrapping is
quite important then you could change it
bassy MI and install a code and
configuration has needed as when you
need it so you use that via user data or
you could use it by a chef puppet
ansible people also use it by AWS code
deploy so that would be pushing out
these install code and configuration
right so in our example we will add the
following script and this is the script
I wrote so what is going to do so it's
gonna install httpd that is dumb and
basically this is an Amazon machine
Linux and what I am planning to show you
is I'm going to show you the HTML page a
simple HTML page but the key thing is I
am NOT going to log into the server and
do anything I'm not going to login or
install Apache or copy and configure
these files I want to do everything
automatically so the first thing is the
shebang as you must know then I'm going
to install Apache and then I'm going to
update my server so that's the second
command yep yum okay correction there
yum update happens by then I'm gonna use
a s3 Amazon command so this is Amazon's
Linux and I need to have a CLI installed
so this is a CLI command if you're not
familiar with so AWS s3 CP CP is copy
be this is a bucket this is an s3 bucket
where it's stored this is where I've
stored my file you would want to have
create an XP you would want to create an
s3 bucket and store them and I would
copy copy that file to the VAR www.h tml
file the index gets copied there then
I'm gonna copy a health check file as
well to that this is gone the hell check
file is needed for the elastic load
balancer to check the page to ensure
that the instance is indeed running then
last for the last I have a command that
starts the Apache service so this is the
command that I have already written and
finally but this is probably not
necessary I'm going to add the service
to the boot right so this is a snapshot
of what we're gonna do right so why do
we auto scale so when why do we
bootstrap basically because less fingers
less mistakes so we once we have a
texted script and deployed it there
won't be any errors right because it's
all you testing on these and make sure
you don't have any human being coming
and logging in you don't need that so
that's an important thing so you have
self-healing availab option available
using this then you have the patience
you can easily audit and manage your
state so if something goes wrong and I
actually come back and see what's my
bootstrapping slip say so how is it
going what is my shell script that I
have actually written that has told out
of man is this then you could scale on a
large scale deployment so in fact to
give you an example real time a lot of
people use auto scaling every day every
day millions of customers of AWS and you
could I can guarantee that a lot of auto
scaling is happening right now how do
they use they would actually could have
an on-premise infrastructure somewhere
or their web applications and they would
eat even do something like in case my
existing servers in my data center is
running out of capacity
I would use Amazon services and build up
new servers so this is what the
automation comes into play right and
then it's flexible the bootstrapping is
not just limited to shell you could use
PowerShell but on this type of their
cloud formation chef puppet ops works
oops works is the chef applicable in AWS
finally security you are locking down
your instances so no one else can log in
and you actually some of the reasons
where this is there you don't even have
to log into the server and you can you
probably disable all type of logging
right so that's that's about it so how
you're going to plan your auto scaling
group so you did to mine the time it
takes launch and configure this
configure the server right because if it
takes a lot of time to configure launch
and configure probably your web traffic
is still busy right and you want to
match and plan accordingly so and the
most important thing you need to find
out what metric you is the most relevant
to your application demand right so you
you cannot i'm showing cpu usage but
that is not always the case that profit
may be network and maybe cpu as well so
we won't want to monitor one or two or
one metric or more right but you need to
know how what is driving your
applications performance so you need to
know what matrix is the most relevant
thing right next is your existing ec2
instance or ma a.m. eyes you might want
to use as part of your scaling plans
right you know what should I use should
I use a Windows one or AM which am I
should I use so that's something you
need to plan and then how many is that
you want to spread all is auto scaling
group and then the role you want to play
or the auto scaling group for
application remember yeah I've been
talking about web but you could have web
your database your application all in an
auto scaling group and then you would
want to know what kind of roles should
each play in their own perspective right
you have
d be an application one know how tough
should you manage so these are things
you should think about alright some do's
and don'ts you need to use iron rules
I am rules are nothing but identity
access management as a whole form so
what it tells easy to is this is the ec2
instance that must communicate with s3
in my example remember there was an AWS
s3 command to run that command I must
give the privilege to easy to to set up
a relationship basically to read the
data from a string SV is another service
so that relationship is built by an I am
role so that role that relationship
should exist and go keyless if you can
keyless is where he keels
he pairs if you know if you have ever
built an easy to instance you know that
to log into it you need a key so ideally
and if you build an auto scaling group
you should go keyless so that if even I
mean even if someone has a key they
won't be able to log in because the key
was not the key was not defined for
those particular auto scaling then you
need to strike a balance between your
golden image which is your ami and
bootstrapping so probably you you have a
set of servers that's there and you have
build your application already so
probably what you could do will you take
an image of that server the existing
server which has the application and
then in your bootstrapping script so
when it boots up it could probably do an
upgrade and update on the system right
okay then some dunes
don't put your access keys anywhere your
API anywhere don't do not put any of
those keys in your ami or even your
bootstrap tips right lot of talking
let's get on to the demo right so okay
and that's it everyone thank you we want
for joining simply learn webinar take
care bye bye
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>