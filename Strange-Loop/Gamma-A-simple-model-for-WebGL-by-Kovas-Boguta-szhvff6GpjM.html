<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Gamma: A simple model for WebGL&quot; by Kovas Boguta | Coder Coacher - Coaching Coders</title><meta content="&quot;Gamma: A simple model for WebGL&quot; by Kovas Boguta - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Gamma: A simple model for WebGL&quot; by Kovas Boguta</b></h2><h5 class="post__date">2015-09-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/szhvff6GpjM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm kvass Bogota thank you so much for
coming I'm excited to talk to you about
gamma gamma is a closure script library
for WebGL with the emphasis on
composition and simplicity we showed
gamma done with some stuff
this is also an ideas talk regardless
what programming language you use
whether you even use WebGL
I hope that this talk gives people some
ideas for the next time they confront a
domain in which composition seems to be
difficult to to get to so we're gonna
start off talking at a very high level
about the problem that gamma is trying
to solve then we'll pop open the hood on
WebGL and take people look at the causes
and consequences of that problem then
we'll move into the solution that gamma
embodies and do some demos so the
problem gamma is sorry graphics graphics
programming is a little bit more extreme
than some other domains and this need to
experiment and iterate well that's
basically two reasons one the result is
subjective does it look good
varies from application to application
you know if it looks good you actually
have to do the experiment there's no
kind of shortcut to that and you also
need to iterate quite a bit because the
solution space is just vast
you know just graphics is always
evolving countless methods that keep you
evolving the developer has to contend
with a very big solution space that they
need to iterate through to get to the
trade-off point of performance and
quality that they're looking for for
their application now computer science
software engineering there's this huge
body about abstraction and reuse that is
intended to let us iterate quickly right
but let's face it in graphics
programming the promise of these tools
does not match the reality graphics
programming is like 2001 except you get
to choose which monolith you spend the
rest of your life with right like the
field is completely dominated by
graphics engines and these things do
everything behind that nice you know
beautiful exterior it's like shaders
state management optimization algorithms
3d math
loading and as long as what you're
experimenting and iterating on remains
within the bounds of the monolith you're
good but as soon as you want to do
something fundamentally new some actual
experiment and what you need to do some
actual graphics programming it's sort of
like your back - banging bones on bones
because there's not an ecosystem of
small composable libraries that you
could lean on when you just want to
remix things in a different way that's
really the fundamental problem I'm
trying to get out with gamma is this
lack of composition at the bottom of
graphics there's one thing I want people
to take away is that composition in
graphics is an unsolved problem and it's
an important problem not because if we
solve it the existing players will
benefit but if we could solve
composition this will open the door to
graphics to the broader world of
programming all these people who are
interested in graphics want to get into
the graph into graphics but they can't
because when they look in the field they
see this alien universe where the normal
laws of the universe don't apply you
know instead of using their higher-order
functions or monads or whatever it's
like let's just pile if-statements on
top of each other so we want to fix the
composition problem to make graphics
programming more accessible more
productive and easier to experiment with
all right let's let's pop the hood open
on WebGL and see exactly where the
problem is coming from and and what the
consequences are for the uninitiated 20
models of WebGL there's the CPU and
there's the GPU CPU does two things
puts in the shader program the GPU and
it puts data into the GPU memory GPU
runs data flows to the shader
this creates pixels pixels going this
thing called the frame buffer which is
either blended to the screen or recycled
for as data for another pass so these
two things the shader program and the
process of putting the data on the GPU
are sort of the two fundamental sources
of complexity that the wort composition
and these are the things that we're
going to try to fix but let's take let's
take a closer look at them first so
shaders shaders as as many of you know
are written in the language called GLSL
GLSL is extremely prim
pretty much for its composition at every
turn almost nothing in the way of data
structures almost nothing in the way of
polymorphism you know they notice no
import statement you can't there's no
sort of standard way to have some
library of functions and just kind of
import functions into your shader input
and output is done through global
variables
there's no way to pass functionality
into the shader and there's no way for
the shaders to delegate functionality to
somebody else really primitive stuff and
if you're writing one shader maybe
that's okay but you know an application
you might need dozens of shaders doing
different things and those shaders are
going to share logic in an ideal world
we'd want something like this right we
want some new shader and say we're gonna
call it f we have some existing pieces
lying around called gmh that do part
each do part of the job we're just gonna
stack those together and get our new
shader right unfortunately this is not
how it works there's just not enough
there in the realm of shaders to let you
programmatically compose shaders and to
new shaders or programmatically compose
their pieces into new shaders but people
need to do this so what do they do so
there's a variety of approaches by far
the most common is to say okay we're
going to have a bunch of shader
fragments maybe as files on disk or
something and they're each gonna do some
part of the job and for a given task or
for a given shader we're gonna pick the
fragments that we want and just stream
join it all together right just mash it
all up and this might be expedient right
but this is this is not composition it's
not composition if you have to plan in
advance so that assumptions can line up
in the future and this kind of non
composition or pre compositional state
has real consequences for product
development it's hard to improve the
system if to make some improvement you
have to figure out how to squeeze it
into the web of assumptions and then
make sure nothing breaks it's hard to
prototype if you have to plan in advance
which variations you want to try and
perhaps more subtly the first idea tends
to get inside and sewn so I started
building my system I had an idea for
some artisanal shader factoring strategy
your two goes by and we realize this is
not
white way to do things but now this
thing's just like too hard to move
there's too many intertwining x' and
that first idea I had was set in stone
and I can't move on to the right idea so
in a bad place with regards to two
shaders second thing this thing of
sending the GL states which I rather
optimistically depicted as the cpu just
putting data into the GPU well when one
does not simply set the GL state right
because you're not just setting the
state it's the whole scape machine I
love this slide the OpenGL machine
complicated from inception and it really
is it's like okay I need to set a piece
of state over here but first I need to
set the piece of state over here and if
you're doing textures you have to set a
piece of steer over here because that
piece of state over here is that a piece
of state over here so it's a real Rube
Goldberg machine and if your if your
code is manipulating that state that
state machine your code becomes a Rube
Goldberg machine this is not something
you can just factor out right okay you
have these operations you split them up
into functions and methods wherever now
you have two problems you have the
problem of the state machine which is
still there your code still needs to
comply with the Rube Goldberg invariants
and now you have you know whatever other
weird abstractions put on top of that
that you have to to chase around and
manage so this is real kryptonite for
composition with the same problems that
I talked about just a minute ago and
putting it all together we can begin to
see sort of the architectural
consequences that permeate the field so
you have these unmitigated sources of
complexity at the bottom now I never
really solved and then all you can
really do is add assumptions at every
layer in the software so you can't
precisely describe what shaders you want
through composition so the layer above
the shaders has to make assumptions
about what the shaders are and it
basically exposes a slightly less big
surface area API to layer above that
that person added some more assumptions
exposes a little bit less surface area
to layer about that and so forth until
you get to the user API which appears to
have a small surface area but in reality
is completely constrained by
this tower of assumptions underneath it
right so the user wants to do something
a little bit different they have to
unwind these assumptions potentially all
the way down to the bottom squeeze their
thing in obviously interoperability is
not going to happen you know you have
your another you have your other
assumption pyramid over here and these
things are just not going to line up
right this is this is how monoliths grow
so to solve the problem we need to solve
the problem at the bottom with shaders
and state so let's do this
gamma the basic idea here is the minimum
composable system you know we're not
chipping asset management
we're not shipping 3d geometry libraries
none of that stuff the only thing we
care about is taking the WebGL API and
making the smallest possible change to
it to recover the property of
composition we want to make as few
assumptions as possible so that gamma
provides a awesome platform for you to
build your own graphics abstractions if
we want to make place the fewest
possible constraints on what that what
those abstractions can be the basic
strategy we're going to use is we're
going to meet on data so we're going to
take those low-level API s make very
small changes to them so that we can
represent them as composable data
there's basically compilers that take
that data and convert them back down to
the actual API but as far as the user
concerned the only thing they now need
to do is to generate data and this is
like the easiest thing ever right like
you know you can generate it yourself
you can use libraries to generate it you
can stack the libraries on top of each
other you can call in to any level of
this chain of abstractions you want you
know constructor functions generating
data is a very very good place to be in
terms of composition so let's let's go
into shaders as I alluded to we're going
to represent the GLSL ast as data and
we're going to use vanilla closure
programming to build up that AST which
means we get to inherit all the
compositional properties of closure
right functions multi methods protocols
all these data structures whatever
closure has compositional mechanisms we
get to use them we're going to compile
that to GLSL
now the the discerning listener will be
like the sounds like metaprogramming
like but isn't metaprogramming like the
least simple and least compositional
thing we could imagine you know this is
this doesn't sound like vanilla
programming well it turns out that the
simplicity of GLSL actually comes to our
rescue here because we can we can we can
sort of constrain our thing to a form of
meta programming that doesn't suck in
particular if once you get rid of things
like variables and scoping and
assignments mutability if you if you get
rid of those meta programming actually
becomes extremely easy and simple and
the reason why we can get rid of those
is because well shaders are actually
functions there are actually almost
entirely pure functions which means that
the the thing that the shader computes
can be semantically represented by a
referent referentially transparent
expression right you know any value can
be replaced with the expression that
computes in and vice versa and this
means that we don't need intermediary
variables we don't need mutability or
assignments any of that stuff we can
just pass these ast fragments around
proliferating them to where they need to
go and lean on the compiler to factor
them out at the end of the day right so
oh this is this a little bit abstract so
we're gonna we're just gonna jump into
the demo and I'll show you how this
works but the bottom line is
metaprogramming becomes like normal
programming
alright enough talking let's let's do
some demo okay great
okay so my first shader so as I
mentioned we're gonna represent let's
see here we can okay I think that's good
we're gonna represent the shader as data
now it's a little bit inconvenient to
just type in raw data structures all the
time so the primary API is constructor
functions if we want a attribute GLSL
actually be variable we have attribute
function we passed the name we passed
the name we passed the type and what we
get back is a hash hash map representing
as data GLSL actually be variable
likewise shaders are represented as data
we have a triangle shader it's a hash
map as vertex shader and has a fragment
shader each one of those shaders is
represented again by a hash map that
whose key keys represent one of the
outputs of the shader a shader can have
multiple outputs and the value is the
ast fragment which you know when it runs
gets assigned to that output so the
vertex shader is simply going to take
the attribute and pass it along as the
output to the built-in GL position
variable and the fragment shader is just
going to take the constant read and
assign it to the built-in GL frag output
which sets the color of the thing so we
have our shader here it's again just a
big data structure we compile the shader
and then we can ask to see the the
actual GLSL string so the the vertex
shader looks like this we have our
attribute declaration main void and
we're just assigning the GL position to
the attribute attribute position thing
likewise the fragment shader pretty
simple we just assign the spec for to
the frag color then we can can run the
thing and run the thing and woohoo we
see a red triangle we can change this
coordinate a little bit just to prove
that it's you know responding to what
we're telling it to so a basic draw is a
utility function that I'm going to
explain in the next part of the talk but
for the purposes right now it just lets
draw the shaders that we're constructing
with some input data okay so we have our
first shader now we want to build
abstraction x' and start composing stuff
so one of the nicest mechanisms of
composition is the function instead of
hard-coding the position attribute and
the color as we were in the previous
shader we're just going to pass those as
arguments to a function which will
construct a brand new shader for us so
the the shader is going to consume as
its argument a hash map with the keys
position in color and those things are
just going to get passed into these
positions in the in the shader so we
have our thing we have our share
function and this is actually not what I
wanted to show right here let's just
grab this guy okay and this is and we're
just gonna print out this thing okay
okay so now now we're calling the shader
function with our parameters for the
color in position we compile it and then
we print out the GLSL right so instead
of pre-baking
these attributes and the color we're
passing it in so if for some reason we
need to change the name of the thing we
just changed the name of the thing that
we're passing down and down the pipeline
right so we change the name of the thing
and we see if the name of the thing has
changed also there's absolutely no
constraint that this thing just needs to
be a constant value we can just start
putting any kind of GLSL ast we want in
that position so okay forget constants
we are going to instead for some reason
we decided that we're going to use a
uniform the color and this is like duct
three right pass a uniform instead and
now in our code a uniform declaration
appears color is in there we're happy
you know we can start building up bigger
bigger bits of AST fragments so we're
gonna say gbr or something this is the
Swizzle operation just some simple
computation
so we parameterize our shader and now we
can just start passing program fragments
that we built up however we want into
the thing and we can get a new shader
that's that's pretty good compared to
squashing strings together okay so for
the rest of this talk or for the rest of
this part of the demo I'm going to use a
particular shader skeleton that's just
going to allow us to quickly explore
coloring the every pixel on the canvas
so what we're going to want to do is in
particular we want to color we want to
color the pixel according to some
formula involving the XY position of the
pixel and so something like this for
example so what we're going to do is
when you need to normalize first we're
going to pop-pop say the x coordinate
out of the GL GL frag horde built in and
we're gonna divide that by the width
because GL frag coordinate basically
scales in this case from 0 to 512 and we
want to rescale it to be between 0 and 1
so we have a consistent basis on which
to build further operations so we
rescale X we rescale Y we return a
closure data structure to contain those
two ast fragments we use a normal
closure binding form 2d structure those
two ast fragments out of there and then
we pass them in to one thing that's
going to generate the Veck 3 which will
represent the RGB values of of the color
that we want ok so that's cool but let's
make something a little bit more
interesting so so we're gonna have
another function the dots function and
with what this is going to do for us is
it's going to compute these two
combinations of sine x times cosine Y
and cosine X times sine of Y again drop
them into a data structure and then we
use a higher order function map closure
script higher order function we're going
to map the absolute value constructor
function across those two things because
sine and cosine vary from negative 1 to
1
but our colors only go from 0 to 1
so we've mapped the absolute value on
there we get a closure script sequence
so start with normalize coordinates call
dots these structure the results again
pass it into our thing oh I probably
thought you ate this thing first
okay now this doesn't do anything that
interesting because we're just going
from zero to one still we're not seeing
the repeated behavior of the thing so
we'll have another little helper
function to rescale after we normalize
from zero to one we're going to rescale
it to go up to 50 and now we see why we
call it the why we call it the dots
function yeah okay okay okay so that's
kind of neat now the grizzle the grizzle
GLSL Warrior will point out that you
know why not just use the vectorized
GLSL functions
maybe this I mean it's cool that you can
you do this higher-order stuff just use
like Clojure script restructuring but
you know this this kind of wolf will
kill and they would be right this is
kind of overkill for this particular
example but I'm doing it this way
because I want to show you one other
thing which is let's take a look at the
source code let's take a look at the
source code that's generated by this
example okay so what we have here is so
this is the normalized and rescaled
x-coordinate this is the normalized and
be scaled y-coordinate and then we're
reusing both of those things in these
two variations of sine and cosine okay
so what happens if we drop G from from
the result well we drop G from the code
right like we're not using it there's no
need to include it in the code this is
dead code elimination and what this
means is your helper functions do not
have to care about how they're used by
the shaders above it so they can return
a bunch of results you know you can have
some infinite sequence of like shaders
being generated by by some helper
function and only the one only the stuff
that you use will end up end up being
encoded into the compiled shader another
thing that happens is okay let's let's
say
you are twice what's going to happen so
if we use our twice it's in fact going
to detect that and insert an
intermediary variable to just contain
the value of R and then we include that
value twice in the output so this is
common sub-expression elimination and
this is actually the key thing to
getting this thing to work right this
bit this is right it's like what's
what's the result
what's the result of this just this dots
function right it's like you know this
huge pile of like ast stuff but what we
want to do we want to pretend it's a
value use something like a let some
binding form and then replicate it to
wherever we understand that that value
is going to be needed and because we're
doing common sub-expression elimination
this all works out because the compiler
will then notice it's a happening
multiple places and just do the
transformation necessary to make this a
plausible thing okay so let's let's move
on to some more interesting visual
result here we can make a circle
function so past the the coordinates of
the fragment past the center coordinates
of the circle and the radius and it'll
just return 1 or 0 depending on if the
thing is inside or outside of the circle
that's cool but it's it's a little bit
more interesting if we map map basically
the circle across our dots function so
we're going to say the center of the
circle and the radius is going to come
from the dots function and now we have
something a little bit more interesting
and that's sort of a final final demo of
this section you know we can make a
couple more tweaks and get a somewhat
interesting animated shader that does
something non-trivial and somewhat
pleasing depending on your point of view
so ok yes
all right so where have we landed here
okay instead of a artisanal system our
method of composition and abstraction is
called closure script it's pretty good
you should check it out we can easily
define reusable bits of logic and stack
them together to explore the spate the
design space we don't need to make
assumptions because we can just put
parameters in at the top and let them
flow through the system and sort of just
as a programmer organ ahhmm exported
view and a reasoning point of view we're
manipulating programs as if we're just
manipulating values it really is quite
simple intuitive and easy so we're in a
much better place with respect to with
respect to shaders now somewhat more
challenging scenario composing these
state operations oh dear let's let's do
it so we're gonna we're going to do
three moves that basically get us to a
better place we're going to reify all
this global implicit state into a
package that we can explicitly pass
around we're going to specify the
configuration aspect of that state which
is sort of the wiring or the plumbing of
how the objects relate to each other
that's going to be immutable data and
that's going to be kind of the core of
how this all works and finally we're
going to need them we're going to need
to operate against the model of GPU
state I mean it's insane to try to
operate directly against the GPU we need
we need sort of an intermediary which
keeps track of what we've done to the
GPU so far and when we put in a new
specification it's going to conform the
GPU to whatever state we specified based
on wherever it's at at the moment so the
low-level API is something like this you
might want to do something like draw
arrays takes three arguments this looks
pretty easy right well in fact there's
an enormous pile of implicit state
hiding behind that very simple call I
have to set the program
I have to set the frame buffer have to
set which vertex attributes point to
which array buffers and you know there
could be a bunch of them you have to set
all the uniforms if you usually textures
you have to bind the texture you want to
bind the texture you have to set the
active texture there's just this huge
pile of implicit state so what we're
gonna do is I'm going to take this pile
of implicit state reify it into a
concrete object and pass it directly as
an argument to our draw a race call so
what this means is different draw ray
calls are no longer going to have an
opportunity to step on each other it's
just no longer possible right you have
all the information you need right there
and you you know if you need to add
another operation sort of in the middle
of this week sequence or at the end you
know no one's the wiser next thing we're
gonna do is if you look at the state
there's actually two kinds of state
there's the state that the shader
program actually sees sort of the data
and the array buffers or the data and
the textures and the uniforms and so
forth and then there's just this pile of
plumbing information you know what are
the you know what texture unit is bond
to which texture which array buffer is
bound to which attributes what's the
current frame buffer what texture is
that frame buffer connected to what
render buffer is that texture connect
that that frame buffer connected just
like all this wiring information and
this part we want to specify is
immutable data so well the situation
that we want is the configuration is
immutable you might have a few of these
configurations they're immutable they
never change and then you have data
that's flowing through them which is
sort of the runtime data for the shader
so we can call out to these different
configurations without them stepping on
each other while passing while passing
the different runtime values into the
shader program but we still we still
need a way to execute this GPU plumbing
and that's where the model comes in I
don't have a lot of time to get into the
details of the model but point being
everybody ends up needing a model of the
GPU state because the GPU is a black
hole you can't kind of ask you what its
data is and expect to perform so we
modeled the GPU
and it it and this and we expose a data
oriented interface to it so that no one
who writes code against the Gama API
ever has to deal with runtime objects
that contain or expose GPU state
directly this is sort of how we prevent
the contagion so kind of the the
resulting picture is something like this
we have a draw erase constructor we
passed the model we passed the GPU
plumbing specification and this compiles
down to a draw arrays object we call
exact that's part of the API with the
runtime shader data and something
actually happens now sort of a subtle
but important point here is in the
process of draw arrays running its
constructor and creating this object
this is our opportunity to sort of pre
compile pre-optimized initialize
allocate etc etc because we don't want
to pay the price of transforming this
immutable data specification which isn't
going to change over and over and over
again with every draw call why not have
an opportunity to just unroll at once
set up some very efficient non
allocating operations that cause that
state to happen and you know just be
able to call it quickly over and over
again so that's that's sort of the set
up there and how the api ends up shaking
out is you have a bunch of data
constructors which are similar to the
GLSL stuff they just generate data
they're you know you're not containing
any runtime objects in there and then
you have these operations which are also
which which which involves
specifications involving the data
constructors but when executors will end
up changing the state so the bottom line
is no more hidden state no more
interactions specification can be
abstracted using simple data and we're
agnostic to data formats caching
strategies etc by way of the pluggable
model and that will let you hit these
different positions in the in the
trade-off space so let's let's show a
little bit about how that works
okay yes so so what we want to do is
first I'm going to show you so I'm going
to show you how this basic draw function
works and then we'll move into a
slightly higher order demo so the
purpose of basic draw is to consume some
shader that we just constructed and just
provide us something that can draw
actually execute it and draw it to the
screen using some very simple
conventions so I'm not I'm not going to
step through every line here but the
point of point of this is this function
saves you a ton of boilerplate but it
itself remains transparent so if any of
you have seen these sort of like WebGL
tutorials online it's like the first
thing you'll notice is no one is using
the actual WebGL API everyone has a
bunch of helper functions that like wire
up a bunch of stuff and then you're like
looking at this tutorial but you're
trying to understand what's happening
but it's like all mutable and it's you
know it's like do I need to call this
one first or do I need to call that one
first like what order can I call them in
how do I add something in like what's
built in what's not built in like what's
the convention here so this function
however is based only on transforming
immutable data so it's very easy to just
pop it open and understand what the data
flow is and change that data flow if you
need to so just to kind of walk through
here a little bit so we can get the
inputs from the shader and get all the
attributes on that shader for every
attribute we're going to create an array
buffer and we're going to turn turn that
into a hash map of sort of attributes to
array buffers for each array buffer we
also want to construct a operation that
will allow us to put data into that
array buffer and then and then we
construct the draw race call so we get
the model the program and the frame
buffer from above and then all we need
to do is to create this specification of
how to wire the attributes up so the
actually wiring specification is
basically we want to say the name of the
attribute and we want to tell it which
array buffer to use and what layout to
use
the layout looks something like this
it's like these all these parameters
that you have to pass into the API about
sort of where in the array buffer to
find the attribute and in basic draw
we're just making the assumption that
there's gonna be a one-to-one
relationship between attributes and
frame buffers so this is just a very
simple scenario and but if you want to
make a more complicated topology I mean
it's all the same principles you just
figure out what you want pass it into
the right places and call it a day when
it comes time to execute the thing so
we've closed over draw arrays we've
closed over a bunch of these or buffer
data calls so we just pluck we just
pluck by attribute by attribute name
data out of the argument stuff it into
the buffer datas and we also call the
draw that we've constructed and that's
it not not very complicated so let's
show you something a little bit
different so the place the place where
the place where we want to be is in this
namespace let's see
okay so we can continue this process is
sort of constructor based wiring of your
graphics pipeline up to a higher level
so what I've done here is I have
encapsulated this this interesting
shader that we made into a into a
construct implementing exec and I also
have on the side have created another
program that just draws a cube and that
thing that draws a cube expects a
texture and we're going to wire these
two things up together via a frame
buffer so we have a sort of frame buffer
constructor function given a width in
the height it constructs the frame
buffer with a certain kind of texture at
the color attachment and a certain kind
of render buffer at the depth attachment
so we can evaluate this and just show
you what that looks like and then we can
pluck the texture out of that frame
buffer and combine it with the texture
unit since most accesses to texture have
to go through a texture unit and then we
make something that initializes the
texture and then we make something that
we're gonna we're gonna draw the fancy
shader to a frame buffer which means
it's not going to be drawn to this
screen and then we're going to draw the
cube with the texture coming from that
frame buffer now that's that's basically
at this bit right here so if I were to
say change this parameter yeah okay yes
a cube a cube with that thing as the
texture so you know this yeah okay so
let's just animate this thing and okay
this is pretty cool right we can just
like take take things that we defined
ahead of time these things do not know
anything about each other and then for
them to interact we construct some stuff
at the next level up and just pass that
into those two things so this is a very
easy data flow to think about as opposed
to like someone in the distant past
constructed this object and now I'm
going to bang on it so that sometimes
distant future somebody else can pick
that thing up and you know have its
values be there so this is this is
composition and I mean I think that
there are some parts of the system that
the design is still a little bit up in
the air but the general principle of
component saying we're going to do the
configuration as data and then just kind
of pass all this stuff down through the
system while allowing opportunities for
optimization and parameterization and
plugging in sort of these very specific
application specific details I think is
a powerful way to go so that's it I am
Kobus be on Twitter Corvo stop Bogota at
gmail.com check out check out my github
I'll be posting most of this code
probably over the weekend and a lot of
these talks finish with we're hiring I'm
actually looking for gigs so if anyone's
interested don't be shy thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>