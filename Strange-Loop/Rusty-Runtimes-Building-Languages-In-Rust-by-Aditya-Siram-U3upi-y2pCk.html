<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Rusty Runtimes: Building Languages In Rust&quot; by Aditya Siram | Coder Coacher - Coaching Coders</title><meta content="&quot;Rusty Runtimes: Building Languages In Rust&quot; by Aditya Siram - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Rusty Runtimes: Building Languages In Rust&quot; by Aditya Siram</b></h2><h5 class="post__date">2016-09-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/U3upi-y2pCk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my talk is on rust so rust is
marketed as sort of this systems
programming language it's got zero cost
adds directions it's got no runtime this
kind of thing but I don't see it used as
much for language development so si has
kind of proliferated this area but I
don't see a lot of uptake with rust and
I would I would have thought that that
would flourish in that area so this talk
is sort of an exploration of using rust
to do language implementation in this
case a simple Lisp and also using rust
as a compilation target so this compiler
is written in rust and it outputs rust
and the compiler will then take that and
compile that into a native executable so
just a little background on me I come
from sort of an ml Lisp background so I
am an I'm program I'm programming
language fanatic I've used hundreds of
different programming languages over the
years but I've never actually designed
or implemented one myself actually I
take it back I implemented a lisp in
Lisp and that's cheating and that
doesn't count and I also have very
little low-level knowledge so I mean I
can't really speak intelligently about
the difference between x64 and armed or
undefined behavior in C or all of those
other gotchas that you have to sort of
overcome in order to do any kind of
low-level development and most of my and
most of my experience has been mostly in
garbage collected business apps
but that low-level stuff is really
interesting to me it was just really
intimidating until sort of rust came
along and I liked the fact that has a
lot of ml influence the pattern matching
is very much derived from ml in fact it
goes beyond ml into racket macros
actually not record macros but pattern
matching which is pretty cool and it
also has this emphasis on immutability
more to the point it has it has it has
an emphasis on managed mutability which
is the other side of the same coin which
is I think a nicer way of saying it and
actually that bullet point about easy to
learn that's total BS I think it's not
it's
when I wrote that I had something in
mind it's not easy to learn rust rust is
a difficult language to learn but I
wrote that when I wrote that what I had
in mind was the fact that a lot of the
type system vocabulary a lot of the
things that rust brings to the table
borrow checkers traits things like that
have a shared vocabulary with languages
that I understand like Scala and Haskell
so knowing that vocabulary from that
side of things allowed me to onboard a
little more smoothly onto rust so that's
what I meant when I wrote easy but it is
not easy so that's please ignore that
some and it also has a very mature meta
programming model which I didn't expect
right down to hygienic macros and more
and we looked we'll look more into that
in a second in fact in a lot of ways
it's better than lisps but just a word
to the wise when I first started
learning rust six weeks ago by the way
the first the first few weeks were
really really frustrating because the
thing look like an ml right and I tried
to make it in ml but it wouldn't turn
into an ml and like after I just
accepted the fact that it's an
imperative programming language and I
just went hog-wild with like four loops
and while loops with mutable counters
and things like that
rust actually became a lot nicer of a
language to work with so it's got a lot
of ml influence it's got a neat type
system but the end of the day it's still
an imperative language so just work to
the vise so the list that I'm going to
implement is called calendar it's a
pretty Lisp looking Lisp that's a
function that takes something and adds
one to it adder and it's also schema SH
in the sense that its tail call
optimized so we have to deal with that
so here's a function that gets the
length of a list by recursing down the
list and just accumulating the number
right so that's a very schema SH way of
doing things as opposed to like using a
for loop or something like that but one
of the unique things about K lambda is
that it's curried by spec so currying
means that say you have a function that
takes like n arguments if you only give
it a couple of arguments then it holds
on to those couple it holds down to that
couple of arguments
you can pass that around as a closure
and give it the rest later
that's what curried means and kale and
and mandates this so in retrospective
this is the V worst part about this
implementation the most challenging part
about this implementation had to do with
dealing with rust and current because
rust and closures do not get along let
me put it another way low level
programming and closures do not get
along because there's a lot of stuff
that's in scope and all of that stuff
has to be managed by you now since
there's no garbage collector or by the
borrow checker yelling at you and you're
doing what the power checker says also
it's tiny it's only a couple of pages
and the nice thing is yes it has a spec
which means that there's other
implementations of it and I can test my
rust implementation against sort of like
a I don't know a ruby implementation if
they give me the same thing then you
know there's a chance that what I did
was right
so parsing calendar so when you parse K
lambda you can you can stick that you
can stick the parse into some of these
token types some of them are fairly
normal for a list but you have a symbol
which is a string you have a number
which is an integer or float or just a
plain old string a console which is all
of those in a vector right and this last
thing called recur which is a marker for
tail call recursion which we need later
to optimize tail calls so when I first
started doing parsing I decided to use
nom and why did I decide to use nom
because I googled how to parse things in
rust and nom nom came up on top and it
seemed to have high github numbers and
also I looked at the API and some of the
and a lot of the function names were
like things that I'm used to like you
know many zero and many one and taken
till and like you know all of these
things that I'm used to and like parser
company - like parser Combinator
libraries and like Haskell or scalar or
whatever so I was like okay I can get
anonymous this is fine and as I got in
on it I realized that all of these
parsers Combinator's were just macros
within macros within macros within
macros so my first introduction to rust
was that writing macros which I don't
recommend as an introduction to rust so
here is a macro called named that
generates a function called KL string
that outputs something of type token so
it's going to take a string and marshal
look into a token so it uses a sub macro
called chain which has further sub
macros inside of it so chain takes a
character parser macro parses a single
quote parses things inside of that
strength and then parses the end of the
end quote over there and then Marshalls
Marshalls all of that into a string the
innards is another piece of magic that
uses this like the macro called escape
to magically escape all of these like
you know slash you know slash slashes
and things like that so there's a lot of
just magic happening here and my first
couple of days when I was writing a few
parsers I was like I don't really know
if I want to continue with this library
like if it's going to make this much use
of macros and I don't really know rust
as it is and now I have macros out
putting piles of rust like how am I ever
gonna like get anything done right but
as it turns out rust macro debugging is
really nice even compared to lisps so
there I've screwed up the kale string
macro and for a character instead of a
character I've given it the string low
and the type checker actually tells me
that the error is in the macro not in
some like generated code right and
that's something that I'm used to from
like dealing with lists lisps and things
like that is like not that the list has
a type checker but like if there's ever
like a a runtime error if it's pointing
to like the thing that's the generated
pile of code which is really hard to
debug and this by the way makes macros
totally practical for like everyday Russ
development if you have some boilerplate
just boilerplate it away in a macro
you're not accruing that much technical
debt as you would with other languages
so I just wanted to throw that that's
just a shout-out to Russ developers for
doing this right in my opinion
so parsing a symbol is only slightly
more complicated it uses that chain
parser again it parses one of a number
of characters like a tooth Bay through Z
or something like that and then the
remainder which is one or more of digits
or characters that's what many zero does
and that's what all does all alternates
between the two parsers again the names
if you're not familiar with them are
chosen from parser Combinator libraries
written in Haskell or a scalp so again
there was a sort of like like like like
name consonants that I was able to like
take advantage of when doing all this
and last block over here just grabs all
that stuff as a vector joins the vector
together and marshals it into a symbol
so parsing an express expression is not
that much different so an S expression
is just a thing within the parens right
it's like the function and the arguments
that go after it so when you parse a an
S expression you again use chain parson
open parenthesis and this Combinator
called many 0 until the reason I'm
showing you this is not because it's
complicated but because this is the
parser that pulled the veil back on this
illusion of sort of functional
programming parser Combinator things
because I had to write that parser
because it didn't exist as I wanted to
on an on a P I and I had to write a
macro and once you write that macro
there's no looking back and thinking the
rust is a functional programming
language because it looks kind of like
that so that's that's a little
terrifying if you've never seen
something like that before but if you
look at it it's I look a little further
it's actually not too bad
so macro rules is the thing that
generates a macro so I have many 0 until
and macro arguments are passed in as and
pattern matched so it's saying given
some input expression and a stop macro
which is sort of stopped when you see
like the end parenthesis and the sub
macro which is like do this to keep
going the rest of it is just standard
looking Rus code with like those things
voiced in different places and it's just
that easy to write a macro like you
don't have to like know a whole
different language you have to know a
little bit more syntax but not a whole
lot more
so now that we've parsed our list we can
marshalling that into the sort of
internal representation of this list so
we have tokens and this is how they look
once the tokens are turned into
something that can actually be
interpreted and run so we have an
element a lot of these are the same
symbol number string a consul but what I
want to concentrate on is this closure
token right here because like I said K
lambda is curried so we lean heavily on
closures for just about everything and
like I said that makes the
implementation quite a bit more complex
than it could have been if it wasn't
curried correctly and also this recur
thing which we need for a tail call
optimization later on so here's the
closure so by the way everything and all
of our list data types are reference
counted because there are no immutable
data types in our list so basically once
you're done with them you can just drop
them so you know I don't need to worry
too much about garbage collection which
is quite fast so the KL closure has
three variants feeding feed me means I
am a function I'm accepting another
argument and I'm gonna get hand you back
another closure so if this models the
whole you know I have more arguments
coming I'm not done yet
thunk which is a special case because a
lot of Lisp forms are special forms that
don't follow like applicative order
evaluation so for instance if you like
so in a standard list form when you pass
something into a function you evaluate
the argument and you pass it in but you
can't do that for an if right so if you
can't evaluate the if branch and the
else branch before you pass it into an
if otherwise you'll have problems you
have to wait until the predicate is
either true or false so for that we use
thunks and finally we have done that
means I'm done here's the final value
which is either a sum something or
nothing or an error so a case where it
could be nothing is if you're you know
writing something to standard out or
something like that so here's a you know
here's us using that abstraction to
write a primitive list function so our
Lisp needs a bunch of primitive
functions in order to bootstrap itself
so in turn is a function that takes us a
string and turns it into a symbol so in
turn is a function that's outputting a
closure right so it is using feed me
which means unexpected one or more
arguments and inside of that feed me our
Seenu creates a new reference count
itself inside of that there's a closure
that accepts the string and inside of
that your met your destruction dead
string extracting it and putting it into
a symbol there's a whole lot of
accidental complexity here unfortunately
so in essence all this function does is
take a string and stick it into a symbol
all of this does that unfortunately so
where this makes more sense is if you
have a function with more than one
argument and that's what this is so
pause is a function that given a string
at a number just hand you back a
character at that index right so same as
before we start with a feed me meaning
we're accepting more arguments and we
have a reference counted closure that
takes a string but inside of that we
have another feed me because we're
accepting two arguments but that closure
requires a move keyword in front of it
right there why does it require move
because this is what is telling the
rustboro checker that i'm going to be
capturing something inside of my
environment and then you have to
explicitly capture that thing inside of
your environment so that's where I'm
going let's trinkle string clone that
means i'm cloning the string from like
the outer function by the way cloning
here doesn't mean I'm copying the entire
string because they're all reference
counted all that means is that I'm
bumping up the reference it's all that
means so it's a cheap operation so but
you still have to do it you have to
manage these things yourself and then
your D structuring the string and then
you're pulling that character out of
that string so here's an example of
using the and so and here is another
special form because it needs to take
arguments that are unavailing thunks to
do that so it needs to be unavailing as
false then the whole and thing like
short-circuits and hands you back false
it should not like evaluate the second
argument so I've deleted all of that
feed me and like reference counting
stuff and so it takes
a thunk and a B thunk moves the a thunk
into the B thunk closure using a thunk
clone forces that thunk which is just a
simple function that I haven't shown you
which gives that thunk an empty set of
parentheses and gets back an element and
then pattern matches on what you just
forced if that thing is false know it if
that thing is false it's just false if
it's true then force the second thing so
this is an example of using thunks that
we've seen before and then everything
goes into this global mutable table it's
rust doesn't really like you making
global mutable variables so it makes the
syntax kind of hard to do it but you can
do it this way so thread-local as a
macro that allows you to that allows you
to declare something in a static
lifetime aesthetic lifetime means it's
available for the rest of this program
it'll never be dropped and a variable
called function underscore table that
has a ref spell and a ref cell is
something that allows you to have
intuited mutability that means that a
thing inside of a ref cell can be
mutated over time right so instead of
that ref cell we have a hash map of a
string going to a closure so what that
is is just a list of all of our
functions that we have so in order to
bootstrap our system we fill in the
function table right and we borrow the
function table immutably using this like
would construct and then we insert
position insert and and insert a whole
bunch of other things that we need to
sort of bootstrap this Lisp you know
cons tail had all of this stuff and then
when we invoke this in Lisp code it just
goes to look it up it looks it up in
that function table this time not
borrowing it muta bleah but just
borrowing it right and then it gets the
function and it either returns the
function or it doesn't if it doesn't
find it so bottom line a function an
expression like cons 1 nil which is just
a singer
element list right outputs of this rust
code right here so like the compiler
will output this rust code where it says
function apply and function apply is a
wrapper around looking up something and
in that function Table one and you know
applying some arguments to it so go get
me a function a closure matching cons
and then give it a reference counted
number one and a reference counted empty
cons and then hand me back a new cell
would hand me back a new cons with one
thing in it and if that's okay go ahead
and clone it if that's bad go ahead and
propagate that air things unfortunately
get a lot more complicated when we're
looking at Lutz and lambdas so in K
lambda a let can always be rewritten as
a lambda so here we're assigning X to
one and then we're adding X and X
doubling X right so that translates to a
lambda where lambda that takes an
argument X and adds it to itself and
then a plot and then is applied to one
right that can't those two you can
always be rewritten that way but this is
the outputted code it is unfortunately
complex and I don't know the way around
it so here I have a function called
apply lambda that takes something that
we that looks a lot like what we saw
before in the primitive functions it's a
feed me data type inside of which we
have a reference counted closure that
uses the move keyword because it might
capture something in an outer function
and then it makes a wholesale copy of
whatever is inside of that reference
count itself and the reason we have to
do that will become clear in a second
it's not a great reason it's an
unsatisfying reason but the reason we
have to do that will become clear so it
makes a copy of that then passes that
copy to the plus where we're adding the
two things together and then way down at
the bottom it passes in that one so why
do we have to do that copy it seems
wasteful to do a wholesale copy of like
a whole string or something like that
and the reason is the rustboro checker
so let's get rid of some complexity and
look at
the complexity we want to look at so
here's where we're applying the lambda
and we move and we move like the
environment into that X closure and the
reason we're doing that is because when
we want to copy it right when we move X
into a sub closure that X has now gone
away so for instance here's a let we
assign X to 2 and then we do x times X
and then throw away the computation just
return X so here X is being used in two
different places it's being used where
you multiply it with itself and it's
also just being returned so we need X
the X to be accessible in two places and
that's where the complexity comes in so
here we have all of that accidental
complexity and here we have the
accidental complexity we want to look at
so what that B compiles to is a closure
that copies X and then moves X into y
because that's where X gets doubled and
the problem is that once X moves into y
it's no longer available like the
rustboro checker says once you move that
into this closure once this closure goes
out of scope I'm going to drop it so any
further uses of X are invalid at that
point so that's why I have to do a
wholesale copy and then in order just to
reuse it down here and a whole portion
of the the complexity of writing this
implementation had to do with making
sure things were copied correctly and in
fact it does a lot of copying that it
doesn't need to do because it doesn't do
a whole lot of static analysis this is a
fairly naive implementation so on the
tail calls so tail calls are so here we
have a function length where there's a
tail call down in the second predicate
action pair so length is so what we have
is a path down to the tail call so what
we maintain is a number so 3 2 1 so
count down to the
third element starting at zero defund
lying the args list and the con that's
three to is the second argument second
predicate action pair and one is the
length so that's how we detect it we
walk down of est and find the recurrence
this is what that ast looks like in in
rusts code in rust datatypes there's a
lot it's a lot more verbose but the but
the underlying structure is still the
same so there's the tail call away at
the end and when we go ahead and mark
this tail call we use that recur data
type that we that we defined way in the
beginning so we get to the tail call we
mark it recur down the fourth line over
there but keep the arguments right so
now that is a marker telling me that at
that point in the code there is a tail
call that needs to be optimized and we
have a similar till we have a similar
data type on the on the internal side on
the internal data type side that's just
also called record but instead of a list
of tokens it keeps a list of elements
and now we add that now we add the
trampoline to the function so what
happens is that we have a standard
closure that we saw before it takes an
accumulator and interior closure takes
the list but now we have a trampoline
that takes the accumulator and a list
and generates all of the giant like rust
code inside of that trampoline but at
the point where it would like call
itself it returns this recur data type
and it applies all of the functions like
if you're going to add one to a number
or something it happens right there
sticks it all back into the recur data
type and then returns it okay now we
have underneath the trampoline we have a
while loop so we have a flag that
signals when something is done or not
like are we done
recurring or not and then we have
initial set of arguments which is the
set of arguments passed in and in the
while loop we just keep passing those
arguments to the trampoline until it is
not a recurred data type anymore because
that point means it's done and then we
unwrap it and that's how we get tail
calls it's and it's not the most
efficient way of doing it
but it works any questions so far
okay yeah so a trampoline is a function
it's called a trampoline because that's
what it's called
in like programming language theory and
stuff like that it's not really a great
name but it's a function that instead of
a tail call will just return the
arguments passed in so that you can keep
passing them and again and again because
if you didn't do that you would blow out
your stack frames and rust doesn't do
tail call optimization which is which is
not which is not great apparently LLVM
does some tail call optimization but i
was never able to get it to work with
rust so like everything that I tried
like blew out the rustic unfortunately
yeah
it's possible I don't know the answer to
that yeah oh I didn't show you that
piece of code because it simply walks
this con Street so it walks this con
Street and looks for a symbol it looks
for a list where the head of the list is
the symbol which is the name of the
function that I'm in right now and then
it just marks it okay so that's how tail
calls
that's how tail calls are optimized and
it is unfortunately it's it's it's kind
of a hankie way of doing it if you think
about it but it does work so to run some
benchmarks this is like either the best
or the worst part of this presentation
unfortunately so here's a here's a
benchmark where all I'm doing is
building a list of cons I'm building a
list so I'm building a list of a hundred
thousand elements starting from one to
hundred thousand actually Missouri 200
thousand nine thousand nine it's
something like that whatever it is any
case SP CL which is a you know heavily
optimized list list implementation does
it sub-second it almost takes longer to
print it than it does to like actually
do the computation it starts off when
you start an S PCL ripple it starts off
at twenty three megabytes of memory it
just grabs that right off the bat and
when you do this computation it jumps to
fifty megabytes and just sits there and
just sits there and just sits there
forever until you actually do something
so what s PCL does is like it waits
until you hit a certain threshold before
it runs a garbage collection collection
cycle so that's why it's using all that
memory Lua and by the way I use Lua and
this benchmark might be kind of
surprising because it's one of the few
scripting languages that is also tail
call optimized so we're comparing apples
to apples here and some to some degree
not not completely but yeah again
runtime was sub second memory initially
was two megabytes you go into
rebel you get yeah you eat up to
megabytes right off the bat it jumps to
14 megabytes and it holds there again
same thing it's waiting for a garbage
collection cycle to come along dial
which is a scheme implementation its run
time as it takes about a second and a
half 15 megabytes initially up to 18 and
holds my awesome list code takes seven
minutes to do the same thing yeah so I
don't know whether to be proud of that
but here's the thing it used the least
memory of all of them if it holds steady
at five and a half and I know it holds
steady at five and a half megabytes
because it takes seven minutes and I can
actually watch my task manager in like
yep still five stoever so up to six note
back down to five root yeah you know one
of these things all the others I
couldn't observe so like I'm kind of fun
of that and I think that okay so oh and
here's the takeaway I definitely need to
do more static analysis right on the
list code I'm copying things where they
don't need to be copy
I'm cloning things where they don't need
to be cloned reference counting when
you're doing a clone it doesn't have
much of a runtime cost but it does have
a runtime cost so I'm possibly doing
that currying is complex all of my
functions are curried which means they
get arguments one by one whether they
need to be carried or not and the vast
majority of code all function calls are
saturated you give the function
everything it needs for the most part
you don't usually carry around closures
so every function call is paying the
cost of currying that is used by a few
so the way around this I guess is just
to sort of keep two versions of the
function floating around one that takes
all of the arguments and one that takes
one or two of the arguments at a time so
there's plenty of low-hanging fruit and
also please bear in mind I started Russ
six weeks ago so my my rustics I'm not
I'm not writing the best Russ code here
the code generation so yes rust has this
like quasi package that like allows you
to quasi quote Rosco
output that and that's pretty nice but I
found the API too complex so all the
cogeneration is done by strings like
it's great it's just it's just string
handling you straight up you know like
so it's bad and also a generating Russ
code was sort of something that I hadn't
seen too often before so this is where
you generate a very strongly typed
language as sort of the format of like a
weaker type language like Lisp and what
I found was that it was very hard to do
a because I don't know Russ very well
and therefore generating Russ is you
know an order of magnitude more
complexity and B because when you when
you generate something that's strongly
typed the type checker catches a lot of
the errors ahead of time so I think that
that makes it worth it for a certain
subset of applications optimizing less
to make the generated rust on par with
you know like the SPL implementation or
all of this stuff is probably gonna take
a lot more work but I think in the end
that something like that would be worth
it
in my case that's that's all ahead and
I'll take any questions
yeah it spends its time in a lot of
places it's so there's no if you're
asking if there's like one hot spot I
couldn't find one so it spends its time
copying things that shouldn't be copied
it spends its time currying things that
shouldn't be curried so basically like
yeah there's there's plenty of
low-hanging fruit there it's a very
naive implementation at this point and
plus you know it I don't I don't save
things off to like an intermediate so
like if I'm applying a whole nested list
of things I don't like go okay let a
equals this thing let B equals this
thing and then apply ABC and D here it's
all done in line so I don't know how the
RUS compiler deals with things like that
but yeah it was kind of fun trying to
find out yeah so there is a file in rust
projects called build RS and what that
does is it you can arbitrarily output
rusts code into your project and when
you do a cargo build it will just build
all that rust code for you so yeah there
there's a way to do that but I haven't
done that here yeah this is just sort of
a initial implementation yeah
Oh 20 hours yeah yeah yeah rust macro
debugging is nicer than a list-maker
debugging as at least as far as I can
tell and rust uses scopes to like
enforce hygienic macros which is which
is a nice thing to have and a lot of
lisps don't have that schemes do but
alas a lot of lisps don't so that's
that's that's kind of a nice thing to
and also rust actually to a small degree
type checks your macros ahead of time so
if you pass in your few so you're gonna
pass in a debt and identify it and you
pass in an expression it will catch that
at at that time and you don't have to
like deal with it
um the short answer is no like there's
things that list macros let you do that
rust makers don't let you do so for
instance a rust maker you can pass in a
bunch of things with the star at the end
of it so if I go like a star and a rust
maker that means that I have a whole
bunch of things coming but in the list
macro I could take that as a list and
like you know do whatever I want with it
like you know get the length of the list
or whatever but in rust I can't do that
but you can do that if you're writing a
compiler plugin which is sort of I
thought out of scope a little bit but
not completely out of scope for the
project in general yeah
okay okay oh oh sorry I'm not that
familiar with with syntax rules okay
cool okay so he is saying that scheme
syntax rules pretty much implement Russ
does yeah
nope not optimized sorry
just if you got it's got to be a tail
call it's got to have no context and
it's got to have everything it needs to
to just be done after the tail call is
done
yeah I would be nice okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>