<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Lies, Damn Lies, and Metrics&quot; by André Arko | Coder Coacher - Coaching Coders</title><meta content="&quot;Lies, Damn Lies, and Metrics&quot; by André Arko - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>&quot;Lies, Damn Lies, and Metrics&quot; by André Arko</b></h2><h5 class="post__date">2016-09-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pYbgcDfM2Ts" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi thanks for coming this talk is called
lies damned lies and metrics it's about
the ways metrics can be tricky can omit
vital information and can sometimes even
actively mislead you about what it is
that you actually need to know before we
get into that let me introduce myself
briefly my name is Andre Arco I'm on
pretty much all the internet things as
indirect I work at cloud city
development doing consulting for
startups that do Web Apps and this is
kind of like a a bundle of things that I
have learned because we were very sad at
work about discovering them so hopefully
you can learn from all of the horrible
things that have happened to me and then
maybe they won't happen to you if if
that's something that your work could
use help with that is also a thing that
I do professionally so maybe talk to me
later the other thing that I do is work
on bundler the Ruby language dependency
manager which provides like a whole new
set of failure modes for computers I'm
not gonna go really deeply into those
but I definitely have some interesting
stories if you want to hear about them
after the talk so let's start with
metrics um
I guess people who make web apps in
general are kind of usually pretty good
about like at least having metrics which
is like a big step up from where people
who make web apps were when I started in
the field in like the early 2000s and
drop in services like New Relic or like
there's like a whole there's a whole
cottage industry now of like we do all
the metrics you just add this one line
to your your thing and we built a plugin
for your programming language and now
you have all these metrics here look at
this dashboard isn't it great
and that is really cool don't get me
wrong it is way better that is way
better than the the prior state where no
one actually had any idea of what was
happening at any time you could like
tail the web server log and be like I
think a thing happened
this is an improvement and without any
metrics like like I was just saying like
your your information is basically
limited to did is it up did it work
could I see it I can um so that's really
cool and and the the first time that
like how how metrics are really really
useful to kind of like peer deeply into
the the black box of production really
hit home was at github first code
conference back in 2009 coda Hale gave a
really great talk called metrics metrics
everywhere and if this talk interests
you I totally encourage you to find the
video on YouTube and check out that talk
as well but his ultimate point was that
the reason that we write applications
that have customers at least is to
deliver business value and the only way
to know if you're delivering business
value is to set up metrics so that you
can measure it and at least for me
personally in 2009 that was like wow I
never actually realized that that
succinctly before that's a really good
point so at this point I'm gonna go out
on a limb and say you're like yeah yeah
metrics I know they're good so this is
the point where I try and convince you
that you want to listen to the rest of
the talk because it's great that metrics
give you visibility into more than zero
things the problem is the way human
brains work having visibility into more
than zero things means that you are now
convinced that you have visibility into
all of the things and the way metrics
work you don't and so not having total
visibility means that you're gonna be
really surprised and really sad later
when you figure out that the thing that
you weren't paying any attention to
because you didn't have a metric for it
was actually the problem so I'm gonna
talk about some specific ways that
metrics mislead you and mean that you
think you have a much fuller picture
than you actually do and then I'm going
to give some like concrete examples of
things that most people don't realize
are potentially screwing them over but
how would they know they've never looked
at the
so the biggest and I really I don't know
how to if I could like in retrospect I
should have made this like flash and
Blaine can have a rainbow like the
biggest problem with metrics today is
averages when you have a lot of metric
information the easiest like human
beings can't comprehend like thousands
and thousands of actual numbers and so
what do you do well you have to distill
it down to some kind of like aggregate
and well what's the easiest aggregate
well averages is the easiest aggregate
you add them all together and then you
divide them and you don't even need to
like keep track of any of the individual
pieces of information you just kind of
like throw them all in a bucket and
you're like here's the average so for
example New Relic not to like and
historically this was much worse New
Relic has a drop in metrics thing
once upon a time said here are all your
averages that's all the information we
have have a great day
they've improved they actually spent
five years building a like super scary
impressive high-velocity data store that
keeps all of the raw data from all of
your your metrics and that you can query
with like any aggregate that you want or
any time span that you want or any
conditions that you want but the default
view and this kind of pisses me off is
still a giant graph of all of the
averages and the problem with averages
is that brains and averages don't go
together well so brains are really good
at finding patterns this is how brains
see Jesus and toast this is how you see
an average and you think aha I know what
is happening so when you see an average
your brain without any other like
specific input automatically says aha
this is an average and a standard
distribution so this is a normal
distribution or a standard distribution
you often called a bell curve and this
is what happens when every value
is random and that's like a very cool
thing but the problem is the metrics
that you're collecting aren't actually
random like if okay I take that back
if you run random.org your metrics
should look like this but if you don't
then you're not collecting random data
and when you see an average and your
brain automatically extrapolates this
bell curve you are actively miss
informing yourself about what is
happening and that's really problematic
so a giant feature of this bell curve is
that 70% of the values like of the total
number of values that were used to
produce this bell curve are within one
standard deviation of the middle the
average and so brains when they see
average numbers think oh that's what
most of the values looked like that
number and in real life not so much here
is a graph containing made-up results
from real life data based on lots and
lots of real-life data that I have seen
and worked with you're kind of mostly
grouped around two numbers
it's totally uneven so to make it easier
to see how averages can wildly mislead
you let's like stack a bunch of these
together and take a look so here's a
date like here here are all of the data
points from a whole bunch of metrics and
each line with all the ups and downs is
the result of collecting a metric at you
know over a while and the higher each
peak is the more times it was at that
value right so we collect metrics for
ten minutes
and if you got it 25 times it'll be a
higher peak than if you got it once the
small black lines which oh yeah you can
you can see them they represent the
average value for that particular metric
so let me line up all the black marks
for you that represent the average for
each one of these individual separate
metrics so
not only do none of these collected
metrics look anything even vaguely like
a bell curve a bunch of them have
basically zero data points at the
average and so you can see an average
number and think I know what's happening
and then you look at the actual data
underlying that average and you're like
wait wait a second I collected that
number that I've been looking at and
thinking gave me like a representative
view of what was happening that never
actually happened in real life not even
once
and so this is the overall problem with
averages like unless your metrics fall
into a standard distribution and really
unless you're running a randomness
server your metrics are never gonna fall
into a standard distribution your
averages are going to actively mislead
not just you but anyone else who sees
those averages so Wow average is
changing over time can tip you off that
something is going wrong they can't tell
you what changed and they can't tell you
how it changed and those are usually the
two pieces of information that you need
to actually do something useful about it
and so averages are I guess being as
generous to averages as I possibly can
they'll at least tell you that something
happened everything else is now up to
you so let's look at an example of how
that can happen so here is a graph it's
not a real graph but it's very
representative of many graphs that I
have known and based on this line which
is an average there could be many many
events happening kind of in that lowish
range between you know maybe 30 and 150
or there could be 80% of the events
happening in the 0 to 10 range and maybe
10% of the events happening somewhere
off the top of the scale of the graph
you have no idea it's an average cool
so the first way to get useful
information out of a metric that
actually tells you something that did in
fact happen in real life is the median
so to review basic math real quickly the
average also called the mean is every
value added together and then divided by
the number of values the actual average
as a result might not have ever occurred
in real life the median value on the
other hand is the value that was higher
than half of the values that you
collected and lower than half of the
values that you collected so at least
you are getting a real-life value that
is smack dab in the middle of everything
that you saw happen so here's the median
as you can see from the Purple Line well
we've already started to learn something
that the average couldn't possibly have
told us at least half of the values that
we're collecting in this situation are
actually very very low so in that spot
where the average jumped up really
really high like it you know it tripled
from what we were seeing earlier the
median didn't change appreciably and so
what that tells us is that probably a
few values went up a lot and most of the
values didn't go up really much at all
so once you're starting to see what's
happening kind of in the middle of your
data set you can start graphing more
things that tell you even more
information about what's going on graph
the 95th percentile so the 95th
percentile is the number that is higher
than 95% of the values that you
collected at lower than 5% of the values
that you collected and here you can see
that the slowest or you know the the the
values that we collected with the
highest numbers the 5% with the highest
values are dramatically higher more than
10 times higher than the median so
continuing that trend it's also really
valuable to graph the 99th percentile
because in most of the scales that most
web developers deal with
1% is probably the the magnitude that
you actually care about like this is
happening often enough that it's a
problem and we should deal with it I
guess
as as Julia Evans mentioned during her
talk about kernel debugging if you have
a huge number of events happening
suddenly smaller and smaller and smaller
percentiles become relevant to you
because if your twitter and you have a
billion tweets happen a day i don't
actually know if that happens I'm just
making up a number but if a billion
tweets happen a day then your slowest
0.0001% of requests happen literally a
million times a day and so maybe that is
the number that you actually care about
because those million users are gonna be
really unhappy with how slow their
requests are and so I I actually know
from chatting with some people who work
at Twitter that they don't bother to
graph 50 or 95 or 99 or any any number
even vaguely like that they start at
99.9 and they go up to 99 point I think
four nines because that's the number
that gives them a small enough number of
events that they actually care about how
many people that's impacting so notice
that this graph has just had to increase
in scale by four times to accommodate
the 99th percentile and now we have
learned why the average went all weird
one percent of requests got incredibly
slow well everything else continued more
or less exactly the same as it was
before and the average went up you know
tripled for that time span so now when
we're trying to like work through this
and resolve it and keep it from
happening again we know that what we
want to look for is a very a very small
number of specific requests that cause
that that dramatically slowed down from
what they were before or new requests
that are very slow that weren't being
made except in this brief time span and
so this is
a pretty clear example of the way where
an average doesn't actually help you
debug or fix a problem but seeing the
percentiles actually like gives you a
pretty strong lead on what you should be
looking for and where you should be
expecting to have to do to like keep
that from happening in the future so
another common problem that happens with
averages is aggregation and aggregation
is of course a fancy way to say that
you're averaging across multiple servers
and so if you're running a typical web
application you're gonna have more than
one machine because one machine isn't
good enough for most web applications
and so for example again if you use some
drop-in service that collects metrics
from all of those machines you're
probably gonna see one graph and that's
an average so this is for change
actually real life data that I collected
from some servers that I run for the
Ruby dependency managers a server-side
API that gets called any time someone
tries to install some ruby libraries as
you can see the number of milliseconds
being measured by this metric started
around two jumped up to over five and
then eventually kind of recovered to
back around - so what does it actually
mean well we don't actually know because
it's an average but you can break out
the graph and instead of seeing a single
aggregate you can see an overlay of all
the individual things on top of one
another and here's the breakout graph of
that same data so a notice that the
scale has actually increased by 10x from
the graph we were looking at before and
noticed that out of these 15 ish servers
only one of them actually suddenly got
slow and this breakout graph let me see
which specific server out of 15 suddenly
got super slow actively nuke that server
and automatically start a new instance
and then it recovered and everything was
fine without this breakout graph like I
I had no idea what was happening it got
really slow I don't know and with with
this breakout graph it was like oh this
this one specific server is proud
maduk their problem solved so one of the
things that I'm trying to get across is
that visualizing your data is basically
the only way to get anything useful from
it into your brain human beings don't
deal well with gigantic streams of
numbers even if they do have patterns in
them but humans deal really well with
pictures but having said that you really
need to break things out and you really
need to if you can't break it out see
like the contents of that data rather
than just averages so one last
illustration to try and really drive
this point home before I move on here
are four different data sets as you can
see the x and y values are wildly
varying between each of these four data
sets you can see very very quickly just
by looking at the actual data set oh
these are four completely different
things
they're basically unrelated but if all
you had access to was aggregate
information about this data set it's a
completely different story so for
example the average of X in that graph
is nine the average of X in that graph
is not the average of X and that graph
is nine and the average of X in that
graph is nine it gets much much worse
actually you're like oh I'll be clever
I'll have more aggregates and they will
show the differences between my data
sets well the average of Y also the same
on every one of those data sets wait it
gets even worse every one of these four
data sets which once you can see the
data they're very very different has the
same average of X average of Y variance
of X variance of Y correlation of X and
y and the same linear regression that
was a very long way of trying to say
please don't trust aggregate information
about multiple data sets and do whatever
you can to actually draw the data that
you have into a graph that you can look
at because those are just four
completely different
things um one last thing
aggregate alerts are similarly
horrifying because if you have an alert
that only goes off once you have more
dead servers than you have a live
servers it's not actually very helpful
so don't use the average of status
checks to do anything use individual
status checks and alert on the first
problem rather than an average problem
and you'll probably be much better off I
I recognize that most of you are
probably fine on that front but enough
I've run into enough places where it
turns out that the alerts were actually
based on some sort of aggregate average
measure that I just want to call that
out because check if it's not I'm really
proud of you if it is you just saved
yourself a really bad time down the road
speaking of servers I have a couple
things to say about servers and how they
can also provide you with some
unexpected misleading results especially
in metrics and then I'll wrap up so you
pay for your servers they are
theoretically Hardware eventually right
you pay someone who pays someone who
pays someone who has Hardware something
like that but even if you bought the
hardware yourself and you racked it
yourself and you put software on it
yourself when you're not in the data
center and it's like serving requests
youyou don't really know what's
happening inside those servers and so
I'm gonna call out a few things that
most people don't know that they don't
know about what's happening in those
servers and we'll talk about ways that
those can be problematic so here's a
really interesting / weird example
whether you use whatever language you
use right web applications are usually
written I say this statistically not
because I think any of you are
necessarily doing it but statistically
whatever applications are written in a
scripting language like Ruby Python
there go
Perle or maybe in Java statistically but
all of those languages contain a runtime
and the issue with runtimes is that they
do things that you didn't write code for
like for example garbage collection
that's really cool don't get me wrong I
like having my garbage collected but
that means that there are times when
your program is running when your code
is not and most people don't until this
has really punch them in the face as a
problem think about the fact that that
is necessarily true so if your program
isn't running while your program is
running how do you tell and some
runtimes provide their own statistics
the JVM is probably the best in this
regard
you can like actually ask it what it did
and it'll tell you at least how long it
took other languages may not provide
useful things for example the Ruby
interpreter didn't tell you how much
time it spent doing garbage collection
until about two years ago and I've been
doing this for about ten years so and
actually to make things even worse there
was four maybe seven years there was a
garbage collection profiler built into
Ruby and it contained a memory leak so
you couldn't use it which was amazing
and you know now that I've called out
garbage collection really specifically
don't let that fool you
the runtime will stop running your code
and run its own code for reasons that
aren't necessarily garbage collection
right there's a lot of bookkeeping to do
there's a lot of things that happen that
you didn't explicitly write code for
that are built into the language or the
VM or the whatever it is that you're
running your code inside so as we've
established unless you're like writing
compiled things and running assembly to
serve your web requests in which case
I'm very sorry
you have runtime lag but how
much do you have right if you can't
directly instrument this how do you even
find out so I learned a very cool trick
from Larry Marburger who maybe even is
here which is run some code inside like
write your own code that says hey I
would like to pause for exactly one
second and then I would like to keep
going and if you check a very precise
system clock both before and after you
ask to wait for one second you can know
how much time you're one second wait
didn't spend running during that one
second
and so that graph that I showed earlier
with the aggregate that run ran on each
individual web server it was actually
how many milliseconds longer than one
second it takes to call sleep one and if
you run how many milliseconds does it
take to call sleep one in a loop
suddenly you know how much time your
program is spending not running wow this
process is executing turns out that's
really really helpful when suddenly for
no particularly apparent reason one of
the servers starts spending a
significant percentage of the time not
actually running your code and you're
like why are the RPMs down so so much I
don't understand and then scaling
backwards from your like language
runtime guess what the language runtime
is running inside another runtime so
you're running on a processor except
your processor probably isn't in some
sense a real processor because if you
use servers today on the internet
chances are really really high that
you're virtualized or containerized or
containerized inside virtualized inside
containerized inside verge I don't know
I don't know anyway so virtual machines
are exactly like runtimes
your code may or may not be running at
any given time and the only way to
really find out what's happening is to
examine external factors and be like hey
that isn't what would have happened if
my code had been running
the whole time that the VM was running
hmm so unfortunately I don't have a cool
trick to let you check for VM lag
because if the VM pauses you'll that
will go into the metric that I just
talked about where you get run time lag
and so if you care about a specific
contended resource in your virtual
machine you're gonna have to figure out
yourself exactly what contended resource
that is but at like a very broad entire
VM level I have heard rumors that
Netflix checks for this in a pretty cool
way where they spin up a VM and then
throw a benchmark suite at it and if
they if the instance meets their
benchmark baseline then they say cool
and they start putting production
software on it and if the instance
doesn't meet their baseline benchmark
they say nope nevermind Amazon give me a
new one of those and then they try again
and as cool as that is because research
indicates that provisioning for example
a single Amazon instance in a single
sized here can give you up to I think
the highest that they saw was a 5x
difference in performance at the same
price point and so if you're not looking
into how performant your instances are
after you ask Amazon for them well maybe
you're overpaying by 5x I don't know
that's a little terrifying and then and
then it gets even worse because of
course the performance of a single
instance can vary wildly over time as
new neighbors on the same physical
hardware come and go so do you Reba Ark
those machines did you did you just find
out that last week you were suddenly
having really a lot of trouble serving
your usual traffic with your usual
number of machines like this is also a
problem I don't have a really good
solution for that either other than to
say keep a really close eye on how many
like how many requests per second for
example your servers are able to sustain
usually and if that number changes look
pretty hard at that and maybe think
about swapping out the instance that
it's running on
so again going back to you like do you
know what you care about depending on
what you're running on that instance you
may care deeply about CPU contention on
the same physical hardware but not care
at all about say disk contention you may
be running memcached and care deeply
about RAM contention good luck figuring
out how to check for that that's really
hard but that may be what you care about
and you may not care about CPU
contention because memcache in general
doesn't really use much CPU or you might
be running a database in which case you
care about all the contentions right
databases are highly optimized to use
all the CPU all the memory all the disk
and all the i/o but like that means that
if you run anything else on the same
physical Hardware the database is no
longer optimized for that situation and
so you can see wildly varying situations
so I highly recommend that you like look
at this and try and figure out what the
variance is between instances and how to
keep an eye on the specific things that
you care about because they can just
drop out from under you without any
warning and without anyone telling you
about it and then one last thing outside
the runtime outside the virtual machine
there's one more thing that could be
destroying your real-world performance
without any metrics or instrumentation
on it and that is routing so when I say
routing I mean the piece of
infrastructure that takes requests from
the outside world and make sure that
they arrive at your actual servers and
then takes the responses from your
actual servers and make sure that they
arrive back in the real world so how
does routing work it's totally possible
that you work professionally as a web
dev for many years and have literally
never thought about this ever because
this is what your world looks like and
that is don't get me wrong that's that's
fine like I have no expectation that you
would have thought about this if you
haven't had to figure out why why god
why this works perfectly
and this doesn't sew in production you
clearly have some single point of entry
whatever you know matches up with your
domain and then is like oh well here's a
server here's an app process running on
that server here's a thread running on
that server here's a something you know
it breaks down into smaller and smaller
individual pieces until you say aha
here's the response and then it has to
like pass back up through that entire
hierarchy of things and you know so if
you're on Heroku froakie's just like
takes care of this if you're on Amazon
they offer their own ec2 her yeah
Amazon Cloud grabbing things which is
cool maybe you set up your own HJ proxy
or your own nginx or you're in in some
startups I've known your own H a proxy
that talks to nginx that talks to H a
proxy it's amazing but and this is the
question that no one really seems to
know the answer to how slow is it so
I'll I've I've asked this question of at
this point probably closing in on a
thousand people raise your hand if you
know or at least you know where to look
up exactly how much time your routing
layer on your web application takes I am
so proud of you all I have given this
talk at DevOps conferences I've given
this talk at Ruby developer conferences
and so far my grand total was one person
and this was like 15 people like this is
amazing this is more than I could have
hoped for and I'm super proud of
everyone here you're making me tear up a
little bit so the next question that you
immediately want to know once you know
how long it takes is does it back up and
so if your load balancer does simple
round-robin chances are there's no
chances if your load balancer does
simple around Robin the answer is yes
you should find out how badly it could
be not that bad
it could be very very bad and your users
are seeing 30-second delays or timeouts
while your applique
instrumentation all those cool numbers
that New Relic gives you for free say
that everything is great so once you
know that routing exists here's what you
can do to at least keep an eye on it and
that is find out what your real life
request time is right like New Relic
says response time but that doesn't
actually mean how long it takes for
requests to arrive to be processed and
to be returned that only tells you how
much time it spent inside your actual
like web application parsing the headers
and concatenated a giant string to send
back so it's really useful to see how
slow things are inside the code that you
have control over but it doesn't
actually give you a good idea of what
your users are experiencing because what
your users are experiencing includes
gigantic network hops it includes a
round-robin router that might be backing
up hundreds of requests before the the
New Relic timer even starts ticking you
might have to wait for a hundred
requests to be served because routers
are terrible and finally it doesn't
account for like real-life transit times
because unfortunately even electrons
have measurable time that they take to
get to places so the only way to know
how long a request actually takes to get
across your entire infrastructure is to
set something up that makes requests
across your entire infrastructure and
then tells you how long they took there
are a cool service there are a couple of
services that do this kingdom has
finally expanded into doing this from
all around the world
run scope does this there's another
service called thousand eyes that also
does this and like their entire reason
for existence is we go to data centers
all around the world and we hit your
entire infrastructure top top to bottom
front to back I don't know one of those
things and then we tell you how long
that actually took because that's the
number that your users are actually
going to care about so the reason of
course that you should care about this a
lot is that
the number that you see in how long
something took inside your web
application server is gonna be much much
much much lower than whatever you see
coming back from this real world metric
and for example Amazon said in 2006 that
100 milliseconds slower in their entire
checkout process which is like six steps
a hundred seconds 100 milliseconds of
slowness across that entire process
dropped their overall revenue by 1% and
when your Amazon 1% is like a lot of
zeros so in the end metrics are actually
pretty good but you need to know what
you're measuring and you need to know
how what you're measuring impacts the
things that you care about in real life
from a business perspective that's it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>