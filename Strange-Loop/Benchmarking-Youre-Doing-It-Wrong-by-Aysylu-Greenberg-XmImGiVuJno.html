<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Benchmarking: You're Doing It Wrong&quot; by Aysylu Greenberg | Coder Coacher - Coaching Coders</title><meta content="&quot;Benchmarking: You're Doing It Wrong&quot; by Aysylu Greenberg - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Benchmarking: You're Doing It Wrong&quot; by Aysylu Greenberg</b></h2><h5 class="post__date">2014-09-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XmImGiVuJno" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so let's talk about benchmarks in order
to understand systems performance one
needs to set up a benchmark it will help
us guide us through towards our
performance goal however if benchmark is
set up incorrectly or interpreted result
incorrectly hours days months of effort
may result in a worst performing
application upset customers and our
inability to detect how exactly it's
performing worse because they batch
records how is reading better so am i
slew Greenberg I work on searching for
structured Google and I'm the maintainer
of flume which is a graph algorithms and
visualization library written in closure
and let's talk about benchmarks
specifically how you're doing it wrong
and hey these are the things I've done
wrong as well you probably came here
expecting the hotel to be memes so
here's one if you're measuring
performance of the application using a
stopwatch you're doing it wrong and all
of you are a pretty smart hair strange
loop and you're probably doing it
correctly but maybe a team you work with
or a co-workers doing it wrong and you
would like to know more ways better ways
to educate them on that so let's get to
it
in order to read good benchmarks one
needs to be full stack and I don't mean
the type of full stack of front-end and
back-end I mean one needs to be a really
full stack like you need to understand
the bytecode or the internal
representation emitted by the compiler
as well as the machine code produced by
the code generator and the operating
system all the way down to the hardware
level including the gate level and
device physics if you have to and let's
not forget about the network stack and
the user how users are actually
utilizing the application is very
important to know when you're setting up
the benchmark so you're not benchmarking
some actions that the users never make
but not everybody has access to this
knowledge because it takes a lot of very
focused effort and years of experience
such knowledge in the first place but we
can write better benchmarks even if we
don't have all that knowledge in the
first place so first let's talk about
what benchmark is to make sure we're on
the same page the way I think about it
is benchmark measures how fast the
program runs so what the latency is also
there are quality benchmarks which will
tell you the coverage of your result set
or the quality of results or whatever
the quality definition is but today
we'll focus specifically on performance
on latency measurements on run time so
in business benchmark is when you
measure when you compare your process to
a goal and when you compare your process
to industry's best practices best
standards so you might wonder how does
this relate to this other definition
that we just discussed well bitch works
allow us to focus not only on the
performance of the program but also on
the performance goal how fast is fast
enough so that your users are happy and
you are saving money resources on your
bills so let this talk we'll be in three
parts first we'll talk about how not to
write benchmarks but looking at a
contract example then we'll look at
common pitfalls and vege work setup and
results and specifically we'll talk
about how you're wrong about the machine
you're wrong about stats and you're
wrong about what matters and to conclude
we'll talk about what are the techniques
who could use to become less strong and
all the examples were going to discuss
today are actual examples real-life
examples that happen to me my colleagues
so there are actual problems in real
life so let's talk about how not to read
benchmarks suppose you have a website
that serves images and a request comes
in into the server and the image can be
served either from cache or from s3 and
images are slow to load so we want to
match mark that
so we'll access one image 1000 times in
our benchmark and we'll measure latency
for each access and we'll start
measuring immediately we perform three
runs of the benchmark and we'll find the
mean and we'll do this on a definition
because prod machine is busy churning
through our production workload so
what's wrong with this benchmark well
the correct question is what isn't wrong
with the special work so we'll approach
it step by step let's talk about the
common pitfalls when it comes to
reasoning about the machine caches are
everywhere in our applications their
caches all the way from application
layer that we build all the way down to
the hardware level and a common approach
in our industry to solve any kind of
latency problems seems to be just put a
cache on it and its caches all the way
down from application layer going down
to the hardware level and most caches
are usually structured in a hierarchy so
your benchmark application won't be
accessing a particular cache level so
one particular cache level will serve
the request for instance in our example
of the website serving images you will
either be talking to the cache or s3 if
the image is not in cache or your local
memory in the cache if the image is not
in local memory of the server so now
let's look at cashless in the processor
in greater detail so each core will have
l1 cache for instruction cache and l1
cache for data cache and instruction
cache is caching of the instructions
that machine executes and data cache
always cache for data and then we'll
have out to cache procore and then we'll
have shared l3 cache for all the cores
so the counter example to cache is being
structured in hierarchy would be the
following suppose you have a bloated
binary which will be hurting execution
performance because we keep because
instructions cognition instruction cache
for instance if
your program you can take variety of
code paths and users always take
different code paths through that
program and there's not really you know
come and pass the take well you're
guaranteed to always be missing
instruction cache what that also means
is that no matter how much you tune your
memcache server you know we're going to
see benefits of improving performance of
the memcache server so for benchmarks
for most benchmarks your benchmarking
particular cache level let's look at the
following program so in black black line
you see is the performance and the
writes y-axis is the latency the lower
the better so what the program does is a
performance random access within an
address range and so the address range
is given to us by n which is the it's
the number of different elements in the
query set the way you can think about it
that's the x-axis and now if we're doing
random access to defeat the prefetcher
which is the clever hardwood clever
technique that hardware does to figure
out what the memory access patterns are
ok so now on the right axis not much
here is number of cache misses per
measurements so what we see here is that
up to 32,000 elements and you may not be
able to see them the numbers on the
bottom that well so our performance is
dominated by the l1 cache effects our
data fits into all one cache and then
afterwards we start missing l1 cache now
up to 128 elements our performance is
dominated by l2 cache effects with over
8 million elements it's actually all
three cache effects that dominate
outperforms we define how our
application runs and they are the small
artifact you see in between that is
actually due to translation lookaside
buffer so the takeaway from here is that
depending on the number of elements you
have and depending on which packs the
caches you're going to be accessing
you're going to see different
performances so accessing one image
1010 is not really a correct way to
approach this so the way you should
think about this is what is the goal of
the benchmark well it depends on what we
want to know if you want to have a
distribution of requests similar to a
realistic workload like you're accessing
ninety percent of the time
top five images and ten percent of time
the rest of the images then you should
start up your benchmark to do precisely
that if you want to measure access time
to a cache or to s3 or to cache will
make sure that all the images your
access actually live in your cache and
to us three you'll make sure that in
which is your access never hit the cache
now let's talk about warm-up and timing
if you're writing in a JVM language like
Java Scala like closure then what you'll
see is that when you load up your
application first it will be executing
interpreted mode and then it will be
executing a mixed mode where some of the
code will be compiled and some of the
code will still be interpreted until it
reaches steady state and compiles maybe
most of the program another example of a
warm-up is cache filling when you set up
your application well first it will take
time for your application to figure out
what are the most commonly accessed
elements what is the most commonly
accessed data to cache data and then
once the application reaches steady
state well then all the elements that
are frequently accessed whole problem be
in the cache and warm-up is the cost to
pay once per long-running application so
when you run your benchmark matters a
lot if you want to understand behavior
in a steady state of the application
then you'll make sure that you want to
make sure that you don't take into
account the warmup time now if you want
to understand a failover behavior then
warmup time where my performance is
actually what you want to be measuring
so you set up your benchmark to measure
that in our case here well we're
interested in a steady state performance
how application performs after lots of
users has been accessing it
so by my starting to measure and
immediately what we'll see is it will
secure our latency result towards high
latency side and it shouldn't really be
part of the ethic a part of the
benchmark now let's talk about periodic
interference it happens when you're
sampling values in the benchmark and it
coincides with an event which can be
considered noise for instance on this
plot what you see is sheep taken with a
VSO VM so it's hip over time and like
that size of the hip over time and the
blue line and all the air underneath is
the least amount of hip and the orange
is their allocated amount of hip so if
we measure duration of active requests
starting at the peak which is where the
garbage collector kicks in and towards
the dip and that's the time when we're
measuring it which is during garbage
collector activity what will a guarantee
to see is much longer times of active
duration requests similarly if we want
to measure number of concurrent requests
during an indexing operation it only
happens always coincides with indexing
operation they will see much lower
number of concurrent requests and if
your periodic interface is not exactly
synchronized the face is not exactly
synchronized like you're measuring
active duration right before the garbage
collector and then right after and then
sometime in between that you're going to
see results that look like there are
over the place and don't really have any
kind of consistency so it's important to
know what kinds of effects you may be
observing whether you're sampling at a
particular rate that some other noise is
happening so by measuring latency for
each access it doesn't give us enough
information now if you measure latency
and throughput would that would tell us
is if you have lower throughput and
higher latency then we may be coinciding
with some other parts of the system that
are doing periodic activity we can also
figure eyes.if coordinator emission
happened and we'll talk about that in
just a moment
another common pitfall that I observe is
doing
using different specs in testing
production machines it's not it doesn't
always cause issues for instance if you
have some function that takes 90 percent
of the time in production machines it'll
probably take 90% of the time in your
test machine as well however for some
more subtle effects like cache effects
and like Layton sees that are not so
dominant what he may see is different
cache effects depending on the size of
RAM so you would want to know for sure
if the differences in the environments
that you is using for your benchmark and
in production will cause issues in the
result that you get or not but usually
it's best to match up the environment as
closely as possible so by doing this
under machine well if my production
machine is 64 gigabyte RAM and my dev
machine is eight gigabyte RAM I may see
some results that I won't see in
production now let's talk about even
more subtle issue which is power mode
changes you may have heard about dynamic
frequency scaling also known as CPU
throttling a common implementation of it
is in tow speed step so what that would
do is it would run your processor will
run at different frequencies it could
run a 1 gigahertz or four gigahertz
depending on what the machine decides to
do best for power conservation and our
statistic test you could just know
whether it happened during your
benchmark and whether that happens
during a production workload to see if
you can compare them well now let's talk
about stats stats are hard to direct and
easy to mess up one of the common
pitfalls I see is taking too few samples
they simply just don't give us enough
data and may include outliers in which
case they will it's hard to reason for
us for what our latency measurements
actually are so how many runs samples is
enough well that depends on your
application but there are good ways to
figure that out
for instance if on this plot would be C
is and
success is done and you can think about
it as runts of the benchmark number of
runs and y-axis is latency and the top
plot you see the blue dots are the
samples and the red dot is the median
now what we see is that at the beginning
like around time five median is not
stable yet so our application still
converging and it runs ten twenty it's
starting to look more convergent so
maybe twenty samples is enough in this
case now on the bottom graph what you
see is green dots are the samples and
the purple dot is the median and a run
time three it dips down to twenty and
then it goes back up and it goes you
know a little crazy there so we're
probably measuring some of the warm-up
effects and when this shows us is that
20 samples is still not enough when I
was still not converging but maybe
towards 40 samples 40 runs were starting
to converge it also depends on whether
you're interested in a long tail so for
some of application that we run in
production we want to make sure that
there are no artifacts that happen hours
days after we launch there so we would
watch it very closely now if you're not
inserting long tail that may be my many
few runs will be enough for you it also
depends on whether or what your risk
profile is if some artifacts that you
may observe in production is actually
something that you care about or it's
fine for it to release so by doing three
runs is just simply not enough and we
should do more runs in order to have
better representation of what our
latencies are now let's talk about
distributions if you have a normal
distribution mean and standard deviation
tell you basically everything you need
to know but due to complexity of your
systems and measuring different effects
of different layers of your system at
once you may not have a normal
distribution and in that case mean also
known as ever
is not stable enough in the case of
outliers in the presence of outliers so
if you have 10 requests that took one
millisecond in one request that took 10
milliseconds that what you're going to
see is that the mean latency is just
about 2 milliseconds which is not a good
representative in this case median is a
much better represented for our sample
set because what we'll do is we'll throw
out all the latency that were observed
and in ascending order say and then
we'll take the midpoint percentiles also
show us distribution that we get so they
carry important information so by
finding mean it's not enough but median
as well as percentiles give us much
better information and also not only not
always not all distributions are non
Gaussian but also you may have
multimodal distributions usually we want
to pick couple points in order for us to
generalize on what the sample set we
have we want to summarize on what we
observe instead of just talking about
the whole sample set and usually people
use 50th percentile 19th and 99th
percentile well the problem was 50th
percentile is all that tells it to us is
that half of the time was slower and
half of the time we are faster which is
not really telling as much also it could
be useless if you have multimodal
distribution imagine this case where you
have latency mergers in milliseconds on
the x-axis and then a y-axis number of
occurrences and we expect that you know
50% I will measure in more sample sets
so we'll have more latencies measures at
about 4 milliseconds than 10
milliseconds now take a moment and
imagine what this distribution looks
like well this is what actually looks
like so what we have here is the 50th
and 99th percentile don't really
summarize and give us a good view into
what our distribution is they really
tell us very little about our
distribution so always make sure to look
at histograms and plot actual
you should to notice any of the
modalities you may have so in this case
we'll have bimodal distribution so
picking different points to summarize
our data is more meaningful to us now
let's talk about outliers this is my
favorite topic because I feel like
outliers get so little love and they're
always dismissed as this something
something that happens so rarely so why
should we care about them you know they
don't really fit into our assumption
into our expected case so let's just
throw them out and now we have this you
know nice little said that we can
actually reason about well so let's talk
about coordinate emission imagine this
case where you have a client send a
request every 10 milliseconds to your
server now you expect that server
response within Martin millisecond so
you send request 0 milliseconds you get
back response at 1 send request at 10
you get back response at 11 then request
a 20 millisecond now a server
experiences a garbage collection so it
doesn't respond until 100 milliseconds
and then you start continue sending
requests and all goes well so when you
get your result set which you'll see is
one request took 80 milliseconds and the
rest of the request took 1 millisecond
so we toss this out now the problem with
this is during those 80 milliseconds in
the request took we missed out on 8
samples that we could have taken so we
don't really have our samples that the
way we were expecting it to have we
don't know what our distribution is
exactly there are statistical ways to
correct for that but requires knowledge
of your architecture very precise
knowledge so it may be very hard to do
another thing so the accordion admission
part is we coordinated with the server
instead of selling 10 million or the
request at 10 milliseconds each apart
what we did is we waited for the server
before we sent back and we emitted some
of the results when our request took
much longer than we expected you can
learn more about coordinate emission and
go today's talk on how not to modulate
and see if you're curious he goes into
much more detail than this but you can
see how by measuring by having this
outlier it will reveal to us that
something went wrong
another thing that is revealed by
outliers is missing of SLS a so lays our
service level agreements they basically
tell us they basically give us
guarantees for how fast this service
that we're requesting from will respond
or we give the guarantee so users how
fast will respond to them
the other problem with outliers is if it
happens one percent of the time then
imagine you have a webpage and it has
100 images so what are 100 images will
load very slowly say 10 times or slower
well with a web page of 100 images every
single user will be affected and a lot
of us work at scale so all these 1%
outliers actually become a real issue
when everyone is affected by them now
let's talk about being wrong about what
matters for setting up the benchmark
oftentimes I observed that people who
know a little bit a lot about
optimization or about performance
engineering it really excited to make
their program run really really fast
well I couldn't put it better than don't
know enough about this programmers waste
enormous amount of time thinking about
the speed of non-critical parts of their
program we should forget about small
efficiencies 97% of the time premature
optimization is the root of all evil yet
would not pass up our opportunities in
that critical 3% often even most
seasoned programmers can quite predict
where the bottleneck would be another
common issue with setting our benchmarks
is using under positive workloads
so for instance in the case of in a
website serving images in production I'm
serving 2 megabyte images but our
benchmark on the thumbnails the 200
kilobyte images because I just want to
get out with my results faster well the
problem with that is we can't quite
predict how that will scale up to 2
megabyte images so we're just getting
results that are meaningless to us and I
thing you may notice is that your
application runs just fine which when
you're benchmarking it they're not
really many outliers everything looks
fine but in real life other services may
take up the resources so you see higher
latency is in your application than you
saw in your benchmark another important
thing to account for is memory pressure
if you're writing a languages that are
garbage collected then a good way to
approach this is to force a garbage
collection at the beginning of the
benchmark and not measure that because
with you don't want to have is bad
measurements from garbage collecting all
the data you generate during the set up
but you do want to measure their garbage
collection times at the end of your
benchmark because what you want to know
is what is the approximate memory
footprint that my application has and I
probably said how long would it take for
us to garbage collect the garbage
generated by the application now the
problem is if your benchmarking a
library you may notice a GC pressure due
to other parts of the system when you
integrate them so your library may be
doing just fine when it's not integrated
with the rest of the system but when the
other parts of the system created lots
of data then you notice that your
latency times are spiking up so let's
talk about how to write better mesmeric
how to be less wrong about this we'll
just discuss the common pitfalls when
reasoning about the machine the stats
and the workloads so let's see how we
can mitigate this
I think the good way to approach from
running benchmarks is to think about
user actions
how are users using it how long do they
spend on each of their parts of the
applications how frequently do they use
every parts of the application and so on
for me the best way to do this is by
trying to model how the users are using
application instead of what I thought
the application will be used how I
thought the users will be trying to use
it and benchmarks don't really uh not
really supposed to give us this magical
answer that
you know database X is much better than
database y but there really are telling
us is that database X is better than Y
for particular workload G with
trade-offs and constraints a B and C so
this level of honesty about what you're
trying to measure it for and what you're
trying to optimize it for what your
performance goal is it's very important
when setting up the benchmarks so what
are the tools that we have in our
toolkit well one of them is profiling
what profiling will reveal to you is on
which parts of the program you spend
most of the time and how frequently is
it executed and what is their memory
usage is another common thing that is
done is good instrumentation and
production so what you do is for every
function that you're accessing you will
record the time and then you stop
recording at the end of that function
and you just log that and this combines
well with aggregating over logs so what
you'll be able to do is go back in time
and retracted ly analyze how long you
spent on each function how frequently
each function was executed and this is
also less prone to coordinate emission
and much easier to do than measuring
leniency in real time and it's not
really subject to the same kinds of
limitations and problems that real-time
latency measurement has another example
of this is doing tracers which is when a
request comes in here records at every
every server that it hits and all the
timings where it spends in each function
how long it spends there and then
analyze that so when talking about
benchmarks we can't really avoid the
topic of micro benchmarks there is a
lots of blog posts out there micro
benchmarking parts of code so let's talk
about those micro benchmarks for them
and to do is measure a small bit of code
a single operation
and to me micro benchmarks are a
blessing and a curse they're quick and
cheap and don't require quiet the same
kind of invoked process as setting up a
benchmark and they answer very narrow
questions very well like should I use
quicksort and mergesort when sorting my
data however they produce often
misleading results and also are not
really representative of the whole
program one of the common issues when
micro benchmarking is not considering a
range of ends that your real application
will be using the coldest plot from
earlier today so what we saw is we saw a
different performance depending on how a
number of elements in our application
number the data set size that we were
operating on and we may see that merge
sort is great if your data fits into l1
cache but a quicksort is better faster
for everything else now if you are micro
benchmarking a tight loop worked from
some sort of side effect like writing to
a file make sure to include that in your
measurements make sure that you're not
just tossing it out and be aware of the
clock resolution in Java Docs for get
current time Millis it actually warns
you that certain operating systems may
have clock resolution of tens of
milliseconds so make sure you know that
this is very exclusive to micro
benchmarks because often we're measuring
very small operations so they don't take
that long for instance if you have clock
resolution of one millisecond and the
operation takes two point formula
seconds then what we'll see is that our
approach our function took two or three
milliseconds to execute and we can use
statistical methods to find out that
actually function took 2.4 milliseconds
but it's harder to do correctly so a
better way to approach this is by
measuring many many iterations of the
same operation and then measured from
the 0th iteration to the last and then
divided up by the number of iterations
another thing that becomes a bigger
problem when doing micro benchmarking is
dead code elimination if you're writing
in JIT compiled languages then if the
compiler notices that you never
executing particular types of fun codes
particular chunks of code then it will
just eliminate all that so dead code
elimination is an optimization done by
compilers
where any code that is no longer at
reachable or never executed it just gets
tossed away so now what happens here is
that we're no longer microbrush working
the same program we started out with so
we're just comparing apples to oranges
another common issue for micro
benchmarks is not doing constant work
per iteration so if you're inserting
elements into a tree and you query those
elements from the tree
well what you'll see is your work will
grow slowly logarithmically and so
because it grows slowly may say if you
think that it's not really an issue the
problem is that if you have 10 elements
vs. you have 1,000 elements there will
be three times slower and also brings us
back to taking many iterations to avoid
issues with a clock resolution well if
each iteration takes ever so slightly
longer then now you are measuring very
different things than you what you
thought you were so there's lots of
different fantastic articles you can
read online on how to do better bend my
better benchmarks including micro
benchmarks specific for your languages
so if you're riding on a JVM there are
lots of amazing people doing very high
quality work in that and don't worry
about memorizing them now I'll post the
slides online and the links but you're
also welcome to use the finest search
engine out there so so to wrap up if you
were to check out anything from the
stack I think it should be these three
things
it slashes all the way down and when you
benchmarking you're accessing a
particular cache level
so you should remember that and you
should try to understand which of the
benchmark which of the cash levels is
actually an issue if it's hierarchical
order then you want to make sure on
which order of the hierarchy you're
actually measuring with your benchmark
if it's instruction cache like we saw
with blow two binaries
well no matter what you do to your
hierarchy these two caches are not
really in hierarchical order they're not
really dependent on each other so you
whatever optimizations you do there just
won't matter another takeaway is
outliers outliers are commonly dismissed
but they actually carry more
informational density then whatever you
would have measured whatever really fits
your theory your expectations of how
your program performs so this should
serve as this strong signal for what
went wrong when your assumptions were
incorrect and whether you're actually
missing us a list and you'll feel
working at scale an outlier you see
however frequently will become a major
issue when you have a just from
probabilistic perspective and another
important thing to remember is
unrealistic and realistic for clothes
when you're setting up your benchmarks
if you were to imagine that this truck
was designed by assuming that only a few
people right and a few bags will be
loaded in it and it was optimized for
that load and application running
production is this truck with that many
people and that many that much load on
it what would happen is truck may never
move so if you optimize your program to
perform well under a particular load
which is much less than your production
load then you will notice that your
procreation is no longer perform as well
but that is it for today thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>