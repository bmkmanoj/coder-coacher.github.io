<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Testing Distributed Systems w/ Deterministic Simulation&quot; by Will Wilson | Coder Coacher - Coaching Coders</title><meta content="&quot;Testing Distributed Systems w/ Deterministic Simulation&quot; by Will Wilson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Testing Distributed Systems w/ Deterministic Simulation&quot; by Will Wilson</b></h2><h5 class="post__date">2014-09-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4fFDFbi3toc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right good morning everybody so my
name is Will I work at foundation DB if
you haven't heard of us we make a
scalable and fault-tolerant database
with asset transactions I'm not here to
talk about that today though instead I'm
going to talk about simulation testing
and why it might make your life easier
so I want to start with an observation
which I hope everybody here agrees with
which is that debugging distributed
systems is preferable to sticking a fork
in your eye but not that preferable it's
actually like it's actually surprisingly
close and people will tell you a lot of
reasons why this is true one of the most
common ones I hear is it's cuz they're
complicated and I'll grant that it's
true they are complicated and debugging
complicated stuff is harder than
debugging simple stuff but I want to
propose that this is not the real reason
why they're really hard to debug so to
look at the real reason let's look at a
super simple example so we've got a
server on the left here and a server on
the right here and the server on the
right is going to send a packet to the
server on the left and this is a non
idempotent packet that means if it gets
received twice it has a different effect
than if it gets received once and the
server on the left has a bug in it which
is it doesn't check how many times the
packets been received but you know this
bug has never manifested it's
asymptomatic because you know networks
always work right so server on the right
sends a packet and it gets lost in a
time warp because neck networks are
mysterious you know somebody
misconfigured a switch some berserk
router sent it to China and sooner or
later like a retry happens like you hope
a distributed system would do and then
this packet emerges from the time-warp
and everything catches fire and explodes
and you lose your data everything's a
disaster and you're like oh goody I get
to debug this now so you set everything
up again and you run your system again
and this time it works fine and you're
like okay I got to get to crash again so
I can debug it so you said it again and
it works fine and it may just keep
working fine because this random network
this network condition here
super transient and super rare and
depending on ridiculously precise
timings you can never get it to show up
again it is going to show up again
probably on a client site right but you
can't make it happen you can't track
down the bug and even worse once you
think you fix the bug you can't verify
that you've actually fixed it so one
more example just to build our intuition
here right same setup server on left
server on the right server on the right
is going to send two packets it sends
them like in order packet a and then
pack it be it's not in its contract that
it has to send them in that order it's
just like we're normal human beings
right so when we program sending two
packets we type like send a then send B
we don't type you know roll a die 50%
chance send a sin B then fit persistent
send be send a that's not what humans do
so it just always happens to send them a
and then B well unfortunately the server
on the left thought that that was the
contract thought that that always did
happen well you see where this is going
now a gets lost in time or B shows up
first then a then the world explodes a
good luck ever debugging this so the
real so that mean the surface level
problem is that we have no repeatability
in our debugging the real problem is
that the messy dirty universe has
intruded on our beautiful pristine land
of pure functions right like the
execution history of this system is not
a pure function of its inputs there's a
source of entropy a source of randomness
which you do not control which is the
network this problem is especially
apparent in distributed systems but you
can get the same kinds of bugs just
replace all the words with like threads
or disks or you name it um so so this is
the problem and this was like a super
bad problem for us because we make a
distributed database that tries to
provide a meaningful guarantee to its
users acid is not a property of a system
that emerges by accident right there
there are a lot of ways of getting that
wrong a lot more ways of getting it
wrong than getting a right and what's
really scary is that there are many more
ways of getting it right and then having
it fail as soon as something unexpected
happens then there are of getting it
right and having it stick and be right
the second problem is that we make a
database like if we just made a web
server or a cache or something we'd be
like whatever dude nuke the VM start a
new one turns out people aren't like
philosophical like that about their data
I don't know why they get really upset
when you tell them to do that
so we basically decide that if we
couldn't solve this problem we shouldn't
even bother trying to build a database
so we did solve the problem so the thing
that the company did was we didn't write
a database we started by writing a
simulation of a database a totally
deterministic simulation and then once
we'd exhaustively debugged that we were
like okay now we can write a database
which is just that plus talking on
networks and talking to disks for real
for actually a couple years there was no
database there was just a simulation
that probably sounds totally insane I
promise you it's more insane than you
think it is we're talking about
simulating not just a process but an
entire network of communicating
processes plus all the interactions they
have with their environment with disks
with os's with networks all within a
single virtual process oh sorry a single
physical process many virtual processes
that sucks it's really hard to do it
turns out to create some real software
engineering challenges so let me run
through those quickly sort of what they
are in theory and then I'll talk about
how we address them and how you might
address them the first is you need
something that I'm going to call single
threaded pseudo concurrency it's a bit
of a mouthful so let me unpack that this
the kameen like conceptually right like
you're trying to simulate many many
different things all happening at the
same time plus all the machinery around
them that's making them think they're
talking to each other so you're going to
need something that looks a little bit
like concurrency it can't actually be
concurrent though because if it were
actually concurrent you would now have a
source of non-determinism which we just
like sought to extirpate right like I
just said like all these problems happen
again with threads so we can't do it
with threads we can't do it in more than
one process we have to do it in one
process it's
easy in some languages it was really
hard in the one we picked the next thing
you need is a simulated implementation
of all the ways in which your processes
can talk to the rest of the universe I
think it's pretty clear why you need
that basically all that randomness all
that entropy needs to be randomness and
entropy that you put there on purpose
and then the last thing you need sounds
kind of dumb but the processes you're
simulating themselves need to actually
be deterministic and it you know if you
get one and two right three is usually
not that bad but there's some ways of
shooting yourself from the foot here so
I'll talk about those um right so so the
way we tackled one was maybe a little
bit insane we knew that we couldn't do
this with threads for the reasons I've
already said co-routines have their own
issues that basically left callbacks and
we also knew that we want to write in
C++ because you know it's fast so you
know the problem here this is a little
bit of dilemma because callbacks plus
C++ is like a nightmarish hellscape it's
not something that we wanted to deal
with what we needed were higher level
primitives some abstractions that we
could actually reason about that we
could actually write and actually read
so the way we did this was we created
something called flow which is sort of
halfway between a library and a new
language
it's a syntactic extension to C++ which
lets you use actor/model concurrency
with the physical implementation totally
single threaded entirely in callbacks
that's done by a sort of scare quotes
compilation step you could call it a
pre-processing step I don't know it's a
compiler whose target is C++ let's say
that so it lets you write things like
this this is like the simplest possible
actor you could write I guess it's like
an asynchronous adder it takes a future
float and a float waits for the future
to become ready it returns the sum
there's two things you should
immediately notice about this the first
is that this actor keyword is not C++
you feed that into your compiler it'll
yell at you this tells the flow compiler
that what follows is an actor definition
and it should treat it as an actor and
generate an actor from this the second
thing you might notice here is
that this return type is wrong right
it's declared to return a future float
but this sure looks like it's just
returning a plain ordinary float that's
because this function body is not going
to appear anywhere in your program it's
almost like declarative you're telling
the actor compiler what you want to have
happen what's actually going to happen
is it's going to generate a new function
and a new class and the function is
immediately going to return a future
which will become ready as soon as the
actor is done executing and as soon as
everything asynchronous is finished
happening um here's a tiny tiny amount
of the generated code that it produces
so the async add function gets redefined
or defined for the first time it gets
Const and modifier stuck on its
parameters those parameters get passed
into the constructor of a class which is
totally generated that class returns
immediately and the implementation of
the actor gets broken up across methods
in the class so every time there was one
of these like weight statements where
we're waiting for some asynchronous
process to terminate that means a
function in the class is going to end
and it's going to set a callback on that
future and the callback is going to
point to the next part of the actor and
then it's going to yield immediately to
a centralised scheduler so that the rest
of your program can continue running at
the very end here's some callback junket
generated at the very end it's going to
it's going to fulfill that future that
you were holding with the promise that
it holds on to and then it destroys
itself and cleans itself up and blah
blah blah and yeah so it's pretty nice
you get to write actors you know you get
to write this but it all happens in one
thread and it can still be super
asynchronous and it's also pretty fast
so here are some numbers that you should
take with a gigantic grain of salt this
is a benchmark called the ring benchmark
it was invented by that guy who just
just gave the previous talk Joe
Armstrong basically you get a ring of
actors and of them and they're all lined
up in a big ring and they pass a message
one to the other and it goes all the way
around the ring and you do that em times
and these were some numbers so two
reasons why you Bay
we shouldn't believe this one is that
the numbers that weren't flow were
numbers that other people ran that we
found on the internet and we think they
probably did a good job running their
own systems but we have no idea the
second reason is that it's kind of a
simplistic benchmark I hope Joe
Armstrong's not here is he okay it's
kind of a dumb benchmark like like I
mean it doesn't mean it's an okay
benchmark but it doesn't actually model
like what real distributed actor systems
do very much and in fact we found that
as you make actors more and more
complicated and have like way more
asynchronicity in the body of the actors
flows relative advantage decreases
considerably although we don't have nice
numbers from other people to compare
that against so that's one reason why
we're currently running flow to to try
and try and make that a little faster
but anyway assuming you're not using C++
you don't have to do anything near that
crazy but we did so the next thing
conversely is something that might be
hard for most of you but was super easy
for us so we already had a
multi-platform program so we had nice
like abstracted out interfaces for
talking to disks talking to networks etc
etc and so we could just drop in a new
implementation right next to those so
you've got like your UNIX network code
and your windows networking code and so
we added some simulated networking code
that was not too bad and so if it's a
simulated network then like when you try
and make a network connection instead of
actually making that work connection
initializes a C++ class which has got
some internal state and some buffers and
like if somebody sends to it then it's
going to wait for a little while to
simulate latency on the setting sending
side is going to wait for a while to
simulate latency on the receiving side
then it's going to copy some bytes
around and then it's going to make the
receiver know that like there's some
bytes available so one kind of cool
thing here in the read method and I'm
going to talk a lot more about this
later is there's this call here to roll
random close and that gets into sort of
the fun part of this talk which is how
we try to turn up bugs so this is just a
taste
basically every time you try and read
from the simulated network there's a
chance that something terrible will
happen so we roll a random number
and if you get unlucky then we roll some
more random numbers and then there's a
chance that your peer is just going to
close the connection there's a chance
that you're just going to close the
connection there's a chance that you
don't know what happened and the
connection just fails and you receive an
error when you try and read so this is
like how we try to smoke out any code in
our system that might have been assuming
the network was reliable which is a very
foolish thing to assume but this is just
the start it gets a lot more fun so then
the last thing you need is determinism
this sounds brain-dead easy right like
like we don't like usually try and write
our processes to be non-deterministic
nevertheless it shows up all the time so
the obvious example is if you ever have
a random number in your program so for
instance in exponential back-off we use
random numbers then you're going to have
to make sure that that random number
comes from a pseudo random number
generator which you control which you
seeded and then the seed of that random
number generator becomes part of the
input of the program right so so that's
fine okay it's a little weird but we can
do that have you ever checked the time
in an if statement so your program just
became non-deterministic if you ever
checked how much disk space you have
free like again like non-deterministic
now like running it two different times
could produce totally different
execution histories our programmers are
trained to recognize this stuff and to
try and avoid it and we still screw it
up all the time really all the time and
that's why we do one last thing which is
some small percentage of our simulation
runs I think right now about 1% we
actually run them twice and then we
check one run them twice with the exact
same inputs mind you so the exact same
things happen in the exact same sequence
and at the very end we check those
random number generators I mentioned and
see what the next random number it would
have generated would have been and if
those don't match exactly we know there
was a determinism failure and we go
track that down so this is obviously not
an exhaustive check you can break
determinism and this will still work but
it guarantees that you'll find those
problems
sooner rather than later um okay so you
get three things that behave like that
and you roll them together not
necessarily in the way that we did again
you may not be using C++ in which case
is probably a lot easier and you have
something which can take a network of
interacting processes and simulate them
together in a totally totally
deterministic way so that's where the
fun begins because the fun part is now
we need to find bugs and so the way we
do that is is with these test files and
these test files declare two types of
things one is a set of stuff that the
system is going to try and achieve
that's this up here and one the rest is
a set of stuff that's going to try to
prevent it from achieving that so in
this case we've declared that we're
going to try and do a cycle test a cycle
test is where we insert a ring of keys
and values into the database so they're
each pointing to the next one like value
ones point a key to so on and then we
begin executing transactions
concurrently in this case a thousand per
second and they're all going to run at
the same time and each transaction is
going to mutate the keys and values in
the database and it's going to do that
subject to a constraint which is that
each transaction taken as a whole
preserves the ring it may reorder stuff
and may move stuff around but the ring
as a whole will stay intact so this is
super cool because it gives us an
invariant that we can check at the ease
at the end that's super easy to tell
whether acid was violated right so like
if there was an ad Amissah T failure one
of those transactions would partially
execute and the ring would be broken or
if some of these transactions clobber at
each other and there was a lack of
isolation again the ring would break or
get shorter or get longer or something
so that's just like a cool a cool like
easy way of telling if there was a
failure that is not of the like you know
it crashed kind and then the last thing
you'll note in that cycle definition is
that we're only expecting to complete 1%
of these and that's because of the rest
of the file so so the next thing here is
we're going to do some random clogging
that's where we take these simulated
network connections like the ones I
showed you and at random or
pseudo-random link
terminus tically next time it'll happen
the exact same way if you rent with the
same inputs we're just going to stop
them and prevent them from sending or
receiving packets try and flush out
things of the sort that you saw in that
very first slide this clogging has the
Swizzle flag set Swizzle assort of like
clogging plus plus I guess it's where
you take a subset of the network
connections and you stop them like on a
rolling basis and then you bring them
back up in reverse order and for reasons
that we totally don't understand this is
better at finding bugs than normal
clogging it's kind of scary so the next
thing the next thing we do here is
called is called attrition in this test
attrition is just powering stuff off
sometimes we power stuff back on in this
case we do we're going to kill ten
machines total over the course of the
test and we're going to leave three on
at any given time so hopefully if
there's some power safety problem
that'll turn it up the last one here is
actually by far the most evil even
though it looks kind of innocuous
sometime in those 30 seconds we're going
to change the configuration of the
database and this particular
configuration change is designed to
provoke a coordination change which
means that the cluster is going to have
to execute multi Paxos and it's going to
be doing that while network connections
are randomly clogged while machines are
going down and rebooting left and right
and while it's trying to get a thousand
transactions done per second so you know
there's a bug in our pack so hopefully
we'll find it yeah we do a crap ton of
other stuff too so this one's like
really nasty instead of just killing
machines
we sometimes set them in the state where
like sort of try and simulate them
gradually failing all future system
calls have like a 1% chance of returning
an error so then the cluster we get to
find out like if it's smart about like
detecting that and like quarantine it
and destroying it before it infects
everything else a test graceful shutdown
tests a lot of good stuff like that we
also have like a our database has a
concept of locality you know it can be
aware of your rack topology or whatever
and of where your land links are and so
the simulation there's that too so we
can simulate just you know killing an
entire data
see if that was really durable we also
simulate dumb sis admins which totally
don't exist in the real world so one
thing we can do is just instantly
atomically swap the IP addresses of two
machines and see what happens or we can
instantly copy the data files from two
computers onto each other and just swap
them just switch their hard drives and
see if that results in any data loss
so that's tons of fun this is just a
random sample like one of the most fun
parts of my job is thinking up new and
creative ways of torturing our database
and then implementing that in simulation
and it'll so fun so now we get to the
basic problem with this whole approach
which is you have some set of machines
out there which are diligently chugging
through simulations exploring the space
of all possible inputs in the space of
all for possible failure modes which as
we learned just a second ago is very
large but still you're exploring it and
you're hoping that you find the bugs um
so the interesting fact is you have
customers hopefully and your customers
are running your distributed systems on
buggy crashy faily grossly under
provisioned totally improperly
configured hardware and they're doing
insane things to it by the way and PS if
it breaks it's your fault so they are
also exploring the space of all possible
inputs and failure modes and hopefully
you have many orders of magnitude more
customers than you have machines in your
test lab and so the question is how on
earth can you possibly hope to explore
that space more quickly than your
customers do another way of thinking
about this is you need to find more bugs
per CPU hour the real world by many
orders of magnitude which is hard so
there's a couple of ways we try to do
that I'm interested to hear what you all
think about this since it's definitely
an ongoing problem one way we do it is
just we make things fail a lot more
often right so like you saw that our
connections drop like pretty regularly
I'll know in the real world how often
does a disc fail like every two or three
years if it's under heavy
or something we make them fail like
every two or three minutes so that means
hopefully if there's a bug in our like
disk failure handling code we have many
more disk failures per CPU hour than the
real world gets and so we find it faster
than our customers would another thing
we can do which is kind of cheating but
that's the name of the game here is
speed up time right so there's a lot of
time when the clusters just sort of
sitting around being quiescent or it's
trying to recover from something and
there's some hard number of seconds it's
waiting for something to happen when
we're in that kind of a state we can
just speed up time and make many more
since econds pass per real-world second
than we did before so long as we have
the computing power on a single core
that's another trick okay so another
thing we do is called buggah fication
that's that's a in-house term I'm sure
but he else does this but causes
something else so the so the intuition
here is if you remember those first
examples I gave you they were both they
the basic problem there was that there
was an asymptomatic bug right the
computer on the left actually didn't
understand the contract of the computer
on the right it was always a bug it just
took something exceedingly rare to make
it show up well if you have
deterministic simulation and you're
exploring that space of all possible
failures you know you hope that it will
show up eventually but wouldn't it be
nice if it you didn't have to wait for
something really weird to happen for it
to show up and so the idea here is you
do just that thing which I said
programmers never do which is sometimes
randomly change what your code does so
in the first example you might have
written sign and bug if I is just a
macro right it expands to like do this
if you're in simulation with probability
something small and we compute a hash on
the line number and stuff anyway right
so you would say something like if bug
if I send packet B and then send pack a
day just to make sure that any consumer
of that interface really understood what
that interface did to make sure that the
like space of things that the interface
did was not like a very narrow subspace
of the set of things that it could
so here just two more examples from our
code you know sometimes don't send
everything you've got ready to send
here's one where if we're bugga fiying
we just never send a timeout
you know because like timeout might
never show up it would really suck if
the other person on the other end of
here we're counting on that timeout for
some reason and you know we do this in
other ways too okay so the last thing
relates to what my favorite topics is
called the Hearst exponent which was
first described in the 1951 edition of
the transactions of the American Society
of Civil Engineers which I own a copy of
because I'm a huge nerd and it was
described in this article long-term
storage capacity of reservoirs by Harris
Hearst so Hearst was a British civil
servant who was sent to Egypt to study
the dams and reservoirs on the Nile and
he noticed that the previous generation
of engineers had designed these dams and
reservoirs so they wouldn't explode
unless there was 100-year flood and they
wouldn't run dry unless there is a
100-year drought
seems pretty sensible so then Hurst
noticed that the 100-year flood and the
100-year drought were happening about
once every 15 years and that was
interesting and what he figured out was
that the previous generation of
engineers and we're all going to snicker
at this but don't because people in
finance did this up until 2008 had
assumed that every rain or not rain
event was an independent trial and they
were totally uncorrelated right but of
course this is a total lie this is not
real in the real world the probability
of rain on Wednesday given rain on
Tuesday is slightly higher than the
probability of rain on Wednesday you
know
full-stop they're not independent at all
and the Hearst exponent is a way of
quantifying that lack of Independence so
you know when you have independent
trials like that what you get is a
Gaussian probability distribution which
falls off very very quickly in the tails
when you take into account the fact that
the Hearst exponent could be not
one-half you get a broader class
distributions called stable Parisian
distributions and the Hearst exponent is
the exact reciprocal of the Alpha
parameter of these guys so alpha of two
corresponds to a Hearst exponent of 1/2
which is a Gaussian but if the Hearst
exponent gets bigger than 1/2 then all
of a sudden you have something that's
not a Gaussian that has way more space
in the tails that means that high Sigma
events or events that naive theory would
predict our high Sigma are going to
happen way way way more often ok what on
earth does that have to do with
distributed systems
the answer is hardware failures are not
independent random events ok you all
know this in your guts right like if a
hard drive fails in a rack what is the
first thing you do oh my god check every
other hard drive in that rack it could
have been in a bad batch there could
have been some bad maintenance there
there could be a humidity problem in the
data center like everybody knows this
intuitively even if they don't actually
do what it implies all the time
the problem is that multiple cascading
failures which a non naive approach to
statistics tells us are much more likely
than a simple naive Gaussian would
predict are among the very very hardest
things to test in real-world physical
testing like getting a whole bunch of
Hardware all set up to like fail in like
some randomly totally terrible together
way is challenging but in simulation you
can do it really easily and we do and we
absolutely manipulate the Hearst
exponent and try and simulate as many of
these multiple cascading failures as we
can because we know that they're going
to happen in the real world a lot umm so
you put that all together we estimate
we've run the equivalent of trillions of
real-world CPU hours worth of tests we
can run five to ten million simulation
runs per night on our cluster each one
of those simulates an entire cluster
behaving anywhere between I call it five
minutes in an hour or two depending on
the test and then plus all that bug of
Education and speeding up time and
everything else and we've been doing
this for years
so we've we've done a lot of testing
so there's some bad news though which is
that we've totally broken debugging so
you all already know that stepping
through code that is laced and infused
with callbacks is horrible if you were
to take a traditional debugging approach
to a deterministic simulation of your
callback infused code that'll be much
worse so you're going to have multiple
sort of callback infected monstrosity x'
all interacting coexisting in the same
process that you're attached to plus all
the simulation code around them that's
trying to convince them that they're
secretly talking to each other it's
insanely challenging we do have people
who are really good at debugging who are
able to like step through like two or
three levels of the stack doing this and
like we're all in awe the rest of us
cannot so what you're left with is
basically printf which sounds pretty
horrible and barbaric and I'll be honest
it is but it's actually not that bad
when you have deterministic simulation
and you know that if you rerun the
simulation with the exact same inputs
the exact same set of stuff will happen
in the exact same order at the exact
same times that lets you put in non
spammy print deaths that depend on
conditions that you know will be
fulfilled next time it lets you
gradually like work your printf deeper
into something kind of you know corner
the bug and then kill it and then you
know once you've killed it it lets you
know that the bug didn't repeat although
there's a subtlety there that if I have
time I'll get to maybe in questions okay
so that's cool but there's still a
nightmare case which is that our
simulation is wrong there's at least two
ways that a simulation can be wrong one
is it's not brutal enough there is some
pattern of failures which can happen in
the real world and which does not happen
in our simulation and you know we don't
think that's true but who the hell knows
networks are weird scary things so
that's one
another problem is we may just
misunderstand the contracts of the
operating systems right like F Sync
might mean something different than we
thought it did I actually the funny
story about that not now though or you
know you're porting to a new platform
and like some system call that you
thought you know is given the same name
confusingly enough actually has a
slightly different slightly different
guarantee that could be a really big
problem or the OS has a bug right that
could be a big problem too you know the
simulation is only as good as our
understanding of what the operating
systems and the hardware actually do so
to solve both well to try and catch both
of these kinds of problems with
simulation we have this backup cluster
which we call sinkhole so sinkhole is a
bunch of little little server
motherboards these are like real
services they're kind of cute but
they're they're real server motherboards
with ECC Ram and whole whole shebang and
they're all hooked up with like cat 5
and through a bunch of switches and both
the switches and the motherboards are
all connected to programmable network
power supplies right oh yeah you see
where I'm going so then we just
programmed these things to turn on and
off all night while our database is
running in the hopes that you know we'll
find something and what we found is that
network power supplies suck they burn
out after like two days it's a giant
pain in the ass then we buy more we've
run through hundreds of these things
also SSDs don't like it when you toggle
their power on off really fast that's a
little bit more expensive we're really
proud to say that we've actually never
found a bug in our database doing this
which makes us think that simulation is
is doing a pretty good job I said I
never found a bug in our database doing
this we have found bugs and other
people's software so this is the other
thing right that simulation can't test
and that's a real danger so software
that we didn't write software that
wasn't written in flow but that's part
of our stack we cannot test in
simulation so early early versions of
foundation DB use zookeeper for
maintaining coordination state
found a power safety bug in zookeeper
with a precursor to sinkhole we report
it they fixed it that was awesome
but that experience was so traumatic and
kind of scary that we ripped it out of
our stack and wrote our own packs s
that's written in flow it runs under
simulation so like now we're like a
little more chill about that also
deploying job as a pain this one's kind
of funny so we once did a sinkhole run
we installed our database on all these
computers started them all up and
running and then just like started
killing power left and right and one of
the processes didn't come back up and we
were like what that can't happen
our database is power safe so we dug
into it a little bit and we found out
that the data files had all been durably
synced and log to disk they were right
there the configuration files for the
database we're like non-existent or
corrupt or something because apt had not
called F sync so then the database
process came back up it was like oh no
configuration file I must be a new
process oh wait there's data here
oh no and a panicked so that was that
was fun okay I've talked for a long time
let me let me wrap up here despite all
that we're doing you know that space of
all possible failures is very very very
large and so we have to explore
systematically but there's all kinds of
ways in which we fail to do that because
we're humans so here are just a few the
things that are on our mind that we
worry about a lot one is you know we'd
probably feel a lot better if we had the
resources to have a couple employees
whose job was just to introduce bugs and
see if they make it through simulation
and then if it does then that's a bug
report against the simulation framework
another thing is more hardware so like
this is kind of weird I feel like we've
entered like a new like phase and the
relationship between man and machine
because if you look at the work flow of
one of us it looks like you make some
changes to the program you recompile and
then you run like 10,000 simulations if
you did something obviously dumb and
then you hope that if you did something
subtly dumb you'll get caught that night
when we run 10 million that sucks
running 10,000 simulations takes like a
minute or two or I don't know a while
you lose your train of thought at
he breaks your flow like this is why one
reason why people use interpreted
languages right is you can even get rid
of that compilation step we've just
massively increased cycle time of
debugging or out of coding and that's
terrible so if we added more hardware
that might like weirdly like increase
the productivity of all of our
programmers just kind of not how it
usually works if you think about it it's
kind of cool so the this one this number
three is is the real nightmare so if you
think about it
say I'm there I'm writing writing some
some programming and I write a bug and
the bug is caught by the simulation
framework I have just immediately got a
negative feedback say I write another
bug and it's not caught by the
simulation framework I get no feedback
so I am slowly but surely being trained
to write the kinds of bugs that slip
through our simulation framework then
I'd like you you're laughing but this
literally keeps our CTO up at night it's
it's horrifying
it sort of bears some resemblance to
like antibiotic resistance and bacteria
if you think about it but like this is
like a real concern we are training our
programmers to defeat the simulation
framework it's a nightmare so we're
thinking of a bunch of different ways of
trying to fix this one is have two
simulation frameworks that operate on
different principles and you know use
one of them for like day-to-day
debugging and like development and
bounce against all the time and the
other one only use it we're about to do
release and run millions and millions of
simulations on that one and see if any
bugs slip through the first one and this
is sort of like how we're trying to
defeat antibiotic resistance right pets
they're the inspiration that would be a
lot of work though so we're trying to
think of other ways to do this let me
know if you have any ideas then the last
thing is just more real-world testing
more stuff like sinkhole we know we
should do this but we hate it because
the hardware is terrible I have a
co-worker who jokes it like every part
of programming is fun except the parts
that interact with networks discs or
power supplies and like that's now all
you know you like ya sinkhole goes
through a million programmable power
supplies a week it's terrible the idea
of having that times 10 gives me
nightmares
but we all know that it's good for us
and like you know we're at the point
where having a little bit more of that
would probably give us a really good
return um ok so that's my talk Zen
behave any questions yeah
yeah so there are definitely pros and
cons to both approaches I will I will
stop you one second here all this
simulation is run on our production code
if I didn't make that totally clear so
the processes huh yes that's right so
the only part of our actual production
code that's not tested under simulation
is the part that actually does the non
simulated talking to disks and networks
which we obviously can't simulate
although we've thought about how we
could write so so right so the benefit
of simulation is you can do many many
more different types of things and you
can generally be far more brutal and far
more like calculatedly evil like in a
real production environment you don't
have like omnipotent evil godlike power
to like stop and start network
connections in the most inconvenient
possible way or to like do what you know
is like the hard case for paxos and like
deliberately do that to try and screw
with it right on the plus side like
doing it for real and your for real
production environment may be teaches
you something about hardware that you
didn't know right so sinkhole is
hopefully I really hope not anything
like what any of our customers run in
production maybe there's something wrong
with all those disks and network cards
that our customers run in production
that we don't know about so there's
advantages to both approaches we should
probably we probably do a lot more of
that yeah I mean Hirst was a
statistician not an environmentalist or
a development economist but I don't know
what we're done all right
sorry I'll talk to you after Thanks
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>