<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;The Biological Path Towards Strong AI&quot; by Matt Taylor | Coder Coacher - Coaching Coders</title><meta content="&quot;The Biological Path Towards Strong AI&quot; by Matt Taylor - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;The Biological Path Towards Strong AI&quot; by Matt Taylor</b></h2><h5 class="post__date">2017-09-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-h-cz7yY-G8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay I've got I've got a lot of content
if you want to talk to me i'ma try
alight on Twitter I'll answer questions
there if you're on the slack channel I
created a room called HTM if you ask any
questions there I'll come back around
afterwards and answer them I'm a
community manager manager at noventa all
of our code is open source so I manage
the open source community okay my agenda
why we K is not intelligent I'm gonna
talk a lot about cortical Anatomy the
power of the pyramidal neuron which is
crucial to our theory and we're going to
talk about layers and columns as those
are structures within the cortex and
then I'm going to do a very deep and
quick dive on the entire HTM Theory our
our theory of how intelligence works in
the cortex even sensory motor stuff all
right
I've already talked to you about this I
don't think we can do some telogen s--
from the reasons that I've sort of told
you but I'm gonna tell you explicitly
why and what's missing so there's
there's two things one is realistic
neurons I mentioned that the point
neuron that's used in machine learning
systems today it's too simple so I'm
gonna tell you what we need to model in
this neuron and the other thing which
may not be immediately evident to you is
that for an intelligent system to exist
it has to be able to move someone named
anything that is intelligent that does
not move what
I don't want to repeat I don't even know
what it was okay okay you can't there is
nothing that is intelligent that does
not move and the reason is we have to be
able to explore our environment we have
to the way we understand reality the way
we understand the world is by testing it
is by interacting with is by doing
somethings by taking an action that
changes something in the world that's
how we differentiate ourselves from our
environment we have to know who we are
versus what our environment is when we
move this thing what happens when we get
a different stimulus when I move over
here my whole perspective of the world
changes you don't really think about
that but I have a completely different
picture when I move here than when I
move here and my brains just seamlessly
integrating it all together so movement
is really important and I'm gonna talk
about that so let's talk about brains
we're gonna do is a little deep dive
into the cortex I'm going to talk about
the neocortex which is the wrinkly stuff
the old brain will just drop out if you
spread this out it looks like a sheet it
looks like it's about the size and
proportion of a dinner napkin and you'll
see these structures this is a
homogeneous structure of the neocortex
it's the same throughout and at its core
is this little cortical processing unit
that we call a cortical column and so
I'm going to talk about this now we've
known that in the cortex there are
layers for over a hundred years
this is qahal is a famous neuroscientist
who did all these drawings of the cortex
back in the late 1800s and he's there
still used in textbooks today so he we
found these layers a long time ago we
knew they existed but this idea of a
column in addition to the layer sort of
creating this kind of structure a
logical structure is sort of new because
you can't look at the cortex and see the
columns but we have the technology now
to see them that they're there we can
see but because of the cellular
structure that these structures do exist
so I'm going to talk about these layers
and column so columns contain layers and
layers
tane neurons so this is just a drawing
of a layer I did these layers are
roughly cylindrical I mean this is all
sort of abstract but but it's definitely
true that layers contain neurons columns
contain layers and the pyramidal neuron
is an amazing computation engine this is
really the atomic computing unit and in
our model as the pyramidal neuron and in
any I think today even an a NN system
it's the primary compute model but
there's something that we need in this
model that we don't have today so we do
have an inactive state and an active
state I mean this is important what the
what the neuron does is it activates
like it turns on its spikes but we need
another one we need a predictive state
and and this turns out to be really
important a neuron needs to know yes I'm
active or no I'm not but I think I might
be I think I might be active soon that's
that's an important prospect because
that's what your brain is constantly
doing it's constantly making predictions
about what it's going to see next now in
addition to these different states the
neuron also has different integration
zones so a little neuroscience lesson
there's three different types of
dendritic segments that a neuron can
have proximal which is feed-forward
input that's like direct input usually
from in the direction of the sensory
organs so some senses are coming up and
we're we're processing that primary
input and when we have distal this is
sort of a lateral input from basal
dendrites and this is a contextual
information that is used to modulate
that proximal signal apical feedback is
generally coming from layers that are
that are higher up in the column or
other parts of the cortex and like a
higher up in the the entire hierarchy of
intelligence I'm not even going to talk
about hierarchy today but so these three
things are really important it's not
just one signal it's like the neuron is
looking at all three of these different
zones and deciding am i active or not am
i predictive or not that's what it
that's its job so I told you that layers
contain neurons right so it follows that
it
our neurons have these integration zones
and they're all oriented in the same
fashion layers themselves we'll also
have these integration zones this lets
us treat this as sort of its own little
compute module so these layers also
compute a layer can have a hundred
thousand neurons in it and but typically
all of the distal input to that layer to
those neurons will come from a common
place all of the proximal input will
come from a common place sometimes
they're split it depends but the point
is the layer doesn't know where it's
getting its input from it does the same
thing so that's across all your brain
these if you're processing visual input
somatic input which is touch auditory
input the cortical columns that are
processing that sensory data are doing
the same exact thing the same process
and it's all about these these layers in
the columns so like I said proximal
input is usually a driver signal and
these are modulatory signals I'm going
to show you some these aren't
simulations they're just visualizations
of these systems running so and it sort
of looks like this it's like a cube this
is the equivalent of a layer in software
so when you see this think of a layer
it's a bunch of neurons I'm not very
good at animating so they're cubes but
so you're gonna see this later I just
want you to know that's that is a layer
and each one of those cubes represents a
pyramidal neuron and their color
represents what's the state it is in
okay I have to talk to you about sparse
distributed representations and this
it's really hard to change to this but
imagine a neuron just one neuron it
might have thousands and thousands of
dendrites like of potential connections
to other neurons right that and what and
it's always looking at those connections
and it's always seeing what's active
what's not and deciding am i next
am i active am i next to my active all
the time if you were to take all those
dendrites and kind of wrap them up into
a fiber you know like a fiber optics
cable I like to think of it as a fiber
optics cable and then you look at the
the end of it you know that's an SDR a
sparse distributed representation in
your brain only two percent of your
neurons are active at any point in time
each one of those neurons that's active
represents something semantically or
more than one thing could represent many
things it turns out this form at the
sparsity and the distribution of it are
really really important to how your
brain computes and each one of those
bits has to have some semantic meaning
so if you're a neuron and you're
deciding whether to fire or not you're
constantly looking at this long bit
array right all the nests dr is is an
array of bits it's really simple but
only two percent of them are going to be
on at any time based upon which ones are
on it's gonna help me decide as a neuron
whether I fire or not and I'm gonna be
looking at my proximal SDR it's coming
from below and I'm gonna be looking at
distal STRs and potentially apical STRs
all to decide whether I'm gonna fire or
not I'm going to show you some of the
properties of SDR is really quickly
because I can just to give you an
impression of what an SDR looks like
that's not very good one
well you can't see the whole thing but
this is like a 256 bit SDR it's a 2%
sparsity with you know dub five bits on
and the capacity of this in this
particular SDR 256 bits with five bits
on there are 8.8 billion ways to arrange
these five bits in this space which is
pretty large but we typically use STRs
that are like this big and we turn like
40 bits on so the capacity is much much
larger I don't even
it's more than there are atoms in the
observable universe the point is you'll
never run out of space here in this if
you think about this as a fiber optics
cable and you've got a signal coming
across that cable you can represent
anything in it like forever so that I
mean if that's not amazing okay one
other thing I'm gonna do a quick this is
a really important property of STRs two
on the Left I've got one random SDR in
the middle here I have another random
SDR on the right here I have their
overlap which is all the bits that they
both share seems really simple really
really important because this is a
similarity score this is how close these
STRs are and another important one is
the union so if this contains some
semantics some description about some
state somewhere and this also does two
then this contains the both of those
semantics and the the previous one
contains the semantics that they both
share and and this is really important
because as a neuron if you're constantly
scanning all of your your distal
dendrites looking at all the neurons
that are on or not you want to know if
you've seen that pattern before so it's
really nice to have this property to
compare oh I've seen this SDR have I
seen this SDR before it's it's it's easy
to do that
yes okay so the question was what is a
predictive state mean biochemically in
the neuroscience the neuroscience
terminology is a depolarized neuron it
has something to do with ion channels
and I don't know I'm not a
neuroscientist but look up depolarized
pyramidal neurons and that is basically
what we say is a predictive state okay
back to slide for a moment talk to STRs
okay let's talk about encoders real
quick encoders in in biology are your
senses so think about your retina or
your ear or whatever your optic nerve
for example looks just like that fiber
optics cable that I showed you and your
retina is doing a ton of work to produce
a semantic representation of what you're
seeing and pipe it into your brain we
don't study senses at my company it
doesn't so all of our encoders are
really stupid really simple not say
stupid they're simple but replicating
the retina and the cochlea is extremely
hard and we're working on the cortex not
the other things
so our encoders but but the fact is in
order to test these theories we have to
have semantic representations to push
into the system and and try and get it
to understand the patterns in those so
we've done that somewhat artificially or
not artificially non-biologically so
these examples of encoders I'm just
going to show you one example like this
date encoder this doesn't even exist in
your brain like we just made this up
imagine you had a watch and you're in
your brain that constantly told you
exactly what time it was what part of
the season it was at what time of day it
was you just always knew exactly what
time it was
that's sort of what this is like so an
example of this I am taking a date
here's today here's tomorrow and I'm
encoding four dimensions of semantics
I'm encoding what day of week it is the
weekend the time of day in the season
and you'll note that I'm not labeling
anything I'm just setting a
section of bits in the representation to
represent that semantically so as I go
forward in time the day of week cycles
periodically through its space the
weekend cycles the time of day I haven't
touched yet but you can see the season
is also slowly periodically moving as I
move forward in time and if I do touch
the time you can see the time of day
also moving down here is the whole
encoding for this time stamp we can
simply take all of those sub and
coatings and just concatenate them
together and we're done so this
represents the date this is a way to
encode semantically a date and we also
have well I'll show you this input space
this sort of introduces the idea of
because we can we can encode a bunch of
different disparate data and put them
all in one SDR and then pass it into the
system we typically call that the input
space for the system so for example
here's some graph data this is just
power consumption at a building or
something so you can see there's obvious
temporal patterns in it and you make
this smaller as I go you know through
the days you'll see these the power
value which is this this bucket right
here is is cycling a lot because that's
that's the main value that I want to
encode here the rest of it is just time
of week and weekend the those other two
values down at the bottom and you'll see
the the weekend one go from one to the
other
so we're encoding not only a scalar
value but at what time it was recorded
so there's automatically an association
there yes you had a question
yeah you could do that um the thing is
if you make it bigger it's weighted
differently so it depends like I wanted
to wait all those generally the same but
how big you make the range for your for
your encoding if you're going to
concatenate it all together with a bunch
of other encodings that affects the the
weighting is important yeah yeah it's
all about how big should we make these
and yeah it's about the importance of
the feature so you so you can sort of
see that this is what an input space and
again imagine the fiber optics cable
that you're looking at this is sort of
how it may be lighting up over time this
could be an input to your brain but this
is totally you know we made this up
right like I could take a completely
different encoding mechanism so I
changed the scalar encoding mechanism to
one that kind of randomly distributes
that bucket instead of keeping it a
continuous bucket it does the same exact
thing so you can imagine their baby
thousands of ways you might be able to
semantically encode this specific data
and into the system so they can
understand it this is just one way okay
so that's encoders alright so here's
where it gets deep spatial pooling in
the brain in one of those layers in some
of those layers and in the brain we have
these little structures called mini
columns and what a mini column is is a
grouping of neurons you actually see
them here it's it's when neurons grouped
together and share proximal input and
this happens everywhere in your brain
and and in every one of these cortical
columns some of the layers are doing
this type of operation and what it's
actually doing the point of it is to
take that spatial input that we just saw
like that input space and redistribute
it so that we have control over that
representation and and you know I think
you'll see why in a minute but we do
that by creating these mini column
structures and saying every cell in this
column is gonna share its proximal input
and this is all about feed-forward
proximal input and but it also has to
maintain the semantic similarity of the
input
and I have to show you this for it to
make any sense I've got a lot of demos
um
over connected synapses okay so you
remember when I showed you that layer in
software I called it and it was like
this big three dimensional grid imagine
that this is is that grid seen from the
top okay so each one of these boxes is
actually a column of neurons not just
one neuron so these are we would call
these mini columns and they all and
here's here's an example input space
we'll pay attention to that so this
would be just some random input that
would come in this input space each one
of these columns has a specific
relationship to that input space so what
I'm showing here is that columns
potential pool of connections that it
might make to the input space proximal
connections every one of these columns
has a different potential pool they're
just randomly initialized we're trying
to set up let's set it up like the brain
because every neuron is not able to
connect to every other neuron or else we
just make it all of them connect to all
of them and there's a reason for that I
don't not gonna get into it but every
one of these has a different
relationship with the space when we
create this out of this state called we
call it a spatial cooler but it's really
just sort of a spatial pooling operation
that we're running we also set up each
one of these columns to have random
initial connections with the input so it
can be immediately stimulated okay each
one of these connections can only exist
in its proximal pull in its potential
pool excuse me there will never be a
connection in the white areas and also
each one of these connections has a
permanence value associated with it so
that some of your deep learning guys
might might find this familiar because
it's basically heavy and learning we're
taking as a threat term yeah we're
taking so yeah like for that one that I
highlighted here's its here's its
permanence it's like 0.6 something it's
connection threshold is 0.1 so it's
connected
all of them initially are different this
one's a little different that one's a
little different you can see the chart
on the side the red ones are not
connected they're too low so those
started off as not being connected this
is sort of the initial state of the
Pooler let me show you how it learns
okay same setup for this visualization
with a little bit of a difference
alright so we have a real input coming
in here it looks familiar right from the
one I showed you earlier
so all these buckets they actually mean
something and here's an example of one
of those columns it didn't activate it
didn't become active the whole point of
spatial Pooler is to turn these
activations into these activations and
retain the semantic meaning of the input
space but crit allow us to normalize how
many bits are on so that bit that I
checked is not active these green boxes
are places where it had connections that
overlapped with the input space so we're
doing an SDR comparison here right we're
saying how many of your connections
overlap with this input space it's the
green ones do that was apparently not
enough for it to become active this one
however had enough of these connections
overlapping with its input space to
become active so what we'll do is we'll
do this calculation for every column in
the structure how much do you overlap
with there do your connections overlap
with this input space and if they
overlap enough will typically stack rank
all those columns and then cut them off
somewhere that's sort of what I try to
show over there all of those above I
don't know 40 4 or somewhere in there
we're gonna turn those columns on by
turning those columns on they and they
inhibit their neighbors from turning on
you know by doing this sort of stack
ranking this competition and this now
represents the semantics of that and the
last step is if these columns win
they're proximal connections to these
these bits in the input space that were
correct those get increased those
permanence values get increased so it
reinforces I recognize that spatial
pattern
specific spatial pattern I'm gonna see
it again and I'm gonna recognize it
again for all of the ones where the
connections did not overlap with that
space in the act of columns then will
decrement them so if we played this for
a long time and it was learning real
patterns and we went and inspected that
that column again we might see that
there's many less connections in the
parts of the space where it hasn't
gained an affinity to like it has it
hasn't started connecting to so that's
actually spatial pooling so what we end
up with and this I'm gonna I'm gonna do
more animations here okay so to sort of
understand
hopefully that these these column these
mini columns all represents some
proximal some proximal connection to an
input space they get activated if the
connections are connected to are active
and then once those columns are
activated then we're going to choose
what cells within the columns become
activated and that's the next step so I
just showed you this is all proximal
input that we've talked about with the
spatial Pooler
but there's other stuff going on here
there's distal connections happening
between the neurons in the layer it just
in this one layer so we're getting our
distal context from this same layer so
that the neurons in this layer are sort
of looping back to themselves and giving
themselves context and what do you do
when the only context you have is
yourself your context is essentially
your past the states that you have been
in in the past so that's what we call
this temporal memory algorithm so it
identifies the context of each input
that we get based upon the state of the
distal dendrites or the distal
connections that the pyramidal neuron
has and it works entirely within the
structure of many columns that we've
just activated and it will put the cells
into a predictive state if necessary so
I have to show you an animation of this
this is by far my coolest animation okay
bear with me I have to set this up so
this is going to be a sequencer just a
little stupid note sequencer okay
okay you're the notes so this is the
input space each note is being encoded
in a different block of cells this one
is a rest and it's not used the spatial
Pooler is activating columns over here
and I can show this a little better if I
spread them out so you see the columns
right so this is spatial pooling
happening right now
and I'm going to show you how cells
within those active columns become
active and become predictive so let's
stop this right here so let's show the
active cells you guys see this okay in
the back and it's kind of okay so now
I'm showing you active cells dive right
in here this is e so these are the
active cells for an E and I I mean I
haven't told you this before but these
cells represent E it's learned it enough
times that they've they do at this point
represent E these active cells represent
a but when we loop around to the first
one look what just happened what's up
with that okay
the thing is I'm sending the sequence in
and I'm not looping it I'm not doing
like over and over and over and over I'm
sending four notes in and then I'm
resetting I'm sending four notes in and
then I'm resetting I'm trying to train
the sequence but I don't want to Train
it on some endless infinite loop of
things or else it'll just think how long
does this ever go on you know if you
imagine it's hard to temporally cut off
the sequence that is kit contains loops
so we're just going to cut it off
manually run it cut it off run it cut it
off so every time it sees an a it sees
it out of context every time is it never
follows anything if we see a c-sharp it
knows all C sharp follows a so I know
these exact
we're gonna turn on so that leads to my
point there are two ways that a neuron
within a mini column will become active
there's two ways the first one is if is
if there are any neurons that are
already in a predictive state if we have
it a column activate and we look through
it and we say oh there's there's a
neuron that's in a predictive state you
win you were right I mean that neuron
was correct because in the last time
step it thought I think I'm going to be
predicted I think I've seen this before
I'm gonna go into a predictive state so
when we get to the next one we'll
activate it but that's not happening
here because we've we've never seen a
come after anything we have no context
so if we have no context if we get an
unrecognized input and there are no
predictive cells here we are going to
activate every cell every cell in the
column because we don't know we're
confused it could be anything and what
will happen is over time we'll pick a
cell to represent that new sequence and
it will represent it going forward so
now you're probably wondering great but
how do we put a cell into a predictive
state so I told you the two ways it
could be active if there is a predictive
cell in the column it activates if
there's no predictive cells in the
column
they all activate we call this bursting
by the way I think that's a neuroscience
term but how do they become predictive
so how we decide whether something is
going to become predictive or not is
will go through based on some input will
have to go through every single cell in
the column I'm just going to show you
which ones are currently predicted at
this at C sharp for example we're
predicting that these cells are going to
come next these are the cells for E
because we've seen this you know 1020
times so far the reason that those
become predictive is because they have
these distal connections that have
already grown because I've been playing
this over and over and over right
this becomes predictive because we've
already done the transition a to c-sharp
over and over and over so every time
we've done that we've grown segments and
reinforced learning from from this C
sharp or this prediction of e to the
previous state which was C sharp and if
I look at some of these other these
others that aren't predictive that's
because they have no segments they have
no connections so if I were to move one
time step forward you should see all of
these blue cells turn orange right so we
correctly predicted e so let me show you
something interesting I want to turn
this off and I'm just I'm gonna let this
play a little I'm going to show you how
bursting really really works how we
really learn a new sequence so I've
learned this pretty well a C sharp e a
what if I stop it
let's stop it right here at C and these
predictive cells
what are they predicting II I'm gonna
change that let's let's make it F we
haven't seen it F before so when I scoot
this forward let's turn on an active
cells okay so at we're at the state
right now where we're at C sharp all
these active cells represent C sharp
we're predicting these cells which are
the cells for e when we move forward
we're not going to get those cells does
anyone know what's gonna happen oh what
was that all the new all the new columns
because we're going to have a new
spatial input it's something that we
have never seen before
we haven't even shown F to this system
yet so we're gonna have a new spatial
input here it is and almost all of them
burst what this is doing is so we've
seen a C sharp e before and now we're
seeing a C sharp F sharp never seen that
so the systems like whoa everything
bursts so we get this spatial input
that's new
except for this one because it must
apparently share a some semantics with E
but for the most part everything bursts
and we're like this is a new sequence so
at this point I'm just gonna play this
forward so we're gonna see these columns
burst for a while until it gets the
rhythm of the new sequence and then it
will eventually stop bursting and
realize okay well this is normal right
this is normal I've seen this sequence
before I've seen a C sharp E and a C
sharp F sharp so it has stopped bursting
except for that very first a a I'm back
at C sharp I'm going to show you all the
predictive cells now does it look like
there's about twice as many predictive
cells why is that it's predicting both
it's predicting E and it's predicting F
sharp because it's seen both of them now
if I were to play this on and on and on
and over and over eventually it'll
forget that it ever had a C sharp to e
transition and it will just have the
pattern C sharp to F sharp all of these
are tuned all of these things are
tunable so you can make a system that
forgets really fast or remembers forever
or whatever so hopefully you get the
gist this is sequence memory this is how
is a really simple example okay this
this size of the structures is is
smaller than we usually use I just can't
visualize the size of structures that we
typically build these systems with okay
I'm running that time okay so you might
be wondering because I said what am I
supposed to do I have seven minutes left
okay you might be wondering hey you said
that the distal signal came from
somewhere else but in this example we we
had we had all the input coming
approximately but we were feeding the
distal input back into ourselves we
weren't getting it from somewhere else
from some other layer some are part of
the cortex like I said that's what
provides the temporal context for the
layer because you're using yourself as
your context as your reference that's
how that works
now what if I don't have much time to go
over this what if we change this a bunch
and we said okay we're going to have
that proximal input be a sensory feature
that some sense
or has felt on some object and we're
gonna have the distal input be the
allocentric location of that object so
if you think about an object you can
think about a coffee cup for example
anywhere in the world any way I could
think about it there I could think about
it there I could place it wherever I
want you have an ala centric
representation of the object mean it's
self-contained it doesn't require any
other coordinate framework it just
exists a coffee cup right so that's what
I mean by allocentric and I'm gonna give
you another demo of this which is in
PowerPoint I didn't make this one
somebody else did it was so good I just
wanted to do it so here we're talking
about a single column of a single
cortical column with two layers so this
is sort of our newer research stuff
coming out of our company so we've
identified this cortical circuit that
we've seen exists it exists in layer
four and layer two three of the cortex
where layer four has many columns and it
receives input and we're going to send
the distal input in as the allocentric
location on an object that we're about
to touch when we touch that object we
get sensory information that comes in is
proximal input though we make a
prediction which is what the location is
based on all the things we've ever
touched on on that part of an object
before and if we're correct then that's
what represents this feature at a
location on an object that gets passed
up to another layer okay this and I
can't go into the details I just don't
have time but this other layer now it's
it's getting proximal input from that
layer below it that's sending in sensory
location features and it's going to
decide based on that sensory feature at
that location these are the neurons that
have represented out in before and these
actually represent objects so in this
case it's ambiguous if we touch this
point on this object well that feels
like a cup and a can and a ball but if
we touch it again we do the same thing
this is a different feature
it's not smooth it's kind of the rim and
then we pass it up then we can take the
ball right out because and this is all
those union properties I'm talking about
STR these are all STRs so we can now
identify okay it's not a ball after the
second touch let's touch it again
here's another unique feature at a
location and I can now rule out the cam
so I know now this is a coffee cup these
bits these on bits in that output layer
represent an object in your brain or in
the brain of the software we can go even
further with this with multiple columns
and this is the cool thing if we have
imagine that each column represents a
finger it doesn't really work like this
in the brain you've got lots of columns
you know working with just one finger
pad but imagine that you had three
columns in each was a representative
finger it's really useful if this finger
can inform this finger right if you're
touching something and they're both
touching they are doing that your your
brain because these columns are sharing
information when you touch something you
get you get feedback from this finger
that helps this finger understand what
you're touching so what happens here is
as we simultaneously touch this object
and they all get different locations
with different features from these
fingers the same thing happens and then
in the output columns one of they're all
ambiguous right the ones more ambiguous
than the other because it's like well
this feels like this this or this and
the other is like it's definitely not a
ball well in your brain these columns
are informing each other and if two of
the three columns are like that's not a
ball why not share that information with
your other finger that thinks it might
be a ball and it can actually feedback
and and inform that the the column
that's associated with that sensory
input that that's not a ball and update
its representation the same thing if we
do yet another grasp with different
features all feeding up into the object
recognition column the this output layer
is really doing a temporal pooling
operation it has a library of all the
objects that's ever learned and it's
just narrowing down narrowing down every
time you touch something that's like
well it's not that it's not that it's
not that that's what it is and
got lots of columns working together all
sharing what they think that object is
that you're touching then it can be much
much faster it can identify the objects
much faster do we do one more touch no
that's it okay and I am I have two
minutes so let me get through these last
bit of slides like I said on the slack
channel there's HTM is one of the rooms
you can ask me questions there and I'll
be around today all of our code is open
source we've got our research code or
core code etc I'm the open source
community manager so if you deal with
any of this stuff you're dealing with me
I'm happy to help and other thing is all
of our research papers are accessible we
try and make everything as transparent
as accessible as possible
and I have YouTube channel so I do
everything I've shown you is on this
YouTube channel I have this whole lesson
called HTM school that goes through
everything from bit arrays to temporal
memory sequences from the ground up and
I'm working on some of the sensorimotor
stuff that I just talked about there'll
be more episodes about that coming soon
so if you're interested in this please
check us out nimitz org i'm rhyolite at
twitter and github and you can follow of
my company into Mendte
also I think that's it yeah so I'm happy
to take questions in the very limited
time that I have yes
yeah that's that's what well okay
our goal is to try and understand how
intelligence works this just happens to
be something that we can see and we can
we can postulate we think that this is
how object recognition works and it's
not just your fingers right it's your
eyes it's your ears it when you think of
a coffee cup you're not just thinking
about how it feels you're thinking about
what it looks like so all of those since
all that sensory input contributes to
your representation of objects that you
know in the world so the existence of a
coffee cup exists everywhere in your
brain all at once and it because well I
wouldn't say everywhere but lots of
places in your brain the place is the
process your somatic senses your visual
your auditor well you can't really hear
coffee cups but you know yeah yeah
no no so the question was if if you get
impaired if you have a brain injury or
something and oh if your sensory input
is impaired so what generally happens if
you're blind or something happens to
your senses is your brain is very
plastic so it'll reroute it'll it'll
take your auditory input and pipe it
into the parts of your brain that's not
getting any input and you'll see that I
mean there's a reason why I'm blind
people have enhanced senses in other
areas it's because their brains still
working at a hundred percent yes they're
great new more for computing chips okay
just a note about hardware there's
nothing in hardware right now that can
can run this stuff really naturally and
fast like we've run it obviously on CPUs
we can run it on GPUs but it's not we're
not going to take advantage of this
architecture until we have hardware that
that is plastic until we have a little
compute until we can represent neurons
that can grow and and degrade
connections to each other we're not
gonna be able to do this in hardware
there's a lot of stuff we can do with
software but but there's definitely more
than one organization working on that
type of plastic hardware anything else
any other questions yes in the middle
the biggest limitation of the current
deep learning models well you know the
thing about integrating all of those
things to to go after a common goal I
think that I mean I think deep learning
can do some really great narrow things
like the facial recognition and voice
recognition and all that stuff but
putting it together into a package that
understands human humans it can
understand that understands intelligence
I mean that you can you know communicate
with it's really hard by the way who
thinks Alexis is intelligent
all right okay thanks everybody for
coming to my talk really appreciate it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>