<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Distributed, Eventually Consistent Computations&quot; by Christopher Meiklejohn | Coder Coacher - Coaching Coders</title><meta content="&quot;Distributed, Eventually Consistent Computations&quot; by Christopher Meiklejohn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Distributed, Eventually Consistent Computations&quot; by Christopher Meiklejohn</b></h2><h5 class="post__date">2015-09-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lsKaNDj4TrE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi I've got a tape I'd like to play
consider a distributed register so we're
gonna have two copies of this
distributed register replica a and
replica B so what we're gonna do is we
can do two operations on this register
we can set the value and we can retrieve
the value so here we're going to set the
value of one and we're gonna
asynchronously send the result to
replica B and imagine this is running in
a distributed system so concurrently we
can also set the register to two ever
applique after the original operation is
done and then set to a replica set to
see on replica B so once we deliver
these messages in the system how can we
know what the value is gonna be right
how do we know that replica a and
replica B will choose the same value and
how do we know what that value is going
to be from the from the point of
programming this model so traditionally
we kind of use synchronization in
systems to enforce an order and what
this allows us to do is reason about
what the value will be given certain
inputs right so given that we take
certain actions we can reason about what
the result of those actions is going to
be so this assists in making programming
easier this also eliminates accidental
non determinism in the system so if you
have a concurrent system and you can
have different scheduler interleavings
and you're not locking data structures
correctly you can have the value under
subset under multiple executions of this
for the same input return different
values for the output and kind of
traditionally we've had techniques for
doing this such as locking mutex is
semaphores monitors and you know all of
the distributed kind of extensions of
this work right so synchronization is
expensive because we have to spend time
we have to spend time to order things we
have to spend time to wait for things
and you know in some systems this is
fine if we're on a single machine it's
it's okay I mean it's not great we'd
like to not have it but there are kind
of two new real trendy classes of
applications that make this problem
exacerbated right so the first is
Internet of Things so if we if we think
about what Internet of Things really
means
we have devices that are low-power they
have limited memory to operate with and
they usually have limited connectivity
and the reason they have limited
connectivity is because it's really
expensive in terms of power to run the
antenna that a lot of these devices use
if these devices happen to operate over
shared stay and computing aggregates
they can make concurrent modifications
to shared aggregates and then come
online and we have a problem of
divergence we don't know how to deal
with what the right correct what the
correct value is and had a reason about
merging those values together similarly
one of the research partners in the
research group I'm working in is that
Rovio entertainment so mobile gaming is
another area where this is really
difficult for instance Angry Birds has
leaderboards has profiles and Rovio
wants the ability that people can
continue to play the game while they're
offline like if you're in an airplane
and you know when you have this when you
have this you're going to be modifying
like a leaderboard with your current
scores you're going to be updating you
know potential your profile maybe you
change your photo maybe you change your
name and then if there are multiple
people playing out of the same account
you have the problem of reconciling
those concurrent changes that happen
while clients were offline and with
things like leaderboards even when the
state is just you know coordinated its
its state that we all kind of contribute
to we also have the problem of saying
well how do I merge this into this
global kind of leaderboard aggregate so
synchronization is expensive so I mean
we want to have our cake and eat it too
right we want systems that don't
synchronize at all and I'm sure you've
seen a bunch of talks at this conference
already or any of the previous years
that talk about how we want to reduce
synchronization whoa no reduce
coordination and Peter Bayliss gave a
great talk yesterday about that but but
we also want to use shared state right
because we like this we want to have
concurrent edits we don't have to route
it we don't want to route everything
through a single kind of client to
perform an update so we we want the best
of both worlds so the idea that we're
working on for our research is trying to
start from the point of zero
synchronization can we start with no
synchronization at all in the
programming model and then only apply a
synchronization where it's necessary so
instead of you know instead of building
a
application ecosystem around a strongly
coordinated system such as zookeeper
why don't we design systems that start
with no coordination and only use the
coordination mechanisms when we need to
enforce something a global system
invariant so the goal of the research
that we're doing and that we've done
over the past three years and are
continuing this year into next is we
want to explore the limits if we want to
see can we design a computational model
that allows us to write coordination
free computations and make sure that
these computations are freaking from
concurrency anomalies when I say
concurrency anomalies I mean things like
the Amazon dynamo show up in cart where
items can come back because we use a
simple merge Union function across like
divergent copies of a cart so if we want
to look at kind of the application space
for distributed computation we have on
the y-axis here the difference between a
strong sharing property and kind of a
weak sharing property so how much shared
State do we operate over on the on the
x-axis we have a coupling as an
infrastructure property and we're not
talking about data centers specifically
we're talking about like data center
kind of latency guarantees moving to
open Internet kind of guarantees as we
as we move outward so things like
MapReduce kind of fit into the weak
sharing model and the strong the strong
coupling model right MapReduce is so it
is possible to do MapReduce across the
world I imagine you can do it but but
usually you want to run it inside on a
data center right you want the latency
requirements you need a strongly
consistent kind of coordination
membership service to you know make the
MapReduce happen and typically you only
share state at the reduced phase right
so the map is embarrassingly parallel in
terms of study at home I mean this is
really like super embarrassingly
parallel right because we don't share
any data you kind of contact the service
every once in a while to check out a
block you compute that block you send it
back if people compute multiple blocks
they don't care because that's just more
information so study at home is kind of
like really really weak on the coupling
property is this open Internet idea
right and then if we think about things
I have a strong sharing property kind of
tied to this model it's things like
Twitter right so I don't know the deets
of how Twitter is implemented but I
imagine that timelines are kind of
objects that that are contended for that
we have concurrent operations on right
your friends are going to tweet and
they're gonna appear in your timeline so
we're gonna have a single kind of source
of truth of this object and we're going
to concurrently write to this object so
this is an idea of strong sharing so in
a graph like this that you would see in
an academic talk where do we want to go
well we obviously always want to go into
the upper right hand quadrant because
that's that's the area that usually
never has anything in it so and this is
the area where we got to have a weak
coupling to the infrastructure where we
don't rely on a particular distribution
model or latency requirements and we can
tolerate things being offline and we
want to move towards the strong sharing
model so we can share a lot of data
between a lot of different clients in
the system so we'll briefly kind of talk
about fundamentals of distributed
computation I'll keep this short because
there's so many distributed computing
talks here that probably reiterate a lot
of this so when we look at concurrent
programming concurrent programming had a
problem of consistency right we have to
reason about what can be seen by what
threads in the system and the ideas of
like how we maintain caches and things
like this but when we move to a
distributed programming we introduced
the problem of partial failure right so
we're gonna we're gonna write to a bunch
of replicas and some of them are gonna
succeed and some of them are gonna fail
and then we're kind of like okay well
how do I reason about if I go to contact
the system again and get a value that I
wrote will it actually be there right so
it's really hard to deal with partial
failure and up until this point and
still today a lot of modern databases do
this today we have distribute we do
distributed computing assuming the
illusion of a single system and this is
something that you see in transactions
right transactions are an idea to
address this and the idea of the system
saying the single system image is that
if I have a distributed database and I
write a value to one of the replicas and
then for instance Tom goes to read that
value he'll he will see it as soon as my
operation completes right there's this
idea that we enforce it's like a single
system it's like there's only one copy
of the register even though it's
replicated everywhere
so if you attended Katie's talk
yesterday she kind of talked about this
idea of consistency models so
consistency models are in distributed
computing a contract between an
application developer and a system and
what a consistency model says is that
hey if you follow these rules I
guarantee that you'll see these events
in a particular order and some
consistency models don't make a
guarantee right they say we don't know
when you'll see the events you'll
eventually see them in an overt order
and that's our favorite consistency
model right
so these consistency model things just
on this spectrum right it's weird
they're like the you know the graph is
kind of like if you you know it's like
all over the place and all of these
things and you're a blonde you know
snapshot isolation and non-monotonic
snapshot isolation causal cross and
causal and you have all of these crazy
consistency models and they kind of all
exist on a spectrum they're kind of
partially ordered I guess right and and
to get a stronger consistency model as
we move towards a stronger consistency
model we need to enforce this model
through the use of synchronization right
so if we need everybody to agree on a
value immediately at a very particular
time we have to use coordination to do
this so what we want to think about is
that a consistency model is analogous to
a programming paradigm because it's a
contract if you think of a programming
paradigm like you know functional
programming and dataflow programming
this is a contract that says well giving
you program and you follow these
particular rules you will see these
particular types of outcomes right so
it's it's like contract that the
application developer makes with the
underlying system that they're that
they're building their application on
top of so so we'll kind of step back and
say all right well why is
synchronization undesirable so it's kind
of intuitive that you don't want to do
this but what kind of you know walk
through it anyway so we have this idea
of like physical time is really hard so
if you went to John Moores talk
yesterday he talked about the problem of
you know synchronizing computers with
NTP you know how it certain interval
computers gives up some computers like
just won't even synchronize we talked
about the problem of
time stamps when they're used for
deletions and if you delete something in
the future what does that mean so that
that sounds like it's a big problem and
you know just generally using physical
time and applications introduces
complexity it's a hard thing to work
with so time kind of takes three
manifestations in computing the first
one is kind of mutable state and
sequential systems so if you think of
sequential systems and you have
functions and these functions use
mutable state these functions are gonna
take different values over time so
that's kind of a difficult thing to
think about right we don't have these
nice properties of referential
transparency and things like that that
we really like with concurrent systems
again we have non determinism so
different scheduler interleavings when
you're doing multi-threaded programming
we usually use locks to enforce an order
so that we can think about the system
and we we know that we can execute it
multiple times and get the same result
it's the worst thing is to run a
computer program you know given two
values the same values three times in a
row and get three different answers
that's not really a fund a job to have
and finally in distributed systems we
have all these problems on network
latency right how do we do failure
detection
I mean failure detection is a
fundamental problem because it's very
hard to do in a safe manner how do we
coordinate right how do we ensure that
we see events in a particular order so a
lot of this is we have to deal with time
because it takes time for messages to go
across the network but you know
ultimately physical time is unavoidable
because it's kind of like a real thing
right yeah when you sit down at a
computer and you and you punch like you
know numbers into this little you know
if you have a distributed word counting
application and you're going to punch
some words in to count them you know
you're going to punch those words in at
a particular time and you're going to
read the results of the words that were
counted at a particular time right so
physical time is unavoidable it's
essential
so we'll digress for a minute and and
talk about the parable of the card
so we think about a car and how a car
drives down a highway
and so as a car drives down the highway
it uses the tires grip the road right
the tires grip the road in this creates
friction and this allows the car to
propel itself forward
and these friction points that the car
makes with the road are very small right
like the car has a massive surface space
but you have these very small contact
points that the car makes contact with
the road where this this reaction
happens but you know if you have a car
and you have a motor in that car then
that motor really doesn't like friction
you don't want friction anywhere near
that car so the motor really relies on
it being as frictionless as possible and
we all know that you know when there's a
lot of friction inside of a motor lots
of bad things happen your system slows
down your system stops functioning
correctly and these are all things that
cause the system to be very difficult to
work with so we're gonna kind of think
about physical time its friction right
so we cannot eliminate physical time
from the system because it's essential
to the problem but we won't really want
to reduce the use of physical time in
our computer programs as much as
possible so if we look at this box here
this box is a is a data flow graph so
just imagine it's some general data flow
composition computation happening inside
the box and what we want to do is we
want to push physical time to those
interaction points right as the car
interacts with the physical world like
the ground and the highway at these at
these funding points we want to push
time out we don't want to have time
inside that box we don't want to have
physical time inside the box but it's
okay to have a notion of logical time
inside the box and we do this we do this
all the time if you saw John's talkie
he talked about you know let the use of
Lamport clocks and we have we have all
of these nice causal tracking mechanisms
that allow us to reason about how events
are propagating in the system but we
don't do any of this kind of based on
physical time so you might ask well why
do I care if there's time in the box
right well I mean the reason you care is
because you're the programmer who's
writing the box and that's that's a
difficult thing you don't want to have a
difficult task where you have to write
all of this code based on time so going
back to the second slide where we said
well what can we do would serve zero
synchronization we can't really do much
if we have a bunch of computers in a
network and these computer
are not actually talking to each other
they you know they're probably not
working together and they can probably
just be independent single systems so we
can't really do much without
synchronization at all but a really
interesting kind of middle ground is
that we can look at this this property
known as strong eventual consistency and
what this is is it's a ventral
consistency model that we're familiar
with but with a strong convergence
property and what this says is that
replicas that deliver the same updates
in any order and can be different orders
at any node will have equivalent state
at the end of delivering those messages
the primary requirement for this model
is fairly weak it only requires eventual
replicas to replicas communication and
this is just to serve the purpose of
delivering all of the messages to all
the nodes in the system and this can be
done transitively right we don't
actually have to have every node talk to
every node what's nice about this is
that it's order insensitive so it's
commutative we can receive the updates
in any order and it's duplicate and
sensitive we can have replays on the
network it's also associative as well
and this is really great because that's
a really good match for unreliable
asynchronous networks our favorite kind
of networks so strong eventual
consistency relies on monotonicity so
we're gonna briefly talk about
monotonicity we don't have time to
really go through you know I can't pull
up Wikipedia and walk through it with
you as much as I'd like to but you know
we will kind of just do a brief
demonstration of what monotonicity is so
if we go back to our original example
where you have replicas and replicas be
we do our set operation we
asynchronously propagate the result and
then we write two and three so now we
have a decision to make so if we're
operating over an ordered domain of
which the natural numbers are so let's
assume we only set natural numbers this
domain is ordered then we can have a
monotonic function which is a function
that's going to preserve that order as
the inputs increase the outputs are
going to increase and this is going to
give us deterministic execution if we
use something like max which is a
monotonic function over in the natural
numbers so here we see well that we get
three because three is the greatest
value that's been seen
and what I can do is I can take any node
in this graph I can completely rearrange
it and I will still get the same results
so this is the limiting accidental non
determinism from the system so if you
went to the CRT t-talk that was earlier
you've probably already learned about
strong eventual consistency so I
apologize for any duplication in content
so how can we succeed programming strong
eventual consistency so what kind of
define a criteria of success and this
will be the outline for the remainder of
the talk and and then we'll kind of kind
of look at what applications we might be
able to build with this so start here
actually so well well begin by
eliminating accidental non determinism
so we've seen that these data structures
I just showed you and these monotonic
functions they're really helpful in
removing accidental non determinism and
what we have to do is we have to if we
want to make this general one a general
purpose programming model we have to
eliminate we have to have the ability to
model non monotonicity in a monotonic
way so if you think about a set a set
isn't monotonic because it that you can
remove an ad from because over time it's
going to have different you know if we
count the elements the cardinality is
changing over time so we have to have a
way to model that in a monotonic fashion
so we can reason about it in the
delivery of our delivery of events in
our system
we'd like to retain properties of
functional programming that allow us to
compose those objects because it's been
shown that converging objects don't
necessary if I just take a counter a
converging counter and I shove it in the
convergent set that will not converge
correctly so we've seen that some of
these things are difficult to do so we
need to have a way to perform
composition and we want to kind of move
as closely to properties that resemble
confluence and referential transparency
specifically related to functional
programming with composition sorry and
finally we need a way to distribute all
this stuff we need a way to run it in a
fault-tolerant runtime and you know be
resilient to failures and be highly
available and all of the the things that
make it very practical to use something
like this in production so we'll start
by eliminating accidental non
determinism so you probably heard about
CRT T's I think there's been a talk at
every single strange loop ever on see
already teased by somebody there was
another one this year
and CEO duties are distributed data
structures that uh that have a
deterministic resolution under
concurrency so under concurrent
operations they will converge to a
particular way and these types exist
with many different properties we have
different varieties of all these things
we have sets counters flags which are
like excuse me which are like billions
we have different types of registers we
have a map which enables composition for
a single data structure and there are
graphs and these data structures try to
mimic the sequential counterpart as much
as possible however the sequential
version of a set doesn't have a
concurrent add/remove operation of the
same element so a lot of these data
structures they take biases they say
well under addition and removal of the
same item at different nodes in the
network what we'll do is we'll bias
towards ads because we Intuit that you
know users will only remove things that
they've seen in the set so if you follow
these rules again it's back to decide
you have a contract right if you follow
these rules you get these guarantees and
what CEO duties do is they they provide
strong eventual consistency per object
so that not over composition so we're
going to walk through an example we're
going to assume three replicas a B and C
we're gonna model our set as a set of
triples so this is a set of a triple of
so I'm omitting the outside braces to
make it more readable even though it's
not super readable and we have a value
we have a set of unique constants
representing unique additions like a
nonce and then we have a set of removals
so when I add one two replicas a replica
a generates this random lowercase a
constant adds one to this set and then
propagate asynchronously propagates if
replica C then adds one it has an
observed days edition yet because those
messages are taking time to propagate so
replica C will add with unique constant
B and these distinguishes these two
concurrent additions that have happened
in the system now she wants to remove
one from the set so inside the circle is
the user queryable value of the set so
if C wants to remove one from the set it
will take the add set which is a set of
B and it will Union it with the remove
set and the B and what we
we've created what we refer to as a
tombstone set and this tombstone stat
tracks the removals of items in the
network so now when we deliver all of
these messages eventually we guarantee
that we converge to the right result and
the way we do this is it's a pairwise so
this is actually modeled as a monotonic
joint semi-lattice
but it's a pairwise mur to make it very
simple you can think about a pairwise
merge over the triples where the first
element matches by unioning descent and
union for set is for these sets because
they only ever grow is monotonic okay to
determine if the element is in the set
what we do is we take the difference
between the ad set and the remove set
and if that is not the empty set we
remove it so you might be looking at
this saying holy crap that is a lot of
data you were storing a lot of data for
a set that at one time had no elements
in it and yes you're absolutely correct
these sets are modeled you know these
are the complexity is the size of the
operations but there is actually a very
efficient modification that you can make
to reduce this to be just the size of
the active elements in the set with a
vector that represents the actors in the
system and how many times they perform
updates so there there are plenty of
ways to optimize this but those ways are
very difficult to explain in two minutes
so I did not use them so now that we
have these data structures if we want to
kind of retain the properties of
functional programming like these ideas
of confluence and referential
transparency we need to have a model
that allows us to take C or D T's
compose them and get out a C R DT that's
got this convergence property so I this
is the last process the lattice
processing works so this is last that I
don't know you might have heard of this
is the stuff I've been doing for the
past year and this is a distributed
deterministic dataflow variant for
eventual consistency kind of programs
eventually consistent programs and what
we mean by this is that if the program
output is the C R DT that means well
eventually once I deliver all the
updates and even if nodes get
partitioned away and then eventually
come back online once I deliver all the
updates I will get the actual same
answer at that node so all of the nodes
will converge to the correct value
we do this by building upon CRT T's so
in the same way that you think of lists
and Lisp we have lattices that we use
it's the primary data abstraction that
we build everything on top of so we
don't have a mute like we don't have
normal like you know like a integer so
there's not an integer and what we do is
we have a way of doing composition so
that all of that internal metadata that
I said is monotonically growing that I
showed you in the previous example we
have a way to use functional composition
and map that metadata through and build
other types of Co duties that are based
on other ones so last was implemented in
Erlang and and Erlang syntax is a little
bit debatable sometimes so what I'm
going to do is I have a little bit of
pseudocode here you see types are
specifically encoded in the calls
because erlangs type system doesn't
really allow for extension and what we
have here is we declare a set of and we
call it s1 we're going to add three
items to the set so we add items one two
and three then we could declare a second
set and then we can take the first set
apply a function to all the elements in
the set and then generate a new one so
this s2 is also going to be a CR DT and
it will be constantly updated from s1
applying this map so last Palau is a
functional and set theoretic operations
on sets we specifically in the paper
focus on sets but the implementation has
some stuff for counters and registers
and things like that but the paper
mainly focuses on the set data structure
because you can build a lot of things in
terms of it we allow you know we have
operations that look very familiar
product intersection Union filter map
fold things like that and what these
operations do is they do the metadata
computation they transform that metadata
given the function so if you have a map
and you map into another set and I
change the value of the element it maps
the metadata through ensuring you have a
CR DT on the other side if you have a
fold and you fold a counter a set into a
counter it will perform that metadata
mapping so we have this idea that we
need to conserve all of the metadata
across these objects to guarantee
convergence this is like kind of a
standard CRT T property that's expressed
via strong eventual consistency so um
the kind of the way last works we'll
briefly do kind of a high-level overview
is that each replica in the system is a
monotonic stream of states
so each CR dt itself only ever grows we
have processes that read from these
monotonic streams and then write out
another stream so for the product what
we would do is we would have two sets
and we would read them and as they
change that we would continue to read
them and we would produce an output and
that output is also a CR DT so in
addition to computing the Cartesian
product of the sets themselves we
produce the Cartesian product of the
sets metadata to ensure that if I take
two of those objects those will both
converge to the same result and remember
this is tolerant to all these network
anomalies and finally we have the idea
of inflationary reads and and what an
inflationary read is is it ensures
so we won't go into the details there's
a good conversation a good blog post by
Lindsey Cooper about the difference
between inflation's and monotonicity
but what it allows us to do is if we're
reading from a particular replica and
we've seen state s and then we see state
s Prime and then our connection drops
and we go back to a different replica
that hasn't got the s Prime update yet
we guarantee that we won't read a value
from that replica until it's greater so
if you're familiar with distributed
databases this is related to a session
guarantee right the session guarantee
says as long as I'm connected to a
replica I will always continue to
receive greater results if I go to
another node I might have to wait for
those results to be available but this
ensures that we continue forward
processing of these transformations
under failure conditions in the network
so we'll look at a quick example of what
these streams look like to just
demonstrate so if you imagine we have
two clients here and we have a replica
so they both start off with the empty
set and we're using the same triple
notation we had before if one is added
with a in the add set and then that's
sent to replicas a and concurrently C 2
adds with B and sends a replica a
replica a does not choose one or the
other
it merges them together as it receives
them so this is an important distinction
from systems that use something like
glass writer winds where we're racing to
see which value we're going to draw
so in this system were always growing
we're always moving forward and then see
one can continue to apply updates to its
local state and send them to replica a
and then eventually it can get the state
from rep okay if it likes in this
example this stream at replica is
monotonic this is always growing over
time it's actually inflationary because
the mutation is applied and the
resulting state is always greater so if
we want to build a system to compose
these we do this with this idea of the
of the monotonic process so again we'll
go back to we're using a similar example
replica a has the empty set we have a
process which is going to apply our map
function and then F of ereve is just
going to be the value with the map
applied to the element so we're just
using that for shorthand so we start by
saying okay I'm the process I want to
read against replica a and the last
value I saw was bottom so the empty set
when replica a changes and one is added
with the addition of a this read returns
to process one and says yes I have a
state that's greater than their last
observed state and p1 processes that
value and then propagates that value to
the other CR DT so this is just this F
of R of a is just the output C R DT
doesn't work so then p1 will iterate
again and it will say okay I'm gonna do
a strict read again and I'm gonna give
you the last state I observed and then
that reads not going to return until
it's greater again here we do this with
state you probably say wow it's really
efficient to keep inefficient to keep
the whole state around yes it's true in
practice you know semantically we can do
this with the full state but in practice
we use logical clocks to model this so
you can do this with a version vector
and then finally the state changes again
one is removed from the set the
functions applied and the map function
produces a set where the values been
changed but the element still deleted so
this map transformation is fairly
trivial but you can imagine that
something like a fold is a lot more
complex and even the filter is more
complex because you can't omit the
element in the filter because now you're
back to the problem of knowing did I see
it or did I not see it so with the
filter you actually need to kind of
transform elements from active elements
to deleted elements so some of these
transformations are non-trivial
and if we have a node that sees this
execution the confluence property we get
through this monotonicity is that
somebody else also could see this
execution right and they only see some
subset of the states but as long as they
get that final message as long as we
guarantee that they both see like some
final message about some piece of state
we'll see that the result is still going
to be the same so this is really nice
because we can reduce the times that
these processes need to communicate with
the server and still have the
computation be correct once we've
delivered all the events in the system
so finally we'll briefly talk about some
work that's in progress called selective
hearing this is a epidemic broadcast
based runtime system that we've
developed so if you're familiar with
gossip protocols this is a we build on
the gossip protocol work gossip
protocols allow for a very efficient
dissemination of information so reliable
broadcast under failures that can handle
a very large amount of nodes we've seen
some protocols do ten fifteen twenty
five thousand nodes in evaluations and
what makes this matching so brilliant is
that broadcast protocols achieve their
efficiency through weak ordering so this
is why it's not a general-purpose model
to build things on but that's great
because we don't care about message
ordering though our entire computational
model builds on the fact that messages
can be reordered and we guarantee that
we converge correctly and finally the
reason for the name selective hearing is
that we want nodes to be able to
selectively kind of opt into
computations so if I have a program that
requires some variable state and I know
that that variable state is on these
five nodes then I can express kind of
interest in that variable so it's kind
of a runtime that resembles a
publish/subscribe system so I've shown
you I've shown you that you can
eliminate accidental non determinism
through CRT peas we can find a way to
compose these things and build other CRT
teas and finally we can efficiently
distribute them with a really nice
runtime that's efficient so now the
question is well can we actually even
build anything than any of this so
hopefully so we're going to talk about a
mobile game platform so imagine
angry birds as an example advertisements
are going to be displayed with in-game
clients are going to go offline and
people are going to continue seeing ads
in the game so we want clients to be
continued to make progress still record
the ad impressions and we want to do
this completely coordination for you or
minimizing coordination as much as
possible so this is what the data flow
graph looks like and we'll walk through
it so let's imagine that we have Riot
Games in Rovio and they want to
advertise inside of a game so they have
a bunch of ad counters ads and we're
gonna just like kind of group them into
a set and then Union those sets together
so let's imagine that there's a notion
of contracts to make the example a
little bit more difficult and contracts
are you know saying that an ad is able
to be displayed at a particular time so
what you'd want to do like in Ruby on
Rails or a web framework similar that's
similar to that is you would say to your
sequel database well hey you know
computer join where these two things are
equivalent
where the keys match so in data flow we
can kind of model this with you know
compute computing a Cartesian product
and then doing the filter and then only
getting the ads that are active we can
give these clients all out too so we can
distribute these counters out to the
clients the clients can continue to
increment these counters so they have a
counter that represents kind of a global
counter and then they diverge from that
and then they periodically send their
counters back to like the data center
and then the data center runs a process
that's doing one of those inflationary
reads it says don't let me don't let
this process continue running until the
advertisement reaches 50,000 so all
these clients are continuously merging
they're stayed in the counter is growing
slowly monotonically and then when we
hit that trigger value we remove items
from the set the set is modeled
monotonically so that flushes down to
the clients and this is done completely
the only part we have coordination is
where we synchronize with the server to
send our states so this is great the
advertisement counter is completely
monotonic we can disable contracts and
advertisements all through monotonicity
all with monotonicity the counter itself
is monotonic obviously it's a girl on
the counter and we could take any node
in that graph and put it on anywhere any
physical machine because the data
structures correctly capture the
concurrency in the system and an are
guaranteed to merge correctly so we can
arbitrarily distribute this graph
that's really really nice let me put it
all on the same machine if we want and
finally if we think of the system as
having a global truth if we had an
outside observer who can see the global
truth of what the counters are we can
measure divergence as how often we
synchronize and put our results into the
global result so you know wrap up I
think behind so what do I like about
this model we have built up from zero
synchronization we didn't build a system
where we had to remove coordination the
trade-off that we made was that we if we
want our advertisement counter to be
more correct to diverge less we
synchronized more but the application
design uses no coordination at the
lowest level and this is a really nice
way to build applications so finally
just kind of talk about what's next
briefly because I'm running out of time
metadata can grow very large we've shown
that we have mechanisms for reducing the
metadata in the system we have efficient
representations of sets that use vectors
rather than storing all of the
operations and we actually have a
unpublished appendix to our original
paper that extends us to a bunch of
other different optimized data types
that that hopefully will make a public
appearance soon i Function is is not
amazingly general it relies on the
binary function applied to fold to be
associative commutative idempotent and
have the ability to be inverted so if I
have a set where I've removed the item
and added the item multiple times I need
to and I'm folding that into a counter I
need to have a way to reflect the
additions of the count the increments of
the counter and the decrement of the
counter in a in a way where I conserve
the metadata between the two objects
completely and finally what can we
derive from the data flow graph so can
we do things where we see that hey
you're running this map on this node and
this filter on this node well we can
just combine these things right into a
fold so can we use the data flow graph
to derive distribution and can we use a
minimum required distribution to derive
an optimized data flow graph so this is
stuff that I'm really interested in but
have not even begun thinking about but
seems exciting so to kind of wrap up
what have we learned so we've learned
that we want to eliminate accidental non
determinism and we've learned that we
can do this with CRT tease and this
provides a really great building block
to do compositions of CRT T's to build
programs that observe this strong
convergence property and once we do that
if we have an efficient way to
distribute this over nodes that's
resilient right because CRT T's rely on
it like you know you have to be tolerant
up to some number of failures and
depending on how you replicate can we
build a runtime system that allows us to
do very efficient scaling of this
programming model so to wrap up one of
the key points synchronization is
expensive you probably all know this you
know you're never gonna get faster than
the critical section that you're locking
on this is kind of straightforward
concurrent programming a lot of these
applications are not possible it's not
possible to synchronize always so if
you're a mobile application clients are
going to be offline occasionally a funny
anecdote was I said at one point you
know you call your friends and compute a
round of consensus tell them to get
online at 7:00 and Paul Brill said back
to me well now you've just pushed the
consensus problem over the phone and
finally you know some things require
synchronization global invariants atomic
visibility so we have a bunch of papers
you can check them out if you'd like we
tagged a release 0.01 it took me forever
to get this Erling packaging thing
working even though I have a ton of
experience with it oh well so it works
you can download this package it's a
it's a not comprehensive implementation
or everything be built but it's fully
executable and you can run our demo
program so that's kind of nice and
finally I'd like to thank the European
Union not only did they fund a bunch of
my research over the past three years
but they also offered me a fellowship so
this is going to provide me with the
ability to do my PhD research on last
next year so I'm very grateful to them
and I'm Chris Michael John thank you
very much for coming
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>