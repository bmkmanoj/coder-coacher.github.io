<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;How to Have your Causality and Wall Clocks, Too&quot; by Jon Moore | Coder Coacher - Coaching Coders</title><meta content="&quot;How to Have your Causality and Wall Clocks, Too&quot; by Jon Moore - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;How to Have your Causality and Wall Clocks, Too&quot; by Jon Moore</b></h2><h5 class="post__date">2015-09-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YqNGbvFHoKM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right hi everyone good morning my
name is John Moore and I'm really
excited to share with you some research
so I've been doing recently into a
particularly annoying problem now at
Comcast as I think is the case in in
many places we have a services oriented
architecture and so the following
pattern of interactions is relatively
common so I have a server a request
comes into it in order to service that
request I have to make a downstreams
call to some other server now in the
process of doing its work server B might
generate a log as part of doing that
work then return a response to server a
who also generates a log message before
returning response back to the client
now if the clocks on these servers are
not well synchronized we can run into
something a little problematic right
which is that we can get the timestamps
coming out in this order now if we're
collecting all of these log messages
somewhere centrally where we can
aggregate them and do searches on them
to debug production issues this gets
really confusing right because through
the pattern of interactions we saw we
know that this one totally happened
before that one but the timestamps don't
reflect that right so the the timestamps
don't reflect the causal history of what
happened in the system now
of course there are some treatments from
the literature about how to deal with
causality right up folks have heard of
Leslie Lamport
yes maybe Turing Award winner all-around
nice guy actually I don't know him so I
don't know he's nice but I'll assume
he's nice um anyway he invented this
concept of logical time many people
refer to this as Lamport clocks um
people familiar with this concept show
hands okay some people not so we'll do a
quick review so what we have here are
the three vertical lines are three
separate processes the dots on those
lines are events that happen and the
squiggly line squiggly arrows are
messages sent between the processes
right so this is a distributed system
and so what Leslie Lamport laid out was
that there are two main things that help
us understand sort of a happens before a
relationship in the system
so one of them is sending and receiving
messages right we know that a message
has to be received after it was sent and
so the other one is that if I can
observe two events locally on a process
I also know what order they happened and
then this is a transitive relationship
right so I can continue tracing these
happens before relationships and I can
conclude that this event down here p1
happened before this event over here r3
what he also proposed was assigning
timestamps to these things so the idea
is that I might assign a time step one
to this event over here and then by
tracing this happens before relationship
the ideas that I have to assign a
subsequently higher timestamp to
everything that happens after this right
and so typically that timestamp gets
included and piggybacked on the message
that actually gets sent between the
processes so when I receive that I might
say AHA I received it at time two and
there's another local event I'll call
that three and then four and then five
and so by following this scheme what we
end up with we see that when we know
that some one thing happened before
another then we see that it gets
assigned sort of a lower timestamp or
rather it's it's really reversed right
things that happen after the first one
getting assigned later timestamps and so
that's good because these timestamps
reflect the causal history of the
interactions in the system okay but
there's a problem right which is that we
have to do production support on this
and so you know in the middle of the
night pager goes off and you know did
you hear about the error that happened
at time 42 this is difficult for humans
to reason about it's hard to do
production support when the thing that
you're looking for happened at time 42
now you know your production support
buddy of course the first question that
they're gonna ask is well what timezone
is that in but but the fact remains that
these logical this logical time doesn't
bear a relationship to the wall clock
time that's meaningful to us as humans
now another piece of relevant prior work
was published last year in a tech report
by some folks out at SUNY Buffalo where
they
the concept of hybrid logical clocks and
so what they did was they took a
component of these clocks which actually
was a physical clock reading right so
something that makes sense to humans and
then they paired it with a counter that
could be incremented in the same way as
the Lamport clocks and then they put
these two things together and I'll
explain a little bit how these work but
the thing to understand here is that the
most significant bit here is the
physical clock reading right so if I'm
comparing two time stamps it's the clock
readings that sort of matter first and
then the counters are kind of
tiebreakers so how does this work in
practice so if we have two local events
p2 and p3 and we've already assigned a
logical time to p2 now we need to assign
a time to p3 so the way that we do that
is we take a local reading of our system
clock and then we need to assign a time
stamp that's strictly greater than the
last logical time down here at the
bottom as well as the system clock so in
this case the system clocks physical
component is is sort of ahead of the
logical time and so we take that one and
we can reset the counter to zero now in
another case it may be that when we take
the system clock reading it's actually
the system clock maybe behind the last
logical time stamp we've seen because
maybe we learned that logical time stamp
from some other system that we're
talking to and so in this case what we
do is we preserve that physical
component but we increment the counter
right so both of these cases we can see
that by comparing the time simply
assigned at p3 it's still strictly after
the timestamp at time p2 right so so
this is good that's an important
property here similarly when we receive
messages the same thing works right the
the time stamps are going to be
piggybacked on the message exchanges and
so we'll get one of these logical time
stamps coming in we still take a system
clock reading and now the time that we
assigned to p2 the time that we receive
that message right this has to be
strictly greater than than all of these
things right and so in this case
actually is with the first case we saw
the system clock has sort of advanced
things and we can sort of reset the
counter to zero and we can see that
that's both greater than the last local
timestamp and it's also greater than the
logical timestamp on the message we
received right there are other other
cases where you know again our system
clock my people having the logical clock
and so or perhaps the biological clock
we receive some somewhere else that
physical clock component is ahead of
what we're doing and so we just
increment the counter if there are ties
right we just need to make sure the
counter portion is sort of higher than
both of them okay now this is really
cool all right because what we it seems
like what we have here is the best of
both worlds right there is a component
here that tracks the physical time and
the wall clock time it makes sense to
humans right and this is where the local
system clock readings come into play
right eventually as time the wall clock
time progresses forward it also pushes
the logical time for it in the system
but we also preserve causality right
with this rule that requires that when
we assign time stamps there's strictly
greater than the time stamps we observed
we're continuing to track causality so
this is great right I am seven minutes
into the talk and we can all go home you
know well you know it does work you know
pretty well right there's there's this
thing called NTP and an NTP is actually
really good at synchronizing clocks
within a data center like NTP is good
enough that within the data center on a
LAN you can have you know a handful of
milliseconds or even sub millisecond
synchronization between between the the
server clocks in your in your cluster
and so this this sounds wonderful and
and I found this great tweet earlier
this month
that that sort of will get to the
weakness right it's time to do some work
just kidding NTP isn't running I have no
idea what time it is right and so so
this is on this is unfortunately a
reality that we have to deal with right
there there are a number of reasons why
NTP might not be keeping your clocks in
sync so for example if your sis
clock gets far enough away from the
clock server you're trying to
synchronize against NTP gives up just
says I don't know what's going on I'm
gonna stop trying to synchronize your
clock if you get to this point it's
going to be really hard to get
resynchronized automatically again or
maybe your instance rebooted and you
forgot to include ntpd in the startup
script right and so you just NTP never
woke up for you in the morning and so it
wasn't even running or maybe you didn't
set up your security group rules in a
way that lets ntp traffic through and so
it's like yep daemons up and running
it's all great and it's actually not
even talking to anything right and so so
the reality is that that what we run in
production right they ultimately they
run on physical machines that can fail
and and they're managed by humans that
that make mistakes occasionally and so
the the real problem comes though when
because it just takes one server whose
clock runs far enough ahead of everybody
else in the cluster right and this is
actually a really big problem and so so
why is that so so let's say we've got
this timestamp here and you know he's
like oh this is this off a little bit
you know it's actually 10:20 right now
so so an enterprising engineer logs into
the server and says I'm gonna fix the
clock on this server I'm gonna you know
sue due date and and set the date here
but but I have a typo right and so
instead of typing the Year 2015 I typed
the year 2050 1 and I just set my
servers time several years into the
future multiple decades no less now this
is a real problem right because the
logical time here is going to propagate
to everybody in the system and they have
to now for all subsequent events assign
timestamps that are greater than this
one right so this is actually going to
drag everybody's logical time forward
with it and the problem is there's no
way to fix it until the year 2050 one
we have to wait until the year 2050 one
before correctly set system clocks even
if we went back to the server and fixed
its clock we have to wait till year 2050
one before the system clocks start
pushing things for it so so this this
hydrological clock scheme is really cool
but it's but it's somewhat fragile and
so the research that I've been doing is
is around how do we deal with all of
these clocks that might go cuckoo on us
and so I've been working on some
extensions to this hybrid logical clock
scheme that I've been referring to as
distributed monotonic clocks now I
support services in production I'm proud
to say it and and so one of the things
you know I don't like this whole I can't
deal with that until the year 2050 one
that's extremely unsettling to me and so
we need to build in something that gives
us the ability to recover from this case
that we know will happen right we know
at some point some clocks somewhere will
get far enough ahead and we'll drag all
of the logical time stamps forward right
it's going to happen how many people
have had a production incident caused by
clocks not being synchronized it's okay
that's a lot of hands right so like you
know this is going to happen so so the
first thing that that we need to add is
a reset button we need to get out of
jail free cards so so we're going to
start with our logical timestamps and
and this one's actually relatively
straightforward so what we're going to
do is we're going to add an epoch
counter at the front okay and that is
now the new most significant bit of the
of that of a lot of the hybrid timestamp
here so what this lets us do is let's
say that that this has happened right
logical time has gotten pulled into the
future and we want to go fix it so on
some server that actually has sort of a
correctly synchronized clock as far as
we understand what actual time it is and
I won't get into the sort of
relativistic physics event but but what
we do is we can issue a reset operation
here and and what that does is it takes
the local system clock reading
and then it combines it with the logical
time sample what we do is we increment
the epoch counter we can take the system
clock reading and start the counter over
at zero okay so this still reflects
causality right because this is at the
reset operation is a local event right
so we can see that the time same on the
top is still after the timestamp at the
bottom right because the epoch is later
right 2 is greater than 1 however we've
been able to put the the part of this
that makes sense to humans back in sync
with regular time and then as that one
gets propagated around all of the other
all the other libraries will see aha
we're on a later epoch now and I can
actually back off and start
resynchronizing with sort of the
physical time that makes sense again and
so that gives us a way out and they have
a way to fix it but but even though we
have this this is still a little bit of
a drag right I don't want to have to go
login the server is an issue a reset
operation and and furthermore the time
between when the clocks got pulled into
the future and when I issue the reset
operation you know the time stamps that
I'm generating are kind of wrong right
there they reflect causality but they're
not right so it'd be really good if we
could figure out a way to avoid having
to push this reset operation in the
beginning so so what would that look
like but so what that that would look
like is okay let's say we have the
current logical timestamp here and you
know we receive a message and okay now
we need to assign in your timestamp here
right I'm gonna take a clock reading and
what I really would like is for this
system here to say timeout I am too far
ahead right and so I am not actually
going to increment the clock portion I'm
just gonna do the counter portion so if
we could achieve this that will be great
because if there were just a couple of
servers whose clocks were ahead great
they just mess around with the counter
portion they're reflecting causality but
they're not dragging logical time
forward into the future with them okay
now of course this is the big trick
right how do I figure out that I'm too
far
ahead this is obviously going to require
coordination between sort of all of the
servers in some sense right because you
know I'm too far ahead of what right
with just you know we already know that
we don't necessarily want to directly
depend on NTP because that's I mean
we're already doing that right we need
to do something else and really the
issue is what our clocks are with
respect to everybody else that that's
sort of in the in the cluster here now
the tricky thing of course is that
because we need to include these
timestamps piggybacked on application
message exchanges it means that our
coordination protocol will probably have
to also be piggybacked over that as well
now it doesn't have to be but there are
some advantages to this so in particular
I don't have to open additional
firewalls right like my applications are
already sending messages to each other I
get to piggyback on top of that I don't
have to worry about connectivity I don't
have to worry about cluster membership
any of this sort of stuff so there's
some advantages there I mean I could
imagine the scheme as a library embedded
in my application that that kind of has
a relatively simple interface so so the
idea is hey I'm an application I'm ready
to go send a message to someone else
tell me what time it is Oh distributed
mama Kahn o'clock library right and I'll
get a sequence of bytes I'll go put that
in my message I'm about to send maybe
it's an HTTP header
maybe it's embedded as an extra field in
a JSON document and then I'll send that
over to whatever I'm what other other
application than I'm speaking to you but
when it receives it knows to look for at
this timestamp and then hands it off to
its own local library like hey I just
got this timestamp from somebody please
ingest it and update your concept of
local time right this is a pretty
minimal interface and so if we can
manage to achieve this coordination
piggybacked on top of the other things
then then we get some nice clean
separation there's probably some
additional methods here right like I do
actually care a little bit about being
able to log out the time stamps I don't
want to completely treat them okay Klee
in particular I'd like to be able to be
able to see well what is the physical
portion of that because that's actually
the whole useful bit
is being able to pull those out but if
we're gonna run this as sort of a
piggyback protocol there are some
challenges we have to overcome right so
so the first one is we don't a priori
know who our neighbors are right I'm
coming up as a library I have no idea
who my hosting application is going to
talk to I don't know how many neighbors
I have or what the network topology is
okay so so this is gonna be challenging
how are we gonna do this coordination so
so I started doing some research trying
to find I said surely somebody has
invented sort of protocols that that's
sort of operate in this and of course
write the hard part is figuring out what
the right search term is and so it turns
out that the right search term is
something called a population protocol
so how many people have heard of
population protocols before okay a
couple art this is cool great this is
Beezer really neat so so what a
population protocol is this model is a
collection of nodes where each node gets
to run a finite state machine and then
and then they the way this works is it's
a lot like bumper cars right so each
node is like a bumper car on a bumper
car ride and at some point they get
close enough and they interact and when
they interact they can observe each
other state machines and then advance
their own state machines as a result and
then they care them off and go sort of
interact with with sort of some of the
other nodes in the system and so these
types of protocols have been used for
example to model flocking of birds or
schools of fish and so what's
interesting about them is that they rely
mostly on local interactions right the
individual navigation discussion or
decision that you make are related to
you know sort of who's around you and
your local interactions and yet there's
this sort of emergent behavior that
happens over the system as a whole now
there's a couple tricky things about
these population protocols so so the
first one is there's no real sense of
termination right because because at
some point you may find out that
hey there's just somebody else I just
haven't happened to interact with at
some point and so you know an omniscient
observer can perhaps observe that things
have terminated but no individual node
can actually tell that things have
terminated which makes it really
interesting um instead we talk about a
concept of convergence so sort of a
quote successful population protocol
results in a convergence where all of
the nodes agree on some state eventually
so so this is now the inspiration for
for what are we going to do about our
system clocks right so if we view our
our system of nodes as a flock of birds
one of them has a median system clock
and so the intuition is that if I can
tell my relation to the median system
clock somehow then I can say okay I'm
sort of within the flock I'm okay
and so I'll use my system clock to
advance the logical time stamps as we
saw before but if I'm sort of outside
the flock and I've gotten too far ahead
there's a hold on now I'm not I'm gonna
run in this degraded mode where I'm not
going to advance the physical clock
portion I'm just gonna advance the
counter portion on the end so how do we
achieve this right so so so we're gonna
try to calculate a median when we don't
know how many things there are so that
that sounds challenging and so so so of
course we're not going to calculate the
actual median we're gonna try to get an
estimate of it which for our cases is is
probably okay NTP is going to be running
most of the time and while we really
care about are the couple of outliers
that have really sort of dragged things
out into the future right especially the
guy that's that's out in here 2051 right
that that's the one we want to avoid so
what we're gonna do here is a here's a
nice graph here and so we're going to
start grouping things into a hierarchy
and the way that works is we're going to
identify an independent set and so
contrast may not be great but but some
of these nodes now turn red so so
they're members of the independent set
and the rule the rule here is no two
members of the set can be adjacent and
every note of the set is either but
sorry every node in the graph is either
one of the members of the set or their
adjacent to one of the members of the
set so so the way to think about it is
well let's move a little forward so so
this node in the center here is a blue
node right so it's not a member of the
set and it happens to be adjacent to
three members of the set and what we
wanted to do is to sort of associate
with one of these and so we're gonna
give it a tie breaker which is the
degree of the node right so this this
node here has a degree three this one
has degree four and this one has degree
five so we're gonna say aha you win and
I'm going to associate myself with this
member of the independent set and so
when everybody does that this kind of
induces this set of groups hopefully
this can this shows up better for
everyone and so the way to think about
it is imagine all of the nodes in the
graph are towns and and they want to
form a County and so a bunch of nearby
towns are gonna say hey we're gonna be a
County and one of us is going to become
the county seat right that's that's the
way to think about this now
now we recurse right so each one of
these is a group these groups have
adjacencies which are neighbors and so
we identify another independent set
right so we find these two members of
the set we figure out whose adjacent to
them we get another next layer up group
we repeat independent set who's next to
us one top-level group and now we've got
a group that covers everybody and and
there there's nobody outside this group
right so so we can stop right I don't
have to start working on the next level
because I don't have anybody that's
outside the group that's adjacent to me
and so what this induces is sort of a
hierarchy of groups and an a and then we
can assemble this with a population
protocol and so these things can
self-assemble without knowing ahead of
time how many nodes are in the system or
what the topology is so we're gonna have
a nice little visualization of this
going on here so
I can find my cursor here so so we're
gonna see here this is a random topology
of 20 nodes I'm gonna step it once maybe
right so a message send will be
highlighted in red when that gets
received so here's two that went into
flight at the same time right and then
as they're received they sort of come
off right so I'm gonna speed this up now
what we're gonna see is these are going
to self-assemble into sort of a single
hierarchy so nodes are going to change
color and they're going to adopt the
color of the node that is there sort of
highest level leader and then the
representatives write the county seeds
the state capitals they get subsequently
bigger as they go and so so so we're
done here and I can actually go back and
and illustrate some of the lower level
groups right so so we can see that these
things are able to to put themselves
together in that in that way so so this
is just the result of spinning out a
trace of some simulations that we did so
when you see here let's get back to the
presentation so how well is this work in
practice so so ran some simulations for
random graphs over a sort of a
significant number of nodes and we
looked at the convergence time so that
the idea here is that we asked just to
sort orienting so this is this is in
simulated seconds where each node sends
a message ten times a second to a random
neighbor right so we're looking about
ten messages per second sent by each by
each node and so basically when we when
we track this the convergence time is
the time which that sort of hierarchy
got assembled right as you can imagine
from the fact that this hierarchy is you
know it's a tree right and so the
convergence time is in fact order log n
so so this actually scales really well
up to sort of larger and larger numbers
of nodes this was a really important
sort of design requirement because
you know looking forward you know we
have tens of thousands of servers that
are running in data centers when we
start to include clients the Internet of
Things like we it's really important
that this stuff scale out similarly and
in a related fashion if we look at the
highest sort of level number that's
needed to sort of cover these things it
also sort of scales logarithmically
which is great so so now the question is
well how well is this do you at
estimating sort of a median and so we've
got another experiment here where I'm
going to show us several runs on a 50
node cluster where what we do is we we
assign everybody a random number between
zero and one right and it's uniformly
distributed here and so if we can
actually go calculate the actual medians
right so you know I've handed out 50
random numbers what are the actual
medians and then just for for reference
I also showed the the 40th and 60th
percentiles
on these things and then what did the
top level sort of estimate produce in
many cases it's it's not too far off the
median in these cases and so it
obviously isn't in every case right
we've got this case over here on the
right where you know I'm not between the
40th and 60 percentile so so we'll have
to take a look and see but is it close
enough is really the question so there's
some more work needed to here but but so
far this looks promising so let's talk a
little bit about how because I just
talked about medians of random numbers
right but we want we care about clock
offsets right so so how does that work
so let's zoom in on this on this little
group here so the idea is that sort of
the representative of a group is going
to calculate the median clock for that
group right and so so this is all in
terms of relative clock offsets right so
my relative clock offset to my self is
zero and then by exchanging messages
with my neighbors I can figure out my
relative clock offsets with them right
does that this is actually how NTP does
its synchronization
by I say hey I think it is this time and
then somebody in the back will receive
that write down what time they think it
is when they got it then send it back to
me and include what time they think it
is when they sent it and then I can see
what time I get the response and then
there's a whole bunch of algebra that I
didn't have time to include in here but
but basically you can get an estimate of
our relative clock offsets and so
perhaps the relative clock offsets look
like this and so now we've got a
relatively simple computation which is
okay which one of these is the median
right it's it's this one so so that's
the median clock and so basically what
this representative will say aha my
offset to the median clock here is one
I'm one behind the median clock and so
then it will begin telling all the other
members of the group hey I am one behind
the median clock in our group so what
does that mean for for example this node
okay so so now let's look at things with
respect to this node so we have to
adjust all of the offsets relatively
right so so now with that node has a
zero offset to itself and all of the
other offsets have shifted okay and this
is a nice thing about medians is that
this is still the median clock right so
we've still selected the right median
clock and when the leader says hey I'm
one behind the medium clock I can say
well I'm three ahead of you so I must be
two ahead of the median clock right and
so in this fashion by doing sort of hop
wise relative translations we can
actually send estimates so the median
clock out to to all of the all the
members of the cluster eventually right
so in this case it's enough for all the
members of my group to know this median
but then at the next level up right the
representative that group is going to
look at the median clocks of all of
those groups and then compute its own
median right so it's going to do medians
of medians until up at the top somebody
actually has an estimate and says I
think that clock is the median clock for
the system and then also everybody can
understand
and what their relative offset is there
and so so that's how we achieve this
right so the idea is that if I can get
this estimate of my offset from the
median clock if that gets more than a
configured amount ahead of time then I
can make this conclusion I'm too far
ahead of everyone and I can sort of run
in this degraded mode now incidentally
this also works well if the system
that's involved doesn't have a clock or
it doesn't have a reliable clock so so
so how many people have written software
that has to run on end-user devices all
right run in a browser run in a mobile
app how many people have ever tried to
read the local time from those things
and and and how often is that like
accurately synchronized with sort of
like reliable time sources right so so
there's many cases where we can't even
trust the system got like we would never
trust the system clock on some of these
things and you know when we start to
look at embedded devices somewhere a
sensor networks things like this some of
these things just due to power
requirements may not be able to run NTP
right they probably have clocks embedded
in them they will drift over time and so
what we really need is a way for them to
detect when they've sort of gotten too
out of whack and and then to exclude
themselves right so just because you
know one one chip goes a little haywire
and runs ahead of time shouldn't
necessarily mean that that our time
stamps stop making sense so so obviously
this is this is a work in progress and
there are a number of open problems that
that I'm still interested in working on
but which I think are tractable so so
the first one is payload size so we're
talking about this as sort of a
piggyback protocol right where this is
going to be carried along with sort of
regular application message exchanges
and so when we start to add up okay I've
got maybe tens of thousands of
participants you know I've got 1415
levels of hierarchy here where I have to
transfer you know transmit things like
okay who's the representative at this
level and and whose adjacent to me as my
peers and
you know what are the one of the
relative o'clock offsets and and all of
the information that comes into actually
even just you know the round trip to to
establish what a relative clock out set
is between neighbors like this can add
up to several hundred bytes now you know
I've definitely seen context where we've
got web services and I've got Olaf -
bearer tokens that are way bigger than
that so I think there's a even even so
there's still a lot of places where this
is still okay but I think there's also
things we can do to reduce this so for
example once the sort of hierarchy of
groups kind of stabilizes we can stop
sort of sharing information about some
of the lower level groups or only doing
it periodically so that we can sort of
amortize down the cost all right we can
we can choose which pieces of the
population protocol we choose to include
in a piggy bank message but but to that
point so far the experiments that I've
run have been on a fixed topology but
but what do we do and we have a new
server that shows up right and wants to
come in and play how do we successfully
incorporate that noose that new
participant into the cluster without
having to recalculate sort of all of the
levels above it you know is there some
sort of quiescent period where after I
join I can try to just sort of join some
of the structure that's already there or
you know is it going to be like total
chaos and we just sort of have to
recalculate everything similarly we have
to deal with no departures right so no
it's gonna be fail it can fail they can
be taken down for you know for for an
upgrade and in particular if if we lose
nodes that happen to be representatives
at certain levels right these are the
things that are calculating medians and
so so we need a way to detect them and
to come back around and sort of recover
from those things being gone obviously a
lot more experiments are needed I've
done a lot of my experiments on on
random graph topologies but obviously
well maybe not obviously but but
hopefully the topologies and our data
centers are not random and so you know
I'm
I'm really looking forward to running
this in topologies that reflect more of
a sort of Assyria you know collection of
services type topology and then finally
you know there's a lot here that I think
is is tractable by formal methods right
so in particular it probably bears sort
of I think this is not a hard proof but
it's probably a proof worth doing that
like for example our reset operation and
all of the other adjustments that we
make when we add epics to the logical
time stamps that that we really are
preserving sort of that happens before
relationship with respect to the time
stamps the population protocols that I
mentioned there's a whole sort of formal
methods community around these types of
protocols and so it'd be really great to
do some formal analysis around things
like conversions time and and sort of an
expected number of levels and how
quickly we can converge this hierarchy
so so that's what I have for today I've
talked a little bit about this new
scheme for hybrid logical clocks that
are pursuing called distributed
monotonic clocks these reflect causality
but yet can track human time to you know
here that here the idea is that we just
want time stamps that are sensible to
humans we're not looking for a sort of
banking level must exactly match the
atomic clock type of accuracy or here
right it's it's good enough in many of
our cases to sort of say like well some
time planning was going on at 3:00 a.m.
last night let me actually go look at
what was going on around that time and
let's at least have the time stamps come
out in the right order corresponding to
what they happen there's still a lot of
benefit to be gotten from that we
obviously needed to add an ability to
give ourselves some where to stand
operationally in the inevitable case
that somebody's clock runs away with
itself and then I think the most
interesting piece here is this idea of
sort of looking at population protocol
flocking of the servers to see if we can
actually get a sense of a flock of
servers to figure out when I've actually
wandered too far out of the flock in
terms of my own clock and the scheme
does accommodate some clock 'less nodes
or nodes that that are
permanently untrusted as far as their
system clocks go obviously a lot more
work here is needed but but more work is
coming
this is seems to be very promising so
far at this point I'd be really happy to
take questions and if you have ideas in
particular for how the scheme could be
improved or or related research that
might be relevant please find me sort of
after the talk I'd really be interested
in that feedback yes question so the
question here was I've taught you know
with the reset button that's primarily
meant to address clocks that have gotten
too far ahead and so the question was
our clocks that are too far behind sort
of equally problematic so I think
they're not quite as problematic in the
sense that you can just go fix their
clocks right and then they catch up to
everybody else and and and no sort of
time staff have gotten really too out of
whack you know they're they're going to
be getting logical time stamps from the
other members of the of the cluster and
so to some extent the other that you
know their peers are going to be
responsible for advancing the physical
clock portion but on the other hand they
can still tell hey I'm really behind and
they can raise their hand and say hey by
the way somebody should probably come
and look at me and get me corrected so
so that that's a great question yes
question over here
so this part this protocol might be
interesting only if it fails less often
than ntpa I'll have to think about that
I think that I think the way that I
think about this is in terms of defense
in depth in the sense of that that MTP
is going to fail right like it would
like the number of people that raised
their hands with you know like like it
got out of whack and we got a production
incident as well like it happens and so
I think about this and this is you know
in particular the why the flocking
behavior is sort of interesting is
because those are relative references
right they don't depend on the external
time source and so so the idea is that
this sort of works as long as one or the
other is kind of working right as long
as either MTP synchronization is
happening or most of your servers are
sort of approximately in sync with ntp
then then even one of those things sort
of masks some of the problems here so I
look at it in terms of more
defense-in-depth
I also think this this idea of this sort
of self-assembling hierarchy could be
sort of applicable sort of beyond just
this particular setting and so so I
think it's interesting in that sense as
well yes oh yeah so the the question was
can we explain a little more about the
clock listed so this was the this was
this case here let me catch up here
where where we had somebody who who
thought hey I don't even have a clock
right so the come on now PowerPoint
there we go so in this case the idea is
that either I don't have a system clock
or my system clock I'm just going to
consider it completely unreliable
right because it's somebody's lap you
know it's an end-users laptop right who
has you know has a different time zone
but they've made the numbers at the top
of their screen line up with their local
time zone right and so they're like five
hours off
you know in terms of UTC time right and
so there's many cases where you're just
not going to trust the system clots
there and so in this case what happens
is those elements of the system
especially if a priori you know that
they're not going to be trustworthy they
can just run in this sort of degraded
mode where they receive timestamps from
other parts of the system
you know presumably parts of your system
that are running in your data center
where you have more resources where
those things can be running in TP and so
they'll receive time Samsun when they
have local events that happen they can
just increment the counter portion at
the end without messing around with the
physical clock portion all right so
unfortunately I got the we have to wrap
it up signal so I know there were a
couple more questions please feel free
to come and find me afterwards and thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>