<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Lazy Defenses: Using Scaled TTLs to Keep Your Cache Correct&quot; by Bonnie Eisenman | Coder Coacher - Coaching Coders</title><meta content="&quot;Lazy Defenses: Using Scaled TTLs to Keep Your Cache Correct&quot; by Bonnie Eisenman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Lazy Defenses: Using Scaled TTLs to Keep Your Cache Correct&quot; by Bonnie Eisenman</b></h2><h5 class="post__date">2017-10-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kxMKnx__uso" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay hello everyone thanks so much for
being here with me at strangely today I
am really excited to get started so
before we begin my name is Bonnie I am a
software engineer and the tech lead on
the gizmo doctor team at Twitter were
named after a DuckTales character you
can see him on that slide yeah Wow I
didn't know that they were like
ducktales fans as a fan of still so the
names not important what matters is that
we're part of core services we run the
user service and the social graph
service at Twitter among other things
and those services manage all user data
and information about relationships
between users so that's things like
what's your screen name what's your
profile name are you following someone
as you can imagine that means that we
get to see some pretty fun problems and
I'm gonna be talking about some of them
today so specifically I'm gonna be
focusing on a deceptively simple
technique scaled TTLs that we use in
order to build confidence in the values
that we store in cash and I'm gonna
begin with a pretty general overview of
cashing and distributed systems so if
you haven't done distributed systems
design before don't worry we're gonna
start off fairly basic and then I'm
gonna build up to explain the
motivations behind the modern-day
caching architecture that we use on the
Twitter user service so if you want to
find me on the internet afterwards as
you would expect from a Twitter engineer
I'm on Twitter I'm at Brandel you can
also find me on my blog at Bonnie
Eisenman calm and I'm also the author of
learning react native which has nothing
to do with what I'm talking about today
but it's about how to use JavaScript to
build mobile apps for iOS and Android
and it's at that bitly link all right so
let's get started we're going to begin
with a very common story so you're
working on a new project you're just
trying to build an MVP you have
successfully followed a rails tutorial
and now you have a simple application
layer talking to your database when you
get requests in you serve data out of
your database and everyone is happy good
job so let's say that your startup
actually gets some traction and whether
it's something goes viral or organic
user growth you get a big spike in
traffic this is really exciting it means
that people actually like what you built
and they are using it it's also not so
great you weren't actually prepared to
handle that much traffic some of you
might recognize the since retired fail
whale which used to be something that
you would see on Twitter when this
all right so now you have an application
that you built and sometimes it falls
over so what do you do next so there are
several right answers and I'm stealing
this quote from Donald Knuth premature
optimization is the root of all evil the
answer to how should you scale your
application will always depend on the
specifics of your particular use case so
the first step is always to measure and
figure out what your problems actually
are this would be a very very very broad
talk if I went into all of the possible
solutions maybe you need more instances
maybe you can charge your databases
maybe you could sprinkle some Q's on top
of everything today we're gonna be
talking about caching so when I say
caching I mean storing and retrieving
data from a high-performance store I'm
explicitly not talking about this kind
of cache so we're not talking about
hardware caches you might know that your
processor has things called like an l1
and l2 cache we're going to be talking
about the principle of caching as it
applies to distributed systems so these
are quote-unquote all numbers that all
programmers should know I kept the
quotes there intentionally these are
honestly mostly folklore but they're
sourced from several computer science
papers and from several talks you can
find all of the links at the github link
down below but even though their
folklore there's a lot of use here and
the utility comes not from the
particular numbers but the orders of
magnitude between each step in that list
and these give us a good sense of
intuition to start thinking about
reasonable designs so this is why we use
caching reading from memory is always
much much much faster than reading from
hard disk and you can see that in the
way that the numbers get bigger and
bigger
now if you've used caches before you
might be familiar with memcached which
is a distributed and memory key value
store if you're being really pedantic
you'll pronounce it in memcache D you
don't have to do that Redis is an
in-memory store that some people use as
a cache - it stores data structures
instead of simple keys and values but
the basic idea is the same we mostly use
memcache at Twitter and we actually use
a specific variant to us which we've
open-sourced
it's called
- em cash if you're being pedantic and -
em cash if you're not I'm gonna call it
- em cash or Twitter memcache so this
the stuff I'm gonna be talking about
today is motivated by my team's work
using Twitter memcache but the
principles should apply regardless of
what kind of cash are using so these
specifics don't really matter all right
so we're gonna get into some diagrams so
if you remember our very early rails app
that we built from our tutorial this the
architecture diagram might look
something like this you have a service
or application layer it talks to a
database when you get a request in the
service queries the database returns the
data very straightforward we've got one
line now we want to add caching to see
if this helps our resiliency so that we
can actually handle traffic spikes so in
this very basic set up your application
calls out to the cache to try read
something if it's there we return that
data if it's not there called the
database now even for the most basic and
naive approach we have to make some
explicit design decisions here so we
have to decide what we want to store in
the cache we have to decide how long it
should stay in there is there such a
thing as stale data do we want to you
know doesn't stay to ever change is
there a sense of freshness we also have
to decide what to do when the cache
becomes full so you can only fit so much
stuff into memory and unless you have a
very small data set that entirely fits
into memory you'll have to decide what
happens when you want to add something
to a full cache what do you evict and
then what do you do when data changes so
if someone sends or write requests to
your database or to your application and
they want to modify something what do
you do then so before we get into this
impossible answers I'm gonna introduce a
teensy bit of jargon so a TTL or time to
live is the amount of time that we're
considering something in the cache to be
valid and then a hit and a miss
something is a cache hit if we look for
it and we find it it's a Miss if we look
for it and we don't find it and then LRU
is one common strategy for determining
what to evict so when you're trying to
push something into a cache that's full
you say get rid of the thing that I used
last alright so in our first set up as
we are struggling with our basic rails
app to survive traffic spikes we might
take this as approach
it's a read-through LRU cache so it's
what many people reach for first so all
queries will first check the cache if
you get a hit return that to the user if
you get a miss query the database and
you'll return that to the user and
you'll also stick it into your cache
with some sort of TTL on right you will
invalidate keys in the cache and you
will treat expired keys as misses so if
you go to look something up in the cache
and it's there but the TTL has passed
you're gonna say oh just kidding it's
not there and when the cache is full
we're gonna evict based on LRU so these
are some possible answers to the
questions that we have to answer before
we even start using caching all right so
does this work and the answer is mostly
you're in a better place than before but
we've introduced some new problems to
our system and we can do a lot better so
some of these problems with this setup
you're guaranteeing that cache misses
occur because they occur every time
something in the cache expires and
because everything expires based on the
TTL you were guaranteeing that your
end-users will be the ones to pay that
latency penalty and you're guaranteeing
that misses will occur on a regular
basis so you're backing stores are going
to see inconsistent traffic levels
because the traffic is driven by a
combination of things in cache expiring
as well as real users querying for them
now none of these problems are the end
of the world it's better than the
situation we had before you can handle a
little bit more traffic but we can do
better
all right so something that people often
reach for next is introducing a concept
of soft and hard TTLs where your soft
TTL is much shorter than your hard TTL
so the whole point of having a TTL is to
keep your cache data fresh but we can
decouple the decision about is this
fresh enough to actually serve it to an
end user with the question of should I
go update this data so in having a soft
and hard TTL lets us do that so when we
have to TTL s
soft and hard when we get a read request
in and we find something in the cache if
the soft TTL has expired we'll treat it
as a cache hit and return it to the user
but in the background
we'll go and refresh that data so that
we can guarantee that it'll be fresh in
the cache
now if the hard TTL has expired we'll
still going to treat it as cache miss so
beyond the hard TTL we're saying that
the data is useless to us so these are
some examples of values that we might
use for soft and hard TTL some portions
of my code base use a to our soft TTL
and a 12-hour hard TTL but different
datas different pieces of data should
get different details based on your
business needs so the user service
Twitter users are complicated bundles of
data basically one item that we store is
the profile link highlight color which
you can change no one really minds if
that's a little bit still I promise
but that versus whether or not your
account is private that matters a lot
more so we can tolerate a lot less
staleness for that value so because of
that you should be tuning these based on
your business needs now memcache
supports a concept of a native TTL but
it's a pretty simplistic thing and you
can't do stuff like soft or hard details
with it so instead you have to implement
it at your application layer so this is
not supported by memcache natively but
it's not too hard to implement and we'll
get into what the interface looks like
in code for it later on all right so
I've talked a little bit about a
hypothetical caching setup and how you
might evolve a very naive caching
strategy and now I'm going to get into
the good stuff of the actual challenges
that we see on the user service at
Twitter all right so like I mentioned
users are bundles of data and the user
service handles all reads and writes to
user data so that's live in production
that's both when you hit twitter.com and
you load a timeline and there might be
you know a couple hundred users in that
timeline with their profile images and
their screen names and all of that it's
also for things like offline data
analysis so that Business Analytics can
calculate things like how many monthly
active users do we have on the site and
user data includes a lot of different
things so there's your screen name and
your display name there's also your pro
while imageurl there's also your account
settings whether or not you're protected
or verified a lot of stuff goes into
making a user so we handle millions of
queries per second and we do that with
thousands of instances of our service so
we deal with a decent amount of traffic
now each service at Twitter has very
different characteristics and patterns
that's the whole reason why the core
services are divided up the way that
they are and the user service has its
own particularity
so for one we have way more reads than
writes so again if you think about the
Twitter timeline you see a whole lot of
users rendered to their people update
their Twitter user objects so whether
that's their account settings or
something like that that happens a lot
less often so it's very uneven reads
versus writes we also see traffic spikes
driven by major events that's just
quintessentially Twitter so whether or
not that's a sporting event or something
in politics or a natural disaster
traffic spikes happen all the time we
also see really uneven traffic across
the ID space so some people are much
more popular than others it's just true
Taylor Swift is always gonna have a lot
more traffic to her user ID than I will
and so you know we can't expect even
traffic based on IDs and writes often
happen in a flurry of consecutive writes
so if you update one field you're
probably gonna have more updates
following that it's also a pretty large
data set because we're dealing with all
users ever created at Twitter so we
can't do something naive like just shove
it all into memory all right so if you
remember our simple application diagram
this is not what my world looks like
instead it looks something a little bit
more like this the user service has over
a dozen backends that we depend upon
these are things like the email service
or the social graft service or geo not
to mention our own databases and none of
those services are running on a single
instance either so if we were to
actually whiteboard out all of the real
connections we would be here all day and
this was our basic set up for cash
in reality it looks a little bit more
like this so the user service has its
own cache cluster which again contains
many many instances now in code we want
to group these logically connected
things together so we'll talk about
having an email cache or a social graph
cache even though it's all the same
cache cluster so in code we represent
them a little bit like this but
everything in the tan is all located
physically in the same place right so
earlier we talked about why we why we
might want to use caching so let's look
at whether or not that works for the
user service one we want to respond
faster than the backing stories yes god
yes we can do things a lot a lot faster
when we serve it out of cache secondly
we also wanted to reduce pressure on our
backing stores so we wanted to send them
less traffic and more regular traffic so
that it's easier for and cheaper for
them to run now when we introduced
caching with soft and hard tea tales we
saw a pretty big shift in query pattern
so you can see on the one side we've got
these huge waves of periodic traffic
waves those are happening over the
course of hours and then once we
introduced soft and hard details you can
see that the line flattens out so that's
much better our database team likes that
better and we rely very very heavily on
cash so 99.9% of all requests are served
out of cash on a good day that's much
higher and this doesn't mean that we
have like almost the entire user space
in cash it means that for incoming
requests over 99.9% of them are served
from cache and that's an important
distinction it's what lets us be as
efficient as we are all right so now
I've given you sort of an overview of
the state of the world let's talk about
some problems because those are more fun
all right so the first one I mentioned a
little bit earlier is traffic spikes and
these are absolutely essential to how
our business works so whether or not
something like the World Cup or Japanese
New Year's
fun fact Japanese New Year's is our
biggest New Year's Eve our spikes are a
totally normal part of our business and
one of our most famous ones and
infamous ones internally is this so this
is the selfie that broke Twitter how
many of you have seen this selfie yeah
nice
alright so for a long time this photo
had the record for the most retweets oh
that has since been broken Ellen
DeGeneres broke Twitter on live TV which
was really exciting we actually have a
painting of this photograph on the wall
at Twitter HQ okay it's been
memorialized so you'll notice that
there's a lot of celebrities in this
photo and what happened when this got
tweeted and when Ellen said on live
television hey guys you should all
retreat this a handful of user lookups
became very popular very quickly now all
of our on call engineers were watching
the Oscars live in a room together has
it happened and all of them turned to
look at each other and went oh well this
will be fun so what happens when this
handful of user lookups all become
massively popular is that that traffic
all falls onto a pretty small number of
cache nodes and we overwhelmed our
memcache cluster so that was
embarrassing let's fix it so for a
solution we can turn for inspiration
back to these numbers that every
programmer should know so even though we
were reading from our memcache cluster
it was still way too slow now we could
have added an enormous amount more
capacity I suppose to account for that
but that wouldn't really help instead
what about reading from main memory
instead of doing a same DC round-trip so
that'll be a thousand times faster and
we can use this to solve the Ellen
selphie problem so now what we have is
we have an in process hot key cache Y in
process because it's much faster why
hotkeys because we can't fit everything
so we define hot keys as keys which we
look up more than a certain number of
times per minute we just call them hot
this is tuned empirically it's basically
the result of several production
incidents and the cumulative knowledge
we have gained from that and we put a
30-second TTL on that cache so it's very
very short so that we don't have to
worry about this being too stale but
this allows us to defender--
against things like the Ellen selfie
problem so other events which no longer
cause us these kinds of problems which
used to the World Cup the Oscars the
Olympics presidential inaugurations lots
of things cause this pattern of spiky
lookups for either one or a handful of
users and it's very nice not to worry
about them anymore so that's hotkey
caching it's great
we should have added it earlier all
right problem number two is outages so
in a complex distributed system failure
and degradation are totally normal
events but this can manifest in some
unintuitive ways so raise your hand if
you've heard of a retry storm before ok
few hands yeah this is a really common
scenario so I'm gonna talk through it
really quick we've got a super simple
service diagram here a calls B which
calls C nice and straightforward when
everything is working data flows in one
direction data comes back out this
should be great now let's say that
service C isn't doing so well it's a
little bit unhealthy and because II well
a calls B which then calls see now this
request fails but that's fine because
service B is configured to retry
everything twice so it issues two more
requests and they both fail so after
querying C three times service B gives
up and tells a I'm sorry this request
has failed
it says no problem I'll retry twice so
you can see where this is going
because each of those requests is gonna
balloon so in this very simple world one
incoming request balloons out to nine if
service C is down and you can imagine a
world where I say 10 services are
calling B and 10 services are calling
each of those and these things can
quickly get out of hand at the worst
possible moment now while all of this is
going on the team who's running service
C is desperately trying to keep things
afloat and maybe they could have if you
all hadn't been giant jerks and dumped a
bunch of traffic on them when they did
not want it and for a service like mine
so the user service has over 300
customer services within the company so
that's a lot if all of those hit us with
a retry store and when things get bad
that is not fun but luckily caching can
help us with this so we have a solution
that we call dark moding or auto dark
mart auto dark moding or back pressure
or automated back off we really need to
standardize our naming whatever you call
it
the idea is pretty simple but it's very
effective so when you notice that your
success rate is starting to drop stop
sending it a bunch of traffic that's no
good why would you do that slow the
torrent of traffic down to a trickle
just enough so that you can keep
measuring success rate so now we don't
want to reject all of those requests
because that just you know creates the
problem all over again but instead if
you have a decent cache hit rate you can
just serve stale data out of your cache
and then you can gradually restore
traffic as your backends recover now
this isn't ideal you're still serving
stale data depending on your business
needs this may or may not be acceptable
but it's a lot better than causing an
incident wallet incident is going on all
right so the TLDR dark remoting is great
we like it we use it extensively if your
cache hit rate is reasonable this is a
really great thing to implement and a
really easy win all right
so the next problem is the case of the
missing account so this happened in the
middle of a Lakers game
the Lakers account disappeared that was
uh that was fun we got a lot of really
sad user reports and a lot of very very
confused things again of course games
are on live TV so it was fun to watch on
live television as everyone went where
did the Lakers go
so before I dig into this a quick
shout-out to Etsy's Coda's craft blog
and specifically the blameless post
mortems post if you haven't read it yet
I highly recommend it
so all incidents at Twitter get post
mortems
where the goal is to figure out what
happened and then why did that happen
and then why did that happen what made
it possible for this to happen we try to
figure out what we can do to stop the
same kind of thing from happening again
so you can imagine this warranted a
post-mortem so our team started digging
into how on earth the Lakers account had
vanished
so was this an application layer bug did
we have like a bad deploy was there an
obscure untested code path how on earth
did we do this
the TLDR is that what probably happened
is that we cashed a transient not found
result from our database everything else
was behaving as expected but when you're
dealing with as much data as we do we
expect that sometimes weird stuff will
just happen sometimes things get
corrupted in transit maybe there are
ghosts I don't know the problem here was
not that we had gotten a bad value back
we should be able to handle that the
issue is that once we got the bad value
we kept it in cash which is how we serve
traffic during spikes during things such
as sports games and our default cash
time was 12 hours so a single bad value
from the database would stick around for
12 hours and for something like a not
found and that's really not good so what
do you do when you don't trust your
database it's sort of a large
existential question
but this issue is not limited to not
bounce any piece of data can be
incorrect or incomplete or corrupted we
really want to be able to handle that
regardless so this is a favorite paper
of mine it's called how complex systems
fails by Richard cook and it has a
really nice line so complex systems
contain changing mixtures of failure
latent within them
so again any kind of data can be
incorrect or incomplete or corrupted and
we have to expect that that will always
be true and that we will not be able to
predict how that will manifest it's just
going to happen we might as well be
ready for it now I'm gonna take a little
bit of a detour which might help explain
why this is so easy or why we should
expect these kinds of failures to be
common so let's talk about cross data
center replication now we have an
eventually consistent database and as
someone joked to me earlier at this
conference eventually consistent means
inconsistent so any incoming write
request that our service gets needs to
update its own cache then it needs to
write to the database and this is all in
one data center and then we need to
update the other data centers cache and
then we have to rely on our database to
handle its own cross data center
replication across all of our data
centers yeah this should scare you um so
this is a recipe for race conditions
it's really great race conditions make
us sad and for some kinds of values this
is okay but this is inevitably going to
result in the kind of block I like a
account just disappearing now if we
think again about the basics of querying
from cache vs. clearing from the
underlying database we have this TTL
which basically Tunes how fresh we want
data to be so we could decrease all of
our softy TLS to mitigate the impact of
this kind of caching of bad data that
will result in more traffic to our
backing stores that'll put more pressure
on them that's marks
pensive so now we're in this awkward
situation and where we're trying to
decide on a trade-off between resiliency
with operational load there are many
reasonable ways that you could make that
trade-off there are plenty of answers
that I could defend on the grounds of
business needs I don't like having to
make that trade-off that just seems like
we're losing either way so we did
something different and what we ended up
doing was scaled TTLs
now this only works if you're eventually
consistent database is in fact
eventually consistent but luckily that's
not my problem to solve so the idea is
that we're going to adjust our TTL based
on the likelihood that a value is
correct we're gonna start it at a very
short amount of time and ramp up and to
the user this will make it seem like any
inconsistencies fix themselves what
while it doesn't add any operational
load to our own databases so this is
great so how do we build confidence how
do we get an idea that probably this
value is correct the answer there is
repetition so when something's soft
detail expires we have to go and fetch
it from the database anyway so what we
do is we say that hey if the value is
staying the same on consecutive reads
it's probably pretty good it's a good
signal for accuracy without having to
make any sort of extra expensive calls
so when we when a value changes why
they're not that's like on its initial
creation or on right and we put it into
cache we start the TTL at 2 minutes and
we also store a counter for how many
times we have consecutively read the
same value the next time when it expires
we say hey is the value the same if it's
different then we'll keep the TTL at 2
minutes until things fix themselves and
if it's the same we'll bump it up to 30
minutes and then 6 hours and then 12
hours and then 24 hours now these
particular steps were things that we
chose because they worked in practice
but also because they have the nice
property of resulting in the same
number of reads to the database over a
several day span as our old TTL values
did so again this did not cost us
anything extra but it made it so that
inconsistent results would get fixed
more quickly so if we think about the
Lakers case before with our you know
very simple unskilled TTLs if we
received a transient bad value the user
service would go great that's awesome
I'll put it in my cache and then twelve
hours later we would notice that it was
wrong so that's really bad we don't like
things sticking around for that long and
now we have scaled TTLs so when we
receive and not found it's different
from the previous value and the user
service notices that so we reset the
soft TTL step to zero and then two
minutes later a read-through will occur
and we'll notice that now the Lakers
account exists so then two minutes after
that we'll check again and two minutes
after that we'll check again and once we
settle on a consistent value then that's
what stays in cache for longer so we
like measuring things we keep track of
stats on both inconsistencies
so we dispatch RPC calls to measure what
another data center thinks and we also
keep track of which step how many
consecutive reads things tend to cluster
at so we only go up to step four because
anything higher than that we just
pretend doesn't exist on the left you
can see the step distribution for an
immutable field so racy right conditions
don't happen so that's sort of the
perfect state the balance study state
given create traffic and on the right we
have a field that sees the most frequent
clustered flurry of writes so it's the
field that is most vulnerable to race
conditions and as you can see instead of
clustering towards that purple green
stuff at the top there's a lot of green
there's also a really nice bar of spiky
things at the bottom where you can see
that it's usually inconsistent for the
first few minutes so the implementation
of this it's very very similar to
implementing softie TLS
we store a short which contains the
number of consecutive consistent reads
and when it's inconsistent we reset it
to zero so pretty simple logic doesn't
take up too much extra space and after
we implemented it and we deployed it and
we scaled it up and we measured some
stuff we saw that we had up to a 30%
reduction in cross DC inconsistencies so
that was awesome
and the change was most dramatic all
user data where changes happen
frequently which makes sense so and
we're defining inconsistency as data
changing between reads when we don't
expect it to so that was exciting and
this has several benefits so we get to
magically masks eventually inconsistent
or flakey database behavior we also
found it to be pretty simple to adopt
and implement it didn't require a ton of
complex integration on our end it also
adapts organically to different query
patterns so for different fields of the
user things behave very differently but
this has the nice characteristic of it
just adapts on its own you don't have to
do a lot of manual tuning there are a
few gotchas so the first is that it
requires a gradual ramp up you have to
have this data before you use it to make
decisions otherwise if you just deploy
it straightforwardly
you'll find that everything has an
initial number of consecutive reads of 0
which means suddenly your TTL s4
everything will plummet down to 2
minutes don't do that you also need to
use this in tandem with dark moding or
automated back off or automated back
pressure whatever you call that kind of
mechanism if you don't you have
successfully caused your own retry storm
because in the face of flaky behavior
from your database this will send more
traffic because your TTL will be shorter
so you have to take the operational
impact into consideration a little bit
when you're deploying this talk to your
database team before you do this please
so if you want to figure out whether or
not this is something which can be
useful for your service
so first of all measure do you have
these problems is this actually
something that you're seeing in
production then think about what your
write traffic looks like how much
staleness is acceptable to you whether
or not these trade offs are actually
reasonable for your service all right
but if these trade ups are reasonable
Congrats you should do it all right the
last thing I'm going to talk about is
some of the programming idioms we use to
make it easier for service owners at
Twitter to implement these things
correctly so we have an internal library
that's designed to encourage
decomposition and reuse of common pieces
of service architecture
it's called servo these examples are all
going to be in Scala but the language
really doesn't matter too much there's
just going to be some type annotations
all right so the first thing that we
have is a repository type you ask it
something and eventually it answers
that's all that that type says so the
future contains the eventual result you
ask it something of type of queue that's
fine then we have a notion of something
called a key value repository where you
can ask it for information about several
keys at once it returns a result which
contains a mixture of like founds and
not founds so pretty basic so we have a
key value repository of type Q K and V Q
is usually a sequence of values or
sequence of keys sorry all right we also
have a cache trait which gives us a
unified way to talk about caches none of
this stuff is particularly memcache
specific just means that we can do set
and get an add and delete they're not
particularly complex interfaces all
right so the first thing we're gonna do
is abstract away the caching behavior so
you give this caching key value
repository constructor a cash and a
underlying repository it gives you back
a cache and key value apposite Ori like
the name implies when you call the
caching key Val your posit Ori it
handles all of the caching nonsens for
you same thing for dark moding savings
interface except now it has extra logic
around measuring the success rate from
the repository so that it can make
decisions about whether or not to serve
stale data out of cash all right now you
might have noticed in those types of
matures that there's a type called a
cashed of V and this is just the
metadata that I had mentioned earlier so
because memcache does not natively
support things like a soft TTL or
keeping track of the number of
consecutive consistent reads things like
that instead of just storing a value of
type V we store a cache of V which
contains a tiny bit of extra information
that we use to make smarter decisions
now when we wire it all together the
names start to get really long we have a
scale dark mode and caching key value
posit or E yeah the names tend to get a
little bit too long and what this does
is it basically hides like this Russian
nesting doll lot logic which can get
really easy to wire up incorrectly so
when you when should you do our toe dock
moding when should you read through to
the underlying data store how do you
calculate the soft and hard details all
of this is handled by this scales dark
mode and caching key value repository
which is a terrible tongue twister but
you shove all of that logic into one
place and you never think about it again
but if you have to go figure out how it
works that's where you look now actually
querying your repository becomes much
easier you just ask your caching repo
for our user ID and that's the end of
that so now all of the caching and
hydration logic is hidden from you all
right so what are the end results here
so we use caching to solve a lot of our
problems on the user service
it helps us weather traffic spikes
inconsistent databases total outages and
it lets us do all of that while serving
millions of queries per second and
hopefully you never see Twitter comm go
down and we use a combination of scaled
soft and hard TTL and
junction with auto dark mooting and that
keeps us up and running even under
really extreme conditions we've had
cases where our database went down for
hours at a time and nobody noticed which
was really exciting alright so another
quote from how complex systems fail
failure free operations require
continuous experience with failure which
is you know one of those things that
looks like a paradox until you think
about it so all of the incidents and
failure modes that I've described in
this talk they're the reason why Twitter
comm is more robust today so good post
mortem analyses can help you learn
critically important lessons from
production incidents and hopefully stop
them from happening again so yeah
there's one thing I want you to take
away that caching is kind of great but
first you need to figure out what you're
using it for so the strategies that we
use on the user service are designed for
our particular problem space they're
very particular to us and the robustness
of it is a direct consequence of the
knowledge that we've earned from real
failures so if it wasn't tailored for us
it would be a lot less useful so go
forth hopefully some of this is useful
for your own service designs but first
measure alright thank you very much if
you want the slides they're there</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>