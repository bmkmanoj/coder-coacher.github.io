<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Monadic Deep Learning&quot; by Yang Bo, Xiaolei Wang | Coder Coacher - Coaching Coders</title><meta content="&quot;Monadic Deep Learning&quot; by Yang Bo, Xiaolei Wang - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Monadic Deep Learning&quot; by Yang Bo, Xiaolei Wang</b></h2><h5 class="post__date">2017-09-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FiMz-11ESUQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone it's my owner
to share our recent research on deep
learning so my Lemmy is young but open
source developer also works i maintains
and contributes hundreds of open-source
projects most notable projects are
pending scala and deep learning dos
Carla hello my name is Shallon I am so
late data scientists in solvers from
name my company is a place we are our
sort words we are honored to stand here
sharing ourselves today
so to summarize today out how it will be
about two things first one deep learning
second one is about the functional
programming so we are starting on why we
can tell this deep neural network
please functional programming first and
then well present in our learning
framework name depend on Scala who are
showing some truly details and they were
illustrate what is and how to make
monotectic learning world as well as to
solve this expression problems in
stralla yeah actually I am so tired I
was leading a project for our customer
resume image I spent about two ages 14
16 hours a day
Tony's a parameter slightly error a deep
learning project so it's punishes her
space and it's long term TFSA was
drumming frizzy program in NeighborWorks
i was dreaming about automating
programming robots who helped me so
today I'll copy it is malleable
automated program a robot
yeah modo means as this kind of
generating of new rules not exactly
I mean automatic programming with you
all it works
oh please nurse that is interesting I
have read a lot of paper trying to do
that but I don't know if someone has
finished you know about aro the best
algorithms for some deep learning is
large SVM and random forests but I never
see any kinds of support vector machine
lab
nowadays we have deep learning labs
everywhere why that is because that we
don't have only many parameter C as we
are and we don't have many parameters in
random forests but nowadays we have tons
of parameters and hyper parameters in
deep learning somehow I think it means
Harper parameters of neural network is
default mer oh no I'm used to think that
machine learning can automate
programming and generate a program for
me unfortunately deep learning itself is
to complete to be automatic so what do
you guys make it so so complete yes and
McGlothlin is a polite deep learning
written by jordan floor and Hinton here
is illustration of the deep learning
model it is difficult for the computer
understands the meaning of the raw input
data such as this image right here arepa
saw is has some float values so function
marine from a set of this kind of pixels
now object a do today is very
complicated
deep learning sources difficulty by
feedings uh maybe in tone series of
simple mappings each described by a
different layer of the model so sitive
means the number of layers is very high
interpretation of deep learning so you
know in fact neural networks can be sing
and functional programming yes recently
I have raised a twist-off all's at all
neural networks types and functional
programming it is says I functional
programming with the same structure as
neural network well be the way people
understand deep learning maybe thirty
years later however Cree says that it is
acetate adamant rather than adamant of
which it will not affect the one Chris
wrote the article but now his argument
become effect because we can represent
neural networks and functional
programming with the help of our library
depend on Scala
so today please show us what you guys
have down indeed learner Scala
of course
different of colleges a Scala library to
create neural networks
I know Scala it is sad search it is a
GVM language and a sparse both
object-oriented programming and
functional programming so those is
problems of artists design for
functional programming yellow
independence color varied types of
neural networks can be seen as man
produced or other higher canted
functions and especially you can create
dynamic neural networks from knowledge
or the well known Combinator flat map
and for object object oriented
programming our plugin system is
designed according to an approach called
object add grass which resolved the
problem the problem expressing problem
so I got 30 points here object algebra
and expression problem I'm dodging
abused I will introduce the plug-in
system later for now or I can tell you
that you can share your own algorithms
models and hyperparameters as plugging
as simple as creating some kids artists
then your plugin users simply import
those plugins and cows all all those
ability from those plugins or together
our tourism has a bit half-dazed
interesting so adults is a data
scientist here like may intend to use a
Python network as a environment
environment what environment you know
ipython notebook actually has real and
to eat a lot hook which supports not
only present but also other programming
language and yes you can create the
alert words in deep learning ecology
code book okay I used to seems that you
cannot world rehearse dynamic
programming language Scala is a state
programming language however it has the
future of grunts hammer reflection so
which allowing dynamic code excusing as
a result you
Karin dependents coloring book one cell
per one CEO and ski-e-o keep all the
benefits of type checking mm-hmm
impressive
so place some gem oh okay so firstly let
me ask you a question what is the left
lumbar use our success as a human I
think maybe his hot rod roles can be
understand here as a Thomas word
automaton what I think it is kind of
arithmetic progression and trauma
difference of first sin you insist on
certain eye shapes may be no mores a 2d
lines of Python well what rate out about
how could computer with of it without
any extra input of the rules even the
traditional machine learning we also age
the BIOS is a known synchro is a
training data and we will try to predict
so in different of Scala
despite the implementation of the robot
you can create the robot and the
function like this so Christmas number
is not an ordinary function taken a
question and parameter which is lower
numbers in the sequence and the return
value is the next number predict by the
robot and the usage of kaznyk number you
know difference from ordinary function
are you see you can invoke the function
and print the result so thank you to say
all you relax works functions all right
so what is appropriate way to light
robot know what is happening along with
a function good question a liberal
network is not a pure ordinary function
because a pure function always protoss
the same output according to the same
input however when you are creating this
IQ test a robot you did expect the
robbed works well you cannot expect the
robot work well and the very beginning
because the robots you know nothing
answer than time
and when you feed more and more tackle
it we are not ontology so for example
yes you can create a low function IQ
test the robot here the IQ terrible
Trina which has two parameters the IQ
test question and the expected answers
we expect that the robot will be
improved when we continuously feed it
the data so the IQ test local trainer is
composed of two functions case neck
number and the news functions so as
always already know ethnic number
returns the prediction of the robot so
then the newly indeed news function
evaluated the lose which indicates if
the prediction of the robot is correct
and how fight yield from expected answer
oh that is quite different from my
understanding of common deep learning
framers like tinder flow well you
already use a loss function endurance
optimization live here tensorflow sloths
paternity is kind of not like true
function it is somehow an instruction of
optimization are really poor functions
including the self so that is why you
can easily compose two functions Christ
next number here and it slows country
here into a new function good catch
so how to generate as a fortune so
that's easy you can simply call the tree
method and the function IQ test the
robber trainer ideally the robot we all
learned some was from the training data
so the robot answer will become closer
and closer to the correct answer and the
rules become smaller and smaller than to
say a new your network is not only an
ordinary function button function with
the ability of training mm-hmm I still
since that there is no guarantee for a
new network to learn our
for instance the role here means the
adult Astra but it depends on how it
assigns laws and the predatory functions
so let's implement the function and the
prediction function so okay so you are
getting use a square laws here which is
a sphere of the difference between the
grunt rules and his robots answer so and
you are using a sum of polynomials as a
production function but his looks very
strange to me I already performed his
kind of Landon transformation in number
transition is yeah like this one is
Adelaide your chart this clothing tender
flow oh it might not be a deep learning
because we only have one foolish net
leaders here but actually this is very
other framers than the flows and okay
Tosh learns what is it about it the
Scala it can be represented as MapReduce
if you use functional programming style
so it means MapReduce stuff is address
net number function yes matrix
multiplication can be split into two
states the first stage is multiplying
each input of weight the second stage is
the sum which can be implemented and the
reduce underscore plus underscore than
to say alien vector right computations
can be split into more automic
higher-order function calls so what is
benefited to this higher order function
instead of vectorized commutations
because the higher-order functions are
more flexible arrays in a more question
i saw some ways here are referred in the
function as a channel yes they are the
function knowledge of Connect number
house of two parts the first part is the
code right Empire human programmer and
the second class is the weight known by
the machine in other word the mainly
right-hand part of the code is just a
template of functions and defends the
structure of the program which still
have some hope to become completed by
the machine from a program and point of
view I feel the express the experience
of creating such a program template in
different Escala like some kind of meta
programming very similar to creating an
HTML template so since the host can be
automated by the machine now they are
taking part to our first discussion as
beginning to the machine there's a scale
of programming to some extent yes let's
think about some typical practices we
can't describe the problem as test cases
then changes the function implementation
in order to pass that test
yeah since the test-driven design if we
consider the test case here as training
data and the test pass here a small
portion will not minimize the loss
runways available observations it is
just like the training provides in a
neural network so the health also
adherence as a neural network is mass
function and it is meta programming but
can we say it is functional programming
less darkness in power in total current
in your network
it is very balanced as input for somehow
a Tetris sentence as input and worrying
sentiment analysis is actually a further
left
suppose you have a stack of input future
when you are left on it you provide an
initial state and a state under step
functions and for the left folks
function applies lost em function on
each element of the
with stated repeatedly finally you work
as the result state some similar tuna
our encoder truly plays include excuse
me what is a food after okay that's it I
say the step function here Pizza state
and an element of input as parameters so
I can create different implementation of
step function for different variants of
our light long time short-term memory
for example this encoder which using H
as its activation function so I would
like to charge another instance is 2d
convolutional neural network this way is
a most may be the most family for all
rods here it is ephemeral since the
image has revision or image perception
task a little tricky in functional
programming it's like a winter month you
can zip your input with an offset of
itself
the pro then you provide a kernel for
the following map most method so how
transients treat apply to the 2d silly
or for journalists for to TCM you will
have to deep more cases of the offset of
the input together and provide a larger
color so for example here we have four
four cases or offset but it's just kind
of redundancy this is a two by two and
oh so how it comes slight a three by
three or five mile files you have 25
variables it's kind of strange and
border bridge you are right
in fact one of my future research is
using zipper and hope and to male to
model the iana those polar plates here
in this man
and the approach will be minimized in my
new approach hmm
so maybe less age so here I think this
hair is your fortune on names of the
common layers as described by the
original author and you have done that
by your whole into porn Australia right
yeah
so based on what we have discussed about
if we would like to improve automated
programming robot so they should develop
a general functional tablets that could
fit all the human creative functions do
you have any other I think we can create
a general model that contains many
sublet for different domains each tablet
is you the for certain input so I guess
your idea request conditional switching
of subnets according to the data just do
you have any idea so how do you guys
make conditions in new your let works
that's she okay I have read a paper is
named by the sparse mediating the
mixture of its verse is published maybe
two years ago this means that in this
paper for error observation smaller
itself that's try to select as a
correspond its birth to performs
repetition with this design it is
possible for us to train a huge neural
network but only a small part of age is
activated during the training progress
so the model has run very fast visually
a huge knowledge base so would you
please share your implementation of this
kind of computational cost because
annals that its original source code
there is a lot of trees okay let's
simplify the problem by creating a
conditional neural networks that only
have two branch a logical approaches
excuse the conditions and selects tablet
by the condition the this approach can
be written as this so there are three
supplies in the logic 88 led function
that gets returned a pair of double
layers which determines which tablet is
prefer between the sublet and right
sublet so do you mean trainee answer
gauge the result of the sublet will
multiplied by the value returned by the
case as we not Bank provocation will be
performed under Kate okay I know I
noticed another scenes that in your code
iterator naive dated night why because
they are you
Foreman's issue on the lodge of Katie
left interplant of Scala or layers
including Skylar layers like double
layer and the victor right layers like
in the layer represent lazily evaluated
differentiable computational Chris which
we are be executed until its predict or
the tree method is invoked so you can
see there are two calls to protect
messaging the if clause
here and here so which means the
computational grief evaluated twice also
logical as itself is a computational
grief there will be a predict or the
Treme's method we have you invoked from
the user in the future so which we are
executing the computational grief one
more time but what even was the input is
the computational quest and it will be
evaluated three times which may contain
very complicated future extracting
process all right it would be a waste of
the computational results to evaluate
the input here yes in this
implementation of conditional neural x2
only evaluated one branch of the sublet
for one sample however the precondition
case and the input were evaluated
repeatedly it doesn't sound like a wise
approach is it possible not to evaluate
chance great okay so this is impossible
as long as you use more later managed
it's a type class or interface whatever
you call it
genome generally speaking if you have a
class with the flat map then the class
is a mulatto flat man yes this side
called flat map is the Combinator than
composed two computations into one
computation for example here too is type
data represents differentiable
computation occurrence which has a flat
map method in other word to either
mulatto
got it
the state one computation is the compute
is the precondition and the state 2 is a
copping something than to return the
computation of the final result and
finally when you plant man stage 1 and
stage 2 together you will get a Leo
computation which contains both states
but why do you have to express this
competition into two stages because we
need dynamic you see the stage 2 is a
function which is returned computation
which is dynamically determined by the
result of stage 1 now I don't understand
age with allies at 18 network to be
stage 1 unless the branch submerged to
be searched to so we turn Tobias
enlarging this way that's right let's
code it what is a - bottle here this -
Pato so it's a larger Combinator you'll
owe our kitchen network actually we turn
the pair double layer say a pair of
differentiable computational grief or
double however this flat map requires
only one computation not a pair of
computation
so
we use this to po2 in order to convert a
pair of computation into computational
pair mmm interesting so it's very simple
but there is another problem by default
these two poor two method performs
sequential execution which means the
pair of the computations returned by our
kt network will be evaluated one by one
so what is a problem here you know we
usually submit this kind of computation
on GPU so you need to make those
computation be evaluated in perryland
for better performance I thought all the
GPU task here are exaggerated in
parallel but thought that's right
normally your vector right the
computation we are basically to thank
round pieces and distributed to separate
computation units and GPU but we are
talking about cost grant paranoid so if
you submit only one computation to GPU
and one time when the GPU completes one
computation and the waiting for the left
computation it will call the GPU
starvation meters so we can resolve this
problem by under some peril and tax so
now those computations are marked and
parallel that to vote who will run them
in peril on problem resolved yeah so to
do please just summarize it by our four
map okay say here is your stretch of the
coach could you please let me know what
is a forward
okay the apprentice Carla all ages are
differentiable computational quiz but
uses a dual is a computational graph
just in fact a layer you simply or
Rampur - so what is the difference here
yellow layer does not have parameters
thus it is not possible to have a flange
mount for those types or making them
male on the other hand to either male so
you can Korea magnetic dynamic neural
network only Andrew not our layers right
but you can convert a layer into a to
Vassar method for then you flat mount
onto
creating your own dynamic networks and
finally converting the two bank to a
layer mm-hmm that it plans as wiser is
afford
so if you have any question just
interrupt me processes this thought
maybe kind of stole out here so until
now all we have talked about the
relationship between the deep learning
and functional programming and yes deep
learning is a higher order function and
the only difference here is neural
network itself is a template so we have
some weights time updating itself by the
loss the Oh laser is no need for them
expertise and rules but ultimately
nowadays we have some hyperparameters so
how our parameters here is referring to
the structure of the neural network for
instance in our destruction
just last session about the submerged
eros a plant here needs is only hyper
parameters set by the data scientists
based on their knowledge so show me
already salivating deeper under Scala
those hyper parameters you are talking
about is actually low and as the
expression problem which is about how to
and both Leo tribes and the new
functions into a system I remember that
you have mentioned that before
deep learned Australis of the impression
problems with the approach taught object
algebra so what does it mean by Tipler
Scala is about two types and functions
firstly I will confess that I omitted
the hyper primate configuration apart
from all the previous code examples so
if we include those hyperparameters
configuration the code become like this
okay how parameters here should be a
variable and the inter are revealed here
should be at hive but what is is
hyperparameters thought in our Rivage a
typo fixed by a variable R you know this
is Scala
so in fact those types are called pants
dependent type in Scala and those
clothes is somehow true I cannot imagine
that I had to pose a hyperparameters
dodged in front of anything
you don't have to because you can't just
end some import mm-hmm but why I can mix
all the marbles now perfect said the
first Israeli is that you can create
different traffic for different hyper
parameters so for example if you want
out of your sublet have different
learning rate and then you can do this
so you have a certain reason here yeah
so to read the section reason you to
read of the expression problem these
hyper firm prefix itself is composing is
possible it can be composed from
difference of plucking so as a vary
between East as a tip lenders car
sharing algorithms as a pairing yes for
example I will show you up say
unplugging which and the support of
convolutional neural networks and how to
use it
ok that's it
so you import the come to tea and then
you can use it here
you can think of cloudy and interrelated
as expressions which are added into the
system by in neighbor say unplugging and
in the real layer plugins so you in this
this is the beauty plugins which
contains all the beauty in other plugins
so then that's exactly what the present
problem means but I think such is not
enough to solve this by the for the term
emotional interest well I try to turn in
miles hopper parameters it is really I
don't want to introduce new it versions
here instead I want to make my
interesting it person very optimized yes
you can some plugins to change the
behavior of existing API for example
there are various variant of
optimization plugin so including
including momentum diagram and atom so
how do I use this type of bearings so
note that the city you can special here
is changed according to the enabled
plugins so that means as this code meets
all the ways here being optimized by
momentum now like this in fact it's
moment with flat fixed learning rate
because you in neighbor the both fixed a
learning rate tracking and a moment
clogging mittens
so let's summarize about our table today
first we use the basis of motion journey
into Cambodia fortunes certain we have
two maps come on deep learning layers
into higher-order functions so they are
going to how to create the dynamic
neural network from Mona's last point is
how to massage a differentiable function
l-system become intense ball so what is
your future world today some of the code
examples shown here are placed on top of
layers which support element-wise
operate operations with higher-order
functions however those element wide
operations that not one GPU and to this
and the moment so I guess that will be
very slow incorporation to the Buddha
based solution and yes gypsy-o is very
important today yes we have a lot of
vector drive in the relayer
which is based on and e4j and you can
run it on GPU but it does not support
element wise higher-order functions so
it's not that functional mm-hmm so it
means that for their current
implementation I cannot have both
element wise functional programming and
it's abuse part at the same time
unfortunately yes so that's why we are
creating our loop and so in deep
learning
oscalus tree the new bank and we also
proposed element wise higher-order
functions and the GPU and the same time
you are getting Tober into right now and
a lot of features in people are linked
oscalus tree the distributed model which
allows running of very large neural
networks cluster clustering substrate so
if you have any question please just let
me know the forces distortion you can
email to Ambo here and for the open
source free world so address of the
added hub test is as end of this
and the question
morning terms of
yeah
actually the beauty operators are
appliquÃ©d 94 so you can have the
paradigm ability by default yes they are
so polite in including today's flight
any more question so second forum today
and if you don't have an interest in
canter
maybe you can just send us an email</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>