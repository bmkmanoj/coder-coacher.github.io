<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Building Secure Cultures&quot; by Leigh Honeywell | Coder Coacher - Coaching Coders</title><meta content="&quot;Building Secure Cultures&quot; by Leigh Honeywell - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Building Secure Cultures&quot; by Leigh Honeywell</b></h2><h5 class="post__date">2016-09-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2BvVZU4IPKc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey everyone I'm so excited to be here
I've heard so many great things about
strange loop over the years and it's
just such an honor to get to talk to you
about some of the things I've learned
about security over the years so I'm
going to be talking about building
secure cultures my slides are online
already so you don't have to take notes
there's lots of creative commons
attribution xin the link in the notes as
well as links to various resources so
check them out um also quick content
note i am going to talk about plane
crashes but nothing graphic and like pre
minor so how'd they were like
investigated and solved if you're not a
fan of plane crashes just a heads up so
me my name lee honeywell i work at slack
on the Security Response Team there I'm
managing it I used to work at Heroku
microsoft semantic i paint and i'm
sometimes a cranky feminist on the
internet i laughed a bunch when Amy
apologized for being a lawyer yesterday
I was raised by a feral pack of Canadian
lawyers and I think lawyers are really
important for society I think it's
actually security people that need to be
apologizing like I'm a security person
I'm apologizing to all of you it's also
just partly being Canadian so sorry
that's how you know someone's Canadian
you bump into them and if they apologize
to you they're Canadian so we get told
to move fast and break things right this
is like one of the mantras of Silicon
Valley but then this happens it's a
little hard to see the text here but
this is some guy named Khalil posting on
Mark Zuckerberg swall he tried to report
a security bug to Facebook through their
usually excellent bug bounty program you
know they misinterpreted the result
turned down the bug he posted on zoosk
wall and and then we get stuff like this
har plate is a fascinating case study of
the state of security response in the
open source world a researcher at Google
Neil meta found the bug went through
various like proper channels to report
it um you know and it got like shared
with the Linux distros the major cloud
vendors if you really important sites
when you read through a detailed
timeline of the event you start to see
where the information starts to move
around
and there's starting to be like just
enough information out there that other
researchers go poking and some Finnish
researchers found the same bug and then
everyone was like all the cats out of
the bag and the embargo actually broke
so it was released a Monday morning
instead of a Tuesday but I want to go
back even further this is a map of the
world on July fifteenth 2001 this is the
code red worm it exploited a
vulnerability in microsoft iis that
hadn't been patched about a month
previously as bulletin MSO 1033 and the
reason I know those numbers is that I
used to work ten years later I worked on
that team the Microsoft Security
Response Center I handled security
vulnerabilities in windows office
sharepoint skype number of others and
the the thing that was pretty cool there
we had this whole set of policies and
practices in place where we could work
with external people to take in security
vulnerability information we had all
this telemetry where if someone was
using malware in the wild and it would
cause crashes there's a great story in
the notes I'm not going to go into in
detail but really I you would find these
bugs that were being actively exploited
it would show up in telemetry and you'd
be able to reverse engineer what was the
vulnerability that was being that was
being exploited there it was this
methodical ceaseless every second
Tuesday of the month and every once in a
while a second time during the month for
emergency patches process of updating a
billion computers around the world so if
you if you were running windows in 20
2012 I rebooted your computer um and
sorry so in that job I got to work
internally within Microsoft with
developers testers executives PR
everybody coordinating shipping patches
and windows shipping patches in office
and working with the external
researchers who were often reporting
bugs to us and then you know in the best
cases we would take the lessons learned
from those bugs that were reported to us
cycle them back into the development
process and build more secure software
in the future and it's like we do
something pretty similar we have a bug
bounty program we're a pair
we had 177 thousand dollars and bounties
paid out it's we've had hundreds of
researchers around the world report bugs
to us but this is the sistah land after
the fact kind of thing so it makes me
wonder like what does it mean to build
secure software before your shipping it
right Bounty's Security Response all of
this stuff is the cat's already out of
the bag your site's already your sites
already owned your desktop software that
you shipped already has a bug in it what
can we do but before we ship that back
code to make things better so some of
the things that that looks like in a
culture in a in an organization that has
a healthy security culture is you have
developers reaching out to the security
team when they're stuck or unsure about
the implementation of the future you
have developers finding bugs in each
other's code security bugs during the
code review process you have a enough
tooling testing in place that people
feel like they're protected from small
errors or regressions and one of the big
ones one of the big like organizational
smells of a healthy security culture is
you have people saying like fessing up
when they make a mistake about security
reaching out proactively to say oh hey I
pasted that AWS cred in the wrong window
and a slack diem whatever I deleted it
and cycled it already but I just wanted
to let you know also please don't put
your slack your slack tokens on github
makes me really sad has anyone had a
slack token deleted from github it's
been nuked that was posted on github No
okay we nuke them proactively yes yay
excellent so we proactively go out and
and nuke those tokens what we're talking
about here is complexity write the
software that many of you work on is
unimaginably and unknowable complex with
openssl we could blame the like weird
janky export regulations stuff that
people had to do regulatory compliance
stuff but in any sufficiently large code
base you're going to have those weird
dark corners you're going to make
mistakes we're human we make me make
mistakes you're going to introduce
security bug
one model that I like to think about in
thinking about security bugs is and
complex systems it's called the
swiss-cheese model of accident causation
was first proposed by English
psychologist James reason he talks about
the latent hazards in the system the
holes in the cheese and how failure
occurs when those holes line up and and
the error is able to pass through
insecurities and in testing we called
this bug chaining I first learned about
this book this model from the book the
digital dr. hope hype and harm at the
dawn of medicines computer age which I
particularly like because we're not just
at the dawn of medicines computer age
we're really at the dawn of computer
securities age to like where we are all
beginners at this so what can we do
about this right like we have these
complex systems they're error-prone
we're humans we make errors any
different part of your computer system
can fail so how do we get to this like
solid block of cheese that errors cannot
pass through in thinking about your
system you got your components you've
got your tooling you've got the humans
involved you got your underlying
infrastructure data center cloud
somebody else's computer and each one of
those is going to have holes so all that
we can hope to do is make them smaller
make their be fewer of them and make
sure that they don't line up so here are
some of the things that as individuals
anyone here in the audience can do the
first thing is to go looking as a
developer there's a lot that you can do
as an individual to learn to make your
code better from a security perspective
whether it's reading up on the latest
classes of threat on the OS wiki fuzzing
your code with the adorably named
American fuzzy lock it's named after a
bunny rabbit doing some static analysis
reading some books or getting yourself
some some training and security but
fundamentally though it's a mindset
thing you're putting yourself in the
attackers shoes you're saying if I had
control of this input as I'm thinking
through these data flows what kind of
problems could I cause what shenanigans
could I get into and going from there so
back when Vista was under development
everybody's favorite operating system
the powers that be at
kirsov paid a bunch of external
developers a bunch of external security
researchers to do a full code audit of
all of the new code and they actually
ended up slipping the release of Vista
because they've had so many bugs it was
it was a big project but the interesting
part of the story to me is in 2011 I saw
a talk given by one of these testers
named Kristin Padgett her n da had
expired and she's like I'm gonna tell
all I'm gonna spill all the beans it was
great and so the the things that she was
able to develop in doing this massive
massive scale code audit there was no
way that even with the pretty large crew
of security folks they had they couldn't
go through every single line of code so
what they did was they interviewed teams
and they developed a really strong sense
of security smells so secure the
security smells that she talks about
were things like people's body language
whether they seem calm or anxious as
they're talking to security people
confidence or lack of confidence in
describing the functioning of their
component and so as they worked with
these different developers pm's
different folks around the windows
organization they were able to say oh
this is code there there be dragons
there be dragons here we got to dig into
this code and the effectiveness was
shown by just how many bugs they found
so as like a self awareness thing when
you're writing code paying attention to
that gut feeling paying attention to
that like this this this component is
keeping me up at night not ignoring that
and when you have that feeling asking
for help whether it's from your security
team up here doing some additional
research yourself but following those
hunches following that you know
developing that sense of smell for your
own code and if you reach out for help
within your organization and you get
shot down like that's a pretty useful
signal to maybe not a great one but yeah
so the other thing that I love to tell
people about if they haven't heard about
before is capture the flag so there's
all these hacking tournaments that
people put on and I'll have some links
next but it's basically like jeopardy
you style board there's here's the
hundred point reverse engineering
challenge here's the 200 point web web
app hacking challenge and it's a great
time constrained way of learning new
security related skills CTF timed org
has a great directory of them to get a
team going all you really need is some
form of chat room not agnostic to what
kind and any Google Doc I will note that
security is maybe like 10 years behind
the rest of the world when it comes to
like having welcoming environments and
often if like the event has an IRC
Channel it'll be kind of foul it's still
worth it to me but heads up and then
beyond just what individual things
people can do I think it's really
important to think about organizational
processes so more stuff I learned at
Microsoft they have this security
development lifecycle it's this
sophisticated 100 plus procedure thing
compliance thing that people do despite
its complexity there's a lot of really
interesting stuff that people can learn
from it it's all creative commons
licensed and worth checking out but it's
it's gotten me thinking a lot like this
this is great when you're shipping code
when you're shipping windows every two
years when you're shipping office every
two years but it's less feasible for
those of us in the room who ship code
every day or multiple times a day so the
big thing that my sort of the MacGuffin
I've been chasing for a couple of years
at this point is is what does this look
like when you're shipping code multiple
times every day so I've been thinking
what's a Minimum Viable sdl going beyond
this big process to what what anyone can
implement in a small organization and
I've come up with these four things a
risk assessment up front getting people
thinking about what the security posture
of a particular feature they're working
on is doing some threat modeling it
doesn't need to be very formal it just
needs to be I'm thinking through the
data flows of my project up front a
checklist and there's a ton of different
resources you can use to build those
checklists on your own
whether it's the Mozilla secure coding
checklist the OWASP resources or
Microsoft's own SEL taking the parts
from that that makes sense for you and
then having whatever security tooling is
appropriate for for your code base
whether it's in your builder CI process
static or dynamic analysis getting those
tools in place so here's what it looks
like at slack we built a self-service
sdl that any team can go in and create
an STL project for a new feature that
they're working on it's been a team
effort our head of product security it's
my friend Ari and he couldn't be here
but this is this is as much his work as
it is mine but you start talking about
process life cycles that small
organizations and people freak out also
because this is the section where I'm
talking about slack stuff there's a lot
more emojis coming up just heads up you
know your people are like Oh what is
this process I don't want process you're
adding friction you're slowing me down
and so you get this conflict between
security and dev but it doesn't need to
be like that in fact I want it I want it
to be more like this some people may
recognize our bus ads but yeah that's
what I want security to feel like that
is that is it so much to ask so what is
what does that actually look like for us
it's again that initial risk assessment
this is something that the Microsoft
sequel team pioneered and I worked with
them a few years ago and have sort of
carried this with me and that's the
instead of two weeks before your
shipping or like oh gosh I have to do
all of the security stuff it's getting
people thinking about it at the start of
the project and throughout the process
rather than just on that that last
crunch so we have this little quiz that
you do it's only like six questions long
and various answers will dump you
immediately into high risk or you can
just put yourself into high risk by
saying yes or I'm writing sequel
injection
and so the questions are pretty
straightforward and once you've got that
risk rating it's going to generate oh
it's going to go through the component
survey so the component survey allows
people to opt into the the things that
they're doing so if there's no mobile
aspect they uncheck the mobile part of
the checklist so the checklist look like
this super straightforward and you can
uncheck that everything is checked by
default at the top level and you can
check the specific things the sub sub
topics that you need and you can uncheck
the top-level things you don't need but
we encourage people to err on the side
of your not sure about it just leave it
checked because you can move it into the
I don't need to do this column later and
like nobody gets mad or anything so
before i get to checklist this is the
part i talked about plane crashes so any
any fans of the air crash investigation
show in the room uh yeah okay I'm glad
I'm glad I'm not the only one so
checklists are a huge part of aviation
safety and if you want to see really the
thing that is so great about the air
crash investigation show is there's like
terrible things that happen and then
competent humans show up and they
investigate them and they make processes
so they never happen again and that's
why I like air travel is safer than any
other kind of travel pretty much so most
aviation accidents result from human
error and one of those root causes is
often a failure to comply with
checklists but these checklists also
prevent a ton of accidents so when we
were thinking about how we were going to
design this process design these
checklists we wanted to learn from the
human factors stuff of aviation safety
for like why do people avoid checklists
um what could we adapt from that so my
my colleague read the entire 300-page
report from the FAA on human factors in
the use of design of checklists and we
went through that and we're like what
are the parts of this that matter to
security so there were a there was like
act as some fundamental stuff of where
checklists fail it's failing to use the
checklist
failing to verify the settings visually
being interrupted as a big one so some
of the things that we incorporated into
our own process we're oversight of the
completion of the process from the
security team the security team being
involved in being tagged in at different
parts of the process making the tasks as
simple as possible and I'll go over this
a little bit more but they they're
affirmative statements I'm not you yeah
they're all a firm ative statements
rather than I'm not doing the wrong
thing I am doing the right thing so and
then we also have the feedback cycle
from the bug bounty when our checklist
fail we usually hear about it pretty
quickly which is nice and if you don't
feel like reading a 300-page FAA
document I definitely recommend Atul
Gawande is the checklist manifesto for a
more slightly less dry version of a lot
of the same information so here's what I
checklist actually look like first of
all once you've gone through that the
the generator thing it starts generating
some Trello boards takes a little while
and then you get a board of all of your
different checklists for for the
different categories of security things
that you need to deal with then there's
a checklist for adding your Trello board
to slack it's not the most elegant part
of the process but here's what some of
the checklist actually look like so
we've got regular expressions and then
we've got alert and warning messages and
the alert and warning messages stuff is
actually taken from the Microsoft stl
because their guidance was really good
on that one and relevant to what we do
and then we can have like a visual
overview of what's been checked off and
what hasn't and most importantly because
you've connected it to slack we have a
nice little sdl bot that tells people in
your future channel you've connected it
to the feature channel for whatever the
project is we have a lot of feature
channels it's like we have we have a lot
of channels in general like what it's
kind of bad and yeah so here you have a
couple of examples of how what this
looks like so we checked off a checklist
item
and then marries like hey Josh I don't
think we've actually we're not ready to
check that one off can you leave it
unchecked for now and we'll come back to
it or josh is verifying with the rest of
the team that this particular item has
been correctly correctly dealt with
we've disabled DTD parsing yep okay I
can check that one off so there's
there's that sort of your you're
bringing the security stuff to where
people have where people are actually
working and the reason this matters is
that it a lot it moves away from that
one pour tester who has to do the
hundred and twenty items' checklist two
weeks before the launch to a
collaborative enterprise to a
collaborative effort of people working
together to make sure that your shipping
secure code and it also means that as
teams are working on their own getting
through a particular set of checklists
if they're if they're ever like not sure
how to do things they just tag us in so
here the team is asking Maria for help
with a particular UX decision that has
an impact on security Marie Maria brings
in hey here's an example of how a
third-party does it that that would work
well in this case I think and then the
team is like oh yeah that totally fits
our purposes and Maria just pops out
doesn't need to be lurking in that
channel all day and then we're able to
get ongoing feedback about the impact of
this of this process on teams on on the
work that people are doing because we
have the bug bounty because people are
able to just file bugs in the sdl
process itself internally the the rules
are all just JSON files that live in our
github so people can we can accept PRS
often grammar edits from the rest of the
organization and we're able to were able
to move the the secure development
process quickly not just move our
general software development quickly so
that's what we've done as an
organization but then there's also the
question of like what can what are what
are the cultural factors at work so
there's a number of things in terms
the way we we we create cultures that
affect the security of the software that
we produce and holding ourselves those
among us who are leaders and our
organizations which I suspect as many of
you holding ourselves accountable for
the cultures that we create and the
impact on security that it has it's
pretty standard like blameless culture
stuff for any fans of etsy's kotas craft
blog this quote may be familiar but
operating from the position that people
want to be writing secure code is like
that's the starting point right people
people don't want to be the one who
ships the code that has XSS in it so we
need to be able to figure out what what
do what resources do we need to get
people so that they can ship coats ship
secure code well whether it's time
training or external expertise so
workers Center social rules security
teams super often guilty of well
honestly all of them but really like
let's talk about feign surprise right
how didn't you know that that would
cause XSS like da who's heard something
like that from their security team right
it's yeah so if if there's one thing
that I I tell other security people all
the time I like hold that sign up in
their faces and say like don't don't do
that it's not necessary that that piece
of feigning surprise like it just as as
the rules say it has no social or
educational benefit when people feign
surprise it's to make themselves feel
better and other people feel worse it's
about making other people feel smaller
and that's not how you build a safe
culture that's not how you write secure
software fundamentally writing secure
software requires a level of emotional
safety I've often had the experience of
trying to talk to a security person
feeling kind of like trying to pet that
cap and I say that as a security person
so there's this idea of emotional labor
that it is actually work to give gentle
feedback to be kind in the feedback that
you're giving to other people
it is also emotional labor to be
receiving feedback to be open to hearing
that maybe your baby is ugly and but
this isn't this isn't just like this
isn't just pie in the sky like let's
let's all get along and write secure
software it's actually supported by some
of the social science research into code
quality and when it comes down to it
writing secure code is writing quality
code and writing quality code is writing
secure code so if we are kind in the
feedback that we give we are building a
culture where it is safe to say I don't
know what I'm doing here and when people
are able to say I don't know what I'm
doing they get help and then the code
that they write is better and that
includes security yeah nobody likes
being nobody likes their baby being
called ugly but we need to establish to
reestablish that trust as security
people because people need to be able to
hear if their baby's car seat isn't
plugged in or the seatbelt is frayed as
otherwise disaster so being able to
create a culture where you don't get
torn down for saying I don't know how to
prevent XSS in this this particular code
path there's there's a lot of work to be
done on the security side of things to
rebuild that trust so coming back to the
digital doctor I really like this quote
because it cuts to the core of why we
need to be able to have trust in each
other to do security we need to be able
to talk compassionately about the ugly
parts of our code if we have any hope
whatsoever of it being secure and I
talked a lot faster than I expected but
again there are slides available and
yeah thank you very much for listening
to me talk about secure software</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>