<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Aggregator: MapReduce in the type system&quot; by Dan Frank | Coder Coacher - Coaching Coders</title><meta content="&quot;Aggregator: MapReduce in the type system&quot; by Dan Frank - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Aggregator: MapReduce in the type system&quot; by Dan Frank</b></h2><h5 class="post__date">2015-09-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2ndQ6DGRnJA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm Dan I'm going to be talking about
aggregator MapReduce in the type system
so before we kind of dive into that I
need to say a couple words about right
that's where I work and that's because
we're going to be using that for a lot
of examples today and I'll help motivate
some of this work so stripe if you're
not familiar we we fancy ourselves the
easiest way for businesses to accept
payments online this is primarily credit
card payments and we kind of present
them with a couple nice integrations and
the idea is that we smooth smooth over
some of the rough edges of kind of
dealing with financial integrations and
that you shouldn't need to be like a an
expert in payments to start a business
online so I bring this up because like I
said we're going to be using a lot of
examples from kind of a stripe data
domain so you know typically the kind of
the big units of data and the stripe
ecosystems or things like cards and
users and customers and transactions I
might refer to transactions as charges
or customers as merchants or something
like that but you get you get the
picture the kind of lowest level data
point is like a transaction or charge
happened and so data analysis that
stripe in particular kind of has a
couple of applications you know we could
be doing there's a lot of kind of
general purpose analytics for kind of
informing you know what what features we
you know are getting you set of what we
aren't you know any amount of product
development or business analysis
additionally a lot of the data analysis
that we do goes towards up preventing
and predicting fraud so that's what
we're going to do today is we're kind of
going to work up to using the aggregator
on these kind of units of data and show
how that gets used as a fraud signal for
us anyway on to today's topic map
producing the type system so what do I
talk about what am I talking about when
i talk about MapReduce so I'd like to
zoom out a little bit on this point I'd
say that kind of a lot of forms of data
analysis kind of take this general
picture where you're kind of going from
raw data you've got like some crap that
happened that you know about and you
want to turn that into statements about
properties that you care about so in
this case we were starting with a bunch
of colored squares and what we are
working towards is the statement that
like there are four orange yellow
squares there are two green yup or yeah
something like that you see what I'm
saying we're kind of going from just
kind of
statements that happened to or rather
facts that happened to statements about
properties that we're interested in and
that's kind of like the whole point of
data analysis there you know you start
with facts you wind up with statements
and you can think of this sort of as
reducing the dimension of the data as
well you know I visually laid it out
like that but you know you typically
kind of talk about data in terms of rows
and columns you have a number of things
that happened and they have a number of
attributes and we're kind of trying to
shrink down that space to maybe just
kind of like a list of quantities that
we care about presumably indexed by some
attributes it's possible that you could
want to reduce that even further you
might want to go from this kind of list
of the counts of these colors to saying
you know what what color occurs the most
you know what's the average occurrence
stuff like that in that case you kind of
get down to a single number representing
your whole data set that's like a zero
dimensional representation of things and
I'd say that this kind of dimensionality
reduction can can pop up in areas where
you wouldn't necessarily expect it or
what you wouldn't think of as data
analysis necessarily so consider if
you're trying to rank comments you know
assume that our data points in this case
are like up votes and down votes on
comments and you kind of go through a
similar process where you kind of
organize things up and you decide you
want to kind of come up with some
ordering of the comments and that
amounts to kind of producing some scalar
kind of quantified statement about each
one and by the way as far as this
problem goes there's been like plenty of
ink spilled on the bright way to you
know rank things relative to up votes
and down votes I'm sure you can think of
several ways to do it but anyway back to
that first example this kind of basic
thing so we're going to go from here
which in case it wasn't clear this is uh
in case I didn't say it this is kind of
counting how much each color appears so
I'd like to kind of move us on to the
equivalent in the stripe domain so let's
say we were asking for all of our
merchants how many charges has each one
made and I've just kind of tossed up an
implementation in sequel that would more
or less work and so let's step through
you know how this have we organized this
you know we've kind of we're specifying
like that we want to do some grouping
and we're specifying kind of how we want
to you know kind of our groups it's
pretty simple there's not a lot going on
there
you know the one thing I might call out
though is that we're not at any point
specifying how we want to do this we're
just kind of specifying what we want to
happen and it happens I think Peter
talked about stuff like that yesterday
so zooming in in particular going from
this just kind of focus on where we
start and what results we want let's
kind of examine like mapreduce
specifically so that kind of that starts
to inform a little bit more the
mechanics of how this stuff happens so
now you kind of laid it out specifically
as okay MapReduce has these two phases
you know you go from your kind of
unstructured massive data points and you
group things up based on these
attributes that you're interested in and
then you have some way of reducing down
those groups and that reduces you know
meant to be kind of the the same ideas
like the functional programming concept
of reduce you know you kind of like have
this list and you have some way of
chunking things down and so the
programmer is expected to fill in a
couple of blanks here one of which is
you know given a data point what group
does it belong to and given a group of
data points how do I reduce those down
that that's kind of the API are given
for doing that sort of thing but you
know again this is this is just kind of
like a way to accomplish like I said was
a pretty general goal for us and some
you know just in case people don't have
the pleasure of working with this day to
day you know I just kind of want to take
a peek at what this API like formally
looks like especially in like the Hadoop
context there's a lot of characters
there a lot of kind of parametrization I
wouldn't focus too much on this other
than to point out that the API are given
for what I just described which is
breaking things up into groups and
reducing them down two groups kind of
amounts to this like okay given a data
point admit like a kv-2 bowl and given
then like in your reduced given a key
and a sequence of data points you know
Amit two more tuples it's always framed
in this like kv pairs that you're
sending out and stuff ok so so let's
look at that same computation that we
were doing before this how many charges
per merchant and kind of sketch it out
as a MapReduce job so you know let's say
your incoming data you've got your data
point and you're going to extract the
merchant like I said and you're going to
say ok well ok so there was one here and
then when you reduce things you've got
your keys your merchant again
you're going to be summing your values
so I think it's interesting to reflect
on how this differs from the the sequel
that we were doing before there's a
couple of things that are happening
differently you know this this feels
very much more like telling the telling
the program what to do than what you
want to happen if that makes any sense
you know a little bit more imperative
here and it's also kind of it's very
intimately tied to knowing how the
platform is going to work like if you
just looked at this in isolation it
wouldn't be clear what it was going to
do you have to build them this knowledge
of what the platform is going to do for
you so speaking of which what is the
kind of MapReduce platform that i'm
referring to why do people get excited
about this the idea is that those phases
that I described before are pretty easy
to split among multiple machines so it's
something that kind of admits itself
well to parallelization both the kind of
I won the send data points out two
groups and I want to reduce groups down
those are both things you can kind of
stick on your emoji computers as you
like so you know it kind of decomposes
the problem a bit that's a little bit
nice and that there's some amount of
heavy lifting of sorting these groups
around the platform does for you and the
idea is that you the application
developer just need to kind of focus on
filling in the blanks there and it can
do the rest for you but the assertion
I'm making today is that I don't think
is this is like the decomposition that
we as developers really want or at least
it's not the one that I want in
particular this is a decomposition that
favors this particular implementation in
this particular like execution
environment right like this is you were
decomposing it in a way that makes it
easy to kind of parallel eyes and run it
at scale or whatever but it doesn't
really kind of optimized for expressing
the computations that we want so that's
what we're going to get to so what I
mean is that kind of in this in this
phase we typically you know we've got
our kind of reduce operation we want to
count things up and we we somehow kind
of bleed our logic into both of these
phases where you know for any
computation that we're trying to do we
kind of split what we're saying between
these two phases and it makes it kind of
hard to build on things to refactor
things or combine them you know given
this data point we've now decided that
you know the only information we care
about it is that it's orange and that
there was one of it but when you want to
kind of start doing more you know more
powerful things that you need to kind of
go back
can revise this as your mat phase let's
say so what are the kind of real
components that I think we should break
this down into I think that you know
this this kind of general paradigm
luggage it certainly works but i think
that rather than kind of talk about
those map and reduce operations what we
probably want to talk about as far as
expressing these computations goes is
we've got the two phases which is kind
of well what I've been saying in English
group the data points by you know the
entities of interest in our case it's
been like the merchant and the stripe
domain or those are the color and the
kind of colored squares and then given
the sequence of data points reduce them
down so I specifically mean that as
opposed to like omit key value pairs
okay so at this point i will say that we
are going to kind of take a turn which
is that i'm going to talk only about the
second point from here on it be kind of
the first point is like not that
interesting to me it's pretty easy you
know you get a data point you kind of
assign some key to it may be more than
one key but i think there's a lot more
kind of breath that we can explore in
the second point this reducing operation
so what am i getting into when i say
that there's there's like a lot of kind
of depth in this reduced so with the
counting that was pretty kind of that
obvious you know it was just how do you
come things in this case though if you
look at this as kind of an example data
set it's not it's not entirely clear
what this is supposed to reduce down to
and that's you know kind of
representative of the real world a lot
of your data points are multifaceted and
you want to do more than just count how
many of them there are so what am I
trying to say about this maybe I want to
say how many distinct shapes were there
is there's three there or maybe I want
to ask what the kind of mode appearance
of shapes is there's two or maybe I'm
not even interested in the shape
specifically maybe some of them have
these these kind of outlines and I want
to count those so we're going to be
exploring stuff like that where there's
you know there's a number of ways given
a sequence of data points that you might
want to reduce it down and that's what I
aggregator lets you do so a top back to
an example in the Striped domain we're
going to be sticking with this example
for a while so probably that's to get
your head around it now
so let's say I want to say not just how
many charges has a merchant had how many
different cards have they seen this is
kind of a proxy for how many customers
do they have or whatever so again kind
of looking at this in sequel it looks
pretty much the same as what we did
before except instead of our count star
there we've got this count distinct card
now so I think this is um I think this
is kind of neat this kind of reflects
what we were saying before in that you
know the grouping phase is still the
same and we've just kind of had to edit
our you know reducing our combining
phase to make this work out and again
we're not telling sequel how we want to
compute this we're just telling it what
we want computed and trust that it can
figure it out so uh you know just for
contrast let's look again in my little
phone MapReduce how that would look so
notice now that we've kind of you know
we're again extracting the merchant as
we were before but our map phase now you
know previously we were kind of emitting
a one because that was all we cared
about and now we need to know that we
need to admit this card and I know that
because I know that I'm going to have to
kind of get the distinct values later so
I'm kind of doing this thing where I've
had to you know knowing what I need to
do in the reduce phase that had to go
back and change my map phase and that
you know if you're kind of working in
this that'll be kind of like a daily
familiarity and it's really just it's
not that fun to have to kind of jump
between those two so specifically I
think we can do better at expressing
these computations and so it's time to
introduce aggregator so aggregator is a
scala trait in algebra algebra Isaiah is
a library that Twitter's released their
tagline is abstract algebra for Scala
it's available on github it's been there
for a while and so the idea with
aggregator is to use types is too well
the idea is to express exactly these
kinds of computations these kind of
MapReduce and then map operations and we
use kind of types along the way to kind
of guide how these can be composed and
how they can be reused and the idea is
that it'll it's going to express a lot
of different things that we might want
to do when we reducing down data
certainly more than sequel can get us
but you know using these things it's
easy to use them as building blocks
addition
Lee it's not so much tied to being
executed like as a Hadoop job or
whatever you kind of you'll be
expressing how to do these computations
without necessarily specifying a
particular execution platform will talk
about about why that's important in a
bit okay so sticking with our previous
example how many cards were there /
merchant I'm going to start getting into
like some pseudo Scala syntax here so
you know the typical the general shape
of this is that we have a sequence of
charges that have happened and at the
end we want to get out an answer that's
like an integer how many different cards
were there among those charges so again
this is kind of just that reduce phase
so if you recall how we did this though
we're not actually really just kind of
hopping from the charges to the integer
along the way we have this thing that we
had to accumulate and so I want to
introduce the what I'll be calling a
computation type from here in it which
is that in between there's this kind of
running total that we need to maintain
and in our case it's it's going to be a
set of cards and you know in some
computations you don't really need to
think about that if you're just counting
things than you're you know you
accumulate account along the way and
then at the end that's your answer in
this case for many computations you've
got something that you want to
accumulate along the way before
presenting an answer and and yes I know
that's not Scala syntax for much of
anything so you know let's let's look at
an example here that's kind of using
this sort of computation type just in a
pure scala collections way and then what
will kind of get to the real stuff after
that so if I've got this kind of if I've
got this list here as I was saying
before if I'm just counting things then
I can just kind of you know take every
every item that I'm interested in and
say okay that's a one and I'll add them
up and that's my answer right there I've
been kind of using this reduced
structure with which has this
accumulator thing but that's just my
answer whereas if I want to get you know
distinct elements well I've got this set
accumulator that I create here but then
notice at the end that to get the answer
I want I need to call this dot size at
the end so there's a bit of a
distinction there so let's look at how
aggregator treats this so an aggregator
is it's this trait and it's got three
type parameters so
for those who don't kind of work with
Scott all the time the ideas that you
can kind of you can put together one of
these structures be it a class or a
trade or whatever that kind of operate
saan some things of other types and you
can implement it while being somewhat
generic to those other types I recognize
if you're a goal-line programmer this
might be slightly mind blowing but bear
with me so aggregator kind will have
these three types there's uh there's
there's this a type which is the input
type there's the B type which is that
computation that we were describing and
the c-type is going to be the output and
so these traits traits are kind of like
somewhere between an abstract class and
an interface in java de la they'll emit
some things from being implemented and
then give you some other things for free
so in this case the few things that we
want to implement our we've got a
prepare operation which given our input
type will kind of get us call it like a
singleton member of the computation type
something like that we just need to go
from like the input to what it is that
we want to add up we're going to have
this reduce method I'm actually kind of
taking a shortcut from the from the real
API here but we'll refer to the reduced
method it's going to take two members of
the computation type and combine them as
an aside if you're into the sort of
thing the reduce you want that to be
associative you need that to be
associated for to do much of any good
but we won't really delve into that and
then present is going to say okay given
given you know a computation that we've
had running what's the answer that we
want out of that so it's kind of a lot
of words you know will we can visually
look at it like this and maybe this
doesn't do you much good but we're going
to build on this diagram so you know you
kind of take a in and you add up these
elements of B you eventually get c out
so let's return to our example and see
how we would kind of implement those
three methods in the case we were
describing before so let's say we wanted
to do look a merchant card count again
this is the you know set of distinct
cards that appear with a merchant so
notice I filled in what those what those
a B and C types are here our input is
going to be the charge notice it's like
a single charge the input is just the
type of one data point the computation
type is going to be a set of cards
as we were saying that's what we need to
accumulate and the output and I wrote
long but you know some quantity and
these are pretty simple you know you
kind of you make the singleton set like
I said as your preparer that's us going
from our input type to something that we
want to add up you've got your reduces
just kind of the union of two sets and
your present is the size just as we are
describing before so you know it might
be worth taking a second to reflect and
compare this to you know the other ways
there's like a couple of other ways that
we've already implemented the same
computation notice how we're decomposing
it into these pieces but we're not
really making any assumptions about how
that well where they were not terribly
tied to a particular execution platform
here we've kind of described everything
that needs to be done but not quite how
it fits together it's also somewhere i
would say sitting between the kind of
MapReduce and sequel forums and that
we're describing what needs to be done
we're kind of we're certainly saying it
in code but we're not really saying when
in what order so I don't know it's just
kind of an observation so at this point
you're looking at this and this is
definitely the most verbose way to
describe that computation so far and you
may well be unconvinced that this is
going to do you any good so let's kind
of explore what more we can do with
aggregators so in particular I'd like to
talk about how you can compose them how
you can kind of reuse them that way and
the standard library of aggregators that
you can draw from then I'm going to talk
about kind of different you know
patterns for executing them whether it's
a MapReduce context or or elsewhere and
finally I'm going to kind of talk about
it in an example of fraud prevention
that's right and in the course of this I
will eventually get to why I keep going
on about separating the kind of
definition of this job from how it's
executed so when I talk about leveraging
the standard library like I said that
previous example was you know kind of
ridiculously verbose and it turns out
that you know if you kind of zoom in at
this kind of computation type as sort of
the core part of the aggregator there's
not that many of these computations that
were typically interested in there's
like a lot of pretty common ways that we
want to roll these things up when you
kind of get down to the very core of it
and a lot of these kind of come bundled
for us and so we don't you know we can
kind
of just drawing them right away so if we
want to kind of take the unique kind of
elements then that's um you know that's
pretty easy that's right there if we
want the size of elements the median
whatever things like that and so it's
nice there is that you know because
we've got this kind of relatively fixed
set of things that we're probably
interested in you know a lot of these
have been implemented for us already and
because we've kind of decomposed that
you know we've kind of separated out
this computation type from your inputs
and your desired output you can do that
with that knowledge of you know my
application that I want to do for stripe
or what somebody at Twitter wants to do
we can kind of share the underlying
computation so you know I'll just point
out that if we do this structure here
I've kind of given you our three types
that leaves us with you know we're going
to be inputting a card notice not a
charge and will again be kind of
aggregating a set of cards and be left
with with an integer the answer so okay
we haven't quite gotten to to kind of
you know re implementing our example yet
because our input type is different so
aggregator gives you something to work
with that so we've got this this
function called composed prepare so this
is available on all aggregators if you
have an instance of an aggregator that's
what you know unique count is an
instance of one of them you can call
compose prepare with another function
and get a new aggregator that's got that
prepare operations stuck on the front so
in this case this is telling us how to
get from a charge to a card and we kind
of just run that prepare before any
other aggregator operations and now
we're left with the type signature that
we want so I've got a little diagram
kind of referring back to our previous
visual language you know we started with
this thing that took a card and
aggregated a set of cards and you could
think of compose prepare as I'm kind of
sticking this thing around it where you
now have charges your input but it's
still using the other aggregator under
the hood and at the end you're left with
another aggregator so that's kind of
nice this this is what helps you kind of
take these pre-built aggregators that
exist and map them to you know your
domain so has anybody else been uh been
kind of has anything been nagging
anybody about this example so
far you know like if you're doing this
kind of computation where you want to
maintain these sets you know along the
way if you're doing this in like a
Hadoop context or something and you do
this in your day job you've likely
encountered a case where that set is
going to kind of grow in memory to a
point where where that starts to be
untenable for some of your larger
customers so what people will sometimes
do in this case is say okay you know
beyond a certain point I don't care
about the exact answer and there's
there's you know out there in the world
there's these approximate data
structures that allow you to get kind of
an estimation of the answer in the fixed
space of memory so I won't get into it
too much but algebra it has a lot of
those implemented and what's nice here
is that we can very quickly swap that
out so this is you know this is where
you're starting to really see the
benefits here is that we kind of had
this this general way of computing set
sizes and now we can kind of swap in for
it something that computes set sizes in
a kind of approximate way using a fixed
memory footprint and that that one that
I'm actually quoting there will kind of
give you the exact answer up until some
minimum size and then drop down to the
approximate thing it's pretty much just
what you want so yeah that's really nice
you know that's where you start to
really reap the benefits here is that
algebra it has like a wealth of these
kind of approximate or otherwise kind of
difficult computations that you can make
use of so here's a list of some of them
I won't go into too much detail but this
is just kind of a feel of some of the
things that it offers for you so now
let's kind of talk about different ways
that you can kind of actually use these
you'll note that I've yet to call any of
these methods really so how you know how
does one actually put this to use so
first off the kind of simplest way is
that any of these aggregators has an
apply method which will just take a
sequence of inputs and give you the
answer at the end and that's just kind
of doing your your all your computation
in one fell swoop and that can be pretty
useful so as an example just to show us
that we can kind of get back to where we
started at least here's kind of a
MapReduce like fully Hadoop style thing
implemented with aggregator so remember
I've got that key function that I told
you I don't care about and then our
reduce phase just becomes applying the
aggregator to our values so we went to
almost too much but that's kind of the
simplest way that you could execute one
of
days if you've kind of rolled up all
your computation in there so there's
other ways that you can do it though in
particular you can imagine kind of as
you take in data points at each you know
at each data point that you get you
continue to update your running total
and you can ask for the answer at any
point along the way there and so that's
really nice if you're kind of looking at
it in more of streaming context which
we'll do in just a second and you know
this sort of thing is trivial if you're
just kind of doing raw counters but when
you start to do stuff like set sizes and
whatnot you know it really helps to kind
of expose what that sort of underlying
computational type is and that's very
natural with aggregators so having seen
this stuff I'd like to move us on to
talking about fraud prevention that's
right so in particular we're going to
talk about a problem that we call
merchant fraud so this is um this is a
space where we're trying to classify the
case where merchants themselves are bad
actors so somebody could they'll sign up
and they'll kind of run a bunch of
stolen credit cards against us that's
not terribly exciting but totally
insidious and so we can we can try to
detect this activity by looking at what
they're doing when they kind of make an
account with us I'm looking at the
charges made on their account so I you
know kind of glance through how this is
going to wind up working we're going to
have like a predictive model and just as
a kind of you know crash course and that
sort of thing the way this will
generally work is that we're going to
we're going to you know come up with
some features these are attributes of
the merchant that we're interested in
and we're going to combine them by
assigning weights to them and summing
them up let's say that's just one way to
do it if you're really in the aggregator
mindset you'd notice that combining
these features could probably be
expressed as an aggregator as well but
we won't really go there so let's talk
about what these features could be
there's a couple of kinds of features
that we typically refer to when we work
on this stuff that's right we talk about
static features which are like where was
the merchant when they signed up for
this account or what time of day was it
and that stuff's pretty easy you just
store it once you look at
we also have these things that we call
dynamic features and these are kind of
based on historical kind of measurements
that we've taken so like for emergent
what's their average charge amount or
how many cards if they worked with stuff
like that that classic thing winds up
being a lot more helpful for us I guess
it's just harder for merchants to for
fraudsters to fake or whatnot but so
yeah you know additionally there a
little bit harder to compute so most of
these kind of have the shape of those
aggregates that we've been describing
earlier and that we've kind of reduced
down some past activity to some
statement about what the merchant has
been up to okay so so that's all well
and good and remember as I was saying
before when we want to make a prediction
we want to kind of get all these
features available and combine them so
that means that for these kinds of
computations we want to have those
available to us at prediction time so
let's talk about what it would look like
to assemble one of these features the
real one so let's say that we're
interested in the number of
international cards that the merchant is
used so I'm going to like kind of not
get into that top one but let's just say
that given a charge we can kind of
optionally you know come up with the
card that was used if it was
international so we can pretty quickly
hop using what we've done before and
there's some kind of magic and here to
make it work with options and we can
kind of hop into saying okay well this
is going to be you know given emergence
charges this is kind of the number of
international cards that they've used
and that that's pretty you know easy to
do once we've got this set size stuff at
our disposal but you know we may look at
that and evaluate it and decide that
what we actually wanted wasn't just the
total number but but that number as a
fraction of all the cards they've seen
because you know this might work
differently on different sized merchants
so it turns out we can do that rather
easily as well so I want to highlight
this from two method so this is an
interesting thing that aggregators get
you it's a little bit like that composed
prepare that I showed you if you have
two aggregators that have the same input
type you can produce a new aggregator
that does both of the computations and
gives you both of the answers so their
computation types are you know they can
be separate their output types can be
set
so let's look at that in our visual
language again now just in this case it
happens to be that they're kind of both
the exact same type but you know really
what we want to focus on is having the
same input type and you can imagine this
kind of from to this joining is putting
a structure like this around it where
you now kind of have your input is just
the charge and it's going to go through
both of these computations and that's
still a single aggregator so that you
know that gets us you know we're doing
okay remember our example is that we've
kind of got the international cards and
the total cards that were computing but
we don't kind of want those two integers
that's an answer we want the ratio so
aggregator lets us do that as well we
have this and then present method which
you know you tack on somewhat like
composed prepare give it an aggregator
you kind of give it another function
that's like an extra presentation step
and this as you can see especially comes
in handy when you've kind of got
multiple aggregators going on where you
have some something that you know you
want to do with two of them so in this
case we've now noticed that we've kind
of changed our output type to a double
so we're taking the ratio there and so
again visually let's see if we can have
a look at this for whatever reason these
diagrams are like making my computer
like go into a panic attack but anyway
here we go we've got one of these things
and if you imagine laying on compose
prepare this is just going to be us
putting on this extra step but again at
all stages here we still have an
aggregator each time we call one of
these compose presents or compose
prepare and then present stuff like that
still aggregators all the way down and
that's important because we can continue
doing this we can continue building this
up you know that was just one feature
that I showed you we had that ratio of
international cards but you can imagine
that we might want to do the same thing
for prepaid cards we can build up that
aggregator the same way and compose the
two of them and in this way we have one
aggregator that's now computing both of
these features and what's really nice
there is that we can just kind of throw
that into one job and let that all run
if you're trying to do this with kind of
your MapReduce jobs and your map and
your reduce phase it can become quite a
pain to kind of make them all work at
the same time
and then I've kind of tacked on that
maybe you'll want to kind of present it
as JSON depending on who's using it you
know all that stuff is pretty easy and
you know that that is how we express
these features by the way so that's all
well and good our problem here though is
that typically when you'd want to run
something like this you kind of want to
roll up all this activity and you might
do it in a nightly batch job and for us
unfortunately our kind of our assailants
don't really cooperate with that
execution scheduled and you know we need
to be able to kind of have these
computations ready faster because we we
need to make these determinations much
more frequently and like I said when we
want to make these predictions what we
have to do is have all of these feature
computations ready so let's see what we
can do there so at this point what we
start using is Twitter's summing bird
package so may be familiar to some of
you but what this allows you to do is
run MapReduce like code you kind of
write your application code once and
it's able to formulate that as either a
storm topology for kind of a real-time
streaming effect or a Hadoop job it also
gives you the facilities to take the
outputs of both of those and combine
them into one answer and this is a very
nice fit with algebra and aggregator
where it lets you do this sort of thing
with these very complex calculations you
know people have been doing hybrid batch
systems for quite a while but you
typically rely on some properties of
your database or something to kind of
have results that you can recombine this
lets us kind of push that into the
application layer or we can do these
more powerful computations so let's uh
let's look at how this looks so you know
we're hopping back to our aggregator
types here again you can imagine we have
a sort of input that's a sequence of
data points of our type a or input type
and then we fork that off we send it to
our real-time layer and we send it to
our batch layer and they're both going
to run their computations and what
they're going to do is they're going to
kind of do that prepare and they're
going to kind of reduce things down and
they'll be storing their computation
type in their respective databases
finally when a query comes in we
query for both the real-time results and
the batch results and since we know how
to combine results by a reduce operation
we can merge those together and then
present it as our output type C so from
the outside all we see is that we have
the input type that we want and the
output type that we want but in order to
be able to recombine these and do these
incremental combination or yet these
incremental computations it's pretty
necessary that we've elevated that
computation type to a first class
citizen and know how to operate with
that and that's you know that's one of
the great things that aggregator buys
you and so you know this this general
shape this is how we kind of have this
fraud application running where we've
got all of our features available in
real time okay so it's not clear the
ideas that we're pre computing all the
feature values and then we can query for
them whenever we want so that's um
that's that's basically what i have here
so as a recap you know we've kind of we
started by talking about kind of
reduction in MapReduce as being kind of
at the heart of a lot of data analysis
problems that a lot of a lot of problems
that we're trying to do with large data
sets are to reduce the dimension somehow
then we went through how aggregator will
kind of define that reduction you know
within its types and how it lets you you
know express that pretty pretty flexibly
how you can compose and decompose
aggregators to reuse them well notice
that a lot of that stuff that we
described before is made possible by you
controlling when you call each different
phase and finally we talked about how it
being kind of independent from an
execution platform allows you to do
flexible deployments like this kind of
batch hybrid thing so like I said that
is very much how we think about these
computations and I will be more onerous
than I usually am with a sort of thing
like this is frankly a pretty fun way to
express these kinds of aggregates so if
you want to prevent criminals from
stealing money by doing magic with math
and computers then you know you should
give us a look and looks like I've got a
few minutes for questions but uh thanks
very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>