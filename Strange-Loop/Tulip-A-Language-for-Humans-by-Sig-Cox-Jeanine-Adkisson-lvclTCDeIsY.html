<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Tulip: A Language for Humans&quot; by Sig Cox, Jeanine Adkisson | Coder Coacher - Coaching Coders</title><meta content="&quot;Tulip: A Language for Humans&quot; by Sig Cox, Jeanine Adkisson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Tulip: A Language for Humans&quot; by Sig Cox, Jeanine Adkisson</b></h2><h5 class="post__date">2016-09-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lvclTCDeIsY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Janine and this is sig and
we're here to talk to you about tulip
which is our work-in-progress
general-purpose scripting language that
that we have so this is how you can find
us on the internet there's our URL for
getting started and learning about tulip
um whenever I tell somebody that I'm
making a general-purpose scripting
language I get a little bit of side-eye
because there are a lot of
general-purpose scripting languages and
and many of us have our gripes about
them but I think tulip is special and I
think we are ready for a new
general-purpose scripting language and I
want to convince you that we are and
that tulip is a good candidate to be it
so what makes tulip special first of all
the design focus that we've had we've
done a lot of very intensive design
before we even started doing an
implementation which is not often what
you see in scripting languages we have
studied a lot of prior art and tried to
make better decisions than were made in
the past and learn from the mistakes of
people who come before us every feature
I'm going to talk to you about today is
the result of a very conscious trade-off
and a lot of thought I could probably
talk your ear off for an hour or more
about every a little bit and we're in a
particular niche that is not very well
served by programming languages right
now and that is allowing humans to do
powerful things on a repple interface
the only languages that are good at that
right now are shells and they don't have
the kind of features you would want for
large programs tulip ships with
batteries included we recognize that
there are a lot of language features
that have to be language features and
that can't be libraries including
concurrency tail calls and a number of
things and because we don't make you
implement this stuff for yourself this
is stuff that you would always have to
implement if we didn't ship it we can
make it fast and not slow and sig will
talk about exactly how fast we mean the
trade-off is that tulip has a lot of
features and so it has kind of a larger
surface area of things to learn
but I think that's a good trade-off
because you would have to do that anyway
in in a language where you build stuff
up yourself we recognize that if you're
gonna start a language these days you
have to be very intentional about the
community around the language I'm really
sick of having languages that are you
know where eventually you have some sis
white men who are you know the people
who started the language and established
the culture so that we're doing a couple
of things tulip is one of the languages
to come out of the emerging languages
networks neck which is sort of intended
to be kind of a cultural bubble within
functional programming we're not perfect
uh
we're not immune from a lot of the
influences around us but we try to be
not your usual hacker culture and just a
little bit better
tulip itself is unapologetically femme
if you are working on or in tulip you
should expect to be interacting with
women who probably know more than you
about tulip our branding is very femme
our core team is all women and the
intention is that the act of doing
distributed systems programming or
embedded programming or any kind of
programming and tulip is women's work
and if you don't like this you can use
another language and that's fine our
core team includes the two of us here me
Jeanine
I did the design and I'm writing the
compiler front-end cig did our runtime
design was writing our LLVM backend and
Lexie lambda who is right here also
known as Alexis King if you go see her
racket contact she will tell you about
her racket implementation of tulip and
the macro system is very influenced by
some conversations I had with her
although if anything is broken or wrong
it's my fault and not hers and
importantly what we've done is we've
taken an untyped scripting language and
eliminated nil which is rather unique
and the only other popular language that
has done this to my knowledge is Erlang
so I'll get into what that means and how
we eliminate that large headache in a
minute so today I'm going to give you a
tour of tulip I will give you a tour of
the front end and the design and cig
will give you a tour of the back end and
the runtime first I'm going to show you
some pretty pictures we're not going to
go into too much depth just I want you
to see what it kind of looks like and
kind of get excited about how pretty it
is I'm gonna tell you about the core
language and some of our organ onic
features I'm gonna talk to you about nil
for a little bit and then I'm going to
tell you about what kind of abstraction
tools that we ship with and then I'm
going to hand it to sig to talk about
the runtime
okay so first in pretty pictures here's
a pretty picture look how pretty it is
oh I'm cropping off the left side aren't
I well this is a tulip module here I can
just oh nice okay this is a tulip module
that implements a mutable ref using an
Erlang style looping server to hold the
state sig is actually gonna go into a
little bit more detail on this example
but for now just it was pretty here we
have another pretty picture where we
have a module that implements a lazy
list of all prime numbers so we can do
very sort of functional value oriented
semantics as well as kind of
process-oriented
imperative kind of semantics and we
support both although the functional
value oriented stuff is more convenient
so you will probably end up using it
more okay so what kind of language is
tool it
we are not tight checked there is no
type checker which means the trade-off
there being we have runtime errors we
have nice ways of handling those runtime
errors though it's a mutation
discouraged language I used to say that
it was pure but it actually has side
effects but all those side effects are
reified in message passing between
processes so we have side effects and if
you want mutable semantics you need to
use explicit refs just as you would in
Erlang our closure
we're a garbage-collected language we're
what I call homo iconic enough in that
we have the kind of good parts of being
homo a conic without some of the bad
parts we are a pattern matching language
so you're you're sort of expected way of
doing branching and inspecting your data
structures is through patterns which are
a core part of the language and it is a
process oriented language in that you
there's concurrency baked in at the at
the very beginning through message
passing processes and sig we'll talk
more about those so basic syntax these
are variable names that use dashes
because I think they're pretty and
comments are hashes as should be
familiar here's a basic expression here
we're multiplying four and five and then
adding three I want you to notice two
things one is function calls are like
Haskell or ml where you just put stuff
next to each other and that's a function
call and you use parentheses to group
stuff the second is that we're using
words to do math and this is very
intentional Tulip does not have in fix
math and the reason for that is there
are a couple of things but most of the
time when you do math you're probably
going to be doing it in a higher-order
level and you're going to using these as
first order functions and not having to
deal with weird parsing rules around in
fix stuff is is very convenient they're
just regular functions that add and
multiply stuff so tulip has no in fixed
math but we do have one infix operator
in the whole language and it's very
important and it's pronounced either
into or then it's this little greater
than symbol here when I used to work in
in ops we called it AGA's into Edison
this goes into that
but instead of scent of piping a command
into a file or a command into another
command
we're piping a value into a function so
you have a value and then you apply
function and then you apply another
function and then you apply another
function so a function composition is
very very natural and to load it and it
reads from left to right and you compose
it from left to right as you would be
typing on a repla
okay so lambdas are also a thing that we
have it's a functional programming
language they're just square brackets
with an arrow that separates the
argument body here we're mapping a
function that adds three to a thing over
a vector I'll talk about that vector
literal syntax later it's a macro but
for now this there's a slightly more
idiomatic way to do this which is in
tulip you usually start with the data
and then apply functions to it similarly
to how you would do it in a shell so we
start with the vector and then apply map
to it and here we're only passing map
one argument in which means it becomes a
function that expects its last argument
we're also using quick lambda syntax
here so there's no arrow in that lambda
instead we're using dollar sign for the
variable we can actually do one better
with our Auto Curry functionality and
just use add three and when you provide
less than the expected number of
arguments to a function you just get a
partially applied function that expects
the rest of their arguments so here add
three years just a function that adds
three to a thing so all of these are
equivalent but the bottom I would say is
the most kind of idiomatic and certainly
the easiest to type we got some nice
literals we got traditional double
quoted strings
we've got simple strings which kind of
look like Lisp symbols but are actually
just strings they refer when you're
using strings in a kind of a token e way
we've got two poles we've got red x's
vectors and maps at the bottom again
those are all macros and I will explain
what how those work but we use macros
for a number of kinds of literals that
we don't have special syntax for
Blotz blocks are very important in tulip
they are delimited by curly braces and
they allow you to do multiple things and
the value of a block is the thing at the
end and they let you do two things one
is bind variables to use later if you
were binding a variable and using it
later and the other is chaining
side-effects together so I do one thing
and then I do another thing and they
happen in order and you notice here I
used a new line between the statements
and here I used a semicolon those are
exactly equivalent in all cases the
lexer can't tell the difference between
a semicolon and a newline well this
means is anything you can do in a file
you can do on the repple there's no real
limitation you don't have to do the
Python thing where you insert a special
new line and indented correctly and all
this stuff so the repple is very first
class and we optimize very much for that
kind of interaction ML style application
has a slight weakness in that zero
argument functions are a little weird
because there's nothing to put next to
the thing to say that it's a function
call so in tulip we've introduced this
bang syntax which you can think of as a
ghost argument so here we're defining a
function start sprinklers which takes a
bang argument and evaluates a thing if
you refer to it without the bang it's
the function that hasn't executed yet
and with the bang it's the the result of
the function and those sprinklers will
start I like this better than launch
rockets it's a little more garden
focused
we of course also have zero argument
lambdas or you just put a bang in the
argument position and this particular
pattern of a zero argument lambda two a
block is so common that we have sugar
for it you can make a lambda with
Curly's as well so tag words tag words
are the core building block of tool all
tulip data structures and they're a
major part of what makes tulip unique by
themselves they look like this they're
just a dot and identifiers and and by
themselves they just act as kind of a
symbol the value of this is just dot
some word itself it doesn't do anything
but you can also use them to construct
containers so what we have here is a
tagged container that contains two
values it's tag is dot some word and it
has two values in it of course those
values could also be tag containers so
you can use them to build in trees if
you ever want to put a global and a klux
this is how you would do it you can make
trees as you like and of course if you
have a value that is one of these you
can pattern match against them in your
regular lambda syntax and the way this
works is it'll go through and find the
first one that matches in both the tag
name and arity and evaluate the thing on
the right I think bound the variables in
it and you can make these arbitrarily
nested as you like I'm just showing the
top level here all right this is
familiar this is an implementation of
the variants pattern which is a very
common pattern across a lot of
functional languages to deal with values
that could be more than one thing every
one of these pattern matches can also
have guards on it and guards are boolean
expressions and we'd find the first one
that's true and evaluate the right-hand
side of that else here is just a
variable that is true in order to make
it a little prettier and we're very
serious about tag words are baked into
the very core of the language boolean
Xin tulip are tags they're the tags tnf
and this is how you would do kind of a
traditional if expression
and if you're used to a more imperative
style language you might think this is a
little heavyweight but when you have
pattern metrics and guards using an
actual if is actually a little bit rare
you would normally use a guard or a
pattern match to do your branching and
to inspect your data but if you just
want to check if something is true or
false this is how you do it we also use
tag words for optional values values
that might not be there so in the case
that it is there we wrap it in some and
the case that is not there we use none
and this way you can design your API so
that you can return a value that says in
itself that it might not be there which
means users who consume that value are
very much encouraged to check the case
when it's not and you never end up with
surprise nulls we also use tag trees for
cons lists and this would be a little
bit inconvenient to type out all the
time so we give you a macro that expands
to that and this was the awkward part
where I said there was no nil and too
late' and you can see both nil and none
on the screen so let me explain myself
my friend allele who many of you know
because by queer types on the internet
describes herself as a null Wrangler
this is very relatable to me I spend so
much time chasing down null pointer
exceptions that sometimes it feels like
that's my entire job Tony horror the
inventor of null famously called it his
billion dollar mistake so what's what's
so bad about No right like we need to
say that something is nothing sometimes
right problem is we mean a lot of things
when we say nothing what do we mean what
do you mean when we say nothing well we
use a null pointer for example at the
end of a linked list to say that this is
the empty list in a lot of lists to say
there's nothing left we use it as a
return value for a successful
side-effect function to say I did the
thing and there's nothing to say right
we use it for a non crashing error if a
value couldn't be computed we say oh we
couldn't compute your value it's not
Ruby does this for string searches for
example it'll return nil if it doesn't
find the string a value that might or
might not be there an optional value
that is not there we use nil for or null
an uninitialized record fields we say oh
this object doesn't have this property
it's null right or undefined or a
similar idea this space is too big for
one value right like and this is part of
the problem when like a nil pops up in
production and you look at it and you
say I don't know what this nil came from
was it some value got in there from a
wrong place was it a project didn't have
a property was it just an empty list I
don't know
so in tulip we use different things for
all of these and they all have the
unique counterparts so empty list is nil
in similar to lisps or haskell on a
successful side-effect we say ok and
this is exactly what Erlang and elixir
do because we did the thing it's ok for
a non crashing error we tell you it was
an error and we tell you the reason and
if it in in the case that it might error
we also wrapped the happy case so that
you can do a very simple check of
whether it was an error or not and you
are encouraged to do so in order to get
at the data that you want in the happy
case and the same for empty optional
values we use none and the counterpart
here is some so if you have a value that
could be missing but is there it's
marked as this could be missing it's
some of the thing rather than none
and uninitialized record fields are a
little bit complicated I'm not going to
go into them a whole lot suffice to say
if you're using uninitialized record
fields it's probably a bad thing but
sometimes you have to do it and in that
case you use on def a slight side a it
elixir here elixir took a language
Erlang which it's based on the the
runtime of that doesn't have nil
and does a has a very similar approach
to what I'm presenting here and they
added a nil back in and they added no
back in for the reason they wanted an if
statement that didn't have an else and
in that case it had to have a value and
they said that adds to be null of some
kind and I think dealing with nil and
having a semantics that makes it easy to
avoid nil entirely is way bigger of a
fish then then single branch if and in
fact you can just use pattern matching
in that way to to get around that
problem anyway so this is one very
important way in which were different
from elixir and it is very deep reaching
so let's talk about abstraction tools a
very common way to abstract stuff is to
define an interface and expect other
people to implement it on their data
structures in tulipwood just give you
this so here we are defining a method
called map it takes two arguments and
the second one is the one that we
pattern match against that's what the
percent means and then other people come
along and implement it so the you just
use your regular patterns they're a
little bit limited so that we can do
this in a performant and semantically
good way but you just implement these
methods on your patterns so map is
implemented on nil which is just nil and
cons so we get our mapping over linked
lists we implemented on some and none to
get mapping over optionals and you can
go implement map on whatever cool data
structure that you come up with and it
will just work with with map all the
time so that's fine
another common way to abstract stuff is
don't want to break stuff out into
namespaces and in tulip we provide you
modules for that modules or namespaces
that can be included in each other and
you look stuff up with a slash pretty
straightforward but they can also take
arguments and this lets you do a lot of
the things that you might be familiar
with in object-oriented programming you
bundle some data with
functionality widths actually works in
tulip is that every member of the module
becomes a function with two extra
arguments at the beginning or with the
extra arguments of being it at the
beginning and when you call the module
you get a module instance where all of
the members have those arguments curried
in as if it's already been called with
those arguments so here if we say P
slash magnitude we get five
but if you say point slash magnitude you
get a two argument function and
similarly with move which on P is a two
argument function and on point is a four
argument function because it expects the
extra two arguments of x and y and so
this allows you to use those members in
higher order functions a little bit
easier so that's pretty fun
another way to want to abstract things
is syntactically and we have macros for
that you'll notice in the first line
that's a macro invocation they are all
marked
there is no never in tulip a point where
you're confused about whether something
is a macro or a function call which
happens to me all the time in lists the
syntax is represented by a tree that is
a simplified tree and this is an
approach we stole from Dylan our macro
system is kind of a cross between Dylan
and rust right now it's it's stolen from
the DX pers kind of approach where we
have kind of a simplified tree that
doesn't it doesn't do a full semantics
parse right because the things inside
the macro don't have to be valid syntax
I just have to be syntax but has to be
well nested so we make it into a tree
that just says here's the tokens and how
they're nested the data structure here
is a little bit simplified the actual
one will have source location
information like record syntax objects
do okay there are a couple other kinds
of macros
there are definition macros all this
stuff that starts with at can be
user-defined they're annotation macros
oops annotation macros which affect the
thing on the next line
for things like documentation or gradual
types and then there's parsing macros
which instead of operating on syntax are
responsible for parsing a string and it
can be an arbitrary string as long as
the Curly's are balanced so we use them
for rec access for example we also ship
with environments or dynamic variables
or if you're used to racket parameters
so these are variables that are scoped
rather than lexically which is the
default they're scopes to the stack so
it for the value it looks to the caller
and the caller is caller
so using these you can create
environments in which a variable is
bound to a value and and avoid having to
thread arguments through your entire
code base and finally a tulip by itself
is strict if you apply a function it
just happens but if you want lazy
semantics you can add that too you just
put a tilde on it tilde means lazy and
in this example the first line won't
evaluate anything and the lazy thunk
will get forced when you pattern match
it and it'll only get forced to exactly
what it needs to decide which branch to
take in sort of a week at normal form
style those are our some of our
instruction tools that I like a lot and
with that I'm going to pass it to sig to
talk to you about the runtime okay so
Janine doesn't resides in vim I do mine
in blender I'm not really a master of
this art form yet but here are my
beautiful slides
so I'm going to talk to you a bit about
tulips semantics and its runtime design
from a very high-level overview this is
what the tulip runtime looks like
architecture early code flows linearly
through the entire process it goes
through parser and a static analysis
phase that does symbol resolution we
call that part the compiler it then gets
converted to LLVM IR that IR is shoved
into our process model and as processes
get messages sent to them that code gets
did it into x86 we call that part the
runtime so tulip is heavily process
oriented though it isn't quite the same
thing as airline i feel familiar with
that we use processes to organize code
and all heat allocations so there's no
representation of code that isn't
contained within a process and there's
no memory that's ever allocated outside
of our process model we use erling style
message queues with one caveat and that
caveat is when a message gets put into
the queue no buffer is ever allocated
for it unless the process after it gets
reactivated cannot consume it otherwise
it's just a standard bounded queue that
fills up with messages processes are
concurrent but they're not threads they
don't run completely parallel we have no
locking constructs and our scheduler is
smart enough to noon when did not run
some processes so this is a syntax
example of tulip you may notice that I
don't have any syntax highlighting like
Janine had in her pretty slide show it
turns out it's pretty difficult to write
a syntax highlighter when the only thing
you know about your text is what
triangles compose it so this may be a
little bit more difficult to read these
are the two primitives we use for
interacting with processes or rather
spawning them so spawn is a function
that takes a lambda contained within one
process does a copy into a new process
and invokes the process in this case it
takes a milleri function inside that
function we have a call to receive which
is a tulip built-in that looks into the
message to you
and wait until it gets a message and
applies the lambda that's in its
argument to it in this case this process
will start up wait for a message print
of that message and then immediately die
I also mentioned that processes contain
all of our heap allocations and in fact
anytime you make an explicit heap
allocation and tulipe up to spawn a
process that was the ref example that
janine showed earlier here's how you
allocate a memory so on the left here we
have a similar syntax example as before
except I'm gonna walk through it in a
little bit more detail so here a ref is
a parameterised module that essentially
works as a pointer in tulip it contains
a process ID which is a unique
identifier for each process and it
exposes an interface where you can set a
value to that pointer which here means
you send a message to that process to
replace the contents of its memory and
you can receive the contents of that
heap allocation also just by sending up
the get tag the loop function down at
the bottom is a simplified example of
what a writhe actually looks like in
tulip they're not actually recursive
functions we have a lighter-weight
optimization for allocating memory but
it's just similar to like how you would
keep a state object in Erlang you just
loop over a single value forever waiting
for a message to update it or send it
out so it's relatively simple this is
how you use it on their Apple you create
a ref process is implicitly spawned from
that function you get a pointer to it
back and then you can read that memory
and then set that memory and get the
mutable semantics you want so that kind
of seems a little bit silly for every
heap allocation if you work with a lower
level language where you do heap
allocations a lot one of the most
important features of tulip that I focus
on a lot is that it's not slow in fact
in that process example I showed you
before what actually happens when you
spawn that ref is that 16 bytes get
allocated and then you just get a
pointer to it
but because we express those in sort of
a process driven way in the rest of our
semantics are almost purely functional
we can do optimization passes that are
traditional for ML style languages so
the speed of SML Oro camel is what you
should expect from tulip
we're always cheated we do not have an
interpreter mode we use just-in-time
compilation in the sense of it only gets
compiled when a message is sent to a
process all of our optimization passes
are done by LOV M on their SSA which
means our code generator is fairly
performant on other platforms that we
haven't even considered both do Nina and
I have x86 laptops that run our clinics
so a very limited section of possible
platforms but we expect it will also run
pretty well in arm also and I will at
some point pour it to my phone so
another aspect of the runtime is that
its semantics are seemingly kind of
strict but they're also very usable and
from the user level it's it's
comfortable you don't have to think
about too many implementation details
when you're working with tulip the
language is flexible but I would say not
dynamic Gd that I disagree about the
definitions of dynamic language and of
pure language so the terms are a little
bit different here by flexible I mean
you can do things that you would
normally do in a scripting language you
can overload methods you can use mutable
like semantics and you can express
things in a way that's easy for other
people unlike a team you're working on
to understand without deeper you know
finding abstractions um and a lot of the
benefits of highly dynamic languages
specifically eval we get back using our
process model so in this case where you
would normally just eval a string in
tulip you instead want to parse it and
then spawn a process for it which is
really not that arduous we fail early
whenever possible this is generally
considered a bad thing
for scripting languages but for to look
we think it's very important because
scripting languages usually fail so late
but it may take two years before you
discover that you've written the wrong
thing to the database so until up
instead when a pattern match fails it
doesn't contain like a handler for the
data you actually gave it or you did
something that was semantically
incorrect the process just crashes and
this is relatively safe because there
are lots of processes the we expose a
lot of constructs for handling errors so
you can tell when a process has crashed
and like restart it create a little
watchdog daemon inside your code or
handle it any way you like inside of
that process we also lose limited
performance to garbage collection
because all heap allocation are
performed within processes and we use
some custom memory semantics we don't
actually have to stop most of your
program when we do garbage collection
there's no like GC phase there's just a
couple of processes that get stopped for
a bit to get there like scope objects
culled down a little bit it's relatively
performant compared to I write Haskell
for a living it's a good GC tulip is
also one of very few scripting languages
I know that has a formalization against
an abstract machine when I started
working on tulip I originally formalized
it against the cek lambda machine which
is a fairly simple lambda calculus
semantics it's drifted a lot since then
but we still use an underlying formal
abstraction to structure our compiler
and to talk about its semantics
internally it is also and this is
perhaps very unusual for a scripting
language of any sort it's possible for
any given program to prove a worst case
execution time so though I don't
recommend it
you can put tulip into space
I've also focused a lot on trying to
prepare the code base for new
contributors so we have a run time
that's written in fairly concise C but
it's not a
concise see I try to make things
readable and not be pointer arithmetic
you see here the you data flow through
the compiler is very obvious completely
linear and all incident data that gets
created as part of our compilation
progress is in a tag geniune so if you
were to at some point run into a tulip
runtime bug early in our language and
you had to look into the compiler to see
what was happening you could always know
what the data is without looking at
where it came from and we also make very
frugal use of allocation I've actually
written a couple custom alligators for
our processes themselves because I'm
obsessive about performance and all of
the incident data that our compiler
creates is pushed through I think three
or four malloc calls now and that's it
okay what is to look at
so I hope I've convinced you the tulip
has a fairly reasonable foundation
underneath it but what would you want to
use it for we think it'd be particularly
good for embedding into an application
this is normally what you do with the
scripting language right a lot of our
semantics and certainly our triple focus
is designed around this idea that it
will be stuck into a larger application
that has its own semantics and tulip
will be having to interact with it
through some barrier and our process
model is structured for this as well so
you might not think that what you want
in your application scripts is to have
concurrent processes or spun off
thousands of processes there's something
but it turns out in a lot of cases that
is actually what you want it's
especially what you want in video games
or physical simulations where you have
actors that have to run concurrently and
interact with each other but it's also
what you want for you is because this
sort of structure allows you to
circumvent callbacks entirely instead of
having a callback oriented structure
where you explicitly route your events
just by like the control flow constructs
of your language you use message passing
and construct these graphs or circuits
of processes that thread of its
themselves and are able to handle events
concurrently in this domain we offer
advantages over most of the established
players tulip is a safer language than
Lua Lua makes it very easy to with an
accidental miss type in one line of code
remove all memory that you've allocated
in the entire rest of the program it's a
little absurd we're safer than that
we're also generally faster than Python
and by Python here I mean the C Python
runtime four to seven which is certainly
what most people use in Python we're not
quite as fast as pi PI yet I'm gonna
beat them
and it's also a little more comfortable
to write than JavaScript which of course
has a particular representation Boulder
Hey
and our repple is extremely useful for
runtime debugging of things the Tulip
runtime makes it very easy to attach a
interactive repple context to a running
like UI or something that is written
using it as an embedded platform and
just talk to the buttons
and figure out what they did wrong and
ask them what their problem is as well
and this is something I'd like to use to
look for
I think tulip would be extremely good
for making the opposite situation a bit
better so in ops you normally have
tooling where you have something like a
puppet script that does your deployment
phase and inside that puppet script you
shell out to bash to use some actual
manipulations in the file system or with
the processes so the puppet layer sort
of contains a state machine that sets up
stuff and contains like information
about the dependencies of what order to
do things and then the bash scripts
itself do the actual operations tulip
can do both of those and it's pretty
good at both of those our process model
is very good at expressing finite state
machines and finite state machines with
different C's on other state machines in
fact when you implement a state machine
as a graph of processes in tulip our
scheduler is smart enough to never run a
process that does not currently have its
state active because our scheduling
semantics are based on the data flow our
data primitives the the tag words are
unstructured enough to be useful for
Michelle so it's fairly trivial to go
from like the output from LS or
something and parse it into a very tulip
data structure they're also structured
enough to be more useful than the raw
text itself you can map over that output
or you can use like if you were getting
output from a process tree or something
you can use a lens to recurse down it
and find if your process is actually
running our process crafts also have
significantly better failure modes than
UNIX process trees in a UNIX process
tree if the parent process dies
and it has some like strong air all the
information you get is at worst an
integer and it best a string on standard
out in tulip you get a lot of
information from the runtime that is
containing the code that failed and you
can have it return its state and inspect
what happened the debugging experience
is much better I also think tulip would
be fairly good at web programming though
I wouldn't use it for this the biggest
selling point in the web domain for this
language is that heterogeneous trees are
our primary data structure whereas in
most languages it's a pretty difficult
process to get a templating language to
actually work in produce HTML and tulip
you can just express it as the tree of
things that you want with function calls
inside of it you don't need a language
for templating in most cases as well we
have the same benefit that Haskell and
Erlang do in that are our process
scheduling semantics folk work pretty
effectively as a load balancer such that
unless you have a performance like
problem that you need to like schedule
around
that's something more complicated than
agent aisle of service attack you
probably won't have to write any logic
for that it will just work like work
does in Haskell or like or like what
frameworks do we also have a very very
small language level attack surface if
you're exposing your code to the public
web not having eval is a great feature
it's actually extremely unlikely in
tulip that someone can get enough
information out of your gear like web
application to insert something into
your database and certainly they can't
mutate any memory around any code except
a process that is fine on that memory on
the string they gave it okay how done is
to look so this is what we've completed
so far about a week ago we got the JIT
working and got it up to reasonable
performance and we got the compiler
section working here is what does not
work the jiggin compiler do not
currently like connect we can't pass
data from one end to the other yet it
will be will have that running fairly
soon like in a week or so but a full
implementation of our process semantics
on top of that will take a month or so
or a couple months and a stable release
of the language is certainly more than a
year away as well on our design side
we're still in the process of designing
our standard library suggestions for it
are very much welcome it looks like I'm
out of time so I'm going to skip to this
takeaway section I hope I have convinced
you that tulip is good and not bad it
has a lot of potential to improve the
scripting languages space and it has a
pretty good technical foundation
underneath it's usable and accessible
design we'd really like some help you
might be wondering why we came up here
to present a language that you can't
actually use yet and the answer is is
that we really need to grow our
community right now
scaling a language project like this
with a process model on a custom garbage
collector and all these semantics we've
talked about is a job for more than two
people
Janine and I are working really hard on
this and we'd like to work a little less
hard the roles we need right now our
documentation writing and we're really
really focused on this we would like to
release tulip with extremely solid
documentation we need help with library
design and especially the linz part that
I mentioned before we need as many human
fuzzers as possible because we do have a
JIT compiler and it is generating x86
and we need C programmers because I had
to do a lot of C lately you can contact
us here our PL design chat snake is
located at snake dunya net that's where
the inviter is our website is at tulip
link org and these are our Twitter's
so I don't know if I have time for
questions this is the end okay I don't</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>