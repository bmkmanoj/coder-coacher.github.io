<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Exotic Functional Data Structures: Hitchhiker Trees&quot; by David Greenberg | Coder Coacher - Coaching Coders</title><meta content="&quot;Exotic Functional Data Structures: Hitchhiker Trees&quot; by David Greenberg - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Exotic Functional Data Structures: Hitchhiker Trees&quot; by David Greenberg</b></h2><h5 class="post__date">2016-09-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/jdn617M3-P4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well welcome everyone today we're gonna
be talking about exotic functional data
structures and specifically we're going
to be talking about hitchhiker trees
before we get started I just want to
tell you a little bit about me my name
is David Greenberg I'm an author there's
this book I wrote I'm an engineer and
now I actually consult working mostly on
mesas and distributed systems problems
and also just a little announcement at
12:30 today I'll be signing and giving
away copies of this book building
applications on mesas so let's get
started though there's lots of cover
here because functional data structures
are pretty complicated so what are
functional data structures well at their
core a functional data structure is
immutable that's really the difference
between a functional data structure and
a regular data structure so what is a
mutable mean well consider seven when we
add one to seven we get eight but the
thing is seven is still seven if you
think about what is it a radio or a list
or something or map in most languages
when you you know when you add an
element to that that's not what happens
so let's look at some examples in Python
just to sort of build some intuition
about what a functional data structure
actually is so here we have a Python
program where we define this list X and
X has three elements and then we say
that Y is equal to X and we add a new
element to Y now this program prints
that I'm a sad panda now why is that
well it's because when we added the
element to Y we also kind of added it to
X by mistake now when we look at the
program it doesn't look like we added to
X it looks like we added it to Y you
know but this is how it goes
without functional data structures how
do we fix this well I made a little
change to the program if it's not
jumping out to you I'll highlight it
here and what this changes is this
little sigil it actually copies the list
X so now we're not saying that Y is
equal to X we're saying that Y is a copy
of X and so now when we when we compare
these two lists having added a new
element to Y we see that they are
different and so we can be a happy Panda
and so that's great right there's this
basic idea of copying it turns out it's
gonna be really important
so here's a list of fruit maybe these
are my favorite fruit they're not
actually because I don't really like
apples that much so how would I mutate
this list to be to represent my favorite
fruit I don't like apples but I kind of
like mangoes instead so we just are
going to copy the list which isn't red
and then we're going to make a new one
which is green so for the rest of this
talk whenever I put data structures up
on slides I'm gonna highlight them so
that anything in black hasn't changed
anything in red has been D allocated and
anything in green has been allocated or
mutated just to sort of get a feeling
for where were where we're spending our
cost of allocations and deallocations so
what we can see here what's going on is
that we've when we copied this list it's
in the process of copying is what we
actually made the change so the old list
in red that's still the exact same list
that it was before kind of like how
seven doesn't change when you add one to
it you just get another thing which is
eight you know that's what we have going
on here we have the old one on the left
and the new one on the right now
this isn't super great though because we
did have to copy the entire list so in
order to do better we're gonna have to
introduce a new concept which is
pointers also known as reference isn't a
lot of languages now most languages use
these and you're probably familiar with
them but maybe you haven't encountered
them so let's just talk a little more
about them so here we have a struct and
this is a struct kind of like biometric
information about me you know has my
name in the first field it has my
occupation my hair color my eye color
and the thing that I want to point out
here is that my name in the first field
that's actually that's like an embedded
struct so inside of this record with
four fields the first field is actually
a new is a different record with two
fields but we've embedded them together
so this is one way to represent data but
we could also represent it with a
pointer so by representing this data
with a pointer what we can do is we can
take that that name that with the first
name of the last name we can move that
off to a different place in memory and
instead of storing the full name
embedded in my biometric struct I can
just point to it with that little arrow
so also throughout this talk whenever we
have pointers or pointer fields the one
thing that's always going to be in
common is there's always going to be
angle
gets around them just to kind of help
you visually distinguish between actual
values and pointers okay so what's the
point of pointers
well pointers enable sharing so what we
can do is if we have something else say
an employee record on the bottom left
then we can have a biometrics record and
an employee record they can share the
same name record so the sharing is
really is really kind of an interesting
thing so let's explore how is pointers
and sharing our pointers which enable
sharing how is that related to
functional data structures you know how
can that actually help us so if we go
back to our example where we have our
our struct where we head to what we want
it to modify it make an entirely new
copy which forced us to make a whole new
allocation and deallocate the entire old
array how can we do better so we're
gonna do better by using a linked list
so this is a singly linked list and this
is a functional singly linked list so
we're gonna have to treat it slightly
differently because there's no more
mutation allowed so suppose I want to
mutate this linked list right I want to
change it so that instead of having an
apple at the front we want to have a
mango at the front so what we do is just
this and what we've done here is we have
by because this the last four elements
are the same for the old linked list and
the new linked list we only had to
allocate and deallocate at the first
element right so by only changing the
first element this actually saves us a
lot of computational resources a lot of
kind of memory allocation and
de-allocation because we only had to now
allocate and deallocate one element
instead of five this is better okay
now the problem is that in the worst
case this this actually gets pretty bad
in fact it gets linear in the number of
elements in the list so here in this
case instead I want it I want to say you
know it's not that I like I actually
changed my mind I like apples but I'm
not a big fan of bananas so we're gonna
say instead of bananas I like mangoes
and so to do this I actually have to
change the first three elements we had
to deallocate and allocate new ones okay
so now there's something weird going on
here maybe you're wondering why why
three because the first two elements are
the same and so this is this is actually
it's a philosophical thing but it's
practical as well and
the question is this when is an apple
not an apple in this case I'm referring
to the apple at the head of each list
well an apple that points to an orange
that points to a banana is different
than an apple the points to an orange
the points to a mango yeah so what is
that what does that mean well when we
think about pointers right remember
pointers are just kind of a different
way of representing embedding
information into a struct but instead
we're just pointing to it so that it can
be shared but really that Apple and and
orange at the beginning of the list
those are different apples and oranges
because when we sort of trace down what
their descendants look like their
descendants are different and so this
idea you know of what is the what is
something why do we have to copy it
versus not versus be able to leave it in
place and share it this is an important
question that we're going to revisit for
you know continuously throughout this
talk so this idea here what we're doing
is we're copying the path and the path
is we're tracing from the thing that we
want to mutate we're tracing it all the
way back to the root of the data
structure the root is something which
nothing points to it and that's what
makes it the root so we have to copy
this entire path to the root of course
in this case copying the entire path
could be the whole list and so we needs
to do better and so what we're gonna do
is we're gonna do better by using trees
now we're going to talk about a bunch of
different types of trees we're gonna
build up to hitchhiker trees because
they have a lot of kind of tricks in
them so we're gonna talk about binary
search trees and then we're going to
talk about B trees and B plus trees and
then fractal trees and then hitch-hiker
trees because each one's gonna kind of
build on top of them as it gets more and
more complex so we'll start with binary
search trees binary search trees why are
they called this well binary because
there are two children for each node
their search trees because they're
sorted which enables us to do a search
now the sort that they do you look at
this and you say you know David that
doesn't that doesn't look really sorted
to me you know it kind of looks sticky
scattered elements throughout it
randomly well the sort of this tree and
all trees are going to use is for any
node all children to the left of it are
less all children to the right of it are
greater and so we can see this property
is true so if we want to
the value three in the tree I've
highlighted whenever I want to just call
attention to something will make it
orange okay no more colors so when we
highlight it we're gonna look up three
right so we say well where is three and
we look at the root well root is 4 and
we know 3 is less than 4 so we can
descend to the left and then we say okay
well now we're on two we know 2 is we
know 3 is greater than 2 and so we go to
the right and lo and behold we find 3 so
the thing about this is the lookups are
log base 2 of n so I want to give you
some intuition about how we're actually
going to come up with these big o
runtimes because as we go into B trees
and B plus trees and fractal trees and
hitch-hiker trees they're each doing
tricks to sort of manipulate the Big O
runtime in funky ways and it I think it
really helps to make sure we're all on
the same page about where this log base
2 event is coming from so if we count
the number of elements in each level on
the first level which because we're
computer scientists who don't use MATLAB
or Lua is indexed 0 we say well there's
2 to the 0 elements in the first level
and so that's one element and of course
there's one element it's the root and on
the second level which is index 1
there's 2 to the 1 elements and you know
there are and on the third level there's
2 to the second power elements and and
so on and so on we would keep increasing
that number now in Big O analysis we
only care about the dominating factor
that is the the the term of our equation
that is the growing biggest fastest and
so in our case what's growing biggest
fastest it's the number of leaves in the
tree the number the leaves are the
bottom elements of the trees so that's
what's growing biggest fastest and so
that's what we're going to do the
analysis based on so let's do a little
algebra I'm sorry but let's you know
let's kind of walk through this and see
how this works so we have L levels in
the tree this is just sort of you know
by definition we have a tree we count it
how many levels there are however many
levels there are that's L ok now we know
that lookups cost L hopefully I
convinced you when we went through that
little example of looking up 3 that
whenever we look up a value in a tree
we're always going to see that it is L
levels deep
now the other thing is that only the
last level matters I tried to give some
some intuition into why that's the case
you know and I think that if you want to
know if you don't believe me
and it seems a little bit hand wavy it
is a little hand wavy and there's
definitely a lot more rigorous ways to
convince yourself of this okay so
there's also there's two to the L minus
one elements in the last level alright
so now we have some terms that we can
work with so if n is the number of
elements in the last level then n is
equal to two the two the L minus one
because we're just kind of plugging
definitions into each other so now we do
some algebra you got to trust me this is
how algebra works and we get that log
base two of n is equal to L so what is L
L is the number of levels we have in the
tree and L is the cost of doing a lookup
in the tree so if L is the cost of a
lookup in the tree then log base two of
n is the cost of a look up in the tree
now the other thing that I just want to
point out here because it's going to
matter is that we had we use two to the
L minus one because there was two
children at each level and that two is
the same two that got copied down to the
subscript on that log so log base two so
we're gonna play with this stuff in a
little while when we start talking about
B trees and B plus trees okay so
functional updates so I've talked about
trees I talked about these binary search
trees but I haven't talked about a
functional binary search tree you know
what does it mean to be functional well
we're gonna take that path copy an idea
from the linked lists and it turns out
path copying works way better with trees
so here is an example where we want well
what we're gonna do here is we're gonna
change the node which has three and
we're going to change it to be 3.14
which is similar to PI so what we have
is we actually need to only deallocate
that path from the root to three and
we're allocating this new path from the
root to 3.14 and what you can see though
is that actually a bunch of the nodes
are staying black we don't actually need
to change those nodes we don't need to
touch them because from their
perspective they're some trees have not
changed whatsoever they're exactly the
same and what's cool about this is that
the updates are still log base two of n
now I want you to think about that just
for a
second here again the updates for a
functional tree are the same cost as the
updates for a mutable tree that's Impala
Klee anyway so this is pretty exciting
right we can actually start we're seeing
a way that we can take functional data
structures and get the same performance
that we would get out of a mutable data
structure there's a few other properties
of trees that that are worth knowing
about and that we're not going to talk
about in this talk so trees are balanced
right one of the things we're going to
assume throughout that we've been
assuming we're gonna continue to assume
is that our trees are balanced which
means that there's you know they're sort
of triangular with kind of a flat bottom
and and sloping sides they're not
leaning heavily to one direction they're
not sort of like a line that just you
know squiggles off into the bottom right
or bottom left distance how do we
maintain this there's some algorithms
that do this there's sort of two big
families of them if you're interested in
learning about that there's a book
called CLRS the CLRS book is kind of the
canonical book of writing about how
algorithms work so if you want to learn
about tree balancing you could read CLRS
or you can try wikipedia the other
question is how do we actually order the
values well in this talk we're only
going to be talking about sorted trees
because these are what have been
interesting to me and these are kind of
what all these trees we're talking about
take advantage of there is another way
to order the values in a tree though and
that way to order them is called a tri
which is also pronounced the tree that's
that word where the first a is an i up
there so a tri is out of scope but i
want to point them out because the same
stuff we're gonna talk about the same
performance optimizations we're going to
talk about in most cases apply to tries
and that's actually the way that
language is like skaila closure and
elixir that's how they implement their
immutable hash maps as they use tries
instead of trees and if we have some
time at the end I do have a couple bonus
slides about how that's actually done
we'll see okay so the next thing I want
to talk about is is what if we change
our cost model so where did that to come
from in the log base two of n well that
too came from the number of children
that we had to go to right there was two
children as a binary search tree now the
thing that we're trying to optimize in
that tree if we all another way to think
about
that is what was that cost that we were
looking at that height well at each
level we needed to do a comparison and
so what actually that the sort of the
cost model that a binary search tree is
evaluated under is the comparison cost
model we're trying to count how many
times do we have to check whether we're
greater than less than or equal to each
time we do that we that's sort of the
thing we're counting up so what if we
change our cost model to i/o what if
instead we say that you know well it
turns out that things like and if we
want to read data from a disk we're
probably getting 4k of data at a time or
maybe a megabyte of data at a time it's
actually no more efficient to read one
byte versus a thousand bytes when we're
reading it off of you know a disk and if
we're reading it over a network that
number could get even bigger you know it
could be a megabyte or two megabytes so
let's try a new idea what if we actually
increase the number of children per
level because comparisons aren't really
expensive we can do a bunch of
comparisons inside of every node instead
what let's do is let's try to make it so
that each node carries as much data as
possible okay and we're gonna do that by
making fat nodes with B children that B
stands for branching factor and that B
is for B trees so here's an image of a B
tree and if we look at this B tree we
see okay it's a tree you know kind of
ran out of space because these B trees
they have this you know branching factor
that's really big and the text gets too
small if I try to show more levels so
here what we see is we look at the root
and we see okay the root has some values
like 5 10 15 and 20 and it turns out
that same sorting property is true in
this as it is in the in the binary
search tree so let's look at that right
if we look the first element in the root
is 5 and so if we look at the very left
most leaf we see that all those values
are less than 5 in fact they're from 1
to 4 and if we look at the all the other
leaves we see those are all greater so
what we sort of done is 0-2 taken that
binary search stream we've kind of
scrunched up a few levels of that tree
we kind of scrunch them up and suggest
one node so these B trees they're
they're great actually they're really
great they're optimal for reads there's
a lower bound of log base B of N on
lookups unsorted data
and that's way beyond the scope of this
talk to proof I don't even remember how
you prove it but let's just take it as a
given that that's not that's gonna be
our bound okay so it's really cool
though that we can control the base of
the logarithm you know with these binary
search trees we were stuck with always
being log base 2 of n with B trees where
log base B of N and so you know why is
that cool so suppose we had a tree with
a thousand elements and it's a binary
search tree well in that case we're
gonna spend you know about 10 units of
time when we want to do a lookup in this
tree okay well that's cool you know ten
units a time seems reasonable especially
if they're small units but what if we go
to that B tree on the previous slide you
know with with five children well when
we only have five children we're
actually going to be able to nearly
double the performance so we just
increase the number of children and now
we get a constant factor speed-up and
then again you know what if we wanted to
know an even bigger beach we see a
hundred children per node well now we're
nearly seven times faster than the
binary search tree and the reason is
that our speed it's not coming from the
number of comparisons we're doing it's
coming from the amount of data we have
to read from disks and so this V tree is
allowing us to read more data more
useful data that we can act on on every
single time we do i oh and so this is
great by going wide we get these big
constant speed ups for free and this is
because of this aisle cost model now I
want to point out these speed ups they
are constant speed ups you know we're
not getting some kind of asymptotic
performance improvement but still you
know is anybody would be happy if their
program was a hundred times faster just
for free yeah you know sure it's not it
doesn't get even faster when you run
more data but you know I'm not gonna say
no so B tree bookkeeping though you know
there is a downside with V trees or
there's something that I find personally
annoying with implementing B trees which
is that the bookkeeping is is quite a
bit trickier the reason is that each one
of those nodes we don't have that easy
to express invariant of oh yeah well you
know if it's smaller it goes to the left
and if it's bigger it goes to the right
instead we have this thing where oh well
we have you know K elements on each or
on each level and then we have you know
k plus 1 children and
have this particular property and good
luck figuring that out it can be kind of
challenging and so there's this idea
that a lot of people had you know saying
well you know if that's kind of annoying
to implement what if we what if we
separated node types actually what if
instead of storing data throughout the
tree what if we only store data at the
leaves and we'll call those the data
nodes and then we only store index
information in the middle and the root
and we'll call those index nodes now the
other the other kind of cool thing about
doing this is you know throughout this
talk we're only looking at the keys in
the tree but remember often maps are
kind of what we care about not sets and
so along with each of those numeric keys
there's some value associated with it
that's just sitting there and so when we
change our tree and we separate the
index and the data nodes values only
need to be sort in data nodes because
the index nodes are just storing those
keys and the keys are probably smaller
so you can fit more keys per level so
this is another performance enhancement
that people get and now what is this
called you know we've been talking about
this idea of separating the index and
the data nodes well that's a B+ tree and
so here we can see a B+ tree it looks
similar to the B tree you know it's got
children
it's got index nodes but the difference
here is is what I've done is said okay
the root doesn't store any data instead
it's just sort of replicating the
largest value from that child up so you
can see that the first element of the
root is the largest value from the first
child for the second one is 8 and so on
and the last one is plus and the reason
it's plus is that that just means this
is bigger than anything else you know we
we don't care what it is but the really
big stuff goes over in this direction
and so we create this sort and you know
our lookups are still gonna work the
same so if we want to look up the value
9 we scan across the root until we find
the first index element which is going
to be greater than 9 which is 12 and
then we go down a level and we look in
that node and you know there's 9 now for
the for the rest of this talk I'm
actually going to reduce be kind of
pathologically there's only going to be
three children for each node and the
reason is I want to show three level
trees because as we start talking about
fractal trees and hitch-hiker trees
they're optimizations and their
improvements really depend on multiple
levels of the tree existing because
we're kind of gonna get some performance
optimizations and performance wins by
increasing the number of levels or by
taking advantage of the fact that there
are many levels so from now on we're
gonna have these three level trees and
so here's our three level B tree all
right
so fractal trees now we're getting to
the good stuff you know what you really
maybe came here to hear about fractal
trees and hitch-hiker trees so what is a
fractal tree well this is a fractal tree
the difference between this and a B+
tree I'm pointing right here it's this
it's this idea that each one of the
nodes is going to get a little buffer
attached to it you can see here this
fractal tree has buffers of size two so
it's a B+ tree with extra buffers added
to all the index nodes so a fractal tree
just say it again a fractal tree is a B+
tree but we're putting this buffer this
log this place we can store data
temporarily we're putting that on every
one of the index nodes so in order to
understand what this is about well I
want to make a little aside okay off of
trees let's go back to something simpler
and different because you know what that
that log base B of n that was only for
sorted lookups right and inserting into
a tree is not a sorted lookup I mean
it's inserting that lookup it's
different so we can do better and how we
can do better is by appending to a log
now appending to a log is a constant
time operation so supposing that we have
this log here and we're gonna append in
the direction of the arrow then we
always know the next index where we need
to insert it before we even do the
insertion there's there's no bookkeeping
just in Golders just incrementing a
number tells us where to insert it so we
want to insert a first element at index
zero and because we inserted that
element at index zero we know the next
element belongs at index one and we know
the next one belongs at index two and
the next one at index 3 and the last one
is going to belong at index four we
didn't have to think about that there
was no tree balancing there was no
complex algorithm to do this it was
really fast to just append to the log
and so when we consider a fractal tree
you know this is what we're going to
take advantage of is that each of
little buffers that we stuck on the
index notes each of those little logs
those are going to be really fast to
insert into and we're going to take
advantage of that to sort of smooth out
the performance of our B plus trees
insertions so let's start we insert 0
into this tree and we stuck 0 right
there right in the root node why do we
stick it there because that insertion of
0
there were space for it in the buffer up
there and the other thing that I want to
point out I want to highlight here is
that we only even had to touch the root
node we literally don't even care what
the rest of the tree is doing or what's
going on this is this operation costed 1
it's only one thing we touched it's very
very efficient so let's insert another
element negative 1 and once again it
fits in the buffer in the root node we
only have to touch the root node and so
this is already better than what a B+
tree would require which would be at
least touching one node at every level
so now let's insert a new value 28 so I
want you to think for a second you know
we're gonna insert 28 what might happen
you know where are those values going to
go because we don't have space in that
buffer anymore all right times up so
what we're gonna do is insert that we're
still want to insert that in the root
but we have to do first who's to free up
that space and we're freeing up the
space by flushing those values down and
so here you can see that those values
when they get flushed they're going to
the left all right they're going down to
the to the left level and the reason for
that is if you think about where would
we like to insert those if this wasn't a
fractal tree well we would insert them
all the way on the bottom left
sorry bottom left of the of the tree and
that's because they are the smallest
elements right they're even smaller than
the current smallest elements of the
tree so they belong in that direction so
we're gonna flush them down in that
direction and after we flush them down
that frees up space in our root buffers
and so we can do a new insertion so
we'll keep going you know we'll insert
29 that's again fits in the root we're
back to our situation where we only have
to touch one node and we'll insert
negative 2 which is you know also great
we're gonna flush 28 and 29 down this
time to that
and you know they fit and we have new
space in the route again we're gonna
insert 11.5 and now at this point I just
want to pause for a second to say at
this point something interesting is
gonna happen on our next insertion
because 11.5 can go to the middle node
right there space for it there but
negative two that's gonna be going
that's gonna be going over to the left
and so it doesn't really fit though
right we tweet negative 1 and 0 or over
on the left buffer so where do they go
well when we insert this this additional
value what happens is we're gonna have
to flush but we're gonna flush
recursively right so actually flushing
is always a recursive operation in a
fractal tree and so what we ended up
doing here was negative 1 &amp;amp; 0
they got flushed so far down that they
became a leaf of the tree in fact the
way that fractal trees are implemented
is that they actually are just going to
at that point trigger at the standard B+
tree insertion algorithm okay so this is
how these rights work it's this idea of
we have these buffers we fill up the
buffers when a buffer fills up we flush
it down to the next level recursively
until we find enough space and when it
hits the bottom that's when we actually
insert it into the tree like we normally
would with a B+ tree and so this is a
fractal tree and it gives us this big
improvement in right performance now
what about reeds though you know it's
not so obvious how we're actually gonna
read this data because it's not that the
trees aren't really in sorted order
anymore well let's look at a different
tree a simpler tree to get an example of
how we can do a read so here we have a
super simple fractal tree almost nothing
going on in it and we want to look up 20
so to look up a value in a fractal tree
there's actually it's actually a
two-step process so the first thing we
do is we find the path that we want to
do that look up you know so that we can
do that look up the same kind of path
fighting that we did for the binary
search trees and the B trees and the B
plus trees we're finding this path of
all the nodes along the path and then
what we do and this is the cool part is
we're gonna project the pending
operations so just to highlight that
right we're taking every one of the
pending operations that was along
half that we did look up on and we're
gonna project them all down into that
leaf node essentially it turns out even
for a fractal tree which is mutable we
still need to use functional data
structures for this part of the
operation because we do we want to make
sure that we're not actually changing
the tree but in order to do the lookup
we have to pretend like we're changing
the tree so it's kind of like we have
our old node value which hasn't changed
over here but then we have to create
this simulated new value okay so once we
do this simulation of the new value of
the new leaf then now we can actually do
lookup directly on the leaf and you know
we we do our little search within that
single leaf we see 20 is there and we
get our answer so this logic here this
is broken four scans okay so the scan is
another common date operation we want to
do on sorted trees and a scan just says
you know let's start from all values
that are greater than something and less
than something it's the sub range it's
it's we're scanning across a bunch of
stuff and so this is broken four scans
right because if we project the pending
operations on each path to every node
then for instance we can see that the
roots pending operations are going into
every single node right is kind of crazy
and so we end up with with you know gems
of our sorted tree it's definitely
sorted when it goes you know fourteen
twenty thirty fifteen or fourteen twenty
thirty ten fifteen right that's
definitely sorted order so okay so it
turns out it's actually slightly more
complex what we do is we actually only
project values within range so for a
Fraxel tree and for a hitchhiker tree
what we're gonna end up doing is we
actually have to figure out which
operations might end up in that leaf and
then project only those operations a
little bit more complex implementation
wise but when we're thinking about it
you know just this idea of projecting
the path of all the pending operations
is what allows us to actually get good
results correct results in our in our
fractal tree reads so I've been talking
a lot about fractal trees and maybe
you're wondering okay but I thought this
talks about hitchhiker trees what's the
deal you know what's going on here so
the one of the big differences between a
hitch-hiker tree and a fractal tree is
whether or not it's
using path copying so fractal trees they
do update in place they're similar to a
B+ tree or a B tree or whatever you know
and that they're actually designed to be
making these modifications and mutations
in place and when we look at commercial
fractal trees they typically take
advantage of this in order to expose
different types of concurrency in their
operations in a way that is completely
incompatible with a functional data
structure in comparison a hitch-hiker
tree the one of the most fundamentally
important differences that hitch-hiker
tree uses path copying so that a
hitch-hiker tree is a functional and
immutable data structure that still is
able to gain these performance
advantages of the faster inserts and the
better i/o performance another
difference between the two of them that
is not something that we can really have
time to go into in this talk is that
hitchhiker trees are more optimized for
storage which returns bigger amounts of
data that's with a higher latency
whereas fractal trees are have really
been optimized for things like solid
state disks and local disks where
there's a slightly different performance
trade-off in latency and and size of
block so let's look at something else
though okay let's talk about flush
control this is another thing that's
really important with the hitch-hiker
tree in terms of understanding where
where you're actually gaining
performance so I have this this example
again of the B+ tree slash fractal tree
slash hitch-hiker tree and all the
assertions that we made and there were
seven seven operations is what we did
okay so and we have this table as well
and each row is the i/o is i/o costs for
a type of tree in each column might
represent a different thing so the total
i/o that's that's what it sounds like
it's the total number of i/o operations
that we're done to do seven inserts the
i/os per flush that is looking at each
flush each time you flush the tree
how many iOS did you do and then lastly
the average io per insert that's the
total i/o divided by seven because we're
averaging it out right it's not
necessarily the max i/o as we did at a
single time that is sort of the worst
case pause when we did a write instead
we're saying what was sort of the
average when we averaged it out and so
for a B+ tree you know every time we do
we have to touch every level of the tree
to get all the way down and let's assume
that we want to persist those two discs
and so that means we're also doing 3 iOS
every time we flush because we have to
write those out every single time and so
of course this gives us an average of 3
iOS per insert now for a fractal tree we
only had to do 12 iOS remember because
there's 12 iOS sometimes when we didn't
insert we only have to touch the root so
the iOS for flush they could be only one
but in the worst case remember when we
inserted 100 in that last insertion that
actually caused us to have to write four
nodes that's even more that's an even
worse pause than what the B+ tree caused
us to do so the iOS per flush can be
highly variable with a fractal tree and
then but the on average you know we
actually end up doing a lot better
almost twice better than what we got
with the B+ tree by using the fractal
tree and that's because we did end up
doing a much fewer iOS overall because
we we were able to we didn't have to
touch every level of the tree every time
so with a hitch-hiker tree we can do
even better and with the hitch-hiker
tree what we're doing is we actually
will only have to do 5 iOS overall and
the reason is we could actually just
make the decision to not flush until
we've made a whole bunch of rights and
so in this case we only have one flush
which costs 5 iOS but it only happened
once so the latency on that flush is
quite a bit longer but also in addition
to in exchange for that increased
latency our iOS / insert is less than 1
io / insert that's that's pretty great
so the other thing I do want to point
out though is that with a hitch-hiker
tree and with its API and also with a
fractal tree it's really up to you when
you want to flush so you kind of have
this this trade-off space of you can
choose to flush more often and spend
more on i/o costs or flush less less
often and save on i/o costs at the
expense of you know not having your data
written to a disk somewhere so real
branching factors all right it turns out
that you know in these examples we've
been looking at stuff with three or five
or six children but that's not really
that's not really how many children
there are supposed to be that's not
really how many there are a B+ tree
typically has a fan-out
of one to two thousand elements alright
the reason is that remember when we
talked about what is the sort of the
block size of most disks it could be
anywhere from four kilobytes to one
megabyte well we can easily fit that
many keys into a single node so the
branching factor for B plus tree is
pretty big so you might think the
branching factor for a hitchhiker tree
would also be pretty big and it isn't
strangely it's actually much less maybe
100 200 could be even less so why is
that well it's because those buffers and
the hitch-hiker tree those actually end
up being really huge because remember
the thing that we that often we care
about and this is a trade-off that we
can make as we often care about
increasing our insertion time we want to
want to increase the performance when
we're doing operations on the tree while
we're doing writes to the tree we want
to and then we're okay with maybe having
a small penalty on reads and so there's
actually a Wikipedia article about this
I believe where they show some math
again kind of complex or whatever and
they actually end up getting better than
log base log base B of n for operations
on fractal trees because the buffers are
so big and there's there's various ways
you can try to tune this and
what-have-you okay so you know maybe
you're thinking this is kind of cool
this is interesting I'd like to try
these fractal trees these hitch-hiker
trees I want to play with them well it's
on github and it's available as part of
the data crypt project so data crypt is
entirely written in closure and it's
entirely pluggable and when I say it's
pluggable I mean it's pluggable in all
kinds of ways the backend storage is
pluggable initially I implemented a
Redis back-end and an in-memory back-end
but since has contributions for database
backends and for s3 as a back-end the
i/o management layer is pluggable so
when you want to flush when you want to
compress data all of that is up to you
for how you want to actually do that and
you can write plugins for changing that
the serialization formats pluggable
again this allows you to control things
like compression and encryption in order
to get additional performance gains
there and even the sorting algorithm is
pluggable so you can use the default you
know JVM sort
or you can use a car um an ordinal sword
or a lexographic sword or really
whatever sort function you want to use
it's all pluggable with data crypt and
what data crypt gives you is it gives
you this this framework this API for
interacting with a hitchhiker tree in a
very fundamental way so you can insert
things into it you can delete things
from it you can flush it to disk and and
do a variety of cache management
operations I mentioned briefly that the
hitch-hiker tree as compared to the
fractal tree is designed for remote
storage store it's even further away
reading even bigger amounts of data and
so there's a bunch of cache management
functionality that it supports for that
and so right now today you can actually
use this also in an application it works
with Redis and it's called the outboard
API so what is the outboard API well it
looks like a hash map except the data
stored off heap in Redis which is a
major innovation obviously compared to
Redis so it in and you know it actually
is though it's not the same thing as
Redis because although Redis is an off
he - map - you know pretty much what the
hitch-hiker tree ad is it's a functional
data structure so you have free
snapshots so no matter how much data
you're storing in Redis you can actually
as you make modifications you can say Oh
actually snap this and preserve this map
and that's free and so what that means
though is that in addition to having all
these snapshots that you can make
whenever you want to at basically zero
cost you have this still a disadvantage
of your functional program when you need
to restart the virtual machine it can
just reconnect to Redis and you can be
right off to the races and this is a
really interesting idea and this is
something that actually inspired me to
start thinking about these in the first
place which is that once when we're
writing functional programs we're
building these functional systems we
don't actually have to tie the lifetime
of our data structures to the lifetime
of our runtime which means that as we're
redeploying code as we're making changes
as we're doing those kinds of things
restarting our virtual machine doesn't
mean we need to actually flush out our
memory it doesn't mean we need to get
rid of all that state we've accumulated
in memory and that means that we can do
restarts much faster and that's pretty
exciting
so I want to give some shoutouts and
thanks to Andy Chambers for contributing
the JDBC back-end for the
hitchhiker trees and also for improving
the the way that we do garbage
collection and also the Casey Marshall
for contributing the s3 back-end so you
know I think the big question now is
what are we going to build next I would
you know love to have anyone or everyone
as a contributor to the hitch-hiker
trees on github at the data crib project
I don't think we have any time for Q&amp;amp;A
so thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>