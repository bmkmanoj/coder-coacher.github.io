<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Probabilistic Programs Which Make (Common) Sense&quot; by Zenna Tavares | Coder Coacher - Coaching Coders</title><meta content="&quot;Probabilistic Programs Which Make (Common) Sense&quot; by Zenna Tavares - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Probabilistic Programs Which Make (Common) Sense&quot; by Zenna Tavares</b></h2><h5 class="post__date">2015-09-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xxA766PrzQI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hello everyone money incentive Rs I'm
a PhD student at MIT and I'm I'm in a
computer assisted programming group and
our goal is mostly to take one of your
jobs away jokin assisted is the keyword
but really if you're interested in the
kind of academic work we do go to a
website there's many cool projects that
you should check out but today I'm going
to talk about something slightly
different which is common sense so the
last talk was about determinism this is
very much about non determinism but
before I talk about what I'm going to
talk about let's have a an example an
observation I've made so I'm from London
and this is the kind of stare you're
seeing in the London Underground the
subway and what I noticed was that in
this case you you doesn't have these
stairs and you go down and you turn left
to right and there's the platform and
what often happens is that somebody will
be walking down and I'll be for some
reason now they'll run or they'll go a
little bit quickly and if people behind
them will start to run and everybody
will start running down the stairs and
you get to the platform and there's no
train right so what's happening here
what's happening is that you are putting
yourself in other people's minds and
you're trying to figure out the world
based on your observations from other
people's actions and some some
colleagues and friends of mine have
tried to model this in humans and and
mathematically and this is my simple
explanation of my derivation of their
work and so the idea is that we have a
simple two dimensional world so you can
think about it as we're looking down in
the 2d space like a Google Maps kind of
view and they're only nine possible
states but there are two types of
terrain is the red terrain and is the
green train and as the cost to traverse
the different kinds of train and you
could imagine that maybe it's hilly or
rugged or smooth and so the question
that I want you to consider is what are
you what can you figure out about the
world by observing an agent or a
reasonable person going from the start
to the target and so the first thing to
realize is that there's no one to answer
there are some things that are more or
less plausible and so what we'll do is
we'll represent our belief by a set of
finite samples where a world is more
like to be in the set if it's more
plausible
so it has one belief so we've got free
samples and what this is saying is that
it kind of thinks that the so sorry what
I'm visualizing this by saying the
height of the terrain is is how
expensive it is so the higher is this
more expensive and so what this is
saying is that the the red region is not
very expensive to cross and it doesn't
have any strong belief about the green
region on the other hand if you saw
somebody walk all the way around you
might believe something different that
the red region is quite costly otherwise
why would they go all the way around to
avoid it and so these samples are
actually samples from the publicity
program and system that I've built and
my point is that at least to me it
agrees qualitatively with my human
intuition and so what I'm going to try
to explain to you today is but how can
we build systems which have some degree
of common sense or plausible reasoning
and my claim is that probabilistic
program is the framework to do this so
suppose you know our goal is to build
commander data lieutenant come on the
data I tried to design his positronic
brain so let's drill down a bit on what
common-sense me so we want data to to
realize that if he goes from for example
his his quarters to the to the bridge
and he puts his phaser in his pocket in
his quarters his phaser should still be
in his pocket when he gets to the bridge
we wanted to know that if it takes 10
minutes to go from his quarters to the
bridge that he should leave 10 minutes
before right he wanted to know that if
there's a fire on the bridge that maybe
he shouldn't go there or maybe that he
should run to get there faster and I he
does run he would get there faster and
so what's coming with all these examples
and the previous example is in some
sense how mundane they are how boring
they're easy for everybody to do and at
the same time they require an
unfathomable amount of knowledge for
example the phaser and pocket example to
know that his face is still gonna be in
his pocket he needs them he needs to
know about physics he needs to know that
objects that physically I've studied
objects don't go through each other
these things stay contained he needs to
know even more basic things about object
permanence
for example in the real world things
don't just flicker in and out of
existence the other thing that's come in
in these examples that there's no qu
answer there's any more or less
two things and so we want data to be
able to reason this plausible
common-sense way okay so let's go back
even further and say before we you know
trying to figure out common sense let's
try and figure out the meta scientific
question how should we figure out common
sense and so one way would be to study
how humans but you know how humans
employ their common sense but humans are
complicated and so we're not gonna do
that for the moment we're gonna try and
say instead of how do we reason how
should we reason what are the normative
processes of reasoning and so the way
with this we'll make a list of rules and
it turns out somebody's already made
this list first so we just take their
list I'm sure the first the first thing
on our list is that plausibility so data
is gonna be reason about things like how
likely is it that my cat spot is hungry
for example these statements we should
have signed some degree of plausibility
to them and we running is real numbers
so if you want to think in program of
speech we'll use floating point numbers
the second thing is that whatever system
we the device should agree with you know
in tests at least some qualitative level
with human reasoning we're not going to
study humans but we wanted to agree with
you know basic lon basic logic and the
third thing is consistency and so
consistency this is in the conventional
sense you know if there are multiple
ways to get to some to some conclusion
and all of these ways should drive the
same conclusion I mean also you know
data shouldn't he shouldn't just ignore
arbitrary information you should take
into into account all the relevant
information and so it turns out that if
you make these rules or these orders
which is more formal then there is a
unique set of rules with with which to
reason and these are surprise surprise
the rules of probability and so Cox
wasn't the first person to to show this
he he showed it formally as I've got
here you know Laplace says property in
theory is nothing about common sense
reduced the calculation and I said
surprise surprise but actually is
surprising why should it be that these
rules we have for reasoning about
gambling and chance why should me that
we can appropriately needs to use for
common sense reasoning well another way
to think about it is that in a real
world there aren't that many things
that are actually random it's just that
we have subjective uncertainty so
everyone has a program I imagine and now
we've brought programs and computers
that are extremely deterministic and yet
when I compile upon my programs like who
knows what's going to happen and that's
because I have a person I have limited
you know intellectual capacity and that
introduces uncertainty so there's
uncertainty everywhere and there's maybe
there's some randomness in some places
but it's mostly uncertainty and so the
two main dimensions that I'm going to
talk about are one representation so
we're saying that what we want to do is
build these models of the world how
should we represent least concretely
we're gonna get from the abstract rules
of probability which I don't really
describe yet we're gonna go from these
abstract rules down to concrete
algorithms that implement these rules
and the first question as you will know
is when you do this how do you you know
represent these things in the machine
and the second thing is what kind of
inference questions are we going to try
to answer and I think most of the
different problems to programming
systems that you may have heard of are
differentiated on these on these two
axes so the first perspective is
probably the most conventional one maybe
if you went to the cautious talk he
probably talked about this and the idea
here is that we're going to represent a
model of the world by a random process a
program that simulates that world so
let's take a simple example so imagine
somebody gives you maybe a friend
actually maybe the enemy gives you a
radioactive box
and your goal is to figure out you know
what is the material in this box based
on some you know observations maybe
you've got a Geiger counter you imagine
the radiation and say more precisely
we're going to try and figure out this
parameter lambda which is the premise
for the for the exponential distribution
and we have some private life which is
we just think it's maybe uniform between
0 &amp;amp; 2 and the question is what should we
now believe about lambda
given that we've got some observations
and so the way that we'll do this is
that will stimulate will randomly sample
the value of lambda and then we'll some
poor value of x1 x2 and x3 using that
value of lambda as the parameter and
then we'll check
whether these X values are equal to our
observations and if they are then we'll
keep this finding of lambda otherwise
we'll try again but what's actually
going on here well what we're doing is
we're simulating the world there are
things in the real world which we can't
observe so we'll design a simulation of
that world
we'll check whether all the things that
we can observe match the things in our
simulation and if they do then we'll
look at the unobservable things that we
can observe in a simulation because in
the simulation we can look at anything
as a simulation and so this is a kind of
a neat idea and so here I'm showing the
rule of conditional probability for the
first time and we can see that and so
what the rule says is that the
probability of egg conditioned on B is
the property of both of them happening
divided by the property of being and all
that means is that we're restriction or
we're restricting our world to be so
when you think about conditional
probability
just think about restriction we're
saying okay here's the world now here's
a smaller world and the way we're doing
this in our code we have this while loop
which is sampling and then it's checking
if our condition holds if it doesn't
hold them we try again
so we're restricting by basically
ignoring the worlds where our conditions
don't hold so unfortunately it's not so
easy and maybe something you seem wise
not too easy and it's not so easy
because it's very unlikely that my
conditions will hold if I just randomly
at the track right it's basically
guessing check it's not it's not in
practice it's not very efficient in fact
its intractable so you know in our
fantasies in our dreams the world is
like the left or we can just sample and
get you know good points but in reality
it's like the right hand side or my left
hand side where we can solve forever and
we'll never get good points will never
find simulations which match the real
world okay but this is the main approach
and most of the probability program
languages that you know about for
example venture Church where people are
Anglican they take this approach they
but they use very clever tricks to try
and reformulate the problem so it's more
tractable and so what they gain from
this approach is that is sufficient you
can run these simulations just as fast
as you can run a normal probe
and it's very expressive you can use all
the features in your in your language
you can basically buy it you know any
you can simulate any distribution on the
other hand what we've lost is that now
we've tied this idea of randomness to
our idea of uncertainty and I've said
that we don't need to think about these
things as the same and this problem that
I just highlighted where it's hard to
find simulations which match your
observations always satisfy our
constraints is unavoidable and many of
the you know many of the methods they
use get around it in some sense but the
problem is its fundamental so the second
perspective which is the which is the
approach that we take it's kind of the
purely functional approach let's not
think about randomness so much let me
just go to a demo to show you our
language or our library in action so
this is all built on Julia and you can
try to start yourself Julia box is a
website where you can run these things
in the browser you'll see okay it's
always better right alright so this is
how you would basically add Sigma
actually it's just this such a just
package Locker in Sigma but this is just
updates the latest version and then you
just do used in signal and it's simple
as that and so here's a very simple
model we're going to say that a person
if you know some arbitrary person the
property that they're a man is 7.7 70%
and I'm going to say okay if if a person
is a man the property that they're
mortal is 100% they're definitely mortal
if they're not a man and there's some
there's some promise you point seven
seven percent net and they're mortal and
so we can ask Sigma what is the
probability that a person is mortal and
hopefully Sigma will answer and Sigma
comes back saying okay it's somewhere
between 92 percent and ninety three
point five percent means that these are
bounds on the answer well we can ask a
different question like what is the
property that a person is a man
condition the fact that that person is
mortal right and seeing what
like this as well as between 70% and 79%
or we can ask kind of the inverse
question which should just be true
actually what's the property that person
is mortal given at their man and Sigma
will say well it's between 0.9 7 and 1
we know is 100% but Sigma is approximate
well we can take our previous example
this in a parameter estimation we're
trying to find lambda of this
radioactive box and we can draw many
samples of lambda conditions on some
observations Sigma will think for a few
seconds and then I'll come back with a
bunch of samples and we can visualize
these as our belief about what lambda
should be and so here we can see we've
got some distribution this is our belief
about London remember before it was
uniform and now we have some
observations there's no longer uniform
we can do things which you may not think
of as common-sense reasoning but they're
still kind of cool so imagine you said
okay so how can we sample from the
surface of some shape for example of an
ellipsoid and Sigma you just literally
write down a uniform distribution over a
box and say condition that box to be on
the surface of an ellipsoid so we had we
just have the equation of an ellipsoid
right here and we can generate samples
and then hopefully we can just plot
these and you see we forgot to include
this
and you can see we just got you know
points on the service level of a shape
and you can arbitrarily change the shape
you can change the distribution and
actually I mean it might be quite hard
to figure out how to do this
mathematically but you can just ask me
to do it and it will do it at least
approximately another thing we might do
is you can take a matrix and say okay
how can we factorize matrices into
smaller matrices and so there many ways
to do this but they involve complicated
algorithms and admittedly that you know
the way more efficient and Sigma but in
Sigma we can literally just say okay has
our matrix to factorize
now give me some matrix W and some
matrix matrix H such that the product
equals this matrix right and so we have
the constraint you know W times H equals
matrix the factor is simple as ax and
hopefully if we run this it will figure
it out it might take a few seconds
well what is one is thinking about that
simple you can think that you can think
about Sigma as it as a declarative
programming language so you can think
about it like Prolog but for the real
numbers where we can set we can just
define and constraints and our Sigma to
solve these constraints in a
probabilistic way seems to be having
some trouble if this way Africa seconds
the demigods are hesitant today okay so
we can see it the Heron we just found so
just to make this clear I found two
matrices such that their product is some
arbitrary majors that I chose and I'm
just multiplying them again together to
show that they're actually the same
matrix so if you just maybe it's hard to
compare but for example the first row
here is point two six six point one
three six nine and then we get a similar
you know 0.26 7.13 Center right and so
Singh was given us to correct on so
that's what I'm showing you here so
let's go back to the slides and so how
does it work so the first thing that we
do is separate out randomness from our
idea of uncertainty and so the way that
we'll do this is we'll define a set and
we'll call this set Omega and Omega
represents basically in the universe all
the possible ways that the world could
be and now we have functions from this
set to another set and you can think of
these functions as features so for
example X here X in this example could
be you know does my some coin I flip
turn up heads or tails and so you can
think of these functions as basically
partitioning the original space and the
benefit of this approach is that we've
separated our non determinism from you
know our aspects or properties of the
world and we can connect them all
together by going back through the world
so let me show you what I mean by that
so so these functions are called random
variables which is a bad name because
they're not random and they're not
variables but that's what we call them
but in Sigma we literally take the idea
of a random Breville so lambda hair is
not a sample it has this type which you
know I've defined it around var which is
basically a function it's just a wrapper
around the function and it's a function
so we can you know just apply it to
arguments and so for example uniform
between 0 &amp;amp; 2 all it does it now we can
define it like so it takes in some
argument Omega and then multiplied the
first component by 2 right and it's just
a function it's a sample from this
function all you would do is with sample
a point in omega and then apply the
function to that point right and so
before in a previously in the previous
way of doing publicity programming we
were dealing with samples with
multiplying and adding and using these
points but now where we're dealing with
functions so what does it mean to add
two functions together or to apply a
function to another function well it's
defined point wise and what this means
is that you know if you think about
these functions as boxes you exit the
box and why the box we're going to take
the outputs of these boxes and put them
to the input of + so we're going to
create a new function which is the
competition of the previous one and so
before instead of thinking about our
program as manipulating samples what
we're actually doing is we're building
up a complicated function every time we
using an imperative program which
jewelleries you should all use julia by
the way but we're using a complicated
imperative program to build another
function so let's go through so how does
that actually work how does Sigma you
know find solve these constraints or the
first thing to do is realize that
everything's connected so we have all
these random variables and then we'll
define in the same space and they will
they will connect it through the same
space so if I know something about why I
know something about X and sand and vice
versa and so but this you know just
using the functional paradigm doesn't
solve all our problems we still have the
same problem that we need to find
simulations in the world which match our
observations always satisfy our
constraints we still have this you know
trying to throw darts into an infinite
dimension or very large dimensional
space and so the the solution we take in
Sigma is to not consider a single point
at one time we
to the sets of points at a time and so
the first question is how can you
represent a set where we represent a set
by a lower and upper bound in in one or
multiple dimensions so the basically
high dimensional boxes and before we
could always just check you know one
point does it satisfy our constraint or
condition or not now that we have sets
it's a little bit more complicated right
so it could be that all of the points in
my set satisfy my constraint which is
the green case it could be that no none
of them thing which is the red case or
could be mixed some of them might have
some of them not and so we have an
Oracle we're gonna say we have a
constraint solver which is basically an
Oracle which can determine which for any
given box which one is it is it the the
red green or pink case which we want to
call true/false and true/false
but this by itself doesn't help us find
points in you know that satisfy our
conditions directly does it doesn't help
us find simulations which match the real
world we have to we need something else
so what what they will play a game with
this Oracle will play a game with the
constraint solver and you can think of
this game like a kind of a binary search
but in a multivariate continuous to mean
and so what I mean by this is going to
start with the whole the whole of Omega
the whole all all the possible you know
points in the universe I'm gonna ask our
Oracle this question we're going to
create this Oracle with this box and the
Oracle is going to come back saying well
for this box there are some points which
you know satisfy your condition and some
points that don't we have this pink this
true/false case and so in this case we
split the space in half and then we ask
the Oracle again for both halves and so
at any point in time we're going to be
inspecting one particular box and so we
ask the question we ask the question
again and the Oracle comes back saying
or is the same situation and when this
happens we randomly choose one side in
this case we want to choose the right
hand side and then we split I mean and
we asked again and now they're all said
well that top right box is empty there's
no points in that space which will match
which will match our conditions and so
this forces us to choose the lower right
hand side and we keep on playing this
game beginning
again until we eventually find a
simulation that matches our conditions
so just in the same way that you can
very quickly narrow down on the spacing
of using a binary search we can do the
same thing in this in this continuous
domain to find points which satisfy our
constraints and actually this person is
a little in what can be very biased so
we use some standard statistical
techniques to kind of account for the
bias so we actually get the samples
towards the correct distribution one
extra point is that in many of the
examples I showed you these constraints
may be like infinitely small lines so
you may not be able to fit a box inside
of a line so what we do in Sigma is that
you give it a problem and it relaxes the
property and weakens it into something
that's easier to satisfy and this is
both practical and actually it's
fundamental to get around something
decided with the two issues and so what
if we gain from this approach well we've
separated randomness from our modeling
even though we using randomness and we
using many techniques to sample the
model itself is this pure function we
just have these these procedures which
work with it with these functions and
we've we've also this was the second
point but the first point is that we can
condition on things which are hard to
satisfy for those examples that I showed
you I don't know of any other problems
of programming systems that can can
solve these problems maybe you can go
through some you know strange
transformations and relaxation to make a
solvable but in Sigma you can say the
problem directly and what have we lost
while we've lost is known as the fishing
we have to work a lot harder to generate
a particular sample any sample and we're
no longer universal you can't describe
anything in Sigma although it's very
expressing you can describe with most
things but not everything okay so the
third perspective is that distributions
as as unnormalized densities and I'll
describe what that means but first I'm
going to show you some cats so this I
don't know how many people have seen
this work well this is quite recent work
and the idea is you so you give this
system
an image of a cat for example and you
also give it an image of your favorite
artist and it tries to recreate the
image of the image you gave it in the
style of the artist and the point is
this is this is not a kind of a simple
Photoshop filter it's really trying to
capture the abstract properties of the
art and so let me show you some more
examples all of the same all of the same
cat and you can see they're quite
impressive right
and so the reason why I showed you this
example one it's cool but also it points
out that some things in the world are
complicated people in statistical
modeling and scientific modeling other
thing about the world is quite simple so
we can use simple more simple rules in
the mathematical equations or programs
to describe the world but sometimes it's
really complicated most of you could see
a Monet painting and say okay that looks
like mo named Peyton but then you write
down the rule the the algorithm that
describes you know whether this is where
whether it's not so you know Einstein
said yeah when a number of factors
coming into place too large scientific
methods in most cases fell so this is
kind of depressing maybe we can't figure
out you know all these interesting
things that humans are able to do on the
other hand humans can do them and save
Adam a bat'leth who is a famous computer
scientist who developed FGM she says we
should approach complex worlds from a
different perspective or different
different position than simple worlds
once you give up explain ability to gain
better predictability and so we're going
to take this idea and we're gonna try
and think about an interesting problem
which has both simple well a simple
simple structure and also a complicated
structure and so going back to command
the data we have you know we want we
want data to be able to see I wanted to
see the world when it's the other you
know from some image images going into
the camera eyes that he has to be able
to figure out you know what is the 3d
structure what is the texture where the
lights were am I in position relative to
the rest of the world and you can think
of this process of vision as as as I
said here it's going from an image to a
3d representation of a scene with all
that entails like a function but at the
same time it's not really a function
right because there's not enough image
it's not by jected function there's not
enough image sorry there's not enough
information in the image to
deterministically determine what the
scene is for example you can see me
right now you can't see my back but you
don't imagine that there's flying tiny
elephants behind my back right or a
circus this is implausible right so some
things are possible but there
plausible and so this is why I argue why
vision is maybe the most common of
common-sense reasonings
everybody can do it but it requires
portable probabilistic inference the
second thing is that we know how to
invert this process anybody who's
watched the movie or video or played a
video game knows that we can take 3d
scenes and render them into 2d images
right and we can do this in a way which
is fairly simple and it's simple because
physics is relatively simple at least
our understanding of it and so what
we're going to try it and do is take an
observe image so I should say that I
can't do this yeah I mean I'm going to
show you some very simple examples but
in a previous slide I had this citation
where they did some much more impressive
stuff than I'm going to show you but our
approach is quite different and I hope
that hopefully in the end it will pay
off and so the idea is that we have some
observed image and we're going to take
we're searching for a scene such that if
we render that scene the difference
between that rendered scene and our
observed image is is 0 or is minimized
why does that make sense and at the same
time for the reason that I just said
about you know these fine elephants we
also need some constraints on
plausibility so we're going to define
another function which is going to be a
function from our scene and it's going
to you know for every scene it's going
to assign a plausibility value right and
in fact the lower the value the more
plausible it is and so we're going to
try and do a joint minimization of these
two things one thing is making sure that
these scenes are plausible the other
thing is making sure that these these
scenes render to the actual observed
image and so here has very very
preliminary results and so what I'm
going to show you on the right hand side
is is the the target image and this
target image is your your observed image
and on the left-hand side I'm going to
show you the the optimization process
but remember we're not we're not
my pixel space we're optimizing in the
scene space and I'm just rendering it so
that you can see what's going on and so
it starts here and then you can see the
the random inaugurate also the
optimization algorithm is is making some
changes it's basically searching now
it's decided to increase the light
because light is another parameter in
the scene so everything's overexposed
that wasn't a good idea so it goes back
and you can see it gradually provides
the hip so you can see the overall shape
correct but I got all the colors the
wrong way around so this is the extent
of my of my work in this area so in in
the in the previous diagram I had least
these three functions one was this
likelihood function which says how close
was the scene the other one was this the
ray tracing function or the rendering
function right and the third one was
this comparison function so the
rendering function is as I said is quite
simple to write down in any language but
it's very hard to optimize it's not I
don't know how much people know about
optimization but in optimization we
generally like smooth surfaces where we
can find a gradient we need a gradient
as well to find out how to go down and
minimize the cost the like that the
plausibility function we don't know how
to write this down we want to learn this
from data and also the comparison
function is is not as non-trivial you
could just compare the pixel level which
is what I did which is why it doesn't
work so well but we want to compare in a
more abstract sense so one question is
can we combine all these things and so
for the for the cats I show you earlier
they did this by using neural networks
deep neural networks which are current
you know gain a lot of buzz reasoning
but how should we think about deep
neural networks so for anybody who
doesn't know a deep neural network is a
is basically a pure function and it's a
pure function composed of composed of
nodes and into these nodes are these
edges and you can think about real value
numbers or real numbers going into these
nodes and they get multiplied by a
weight which is associated with the edge
so if you want to think in matrix terms
I've got
I'm made for it you know for any
particular note I've got a matrix of
values going in I've got so a vector of
values going I've got a vector of ways I
do the dot product I multiply I do a
point wise multiplication in a nice Sun
all right and then we apply a
non-linearity to the output and it's
non-linearity is necessary to allow
these functions to you know to find all
the interesting features otherwise you
just have linear functions so another
way to think about a neural network is
that the program in a program in a
programming language and in this
programming language you only have three
operations plus multiplication and some
non-linearity nominee is the sigmoid
function or even simpler as dot products
and nonlinearities so one question that
you might have if you take this
perspective is can I can we take what we
know about programming languages and
what we know about your networks and why
they can do these interesting things
then combine them and I know have the
answer to this I mean we're working on
it but just to examine it a bit closer
in a programming language we have
composition and modularity right you can
make really complicate things by using
simpler things and combining them
together your networks for the most part
don't have any of this and then a few
parts that they've added have led to
really impressive games right for
example convolutional neural networks
which were used I think for the cat
example they have a degree of of
modularity they have shared weights so
can we take this idea further take all
this knowledge that we have about how to
compose functions and use them and use
them in a neural network sentence and
what's good about neural networks while
they're smooth you train these neural
networks by doing optimization for this
smooth space of parameters and we learn
in your notes we learn multiple layers
of representation right and so this is
the kind of a strange a funny term but
normally in programming language we
think about okay I'm going to represent
my data as this string of bits or as
these fields in some some object or
class in your own networks all of the
all of the data is represented
throughout the entire network and so
again I don't have the answer to this
question I have some ideas but maybe we
call
everybody thought about how can we
combine you know what's good about on
your now because your network is a is a
program it's a form of computation and
it's a universal form of computation we
make music in the same way to describe
normal functions or probabilistic
functions densities and so on okay so
I'm gonna wrap up I have you know three
three three main points the first point
is that the question and what is common
sense I'm arguing that common sense is
conditional inference in a variety of
ways this conditional probability
inference when you have a rich way to
represent the world and the only way
that we currently have to represent the
world are programs which are actually
rich enough to represent the world so
what is probably a program one is the
same thing I showed you three different
ways of doing probabilistic programming
and they're all trying to approximate
this simple rule of conditional
conditional inference my last point is I
can does this have any bearing on on
normal programming the kind of stuff
that you do every day
well Sigma as I said it is very
declarative and it's a it's declared it
can be declarative because we have a
advanced solver and so I think there's
going to be a shift I mean they're
already or there already is a shift from
smart people and kind of stupid
compilers to slightly small compilers
and styling stupider people right so
maybe there's this this is going to
continue and it should continue so we
can write programs in the way that we
want to write them as you know as
experts we've become very used to
writing very complicated details and but
it's it's not simple and it shouldn't be
necessary eventually and the other thing
I want to want people to think about is
representation one thing we do in
programming languages is we use we
represent things I don't think we've
acknowledged enough how much modeling
actually goes into our languages why do
we have objects and classes we have this
because they represent things in the
real world and we've kind of taken a
naive a naive model of how to represent
concepts I mean let it run for 20-30
years so maybe we should go back and
accept that we're trying to model the
world and model it in in more in better
ways which you know people have been
studying in many different fields how to
do so that's all thanks everyone for
listening you can check out the github</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>