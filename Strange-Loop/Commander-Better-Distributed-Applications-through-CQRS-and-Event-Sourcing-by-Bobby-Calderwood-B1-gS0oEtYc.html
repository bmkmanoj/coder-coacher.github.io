<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Commander: Better Distributed Applications through CQRS and Event Sourcing&quot; by Bobby Calderwood | Coder Coacher - Coaching Coders</title><meta content="&quot;Commander: Better Distributed Applications through CQRS and Event Sourcing&quot; by Bobby Calderwood - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Commander: Better Distributed Applications through CQRS and Event Sourcing&quot; by Bobby Calderwood</b></h2><h5 class="post__date">2016-09-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/B1-gS0oEtYc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Bobby Calderwood I'll be
giving a talk today on a pattern that
I've been using called commander for
building distributed systems and how it
works
just by show of hands who went to David
McNeil's talk yesterday on distributed
transaction logs distributive logs nice
y'all can leave no not not quite we've
he and I had a good conversation in
hallway after and it's good one other
you know when smart people that I've
seen speak other places and admire have
similar ideas so he his talk was about
how to use Amazon Kinesis to do sort of
your disturbance logging stuff this talk
is more about how to how to use that
really powerful primitive the
distributed log to build systems so
there's a couple of little patterns a
little bit of structure just enough
architecture maybe two to really
facilitate building distributed systems
in a way that's easy to reason about and
has some other nice characteristics that
I'll talk about it the particular fit my
my problem space
I worked Capital One Capital One is an
awesome awesome place it's a it's this
like giant Bank that's trying to become
a technology company and to that end
they've they've hired a group of people
called the technology fellows that's
that's the team I work on and yeah we're
trying to help capital make this
transition into becoming a technology
company we're hiring that's the last
I'll say about it come talk to me after
if you're interested in working at a at
a bank that's trying to change the way
people interact with their money so that
it's safer and feels less emotionally
draining to interact with your money
sort of changing changing how banking
works and at Capital One I have a
particular problem space right I've got
this this scale problem like we've got a
lot of transactions that come in via
credit card swipes and bank transactions
and all kinds of other stuff people
interacting with their their money on
their mobile phones we have really great
mobile apps and they're interacting with
it you know a lot of times for a second
we want to provide them an excellent
user experience we also have a security
and compliance burden right like we have
a lot of regulators who like sit right
next door to our internal auditor is
like you know have this building next
door so we've got this sort of
operational constraint in that respect
we also want to be able to like
new features easily and operate it
cheaply and that's probably the biggest
constraint is that we're all trying to
do this with like 7,000 engineers across
this really large organization right so
it's we've got some sort of
organizational challenges how do you
engage that many engineers to contribute
to solving these really hard problems
safely in a way that they can easily
organize mm-hmm so the big idea is that
that this sort of problem spaces has
forced me into as well as my background
I worked at cognate X with rich Hickey
and sue Holloway building the atomic and
so a lot of these ideas kind of come out
of that background I've a background in
functional programming in closure and
other languages that are similar and so
immutability is a big deal to me right
that's no joke mutability if we don't
want global mutable state in our
programs why do we want them in our
distributed systems in this database
right there's a couple of great talks
that rich is given on the language of
the system being sort of more important
than the programming like runtime
language of any given component in that
system right so this is I talk about
systems thinking a lot of the principles
that I'm going to talk about like CQRS
and event sourcing having the past been
applied to like how do I organize my
classes in my Java you know source
hierarchy this is less about that this
is more about like systems thinking how
do I get these components maybe maybe
even call them micro services if you
want how do you get them to sort of
cooperate and do something useful so
we're gonna apply these these techniques
that have traditionally been applied to
sort of source code architecture and the
small - to the larger distributor
systems architecture another idea that
that's become important to me and that
this is born out of Bay Tomic and then
I've built other systems this way that
I've really liked is that action of
perception are not the same thing in our
in our systems but a lot of times we
model them as if they were right if
someone's walking across the street that
person doesn't slow down the more people
that are watching them right that would
make sports super boring because the
more people are watching like they'd
slow down because there's resource
contention for like watching them know
Herc's right perception is a
fundamentally different thing from from
action and and yet we sort of model
model things badly sometimes in our
systems and finally the last insight
that I've had that's become important to
me in the last little bit is that sort
of - organizational behavior sort of
sort of observations one business
services are not databases even though
sometimes we think of them like they are
we've modelled them it's like these
little mutable databases they're event
stream reactors they do a lot more
things than just like write data down
right we take complex interactions we
get information in from the universe we
do a lot of important things one of
which is almost certainly writing data
down someplace so we can remember it but
we also like communicate back out to our
users and cause side-effects via
third-party service providers and do all
kinds of other stuff that's not just
writing writing stuff down so businesses
are better thought of and our services
in particular better thought of as event
stream reactors then as like tiny
databases and finally the other
organizational concern is that
cross-cutting concerns have to be
satisfied in the presence of Conway's
law I've spent a lot of times in
startups and I've moved over into the
sort of rather large organization and
Conway's law is totally a thing right
we'll talk about what that means a
little later in the talk hmm but we have
to solve these problems in a way that
that respects the idea that different
parts of the organization are going to
make their own little piece and that the
overall system architecture is going to
start to resemble like the org chart and
how we talk so let's use that to our
advantage instead of to our detriment so
this is sort of a typical architecture
that we use to solve these big complex
sort of information service problems at
scale right we've got like a rest
endpoint or something out there on the
web like exposing data and actions to
users and then within that same sort of
micro service it's not really micro it
does way too much but within that same
service we'll have like a bunch of
business logic right so a user will send
in like an action-oriented request maybe
a post or a PUD or a patch
whatever and we'll take that in that's
like the red like cross thingy and then
we'll think about it really hard what
are we gonna do about this what are we
gonna do about this what are we gonna do
about this and we'll make a decision and
we'll write that decision down to the
database and then later they'll come
along and make some other requests maybe
at the lead or a PUD or something that's
kind of mutating me and we'll go in and
we'll think about that thing really hard
and we'll go back and find the first
decision we wrote down and we'll change
it so now we've actually lost data twice
we lost data on the way in because we
didn't write down exactly what our
customer wanted from us we just wrote
down what we decided to do about it and
then we lost data again because they
came along and they changed the
consequence the decision that we wrote
down in the first place so we've
actually lost data twice in this system
this is a data lossy system not from
hacking not from negligence but by
design we've lost data so that's that's
bad
later on the boss comes along and says
hey we have a security compliance audit
requirement for this service that you're
writing so we're gonna need you to like
type off a stream of actions so some
message queue or write it to a log or
something somewhere so that our auditors
can see what it is that our that our
customers are asking us for and and to
make sure that we're doing the right
thing in response to their actions and
that's really important in an
organization I think in a you know
interesting like banking a bit probably
in many of your industries as well you
need something like that to reconstruct
the narrative of what's happening in
your services to make sure you're in
compliance with regulations to make sure
you're serving your customers really
well whatever whatever reason you need
that you probably need it later on the
boss will be like hey I want like an
analytics dashboard to show me you know
how things are going in your service so
now say okay what are we gonna do now
we're gonna like ETL out of our primary
database and and build a pretty picture
for the boss and that's all these things
are always like an afterthought so
that's bad so I want to sort of address
this this problematic architecture in
the context of those big ideas I
mentioned at the beginning of the top
first one immutability there's a pattern
known as event sourcing who knows
immense sourcing who knows what that
means awesome I don't have to spend very
much time on this
so event sourcing is a way of modeling
your systems where you store all of the
events that build state rather than just
an aggregate picture of state so if you
think about a chessboard or a chess game
you can either model the chess game in
your software by capturing the current
board state or you can capture chess
notation
you know pawn to f3 or whatever I'm not
gonna chess so there's a bad analogy but
you can capture all of the moves in
chess notation the benefit of doing it
in the event sourcing way is that you
have the whole story of what's happened
and you can always go from that story to
the current state but if you just have
the current state you can't go back to
the other way you can't rebuild the set
of moves because for any given board
state many different narratives or
sequences of events could have led to
that board today right so it's a lossy
way to store things when you're just
storing the present state if you store
the whole narrative and you can always
reconstruct the current state
that's a vents or Singh we've talked
about sort of data loss by design we're
losing data in two ways here which is
bad because we're not storing the
narrative we're not storing exactly what
our customers are asking us for we're
just deciding what to do about what our
customers ask us for and then we go in
like mutate a database somewhere and
then we let them like delete and update
stuff which is also bad language system
languages being more important than than
runtime languages in this architecture
like what is the system language this is
the language is the runtime component of
this like grey box right if that's Java
or whatever then by defaults and not by
design but that's just sort of the
pattern we fall into we don't really
construct a data language for this
system we don't construct you know
contracts and stuff we like pawn that
off on the type system or upon that off
unlike our conventions around how we
call methods or whatever like our
internal API design becomes the contract
but then it becomes really difficult to
integrate with like other services
outside of my language runtime then I
have to like explicitly like you know
design a thing okay maybe I'll expose an
internal rests interface to admins or
whatever internally but doing that kind
of again it's always an after
in these in these types of systems
action is not the same thing as
perception we talk about that a little
earlier another way of saying that is
rights or not same thing as reads and
that's true on a variety of levels
operationally at least most of our
systems we design are like 80 to 90
percent read load right because people
are you know constantly checking how
many transactions they have on their
credit card or whatever and only about
10% write load where they're like I want
to schedule a bill payment so you know
operationally they're different we've
already talked about sort of
semantically how they're different and
yet we model them using kind of the same
device right we've got like this end
point and you can either like get stuff
from it with a get request or you can
like change it with these other you know
these other verbs that sort of couples
operationally it couples them together
from a data model perspective it's sort
of couples them together and we try to
smash our business domain semantics into
the like resource that we expose via the
web and then back in our database we've
got like the grand compromise of the
third normal form right which is sort of
essentially a compromise between right
time performance and read time
performance right it's kind of fast ish
it right and then it's kind of fast ish
it read but both times it's doing a lot
of work back there to get it into the
format it needs so this the third normal
form because we use that same model for
both reads and writes it ends up not
really being performant for either and
it's certainly like couples then
semantically together again another big
idea business services are not databases
I have sort of this this theory that the
it's not my theory the tools we use sort
of shape our psychology right if you
start using a tool it's actually you're
using the tool and the tools using you
it's like changing your how your brain
works and I think we we've worked with
databases for so long and vendors have
aggressively sold databases to like our
senior leadership to the point where we
start to like we start to think of our
business services as if they were these
these databases right so that that
abstraction leaks out into how we expose
data on the web right rests I like rest
please don't don't throw stone
but the common practice of rest is often
just I'm gonna make like a tiny database
and model it as your eye endpoints right
but it's gonna be this like kind of
mutable mini database because that's how
we think and that abstraction is leaked
out into the front-end back in the
backend all of our business logic is
sort of central and influenced heavily
in this sort of dance with art with our
data model that we've that we've stored
a schema in the database so it becomes a
little bit of a leaky abstraction and I
think that's that's kind of a bad thing
Conroy's ah yes this is a thing who's
heard of Conway's law cool I have loved
coming to Strange Loop because like I
don't have to spend a lot of time on
this stuff organizations which to design
systems are constrained to produce
designs which are copies of the
communication structures of these
organizations that's kind of interesting
I've seen this I've seen this the enemy
is us this really does happen in in
large organizations and here you know so
given that that's true right a law in as
much as anything in software could be a
law you know that can either help you or
it can hurt you just like the law of
gravity can you know I can either fall
off the stage and hurt myself or I can
like sling a rocket to Mars right you
can use these laws to get leverage just
as much as they can hurt you so let's
use Conway's law see if we can make it
make it happen for us given the Conway's
laws of thing given that we have these
cross-cutting concerns right concerns
that are are not just the primary
business logic and like storing stuff in
a database we've also got these other
things we need to send like push
notifications to our mobile users and we
need to have this sort of audit trail
for the security and audit folks and we
need to do all these other things that
aren't sort of the core purpose of this
little micro service how do we do that
in the presence of Conway's law how do
we do that in such a way that like the
audit and security people are
responsible for the audit and security
piece of that and the Big Data people
are responsible for like the analytics
piece of that in this model you can't
write you have to contact the team that
built this thing in the gray dotted
lines and ask them to like add
feature into their language on time
because it's all I can't a couple and
bunch together so we solved this by like
libraries and injecting whatever its
spring beans or something in there to
like automatically do this kind of stuff
for us that's a terrible idea
don't do that so I think we can do
better than this obviously because I'm
giving a talk here there's this
architecture that I've been using and
working on and speaking about called I
call it commander and I think it's a
better way of sort of modeling our api's
and services so that their log centric
reactive and and they still expose the
nice properties of rest that that our
API consumers have come to expect and
that you know really facilitate quick
and easy discovery and delivery of
services that then interact with them
the commander architecture when I say
commander I actually sort of mean two
things unfortunately I mean the
architecture at large and then I also
mean a specific component within that
architecture the command architecture is
kind of like rest plus CQRS plus like
immutable logs plus reactive event
stream processing so it looks like the
command architecture is this whole
picture the commander component is is
this piece in the upper left but you see
here we have CQRS because this commander
component in the upper left here is the
right handler in the whole system that's
the thing that you talk to when you were
when you want to assert that actions are
happening right you send commands to
this thing which I'll talk about in a
minute what a command is and then it's
only job really is to write it down to
Kafka or write it down to the immutable
log which which in this implementation
is Kafka so it's a really small job it's
really fast it can do other things you
can do like authorization and
authentication to secure who can do what
it can also do schema conformance and
validation to make sure that the action
that we're sending is something that
we're competent to deal with in the
broader systems way of thinking so it's
basically the way of kind of protecting
what ends up on that on that Kafka topic
for commands and it writes it down to a
topic called commands then in the
backend you have these reactive stream
processors that sit there and say hey
someone's trying to create a user or
transfer money or whatever and it pulls
that immutable value off that log it
doesn't pull it off that log be really
clear it perceives it from that log and
and does something right it decides if
this is a good idea size if this is
something we want to commit to and then
it writes a corresponding event so in
this picture the benefit here is that
we're writing down the story of exactly
what our users are asking us for right
we're not thinking about it and like
making a decision and then writing down
the decision we're writing down exactly
the narrative of what our customers want
from us I want you to transfer money not
like I want to transfer money so we go
to like the money table and you know
subtract from column a and add to column
B right we're just capturing the fact
that our customer asked us for this at
this point in time okay and then the the
business logic reacts to that and writes
down an event so the pluses or commands
the Diamonds our events and then later
other micro consumers downstream consume
the event stream and then writes other
other topics as they want to to
coordinate whatever other work they need
to do and we populate a read optimized
view of what the the business logic
wants to do and then that can serve as
the basis for you know read read only
rest api's that serve as sort of a query
interface so you have a command
interface which is commander in the
upper left you have the query interface
which is down in the lower left there
and we're expressing our actions in the
in the language of the business domain
right we're not expressing it as like
sequel insert statements we're not
expressing it as as complex you know
classes in Java or functions and closure
or whatever we're expressing what the
user wants in a data language and this
data language serves as the lingua
franca of the whole system that all
participants in this system speak a
command is this a command is a an action
and a data I want to transfer money like
that and the action is always phrased in
the imperative this is something that's
coming from the outside of our system so
we don't try
yet this is not something that we've
asserted has happened this is just
something that we know is a request from
outside of our system
for some for some action to happen
transfer my money please an event after
it's been processed by the by the
command processing logic is something
that's whose action is phrased in the in
past tense this is something that's
occurred we've processed this via
business logic and this is something
that we want to happen money transferred
it's done it's feed to complete and it
can have you know a data payload we
track the parent you know what upstream
command or event led to this particular
event so you can track the data
provenance back and and see cascading
causal linkages but this is this is how
an event is shaped they're very similar
you notice I both have sort of this
action and data key but it's a very
simple structure and using this schema
you can express essentially anything
that could happen in your systems right
I want to transfer money I want to
create a user I want to issue a discount
to people who have purchased three or
more things since November but haven't
been back since right I mean there's a
lot of things you can express using this
using this schema and it separates
action from perception as we talked
about there's sort of this this
distinction and that's the secure eyes
bit what's neat here is that from one
log one business oriented domain level
log of things that are happening our
system we can create as many data views
of that of that set of events as we want
and we don't all have to agree on schema
and we don't all have to agree on on use
case or operational characteristics
right all the different groups in the
organization can create the data view of
this series of business events that
matters to them without coordination
with anyone else
talk about kind of how that how that
helps in a little bit again we talk
about this we write down everything just
as its intended and then these these
read and query api's are are completely
decoupled from the right paths in the
application
the other thing to note here is that
commander and the upper left there the
right handler doesn't know anything
about your business domain other than
maybe a schema of you know this is a
valid action and when you have this
action the data payload needs to look
like this roughly but that's all it
doesn't know any business domain
semantics it doesn't know any business
logic it really is just sort of the
right handler in the whole distributor
architecture and by building it this way
it allows us to exploit Conway's law
rather than collapsing under its weight
so in this case you can clearly
distinguish the responsibility that like
the primary service team has right so
this would be like something in the line
of business that's really close to the
customers it's providing a direct
business service to these customers it
knows the customers use case it knows
the business logic it needs to be sort
of primarily focused on pleasing and
serving that user so in this case the
primary team is responsible for
implementing that the command processing
business logic which is a really small
job right that is like a function or
like a class it's a really small thing
and you can read it and kind of one one
page in your editor a small amount of
business logic usually right sometimes a
more complicated domains and then
they're responsible to implement at
least one micro can micro consumer that
populates a read optimized view that
serves as the basis for these these
query api's which they will will write
and provide right so they don't provide
commander or really even have to worry
about it operationally they just send
their actions to commander they
implement on their own these query api's
and that can be whatever they want it
can be this restful like beautiful you
know rest afar en temple or it can be
like Falkor or graph QL or whatever sort
of representation they need to expose to
their clients they can expose that and
not worry about trying to please other
actors within their organization right
the enterprise like the central team
that's not as close to the customers but
is trying to provide like cross-cutting
services can provide commander the web
service that takes in these these
actions it can run you know Kafka or
whatever you're using for your event log
and then it can provide other micro
consumers
non-application core things like
analytics and auditing and operations
metrics and monitoring and other other
types of concerns and they can do this
without any coordination whatsoever with
the primary application team so the
application team is freed up to just
focus on the business logic that's gonna
delight their users the central teams
who have you know have to for legal
reasons you know take a an audit of
what's going on across their
organization or for Operations purposes
need to get some metrics on you know how
many of these actions are we taking in
per second or whatever or want to build
pretty pictures for the boss to get a
feel of situational awareness of how the
business is going they don't have to
know or talk to the application team
they just read off this stream of events
because the same language the same
lingua franca that's used to build the
primary application service is precisely
the same language that all these
cross-cutting concerns have access to to
build their concerns right it's this
data contract that everyone's kind of
leveling the playing field right now the
application team isn't in this
privileged position and everyone else is
a second-class citizen who has to like
go beg that application team to pipe me
off some data someplace or ETL data out
of your database to me please
now everyone's speaking the same
streaming kind of real-time data
contract language so what is this was
the command a component bring us talked
about this a little bit before it's the
single writer in the system so I worked
on a database a few years ago called the
atomic which has a very similar
architecture but it's sort of the atomic
it is constrained to doing the data
oriented stuff right that's at a much
lower level than what I'm talking about
here that's like you know which facts do
I want to assert at any given time and
it also has a single writer called the
trans actor that takes in these rights
writes them down to the immutable log
populates the indexes and stuff so that
we can so we can query that data later
so if you take that sort of architecture
and zoom it out to now instead of data
domain language you're talking about
business domain language that's sort of
what commander does so commander axe is
like kind of the trans actor ish
component in this in this broader
business
system its job is taking in rights
validate make sure that the structure of
those rights looks reasonable and then
writes it down to Kafka
it's very performant cuz writing in
Kafka is a very small thing it's fast it
ensures schema conformance as we talked
about it also indexes all the commands
that come into the system you know that
come across that that commands topic and
all the events that are cascading
results of people processing those
commands into events and it indexes
those so that you can have sort of a
read view so you can perceive the events
and commands going on in the system so
it exposes that via you know your your
typical get at a collection kind of end
point to see all the commands have
happens and it provides a server sent
events interface so that your clients
and JavaScript or whatever can be
sitting there getting pushed a stream of
new commands and events that are flowing
through your system now how do we
implement so I've talked about commander
the little bit in the upper left how do
we implement the the reactive pieces
like the command processors and the
little micro consumers that are
populating read-only views or pipe and
stuff out into some analytics view or or
you know doing financial auditing or
whatever how do we implement those
things for me and Kafka the answer is
also in its Kafka streams who's used
Kafka streams before it's pretty new the
relatively recent in in Kafka 1000 but
it's a really great feature and what it
allows you to do is express in an API
somewhat similar to Java eight streams
or transducers in closure you can
specify given a set of source topics you
know map you know so each each event
that comes across those those topics do
X to it and then you can basically
reduce those out into another set of
output topics so this is precisely the
way that I would use to implement where
those go those micro consumers and
command processors cuz that's exactly
the job right something comes in I think
about it and do some stuff and then I
write out to another topic I may have
caused some side effects along the way
writing to a database
whatever but that's a great way to
handle it so the Kafka streams was sort
of like I was thinking about this I was
working on the architecture kind of
trying to tighten it up and then the
Kafka team like drops Kafka streams on
me that's like perfect so this is what
Kafka streams looks like you don't need
to read the thing this is primarily
there to like demonstrate how small this
is this is the command processor for
like a customer service where it takes
in the customer created action and for
each one of those things it emits are
sorry we're mind it takes in the
customer created command for each
command that it sees on the commands
topic it emits a customer created event
it's a very small job it also along the
way stores in a local store in like our
local rocks DB cache is how the
implementing capsule streams it stores a
created customer here's the the customer
store again a very very small thing
where I can you know drop a customer in
there I can list all the customers that
are there and I can list the specific
one by ID so I'm gonna show you how that
kind of works I can see what you're
looking at here is the swagger UI for
the commander interface if I I like that
collapse it's a very small API you can
like list all the commands you can
create a command and you can list or get
a specific command same thing with
events you can perceive the events that
are going through either you know
paginating over them in a collection or
looking at a specific one by its ID so
the API is very small here for
interacting with commander it's just
about writing down commands and
perceiving them once they've been
written down so here we we've got a
command that we're gonna send we're
gonna create a customer oh yes
absolutely
Thanks
how's that look visible cool 1/1 yes
from the back so here's a customer here
the action is create customer the data
payload is you know first name last name
address whatever so we can try it and
sure enough we got back a response body
telling us ok here's what that looked
like once it got written down to Kafka
it gives us a 202 the semantics of HTTP
202 is like yep haja working on it come
back later and check out what happened
that's the default is an asynchronous
right where I write down to the commands
topic and then I return back to the user
saying I get we heard you there's also
an option up here for a parameter called
sync if I send sync true I'm actually
specifying that I want commander so that
they're waiting for that command to get
written to the commands topic to get
processed by some business logic and for
a corresponding event to be written to
the events topic and then I'll return so
you can provide the illusion of
synchrony because you've got you've
these very simple primitives you can
either have the async default or provide
the illusion to the caller of synchrony
that by the time it returns with a by
the time it returns with a 201 created
that command has been created handled of
course mining event has been created and
here now we've got in children we've got
the the corresponding event ID that was
created all right everyone fallen so far
the other service that I have running
here is a customer service that's the
like read-only perception API it's kafka
streams app I showed you like the vast
majority of the code on the prior two
slides it's a very very small thing but
its job is to just sit there waiting for
this one particular event there a
command type to come through it then
creates that in its local view of state
and emits the event saying yep created
we're good and if you can see here's the
number of current customers and it just
went up because we just submitted to
customers there if you come back here
we can we can certainly perceive the
commands you know by grabbing them and
we can see you know hey we've got we've
got these commands and we can paginate
over them and we can see the history in
in order of what's happened in our
system or we can grab you know
paginating slices of ad or whatever same
thing with events I'm not gonna show
that see it's the same thing essentially
we can also list and perceive the the
the sequence of events that have led
this so this is a really powerful set of
primitives it's a different way of
thinking about things
but it's a way of building these systems
that you just write actions someone else
implements the business logic probably
and then you can perceive the the
consequences of that separately so in
summary the important jobs of of these
distributed systems are to capture
customer intent to write down what it is
our customers want from us write down
that whole story so that we can serve
them better and so we can involve our
business logic incrementally right if we
don't know exactly how to handle all
these events right now or if the laws or
the business logic changes in the future
we can just go back to the beginning of
the story of these events and replay
them into the new business logic and
build a new view of the world according
to this new business logic it's a very
very powerful stuff in banking there's a
particular use case for doing that where
a customer with certain special
conditions can come to us and say hey so
this is service members military service
members can come to us and say hey two
years ago I was deployed on active duty
and we have to go back and you know
recalculate their interest rate at a
lower interest rate that's fixed by the
law and take away certain classes of
fees and whatever and reimburse them
when all you have is like the current
state of the world in your database
that's really hard but if you have this
sort of narrative of all the
interactions we've ever had with our
customers in business domain terms you
can go back and replay that and make it
right by your customer you can serve
your customer better because you
remember what they've asked you for
instead of just what you decided to do
about it in version 1.1 of the
logic the other powerful note here is
that this type of distributed system
does not require temporal or
organizational coordination between the
implementing teams of the various bits
here right in in the typical sort of
HTTP micro services world I have like a
runtime liveness requirement anything
that I call at runtime has to be alive
and there's you know great things like
histories and all that to to paper over
that but the fact is if this other thing
that I need at this time isn't alive I'm
down in this world that's decouple
temporally right one service can write
something down to a topic and and forget
it ever happened at some point in the
future maybe immediately or maybe after
it recovers another service downstream
can consume that event do other things
and that you don't have to have that
temporal coordination and you also don't
have to have organizational coordination
right these teams don't even have to
know about each other they're all just
speaking this common lingua franca most
of these ideas are not mine I'm using
them and profiting from them greatly in
my personal work and I hope that's been
useful to you but a lot of these ideas
immutability rich and stew CQRS there's
a lot of really great academic and
business oriented domain driven design
is kind of the domain where a lot of
those ideas come from Kafka event stream
reactors may adjust wrote a really
awesome blog post that linked to my talk
that I gave less last month where she
talked about this CQRS and event
sourcing specifically using caucus
streams and then organization and
management how you sort of deal with the
organizational and people sides of
building these types of systems Mel
Conway Elliott Gould rad gene Kim and
Michael Nygaard as an announcement I
have like working software that
demonstrates this if you go to this tiny
URL you can see a public github repo my
generous generous employers at Capital
One recently worked me through the open
source process and so on an evaluation
alpha don't use this in production basis
you can go look at how I've done this
and how I communicate with Kafka and how
I implement the various bits it's
implementing closure for those of you
who are into closure that's probably
awesome for those of you or not
seriously but you can go look at it and
then here's some other references that I
use while while while making this I'll
show you the the repo here you can see
is up in live and we have everything you
need to sort of learn about about this
talk so any questions sure
so an error in a certain way of thinking
is oh yes how do we handle error
conditions in particular making sure
that the causal ordering of the events
remains consistent is that okay so an
error in some ways is just another kind
of event right so if we you know try to
create a user but it turns out a user
like that already exists in our system
instead of admitting a user created
event we can omit a sorry I can't do
that events but we're still recording
that we though we tried but that
something happened so that we could not
do so and that would then be conveyed
out to the user to show like hey that
didn't work same thing was trying to
transferring money in a future version
of this I'm working towards this there
will be a notion of for a command type
here's the action here's the schema of
the data payload and here's the
completing event so we're gonna wait for
an event whose topic looks like this and
that will be a set you know there'll be
a set of completing events
so either the error action or the
success action will indicate that this
command has been handled so what that
will facilitate is allowing a cascading
sequence of you know event processor
event processor event processor and at
any point along the line any one of
those things can say Oh something bad
happened bail out right and error
condition that will tell commander that
this this command can be considered
handled but all the other things can
take whatever rollback actions they need
to luckily a log is a sufficiently
simple primitive that it had every other
distributed algorithm in the world
is literally made out of logs the rafts
and distributed transactions and
two-phase commit can all be modeled
using a log so if you need something
like two-phase commit just build that
out of you know events that answer your
question
cool um I don't know that's a good
question um we talked about internally
having like a library that would sit on
top of a Kafka producer that as it got
sent it would check schema conformance
before sending to the underlying topic
consumer that that's sort of an open
question generally we would trust people
who are meeting events more than people
who are meeting commands because
commands are coming from like the
dangerous scary internet and events are
coming from people I ostensibly trust
who sit over in marketing or whatever so
we haven't talked about a vent schemas
as much as command schemas but that's an
open question good question
see any question from women yes the
current state will be tracked on an
ongoing aggregate basis by those
read-only view builders so you can be
building aggregates from that log and
straw wherever you want in Mongo or in
Postgres or whatever you can be doing
that as the events come in in real-time
snapshots or you can you can be doing
business logic where you say hey we got
a new customer created event so we're
gonna go and build that customer in in
our database you know build their
profile or whatever if you're doing like
financial aggregation you can say like
you know money transfer from account to
account you can go to your ledger and
and do the math in the ledger to make
sure that the the ledger reflects the
state of the event log but really all of
your views are like projections off of
the business events that have happened
in that log but if you if you needed to
go back and like rebuild the whole thing
which is totally an option because
you've got all that stuff if say your
your business logic change in your
financial software or you have a new way
of getting stuff into the ledger you
could go back on like a batch basis and
say like let's play from the beginning
of time up
now there's there's also a notion that I
didn't talk about that I probably should
of snapshot events where periodically
the financial auditors or whoever in my
world would write down an event saying
here's a snapshot we've been working and
consuming these events over here and
here's the blessed picture of our
balance sheet and and general ledger so
everyone can play from that event
forward it's just like a snapshot in
Delta that answer your question they're
great time for time for zero more
questions I'll be on the hall happy to
happy to continue to talk thank you
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>