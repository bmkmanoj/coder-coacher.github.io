<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Haxl: A Big Hammer for Concurrency&quot; by Simon Marlow | Coder Coacher - Coaching Coders</title><meta content="&quot;Haxl: A Big Hammer for Concurrency&quot; by Simon Marlow - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Haxl: A Big Hammer for Concurrency&quot; by Simon Marlow</b></h2><h5 class="post__date">2017-09-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sT6VJkkhy0o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Simon Marlowe I work at
Facebook and I'd like to tell you about
axel so first of all to set the scene
let's talk a bit about IO so sooner or
later when we're writing programs we
have to write programs that interact
with the real world in some way and that
involves doing some sort of i/o but IO
brings with it a number of problems
first of all it tends to be quite slow
so and we're doing lots of i/o we like
to try and overlap it as much as
possible using some kind of concurrency
secondly IO tends to be hard to test
because the next time you do the IO it
might give a different result because
it's interacting with the real world it
might have changed the world or the
world itself might have changed so it's
hard to build reproducible tests thirdly
it's hard to debug because when you got
a failure and you try to reproduce that
failure the the code that you ran might
not give the same result because the
world has changed again so debugging
problems that occurred in production or
occurred on the customers machine might
be quite difficult so these three
problems might not seem related but I'm
going to tell you about a framework that
helps with all three of them but maybe
what you're thinking is what are you
talking about Simon I know how to solve
these problems right I've been doing
this for a long time I write code all
the time
I do concurrency I do testing I know how
to solve these problems and you're
probably right for example let's look at
concurrency right every language has
some kind of concurrency and these
programming models like async await are
quite popular these days it's a
particularly for doing overlapping of
i/o but then there's also threads and
futures and actors and all the other
different kinds of concurrency that we
have available we have a wealth of
different ways for doing concurrency
these days but these are ideal in all
situations in particular I have to
remember when to use concurrency so I've
got a look at my code I've got to find
the places where I can overlap the i/o
and I've got to explicitly use some kind
of concurrency and even if you do that
there are ways that you can still go
wrong so with futures you can wait too
early for example you can write
concurrency in a way that isn't optimal
for the the available concurrency in
your program and then even if you do it
the concurrency is cluttered the code
so you're miss mixing up the
functionality of your code with the
operational details of the concurrency
and then when somebody comes along later
on to refactor your code they've got to
or they may have to change the
dependencies which may lead to changing
the concurrency and the structure of the
the concurrency in the code and then
refactoring itself of course is harder
because you've got all this extra
structure in the code so so maybe we
shouldn't have to do this but but you're
probably thinking well but I have to do
this because there might be side effects
right so I can't just have rampant
concurrency my program because the side
effects might interleave in some
non-deterministic way and then I can't
tell what my program is doing
and again that's absolutely right but
many of the cases many of the programs
that we write have have parts where
we're insensitive to the reordering of
operations so for example if we're
gathering data and then making a
decision based on that data the parts
where we're gathering the data we don't
mind particularly if we're doing
multiple database accesses and those
like database accesses get reordered all
done in parallel or whatever we probably
don't mind about that and then we can
make the decisions and this part of our
program is really side-effect free it in
in a sort of moral way right it's not
technically side-effect free but it's
morally scientific for you because we're
happy for things to be reordered so lots
of things fall into this kind of
category for example rendering a web
page so if you hit your web app
application and it goes and fetches some
data from the databases and they and the
services and so forth and they generate
some HTML and sends it back down to you
all of that fetching the data and
generating the HTML all of that was
really side-effect free and we could
have just exploited all the concurrency
that was available so the thing I'm
going to claim here is that when there
are no side effects in the parts of your
program that have no side effects
concurrency is probably a better default
than the sequential default that we have
right now
so what about the other two problems I
told you about how do we go about
testing our i/o code well you can just
sort of run it and if it does the right
thing well maybe it'll do the right
thing when I actually push it into
production they'll be fine so obviously
that's not not always the best way to do
it it leads to test plans like this that
say oh well it sort of worked on my
machine so I guess it's okay how can we
do better than this well the problem is
I oh interact with the real world so we
have to figure out some way to build a
reproducible test case so we could
reserved part of the world for testing
maybe some little bit that you don't
mind about too much and so you could
have a test database for example and
that's okay but you've got to make sure
that the world is working well enough
for that test database to work you've
got to make sure that the test database
is representative enough of the the rest
of the world when you want to run the
code for real and you got to make sure
that your test when you run it against
the test database doesn't accidentally
go and modify the real database and that
has happened I believe so that's one way
that we could do it a slightly better
way to do it is to somehow fake the
world so wrap your tests in some kind of
pretend world that behaves exactly like
the real world and as far as the test is
concerned so that we can test our code
against the fake the fake world and
usually what this is what we call a mock
API so we take some API is the API is in
our program that do the i/o and we
create a mock version of that API but
then we have to populate that Marc API
with a test data so now when we got to
get some test data from somewhere so
where do we get the test data from well
we could write some code to generate the
test data but that's sort of hard work
well obviously we can write the test
data by hand that's even harder work
what we really like to do is to run the
test against the real world and then
capture all that data and then use that
to replay our test over and over again
but building these mocks that can record
data and then replay it later it's quite
hard work and we have to do it for each
different kind of i/o that we've got so
this is kind of the state of the art but
it's it's still hard work
what about debugging so what happens
when something goes wrong in production
or on your customers machine or whatever
how can you reproduce that failure and
try and diagnose what happened well
usually what we do is we add lots and
lots of logging and we capture all that
logging and then we try and figure out
what happened but yeah this is not a
great solution either because again you
have to remember to do it and you have
to anticipate all the places where you
should log stuff just in case something
goes wrong and if you didn't get it
right and you got a failure that isn't
isn't described enough by the logging to
be able to diagnose it you have to add
some more logging and then you have to
get that back into production and then
you have to hope that the failure
reproduces again and then go around this
loop hopefully not too many times and
then the logging clutters all the code
so you've got all this logging spread
around your code what we do what we want
to happen is to just get the failure and
be able to reproduce it and diagnose it
that's ideally what we want so let me
take it was like digression for a minute
and talk about a class of tools that I
like to call big hammers so the
characteristics of a big hammer is it
takes a hard problem and just makes it
go away right it just solves some hard
problem makes it go away but these
things are often because they these
problems are so hard you have to go to
some effort in order to use the big
hammer so you might have to change your
workflow you might have to write some
boilerplate or you know go to some extra
work in order to use the big hammer so
this is a bit abstract but let me give
you a few examples to give you an idea
of what I mean so the first one that
came to mind was distributed source
control so I come from a time before
this where we used to email patches to
each other on mailing lists and and it
and it was not very fun so nowadays of
course we can exchange changes with each
other very easily we can track lines of
development we have a wealth of
information about the history of our
projects and this has just
revolutionized the way that we do
collaborative software development but
you have to go to some effort to use it
you have to
you have to commit your changes you have
to write commit logs you have to attract
branches and so forth but we all do this
because it's worthwhile secondly garbage
collection makes the problem of memory
management go away well it doesn't
completely make you go away
it gives it to the jvm team in your
company or something but the by and
large for the programmer it makes the
problem of memory management go away
language-independent RPC is very useful
if you have a large ecosystem of
software and you want to write things in
different languages and the idea of
language independent RPC is that you
just specify your types and your
services in one language independent way
and then you compile that into different
languages so you can access all of your
services and all of your data from
components written in different
languages so this just makes your
ecosystem able to scale in lots of
different ways and let you choose the
best tool for the job and you can see
where I'm going with this the big hammer
that I'm going to talk about is a thing
called hacks on their bodies hacks all
well axle is a Haskell library and the
point of axle is that it provides an
abstraction over concurrent IO and it
works in conjunction with a compiler
extension that we developed called
applicative do which is in the Haskell
compiler it was released in GAC 8.0
and so let me give you an example of
what hacks will can do so I've chosen as
an example a script a kind of DevOps you
type script that you might run on your
on your network and it's going to look
at a bunch of machines and update
software on those machines so I need a
little API first of all I need a
function called get latest version to
get latest version is going to query the
software database for the latest version
of some software and it's a hacksaw
computation that returns a version this
is its type if you don't really ask
although the blue bits are the types
next we have a function called get hosts
and get host is going to find out the
names of all the hosts on the network
that I need to run my script against so
it's a hacksaw computation that returns
a list of hosts
the next function is called get
installed version so this is a function
that takes a host and it returns a
version they queries that host for the
version of the software that's installed
on that host and finally I've got a
function update - which performs an
operation it takes a version and a host
and it updates the software on that host
to the version that you give it and it
doesn't return a result so here is the
script so it's a do expression in
Haskell and du introduces a sequence of
statements each of the statements has
the operation to run on the right-hand
side and on the left hand side the
variable that we're going to bind the
result to so this is running get latest
version and binding the result version
to the variable latest next we run get
hosts and we bind the result to a
variable hosts next we're going to call
get installed version on each of those
hosts so I'm going to map the get
installed version operation over the
list of hosts and I get back a list of
installed versions next I need to figure
out which of those hosts I need to
update so I've got to look at each of
those hosts and the installed version on
that host and build a list of hosts that
have an outdated version so this is a
list comprehension
it's iterating through the zip of the
host and installed lists and every time
we find a version that's less than the
latest version we put the H in the list
so we end up with a list of hosts that
have an outdated version and finally
when we got that list of outdated hosts
we can just map our update to operation
passing it the latest version to install
onto those outdated hosts so this is the
complete script and that's more or less
exactly what you want to write but some
parts of the script could run in
parallel so which parts let's look at
the dependency graph of these operations
so this graph is just representing the
data dependencies between the various
operations in the script and you can see
that getting the hosts and getting the
latest version have no dependencies
between them so we could be doing those
things in parallel and once we've got
all the hosts
querying each of those hosts for the
installed version is also something we
can do in parallel across all of the
hosts and finally doing all the updates
can be done in parallel across all of
the hosts that need updating and the
nice thing about axel is if I just run
this script in axle with the applicative
du compiler extension it will actually
execute the program according to this
dependency graph and it will do things
in parallel as far as possible how well
so the data dependencies determine the
ordering rather than the sequential
statements that we wrote the compiler is
going to look at the data dependencies
and when you have independent
computations those will happen in
parallel as far as possible
I didn't write any explicit concurrency
constructs at all so there was no fork
there was no async no await none of that
stuff just a sequence of statements with
dependencies between them and so the
kind of the slogan is that you get the
code you get to write the code that you
wanted and you get parallelism for no
extra effort so just like in garbage
collection we abstracted away from the
memory management in axle we're
abstracting away from the concurrency
and I'm not saying that both of these
methods do a perfect job writing
concurrent in garbage collection if you
did the memory management by yourself
you could probably do a slightly more
efficient job than the garbage collector
and in hacks all if you're prepared to
do the scheduling yourself you could
probably do a better job than axle 2 but
if you don't mind getting 80 or 90% of
the way there you can get there for very
little effort just by using the big
hammer what to put it another way what
we did here is we flipped the default
from sequential to concurrent instead of
everything being forced to be sequential
and having to say which things are
concurrent everything is concurrent
unless you say so or unless you have a
data dependency and this makes a lot of
sense when concurrent is the right
default in the parts of your program
where you don't mind
reordering things you were just like
concurrency to happen so perhaps you're
wondering how it works well the problem
is first of all the data dependencies
are not first-class things in our
language so weak
and talk about data dependencies on the
library so I can't write the library
that does this like I have to get the
compiler involved somehow but I don't
want to build all of this functionality
into the compiler somehow I got to find
some more abstract way of doing what I
need to do so let's look at the fragment
of this example that we talked about we
had these two statements get latest
version and get host and they're
independent of each other
but that only the compiler knows that
because only the compiler can look at
the variable names and see where they
occur and the compiler when it sees this
statement this is actually syntactic
sugar the do statement and the compiler
expands it into a larger expression
using the Monad bind operator and every
Mon I've implements the monad bind
operator this is how the do syntax does
different things depending on which
monad you are using and that that's fine
but the problem is that we've already
lost as far as parallelism goes here
because the monad bind operator
incorporates into it the idea of
sequentiality because it takes two
arguments a computation on the left that
returns an a and the computation on the
right I was holding a function on the
right that takes the a that was returned
by the left so we can't do the right
thing until we've done the left thing so
it forces sequentiality so the Monod
bind operator is the sequential
composition and that's not what we want
this could only be sequential we've
already gone wrong if we've translated
the the expression into this monad
expression so we need to use a slightly
different abstraction unfortunately
haskell provides a thing called
applicative so plickers if is another
way of combining computations but only
uses this operation called app or
sometimes we call it splat and this is
kind of a parallel composition of things
so it combines things in parallel as
long as the implementation of this
operator can exploit that parallelism
and the reason it can do that is because
the two arguments to the splat operator
are independent the left is a
computation that returns a function and
the right is a computation that returns
a value and then finally the function is
applied to the value
this is all very well but I don't really
want to write this thing by hand it
looks a bit like line noise and I've
also had to still figure out which parts
of my program I can do in parallel in
order to to write it in this form so we
don't want to write that by hand so what
we did is we added an extension to the
compiler called the applicative du
transformation and applicative du looks
at the program looks at each of these
two statements and the dependencies
between the statements in the do block
and it translates it into the
applicative style as far as possible so
it tries to extract all of the available
parallelism between the statements and
embody that by expressing it in the
applicative style that's the first part
and then the second part is that the
hacks are library implements the splat
operator in order to give you the
parallelism well what I mean by that how
does it implements operator to give you
parallelism well that was the first
transformation then the second part is
that axle is going to evaluate this
computation in order to find a list of
things that it can do in parallel and
then it will give that list of things
that it's doing in parallel to the back
end and it's your job to provide the
back end so I haven't axel doesn't
embody any particular kind of i/o into
it you have to say how to execute your
i/o and this function fetch that you
provide is passed as a list of
operations that hacks all extracted from
your code and given a list of operations
of course you can choose how to do them
in parallel so you can choose to just
overlap them all using threads or you
could choose to perhaps you can batch
them together and send the a single
request as a single batch down to the
database or use any kind of mechanism
that you you you want to but the point
is that you provide the fetch operation
axles job is to run your code and
extract all of those operations and then
give you the list that you can do in
parallel
so the overall effect of doing this is
if you think about the the structure of
your code as a dependency graph where
the nodes of the IO hack cell is
exploring this dependency graph in a
breadth-first way so it's finding a list
of things that it can do in parallel but
it does all those things in parallel and
then it carries on running the
computation again because those the
results of unblocked more of the graph
now we can explore more of the graph let
me find more IO and we keep on doing
this over and over again until the whole
thing is finished and we have an answer
so what about the other two problems
that I talked about I mentioned testing
and debugging so in order to use hacks
all for your IO what you have to do is
you have to make a data type for each of
the different kinds of IO in the program
so here's an example where I've made a
data type for doing an HTTP request and
then once I've made the data type I have
to add some boilerplate instances for
various things and I have to implement
that that IO by providing the fetch
operation that I just talked about and
in this case so fetch is just going to
take the HTTP data type and it's going
to pass it off to some HTTP request
library so it's fairly straightforward
to implement all this stuff and you have
to do that for each different type of
i/o but now that I've done that all of
our i/o is data and you can do a lot
more with data than you can do with pure
i/o because you can inspect it and you
can compare it and one of the things
that hacks will does with your i/o is
that it makes a cache of all of the
requests and the responses that have
happened in the code so far normally we
use that in the per request way if
you're writing a server we start a fresh
cache when you you get a new request on
the server and then we throw the the
cache away at the end so we don't have
to worry about data becoming stale it
just lasts for the the cache lasts for
the period of the request but then we
have this nice property that if you
fetch data again you get back the same
result that you got back the first time
and this is of course really good for
performance it's also really nice for
correctness for example if you're
writing a web application and you have
to fetch lots of data it's a bit strange
if different parts of the page had
different reflected different data
because the data changed underneath you
while you were generating the webpage so
axial kind of avoids that problem
because it's making sure that you get
back the same result if you fetch the
same data again we've also found that
it's really useful for modularity that's
a bit surprising perhaps but if you
fetch the same data in different parts
of your program in order to optimize
that what you would have to do is find
those different places where you're you
using the same data fetching and extract
that into another module and do it first
and then pass the results down but
that's created so extra coupling between
different components in your program and
now that's making reef refactoring
harder in the future because if you
change the program such that you don't
need the data anymore you've got to go
back to the shared components and maybe
change it so it's much easier if you
don't have to do that if you just have a
cache behind the scenes that's
remembering what you fetched and you're
just free to fetch whatever you like
wherever you like in your program then
that means you can keep the component
separate and you don't have to worry
about fetching things upfront so now we
have a cache that's recorded all of the
i/o that we performed during our
requests or during her the run of our
code and so having got to the end of our
request we have a full cache that
records everything that we've fetched
now if you run the code again we'd
guarantee to get exactly the same result
that we got the first time and that's
because we've wrapped all of the i/o in
the code there's no way that we can have
non deterministic effects happening in
the middle so that's a nice property to
have and we can exploit that
so hexyl gives you a way to dump the
cache it's got an operation called dump
cache as Haskell so when you run them
cache as Haskell it prints out the cash
as a Haskell program and the effect of
running this program is to populate the
cache again so of course you could
serialize it in different ways you could
also you know dump it as binary or text
but this is a really useful
serialization format because the
compiler is the deserialize err
so it's okay so we've dumped the cash as
a Haskell program now we have all the
pieces we need to make a test so we run
the code we've done the cash into a file
we commit the file into our repository
and now we have a unit test cool right
and and because you can populate the
cache programmatically you can also
write libraries that generate test data
so there's a way to make synthetic test
data as well and so this is really
really useful and it's really useful to
make the test and to re record the data
when you need to we use this quite a lot
in our system at Facebook and finally
this gives us a handle on the debugging
problem as well so the debugging problem
was that we don't know how to reproduce
our problem when it happens in
production but now we can just dump the
cache and provided we have all the other
pieces we need we have the code that was
running we have the input to the request
and we have the cache that records
everything that that was fetched from
the world during the course of running
that request now I can just reproduce
the failure and I can diagnose exactly
what happened when the failure happened
in practice so why did we make axel well
actually is actually used at scale in
the system called Sigma at Facebook
Sigma's job is to classify lots of
different actions on Facebook and
content according to whether those
actions or that content is abusive in
some way spam is one of the main
classified classifications of abuse but
there's also things like malware other
kinds of other kinds of abuse fake
accounts and so forth that we try and
classify and all of the different logics
that that's that's involved in trying to
classify something as abuse is all
written in axle and runs on the Sigma
service and hak'tyl gives us the way of
running all of these different rules and
all of this logic in parallel so there's
a nice blog post that you can read about
on the Facebook engineering blog Axl is
also open source so you can go and find
hacks along github if Haskell is not
your thing then there's a whole bunch of
clones laughs Axl in your favorite
language I hope so at last can we have
about eight different clones and these
implement really the main features of
hacks all not necessarily all of the
bells and whistles that we have but the
the idea has been re-implemented in
several different languages including
one in Haskell it turns out because
somebody thought they could do it in the
nicer way than we did which is perfectly
fine okay so just to summarize so you
have to write some boilerplate for all
of your i/o
so that that's the contract right so you
you look at all the i/o in your program
you have to write a datatype when you
have to write some boilerplate you have
to say how to execute that i/o but once
you've done that for all of the i/o in
your program then you get lots of nice
benefits you get automatic concurrency
you get caching the caching gives you
testability automatic record replay so
it's like it a mock layer for all of the
different types of i/o that you're doing
in your program and finally you get
debug ability because you can capture
the cache and then you can reproduce
failures that happened later on so I've
just about reached the end but I have
plenty of time and I'd be happy to take
questions
thank you
yep
yeah that's a really good question so
I'll repeat the question and the
question is do we have to do everything
in strict layers like this and do we
have to wait for the complete layer to
finish before we do the next part and
actually we're working on the new
version of axle which I'll hopefully
release very soon I'm just testing it at
the moment that can arbitrarily overlap
all these different things so it relies
on implementing your IO in such a way
that it rather than just returning a
result it has to call back later on to
tell you it's got the result but yes so
and we found some nice latency wins by
by implementing that so it's able to
overlap more things a number of
different things and sorry the question
was what drove our team to use Haskell a
number of different things so we there
was an existing functional language that
was used as a DSL internally in the
system that we were working on and that
language reached its its limit really it
needed lots of tooling it needed lots of
extensions and we really needed to use a
real language instead but the the area
we are working in has some slightly
unique demands so we have to be able to
get stuff into production very very
quickly and that means having a strong
type system is really useful having an
abstraction that meant the user doesn't
have to think about concurrency is also
really useful so we experimented with
various different languages and we found
that doing this in Haskell worked out
really nicely
right so the question is isn't mapping
sequential and the answer is map n uses
applicative internally so this wasn't
true in the past actually it changed at
some point when the applicative class
was added to the type class hierarchy in
haskell so map n is defined in terms of
applicative and a bunch of other things
are defined in terms of applicative as
well so they get to take advantage
automatically of the the implementation
of the applicative operator in axel I
think I have a question now the question
is is there a boundary or a lifecycle of
the cache and so we implemented well so
in our system requests tend to be quite
short-lived so we didn't implement a
boundary on the cache it's not clear to
me exactly how you should do that and we
certainly have a way to run things
without a cache we have a way to clear
the cache but the particular policy
probably depends very much on your use
case and maybe you want to have a
bounded sized cache or something like
that but the problem is that as soon as
you decide not to cache everything you
lose some of these nice properties so
you can't guarantee to have the complete
record of all the i/o and you can't
guarantee to be able to generate a unit
test and so forth
now the question is if there are pure
functions in the denotation do we catch
those as well and the answer is no we do
have a generalization of the caching
mechanism called memoization which lets
you cache not just a data fetch but a
whole computation we found that to be
really really useful so you can you can
annotate functions with with the memo
function and it will record the result
of that so we use that for caching
computation as well as data fetching
okay that's a really good question so
the question is can you use this to make
a build system and the answer is yes and
I've done it I'd be happy to show you
later okay I think I'm going to wrap up
there thanks very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>