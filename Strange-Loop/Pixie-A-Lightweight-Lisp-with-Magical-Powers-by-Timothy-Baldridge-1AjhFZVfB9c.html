<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Pixie - A Lightweight Lisp with 'Magical' Powers&quot; by Timothy Baldridge | Coder Coacher - Coaching Coders</title><meta content="&quot;Pixie - A Lightweight Lisp with 'Magical' Powers&quot; by Timothy Baldridge - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Pixie - A Lightweight Lisp with 'Magical' Powers&quot; by Timothy Baldridge</b></h2><h5 class="post__date">2015-09-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1AjhFZVfB9c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you all for coming my name is Tim
Baldrige I'm gonna talk a little bit
today about a language I've been working
on for the past year along with some
help from some other people called pixie
it's actually kind of cool that about
exactly a year ago the first commit for
pixie was made so it's in that
interesting point in time for language
development where it's in the middle of
alpha to beta so you know you can do
cool things with it you can build some
cool programs play around with it come
and tell me that you're running your
startup on it and I'll probably call you
a fool but so let's let's get started so
the words I used to describe pixie today
are huh that you're it'll make your
computer shut off first of all let's see
if the screen comes back my computer
went to sleep there hopefully doesn't do
this a whole lot warm there we go okay
so the the words they use describe it is
it's a small fast light list with
magical powers and we put magical in
quotes because nothing is truly magical
in computing right it was all invented
by someone in the 70s and we're just
kind of rediscovering him but I'd like
to talk about each one of these things
individually and we'll go through them a
little bit so first of all it is small
if you compress it with gzip and
downloaded it's about a two and a half
Meg download when you start the Red Bull
it takes about ten megabytes of RAM
which is seems to be pretty small for
languages today and the startup is
pretty good so it starts up in about 175
milliseconds on my laptop and on other
systems like raspberry PI's and arms it
starts a little slower but that's to be
expected um so it's fat it's small it's
it's also relatively fast it's
lightweight and I use this word fast to
describe it as well I like to dig into
that a little bit so I wrote as an
example today a Mandelbrot a calculation
program and to kind of frame this I've
written the same algorithm before in
Java and using LLVM byte code and the
Java version is about takes about 600
milliseconds to render this the same
algorithm LLVM byte code takes about 500
milliseconds and let's see how this
works with pay
see now now to to put this in in mind
the Java version was statically typed
using doubles the LLVM byte code was
also using doubles but in a bytecode
format that was then compiled with their
JIT and let's run this here with the in
pixie this was fully dynamic Lisp code
running this and once the JIT warms up
we're at about seven hundred forty three
milliseconds so it's not slow for doing
math like things and we can take a look
at that code real quick so here is the
the guts of that and you can see we
don't have any type hints we don't have
any types at all whatsoever this is
purely dynamic Lisp code in fact the
only things we see if types at all here
are the floats and the there's a call to
int down here that does some conversion
and that's purely for making sure that
it does the math that we want it to
truncating floats extending into floats
that sort of thing but there's no type
hints at all given to the in legit it
just kind of figures it out on its own
so let's get back here and let's go
ahead and start up a rebel because
that's what we should do in a list right
okay so we have a rebel here on the
right start it up
so the actual magical bits I want to
talk about today really fall into these
three or four categories first of all
pixie has what's called a tracing JIT
and that's relatively rare in the in
programming languages and we'll talk
about that and has some lightweight
threads or stack lips as they're called
by the virtual machine and we'll talk
about that it has excellent C Interop
and I'll go over how that works as well
and it's a lisp I mean I consider Lisp a
magical power because I like this right
so the syntax for pixie is quite
inspired by closure this is mostly
because I program and closure for a day
job and I never really programmed and
scheme or Common Lisp and so I prefer
the closure syntax so if you're
unfamiliar with Lisp it's it's actually
pretty simple things and parens are
function calls the first thing in the
parens the function so
now that I hit the right there we go so
plus 1into returns three if we have x
equals 42 and then we increment it it
returns 43 we have immutable collections
so here we have a hashmap a is 42 B is 1
and that works it's expected and they
are immutable collections so if we say m
is one thing and then we modify it down
here in this ax so she can print both
the old and new versions of the hashmap
and that works as we expect
now I stopped short of calling this a
variant of closure because there are
some small differences and I kind of
wanted the the flexibility to change
pick C at any point because I wanted to
do something a little differently for
performance reasons or whatever and one
of them we can kind of see here so if
you've programmed in closure you know
that I function with a variable number
of arguments those arguments get handed
to you as a linked list and in pixie
that's a little different they get
handed to us as an array so there's
going to be little things perhaps that
you run into using pixie that are a bit
different but I'm sure we can live with
that
okay so pixie is a language that has its
own JIT in its own virtual machine and
its own runtime and it's built off of
what is known as the our Python tool
chain so who here is familiar with pi PI
at least is heard of it before
all right good number of people
excellent so the developers of pi PI did
an excellent thing when they wrote I
started that project and for those of
you who aren't aware pi PI is a
implementation of Python in Python which
sounds like a fantastically bad idea
until you actually realize what they did
and what they did was they wrote an
entire tool chain for building languages
in Python so the basic idea is is that
you write your interpreter in this thing
called our Python and our Python is a
reduced subset of Python that is
inferred fully inferred and statically
typed code so it basically takes your
Python code does a lot of crunching on
it and spits out something that has to
be able to compile to C so those are
kind of the restrictions it has a type
system somewhat like you would expect in
C but it's all statically and
and to that code before they translate
it to see they include a garbage
collector which is kind of a nice
feature so you start off and you write
your interpreter and your compiler and
your parser and this C quazy C Python
thing and you run it through the
translator and it spits out C code that
gets compiled into a C executable now
that in and of itself is not an
incredibly cool thing I mean if I was
just wanted to build a language I would
probably just use C instead of using
some mostly working tool change by their
own admission of the developers it
mostly works right so but but there's
another reason to do it this way and and
that is to get a JIT the tool chain
provides tools for writing Ajit's
specifically a specific type of jet
known as a tracing jet so to discover to
look at why we would want something like
this let's look at a piece of example
code so here's some code in pixie that
says do x x to 10000 so this will start
X at 0 and loop 9999 times incrementing
X each time now the actual guts of that
code looks something like this it's a do
x as a macro that expands to this loop x
equals 0 while x is less than ten
hundred ten thousand increment X and
then jump back up to the top
okay so what's increment well increment
is this tiny function that says X plus 1
all right well what's plus well plus
does a bunch of things but one of the
things it does in pixie is call - add
great that doesn't help us much at all
so what is - add well - add is a double
polymorphic function or a function that
dispatches on the first two types of the
of the arguments handed to it so in this
case we're saying if we are handed an
integer and an integer then we want to
call this primitive function called add
int and the actual code behind this in
pixie is a little bit different but
we're using this as an example for today
so the problem is is with a normal
traditional JIT like a method level jet
that you would find in LLVM or dotnet on
it's a little hard to figure out what
the
should do with this if it comes up to
this function increment what can it
really figure out not a whole lot
there's not a whole lot of context here
it says you will be given something and
then you will pass that to this plus
function
what sort of unboxing or optimization or
enhancement can it do here there isn't a
whole lot there's not enough context now
there are other chits out there such as
a lot of JavaScript jets and hotspot is
just a really weird beast that exists
somewhere in between these two
classifications of method jets and
tracing jets but in general they also
work the same way they work by inlining
by finding ways to partially evaluate
parts of your functions and so forth ok
so what is the internal representation
of this and look like well here's the
actual code for a double polymorphic
function in pixie and as you can see it
looks a lot like Python and we have
things like dictionaries and lists so a
function in pixie is is simply a class
that has a method called invoke not
invoke and it takes a list of arguments
and what we're going to do is we get the
type of the first argument and the type
of the second argument and then we look
up the function we want to call based
upon those two arguments and then we
call it so we look at the body of this
get function we see that what we're
basically doing is two lookups we look
up in one hash map to find the function
otherhand in that second one we look up
the function we want to execute pretty
simple right this is it's a simple way
to implement a polymorphic function like
this even if it is a little bit naive
right but if we start to realize that we
are executing this invoke for every
single integer add in our language how
could this possibly ever be fast we're
doing two dictionary Dyck lookups for
every single mathematical operation plus
boxing and a bunch of other stuff so
this is where a tracing jet comes into
play now tracing JIT doesn't look at the
code like we would expect but instead
looks at loops and uses loops to provide
context so here what is the actual
context of the code we're interested in
it's the body of this loop the code
between the top and the bottom of the
loop and those within that loop we have
all the contexts we need to know the
types now the problem is with tracing
jits they're really really hard to write
the original tech was written like all
good texts sometime in the 70s and it
was by HP I believe wrote the first
tracing jet and it was a research
project you know at one point Mozilla
had a JIT known as a trace monkey that
they discontinued because it was too
hard to maintain a little bit later
there was a JIT for python known as
psycho way back in the day and it works
pretty well works great one person
understood it and it was too hard to
maintain and was discontinued see a bit
of a theme here one of the only existing
tracing jits outside of Python is
actually legit which kind of benefits
from the fact that Lua is such a simple
language that maintaining a complex JIT
like this is is not as hard well the
developers of Pi had this great idea
they said you know we're already
translating to C and C doesn't have a
garbage collector but we're writing code
that that like layers the garbage
collector into our our Python code for
us why not do that for a JIT why write a
JIT that's hard to write well we don't
make the computer do that that sounds
like a fantastic idea so that's exactly
what they did they they don't write jits
our PI pi base languages are Python
based languages don't write jits they
write hints to a JIT generator that
writes it for you
it's really crazy and fantastic so a lot
of that just mostly involves marking the
start and the end of the loop so inside
the pixi interpreter we have certain
hints that say hey here's the start of a
loop here's the end of the loop and that
codes a little complex and we won't get
a whole lot into that but here's an old
simpler bit that I think we can we can
all look at today and that's this
annotation at the top of this function
called Eli double promote and what Eli
double promote says is that if this
method is handed the same arguments over
and over you can replace the call to
this method with its return value
and we all know that as being pure like
I wouldn't just mark this as a
functionally pure method well purity
also means you're not doing side effects
in you're allowed to do side effects in
here as long as they don't change the
output so things like caching and stuff
like that are allowed and so elida bol
promote makes a little more sense and if
we look back up at our code here we can
see that that really helps us quite a
lot we say if we call add with two
integers then we can assume the out of
the function that we want to invoke in
this lookup is always going to be the
same and if it's always going to be the
same we can look at that function and
realize that it takes two int and
returns and ends which means we can
basically type the entire body of this
loop and that's done for us by the legit
so a tracing JIT is known as a tracing
JIT because that's basically what it
does it will find the loop and then walk
the entire loop recording every
instruction executed by the interpreter
and anything the interpreter calls and
create a long linear trace with all the
branches removed all of the conditional
logic removed and it's just one pass
through the JIT it will go back later
and patch up branches if it needs to but
in general it's just a linear trace so
here's what a trace looks like for that
code that we looked like looked at and
you know kind of squint it's a little
hard to understand but the the blue bits
here are basically the byte codes
executed by the pixie interpreter so you
know here we're inside equals we're down
here inside increment and then we go
into plus and then we go back out of
that into increment and so forth and if
we rip out all that debug information
here's what's left for all those
functions all the polymorphic dispatch
everything we have a label we have a
guard not invalidated and make sure no
one has modified our polymorphic
functions out from underneath this we're
gonna do an integer comparison we test
whether it's true or false and we do an
ADD and check if we overflow and jump
all that gets compiled to about four CPU
instructions and that's kind of what
originally excited me about writing a
tracing JIT for a lisp was that in
functional languages we tend to write
these really
functions that don't do a whole lot or
are just compositions of other functions
and a tracing JIT has the ability to
dive through all of that remove all of
the the niceties that we like to have
all the composition and return a very
nice concise trace that's actually
pretty fast and so we can also do really
crazy stuff like this all right we
talked about before that a variable
length function a function that takes
variable number of arguments and pixie
returns it as a and array so here we can
just at create a this function I'm
calling Adam we call it sum or whatever
that basically just takes alt arguments
and adds them up and we do that with a
reduce so reduce our accumulator is zero
at everything in using + and once again
I mean so we're doing there's a loop
inside a reduce there's a creation of
array argument arrays and all this other
stuff and if we go through and look at
this trace as well it's a little longer
but basically when we get all the way to
the end here this is the reduced trace
once again just a couple additions all
the overhead of creating argument lists
out of arrays and lists and all that is
just removed for us so that's cool that
was one of the first things I wanted to
have in a language that I would write is
a list with a tracing JIT because they
really don't exist there's a few
languages out there that try this but
there haven't been a whole lot that have
been attempted so the second thing I
always wanted to have in a language like
this was lightweight threads the ability
to have threads decoupled from OS
threads and to do things like a
continuation from those so thankfully we
stood on the are Python tool chain which
has some facilities for helping us do
this and let's see here how about we
there we go and what we can do is we
provide this abstraction then I'm gonna
show here for creating lightweight
threats so we're gonna create a promise
which is kind of a cell we can put
things into and then we're gonna create
this thing called the future which
creates a lightweight thread which is
just if anyone here is familiar with
like set jump long jump and see that's
kind of what we're doing here some weird
trickery with the C stack and that sort
of thing
but in a way that doesn't mess up the
JIT and and stuff like that so we can
create this little lightweight process
and with them lightweight process we can
make this call to call CC now this is
different than the scheme call CC and
that it's not a full continuation of the
entire program it's just a continuation
up to the start of the body of whatever
process lightweight thread you're in
here so we can we can get our
continuation and we get that as K and we
put that in the promise so what we can
do is run this and we see this before
call CC down here in our repple so at
this point what's happened is this
little future is executed up to the
point of this call to call CC and now we
have a handle to the remainder of the
execution of this process that we can go
and wait to execute and this is not any
sort of macro magic or anything this
call to call CC could be 50 layers deep
in a in a call stack somewhere and we
can just save off the the thread and
pause it and we can print it here and
see if the value is actually a stack let
handle okay and then later on we can
come along and say okay let's continue
on and this is some weird machinery
mostly because this is often in library
code somewhere and when we run this
machinery it says call CC returned 42 so
we passed 42 to the continuation that
then is put in as the return value to
call CC and this little process
continues executing and we see the
output on the right side here so what
does that get us well we did in pixie as
we decided we needed a good IO library
something that has some good
abstractions and so we pulled in the
libuv library from nodejs nodejs has a
nice IO library underneath called libuv
and if anyone's ever programmed a node
they know that its callbacks everywhere
but if at any time you can take your
currently executing thread and turn it
into a callback then you can take and
create this little lightweight threads
that anytime just pause them attach them
as a callback and continue on so in our
example of our Mandelbrot Code we do
that here at the end we just call sleep
for ten thousand milliseconds or ten
and that it executes this code here we
call call cc to get our continuation
hand that continuation off to libuv and
say when you're done
call us and we'll continue on so that's
kind of cool
the ability to do this I owe this
asynchronous i/o and work with libuv in
a way that is nice for the programmer
and not just nice for the the runtime
and on top of that we can build all
sorts of things so here's an example of
a communicating sequential processes
code a lot like you would see and go or
for instance core async enclosure but in
this case we're not using macro magic or
syntax or any sort of compiler thing are
put in take from channels the ability to
pause the current thread as we're giving
values to another thread is just a
function that we pass around and with
this sort of these stack le'ts or these
continuations we can do all sorts of
things like build generators you can do
some complex you know exception handling
or just asynchronous operations ok so
let's see here I want to talk a little
bit about I will talk a little bit about
this here because it's a kind of cool
example another thing we added to pixie
is it's a really simple open-ended
object system so and we'll see an
example of this used a little bit later
but we have these dot forms if you're
familiar with closure this is a type of
way of doing Interop saying on this
object pass it a message which is a
method I want to execute on that object
if you from a lot of languages have this
a Python has get an attribute ruby has
something like that too I forget the
name of it but we have that sort of
thing in pixie - so it's an open-ended
object-oriented system so we can define
an object and then we can or in this
case say if we try to look up attribute
X then we're going to return a value
otherwise return not found so here if we
look up X on this object we get 42 and
if we try to look up Y we see it's it's
not found and we'll see a cool use case
for that and
in just a few moments and same thing
with methods okay so the two things so
far we discussed is tracing jits and
these stack --let features which are
kind of nice the third thing I really
wanted in a list was good rock-solid
foreign function or facing with C this
is something I haven't seen a lot of
languages do because it's it tends to be
fairly hard now the art python toolchain
provides good functionality for calling
c functions in the sense that you can
say here's a pointer to a c function and
it expects a double and returns a double
and once you call that a bunch of times
within a trace it will compile down to
just a call to a pointer so all the
logic of wrapping and unwrapping and all
that is is pretty much removed which is
nice but you still have that problem of
what are the types of this function
pointer I am calling and and that's
tends to be a pretty hard problem so the
holy grail that I was looking for the
thing I really wanted to build was a
system where I could say in pixie from
math.h import cosign which is a pretty
tall order because there's a problem and
that is - so this is a library in Lib C
called M and if you go to this library M
there's a there's you can look up the
symbol cosign which just gives you the
pointer to a function that's it you
don't know what that function expects
you don't know what it returns there's
not a whole lot you can do because all
of that information all the typing
information is stored in the header file
math dot age so different libraries out
there approach this sort of thing in
different ways there's one approach is
to do what the JNA a library does for
Java and just say well you better not
hand me the wrong arguments or we'll seg
fault the whole GM JVM okay that works
but you know it's not optimal and it
requires people to add their own asserts
and type checks in it and everything
another option is to do what C FFI does
in Python and say well hand me small
snippets of
see code that define your functions and
I'll I have a seat parser and I'll go
parse those and use that that works as
well but you know no offense to anyone
here I don't trust any of us to write a
C parser you know it's a really complex
beast there's a lot of weird macro magic
and it never really works out well so
probably at this point a lot of people
are thinking well hey didn't Elvia build
a a library that's a C compiler yeah
they did it's called clang and then they
wrap it up as a library called Lib clang
and that that works pretty well except
it's like 30 Meg and the last thing I
really wanted to do was to have you know
pixie this lightfast language with this
huge C compiler bolted on you know so I
actually thought about this quite a lot
and finally came across an idea which
was to use or abuse however you want to
look at it the boost type traits library
so in modern versions of C++ you have a
way to conditionally execute C++
templates and we leveraged that
extensively so here is a template and
that only compiles when the function
handed to the template is a function
that has one argument and we have
multiple instances of these so it's just
a cascading list of templates each one
fails if you hand it the wrong type and
eventually it'll find the right template
to compile so in this case you handed a
function hand at a type of a function
that takes one argument and returns
something and then we recursively call
that template to do reflection upon all
of the arguments and the return-type so
we have this library called FFI and ferb
and it looks something like this
and this is pretty much what I was
originally looking for we say there is a
dynamic library on the system called M
if you're gonna execute a static link
against this you need to link against it
using Lib m okay this is pretty simple
stuff and all of the header information
all the information about the functions
I want to execute is found in math great
and then you just start listing off
symbols that you want to
import using that specification and what
this library does behind the scenes is
take all these symbols create a C file
with all of these things plugged into
that template compile the file and then
run it and that spits out all the type
information so we can do that here it
takes just about that long to compile
and run on this system which is pretty
fast and now we have floor cosine and
sine just as normal pixie functions in
our language okay and one of the cool
things that we built in pixie is an
ability to output byte code as a file on
disk so all of you know this is a macro
and if you have a lot of imports this
will take a while to compile you know I
may take five ten seconds or something
to compile all those templates because
they're not exactly fast but when we're
done we can take the bytecode generated
by this macro and spit it out to disk so
that next time you come to run this
module it loads almost instantaneously
and the takeaway from that is you only
have to have boost and C compilers and
all that other junk installed on the
development machine you wouldn't have to
have it on a production machine but
don't use this in production yet and we
can do this for all sorts of stuff so
for instance here we have a C struct
this is from the live libuv library and
we can say import the C struct and here
are the members I'm interested in this
we'll go find out their type their
offset their size everything it needs to
know the size of the struct so you can
just instantiate this struct set the
members on it with any pixie values that
are compatible and you're off you can
also import compiled time constants so
like if this is you know you VFS link is
defined as 42 we can import that as well
the really crazy thing we can do is
import C callback types so this is a
callback type from libuv and if you want
to talk to an asynchronous function in
libuv you have to hand it to see
callback so the first thing you do is
import
the callback in this this fashion here
and then you go and do something like we
had up here and let's see here there we
go and I'm running off the edge of the
screen a little bit but there's this
function called FF I prep callback and
you hand it a see callback type and any
pixie function and it coerces that
function into a C pointer that you've
been hand off to C so what this means is
is that you can kind of just Interop
between C and pixie take a function hand
it to see if C hands you a function you
can cast it to one of these types and
call it it's just very very easy to to
talk to C and that way which is cool so
I was talking about this once and an
acquaintance of mine said well you know
python has a really cool C API doesn't
it well yeah it does and you say that
you can you work with cool C API is
pretty easily yeah so why don't you call
Python from pixie okay let's let's try
it you know you can actually do it it's
actually really weird so this here is
compiling all the type information it
needs to talk to Python and so here is a
pixie function that creates a vector and
this calls the Python code to create a
Python list you can see it's different
because there's commas and you know the
type is this wrapped pie list and then
we can do cool things like call count on
it so this is Pixies count function that
has been extended to work with this
Python list and then we can do something
completely crazy and hook into that open
ended object-oriented dispatch thing I
talked about earlier to say that when an
arbitrary Python object is called with
you know a dot append is called on it go
look up that method in Python turn it
into something I can call call it
handing at the arguments and give me
whatever it returns so what we're doing
here is creating a Python list adding an
integer to it and returning that list
and we see in fact we get one two
and 42 so I'm not exactly sure how
useful this is but it's it's a it's a
cool exercise nonetheless so one thing I
did want to point out here though too is
let's go look at this Mandelbrot code
again so at the talk we kind of see all
of this come together in this example
that I showed earlier this is all it so
I'm doing interrupts with SDL which is a
nice cross-platform graphics library for
C and so we're just basically saying you
know we're gonna link against STL - and
here's where we get the flags on how to
link to it we're shelling out to a shell
script we're including STL dot H and
from that I just need these functions so
there really isn't an STL wrapper for
pixi at all because you don't really
need it it's just these ten lines of
code and from there we just call the
functions as if they were normal
functions and we have some Interop here
for packing data into an array which we
then hand off to STL as the frame buffer
and this is the guts of what we what we
showed with the Mandelbrot code
it's just loops and normal lists of code
so actually that's that's pretty much
all the things I wanted to go over today
with this it's been a it's a fun project
you know it's with being built on top of
our Python it's pretty easy to get into
and play around with and we have people
stop by all the time there's about three
or four to committers that helped me
with this on a regular basis and so the
link appears at the top
github comm pixie line and it's just
download it try it out let me know what
you think it's fun to play around with
fund to just a you know tune the JED a
little bit or look at something that
interests you and I guess I'm a little
early today so that's all I had thank
you and I guess I have questions or you
have many questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>