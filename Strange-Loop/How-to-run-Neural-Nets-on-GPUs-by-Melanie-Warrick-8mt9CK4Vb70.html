<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;How to run Neural Nets on GPUs' by Melanie Warrick | Coder Coacher - Coaching Coders</title><meta content="&quot;How to run Neural Nets on GPUs' by Melanie Warrick - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;How to run Neural Nets on GPUs' by Melanie Warrick</b></h2><h5 class="post__date">2015-09-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8mt9CK4Vb70" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is Melanie Warrick I'm here
to talk to you guys about how to run
neural nets on GPUs so I'm a deep
learning engineer at sky mines kind of
mine to start at there's like three of
us and we basically are building a
neural net platform this talk is not
necessarily to tell you all about sky
mine I will show you a little bit of
code from our code base but primarily
what I want to do is cover what neural
nets are at a very high level I'm gonna
try to give you some understanding of
what GPUs are and then I'm also going to
show you some code I'm gonna show you a
little bit of code in terms of how you
interact with the GPU as well I'll show
you a little bit of code about how to
build a directional an actual neural net
how many of you have actually applied a
neural net before
alright great how many of you have used
GPUs before okay
how many of you need a nap alright so
this talk is going to be fairly
high-level you may already it looks like
a number of you may already know some of
the things I'm about to cover and I'm
also very welcoming if you have any
input at the end depending on how the
time goes so in terms of the talk I'm
going to start out like I said to talk
about what neural nets are and
specifically I want to take you through
sort of the operation how it functions
and this is extremely simplified but
ultimately they are a machine learning
algorithm for pattern recognition or
pattern or prediction and basically this
idea was born off of the brain it's not
that you are completely simulating the
brain but it's a very rough abstract
concept of the brain functionality
specifically if you think about neurons
firing and synapse is connected and
transforming data and as I speak
actually there are neurons that are
firing in my brain and they're
interpreting data until and passing that
data along until at some point there's
some type of understanding and some type
of result that's coming out of it so
that again extremely have simplified
abstract and that concept was applied in
an artificial neural net in terms of
saying okay well we're going to have
some inputs and we're going to transform
those inputs and have some type of
result at the end and what you see up
here in two
this diagram is the green nodes are
representing an input you've taken some
data you've translated into a numerical
representation the blue nodes are
representing the computation where
you're doing your processing of that
data and each node is doing its own type
of computation and interpretation of the
data at the end that orange node is
really giving you a sense of what's my
result and where we're seeing a lot of
the actual real value for neural nut
applications are in supervised learning
this means you actually know what the
outcome should be you know what the
answer should be
you've got your math textbook you're
trying to do an equation and you look in
the back to get the answer so by doing
that kind of error checking you can go
back into the neural net and into these
computations and make changes to them
and tweak them and tune them to get them
to fit and model whatever problem you're
trying to solve and how you change that
is that as you can see I've got this
equation highlighted on the side and
that one is your linear transformation
this linear transformation is typically
what you will have on every single node
that's in this net and that linear
transformation is basically saying all
right I'm taking in an input or several
inputs really and that's what X is
representing it's representing multiple
inputs that are coming in to just one
node and then it's applying several
weights and multiplying those weights
summing that information together and
then it's applying there's an additional
function that's being applied that I
don't have actually up on the slide but
it's usually known as your activation
function and so combining all of those
computations together you're basically
going to determine what signal will this
neuron send off what signal with this
specific blue node send off to the rest
of the net and that's really what's
going on throughout and this is very
simplified this structure that I have up
here I mean technically for a neural net
you could just have one neuron but
typically when you're working with them
in real-world applications today you're
gonna have easily hundreds and just one
layer and I when I talk about a layer
I'm talking about that vertical
representation of the blue dots on just
one vertical representation that's a
layer you could have a hundred you have
thousands you could even have million
I wouldn't be surprised if some people
are going even further than that based
on whatever type of structures they're
building but I'm just trying to give you
a sense of just sort of an overall how
this functions what's going on and
they're real key to hone in on in terms
of where this has value if as you build
this and train this and you change those
weights that's where you start to make
this fit the problem you're solving okay
hold on to that thought we're gonna come
back to it so why do you care why do we
want to know about neural nets why would
we even want to use neural Nets
well why we care about them is because
they're playing a significant role and
especially in the areas of image
processing and language processing these
areas are great in terms of the type of
data you have that you can interpret
that data and model that data with very
rich feature sets or attributes about
that data so neural nets are being
applied to things like talking to your
phone or self-driving cars image
recognition if you have any kind of
interesting software that is able to
identify people or objects in the images
that you put into it it's also taking
shape though and solving some other
interesting problems and I think this
resonates more with this crowd
you know actually finding anomalies
anomaly detection somebody was telling
me about a windmill farm that uses
neural nets to identify when a windmill
is about to break or any kind of issues
that might be going on in the
functionality of the windmill and the
mechanics of whatever's going on with
the windmill it's also pretty popular in
terms of financial models but where it
really is resonating I think mostly with
companies is around things like
recommender engines and ad placement and
more specifically things that are going
to be around personalization so being
able to take in a lot of information
about your users or your customers and
finding ways to pattern match and more
uniquely interact with those users but
through models good better and different
you can decide on that but that's where
neural nets are going to start to
resonate more and more with companies
and why they care about maybe spending
some money on implementing them so
how neural nets are playing more of a
role nowadays is because or how this
equation is actually coming up a lot I
mean you hear about deep learning and
that's really neural nets actually but
you hear about it a lot when you go to
different tech conferences and the
reason why it's playing such a
significant role while we're seeing real
results from it it's because Moore's Law
has allowed us to have significant
increases in our computational power
just in the last ten years alone these
ideas around neural nets and how they
function has been around since the 50s
it's just that we finally are starting
to see the technology catch up and show
us that we can't apply it in a way that
we want to additionally we have and I
know this is a jargon it gets thrown
around a lot but we do have big data we
have a lot of data that is stored and we
have a lot of labeled data that is
stored Mechanical Turk has allowed us to
label a significant amount of data and
so that's helping us to actually see
some real results in these neural nets
and understand what we want to get out
of them to really kind of hit home in
terms of what's going on with this this
structure how it works how you want to
think about it functioning this is an
example of a computer vision problem and
this computer computer vision problem is
basically taking images and I'm trying
to predict who this person is so I take
an image of a person and I'm breaking
that image down into pixels I'm going to
convert each pixel into a number and
that number will represent how gray is
this pixel that's what I input into the
actual neural net from there I have
multiple layers I've overly simplified
how this structure would be in terms of
computer vision because I really don't
have enough room on the slide but each
layer is representing different features
that you would look at inside of this
picture and you have one layer looking
at edges for example different edges and
we could say a portion of an edge of a
picture and maybe one would be
recognized in one of those nodes and so
each node would represent different
portions of the picture another leh
would look at object parts like a nose
or an iron ear and another layer would
look at faces specific faces and based
on whatever inputs are being signaled
from the previous layer let's say we're
looking at that object parts layer we
got a nose we got an eye we got an ear
and we those are the signals that are
going into the face layer we'll say wow
it's like a puzzle we're starting to see
the pieces we think this is actually the
layer we think this is this face we
think it's Einstein now that's not I'm
Stein we know that but we know that we
at least are starting to get some kind
of result out of snit and now we need to
train it and to train it we will go back
with the errors that we've calculated
and update our weights and try to make
this model more accurately predict and
classify what we want to get out of the
snap so that's to just give you a sense
of how to think about the net how to
think about how it functions what's
going on inside of it
the biggest challenge even though our
computational power has taken off over
the years is that training time is still
our bottleneck that's where we're really
hitting against the wall and people will
spend easily like days sometimes weeks
even months maybe years potentially
trading some of these neural Nets
because the reality is when you start to
talk about these structures and how
large they are and how many moving parts
there are and there's a lot of moving
parts a lot of parts that you can start
to tweak in tune to make these models
fit the training time is significant so
in order to make that improve there's
always ways to find things to go faster
and that's why GPUs are playing a role
with neural nets nowadays GPUs graphical
processing units used to make what you
see on the screen show up on the screen
that's where they they've been primarily
focused but they're fun there's a lot of
researchers that are starting to use
them more and more in terms of doing
computations because they're good with
floating-point operations in particular
they're good with parallel processing so
GPUs are your labor while CPUs are
really more of the decision-maker I
think most of you will probably already
know some of this but you know really
CPUs they're you know they're great
they've got a lot of memory they have
faster clock speed but depending on the
type of problem you're trying to solve
them the type of calculation trying to
do GPUs can really shine and neural nets
are a great example of where they play a
fantastic role because there's
independent
Galatians independent kind of math and
there's a lot of data you want to
process so if you can split it up
correctly across the GPU you can make
things go pretty fast and specifically
there's a great example that Google did
back in 2012 called disbelief and
specifically they had he used about a
thousand servers with 16 CPU cores on
each server ultimately they ran this
model to watch a bunch of YouTube videos
and the idea was we want to see if we
can identify certain objects it became
known as sort of this model that was
really good at identifying cats it
actually could do other things find
other objects than just cats but that
was of course the thing that resonated
the most ultimately they as you can see
spent 5 billion dollars and after a week
they got some great results but then of
course Stanford and actually Baidu also
came along and were like we're gonna see
if we can do this with see with the GPU
and I think you all are all can already
see with three GPUs they basically used
a lot less resources and if they throw
them probably a few more GPUs that it
probably would have spent less time to
just get the same type of results so you
can save time and money and if you want
to really get serious about applying a
neural net in a company you're working
with that's why you want to spend some
time understanding how to do this on a
GPU so just a level set in case there's
anybody here who has not worked with the
GPU before I just wanted to give some
context around certain terminology to be
aware of specifically if you're working
with GPUs usually you're working with an
Nvidia or an AMD card they are the
manufacturers that you usually go to and
videos winning the race in regards to
using GPUs for neural nets usually and
the reason why is because they've spent
a good amount of their time and effort
towards developing some pretty good
software to integrate with the neural
nets and with the GPU cards they've
built CUDA ku DNN which is basically
kudo integrated specifically for deep
neural nets ku blast which is for
especially the matrix math components
these are software drivers that they've
built out to make it easier to integrate
with their cards and with their chips
OpenCL is the alternative in terms of a
driver to integrate what
chips it's open source and it actually
works also you know it works on GPUs it
works on both AMD and NVIDIA and it also
works on CPUs it just hasn't received as
much love and attention frankly for
development I think there's some work to
try there's some efforts to try to
combat you know making it CUDA and not
be the only leader in this space but
frankly neural nets are still a bit of a
niche and that's preventing I think some
of the development that we could see in
that space but if you have any interest
you should jump in okay so let's talk
about a little bit more about why you
would use a GPU and the way I'm going to
do this is I'm actually gonna approach
it from where the challenges are with
the GPU and specifically the challenges
you're going to hit up against are
moving data on to the GPU and I think
some of you are probably pretty familiar
with this memory limits because the
reality is based on the register size
for GPUs usually you're hitting up
against about a four gigabyte memory I
think they've done some configurations
that allow you get up to 12 but you have
to be cognizant of that memory limit and
then branching because GPUs like to do
parallel processing so if you've got
branching code that's where you're going
to start hitting some issues and really
getting your performance now let's talk
about moving memory so here's the thing
right you're working with the GPU and
when you're working with the neural net
you're gonna probably work be working
with easily gigabytes most likely
terabytes and sometimes petabytes or
more in terms of the data size that
you're trying to process so this of
course is starting to touch on well so
the thing is first you got to get the
data on to the GPU and to be able to get
the data on to the GPU you have to take
it from the CPUs memory onto the CPU
move it over to the GPU and then move it
into the GPU memory
we got latency issues right right away
there are some efforts in the
unfortunately diagrams falling off the
screen there but there's some efforts
underway mostly from the software side
to make this seamless and to optimize
how the the memory is being moved back
and forth or how the actual data is
being moved back and forth between the
memory in addition to potentially doing
some pointer sharing between the CP
the GPU so that the CPU can access the
GPUs data at certain pointers I'm
actually not gonna dive too far into
this but just making you aware that
latency in terms of moving data on and
off is an issue drivers are being
developed and hardware is being looked
at in terms of how to make that go
faster you want to think about that when
you're working with it and as I was
starting to kind of dive into memory
limits or your next problem is you're
talking about how much memory are you
working with so if you can only put a
certain amount of memory onto the GPU
then you need to start to think about
well okay do I need to move all of this
data especially if I'm working with
images can I resize the images or the
video and in a lot of cases you
typically can so those are things the
techniques that people are using to be
able to move to work with a lot of data
as well as mini batching if you've got
thousands millions of examples that
you're working with you'll usually break
that down into maybe 100 or a thousand
examples that you batch through the
actual GPU to process but most
importantly distributing you're already
doing some type of distribution across
the GPU in terms of the computation and
the data but you'll probably start to
look at options in terms of using
multiple chips multiple chips in one
server or multiple chips across multiple
servers to be able to process your data
so you can do things all at the same
time across multiple chips which I think
everybody here already understands that
concept the approach in terms of
splitting you're using multiple GPUs
typically splitting data you're usually
thinking about splitting data and most
of the libraries that you would work
with to run a neural net approach it
from a splitting data perspective there
are some groups that are looking at how
to split neural net models how to take
the actual computations across that
model and literally break them out and
put them across different chips you
start to hit across more of a challenge
of making sure that each chip sees all
of the data and then there's a
researcher out of Berkeley who's
actually looking at does the neural net
model have to see all of the data and
can I split both that's about as far as
I'm going to go into
in terms of how to split the data but
there's some fantastic research out
there that you can look into if you find
this interesting so let's talk about
branching so on the GPU chip you are
typically you the smallest component
that you're working with is a thread and
you have some control in terms of
defining how many threads or you're
going to break into blocks and then how
many blocks you have in a grid and the
way you would work with this information
is that you will potentially divide out
your computation across those blocks now
you have to be aware of the fact that I
think you guys probably get this that if
you're working with the block that block
only wants to do one thing at that time
it doesn't want to do multiple things it
doesn't want to do it doesn't want you
to have a lot of conditionals it's like
give me one task
give me one computation and I will do
that and then when I'm done with that I
will move on to the next thing
so this is key because the reality is
when you were building out your program
to work with the GPU you really don't
want to run all of your code on that GPU
you want to run the component that is
going to receive the best benefit from
parallelizing it and doing something in
parallel so in order to do that or where
you're going to find the best benefit is
in this linear calculation this linear
calculation usually is going to be o of
N squared or o of n cubed depending on
what you're doing with this neural net
and how you're building the structure
here and that you can enroll across the
GPU because it's independent so I have
this one layer for example with the w1
w2 w3 w-4 if you're able to see that and
why I emphasize those was because you've
got an example I've got one picture that
pictures broken into pixels I've got on
the first node that first node in this
top layer right a set of weights and I'm
going to apply those weights to that one
picture and so in order to do this I
could pass this through a thread on the
CPU and it'll loop through and multiply
each value together or I could say hey
this one block of threads on my GPU take
these value split it across those
threads and then apply and then do this
calculation all at once just taking you
through this from the standpoint of this
is how you start to think about doing an
ovince squared computation and bill and
basically breaking it down into a know
of one potentially so there's a few
other ways and nuances in terms of how
you can break this out and how you can
think about it but this is where you're
going to get the most gain now in order
to work with the GPU this is an example
of some of the code you would
potentially leverage from CUDA and the
main steps that you're really going to
do to work with the GPU is allocating
memory moving data onto the GPU actually
defining a kernel that will do the
computation that you want to run and
then once you have the result in the
GPUs memory moving the data off and back
into the CPU memory that you can then
further do any kind of calculations do
you want to do from that point and
thinking is something I think is also
something it seems like this group would
probably have a sense of but multiple
ultimately you're potentially syncing
between the CPU and the GPU or syncing
across GPUs depending on the tasks that
you've divided out so I've just listed
up here you know some example code that
you would potentially leverage from CUDA
where CUDA will handle this operations
for you you just need to define the type
of pointers and so forth that you want
to work with but you know if you really
want to get serious about this you don't
have to use Cudas code you could start
writing your own compiler directives
from what I understand I will let you
guys look into that further if you
really want to get into the compiler
directive point the nice thing is there
are some packages that have done this
for you
they've made this a lot easier for you
there's a lot of packages actually that
have that are in existence that allow
you to easily define a neural net and
then also very easily integrate it with
a GPU if you have that on your system
several of them are in Python the data
science community is pretty heavy in
terms of focused on using Python
especially or Python and R and also I
know Julia's pretty popular how easy is
it
so cafes are pretty well-known and
popular one especially in the commercial
space they have what's called protobuf
files they're like yamo files so you
basically send in sort of here are my
configuration commands all you literally
have to do is say use GPU it'll figure
out the rest of it for you it will
handle me
allocating the the space moving data on
and off it'll handle all of that as I
mentioned in the beginning I work for
sky mine we have deep learning Forge a
platform it's in Java and we with Java
you have pom files which are your config
files and all you have to do is say
which back-end do you want to use and
we'll figure that out for you
siano python-based similar on the
command line or in a script you tell it
use GPU they have a couple of other
things you have to do to configure since
pythons a little bit of a memory hog to
tell it you know make sure that your
parameters are within a certain space
and so forth but it's it's fairly simple
it makes this a lot easier for you if
you want to pursue and not have to think
about writing compiler directives so now
I want to show you guys some code
because I know you're all thinking I
want to see more on that code or you're
not because I also wanted the challenge
and this is gonna be fun of showing you
guys how to do your own net code I know
you're all thinking oh we really wanted
to see Java we all love Java because
this is a little fun functional program
that's right so Java all right so I have
a class I have this class that I've
defined for you know basically oh and
actually I'm getting ahead of myself
I have a class and I'm going to show you
this example that I'm going to show you
is called amnesty okay so in this hello
world of neural nets if you may have
already seen this especially those
who've worked with neuronal nuts before
but bear with me it's the easiest one to
show on a presentation illness is
basically saying I got a bunch of
pictures of handwritten digits I'm going
to classify those pictures between 0 and
9 and the pictures are grayscale so I'm
converting these pictures into pixels
and converting those pixels into numbers
I've overly simplified this the numbers
are actually 0 through 255 and then the
structure I want to build is this
structure it's gonna be overly
simplified fully connected if you're
working with images you and you know a
little bit about structures you'll
usually use a convolutional neural net I
don't get I do not have enough time to
go through that today but I will show
you a little bit about just a
straightforward neural net and this
neural net 3 layers I'm actually when
you when you work with these
there's a lot of times they only count
the hidden layer and the output layer
they don't necessarily count the input
layer so we've got technically two
layers but I have two layers my input
I've got a 28 by 28 sized pictures so
that means 28 pixels by 28 pixels that
means it's 784 I have a thousand hidden
nodes that are going to do the
computations for me and I have ten
output nodes that will classify between
0 and 9 so with that said I've got my
class I've got my main method and that
main method will allow me to basically
say and I've got an exception in my main
method which is good but that main
method is going to allow me to run this
code and I'm going to define a couple of
variables and these variables are
basically allowing me to define one
number of rows by number of columns so
the size of the picture and then how
many examples I'm going to use a
thousand and a hundred I'm going to do a
batch size of 100 ok so I've got a
predefined data set iterator and this is
allowing me to say okay this is what my
data set is and so here's the thing if
you've worked with them this illness is
pretty much easily accessible anywhere
we just have a binary that you can pull
in and define how many examples do you
want to use and how do you want to batch
it you can pull this in set it up
however you want but the real meat of
this is where you define and actually
yeah we're gonna take it all where you
will define the
Oh
gotta love coding when my laptop does
not want to show me the example on my
own computer all right
live coding it's fabulous bear with me
I'm gonna get there though okay so
here's what I got right I've got this
multi layer configuration it's just our
way of saying this is an object that's
going to hold this configuration for you
so the configuration is basically taking
in a seed and I'm gonna make this
smaller because maybe that'll make it
easier it's gonna take in a seed and the
seed is one attribute that we're passing
in because when you build out your net
and I create these weights usually one
technique you used to create your
weights the first time out the gate is
randomizing them there's a couple of
different ways you can randomize them
just understand that you randomized them
and as you train the model there's a
number of things that you're trying to
tune so when you randomize the weights
out the gate you need to be able to
duplicate that you need to be able to
replicate that basically over and over
again so you use a C to lock that in if
you've done Mel dose before you
understand this I don't think that's a
surprise the iterations are my way of
saying how many times we're going to go
back into the net and update it as we're
trying to get our error to converge to
either zero or as close to zero or we
stop seeing a change in our error rate
so iterations it's just my way of saying
do it at least five times if I wanted to
I could say do it a thousand times or
until you converge if you don't converge
then stop after five my optimization
algorithm is a technique I use to
basically say this is how I want you to
update the weights that are back inside
the net do cachi gradient descent is
that optimization algorithm it's pretty
popular in terms of a technique that's
used for neural nets look into it
learning rate is just an approach that
you use in terms of saying how much of a
tweak or how much of a change will you
make on your weights when you go back to
make changes regularization is a way of
preventing overfitting so you don't want
your net to be perfectly much
exactly the training data you're working
with you need to have some chaos you
need to have a little bit of error in
there and drop connect is another type
of regularization that I would say you
know spend some time looking into it I
think you'd find that interesting as a
technique if you especially been working
with neural nets
all right so layers layers are where I'm
going to define how to actually make
these layers work right so I got the
blue layer and the blue layer is my
dense layer it's my fully connected
layer and so the number of ends are how
many inputs are coming into this layer
and it's number of rows times number of
columns so 784 inputs number of out is a
thousand meaning I could have up to a
thousand outputs coming out of this
layer so I have a thousand nodes and
then weight an it is just explaining how
to initialize I've got distribute just a
standard create a normal curve that's
what distribution is and when you see
dist and say normal distribution that's
what we're saying we're saying create
this normal curve and sample from that
normal curve to create the weights and
then activation is my activation
function that is better so activation
function as I mentioned you do your
linear calculation of x times W you sum
it and then there's an additional
function you will apply to this to
determine if you're going to have some
kind of output sigmoid is a popular one
and it's a way of saying okay I have a
percentage now squash it up to 1 or
squash it down to 0 in terms of figuring
out what type of signal you'll send out
there's multiple different types of
activation functions you can use when
you're working with the neural net I
would just say spend some time reading
up on that if you haven't already
explored it there's a lot that you can
do with the activation function and
different reasons on why you use certain
activation functions for certain
problems rail is a pretty popular one
and specifically we're a Lewis short for
a rectified linear this is a pretty
popular one when you're working with
image processing and dropout is another
technique we use for regularization and
then layer 1 is the output layer and
that's basically saying here are my as
you can see in out the 10 nodes the 0
through 9 classification nodes that I
want to define weight in it similar
activation function in this case is
softmax this is a type of sigmoid it's a
little bit more stable that you will
usually use when you're doing some type
of classification and then I all I have
at the end here is back prop and
pre-trained back prop is just saying go
back do the action apply back prop and
pre drain false means there's no
predefined weights that I'm using as an
initial weights and so with that
information defined in terms of my
configuration I will take that and pass
that into a model and basically this
model is saying pass this into a model
object that's multi-layer network object
and create this initial framework and
that's what the model in it is doing and
so it's really creating this template
okay so that we have the template good
to go what do we need to do once we have
the template all we have to do at this
point because I have my model object
template if you worked with second learn
before you'll just say fit and you'll
pass in the data and at that point
you'll say run you'll run it and it will
run this it will take in all the inputs
that you've given it it will go back and
look through it and train on it and come
back with the model and that model at
that point you can use to do further
predictions and classifications and you
be able to show you that that's going to
happen let's hope you guys will be able
to read this but here's my pong file
I've got JQ Blas listed here to show you
that I am using this as my back-end I am
going to run this in my IDE and let that
run for a minute and split a few more
things to you guys while it's running so
here's the thing I just stepped you
through just some example code on
configuration and and the reality is yes
that was in our deal for J package which
is open source by the way this is not
something you have to go by but the
reality is what I would try to take you
through with something that you can see
in other code bases you can look at it
in cafe you can look at something like
that maybe not so much in Theano if the
owner takes a
little bit more finagling but there's
other examples out there like lasagna if
you like Python that make it a little
easier for you to break down how to do
configurations for neural nets in terms
of running this on a GPU unfortunately
Nvidia does not provide nvidia SMI this
is a way for you to check in your
command line if your GPU is running and
how is it running you can use that on
Linux or Windows you could use eye stats
if you wanted to see you know how is
your GP performing just have to trust me
that it's working so while it's working
and it's probably done but I'm just
going to talk about a couple things four
techniques to troubleshoot one just very
high level there's no K CUDA capable
device or there's no CUDA available
sometimes your system will shut down the
CUDA or the the CUDA driver and you'll
just have to kick-start it again this is
the command I found that worked on my
laptop what's interesting is Apple's no
longer providing in video cards in their
laptops or in their towers so you know
you might not necessarily be doing a lot
of hard core development you probably
well you won't be doing a lot of hard
core development on Mac or on your
laptop even even if you had a Mac or Y
on the Linux so it's one of those things
where I wouldn't say that you have to
spend too much time thinking about it
when you're working with the system
you'll probably be working with
something through AWS or with Google but
something to be aware of if you're
trying to tinker with it at home if you
see kill you probably need to think
about do I need to reduce the size of my
mini-batch am i you know is my am i
blowing out my memory and if you're
trying to work with compiler directives
then you should think about you know
flushing and how often are you flushing
if it's running really slow you one of
the main culprits is is really how often
are you syncing across the GPU as well
as between the GPU and the CPU and
that's really something that you have to
look at from a standpoint of if you have
direct connection in terms of building
out the CUDA inter interaction yourself
or if you're using a library and
expecting the library to handle it for
you you might want to consider looking
at a different library and if you have
any kind of i/o error this is a simple
throw away when I just threw it up there
but you should look at whether or not
you pointed to the right place where
your
stored and let's go look real quick it's
done
we got a 69 percent accuracy it's not
amazing but you know it's not bad for
about a thousand examples and so yeah I
put this code and I put a lot of other
code some examples from cafe and from
siano into a github repo and I'll show
you that link in a minute I've got a lot
of references I'm going to be posting
these slides for anybody who's
interested that you know you're welcome
to check out I also had some people who
helped me put together this talk I'm
grateful for their time the main things
I wanted you to walk away from this talk
with is you know in terms of neural nets
they're going to play a role in a lot of
things around images and and language
processing and frankly they'll start to
play more and more role especially with
anomaly detection and I think those are
things that kind of resonate where it
will resonate with companies and why
companies will probably want to spend
time and money is because of
personalization and customization if you
want to get serious about it training it
is the hard part
GPS will help you with that GPS will
help you with that because they can do
the same thing multiple times at the
same time GPUs have not had a lot of
time and attention in terms of
development so I can do a couple guys
who work with them and you they were
explaining to me how there's so much
work and effort that's been put into CPS
and optimizing CPUs and there's a lot of
room for growth in that in terms of
development around GPU so if it's
something you find interesting I'd say
check it out but yeah this is where my
github repository is for where I will
have the code posted I work for Skyy
mind we are open source as I mentioned
we are currently working on building out
Scala bindings if you want to come and
help us out if you want to do interests
or Pascal or closure at pod a school but
closure or any kind of other bindings
bring it we'd love it more importantly
getter we have a community we have like
about 600 people on getter and it's just
a chat platform that's through github
that get together and we talk about
neural nets developing them the
challenges you have so if it's something
you have questions on or want to explore
you don't have to necessarily use our
platform I think you'd find it just
interesting from a community perspective
in terms of people to talk to and work
with I'm continuing to develop it so I'd
say you know feel free to check it out
and that's all I got I just want to give
a shout out to strange loop and Alex
Miller and just giving me the
opportunity to come out and speak and I
appreciate your time thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>