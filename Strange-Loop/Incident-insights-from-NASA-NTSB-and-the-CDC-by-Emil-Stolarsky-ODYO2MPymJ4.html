<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Incident insights from NASA, NTSB, and the CDC&quot; by Emil Stolarsky | Coder Coacher - Coaching Coders</title><meta content="&quot;Incident insights from NASA, NTSB, and the CDC&quot; by Emil Stolarsky - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Incident insights from NASA, NTSB, and the CDC&quot; by Emil Stolarsky</b></h2><h5 class="post__date">2017-09-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ODYO2MPymJ4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">to start I'd like everybody here to
think about somebody that's important in
their life right now can be a relative
maybe a parent a sibling your children
or a close friend now picture a
Wednesday morning you walk into the
kitchen and there they are on the floor
unresponsive what do you do you call
9-1-1 the phone rings ring is the gun
rings a third time but there's no
response you think yourself okay maybe I
didn't put the number in right
nine-one-one the phone rings rings again
but still no answer on April 9th 2014
this happened over six thousand times on
this day the 9-1-1 routing system went
down in seven states across America what
had happened is over time we've been
moving our 9-1-1 routing systems away
from telecommunication equipment to IP
based routing a third-party provider
where the name of in Trudeau is one of
these providers that runs this IP system
and on this day their routing system
broke so when a 9-1-1 call goes out it
hits a routing provider and the lists on
a unique ID and then decide which call
center to for that number to that unique
ID is used to identify the call in the
case across multiple departments from
the call center to the fire department
EMS or the police department but there
was a bug in widows code they had
hard-coded the number of IDs they be
able to generate and on April 9th they
hit that limit it took over eight hours
to rectify the issue the software we
build the systems we build the stuff we
put out there has real impact and we all
commonly say that software is eating the
world and as it's doing that our
responsibility to the people around us
grows we're moving from a time when our
systems not working
somebody couldn't consume media on the
Internet to today where if our systems
don't work people can't pay their bills
transportation grinds to a halt and they
can't reach up for help to 9-1-1
I come from Ontario the province of
Ontario up in Canada and in Ontario whoo
clapping for Ontario and across to
Ontario in Ontario over 50% of our
energy is generated through nuclear
power and if you're lucky you can
actually go and get a tour through one
of these factories so imagine you're
walking through and you're seeing all
the engineers and their hard hats you've
seen the control room with the dials and
the gauges and the buttons controlling
everything and you're walking on your
way out and you see something on the
corner of your eye move fast and break
things
gives you pause for a moment doesn't it
I mean this nuclear power plants only
100 kilometers away from where I live
I'm not sure I want the nuclear
engineers there to be moving fast and
breaking things yet if we were to walk
into any tech office in the valley here
and you saw this sign he wouldn't think
twice
of course it's there if we think about a
nuclear energy though we think of this
highly reliable secure
they've got all they've got everything
sort of figured out how to build secure
systems but it turns out this isn't the
case back in 79 this is a picture of the
Three Mile Island power power plant in
1979 after a series of mechanical
failures and operator mistakes one of
the reactors had a meltdown and during
this meltdown and as the ensuing
emergency sort of evolved it turned out
there was no plan they'd built this
nuclear power plant
assuming they build a bunch of safety
into it but they assumed it would always
work there'd never be an issue so when
there was an issue and people had to say
okay what do we do now nobody had an
answer and an only after this event in
1979 did we say all nuclear power plants
going forward how to have an emergency
plan if something blows up if something
goes wrong we know what we're gonna do
and how we move forward in the airline
industry they have a phrase for this
it's called tombstone mentality every
now and again there'll be something
maybe a mechanical failure maybe a
cultural problem that everybody will
know will be aware of but nobody will do
anything to fix it until there's an
accident and somebody pays their life
and that's because people are reactive
all of us we wait for something to
happen before we figure out all right
what are we going to do
when something goes wrong the problem is
is that in the past all these different
industries all these different accidents
the repercussions were localized for us
software its biggest selling point is
its leverage
we can have one engineer build a service
for 100,000 engine people out there if
our software breaks it's not going to
affect maybe a part of a country it can
affect an entire continent or potential
even the globe so what's going on is we
don't have that luxury we don't have the
luxury that other industries had to wait
for something to go wrong and then learn
from those lessons instead we have to be
proactive somehow we have to look out
see where we can grab these lessons and
then learn from them luckily there's a
lot of industries we can do that with
there's the aerospace industry energy
medicine natural disasters to give you
an idea of how long these other
initiatives have been doing it the
National Transportation Safety Board has
investigated over a hundred and forty
thousand aviation incidents today you
would have to travel every single day on
an airplane for three thousand years
before you experienced an accident
there's a lot we can learn from these
other industries so my name is Emil I'm
a production engineer at shop five and I
think a lot about the impact our
software has on the people around us
when it works and when it doesn't work
and about a year ago I realized that
wait if all these other industries have
already went through a lot of these
problems
what can we go and learn in these other
industries and take back and apply and
software and so that's what I did I went
out I started reading a bunch of really
dry manuals read listen to podcasts read
books and so today I'm gonna be showing
some of the things I learned that I
think would be very powerful and useful
for you all to take from go back and try
to implement so when you go and dive
into emergency management which would be
sort of the academic term for it
all emergencies crises or disasters can
be broken down into sort of four cycles
or four steps you've got mitigation
preparedness response and recovery
so with mitigation this is trying to
identify the risks and where the issues
can come from
and reducing their chance of occurring
preparedness is how do we respond to the
Institute when it happens response will
be the actual response and recovery is
getting back to normal so way I like to
think about this is say you have a
database service and your application
calls out to the database service and
this database has a primary and a
standby mitigation would be modifying
your application so that if it loses
connectivity to the database it can
still serve some requests preparedness
is having an on call if the database
goes down who's going to go and respond
that's preparedness response is actually
the tools you'll be running so that you
can switch over from the primary
database to the standby and then
recovery is sending up a new standby for
the currently running database so
mitigation with mitigation is actually
interesting because in the outside of
technology mitigation is almost viewed
as is it isn't really focused on there
is a phrase that's often that's used
nobody ever got fired for failing to
mitigate a disaster disasters will
always happen so why invest in in
lowering their impact but we know in
tech that's not true Cheerilee by the
number in size of our services we know
that good investment in resiliency can
have a big impact but there's still weak
stuff we can learn from other industries
so as I was reading through these
materials I was getting on to reading
about how engineers design airplanes and
rockets every single part in an airplane
is meticulously tracked how long it's
flown how many times has been flown when
was the last time maintenance was done
on that part and then if you hit a
certain number of pressurization x' the
part will either be replaced or it'll be
rated to do another sort of number of
pressurization x' imagine if every time
we wrote a function we said this
function is ready to be called a million
times and at the millionth time the
moments called there's somebody gets an
issue
and now we have to go and have to
reevaluate maybe the function works
great maybe we don't need to rewrite it
or maybe we realized that we didn't
build it properly the first time and
then going we do a refactor this sort of
approach could be very interesting
another thing is actually putting risk
numbers and chances of failure to our
systems there's a lot of tools that the
aerospace industry uses to assign the
chance or likelihood of something
breaking and one of these is a fault
tree so in a fault tree you're doing
deductive reasoning on a single
component in your service failing and
then you'll build out boolean operators
going down so if a database service that
has quorum in order for it to to lose
quorum it needs to lose up to three
notes if there's five so you would have
an and operator that would say three
nodes go down now on a node you'll say
okay the node stops working if it loses
its network connection if the disk fails
or if the CPU blows up so you can have
an Oran either of those three and then
you can go and look at the data and you
can say okay well the chances of the CPU
blowing up is 1% the network card
failing is 3% and the disk failing is 1%
and then you can look at all that and
you can sort of calculate the
probability of that particular system
failing and then you can look back and
say okay well which components are
should we focus on where should I lower
the chance of this system failing or you
can say hmm it's not great that these
things are decoupled or that they're
coupled and that any one of them failing
would cause a whole section to fail so
this is a fault analysis tree from an
airplane and there's actually software
out there where it's just like hundreds
of levels of these fall trees so with
the fault tree what will happen is say
for instance it says like fire and
explosion if another service or system
will break because of a fire explosion
there'll be a whole other tree and
that's just one of the branches off of
it
preparedness is when I was going through
the material and preparedness
oftentimes it could feel a little dry
you sort of going in you're like this is
just a bunch of process I don't I don't
really see how it can help me and when
I'm sort of reflecting on when would you
really say okay I need this I was
thinking about on-call rotation imagine
when we were first bringing out the idea
of on calls into tech organizations you
would say all right I set up the system
it works it shouldn't break and then you
say right now whose job is it going to
be to fix it when it breaks it kind of
feels weird it's it's almost like well
it's not supposed to break why should we
put anybody on a rotation to fix it so
preparedness is almost like that where
it's planning for failure so in 1970
there were a series of forest fires in
Southern California the biggest one
being Laguna Fire over 13 days five
hundred thousand acres were burned seven
hundred buildings were lost and 16
people lost their lives
and during this fire both the Los
Angeles County and the Los Angeles City
Fire Department we're trying to fight
the fires what happened though is
instead of them effectively fighting it
they ended up having miscommunication
people didn't go to fires because they
assumed somebody else would go and deal
with it in that location and afterwards
given the disaster that that whole
response was they put together a
commission and they said okay what
happened we can't let that happen again
the Commission realized that in
retrospect having a single fire
department would have been more
effective than having the two
departments fire and they said okay how
do we avoid making sure this doesn't
happen again
and they came up with the incident
command system ICS
so you can think of the incident command
system as putting a formal structure on
dealing with issues or emergencies if
you think of an orchestra the conductor
is necessary to be there for the whole
orchestra to be able to play that
beautiful piece of Mozart
without them it wouldn't be the same in
an incidence the same it's the same
story you need somebody who's in charge
and responsible you can make executive
decisions on what needs to be worked on
and what can be ignored at the time the
incident command system is this idea
that you have a formal tree structure
people constantly report up and then you
can delegate out it this system had
great success and it moved on and
evolved into NIMS which is the National
Incident Management System but it still
has the same key ideas if you go out and
you do and you sort of look at the
official documents you'll see these like
very large trees with a finance officer
liaison officer and the reality is the
most important part is having somebody
in charge having that structure think
back to the last incident or a doji
dealt with that work there was somebody
implicitly in charge in that moment this
the incident command system formalizes
that and what's interesting about the
incident command system is in the tech
community a few companies have begun
adopting this so we've seen facebook
picked us up with their crisis managers
at Shopify we have I mocks or incident
commanders and their role will be during
an outage though they're in addition to
their sort of day jobs they'll be
getting paged when there's a big enough
incident and they're not supposed to fix
the outage they're not supposed to
actually bring the services back up
their job is to make sure the right on
calls are there the young calls have
their tools that they need and that
customers are getting the information
they need that the stakeholders to know
what's going on response so
we all care about response and I think
we also sometimes tend to over focus on
it but even with that there's a lot we
can learn from under industries about
him so this is the bee same b-17 in
1930s the US Army / Air Force were
running a competition between multiple
airline manufacturers to figure out what
new bomber they wanted to purchase and
the b-17 was sort of the exciting shiny
new toy it could fly twice as far it
could carry a lot more weight than any
other plane and it was a lot more
resilient to damage and so they had most
of the military officers who were part
of the procurement process come out to
the airport to watch what the b-17 take
off and show up at skills and inside
piloting it piloting it was the head of
the test pilots for the Air Force and
very experienced first officer seventeen
seconds after liftoff the airplane
crashed nobody knew what happened how
could it be that such a good airplane
and such experienced pilots had crashed
the airplane the airplane didn't fail
mechanic Winn what had happened is that
certain gauges had to be enabled for the
airplane to take off but shortly after
takeoff
they had to be disengaged the thing is
is that both the pilots I forgot to
disengage it so they got a bunch of the
test pilots from the air force in the
armor to go and sort of think okay how
can we learn to fly this airplane what
do we do and interestingly they came
back and they didn't say we need to get
better training instead they said we
should use a checklist and so this was
the first checklist used in airplanes it
went over some of the most important
things to make sure you're doing before
takeoff during takeoff just after
takeoff before landing during landing
after landing and we've seen this
evolved over time to sort of take the
airline industry by storm if you think
about a professional uses checklist the
first thing you're going to think of is
you're going
think pilots it's so prevalent at this
point in Airlines that when two airlines
marriage the most contentious part is
often which checklist will be the
dominant checklist for that airline now
imagine the last time you were in an
incident we all left playbooks
right we all have if this service goes
down these are the steps you should do
but how often do we fully believe and
let the checklist guide us when I was
reading about checklist I was thinking
okay I can see the value but airplanes
are very mechanical they're very for
this comes first then comes a second
thing then comes a third thing and I
wasn't excited by the idea of taking all
the thinking out of my response to an
outage but interestingly checklists
aren't that checklists are a way of
automating your thought process during
an emergency you don't put down debug
issue on checklist you put down the
obvious so for instance if somebody
deployed a bad code the first thing
you're gonna do is lock deploys why
should the person who's on call and
responding to the issue always have to
remember that we can put that on a sheet
of paper they take out bad deploy
checklist go first thing lock deploys
done you're freeing up your brain cycles
on the more important the more complex
issues that are going on at the time
so this next story is United Airlines
flight 173 the United Airlines the
flight was from JFK to Portland with a
stopover in Denver the flight made it to
Denver everything was fine and then on
landing into Portland odds were lowering
the landing gear they heard a thud it
seemed like the gear was down but the
light wasn't wasn't showing that the
gears were down securely so the pilots
they had the captain the first officer
and the flight engineer decided to do a
go-around and waited in a holding
pattern until the gear until they could
figure out in debug what the issue was
so it took them an hour they were flying
around and then they decided okay we
should start landing so they said we
won't be able to figure it out and on
their approach to landing all four
engines stopped running they'd run out
of fuel
and the airplane crashed just before the
runway so investigators went and looked
at the story we're trying to figure out
what had happened the captain of the fly
was one of the most experienced pilots
at United flying this particular
airplane and when they first on the
first approach into Portland they had
over an hour of fuel left to debug the
issue they found the flight recorders
and it turns out on the flight recorders
both the first officer and the flight
engineer tried to point out that the
airplane was running out of fuel
but the captain was so engulfed and
trying to figure out what happened to
the landing gear that he didn't
acknowledge it the flight engineers at
the flight engineer and the first
officer didn't know what to do and so
they didn't say anything in the 7 in the
late 60s and 70s they went back and they
looked at all the recent airline
accidents and they saw that in over 70%
of the cases pilots had known what the
problem was but failed to make their
other pilots aware of it or point it out
or force a solution
so what end up happening was all the
airlines knew there was a problem the
NTSB knew there was a problem and they
went to NASA and NASA and a bunch of
psychologists came up with an idea crew
resource management crew resource
management it is is this formalization
of interactions between people operating
an aircraft so it it seems very obvious
when you're going over this so this is
sort of the suggested way to talk about
issues or problems on an airplane of
course you're gonna try to get people's
attention of course you're gonna point
out the problem but this wasn't
happening and what happened is once this
came out the airlines starting with
United and then all other airlines went
okay no we are gonna beat this idea into
all of our pilots in training you always
talk about how do you identify an issue
how do you point it out how do you talk
about what the solutions gonna be and
they saw that it worked amazingly this
is sort of an example to give you an
idea of what this might look like when
you I was throughout my research I was
listening to pilots tell stories of near
misses and well in every single one of
those stories they always talked about
crew resource management they always
said the first officer knew to go and
work on the issue and I was finding the
plane or they said I asked them to fly
the plane I was working on the issue we
called out what things were going on and
so I when I think about crew resource
management I think about all the outages
that I've experienced a shopify I think
about the times where something went
wrong an engineer came in and said hey
this is broken this is broken and
everybody just ignored them we didn't we
didn't we didn't immediately hop on it
because there was six other people
saying oh this is broken no this is
broken and then we go back and we say oh
look we have seen this 40 minutes ago
and I'm sure this is the case everywhere
so imagine if we had started training
ourselves to go and use this system
which seems very basic to respond to
incidents and outages never waste a good
crisis recovery is arguably one of the
most important cycles in an incident
after you go and every every incident
has a price to pay
you're either paying for it financially
you're paying for it with time or worse
so we want to come out of all our crisis
disasters incidents outages smarter we
want to say how do we make sure this
doesn't happen the next time how do we
say to the next time something breaks we
can fix it faster we have RCA's and so
our ACA is our crook show of hands who
here has runs our CSI work after
incidents are outages almost the
majority of the majority of the room in
RCA is a lot of the time they almost
feel like process there you formally sit
down and you go through your five whys
why did this happen why did this happen
why did this happen and you try to
identify the root cause but really it's
not what we want from the root cause the
root cause often doesn't give us the
exact answer we're looking for if you
think what's the root cause of people
falling gravity gravity's the root is
the root cause of why people fall but
that doesn't give you a lot of
information if a bunch of people are
following outside on the stairs are you
just gonna blame gravity are you gonna
file an issue no you're gonna have to
figure out why in that specific area you
what's the context of people falling in
that location and root causes it sorry
and doing retrospectives or post-mortems
also they're a way of fighting our own
biases we're all biased people we all
have our own biases that we need to
fight and having a process and doing it
with a team will allow us to sort of
point out each other's biases so one
bias is fundamental
you sneer or as I'm sure we've all
written at least once on an RCA Doc
human error if you look back in time all
mistakes look like a choice the operator
chose to fail over the database the
operator chose to ship broken code but
that's not really the case right in
hindsight while everything all the
answers look clear they're not in the
moment and so it's important that when
we look at different ways other or
organizations are running our CIS we
look at what tools can we take to sort
of adopt a system that'll allow us to
get rid of more of these biases and NASA
is a very interesting one it's it's
called a causal factor tree and so what
they'll do is when there's an issue
they'll map out all the events all the
things that failed in the conditions at
that time and what's interesting about
this is it removes this idea of
linearity you had multiple things going
on in parallel instead of a leading to
be leading to see any of those events
could have happened at different times
and it gives you a clearer picture of
what happened in that moment here again
is another example where it's talking
about a rocket part failing and all the
other a lot of the industry is out there
so like for instance the aerospace
industry has tooling built for building
these sort of trees and models in
analyzing incidents that happened so
it's not like we'll have to go out and
do these things ourselves people are
ready doing this we just go and spend
the effort to pick them up and learn and
see them and and try to implement them
one final very neat thing that's out
there is the aviation safety reporting
system in 1968 the head of the aerospace
or sorry Aeronautics Board in America
gave a speech and was talking about how
everybody knew and had a lot of internal
data on near-misses
so if there's not an actual accident you
don't have to technically have to report
it you can just file it away and every
airline had their own stories their own
horror stories they even knew in some
cases with problems with aircraft but
they didn't talk about it and so he was
saying in the speech how this is not
okay and NASA went wait a second we're a
neutral third party we don't have any
any leg in this race so they set up the
aviation safety reporting system every
pilot can if there's a near miss or an
accident or a situation that they want
to talk about can anonymously go and
report the full story to this service
then every other pilot can go and read
through different reports the ASRs will
issue monthly newsletters I'm talking
about common themes that are going on in
fact the FAA is forbidden from
prosecuting any pilots that have may
have done things incorrectly if they
submit the report to the SRA SRS imagine
if in tech we had a similar system who
here has deployed bad code into
production who here has seen a database
go out at work who here has seen Network
issues I work mmm
seems like all of us who deal with
similar problems may be different
variations but I'm sure every single one
of those incidents could have taught a
valuable lesson to another company in
this room the ASRs does that for
airlines imagine if we started doing
that in the tech community
the future this path is coming faster
than we think we're automating away more
and more systems we're modernizing more
and more of the technologies we have in
our world machine learning is making
great progress we're upsetting
industries we don't have the luxury of
waiting for something to get our ass in
gear and care about this stuff we have
to start caring about it today and we
have to start going and looking at the
body of knowledge that's out there that
we can use in our own organizations so
I've been talking a lot about being
proactive and I thought it's only fair
that I leave you with an example of what
proactive companies look like and
interestingly it's Walmart and Waffle
House Walmart and Waffle House have a
lot of locations in the Southeast United
States and as we unfortunately learnt
this September that part of the world is
very prone to hurricanes so over time
the management in both these companies
realize that they can't just ignore the
problem they have to care about it with
Walmart before Katrina happened or as
Katrina was racing towards the southeast
United States all the executives
gathered in a room and said alright
we're giving we understand this is going
to be chaos
we're gonna give autonomy to the store
managers out there you're gonna make
decisions that you don't know if you can
make those calls make them any way do
the right thing so one store manager in
Louisiana took this to heart and after
Katrina the local responders and needed
extra supplies but the store was
inaccessible so what did she do she took
a bulldozer drove through the wall took
all the supplies put them out on the
parking lot and gave them away for free
then she broke into the pharmacy and
sent all the medical supplies to a local
hospital
in New Orleans Walmart was actually one
of the first companies to bring in
supplies because their supply chains
were so robust to dealing with natural
disasters and crises Waffle House give
it up for Waffle House Waffle House
similarly is tries to be very proactive
when it thinks about natural disasters
Waffle House actually runs two sets of
menus it's got its full constant menu
and then it's got a limited scope down
menu the limited scope down menu has
less perishables it doesn't need as much
energy or equipment to be functioning to
prepare it so during a disaster Waffle
House will actually scope down the
amount of items that's serving at its
restaurants to deal with the current
issue that I also have are very
organized in making sure what staff
can't and can't reach the store and can
work their shifts they're so good at
this that the director of FEMA nicknamed
and index about them so there's this
thing known as the Waffle House index I
swear all of this is true it's out there
I was just as surprised as you were
Green Waffle House is serving its full
menu it's not that bad of a storm yellow
Waffle House is serving only their
second menu their partial scope down
menu it's a pretty rough storm and then
red Waffle House is closed shit's real
so if I leave you with anything from
this talk try to be so good and so on
point about dealing with your incidents
with your outages that people think of
you and use you as an index for the
health of the Internet try to be the
Waffle House of the Internet
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>