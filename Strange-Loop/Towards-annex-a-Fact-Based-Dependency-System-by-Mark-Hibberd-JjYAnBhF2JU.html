<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Towards &quot;annex&quot;, a Fact Based Dependency System&quot; by Mark Hibberd | Coder Coacher - Coaching Coders</title><meta content="&quot;Towards &quot;annex&quot;, a Fact Based Dependency System&quot; by Mark Hibberd - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Strange-Loop/">Strange Loop</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>&quot;Towards &quot;annex&quot;, a Fact Based Dependency System&quot; by Mark Hibberd</b></h2><h5 class="post__date">2014-09-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JjYAnBhF2JU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">oh yeah so programming is hard well I'm
gonna say it's hard at least good
programming is hard yet we seem to
insist on using tools and practices
which make it as difficult as possible
so my name is Mark I'm here to talk
about a tool called annex and I work for
a place called NICTA which if you saw
Brian McKenna's talk yesterday
regrettably I don't get to play with
quad copters all day I build machine
learning pipelines okay
so the enemy is the gramophone mind
whether you agree with the record that's
playing or not this is something I think
about quite heavily when I'm building
tools it's the sort of thing where I
feel like we flip from one tool to the
other our current or old tools are
horrible next generation tools are
amazing until they're horrible again I I
want to take a more restrained approach
and start thinking about what are the
things that make those tools good what
are the things that make them bad so
annex is kind of my experiment in trying
to build a really refined tool with a
really refined set of practices so that
when I build my next tool I can reuse
these practices and keep going so
motivation I guess I probably need a
fair bit of motivation the world
probably doesn't need another crappy
dependency manager so this is kind of my
way of explaining how I came to
dedicating a large chunk of my time to
writing in dependency manager it's also
one way of saying that I believe doing
it all wrong or at least I'm doing it
all wrong hopefully everyone's doing
better than me so two point 0.1 Jack
fixed a bug the night after a release
because you know - OH - Jill went and
fixed the three bugs that Jack
introduced cause he rushed to one Oh
Jane shipped a new feature it was great
awesome 3.00 marketing got ahold of it
it's a pretty horrible situation
but surely this is a joke right we know
a lot about the tools the products we
build we know a lot about our projects
yeah we choose to pack all of this
information to a ridiculous number with
dots in it and look I sympathize right
semantic versioning is something that is
the best of what the tools currently
offer but it's really not good enough
and I'd really like to do that up so the
next thing is so since I've woken up
this morning I've shipped six different
languages to production
some scholars and Haskell some are some
C++ some shelves and Python I've used
eight different dependency managers to
do so but I'm really over language was
I'm really over the tools exist in
language silos we build crappy tools in
one language and then we jump to any
language and rebuild those same tools
programming problems as tools
effectively I think we sell the same
problem in every language all over again
so I want to build tools that across
language so annexes main goal is to be a
cross language divinity manager so I can
use it for scale or I can use it for
Haskell I can use it for shell I can use
it for our I can use it for managing
dependencies between machines on Amazon
I can use it and managing packages on
FreeBSD all these different things time
it's really important so for a typical
scenario for some given artifact I think
this is probably somewhat realistic
depending on your perspective but we
have the situation where you commit some
code we go through it might run through
some CI we publish that and we probably
stop recording information about a
little the little color change there and
then we start forgetting about things
but after that we do some platform
testing we ship it to production we do
some performance testing in production
we get some performance numbers back
eventually we let somebody write in C so
we've got a vulnerability as well it's
great but the point is is that we stop
recording information about our
dependency so early in our life cycle
and we have all this other useful
information that could be fed back into
the dependency
so I want to embrace the fact that
things change over time so this is
really important
and my last motivation is I'm a little
bit sick of closed world assumptions so
I'm going to pick on a particular tool
here NYX because it's the new hotness
that everyone really likes because it
has the qualified of reproducible builds
right and it's not a problem
specifically with NYX but I'll just use
an example is that this problem leads us
to burn the world situations where we
have to pretend that everything that
currently exists doesn't we have to use
NYX all the way down or we get subtle
issues that make our builds not
reproducible so any tool I think has to
accept that there's an open world that
currently exists a bunch of dependency
managers we have to interact with them
we have to be able to pull artifacts
with them in a sane way so basically we
have to assume that we can't control
everything from end to end and what's
the best way to manage that so that's
really important but the end of all this
is the dependencies cost too much right
now every time we pull in a dependency
to one of our projects we think really
hard and often we just don't I want to
get to the point where I can split code
bases like an do dependency management
on a hugely fine-grain up to like I want
to be able to depend on a function as a
dependency that would be great but at
the moment they just cost too much to do
that okay so the concepts of annex here
is a typical graph of the small set of
projects that I work on Napoleon's a
top-level project that does some data
management Boxer is a project which does
some hard lifting heavy lifting batch
operations snowball those some customer
management and Eminence does some
Identity Management so we have a little
triangle little diamonds where there's a
few dependencies so this example come up
a few times but it's also important to
realize that any single dependency graph
exists in a larger dependency graph you
just choose not to worry about it
sometimes so outside of this is a
haskell web app so boy it depends on Y
which depends on Haskell base it depends
on Postgres which depends on Lib PQ
which depends on the operating system
which depended on a C compiler
this all there are more dependencies
than you can possibly imagine and it
keeps going on and on and on so we have
graphs inside of graphs inside of graphs
we just choose to draw boxes around
certain points so the first thing is NX
is a facts store right so we want to
store a bunch of knowledge around what a
dependency is and all of our
dependencies at the same time so how we
do this we start with something that we
can store we call this a family so one
of our projects boxer but because we're
living in the future strings are not
really acceptable so we have some data
structures which always represent
everything is a unique ID and the name
is just some attribute that we attach to
it later on and we can change this if we
want so don't use strings Adams our
particular instance of something that
can be resolvable within a family so if
we use our traditional semantic
versioning this might be box of 1 to 1
which again translate to some atom ID
okay and then we start to worry about
facts so a fact might be a git commit it
could be an API signature so this is a
more complex fact so this isn't just a
single value it's a tree of all the
signatures of all the dependencies of a
single single API so that we can track
the overlapping between to look to
different libraries so you might want to
be able to say a question that I want to
be able to say when I'm doing dependency
management is will something linked
right so this one exposes all of these
API functions this one uses some subset
of it are they still compatible in that
subset so these rich API signature
structures let us work that out upfront
and then we can have arbitrary facts
things like feature flags and stuff like
that we ascribe facts to Adams should be
kind of obvious we take a bunch of facts
and put them against Adam so we'll end
up with boxer it might have this commute
this API signature this feature and then
we ascribe them over time so we'll have
a single world which contains all of our
all of our families Adams and facts and
these worlds change over time so if I
want to learn something about box
say for example I test it on FreeBSD 9.1
I'll go along I'll create a new world
so we everything is immutable over time
so you can always backtrack to the
previous version and so I can say that
there's a new view of of the world where
boxer has the tested attribute so this
kind of comes to one of the very
important design decisions which is that
everything should be predicated on
reliable and reliability and
predictability so the whole idea that we
never ever update a fact inline so
nothing ever version 1 of the world will
always be exactly the same as version 1
for everybody else for at all time so
you have to explicitly manage your time
and it makes things predictable and this
is important to undesigned decision in
general for tools and specifically for
NX so next thing is ax is a data store
so because we want to interact with
other dependency managers on and
interact with the open world doesn't
mean we have to trust it so at no point
until we ever download something
randomly from the internet this is a
pretty important principle but it seems
obvious but yeah so we can also as well
as tributing facts to Adams we
contributed artifacts so this might be a
source tarball it could be a binary it
could be have multiple artifacts with
different tags but you might end up with
something like this might be an
executable it might have been built with
this flag and I'll have this address
which I'll get to in a second so there
are a few important parts about
artifacts we want to be able to I'll
talk about it a bit later we want to be
able to substitute binary binary
artifacts for source artifacts and
source artifacts for binary artifacts so
the amount of information required to
know about an artifact such as all the
flags and all the dependencies was built
with is kind of important so you can
know where they can do substitution or
not the address is basically the content
address such as to hash of the actual
binary okay so that's important for how
we store thinks so effectively the data
store part is just a content addressable
storage where you can store things
locally or remotely everyone does anyone
not know what content addressable
storage is when I say that ok so so
basically content addressable storage is
the idea that
you have a data store of some sort
basically the only way to get to the
actual value in one of the one of your
values is by knowing what data was there
so you do this by taking a hash of the
actual data and you store the blob of
the file at the hash effectively right
so if we have a look at here we'll take
some artifact we'll put it at annexed
orage slash the hash will be some
metadata so I can backtrack and clean
things up if I need to but that's
basically it okay and this gives us some
free predictable caching so I can sync
things locally from a remote server
without ever having to do it which leads
to a really important design decision
for me which is that never ever download
something onto somebody's machine if
it's already there
ever so come from Australia we don't
really have internet yet so this is
really really really important please
don't download something of authority on
somebody's machine so cool so the next
thing is annex is a language so as a
language it's all it's a logic language
I have a history of logic languages I
don't like them any more but I wrote
another one anyway um but it's a it's a
fairly simple language it basically lets
us specify dependencies so I'm showing
you a surface syntax here but the
language is actually defined inside of
an AST and some power structures so that
can be represented in multiple languages
but this is just a simple hopefully easy
to understand surface syntax so
effectively I can say let's depend on
boxer and I want to get something that
has this feature has this commit in it
in its history I was built from this
branch snowball I just want it to be
compatible with some other atom that so
so some previous build I want it to be
binary compatible with Napoleon's still
on semantic versioning so I can use the
semantic versioning facts okay so it's
basically a logic language that lets me
specify my constraints in a more
interesting way okay it also has a first
class notion of time so I can say that
when I'm running this query I wanted to
run against this annex server at this
point at this version
okay so voters don't quite look like
this but somewhat representative and
then you can also have across time at
different hierarchies so it might be
just Napoleon's at that version or
something like that and then you can
also do more interesting crosstime
queries so whilst you might want to
query at the same time every time to get
reproducibility for some world there
might be some things that are important
that you want to know all of the current
knowledge so I want to I want to resolve
all my dependencies as that last Tuesday
because that's when our official build
was and I'm going to continue to do that
but I also want to have a secondary
check which means that there's no
vulnerabilities reported against any of
my dependencies ever so in six months if
one of my dependencies has a
vulnerability reported against that this
will start to fail but it will just be
that's it so that's kind of important
okay it assumes something so this part
here means that if you do across time
dependency you have to be quite careful
about it because that part is not very
producible right because you're looking
at a mutable pointer right but
everything else is reproducible okay so
this leads to another design decision I
guess which is the precision is
important so there are lots of different
ways which dependency managers have gone
in terms of making it easy for users
most of the time we trade rigour and
flexibility quite heavily so we either
have to go entirely flexible where we
specify version bounds and stuff like
this and we get very little
reproducibility or we and have secondary
mechanisms to give us reproducibility or
we go the rigorous route where we have
to specify very precisely what we what
we mean even though that's not really
what we're interested in so the design
decision that it's important to me is
that users only have to specify what
they care about at a particular point in
time okay and so whenever we have
flexibility we never traded at a cost of
determinism so that's what we get by
having immutable views of the world even
though we have a dynamic query across
some ranges it's always reproducible as
at at the same point in time of the
world okay
then the last thing that annex is is a
tool right so it's actually dependency
management tool so it has command line
tool where we can go and fetch
dependencies as at some point in the
world or it'll just pick up the annex
file in the current directory or more
likely you'll say once that I want to
depend on these things at this point in
time in the world - you just says
remember this and then after that it'll
write out a stable file with just that
that information in it and I can then
just say an exception then the next
person who goes and checks out my
project they'll go in X fetch and get
exact same things but I haven't had to
specify very much maybe I haven't
specified anything just the names of the
things I depend on okay so one important
point that I possibly glossed over a
second ago is so I really would implore
people to never ever generate a file
that somebody wouldn't write by hand so
common fight thing in dependency
management is the notion of a lock file
basically where you resolve a dependency
graph and then you write down the exact
version of everything in that graph okay
this means that instead of having a file
such as this where I de specify the
version of the world you have maybe your
450 dependencies all specified with git
hashes and lots of information this
leads to a lot of problems most
specifically if you can't write it by
hand you can't reason about it in a
sensible way so if I want to change it
so that I want to run two different
queries at two different points in the
world it's very difficult to understand
what's going on when you're trying to
compare two log files there's just too
much information so try not to generate
a file that somebody wouldn't write by
hand that's my two cents and the other
thing is that we get a few nice
properties so that because of the whole
we don't download things twice if I
fetch at some point in time then fetch
at some other point in time and then
fetch again that will be instant by
design because everything will have
already downloaded we can just resolve
again okay then there's a bunch of other
commands so for creating add-ons adding
facts and then we have deeper tool
integrations so
we have things like you want to just add
faxed he commits something like what
github does where you can close close a
commute with a fixed tag you know they
just add an X features or annex
attributes or facts in the git commit
and then there's a tool to say pull the
facts from the head so on CI server we
run something like this it says whenever
we do a CI build to take all the facts
are in the current repository and push
them to NX so that we can use them for
resolution next one and you don't have
to do it as a part of the commit you can
also add them after so using like get
notes you can just annotate a commit say
like here's a feature so these sort of
tool integrations are really important I
think we should be leveraging the
current tools that we use a fair bit
more so every time we do it we use a lot
of tools so I'm trying to do this for
mercurial and get and I'll probably let
other people look for other tools but
integrating is good but probably don't
be as bad as key so if you don't write a
command line tool
don't use key this just ended okay there
is probably there is probably also some
useful information here which is that we
do deep integrations with tools so part
of it is that so I write a lot of scale
and I write a lot of Haskell and both
their probably two of the worst
dependency management in existence so we
have fairly deep integrations with both
of those so in SPT we can declare ivory
and its dependencies directly and in
COBOL we have to assume things so we
have a COBOL annex file which specifies
dependencies in a slightly different way
and generates the real COBOL file but
that's just more deep integrations okay
so moving on to a deeper look of how
things work so what does resolution
actually look like so this is kind of a
world I'm sitting here I'm wanting to
results in dependencies there are some
public facts tools out there there's a
public data store the git repository
itself can also be a faxed or so you
don't have to have some server in play
or it can just be we store some facts in
the git repository
so we'll retrieve facts so whenever we
going to resolve a query will retrieve
facts or true facts from here and then
we may send send a query so the query
itself can get resolved partially on the
client and partly on the server so it'll
negotiate how its going to do that and
then we'll sing cannot synchronize any
part of facts we need to a local store
and then I'll link them in so how this
plays out in development there's a few
kind of flows that are important so the
first one is like time based resolution
so one of the main use cases that I had
when I first started designing NX was
basically I wanted to be able to test
multiple dependency resolutions at the
same time and build some tooling around
that so what that means is that if I
have this dependency graph and like
there's some defined in annex in some
way it's pretty minimal and then I can
have two different CI builds so I can
have CI stable which calls an x fetch
and does a build of the artifacts as at
the last point in time that they were
built so that I can have reproducible
build and I have an annex edge which
goes and reef fetches all my
dependencies as at the latest knowledge
to working out whether everything still
builds and then we end up with an X
being out of the display certain things
about version so annex at world 1 2 3 if
I want to go and resolve Napoleon I know
that this will work I know that at some
point somebody introduced some fact or
constraint them in but I'll never be
able to resolve Napoleon at 1 to 4 so
I'm not sure if anyone's ever wanted to
do this button I find this quite painful
when I ever go to use a new project it
has seven dependencies so we use the our
language and you go to our pen and just
like this five dependencies with no
version constraints and you're like aw
which one should i download which ones
will work together we should be other
work that out upfront without ever
having to run and run anything on our
machines so this kind of traffic light
system to be able to do that just useful
yep which is kind of so an open world so
the other thing that we have is like how
do we interact with the outsides and
Napoleon's a web app is wire which is a
simple
Highschool web framework and it uses
some JavaScript class okay so how we do
this is that we don't want to I'm not
expecting people who write y2 all of a
sudden news annex I'm not expecting the
people who write underscore je s to go
and start using an X directly either so
we have the situation where we can say
well let's actually pull Y out of
hackage which is the Haskell package
manager at Samsung at some semantic
version and I want to pull underscore
off cDNAs at some semantic version so
this is kind of how we start interact
with the world what will happen is when
annex resolves this it'll say oh I know
how to pull in facts from these things I
will then pull it into the annex door so
that I have a canonical hash for this so
that I know that it's reproducible even
if the other things mess up and then I
can then start adding facts that I know
so I might test underscore on i-4
because I have to ship something and I
for I don't really but but it's it's
amazing so on underscore I can start
adding extra facts even though these
things are stored in some external
repository and this is kind of useful
for us so I think that we should be
thinking about this back to my open
world concerns I think we should be
thinking about how we interact with less
principle systems so if we're going to
go off and design things that have
reproducibility and all these nine nice
principles we don't want to eschew the
current world even if we think it's less
principled than we currently are we
should be working out ways to interact
with it so source substitution
this one is a flow that comes up when
I'm writing Scala quite a bit I have we
largely binary dependencies in Scala
where we have a set of projects we have
like 30 projects in my company and we
depend on binaries for all of those
projects but occasionally comes up that
we want to make a change that crosses
one of those boundaries so I want to
make a change in some subsequent project
so it might look like this if we depend
well if we dependent this with Scala was
working on some feature up here all of a
sudden
yeah I've got some dependencies and all
of a sudden I need to fix a bug down
here or do a performance fix or
something like that basically I just
want to say and expect that substitute
source and it knows from the annex file
or know-how
build these and then I can also ignore
the constraints if it violates them okay
and so then I can go and make my change
in the transitive dependency and add
something like when I commit my fix I
can just add something that says I must
have this commit or if I had fixed tag I
could say must have this fix and now I
can just go and resolve and test without
ever having to worry about these
transitive dependencies and I've never
had to worry about the workflow or very
painful workflow of going to eminence
building it getting a new version number
going to boxer and snow more updating
their version numbers explicitly and
rolling it up in a cascading fashion I
want to avoid this as much as possible
so I saw surface or substitution is
important from a development workflow
and never had to touch these next one is
binary substitution this one comes from
writing C C++ and Haskell more so binary
substitution is the idea that we use
source dependencies most time so we
build on lots of platforms when we we
generally build their dependencies when
we need them on a specific platform but
this is really slow we generally only
have five or six different machines
probably not even that much why are we
building the same thing over and over
and over again so binary substitution is
the idea that we can predict what an
artifact is going to look like before we
build it and copy in some some artifact
that somebody's already built this is
far more difficult than it sounds but it
is possible
so it requires deduction of the output
signature so basically basically what
compiler it is all the flags and
everything and also the transitive
dependency of all the closure the the
transitive closure of all the
dependencies so if we have Napoleon it's
actual output signature is going to
depend on the version of eminence your
link in the version of box because you
get inlining in compiler so you have any
optimization flags
parts of these code bases will be
inlined and it'll affect the signature
so it's quite difficult to predict but
you can do it yeah and this is something
the next stars really well well somewhat
well which is that it can it has all the
in terms of being UPS predictively
signatures and can help out quite a bit
so distribution the next thing is though
if here we assume that an ex will have
multiple fax service they'll probably
some global one and then companies will
have their own and projects will have
their own then there's going to be
multiple multiple fax back stores and
one of the important parts of annex is
time and time and distributed systems is
hard especially linear time so how do we
actually manage that so the short answer
is that we cheat but basically instead
of doing a fully distributed system we
do a federated system so if you have
seen any time that I've written some
version number or some time Cree I've
also had some given store attached to it
this is basically saying this is the
master of this version of time so each a
version of time is tied to a store and
so I can progress these at different
rates and synchronize them on the client
this is possible so but it does give us
some nice properties so we get infinite
read replicas still so all of these
servers can have this version on them it
just means that when we go to write fax
if we're going to write out a new read
version we can only write it and get
commit through one of the service
ideally we'd like to do better than this
so we're kind of working on a nonlinear
of your fax where basically other facts
are a set that always commute so that we
can basically have a fully distributed
system where you can add fax and get new
versions but it's not quite working at
the moment that's something we're trying
to do the next thing is trust I'll just
kind of mention this quickly because I
did a run of this talk a few weeks ago
and everybody in the audience all of a
sudden started caring about trust
they actually currently download things
from maven central like over HTTP but
you know so I thought it's kind of funny
but we'll see so we have authenticated
family and atom owners so basically this
means that when you read
stro family or you register an atom on a
on a server you get the permission
rights to that family and that atom
there can be different lineages of atoms
with inside of a family but you get some
owner some ownership and then you can
also saw in facts so if you want to
contribute a fact to somebody else's
atom you can sign that and put it in and
then people can choose to trust certain
signatures or not and then we get
mediation of that fuse so if I wanted to
have so I work place with the group I
work in his MBA de if we wanted to have
our own little fax store which proxies
other fax tools I can then restrict it
so that I can say I only want to import
facts that are owned by some subset of
people or signed by some subset of
people which is kind of important cool
so then we have the solving problem so I
won't go into too many details but
basically how solving works is we take
the logic language we compile it down
into an expression that we run through a
Sat solver so this is a large problem
because that solvers at the moment are
optimized for a problem which is
slightly different which is much larger
computations so most that solvers are
written in C or C++ they're basically
black boxes at the moment I'm
considering writing my own at the moment
we just delegate to one of the standard
Haskell ones but the problem is is that
I want to be able to distribute
computation over both the client and the
server and at the moment there is no way
to tease these solvers apart in a
reasonable way to do partial computation
on the client server so this is kind of
an outstanding problem and one of the
holdups for me actually doing a proper
release so that's it yeah so the main
challenge in mapping the equations too
fast it's not too bad but effectively
you just have to come up with an integer
representation of every single fact in
your system which given that in a
dependency system we might have a
million dependencies each one has 10,000
facts in the scope of things it's not
that computationally expensive yeah cool
and secondary challenges are catching
and parcel partial solutions which is
what I was kind of getting out with
potentially writing our own Sat solver
we really want to be able to
car case computation so the chance of if
I run some sort of dependency resolution
algorithm it's going to have some
computation that pretty much everyone on
my team is going to run at some point
recalculating this over and over and
over again is redundant and prefer not
to do it so the last bit about the
solver which is kind of important in
terms of reproducibility the biggest
variable is an annex itself so this is
kind of important so at the moment we
have a mechanism to assume that I'm not
going to get it right the first time
just unlikely it will be right but
basically in annex will have an annex
resolver which we can specify has
version one and this is implicit at the
moment and I write it out as metadata so
that basically I'm making the promise
that every single time I do a fix to the
solver I will keep the old version as
well such that you get full
reproducibility so this is a pretty
large issue but this is kind of how I'm
doing it at the moment so basically we
have resolution and we want to be able
to do it again and again again so bug
compatible for resolvers specified
through the annex file okay so look
forward so once I start I originally
started doing this just and we proved my
development workflow but as I started
doing it lots of interesting things have
cropped up and I keep getting more and
more ideas for what I'd like to do in
the future so this section is more about
playing the sky type things but there
are things that I really am thinking
hard about and would really like to do
the first thing is much deeper analytics
so there's a few parts to this so we
want to be able to do arbitrary queries
and reporting over atoms so if anyone's
ever had a CI server there for 12 months
and they've ever wanted to ask a
questions but it's like got a bunch of
log files they're sitting there doing
nothing this is the sort of thing I want
to get away from all of that information
can be packed into as facts and annex
against atoms and then we can start
start doing better reporting I want to
say how many times have I how many times
have I got something to production that
had failed the three builds before for
example but these are all information
and all facts that can be attributed to
dependencies and I'll be able to start
building analytics and queries at the
top of that so then we want to be able
to get inference of relative facts from
customer issues so one of the things is
is that when a customer or she comes in
and we track back to her version that
version has a long history it might have
had other issues raised against it has a
dependency tree that might have had
issues raised against it so starting to
automatically infer or pull forward
information when we see one of these
would be pretty interesting and then
this one's very pie-in-the-sky but I'd
like to be able to predict days in
advance so there's a few types of facts
that I've already seen patterns which if
a fact exists or if some property exists
that it's more likely to see a variant
production so the number of people that
touch to commit the number of red builds
before the last before the last green
that got shipped there are a lot of
failures that can be predicted based on
the sort of facts that are coming into
the system so I want to be able to do
this and rely on these information so
that's kind of important fixing all the
compilers so all of them so this is a
call out to anybody who designs language
there might be a few people here so one
of the things that has made my job more
difficult than I think it should be is
that languages don't think about
compatibility in very rigid ways so any
compiler that gets written I think
should have the notion of signatures and
should have the notion of source
compatibility and binary compatibility
if that's relevant but it's really
really important so Haskell is going
through a growing pain at the moment
where people are trying to
backwards-compatible add these idea of
signatures but it's really complicated
because it wasn't thought about upfront
basically I want all compilers to start
outputting metadata which tells us
signatures for functions and how they
can be interacted with I think this
would be really useful so fixing all the
compilers is good easier extent
extension via deductive rules so at the
moment there are a few ways to add
global
so an example of why you would want a
global rule would be that I write why I
write a fact book says I tested on I a
six Rob writes a fact that was tested on
Internet Explorer 6 this is kind of not
useful but I can add a global deductive
rule which says I a six is the same as
Internet Explorer 6 such that if anybody
writes ia six or anybody writes Internet
Explorer 6 they get both facts so you
can query against takeaway so but I want
to have a better mechanism for that and
then the communitive fact view which I
talked about before such that we can
fully distribute things yeah and the
last one which came up a little bit last
week was better support for operational
dependencies so I use this allure trying
but would like to use this a little bit
in production so managing dependencies
between machines and services on
machines so there's a whole range of
issues that come about with running
something like this in production that
I'd like to solve so that's kind of what
I've got so far I'm very close to having
a release this is more talk about how
I'm building it but this project will be
released as an open source project at
some point the reason why it's not is
because I'm sick of having 80% complete
projects on my github account but it's
working progress but I think the most
the concepts here and the design
principles that I've undertaken can be
used by most people in lots of settings
so I encourage you to steal these ideas
as much as you can Thanks
there's a schema system so there are a
set of types of facts so there's trees
there's trees and atoms and a few types
inside of them so you can have any
factor that to some sort of schemer and
those the resolver knows how to take
those schemas and map them to the south
over the extensibility problem is
something I would like to solve at some
point but it's a set of schemas for
facts that there's a large number but
it's fixed at the moment yeah no
absolutely you are able to reproduce it
so perhaps glossed over that a little
bit too much which the important thing
is that
so sorry it's kind of important so
effectively this so when you run this
command so antics fetch - you you do get
a lock file but it is something that I
think a human can write so you get when
you get you get this lock file here
which is this is the entire log file
which says that here is the interesting
owner of the server and this is the time
point yeah it's linear with respect to
this server yeah so if I run it I can
run that query again at this point in
time at the server and it will be fully
reproducible yeah yeah and if somebody
adds a fact that'll be one to four or
thereabout
but yes so you still get full
reproducibility but you get it without
having to generate a large log file
sure okay so at the wall it's a binary
protocol at the moment which is defined
internally so I've made it try to make
it as simple as possible the
client-server are both written in
Haskell but the protocol itself could be
done in anything it's fairly naive that
doesn't do anything obligated I'm just
basically you can send listen and values
and there is a implementation that uses
thrift and implementation these
protobufs to do the same sort of thing
sure sure yeah
so the it's using ourself basically
first security at the moment it's right
over those protocols but nothing
sophisticated yeah so I'd use the
signatures on individual fax to get a
additional layer but yeah so I have this
problem we have 30 odd projects that all
use SPT which is effectively the same
problem is what maven has so our my
current solution to this is that I do a
deep integration with the tool so that
it's somewhat easy and effectively with
SPT that just means changing the tag the
key in maven would mean writing a plugin
which reinterpreted the dependencies
from one key to another so you'd
basically instead of writing your
dependencies and all their semantic
versioning you'd write and ex
dependencies and all of its its
artifacts annex would the plug-in would
then go and use our next to download
things and it would then register those
as paths but it would I think from the
maven situation it would probably
require a deep integration with my even
to make it smoother a lot of the tooling
that I've built is designed around doing
these deep integrations so I don't think
it would be that hard for other
languages it gets a bit easier so will
you do it with Python in our and stuff
like that by just replacing the
dependency manager outright because
those tools are slightly less megalithic
than what what maven and SBT yeah but
oh yeah so specifically with respect to
that so the current solution is that
effectively I have a process which
scrapes maven central and creates atoms
for everything on maven central and
register those then we can add extra
facts to those so I have a few processes
that's great maven central say it's
great takács scrapes pipe I and a bunch
of other things so that doesn't take any
of the artifacts directly but it just
scrapes and creates metadata for them so
that I can pull them in at a different
stage yep yep I'm not sure I'm probably
to talk I'm definitely not an RDF or
semantic web person and I've talked to a
few people so a few few people are
writing to her at work and my large
problem that I've had is I think I just
don't have the technical background in
that area to understand the subtleties
so the model is extremely close with the
exception that the computation I want to
do is distribute it which I'm not really
sure how to do that with Sparkle exactly
but maybe I can take it offline and ask
you some more questions to be able to
answer that better
a snowball yep
so there's so the resolution algún with
will pick there are some heuristics
around preferences but it will pick
something that satisfies the constraints
of all three so say all three would have
their own constraints on top of eminence
and it would pick the version of
eminence which has the latest time
effectively the basic heuristic is the
latest that satisfies all of the
constraints and if it can't find
something that satisfies all the
constraints it fails the resolution yes
yeah yeah Norris</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>