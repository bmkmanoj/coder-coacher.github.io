<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning Tutorial: Measuring model performance | Coder Coacher - Coaching Coders</title><meta content="Machine Learning Tutorial: Measuring model performance - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/DataCamp/">DataCamp</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning Tutorial: Measuring model performance</b></h2><h5 class="post__date">2017-03-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YaiUNfKym_A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now that we know how to fit a classifier
and use it to predict the labels of
previously unseen data we need to figure
out how to measure its performance that
is we need a metric in classification
problems accuracy is a commonly used
metric the accuracy of a classifier is
defined as the number of correct
predictions divided by the total number
of data points this begs the question
though which data do we use to compute
accuracy well what we are really
interested in is how well our model will
perform on new data that is samples that
the algorithm has never seen before
well you could compute the accuracy on
the data you use to fit the classifier
however as this data was used to train
it the classifiers performance will not
be indicative of how well it can
generalize to unseen data for this
reason it's common practice to split
your data into two sets a training set
and a test set you trained or fit the
classifier on the training set then you
make predictions on the labeled test set
and compare these predictions with the
noland labels you then compute the
accuracy of your predictions to do this
we first import train tests split from
SK learn model selection we then use the
Train test split function to randomly
split our data
the first argument will be the feature
data the second the targets or labels
the test size keyword argument specifies
what proportion of the original data is
used for the test set
lastly the random state quad sets a seed
for the random number generator that
splits the data in to train and test
setting the seed with the same argument
later will allow you to reproduce the
exact split and your downstream results
train test split returns for arrays the
training data the test data the training
labels and the test labels we unpack
these into four variables X train X 10
white rain and white s respectively by
default train test split splits the data
into 75% training data and 25% test data
which is a good rule of thumb we specify
the size of the test set using the
keyword argument test size which we do
here to set up to 30% it is also best
practice to perform your split so that
your split reflects the labels on your
data that is you want the labels to be
distributed in training test sets as
they are in the original data set to
achieve this we use the keyword argument
stratify equals Y where Y is the list or
array containing the labels we then
instantiate our K nearest neighbors
classifier fit it to the training data
using the fit method make our
predictions on the test data and store
the results as Y underscore pred
printing them shows that the predictions
take on three values as expected to
check out the accuracy of our model we
use the score method of the model and
pass it X test and Y test see here that
the accuracy of our K nearest neighbors
model is approximately 95% which is
pretty good for an out-of-the-box model
recall that we recently discussed the
concept of a decision boundary here we
visualized the decision boundary for
several increasing values of tape in a
K&amp;amp;N model note that as K increases the
decision boundary gets smoother and less
curvy therefore we consider it to be a
less complex model than those with lower
K generally complex models run the risk
of being sensitive to noise in the
specific data that you have rather than
reflecting general trends in the data
this is known as overfitting if you
increase K even more and make the model
even simpler then the model will perform
less well on both tests and training
sets as indicated in this schematic
figure known as a model complexity curve
this is called under fitting we can see
that there is a sweet spot in the middle
which gives us the bet
performance on the test set okay now
it's your turn to practice splitting
your data computing accuracy on your
test set and plotting model complexity
curves</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>