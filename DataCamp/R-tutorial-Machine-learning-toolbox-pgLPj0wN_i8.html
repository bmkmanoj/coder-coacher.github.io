<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>R tutorial: Machine learning toolbox | Coder Coacher - Coaching Coders</title><meta content="R tutorial: Machine learning toolbox - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/DataCamp/">DataCamp</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>R tutorial: Machine learning toolbox</b></h2><h5 class="post__date">2016-11-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pgLPj0wN_i8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the machine learning tool box
course I'm Mack securing a statistician
and author of the carrot package which
I've been working on for over a decade
city carrots one of the most widely used
packages in our for supervised learning
also known as predictive modeling
supervised learning is machine learning
when you have a target variable or
something specific that you want to
predict the classic example of
supervised learning is predicting what
species and honors is based on its
physical measurements another example
will be predicting which customers in
your business will churn or cancel their
service in both these cases we have
something specifically we want to
predict on new data species in churn
there's two main kinds of predictive
models classification and regression
classification models predict
qualitative variables for example the
species of a flower or will a customer
churn or not regression models predict
quantitative variables for example the
price of a diamond once we have a model
we can use a metric to evaluate how well
the model works a metric is quantifiable
and it gives us an objective measure of
how well the model predicts on your data
for regression problems we'll focus on
the root mean squared error or our MSE
as our metric of choice does they error
that linear regression models seek to
minimize for example in the LM function
in R it's a good general purpose error
metric and one of the most common ones
for regression models unfortunately is
common practice to calculate root mean
squared error on the same data that we
used to fit the model this typically
leads to over optimistic estimates of
model performance this is also known as
overfitting a better approach is to use
an out-of-sample estimate for model
performance this is the approach care
takes because it simulates what happens
in the real world and helps us avoid
overfitting
however it's useful to start off by
looking at in simple error so we can
then contrast it later with
out-of-sample error on the same data set
first we load the empty cars data set
and fit a model to the first 20 rows
next we make an in-sample prediction
using the predict function on our model
finally we calculate the
root-mean-square on our training data
and get pretty good results now let's
practice calculating root mean square
error on some other data sets</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>