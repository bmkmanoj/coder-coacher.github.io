<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>DataChats | Episode 16 | An Interview with Peter Bull | Coder Coacher - Coaching Coders</title><meta content="DataChats | Episode 16 | An Interview with Peter Bull - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/DataCamp/">DataCamp</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>DataChats | Episode 16 | An Interview with Peter Bull</b></h2><h5 class="post__date">2017-04-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8jMZkaqMiZc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right welcome everybody it's a sunny
Wednesday afternoon here in Cambridge
Massachusetts
we've just filmed another data count
course I'm Hugo Bound Anderson a data
scientist at data camp this is peter
bull data scientist and co-founder of
driven data that's right yeah I'm really
happy to be here there's been great Hugo
perhaps you can tell us a bit about
yourself and about driven data Peter I'd
love to yes so driven beta is a company
whose mission is to bring the power of
data science to social enterprises
nonprofits and NGOs one of the big ways
in which we do that is by running online
machine learning competitions so we have
data scientists that are all over the
world that come to our platform and they
compete to solve these problems that
have a social impact we've done work in
healthcare we've done work in education
we've done work in International
Development and all of these data
scientists through their skills have
contributed to making the world a better
place
fantastic maybe you can tell us
something about the course that we've
just recorded as well yeah I'd love to
so the course is really exciting
basically it's a case study where what
we do is we look at one of the
competition's that we've run and we walk
through how the competition is set up
what this data set is like it's a
real-world data set it's got all of the
edges and corners that a real data set
has and we look at how the person who
won the competition actually used a
couple of different methods some tools
some tricks some statistical methods
some computational things put it all
together and came up with the best
solution and what we really want to do
is show the students how they can use
some of these same tools and that really
by combining them in the right scenarios
can make really effective machine
learning models great do you think you
could delve very briefly into the types
of tools because we don't want to give
too much of the game away sure sure I
want to at least what your EPPICard out
there yeah so really a big chunk of it
is about natural language processing
there's some text data this is from a
school budget data set so there's some
text from these line items but there are
also a couple of numerical call
that have missing values and so you sort
of have to work with these very
different kinds of data and get them to
play together nicely in a model in order
to get a great score and then because
the datasets so large there are a bunch
of statistical and computational
concerns that you need to address if
you're going to build a good model for
this data set and so we really want to
give this perspective of working with a
real-world problem and getting from this
messy complicated raw data to a really
accurate prediction great what language
we talking about and what what packages
will the will our students learn yeah so
we work through this whole course in
Python and in particular we really focus
on how you would approach this problem
using the tools from scikit-learn so
with scikit-learn you have a huge
community that's building computational
tools in a way that is very rigorous
very well tested and implements most of
the really popular methods and so one of
the great things is that we can take the
winning solution and pretty simply
implement a lot of the tips and tricks
from it in one liners from scikit-learn
so we'll be working through through that
and we'll also use a couple things from
the pandas library as we're loading our
data fantastic so a potentially
controversial question right
why pocket ah that's a good question so
part of it is about the scikit-learn
library the access to a library that so
consistently presents an API is really a
huge benefit to people who are doing
machine learning part of what you do
when you're working on a machine
learning problem is research and
development and as part of that you need
to make lots and lots of changes to how
your code works and see how that affects
your results because the scikit-learn
api is so consistent you can very easily
swap in new methods for example you can
pull out your logistic regression put in
random forest and basically that's one
line change and you get a whole new
model because you can do that so simply
you can much more quickly work through
the different kinds of pre-processing
and modeling choices that you might make
in a problem great this I suppose leads
into another important question would we
have a lot of people taking our courses
and using the platform we have on data
camp who are starting out and they asked
the question watch should I be looking
at are should I'll be looking at Python
other other technologies I should be
using I don't want to set up that type
of dichotomy per se but what I'd like to
know is why would you as a practicing
data scientist use use piped yeah so one
of the the big reasons that I personally
use Python is that there's a very close
connection between the kinds of Python
code that I write to do data science
work and the kinds of Python code that
you might write for other software
development so a lot of our projects are
about building larger pieces of software
that have a machine learning component
into the ability to build that larger
software and our machine learning in the
same language makes that workflow so
much easier so that's one of the big
reasons that we focus on Python but R is
also a great language super powerful and
for our competitions we see people
submitting in both r and python at
almost equal numbers yeah great well I
suppose this kind of gets to the heart
of the matter of what perhaps a full
spec data scientist would look like
that's at some level so someone who you
know can build a web app pipe inputs to
a database then query it put models in
music using Python and all of that you
can do in play yeah all that you can do
very easily in Python and lots of those
things are very actively supported by
developer communities in Python so one
of the biggest considerations when
picking a language is what the community
of practitioners is like that you're
going to be interacting with that's one
of the beauties of the our language is
that there's such a robust community of
statistical practitioners
but one of the really strong advantages
of the Python language is that there's a
really robust community of software
engineers and developers that are
supporting the other pieces of software
that you're also going to build in
Python so in addition to having that
statistical and data community in Python
which is also very strong you've got
communities around web applications for
example building the Django framework or
the flask frames so something we're kind
of dancing around here is the idea of
what data scientist or a deal monition
of data science which I personally think
is currently ill-defined in a number of
respects something we're try to do a
data camp with conversations such as
with people such as yourself developers
and practitioners from around the world
is trying to figure out what data
science actually is yeah maybe you could
get some insight into as a practicing
data scientist yeah so really in my mind
I like to take as broad an approach as
possible to defining data science so I
think a data scientist is sort of like a
software engineer or there are many many
many different kinds of things they can
be doing but a data scientist is really
someone whose job it is to help other
people learn from data that's everything
from deciding which data to collect how
to process that data before you store it
where and how to store that data how to
pull that data out of that database how
to then do some analysis on that data
whether it's more simple statistical
analysis
maybe you just need to know some trends
maybe you need to know things like the
memes and the standard deviations of
particular things or if it's more
complex analysis where maybe you're
building a machine learning system and
you have some predictions you want to
make and then at the other end of that
there's this big piece about
communicating what it means to have done
some of this analysis what are these
results why are they important how does
it relate to some problem I'm at how
does it provide me with insight when I'm
trying to do my work and so really a
data scientist can be involved at any
point along that pipeline and I think
that
over time data scientists are going to
be more specialized into different parts
of that pipeline sort of in the way that
you may have a back-end software
engineer or a front-end software
engineer but for the time being really I
think the data science umbrella is
welcoming anyone who cares about data
and wants to use it to make things
better
great so firstly I agree completely with
everything you just said and what we've
pinpointed is the data part of data
science so I'll be interested also yeah
in what scientific about it and that may
not be well defined either at this point
yeah so I don't think my my personal
view on that is that that is not well
defined yet what pieces of it are
science and which pieces are engineering
because as we describe the process you
have both engineering and science that's
happening there so the scientific
portion of data science is really about
the scientific method it's about having
hypotheses that you're trying to
evaluate using the data that is you have
on hand and I don't think that that is a
rigorous criterium that you want to use
for defining data science as a whole I
think they decides involves a lot of
engineering as well but I think just the
history of the term means that we're
calling it data science but I don't
think that that science portion is
really what's at the heart of it I think
the data is other people may disagree
with that maybe they do yeah well no I
don't as you said there are portions of
it which can involve hypothesis testing
there are also experiments you can do
like a beat it it's a great title so you
know changing the location of a but
about it on your website for some users
to see if that generates more clicks or
doing some sort of statistical test
stone with respect to the responses but
I do think that definitely is not an
overarching theme of what one data
science means or or is but I think when
it's partly history that's where it
comes from is the turn
was really coined in Silicon Valley to
talk about people who were coming in as
analysts and wanting to run those kinds
of scientific experiments like a/b
testing and really has come to encompass
this whole data science process we've
talked about and so I think the the
science part of the name is related to a
lot of the work that happens and then a
lot of the tools we use or the tools you
use for scientific computing but that
the scientific process itself is only
part of the data science Brown yeah I
suppose there's also the point of course
this is the same for software
engineering in all other respects but uh
the iterative and kind of circular
process of the scientific method happens
in data science a lot in terms of you
know collecting data than doing 88 and
building some models and maybe going and
finding some more data or going and
cleaning it in a different manner and
that's that's a similar approach yeah so
I think that really data science
activities are much more often research
and development activities than software
engineering activities would be so as
you're saying a lot of data science is
about how do we figure out the best way
to do something how do we figure out if
we can even solve this problem with the
data we have how do we figure out if we
could ever solve this problem and that
is the sort of iterative
question-answering process of data
science that's really a research
question because you don't know what the
answer is yet until you've really gotten
in and executed that data science
process as opposed to something like
software engineering where you have a
well understood architecture you're
building torrents absolutely we have a
lot of a lot of students and a lot of
people on the platform who are budding
data scientists mmm a question we get a
lot is what type of things should I be
looking at first what's the best best
entry point into data science do you
have any any thoughts on that yeah for
me the best learning tools have always
been working through real problems
so being able to understand how data
science tools are being used in a
real-world setting what is the business
case for using data what is the problem
I'm trying to solve and then using that
motivation to look at the data science
methods that might be effective in this
scenario so if I understand that I want
to do something like predict customer
churn right this is whether or not a
customer will stop being a subscriber to
my business
I understand the business context of
that already I know that we make money
in this particular way we have
subscribers that fall off we want to
understand how and why that's happening
so now I can go and look ok how does the
data scientific think about this problem
what are the tools for churn analysis
and survival analysis that are out there
what packages implement these tools how
can I find tutorials and other materials
that help me attack this particular
problem I'm looking at and really that
kind of example based learning has been
the most effective thing for me in terms
of really understanding how to go from
raw data to an answer yeah absolutely
and of course humility would stop him
from saying such a thing but in terms of
the case studies and examples he's
talking about I think driven data is an
incredible place thank you to go I mean
doing these types of online competitions
there are vibrant communities of people
other people competing providing
feedback that that type of stuff so
there's a lot happening yeah and that's
part of our mission and setting up these
competitions is to show people the kinds
of problems that our data problem that
they can be working on that also have a
social impact and so they're real data
problems that you can learn from we've
done some of the pieces for you they're
set up to be supervised machine learning
questions already we're telling you
about the context we're telling you
about the problem you're solving and you
get to do a lot of really fun really
interesting parts of data science right
you get to figure out what kind of model
you're going to use what kinds of
pre-processing are going to be important
and all of those decision
points you get to make a submission you
get some feedback on how that changed
your score how that change your
prediction accuracy and that can help
you learn as a data scientist to sort of
see how those different approaches have
an effect on your model actions
absolutely could you could you tell us
about one particularly fun competition
although it's not the one that where
we've done in this course right yeah
yeah so actually last year we ran a
really fun one with the city of Boston
so the city of Boston sends health
inspectors to restaurants right and
those inspectors are looking for things
like people aren't wearing their gloves
or there's food that's not at the right
temperature or like these utensils need
to be stored three feet away from the
refrigerator you know these kinds of
things that are part of the public
health inspection checklist and they're
their process was to basically use the
knowledge of the inspectors they had to
pick some restaurant to go to on a given
day they have a long list of facilities
they need to get through over the course
of a few months and they would pick some
that they wanted to go to in a given day
but the city was curious could they use
data to more effectively send inspectors
to those restaurants that were most
likely to have hygiene violations so for
example you might have the hypothesis as
an inspector that a seafood restaurant
is a riskier place to eat on a hot
summer day and that's because it's super
important that the food is kept at a
cold temperature so can we use that kind
of knowledge to create algorithms that
help prioritize this list for our
inspectors so we took the historical
violation data from the city of Boston
we combined it with a new data set and
this was donated by Yelp and it was the
Yelp reviews of those restaurants so
it's things like the star rating what
kind of cuisine it is what hours it's
open and actually the text of the
reviews themselves as well and we had
competitors build an algorithm that use
that Yelp data to predict which
restaurants we're going to have hygiene
violations and how serious those
violations were going to be
and so that's been great it's really
exciting the city of Boston is actually
implementing a test right now where they
send some inspectors based out based on
the algorithm and some based on their
traditional process and they're sort of
having competition to see who finds more
violations and so that's just one
example of sort of in the Civic
technology space of the kind of ways in
which you can use data to really have an
impact absolutely that's very
interesting is is that competition it's
close but it can people still going on
your website and check out yeah so
actually one of the things we do with
the competitions is every winning
algorithm is open source so we publish
on github all of the code of the winners
of the competitions so that's available
to anyone who wants to look at it and
also Yelp has a great academic data set
program so the Yelp data is actually
available for research and learning
purposes through their website so if you
look for the Yelp academic data set you
can find it for lots of cities around
the United States it's really cool so
we've ascertained and seen examples of
the fact that case studies and actually
getting getting down and dirty with real
data sets is incredibly important in
Python in in particular though I suppose
each person has their own set of
packages and libraries they really like
to use but for data science you start
what are your preferred packages and
libraries and modules yeah so really
pandas is one of the workhorses that I
rely on day-to-day it's the ease with
which you can manipulate data and pandas
is amazing and even doing more complex
things like time series can be really
effective scikit-learn of course is
another huge one that has basically all
of the machine learning methods that we
might want to use recently we've been
working on some deep learning projects
and so we've been working with
convolutional neural networks and the
chaos package in python is a really
great API for accessing computations on
top of tensorflow or fionna so to speak
and you have a preference
- phone piano was that something you
work with more often I work with
tensorflow a little more but I don't
have a strong preference between the two
of them yeah great
so in terms of what you're working on
now are there any super interesting or
super frustrating challenges you're
you're finding in your working life that
that's a great question I mean one of
the things that we constantly find is
that the data never looks like you
imagined it does in your head so I
talked to you about a problem you're
having you're like oh we're collecting
XY and Z these are great things we've
got them in a database it's going to be
amazing so can you just build us a model
that does this and then you get the
actual data and really part of your role
as a data scientist is to look at that
data very skeptically and say okay how
is this actually collected what am I
missing here
what what can I see in this data that is
actually an artifact of how it was
collected or stored rather than
something that's actually going to give
my model some signal and so really that
critical thinking part of cleaning data
is one of the things that I come up
against every day okay yeah
so a number of students will say there
are certain barriers to becoming an
effective data scientist for example
I've heard people say I don't know
enough linear algebra I don't know
enough calculus or statistics
can you speak to if these are particular
barriers and if so how people who don't
have that type of expertise could
consume out them yeah well so there's no
question that the basis of so many of
these algorithms that we work with is
linear algebra and statistics so in some
way if you want to construct algorithms
you really need a fundamental
understanding of both of those things
however you can become a a what I like
to think of as sort of a work backwards
data scientist rather than starting with
statistics and linear algebra
you can start with these implementations
of these algorithms you can say okay all
I know about this algorithm is that I
use it in this particular case and it
does something for me I don't know
what's happening but I do know it's the
right tool in this particular case
because I've learned that because I've
heard that from people because people
who are experts told me that's the way
to approach this problem and then
eventually as you start doing that more
and more you start to understand what
tools are being used you sort of been
drawn into more of the statistical back
background more of the mathematical
background and build up those intuitions
about how those systems work sort of
from the top down rather than being a
linear algebra whiz first and then
understanding how to construct models on
top of that so it's really on a
need-to-know basis when you want to dive
deeper it definitely can be I mean I
think that it's sort of a natural
process for a data scientist to to have
that curiosity to want to dig deeper to
understand how things actually work but
as you say it's something that comes up
every day in your work right like part
of what's exciting about being a data
scientist and you get to learn something
new every day
and so judges and use search engines I
mean which are great examples of the
success of data science right very much
so fantastic oh do I agree with
everything you just say I'd also urge
people who are trying to learn some math
to not be afraid of notation or to
understand that everyone is scared of
notation like you look up you know PCA
on Wikipedia and suddenly you've got all
these you know Sigma's and matrices and
all of that so don't don't be scared or
realize that it that it freaks everyone
out and what is there the learning curve
let me make a recommendation then I
don't think that Wikipedia is the place
to go to understand a mathematical
technique Wikipedia goes very deep very
quickly in a way that is not effective
for learning things so if you actually
need to learn parts of these things you
need to find materials that are designed
for people who are learning you need to
go find that course online that gives
you that the background in linear al
jibra you need to go find a textbook you
need to go find a technical book about
the topic that you're looking at because
Wikipedia will scare you away
immediately there are topics that I know
about and I go to the Wikipedia page and
it says things I don't understand
it gets freaky and that's two or three
things popped popped ins might have been
that the first is you know you can
always jump on coral stackoverflow and
say hey I don't get this can anyone give
an intuitive explanation ah yeah
actually before you do that look up
intuitive explanation of some sort and
it will come what may have answer yeah
my second thought was yeah once we
finish this interview we should jump on
Wikipedia and start making some edits to
dad that's right that's revolutionize
Wikipedia math mathematics by first
giving like some pages you have an
intuition but first giving you know not
all the notation heavy stuff yeah yeah
what you take it back real quick on what
you said I do think it's really
important that people who have questions
go out and ask them online don't be
scared to ask a question yeah don't be
scared to get on Stack Overflow or Cora
and make that community a community of
experts and a community of learners so
really really don't be afraid of it
get in there ask your questions don't be
ashamed
everyone's a learner at some point and
the fact that you had the question means
that someone else probably has it and
that answer being there for someone else
to find is going to be a huge win for
them
yeah I agree completely I think I'd also
say being an educator myself the best
educators I've learned from and worked
with a constantly learners themselves so
having settled that I've got one one
last question for you great
I'd like probably the strongest piece of
advice you have for aspiring data
scientists the strongest piece of advice
I have is to work on real-world problems
I mean it's we talked about it
throughout this interview but really
that's where you learn the most because
so much of data science happens in those
edge cases right it's how to know would
this strange problem that happens every
now and again in a certain data set
that's how you become an expert
a scientist is saying hey that's
something I've seen before this isn't
something that happens in every data set
this is something that happens in
particular data sets but I know what to
do and so really just by working real
problems over and over again you'll put
tools in your toolbox that let you
handle each of those situations as they
come up so really I try to do one thing
from start to finish and then move on it
doesn't have to be perfect I just want
to have started with raw data and gotten
to my answer at the end of my process
and I don't I don't need to know
everything that happens in the middle it
doesn't need to be perfectly written
code but I've understood a lot through
that and then I can move on to something
else
and learn something from a new data set
fantastic
was it with them compatible Peter been
an absolute pleasure great thanks to you
guys I really appreciate it
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>