<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning with R Tutorial: How kmeans() works and practical matters | Coder Coacher - Coaching Coders</title><meta content="Machine Learning with R Tutorial: How kmeans() works and practical matters - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/DataCamp/">DataCamp</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning with R Tutorial: How kmeans() works and practical matters</b></h2><h5 class="post__date">2017-03-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xjpzDx_nywc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">in this section I'm going to help build
intuition about how K means works
internally my goal is to do this through
visual understanding if you're
interested in the mathematics there are
many sources available on the web and in
print after that I will present methods
for determining the number of sub groups
or clusters if that is not known
beforehand here is data with two
features I notice the data for this
sample is originally from two sub groups
the first step in the k-means algorithm
is to randomly assign each point to one
of the two clusters this is the random
aspect of the k-means algorithm cluster
1 is represented by empty green circles
and cluster 2 is represented by empty
blue triangles the next step of k-means
is to calculate the Centers of each of
the two sub groups the Centers of each
sub group is the average position of all
the points in that subgroup the Center
for each sub group is shown as the solid
green circle and the solid blue blue
triangle for sub groups 1 &amp;amp; 2
respectfully next each point in the data
is assigned to the cluster of the
nearest center here you can see that all
the points closest to the solid blue
triangle Center have been assigned to
that cluster the equivalent is true for
the other sub group this completes one
iteration of the k-means algorithm the
k-means algorithm will finish for no
point to change assignment in this case
many points change cluster assignment so
another iteration will be completed here
we see the k-means algorithm after
completion of two iterations new cluster
centers have been calculated and each
observation has been assigned to the
cluster of the nearest center and here's
the algorithm after completion of three
iterations again some points have
changed cluster assignments so another
iteration of the algorithm will be
completed and this is after completion
of the fourth iteration the algorithm is
completed after the fifth iteration no
observations has changed assignment from
the end of the fourth to the end of this
iteration so the k-means algorithm stops
this final point thus shows the cluster
assignments for each observation and the
cluster centers for each of the two
clusters there are other stopping
criteria that you can specify for the
k-means algorithm such as stopping after
some number of iterations or if the
cluster centers move less
some distance because the k-means
algorithm has a random component it is
run multiple times that the best
solution is selected for multiple runs
the k-means algorithm needs a
measurement of model quality determine
the best outcome of multiple runs
k-means at our uses the total within
cluster sum of squares as that
measurement the k-means run with the
minimum total within cluster sum of
squares is considered the best model
total within cluster sum of squares is
easy to calculate for each cluster in
the model and for each observation
assigned to that cluster calculate the
squared distance from the observation to
the cluster Center this is just the
squared Euclidean distance from plain
geometry class sum all of the squared
distance calculated and that is the
total width in cluster sum of squares
our does all of this model selection
automatically by specifying n starting
k-means the algorithm will be run in
start times and the run with the lowest
total width in cluster sum of squares
will be the resulting model
this helps the algorithm find a global
minimum instead of a local minimum but
does not guarantee you that outcome in
the hands-on exercises I will show you
how to determine the total width in
cluster sum of squares from the results
of running k-means here's a visual
example of running the k-means algorithm
on the same data multiple times in this
case it is known that there are three
clusters within the data the graph on
the top right has the lowest within
cluster sum of squares another item of
note cluster membership is color-coded
in these plots notice that even between
runs that find approximately the same
solution that the cluster memberships
are signed differently this is not a big
deal just a result of the k-means
algorithm that you should keep in mind
for repeatability use our set seed
function before running k-means to
guarantee reproducibility if you don't
know the number of subgroups is in the
data beforehand there's a way to
heuristic aliy determine the number of
clusters you could use trial and error
but instead the best approach is to run
k-means with 1 through some number of
clusters recording the total within
cluster sum of squares for each number
of clusters this is then plotted with
the number of clusters on the horizontal
axis and the
folder within cluster summer squares on
the vertical axis this type of plot is
referred to as a scree plot there may be
an elbow in the plotted data a place for
the total within cluster sum of squares
decreases much slower with the addition
of another cluster in the plot above the
elbow appears at two clusters this value
can then be used to approximate the
number of clusters if it is not given or
known beforehand cool let's practice
what you've learned</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>