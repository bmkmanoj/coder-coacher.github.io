<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>DataChats | Episode 5 | An Interview With Ron Pearson | Coder Coacher - Coaching Coders</title><meta content="DataChats | Episode 5 | An Interview With Ron Pearson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/DataCamp/">DataCamp</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>DataChats | Episode 5 | An Interview With Ron Pearson</b></h2><h5 class="post__date">2016-12-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BeAptv-mdOU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right hi everyone I'm Nick I'm a
data scientist of data Kamp I'm here
with Ron Pearson we just finished
recording videos for Ron's new course on
data visualization and R which we're
really excited about so welcome thanks
Nick so one of the first questions I
always like to ask people is what do you
consider yourself are you a statistician
are you a data analyst of data
scientists a hacker and why okay well
since my education was electrical
engineering I don't consider myself a
statistician I don't have the formal
training I have worked a lot and what
has now come to be called data science I
was working in it before it was called
data science and so I guess I would
consider myself a data scientist okay
and what is data science mean to you
data science to me involves a lot of
exploratory data analysis the probably
the the primary driving questions are
can you predict something so building
predictive models is a big component of
that and can you understand something so
exploratory analysis detecting
relationships between data or unexpected
features and data I see those as the
primary components of data data science
yeah it's an interesting perspective
because the things that get all of the
attention are the machine learning and
nap now recently it seems like every
newspaper I pick up is talking about
artificial intelligence but but but
you're actually positioning data science
as a field that's dominated by
exploration by exploratory data analysis
and I don't think it gets the press that
those other areas get what I think it's
often been said that something like 80%
of the tasks of model building is
actually vetting the data getting it
prepared getting it in shape where you
can actually build models with it so I
do
think that even though it doesn't get
the same amount of press I think it's a
a critically important part of that and
in my own view it's a very interesting
part of that because you're looking for
unusual things and and it's amazing
sometimes what you'll find in data yeah
absolutely and it definitely like the
old adage like garbage in garbage out
yes right so if you've got if your data
is garbage it doesn't matter how good
your predictive model is you're not
going to get reliable results and and
likewise if you're not exploring the
data in the right way you may not be
asking the right questions in the first
place so you might get a good answer to
the wrong question right right so that
that's a great way to think about it so
how were you first exposed to the our
language and what is it that the trivia
to it okay well I was first exposed to
are actually through its commercial near
equivalent s+ I was at the DuPont
company at the time and I was involved
in building dynamic models and so I was
trying to actually construct something
called the Martin Thompson data cleaner
which is a supremely effective data
cleaning tool but incredibly complicated
and I was actually looking at
translations of Qyburn Etica to try to
figure out what the tuning parameter
should be my boss came in one day and
said I just heard about this s+ package
that seems to have what you've been
working for months to try to build and
sure enough there was Doug Martin was
actually one of the founders of the
company that that introduced s+ and he
was also one of the authors of the
martin thompson data cleaner paper so it
was natural that it was there i used
that and then i started exploring the
other things that were possible within
s+ and i became you know a complete
devotee of that then as time went on i
got exposed to r and the big advantage
of R is that it's free it's also grown
enormously and so the range of things
that are available in are far surpass
any other
platform that I'm aware of so yeah I've
become a real fan of our that's pretty
cool interesting so what what areas are
you so I know I know you love
exploratory data yes what what do you
enjoy the most like what what areas do
you enjoy working and it could be either
specific domains that you're excited
about or different parts of the data
data science process well I guess I
would have to say you've already
answered it the exploratory data
analysis aspect of things so looking for
unusual things in data and trying to
determine whether those unusual things
are influential enough that you need to
worry about
so by unusual things for example one
unusual thing that doesn't get talked
about a lot but that I find fascinating
or inliers one definition is that these
are in Liars as opposed to outliers so
one definition of inliers is points that
are wrong but consistent with the rest
of the data unfortunately that's not a
mathematical definition but one
characteristic of that kind of in lier
is that often the same value is repeated
and if you look at numerical data in
principle and continuously distributed
data so if you like the Gaussian
distribution ties have zero probability
so if you have a whole bunch of repeated
values in the center of a distribution
of otherwise relatively Untied data that
is often an indication that there's
something very strange going on so it's
things like that that I love digging
into and finding that's really
interesting so in other words me maybe
naively assume that for something to be
wrong or strange about the data that it
would necessarily be like far from the
rest of the day actually it might be
tucked in along all of the normal data
points that should that should be there
disguised disguised well maybe in fact
that's one area that I've done a bit of
work on I did a paper on disguised
missing data which shows up that way so
if you have
values that really are not recorded but
they're recorded with some special value
that may get missed so there are lots of
there are lots of ways that data can can
be flaky and that's fascinating to me
yeah okay very nice so what sorts of
trends in the field are exciting to you
ah the the evolution of the machine
learning models if you do comparisons
between performance of various different
model types in predicting something for
the same data set then historically
linear regression models you know that
was the tool that was available that was
what everybody used and then people
started using other tools but they were
sort of harder to use now you have a lot
of tools like boosted trees random
forests things like that and all kinds
of variations of those things that are
much easier to use and that lead you
often to very different models very
different kinds of predictions than you
can get from more traditional models and
I find that arena exciting especially
with all the different variations of
some of these models one of the most
intriguing model classes I've seen is
the mo B models that are available in
the party kit package so there's a
function called LM tree that fits tree
based models where you have a decision
tree but at the node rather than having
a single prediction you've got a linear
regression model or a generalized linear
model yeah and some cases that can give
you tremendous both predictions and
insight into what's going on in the data
and that it's effectively splitting your
data set into different partitions that
behave very differently yeah that's
pretty interesting I've actually heard
max Coon talk about this type of model
it does they call it a model tree is
that is that the right that's one term
the in I forgotten what the mo B
abbreviation stands for but a party
package was the first place I've seen
this yeah and then
the party kit package is an extension of
that that also supports it but the basic
idea of automatically partitioning your
data set into subsets with different
models for the different subsets is an
extremely powerful one and these tools
that that do that are are I think a
great development and something that I
know are supports I don't know of other
platforms that support that yeah that's
really interesting
so maybe with without going too far off
the deep end here like that I think the
argument that one of the arguments that
max made for this type of model is that
if you have a tree when you get out to
the extremes of the data you never
predict make it you never make a
prediction beyond the most extreme value
at one of the end points of the tree but
if you actually have a linear regression
at that end point it might it might give
you more accurate predictions when you
get that far out in the data because it
can actually make predictions beyond
right beyond where employment yeah yeah
yeah well and another thing that I like
about these these structures is that
often the resulting models are simpler
than if you built let's say if you were
able to get a regression model that had
all kinds of interactions in it and then
you build one of these regression tree
models the regression tree model may
actually have let's say three different
simpler linear regression models that
get pointed to by the tree you may be
able to represent that in terms of a
linear regression model with complicated
interactions but it's much easier to
explain and to use in the form of the
regression tree model than it is in the
regression model with all the
complicated interactions yeah that's
that's also interesting it seems like
it's a lot of what you read about in the
papers are kind of these black box
models where you the the results that
you get are not necessarily
interpretable right they might be highly
accurate and extremely useful in certain
contexts
but but they may not be very
interpretable and but in certain domains
interpretability is still very important
but yes for example public policy works
you have a predictive model it's helping
a judge to make decisions about whether
someone should should go to jail right
all right and and and so there's certain
context where you want to maximize
predictive capability but within the
constraint that you need the end result
to be explainable to the public or the
key stakeholders are and it seems like a
very exciting field right now there's a
lot of people working on this problem of
how do you build highly predictive
models in such a way that they can still
be interpreted or take traditional
blackbox models may be like a random
forest and how can you build some sort
of interface to that that allows you to
communicate the results in an
explainable way right right and and in
fact that's another area where R has
some nice and developing tools so things
like partial dependence plots can give
you an idea of how this blackbox
prediction depends on your different
variables that go into that prediction
even though you're not trying to infer
that from coefficients in a very
complicated model you're looking at it
more from an input-output perspective so
is this related to like a variable
importance but it's a little different
but it's somewhat along those lines
variable importance gives you an idea of
at least the way I look at variable
importance if you eliminated a variable
how much would that hurt your model
prediction the capability whereas in
this case if you're looking at something
like a linear regression model then you
know that the influence of variable X is
this straight line and it's
characterized by the slope of the
intercept for a random forest model
that's probably not true but partial
dependence plots give you a way of
saying okay the curve that relates as
I change X that relates to how my
prediction varies looks like this and so
this is a way of getting doesn't give
you a complete picture of what the black
box is doing but it gives you important
details
similarly the variable importance
measures also give you important details
of saying okay this decision depends
very strongly on these three variables
and essentially not at all in those
other eight and so in terms of
interpreting the results of black box
models that can be very valuable
so maybe just to go a little bit deeper
on on one thing that we discussed
earlier like what do you see the
relationship being between exploratory
data analysis as you define it and
predictive modeling and machine learning
like is there a component to machine
learning or predictive modeling that is
exploratory and then and then the same
way in the course you talk about like
explanatory plots is there some
explanatory phase of predictive modeling
as well as there some in there well the
connection that I see it is and and the
way many people approach this is
exploratory data analysis is a
preliminary phase that you go through
before you build the predictive model to
make sure that you're identifying things
that either variables that are
ridiculously predictive because in fact
they're derived from your response
variable so called post dictor's or data
leakage or outliers that are simply so
strange that if you include them in even
very sophisticated models they give you
horribly biased predictions so a lot of
exploratory data analysis is useful in
sort of cleaning up and preparing the
data so that you've got a good data set
to feed to your predictive modeling
procedure so in that sense I view it as
highly highly important that way but
there are some interesting applications
potential applications of machine
learning tools
and exploratory data analysis so for
example the biruta package in our is a
package that allows you to it builds
random forests and it gives you variable
importance from the of each of the
variables based on that random forest
but it also includes some fictitious
variables that are randomly generated
and so you have a frame of reference to
say okay these variables are or are not
more important than these fictitious
variables and so that that can be very
useful in deciding of all of these 80
variables you've got to look at which
ones are worth investing my effort in
trying to understand better if I'm
trying to predict this this variable
sure because that's that's an arena
where the exploratory problem I mean if
you've got thousands of variables you
can't explore everything so it's
important to guide that exploration in
order to find those things that you
definitely need to know about in order
to build models to accurately predict
what it is that you're most interested
in sure another example I suppose would
be like missing data imputation yes yes
you have like a bunch of missing data
and you actually build a predictive
model to predict based on all the other
information you have what would you
expect the value of this variable right
be for this particular observation a
lots been done with multiple imputation
typically using fairly simple models but
that's obviously an arena if you're
using multiple imputation with random
forests and boosted trees and and deep
learning neural networks and so forth
there ought to be a lot of interesting
things that you could do in getting
better amputations at least in cases
where that's a reasonable reasonable
strategy yeah yeah okay very good
so anything else that that you've got on
your mind that you want well all kinds
of things are rattling around here but
nothing nothing is really percolating to
the surface of this point all right well
this has been really good yeah III learn
every something every time I hang out
with frog he did too
all right well thanks a lot for this
this is great yes yes thanks very much
this has been fun to do great
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>