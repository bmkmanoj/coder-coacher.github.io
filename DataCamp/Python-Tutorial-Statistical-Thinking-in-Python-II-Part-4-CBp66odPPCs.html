<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Python Tutorial: Statistical Thinking in Python II (Part 4) | Coder Coacher - Coaching Coders</title><meta content="Python Tutorial: Statistical Thinking in Python II (Part 4) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/DataCamp/">DataCamp</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Python Tutorial: Statistical Thinking in Python II (Part 4)</b></h2><h5 class="post__date">2017-03-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CBp66odPPCs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">imagine your company has proposed a
redesign of the splash page of its
website they are interested in how many
more users click through to the website
for the redesign versus the original
design you devised a test take a set of
a thousand visitors to the site and
direct 500 of them to the original
splash page and five hundred of them to
the redesigned one you determine whether
or not each of them clicks through to
the rest of the website on the original
page which we'll call page a 45 visitors
click through and on the redesign page
page B sixty-seven visitors click
through this makes you happy because it
is almost a 50% increase in the
click-through rate but maybe there
really is no difference between the
effect of the two designs on the
click-through rate and the difference
you saw is due to random chance you want
to check what is the probability that
you would observe at least the observed
difference in number of clicks through
if that were the case this is exactly
the question you can address with a
hypothesis test a permutation test is a
good choice here because you can
simulate the result as if the redesign
had no effect on the click-through rate
let's code it up in Python for each
splash page design we have a numpy array
which contains 1 or 0 values for whether
or not a visitor clicked through next we
need to define a function diff frac for
our test statistic ours isn't a
difference of the fraction of visitors
who click through we can compute the
fraction who click through by summing
the entries in the arrays of ones and
zeros and then dividing by the number of
entries finally we compute the observed
value of the test statistic using this
function diff frac now everything is in
place to generate our permutation
replicates of the test statistic using
the permutation replicate function you
wrote in the exercises we will generate
10,000 replicates we compute the p-value
as a number of replicates where the test
statistic was at least as great as what
we observed we get a value of point
zero one six which is relatively small
so we might reasonably think that the
readout that the redesign is a real
improvement this is an example of an a/b
test a B testing is often used by
organizations to see if a change in
strategy results in different hopefully
better results generally the null
hypothesis in an a/b test is that your
test statistic is impervious to the
change a low p-value implies that the
change in strategy led to a change in
performance once again though be warned
that statistical significance does not
mean practical significance a difference
in click-through rate may be
statistically significant but if there's
only a couple people per day your
marketing team may not consider the
change worth the cost
a B testing is just a special case of
the hypothesis testing framework we have
already been working with a fun and
informative one let's practice with some
exercises</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>