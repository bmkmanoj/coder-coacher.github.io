<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Speech to Text Application with Ionic 2 and Ionic Native 3+ | Coder Coacher - Coaching Coders</title><meta content="Speech to Text Application with Ionic 2 and Ionic Native 3+ - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Paul-Halliday/">Paul Halliday</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Speech to Text Application with Ionic 2 and Ionic Native 3+</b></h2><h5 class="post__date">2017-03-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dPbT_kElSXA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hailer we're going to make is
speech-to-text application to their so
it's similar to the text-to-speech one
that we did the other day but this time
it was speaking to the form instead of
this form to begin to us so start off in
new I uh next to project ionic start
speech up blank V tube and when you've
done that we need to add the Cordova
plugin so simply type Cordova plugin
adds Cordova plug-in speech recognition
and then we want to save that for - -
save and when you've done that we need
to add the ionic native speech
recognition plug-in to do that npm
install at sign ionic - native / speech
- recognition and make sure you see
about that - awesome i'm going to run
that on the device mouth and then i'm
going to open up in PS cord okay the
first thing we need to do is head over
to our source by directory then up then
up modules doc PS from here we need to
import speech recognition from ionic
native slash speech recognition then in
our providers we need to add speech
recognition to our providers next head
over to your home page and change the
title to something like I like to speech
recognition I'm going to change the
enough while color to primary so we can
have a nice blue just like that then I'm
going to break out all the different
functionalities in two separate buttons
this way you can see how to implement
them so start off by making a button and
in this button we're simply going to say
iron one and we're going to cut the text
to be is the speech supported and then
what we can do is hook that up to a
click event which just says is the
speech of supporters now shred luck a
little something like that when we click
it obviously gives an error because we
haven't implemented yet now head over to
your home TF and we can write the
function and it's going to be ear sync
so before that let's head over to TS
configs or json and target a f6 and then
what we'll do is we'll make an async
function and
call it is speech as supported and this
one will return a promise of type
boolean and in this promise we'll need
to basically ask being speech something
like this for speech dot is recognition
before word together we'll need to
import for default for using imports
from planet net of speech recognition
and we can fill it in to be speech
recognition we can then instantiate and
our constructor and then we can head
back to our ear sync function here so we
would have this for speech dot is
recognition available that's the one we
can aware on this and put this to a
value something like is available is
equal to that this means that the value
of is available will become whatever we
get from this promise here you can
simply logs out and we can return after
that so if we've done everything right
when we click this button we should be
able to see whether speech recognition
is available on the device yep as you
can see we get true in the console when
we click the button now we need to get
the permission to actually use speech
recognition so let's make another button
and this time we'll call it get
permission with these click function get
permission inside of our home component
we can make an async function then get
permission and this will return a
promise a voice so we won't be returning
anything will simply be saying we'll
need to have is try catch blocks to see
whether there's any errors and to see
the result we can then say permission is
equal to this for speech dot request
submission
then we can log B permission out you can
also log out any errors so if we have a
lot on our application now one would
collectively get permission button I'm
not quite sure whether it's going to
show in the browser you but it should
ask us for B permissions you can't see
that on the screen but it's just asked
to record audio I'm going to deny it
right now and we see permission denied
inside of our era block here inside the
catch of get permission
so this time I'm going to do the same
but I'm going to press allow and we can
see we get all care cool now we're going
to check to see whether we have
permission we can do it either way
around we can check our submissions
first that will probably be a better
idea but we're simply going to ask the
question has permission then let's make
another function it's going to be called
a sync has permission and it's going to
return a promise and it's going to be a
boolean we can put it in a try-catch
block again and we'll try to get the
permission to all the reset cons
permission is equal to a result from
this of the speech dot has permission
and we can log out we can also catch an
arrest as any don't forget to add a
function at the end of the another
mission here essentially we're checking
to see whether we have permission and
the result of that goes into this
permission variable here and we're just
simply going to log out to the console
if there's any errors we're going to
catch it here and we're going to contour
the log of ER get a use console daughter
so let's check to see whether this works
I'm going to click house permission and
we get true
so yet we do have permission the next
thing we can do is get these supported
languages from the speech recognition
and we'll quickly make a button for that
call out it get supported languages
and the function will be called guessed
forward languages so async get supported
languages so async get supported
languages going to return a promise
which is going to be an array of strings
so that will try we're going to do this
dot speech
don't forget supported languages and
we're going to resolve that two
languages and we can log out the
languages to the console and then return
and that we have an arrow going to
contour the error P okay so if I click
get support with languages we get the
zone response which means we've missed a
weird so if we had a wave there and
retry it again so there we go we get a
list of these supported languages the
next thing to do is to actually start
listening for speech instead listen the
speech and the function will called
listen for speech like that so now we
can write lesson to speech inside of our
component and that will centrally be
listen for speech and it's going to
return a void so right now we'll just do
this for speech don't start listening
and then we'll subscribe to that and on
the data stream at the moment all this
controls our log it outs and for any
errors or console.log any errors let's
double check that on this one the box
could be listen for speech hello world
my name is Paul and I'm speaking into my
super-awesome ionic native and there we
go we get a list of the different things
I could have said
switcher be super ocean ionic native up
or the super Dawson ionic native act
you're not River 21 from there but as
you can see we've just read a simple
subscription and we're just literally
logged out so we could do a number of
things with this information we could
for example make it dead object up here
inside Bob's call a speech less and that
will be an array of strings like so and
we can make speechless equal to the data
and inside of our home component here
and the HTML the view we can make it
cards and inside the cards will have the
iron card content and then we can view
an entry for and we'll simply say a lead
speech of screech list and inside the
content we'll make a paragraph tag and
we'll simply plug these speech results
so if I click the button on the phone
and I say learn ionic to calm is the
best resource for learning ionic tubes
so it says learn ionic to Chrome is best
resource for learning ionic to and then
I get for saying calm is successful
resource at Sarah but as you can see
we've output the speech from what we've
said on to our device we've gone through
what the permissions will check to see
whether we have the permission we check
to see whether we supported languages
are etc there's a couple of ways which
you can customize this event further we
can import speech recognition listening
options Android and speech recognition
listening options iOS and when we're
passing in the start listening here we
can actually pass in an option variable
so if we made an Android options here
and we made a type speech recognition
listening options Android and we simply
said Disko Android options is equal to
language and us is default and we can
have a look at the interface here so we
can see we have language matches prompt
and short pop-up so nus is default
there's also a leash or pop-up which is
true and I was that sort of like when
you click the button you'll see a pop-up
appear but one of the awesome things
that we can do is actually change the
prompt string when
a prompt on the user for the speech so
if we type in here instead prompt
speaking for your form you can see
whatever you want here that would
actually provide a little dialogue at
the top above the microphone to the user
and you'd be able to essentially you
know customize your app a little bit
more so we can pass this in right here
this to Android option and when we click
I will listen for speech we have
something else speak into your phone
over the top of the Google dialogue now
we can do a similar thing for iOS we can
do this dot iOS options which will make
up at all - hi wash options speech
recognition that listening options iOS
is the type and as you look it we can
have a look at the interface we have
language much as ensure partial and
allow partial results to be returned
further full of which is false it's not
as customizable as the Android version
but we could do this to us options is
equal to and then if we wanted to change
something language we could and instead
we could pass this top iOS options here
but a better way to do that would be to
make whatever you want in your options
also we did language in us and let's
pretend that isn't be default we can
import the platform from ionic angular
and instantiated here in our constructor
and instead we can say if the platform
so is Android we can pass along with the
start listenin function with the Android
options else if the platform is iOS we
can pass along the iOS options so hope
that this tutorial helped you in putting
speech recognition into your ionic 2
apps if it did then hit that subscribe
button and leave a comment down in the
comment section below and don't forget
to check out learn ionic to calm for
more awesome tutorials</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>