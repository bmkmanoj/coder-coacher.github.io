<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NativeScript Speech Recognition with Angular 4 | Coder Coacher - Coaching Coders</title><meta content="NativeScript Speech Recognition with Angular 4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Paul-Halliday/">Paul Halliday</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NativeScript Speech Recognition with Angular 4</b></h2><h5 class="post__date">2017-04-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/C5i_EYjfuTE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey it's Paul today we're gonna like a
using speech recognition in our native
script applications sort of start with
ensure that you have the native script
CLI installed you can do that with a
native script to install TNS - G after
which we can create a new project by
using TNS create and then the name of
our project which will be speech and
then we specify a template I'm going to
be using the template using the - -
templates like and then the template I'm
going to use is native script templates
ng tutorial this will start a blank
native script application based on
angular when I press ENTER this will
download the template so our new project
is now created inside of speech we can
CD into speech and then we need to add
the native script speech recognition
plugin to do that let's run TNS plugin
adds native scripts - speech -
recognition I will install the speech
recognition plug-in to our application
now we can open up in Visual Studio code
or the editor of your choice
inside of our app we can head over to
app module or TS and we can import from
native scripts speech recognition we can
import the speech recognition class add
this to the list of providers inside of
our module then we can import native
script from speech recognition once
again can import the speech recognition
and the speech recognition at
transcription we'll also need the speech
recognition options as we'll be making a
custom options variable so inside the
template of our app we can add something
called a stacked layout the stock layer
will make the buttons that were about to
create stack on top of each other
so inside of our stack layouts we will
have a button and one week tapply button
we're going to trigger the tap event and
that is going to trigger the function
the function I'm gonna create is going
to be called trigger listening so
essentially we're gonna trigger the
listening function which is going to
check to see whether speech recognition
is available on their device if it is
we're going to start listening and if
it's not we're simply going to display a
message that says speech recognition is
not available
so let's write trigger listening
and inside of our app components we'll
need to make a constructor
inside of the constructor we can inject
the speech recognition
as speech we can start writing our
trigger listening function sort a
trigger the listening event we're going
to say this dot speech not available
that returns a promise of type boolean
when the promise is complete we're going
to take the value and we're going to say
if the value is true for example it is
available on their device we are going
to start listening so we'll write that
function in a second and if it's not
available we're gonna alert a message
which says speech recognition is not
available
we can then hook into the aura and for
now we'll consult era the aura
so let's write these starts listening
function an inside of the start
listening function we can call this
speech don't start listening now you'll
notice it has an options parameter that
we need to pass here so let's create the
options parameter we'll make options of
type speech recognition options and it
will instantiate it inside of the
constructor or say this two options is
equal to and if we take a look at the
interface for that it has a locale
an opportunity to return a partial
results but it also has this on results
call back here so we could pass a locale
in here it does default to you the
options of your device we can take the
transcription
and that's going to be if the type
speech recognition transcription that we
imported and we can take that
transcription and log it out to the
console so we can set console dot log
and then we can use es6 template binding
here to see the transcription dot text
we also have the opportunity to log out
other things on the transcription for
example transcription dot finished and
that's a boolean we can then pass the
options variable inside of our start
listening function so we can say start
listening and we'll pass in this top
options
and this also returns a promise so we
can take the value of the promise
and this is actually returned when we
start listening to the user so we can
say started listening we can also log
out any errors that might happen we can
then add the text our button which says
start listening
and we can create a second button which
is going to be stopped listening so this
can stop listening in mid-sentence when
the user taps this button will call stop
listening so stop listening will run at
this dot speech but stop listening and
then this returns a promise once again
we can log out simply stopped listening
to the user and we can log out any
errors that might occur during this
fears to console the error
so right now we have an application that
simply triggers the listening event if
it's available on the device we're going
to start listening to the user if it's
not we're going to alert speech
recognition is not available
once we start listening to the user we
can log out started listening
side of our started listening function
we're passing an options variable that
has an on result callback which contains
the speech recognition transcription
while logging out the text of that
transcription and were logging out the
finished result
we also have the ability to stop
listening to the user if the user
selects this stop listening button let's
run this on the device and test it out
gonna run TNS run Android and this will
run it on my Android device you can also
run TNS emulate Android if you want to
run it on the emulator and you can also
run it on iOS should you want to run it
on iOS the great thing about this
plug-in is it works seamlessly on both
devices
I've run on the device and have made a
fatal error we have not for the text
property on the buttons in the right
location
saw this one little thing to do we have
to add text to the button itself and we
should now see text start listening and
text stop listening inside of our
buttons
when we like start listening
it's gonna ask whether the device can
allow speech to record audio I'm gonna
say yes subscribe for more awesome
videos and as you can see in the console
we have subscribe for more awesome
videos now you can do a variety of
things with this speech recognition
plug-in and displaying it to the console
is just one of them
let's test stopping at the listening
event while we're speaking so I'm gonna
start speaking right now and you can see
starred listening in the console and I'm
gonna press stop listening and we can
see stopped listening to the user and
half of my sentence I hope you found
this video useful and using speech
recognition in your need of script
applications my name is Paul and of
course subscribe to the channel if you
want to see more videos like this let me
know in the comments if you want to see
more near the script videos because
there's lots more that can come in that
direction and until next time I'll see
you in the next video</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>