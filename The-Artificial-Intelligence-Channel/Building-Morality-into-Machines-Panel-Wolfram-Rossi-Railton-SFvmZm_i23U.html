<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building Morality into Machines Panel: Wolfram, Rossi &amp; Railton | Coder Coacher - Coaching Coders</title><meta content="Building Morality into Machines Panel: Wolfram, Rossi &amp; Railton - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building Morality into Machines Panel: Wolfram, Rossi &amp; Railton</b></h2><h5 class="post__date">2017-09-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SFvmZm_i23U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so first I'd like to see if the
panelists have questions for each other
putting you on the spot your top your
speak was very interesting and the idea
of smart machines obviously has a lot of
benefits to it but I was wondering of
implications on a larger stance sorry
on a larger stance looking at the
implications going all the way to
childhood especially just looking at
sorry I'm really looking at my notes
that I wrote just from the common notion
that we learn from that we learned from
our mistakes and so the idea that we are
constantly you know understanding that
this technology is going to be
implemented in society in a much larger
aspect than we're simply talking about
in medical or other infrastructure once
this becomes a much more social
environment that children are going to
be are going to interact with the notion
that there is a constant companion who
is suggesting and telling us and
teaching us what is the right and wrong
things to do in every situation it seems
like there is a lack of our own personal
development and then I think that also
begs the question on a larger
conversation
about originality and creativity and if
we do have these companions who are
talking to us and suggesting based on an
algorithm in which they are constantly
developing I am very curious about what
your thoughts are in innovations and
even artwork and you know who is the
owner of this idea and also sorry one
more thing is that okay okay I think
that it's a very interesting question
and I don't have many answers but I
certainly see it the danger if one
brings this approach to the extreme that
everybody including you know children
are going to be accompanied in their
life in their decision by some support
system then of course you know there is
a danger that creativity learning by
mistakes and originality becomes a bit
but first of all each one of the system
vision it has been personalized so not
the same for everybody and and second I
mean it really brings again the this
fact that I think that this whole once
we have in mind a certain vision as AI
people it's really a multidisciplinary
approach so psychologists you know that
you know know how children you know
evolve can help us understand the
mitigate those and possibly not have
those negative effects and help us
understand if there is in the future a
different way of growing up of building
our own you know identity which possibly
is different from what we have now I
mean I think that people I mean children
that grow up now they grew up they grow
up in a very different environment
up in a very different way from when I
grew up when I was a child is this good
or bad I don't know I mean I think that
there are experts not in AI but another
discipline that can help us understand
the implications of what we do and of
our visions that we can implement but
then you know the implication should be
taking into account so thank you for
this question yeah I had a few minor
comments here any one of the more
bizarre scenarios of how the AI is
takeover so to speak is that we have all
these auto suggestion things about you
know like we have a autocompletes as we
type things in and it's like the AI
knows our you know I'm a person who
happens to collect a lot of data on
myself I probably collected more data on
myself than any other human kind of
bizarrely
and so I have have all this personal
analytics information and so what
amazing systems should be able to
predict for me you know what I should do
they may know better than me what I
should do and there may come a time when
it's just a bunch of water suggestions
that are coming up saying you know you
should take a drink of water now you
should do this did you do that just like
we follow our car GPS says I think it is
extremely likely that most of us will
follow most of those sort of suggestions
because they'll probably be pretty good
suggestions and I think that's kind of
the the soft way that kind of the AI is
take over so to speak first con second
comments is about creativity and so on I
think that people have this view that
you know the deterministic underlying
system the the programmed system doesn't
show originality and creativity I think
this is just not true a good example of
this we made a thing many years ago
called Wolfram tones it was during the
cell phone ringtone craze it still
exists you can go look at it on the web
it's the thing that generates music
using simple cellular automata and it
basically goes out into the
computational universe and it tries to
find you know it has heuristics to
decide you know this is a hip-hop
sounding cellular automaton or something
and it searches you know each cellular
automata it's kind of interesting
because it has kind of an inner logic
it's like it's not just random noise it
has a it has an idea or underneath it
and that sort of rendered in music okay
so I thought was kind of an amusing
thing nobody is going to care about it
turns out I run into all sorts of
composers who say I thought you know a
computer can can take the idea of a
and render it but instead what I hear
from composers is that's kind of a cool
site that I go to to get sort of
creative ideas from which I then build a
whole structure and so the computer in
that case is providing the creative
spark which is sort of a strange thing
my third quick comment perhaps is about
the this question about people learning
you know what the children of the future
will learn and how you know what you
know people learn from the sort of what
civilization has built up and the
environment that we have built for
ourselves and the natural world that
exists it's sort of interesting to see
as we see how kind of they're in the
sort of computational universe of
possibilities there's a lot of stuff
that isn't realized by the natural world
certain reason isn't realized by our
civilization as it now exists and it's
sort of interesting to imagine what as
we get to explore more of that kind of
computational universe how our patterns
of thought changed considerably and
that's that's true for example in this
sort of emergent concepts that arise in
in the insides of neural networks and so
on hi everyone my name is ash oh no an
academic affiliation so throughout this
conference and dr. Wolfram and dr. Rossi
both mentioned rule-based systems for
ethics it strikes me that in human
justice system is the great majority of
the brain power is spent on specific
cases thinking through the details of
you know the different ethical
principles that might apply and rarely
do we see like you know humans spend at
nearly as much time coming up with the
rules even to the extent of you know
fancy legal jargon getting very specific
so my question for you guys and I know
mr. Wolfram mentioned this a little bit
talking about sensors and smart
contracts but what how do we actually do
the complex work of judging individual
cases across different sort of ethical
principles especially in the context of
the fact that most humans have a very
pluralistic and often contradictory
system
ethics I can try taking that I think the
I mean my view of what's possible is to
take you know existing laws and render
them in some kind of symbolic form now
you know laws of different countries
different jurisdictions and so on
they're going to disagree now the
question when you say let's make a
contract I think there's a famous case
about chickens as I recall about a
contract where people where somebody got
a kind of chicken that wasn't the kind
of chicken they thought they were going
to get and the question is when you make
a contract you say I'm going to get this
type of chicken and it's described in
this way it's in in today's world it's a
bunch of English words that say words in
some natural language that say how that
what the chicken is supposed to be like
in the world the future I would imagine
it's much more that both parties will
agree this machine learning system
trained in this way will be the thing
that decides whether it's that kind of
chicken or that other kind of chicken
and I think that that you know if both
parties agree that that's what the
contract the contract is defined by this
code that is this machine learning
system that is going to distinguish
chickens or whatever I mean I think
that's that's some you know I see that
as being a you know you can agree both
parties can agree the code is going to
determine what happens this is a longer
question and I'm not sure I got quite
the import of what you were saying it's
hard to tell okay thank you this is a
question for the whole panel and it's
about the way people today have been
using the words we and our to talk about
our values and things like that and I'm
wondering if that assumes a sort of
commonality to human ethics that is
maybe false so I would have mind here's
the view many theorists have that
Western European ethical traditions
coming out of the Enlightenment or a
sort of historical aberration focusing
on the individual whereas in contrast
say sub-saharan African ethics or East
Asian ethics focus on communal and
communal harmony if all of that's right
then and this is real implications for
AI ethics and in questions like privacy
and autonomy so if all that's right if
that's a reasonable worry I'm wondering
what you think is it necessary before we
cope with AI ethics that we we seek some
sort of convergence some sort of
agreement
Global agreement on intercultural ethics
or do we just accept that AI moralities
will develop independently in different
pockets of the world where the money in
the technologies there and that in fact
AI FX are actually going to diverge and
there'll be different ethical systems
implemented in different machines well
one reason for emphasizing something
like an empathy mechanism is that it's a
way of trying to get moral behavior or
functionally moral behavior that isn't
mediated by a higher-order moral theory
of a particular kind and so therefore it
can serve as a kind of constraint on how
individuals interact even when they have
different moral theories so this is also
relevant to the question about how much
rules matter what will the suggestion
would be that intelligent systems could
be capable of spontaneous adjustment to
each other's preferences each other's
values looking at those under greater
condition conditions of greater
information and adjusting their behavior
in a way that can be mutually beneficial
for them and that doesn't require that
we think we've got the right set of
values right now it requires that we
think we could benefit from working
together
one common perhaps on this the know if
you look at the world today right the 7
billion people divided into roughly 200
countries there's a question can we you
know if we knew sort of the technology
communication mechanisms and so on of
the world can we on the back of an
envelope derive that 7 billion people
will organize themselves into roughly
200 countries it's kind of a scary thing
we recently got data on sort of all
historical country borders there about I
think 1,300 sort of countries that have
existed in history roughly from
historical atlases and so on and you
look at an animation of how the
countries of the of the world have
evolved over time it looks just like
something you know soap soap bubbles
popping and things you know and buy gets
bigger eventually it pops and so on it's
it's a funny process that that I don't
think we understand but I think my might
have to say that my you know the idea
that we're going to have the one magic
sort of AI Constitution that governs
them all I I don't see that because I
think this Constitution has to be a
reflection of our you know our human
and so on and we don't all have quite
the same values and I don't think we can
and I think that's you know that would
be my point of view on that yeah I
definitely agree that is never going to
be one set of values and maybe the
long-term you know vision is that we
will adjust and you know I mean adjust
to the fact that we don't have the same
values but we can interact and we find
it advantageous to you know even in
interaction where shared values but also
in the short term I think there will be
some things some tasks where there are
no there is no set of universal values
so depending on the specific scenarios
that you're going to consider you will
have values that are useful and in that
particular task in Scenario but there
will be other things like even
self-driving cars where you know even
now with normal cars not so climbing
cars no you know even now I mean of
course there are different social norms
and different ways of driving all over
the world but to sell a car that can be
sold all over the world that you have to
pass a certain threshold of safety
constraints and all the cars have to
pass the threshold and then you know you
can improve on one or the other aspect
but all the cars have to part a set of
threshold so I think that in the future
all the start driving cars will have to
pass a certain threshold which can be
tested or you know explained or you know
evaluated in some way and then things
can be different from one to another one
so in that scenario I see the need for a
basic universality for lower you know
low threshold of basic values which are
shared but in another scenarios I see
very specific you know it's great one
totally bizarre point I just just go
ahead for fun I mean this question of
sort of what the future of civilization
is and we've got all these entities
which let's say they're sort of
disembodied souls in
box to the trillion souls or a box of so
there's a kind of a funny thing because
when when you have entities like that
that can replicate in arbitrary numbers
this question of you know how you know
where you get these kind of clumps of
common values gets very weird because
you know we humans seem to like
communities where there are multiple
ones of us so to speak we don't just
want to be one human on on our own but
it's a kind of a funny thing to think
about you know when when you can expand
without bound and yet you have to make
clumps to make the things meaningful how
that works and it kind of gets one into
kind of thinking about trans finite
numbers of souls and so on in it let's
not go so well let's thank all the
panelists for a really wonderful
discussions thank you all for coming
that was a great first day and we'll see
you again tomorrow</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>