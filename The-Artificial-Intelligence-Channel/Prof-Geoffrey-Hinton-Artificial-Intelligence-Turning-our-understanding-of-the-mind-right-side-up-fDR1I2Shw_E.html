<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Prof. Geoffrey Hinton - Artificial Intelligence: Turning our understanding of the mind right side up | Coder Coacher - Coaching Coders</title><meta content="Prof. Geoffrey Hinton - Artificial Intelligence: Turning our understanding of the mind right side up - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Prof. Geoffrey Hinton - Artificial Intelligence: Turning our understanding of the mind right side up</b></h2><h5 class="post__date">2017-09-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fDR1I2Shw_E" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Alan Bernstein I'm the
president and CEO of CFR and it is my
distinct pleasure to welcome all of you
to see farce annual dinner this evening
I'd like to take a moment to recognize
an important individual who's here with
us this evening
the Honorable elizabeth doused well
lieutenant governor of Ontario her honor
is a true friend of science who
throughout her career has strongly
advocated for the importance of the
links between science and science policy
and public policy and thank you again
for joining us your honor it's always a
pleasure to have you with us and you're
always welcome you consider it an open
invitation just let me know and you're
always welcome at a Seafarer of nth I'd
also like to take a moment to recognize
the members of our board of directors
who are here with us this evening
the CFR Board Chair Barb's Diamonds I
don't know where all of you are so
you'll have to forgive me
Vice Chair Bruce Mitchell
to my left pass chair David dodge
where's David
areas and director Stephen Lister I saw
Stephen sitting down and Pat Meredith
see fires bored I'm so privileged as a
CEO to have a board like the one that
that I have they give their time and
their wisdom and their advice and
support so generously and to c4 and help
to help ensure that c4 delivers on our
mission which which is I think I've just
ruined the slide advance you're Jeff
sorry to make a strategic and
transformative contribution to research
we live in a time when organizations
like CFR are needed I think more than
ever the complexity in the magnitude of
today's both opportunities and
challenges from climate change the
refugee crisis that we know all too well
these days terrorism social inclusivity
economic development child and brain
development the health of our oceans the
molecular basis of disease all of those
things and lots more demand the
collaborative efforts of the world's
very best researchers regardless of
country the institution they belong to
the faculty there in the department are
in or the discipline that they subscribe
to and that's what precisely is what c4
does for the past 30 years we have been
connecting Canada and the world's best
minds in unique global research networks
to really discuss deeply questions of
importance to the world I don't think
there's another organization on the
planet like C far we've looked pretty
hard we give our fellows and advisors
who are close to 400 of them now based
in 115 institutions in 18 countries the
time and freedom to explore entirely new
perspectives strike up new
collaborations that they never thought
they would be striking up to take
entirely new paths of discovery our work
puts Canada at the very center of some
of the world's most important
discussions
discussions that ultimately will lead to
transformative knowledge that will
change the world
CFR creates these unique conditions that
make it possible for researchers from
widely divergent fields to share their
individual perspectives and knowledge to
bear on important problems and to share
anti early new ways of understanding an
issue and I can tell you because we're
now going through starting for new
programs how interesting it is how
exciting it is to see the chemistry
between people who not only have they
not met before but would never meet and
their disciplines would never intersect
had it not been for being in a CFR
program and there initially go through a
period of doubt why am I here and who is
this person who are they what are they
talking about I don't understand this
language and gradually over a period of
meetings they get it the light comes on
and it's just a magical thing to see
that happen and to see the new
perspectives of knowledge that comes
with that with that light coming on so
tonight we wanted to give you a bit of a
window into this those sorts of
interdisciplinary conversations that CFR
makes possible as you know we had
originally planned to have a
double-header last year the Jays were
winning by the way with Daniel Dennett
and Geoff Hinton due to an illness a Dan
is unable to be with us today sadly he's
informed us that he'll not be possible
to be here Geoff is not a poor
substitute Geoff is without doubt Geoff
Hinton is without the world's leading
expert on artificial intelligence and
deep learning
he's a CFR distinguished fellow and who
will help us understand why his work and
his colleagues and deep learning has
become one of the hottest areas in
science and in society today and I'll
say more about Geoff later on Geoff will
be joined by our CBC radio host Nora
young who will help us begin to
understand how our world is about to
change by this new science tonight I
have a number of people I'd like to
thank for making see far what it is
today to begin with I'd like to
acknowledge pekus in
careful Pecha served as seven years as
senior vice president at CFR and earlier
this year he informed us that he would
decided to leave CFR and return
full-time to his teaching and research
in high-energy physics and particle
physics at the University of Toronto
Pekka is a world-renowned particle
physicist he was a member of the team
that discovered the Higgs boson that the
discovery of which led to the Nobel
Prize last year in physics and he
brought that international research
reputation to see far and has been a
passionate a truly passionate advocate
for research and a respected colleague
to all of us here at Seifer he's guided
our research programs he's insisted on
rigorous review of each of our programs
every 5 years he's helped evolve the
global Academy for young people and he's
initiated our very first efforts in
knowledge mobilization and I personally
am immensely grateful to Pecha for first
holding my hand when I first got to see
far and for his leadership and helping
to realize see far 2.0 our refreshed
vision for C far Pecha played the lead
role in our first-ever global call for
ideas for research proposals to create
new programs here at CFR and without
question truly without question C far
would not be where it is today without
Becca's leadership his hard work his
passion for research and his passion for
C far factor we're going to miss you and
we miss you well we wish you well I
think Pat's here haven't seen there she
is Pat is really nice to have you here
you'll have your husband back maybe a
little bit more over the coming months
and years
later this evening we're also going to
pay tribute to Richard IV who has been
on Seif Arts Board for twenty years and
who has been truly a mighty champion for
a CFR we'll hear more about and I think
from Richard later on in the evening on
our screens this evening you should be
seeing the names of public and private
supporters and our partners who have
given generously to see far many of you
are here with us tonight and I can't
thank you enough for your support
research cost money no secrets
but if you think of the global issues
that I listed before just think of
climate change or mental illness the
cost of the work that we do is but
actually a very very small drop in a
very very large bucket of the true costs
of those issues to society and I want to
thank particularly those here with us
tonight who have so generously
contributed half a million dollars or
more to help CFR's major new initiatives
the as really foundation the government
of Ontario Richard W and Donna ivy
richard m Ivy Jerry and Geraldine
Heffernan Michael and Sonya Koerner and
the RBC foundation all of you and the
organizations that you represent as well
as many people who of course they've
given much less than that are aptly
critical to do the work that we do we've
also added new research partners for the
very first time in our history
Brain Canada genome Canada genome
British Columbia and for the very first
time again partners from outside of
Canada the US Gordon and Betty Moore
Foundation Gordon Moore being the
inventor of the computer chip supports
our program in quantum materials and
microbial biodiversity and INRIA the
French agency helping to support Jeff's
program in neural computation and
adaptive perception with all of your
support I think we're making tremendous
progress after a very successful global
call for new research ideas we've added
four really exciting new programs
bio-inspired solar energy many of you
we'll have heard Ted Sargent talk about
that last year brain mind and
consciousness the molecular architecture
of life and humans in the microbiome
bringing the total number of our
programs up to 14 I'm very pleased with
that progress but we don't intend to
stop there the world faces many
important questions that can benefit and
indeed absolutely needs research and
from CFR's unique model
thank you all for working with me and my
colleagues to continue CFR's truly vital
work for the world and now please enjoy
your meal Bon Appetit and I will be back
if I could have your attention again
please I hope you all had a had a good
meal I looked at the menu quickly this
evening I said a trio of decent decent
desserts but it actually meant decadent
so I did I read it too quickly but I'm
very pleased that we have Nora Young
with us tonight most of you will be
familiar with Nora as the founding host
of CBC's definitely not the Opera or dnt
oh and now she's the host of spark which
is a show which examines how technology
is shaping our lives and a larger world
in which we live in and after the
presentations Nora will lead normally
Jeff in the conversation I'd also like
to say a few words about about Jeff him
Jeff is a CFR Distinguished Fellow a
distinguished researcher at Google and a
distinguished professor at the
University of Toronto
so he's distinguished times three and
let me point out that he's one of only
three people to be granted the title of
a CFR Distinguished Fellow in our long
history that title is a lifetime honor
it's granted by CFR its Board of
Directors to an extremely small number
of researchers who have made outstanding
long-term long lasting contributions
both the CFR and to science while
substantially advancing knowledge in
their own fields of study I think in
Jeff's case that honor is very very
richly deserved
Jeff became interested in a branch of
computer science called neural networks
back in the last millennia and stayed
interested long enough long after just
about everybody else
had walked away from it in 2004 he found
an intellectual home for his work when
he was asked to found CFR's program
called neural computation and adaptive
perception along with yoshua bengio from
the université de morale and young
Laocoon
from fit from NYU and now Facebook they
along with other fellows in the program
continued to work on neural networks and
developed a revolutionary new approach
to neural networks called deep learning
this form of artificial intelligence has
become hugely successful in the last few
years and indeed is being used for
everything from image recognition to
natural language processing Google
Facebook
China's Baidu and others are using it
and conducting research into it I'm very
proud that CFR took the risks way before
I joined this wonderful organization in
providing the support in those early
days to help make that revolution
possible Wired magazine which is the
sort of magazine of record in Silicon
Valley have done two stories on Jeff on
CFR and on endcap over the last year
I'll just read a brief quote from part
of one of those stories and I quote with
just half a million dollar a year
investment from CFR Hinton's consortium
of free thinkers is set to feed
countless dollars back into the economy
in the process Hinton and CFR have
changed the face of the community that
once spurned them students at
universities are turning away from more
traditional machine learning projects to
work on deep learning in other words
deep learning has now become mainstream
we've ceased to be the lunatic fringe
Hinton says we're now the lunatic core
I'd like to now invite Nora and someone
who's anything but a lunatic to join me
here on the stage Nora
Jeff
thank you very much I'd want to get
right to things I will just say one
thing before we begin the J's
one-seven-one I think so I'm gonna turn
things over to to Jeff to to enlighten
us and then we're gonna have a quick Q&amp;amp;A
between the two of us and I'm all open
up the floor a bit at the end so Jeff
okay I'd like to start by thanking CFR
CFR was the reason I came to Canada in
1987 they had an artificial intelligence
program as one of their first programs
and I came back to Canada in 2002 and I
worked with CFR to set up this program
and it's had a tremendous effect in that
it's enabled researchers in many
different places in mantri both in
Canada like Montreal and UBC and Toronto
and in the States and in Israel and in
Finland all sorts of places to interact
on a regular basis and that led to some
rather pleasing Provost so I'm gonna try
and explain to you what deep learning is
starting by assuming that you know
nothing this is it I'm an academic and I
want to explain these properly so it's
about your networks and your networks
are made up of artificial neurons so
what's an artificial neuron well it's
not quite like a real neuron real
neurons are complicated just like real
molecules are complicated but if you
want to understand a gas you can pretend
a molecules a billiard ball and you can
understand a lot about gases similarly
we're going to idealize systems back
we're going to idealize in urine by
saying it's something that gets a bunch
of inputs if you look at the figure on
the left and on these input lines that
come from other neurons or the census it
has weights it takes activity on an
input line multiplies it by the weight
and adds it all up
that's his total amount and then gives
an output there's a function of the
total input and the input output
function is shown on the right for one
kind of artificial neuron
so if it's total input is above a
threshold that gives an output that just
increases as it gets more input if it's
below the threshold it says nothing so
it has a way of kind of hiding
information it doesn't care about
fluctuations and input if they're below
the threshold okay and this is much
simpler than oriole neural well not not
totally dissimilar but by studying
things like this we can ask if you put a
bunch of these guys together how could
we do stuff and in particular let's take
an interesting task I show you 3 million
numbers and these three million numbers
are the RGB values of the pixels in a
thousand by thousand image and your job
is try to compute a program that takes
three million numbers and outputs a
string of words to describe what's going
on in the image now you don't want to
have to write that program you've much
rather write a simple program that does
learning and let it figure it out
evolution felt the same way so we
connect up these neurons in an
artificial neural network where we have
input neurons that typically represent
things that pixels in an image we have
multiple intermediate layers and then we
have output neurons that represents a
decisions about what might be in the
image we call the layers in the middle
hidden layers because just by knowing
what the inputs and outputs are you
don't know what they're doing
and the aim is to train your network so
it uses those hidden layers sensibly so
how do we train it well there's two
kinds of algorithm the supervised
training in supervised training we
showed an input and we show it the right
output so we shown an image and we say
in this image is a cat and a dog and
then you adjust the weights on all these
neurons so that next time you show at
that image you'll be slightly better
getting the right answer and I'll tell
you how you do that in a minute in
unsupervised training we don't even tell
it the answer we just showed inputs and
it tries to use its hidden neurons in
such a way that from the activities of
the hidden neurons it can reconstruct
the inputs so here's a way to think
about the supervised learning algorithm
we're going to use it's not the
algorithm we use but we use something
that does the same thing more
efficiently if you sort of have a
simple theory of evolution you might
think the way to train the neural
network is this you give it inputs at
the bottom it gets how you get outputs
at the top you compare those with the
correct outputs and see how well you're
doing and you do that for a small sample
of cases where you know the right
answers and you see how well the network
is currently performing on that sample
of cases then you take one of the
weights in the network that weights
shown in red and you change it slightly
and you ask does my network do better or
worse on those cases if it does worse
you leave the weight where it was but if
it does better you keep that change so
you made a mutation to a weight and
you've kept it if the thing gets better
and it's pretty obvious to everybody
that if you did that for long enough
you'd get pretty good weights in this
network well there's an algorithm that
it's telling you one way to the time can
change all the weights in parallel it
just involves using some calculus which
I won't bother you with it's called the
back propagation algorithm and it simply
does pretty much what I was describing
for the mutation method but it does have
all the weights in parallel so if you
have a million weights it's a million
times as efficient as changing one
weight and then seeing how well it does
and if you have a billion weights it's a
billion times as efficient now you
actually have about 10 to the 14 weights
so it's 10 to the 14 times as efficient
which is something like the edge of the
universe um ok it's good to get numbers
that are impressed physicists
so people use this backpropagation
algorithm many different people invented
it but they used it in the 80s when
workstations were fast enough and you
were put in an image at the bottom you
would get out the answers and you were
back propagated error signals and to get
the idea what you're hoping is that
early layers of features will only
layers of these neurons would learn to
be feature detectors or things like
edges and they maybe the next day you'll
detect a pair of edges join it joining
it a fine angle and so that could be a
beak and if you get evidence for a beak
and also evidence for an eye and maybe a
feather then maybe you think is a bird
and so the idea is we get a hierarchy
features this way and we know that the
human brain does object recognition
something like that and it turned out if
you train these networks they can do
that too so in the mid 80s and the late
80s it was reply to lots of things its
algorithm like reading the amounts on
checks detecting credit card fraud
interpreting pap smears but it never
worked quite as well as we hoped maybe
for reading the amounts on cheques it
did but for other things it wasn't quite
as good as we thought it would be and he
couldn't make use of those hidden layers
it couldn't learn lots of layers of
features in the way we thought it ought
to and so most people gave up on it then
we set up the C file program this is
actually a version of history that's
somewhat tailored towards C file then we
set up the C file program and everything
changed a bunch of smart people got
together and had regular meetings and we
figured out how to make backprop work
better and we very concerned with all
the clever little technical tricks we
invented to do that you wouldn't be
interested in those well you need to
know is that he now works amazingly well
particularly if you have a lot of data
and a lot of compute power so he was the
first killer app if you want to
recognize speech you want to be able to
take a sound wave and recognize which
particular piece of which phoneme
someone's saying and so what you do is
take the sound wave pre-process it into
11 frames of coefficients and then
you're asking for the middle frame which
piece of which phoneme is someone say
and here we have whoops here we have 183
different possible pieces of phonemes
and a couple of my students trained a
big deep neural net using back
propagation on our new tricks and they
discovered it works better than standard
speech recognizers just a little bit
better but since thunder speech
recognizers had sort of thirty years of
careful engineering in them and this was
two students in my lab it was obviously
it was going to win
and pretty soon MSR and IBM and Google
were all developing further and one of
my students went to Google in an
internship and by 2012 this came out in
the Android and it was responsible for a
big jump in the quality of the speech
recognition and now all speech
recognizers use some form of neural net
trained with backpropagation all the
good ones anyway then we did the same
thing for object recognition so you take
a high-resolution image and there's a
data set it's important to have a big
data set with a million with a million
images and a thousand different classes
of object and someone has labeled it by
the name of the most prominent object
and since there may be several objects
in the image you're allowed to make five
guesses and if you guess the same name
as them in five guesses you win
otherwise you lose and a bunch of good
computer vision groups used the existing
technology of 2012 the computer vision
technology and the computer vision
people were very down on neural nets
they were saying these things will never
work for real images and then we got
these results so the computer vision
community asymptote is at about 25
percent error and we were getting 16
percent error and something very
impressive happened the computer vision
community over the next year basically
gave up on what they've been doing and
they said okay this works better we're
gonna do that now that's not how
scientists behave if you want to get
scientists to give up on their theory
you wait for them to dying at new
scientists
but in this case they gave up on their
theory and they all do this stuff now
and unfortunately some of them are
better at it than we are
and oops three years later with further
engineering it was down from 16% to 5%
and that's about human levels and so
five years ago if you said how long will
it take before I can show you any image
from the web and you've got a reasonable
better at identifying an obvious object
in it people said oh you're not gonna be
able to do that being images in general
for a long time but now we can do it
okay so these are the kinds of images it
gets and these are it's five guesses and
you'll see there it's very confident as
a cheetah here is confident it's a
bullet train but the point is the other
bets of good bets to the notice that
image has lots of other things in it but
if you ask someone what's that an image
or they would say bullet train and so
does the program here it gets it wrong
it's first buddy scissors and you can
tell from that that it needs glasses
because it sees that chain as the blades
of the scissors frying pans even more
obvious but you can see that all its
bets are visually plausible things
they're visually similar objects so it's
really sort of seeing what's there now
for the last bit I'm gonna talk about
one more application which is applying
this to natural language which Google's
kind of interested in and we're going to
do that using a recurrent Nets of a
horribly complicated kind you've entered
by some people I'm not going to mention
again so this is a simplified version of
their nets called recurrent neural Nets
and the idea with the recurrent net is
at each time step input comes in at the
bottom I've only shown one input neuron
but there would be many and that input
coming into the bottom actually goes to
all the hidden neurons and the net also
can get to give an output and the hidden
neurons are getting input from other
hidden neurons that's why it's a
recurrent net so as time goes by the
states of the hidden neurons at any one
of those time slices are determined by
the input and by the previous states of
all
neurons and the weights on those
connections those two green weights
weights and one red weight going into
the middle neuron they're the same at
each time step because it's a recurrent
Isis reusing the same weights of each
time step and so that kind of net if we
could train it would be able to take a
sequence of inputs and produce a
sequence of outputs and idiots that's
Kiva and two of his co-workers had a
bright idea they said why don't we
abandon the way Google does translation
which is having a huge table of phrases
and map draw the phrases the person
who's got the five minute sign is going
to have to shout at me because I'm not
looking in that direction um good she
didn't charge he said let's just use a
recurrent net and let's have a recurrent
net we feed English words in and then
after we fed the English words in it
spews out French words we don't have any
big phrase table anyway and it's just we
just trained the whole thing by showing
it translator plays we showed this
stream english words i want you to
produce that string of french words so
the way it works is this it's got an
encode or recurrent neural net and that
takes one English word at a time until
it gets to the end of the English
sentence and it converts that English
word into what we call a word vector
which just is just a big bunch of
features of the word so similar words
have very similar feature vectors and
that enables it to generalize and then
those word vectors feed into the hidden
units and the hidden units over time
accumulate information in their state
and the final state of the hidden units
has accumulated information about all
the words we put in and we're going to
call that a thought and this isn't a
kind of I mean this literally I mean
this really is a thought you never saw a
thought before that's what one looks
like
well if you spell that the neural net
that's what one would look like it would
be the activity vector of the final
state of this recurrent net after it
said the English sentence and then to
translate what we do is we take that
thought and we make it the initial state
of the french network and the french
network takes the thought and says okay
given
I thought what do I think the first word
might be and it says well 40% is luck
and 30% is la and 10% says Shah and I've
run out of my french words but there's
some more of them so it puts bets over
French words and when you're training it
you if it really was luck you say okay
you said look 40% but you should have
said learn 100% because that's the right
answer so you're going to back propagate
you're going to change the weights so
it's more likely to give more weight to
learn then what you do is you look at
the next word in the sentence oops I
keep doing that and try to use the laser
pointer um you look at the next word in
the sentence and you put that in and you
say try and I put the second word of the
French sentence so it the first word was
law it has to guess to the law after
it's failed to guess the law you know I
tell it Valor and you say ok the first
word was actually ler what do you think
the second word is and it makes bets
about that and you keep going like that
and you adjust all the weights so that
it will get better at making those bets
after you've trained it you can then get
it to produce sentences so you give it a
thought it produces the distribution of
first words you pick one of them
randomly with 40% chance you pick low
with 30% chance you pick a lot and
whichever one you picked you feed it in
as word one and say ok given that so
first of all what you think mode two is
and it'll give you a distribution you
pick a word as it'll produce a sentence
you keep going to the picks a full stop
and if you run it again it might well
produce a different sentence because you
might randomly pick different words okay
we'll see doing that in a minute um so
that's how it generates sentences after
you've trained it and the impressive
thing about this is it only took about a
man year to do this if you ignore the
few thousand man years it went into the
infrastructure and it works about as
well as standard translation systems and
we seen before that if you can get one
of these deep learning systems done by a
couple of students to work as well as
the standard technology then a few years
later it's going to be much better
what's more we only trained it on a pair
of languages and if you train it on lots
of pairs of languages so for every
language you have an encoder and for
every language you have a decoder but
they can all share the thoughts then you
can give it a Dutch sentence and you get
the translation into 25 European
languages and you can train the whole
system by back propagating through all
25 translations to get much more
information about what the Dutch
sentence meant okay so now let's combine
the vision and the language and then
I'll be done so what we're going to do
is we're going to take the net that
learn to recognize objects and we're
going to say the last layer of that net
before it actually says what the objects
are the last layer of hidden units
before it makes its decisions are really
going to be a description of what's in
the image or an activity vector that
describes what's in the image in terms
of objects rather than in terms of pixel
intensities at the input is the pixel
intensities that tell you what's there
but by the time you get to the last
layer it's got all sorts of bets about
it might be this object or that object
and that's what the last layer is coding
so now what we're going to do is take
that last day and say that's a percept
it's nice to take all these terms I
Luminizer a psychology student and
actually be able to actually have these
things now rather than just talk about
them that's a percept and if we take the
percept
and we map it through a matrix to get a
thought we feed that into the decoder
Network and now the decoder network can
tell us what's in like the image so the
idea is you take your network that could
recognize objects you take the last
hidden layer of it you map that through
one more set of weights to get a thought
that thought goes into the decoder
network which says the thought that is
turns the thought into words and you
train it by showing it images where
someone's told you the caption and it
learns to produce captions and then you
give it new images as never seen before
and see what captions it produces so
here's a new image it had never seen
before in the database the right caption
is people are crouched around in an open
market well the neural net says is a
group of people shopping in and out
Markit here's another one the true
caption is a young girl asleep on the
sofa cuddling a stuffed bear unless
clearly better than what the neural net
says but the neural net says a close-up
of a child holding a stuffed animal and
that's not bad
if you're a computer vision person you
wouldn't have predicted we could do that
by now so this has a lot of implications
for Google particularly for document
processing if we can take a sentence and
turn it into a thought then our
documents just a sequence of thoughts
and we can actually now apply a neural
networks to modeling that sequence of
thoughts we can make each thought be an
input and say predict the next thought
that's natural reasoning that's what a I
could never do I always try to do it in
a different way and it just couldn't do
that now it might turn out that if you
take the stuff on the web and discover
the kind of reasoning that's going on it
is natural reasoning but it's not very
good that's what I suspect but at least
this way we can get computers to
understand what the document says and if
you can do that then Google should be
able to give you much better answers to
your queries you should be able to say
things like find me a document that
supports Stephen Harper and pretends to
be in favor of science but is really
deeply against it if you should want to
say such a thing actually there's no
need anymore
in order to get human levels of
reasoning it seems quite likely that
we'll need human scale of weights in the
in the neural nets and we have about 10
to the 14 of these weights that's 100
trillion and the nets you're seeing
during this translation only have of the
order of 100 million so it orders many
orders of magnitude to smaller present
and that perhaps explains why our Nets
only half understand what they're saying
we're going to need much bigger nets for
this to do a good job but we will the
last two slides about cognitive science
and they're covering the revolution
that's happened that Dennett was going
to talk about so for many years
AI was dominated by the idea that the
internal representations are symbolic
expressions and you operate on them with
rules of inference and most people in AI
didn't think there was any alternative
they didn't think there was AI
hypothesis a few people like neural and
Simon said it's the symbol is the
physical symbol symbol hypothesis but
mostly I people thought that's just how
it has to be and that's because their
only model of how you can take some
sentences and arrive some other true
sentences was formal logic that's a
system that does it similarly for most
physicists the only way you could get
things to propagate was to have a medium
so as a stage in physics when people
didn't think it was a hypothesis that
light ways went through an ether they
thought there's no alternative there
must be an ether let's find it and they
were very upset when there wasn't and
people in conventional area are
hopefully very upset now in particular
people in conventional AI thought that
analogical reasoning was a sort of
second-class citizen that something
we'll come to later that's not really
the essence of reasoning the essence of
reason is proper correct formal
reasoning
actually we know it's exactly the other
way around with people and in fact if
you look at my argument here my argument
for trashing classical AI is not a piece
of logical reasoning it's an analogy
with some physics the other paradigm for
cognitive science comes from biology and
it says look we have biological
organisms we got these brains that have
altered do things like vision and motor
control
they didn't evolve to do logic and they
didn't actually evolved to do natural
language they evolved for other things
and they're highly optimized for these
other things and then we've put all this
high-level stuff on top of them and
they're not very good at it but they can
do it and it's very important to do it
so symbol processing is done on top of
this other operation and it's not done
by having symbols inside the head you
don't have to have symbols inside the
head to do symbol processing in just the
same way as you don't have to have
pixels inside the head to do pixel
processing you look at an image you
process those pixels but someone who
said well you must do that by shuffling
pixels in the head someone like for
example Steve Gosselin would just be
stupid
oh sorry Steve would be incorrect um we
process the only place you find symbols
with us is it the input and at the
output inside it's just all big vectors
of activity that's all there is and
those big vectors of activity are
thoughts
that's what thoughts are
very much chefs I was told to be very
strict with you as to time but you came
in right on the wire so well done okay
and so I want to get into some of the
sort of more broader considerations of
some of the implications of this
research but I want to ask a personal
question to start with which is that
deep learning and neural network
approaches have kind of seen their time
in the wilderness in the past yes so
what was it that kept you so sure that
you're on the right path when there were
large swathes of the AI community that
didn't think it was the right path
they're just obviously the right thing
to do I mean the brain does it right and
the brain doesn't do by someone
programming the brain I mean really
nature somehow I think evolution
programmed the brain and that's how it
does it but that's crazy
um so it's just obvious the brain is
doing this summer and it's doing it by
learning and it's obvious that logic is
something that comes very late and
really if these methods are they're
trying to do logic with aren't able to
do motor control and perception they're
not going to be explaining most of
what's going on in the brain so it just
seemed to me that was never any
alternative right now you alluded to
natural language processing as one of
the applications of this and wondering
if you could expand on that a little bit
and just talk about in practical terms
what would that mean in terms of our
relationship with the computers around
as if we have more advanced natural
language processing okay so I think we
would all appreciate having a personal
assistant who was really intelligent but
accepted very low wages and really knew
all about us but was never critical
except when really necessary and I think
that dream is no longer a dream I think
we're going to be able to make things
that are much much better than things
like Siri things that really understand
what's going on in the conversation and
really understand what you mean and can
deal with novel stuff and I have no idea
how long it's going to be it might be 20
years it might be five years but I think
it's clear that with deep learning we're
going to be able to get something like
yeah and so I think computers are gonna
actually enhance our intelligence a lot
and just take all the boring bits out of
life mm-hmm
you argue that human thought is this
complex pattern of neural activity
rather than as you discuss the
sequential order of reasoning so what's
your work suggest about the way that
mental language and thought work for us
as human beings okay
I'm glad you asked that because as you
know I have a couple more slides
academics are like this they never miss
a chance to put up more slides can I get
up the extra slides please okay I think
and Dennett agrees with me on this which
was a huge relief because I'm not a
philosopher and here's the people get
misled by misunderstanding how the
language of the mental works so most
people think that mental states are
somehow weird spooky things in your head
and I want to argue that's not how the
language works at all and there's very
simple way out of this mistake which is
to say that we want to refer to what's
going on in our brains right I want you
to know that in my brain there's a
strong desire to hit you and you better
behave better and we want to get I want
to communicate that to you and it's no
use me saying that neuron 52 is highly
active because that won't mean anything
to you
even if I gave you the whole activity
vector wouldn't mean anything to you but
a good thing to give to you would be I
could describe the normal consequences
of this activity vector I have and
similarly with sensation I could
describe what would have to be in the
world for me to be having this sensory
activity vector so the idea is that when
I say I have a sensation of red I'm not
referring to something inside my head
almost everybody thinks you're referring
to something inside your head some inner
thing but if you look at the word red
red refers to things in the world okay
it doesn't refer to any things it refers
to the colors of objects in the world
and so the language you put used for
sensation is language refers to things
in the world and what's going on is
we're using a trick we want to refer to
these brain patterns but we can't refer
to the brain pans directly so we refer
to them via their normal causes so I say
to you I've got the brain pattern I
would have if I was looking at something
right so when someone says I'm seeing
pink elephants
they don't mean this pink elephant's in
my head they mean if there were pink
elephants out there in the real world
then what's in my head would be
perception I've got the brain pattern
that would be appropriate for that and
similarly for the language of so that
sensation language and feeling language
is the same
when I say I feel like eating Jerry what
I mean is as apparently my head that if
I do makes I self control what caused me
to hit Jerry so the point here is that a
mental state isn't an internal state
it's a hypothetical external state
that's being used to refer to what's
going on in the brain for a normal
causation or in either direction but
this causing the state in the brain or
the stage in the brain causing this and
there's one place where we get causation
in both directions and that's false
so here's the real language of thought
they said that the language of the word
thought works if I say I can say John
thought and take anything you're like in
pudding quotes and that's what John
thought but that doesn't mean this thing
in quotes is inside John's head it's not
a string of symbols in his head like
there are people used to think what I
mean by that is when I say John thought
where should we go for lunch what I mean
is John had a neural pattern of activity
in his head
that would normally be appropriate that
would normally be caused by somebody
else saying where should we go for lunch
and would also be the normal cause of
him saying where should we go for lunch
you see we have audio in and we have
audio and so with thoughts you can have
an described by their normal causes and
by what they would cause and if you
share a language with somebody then
that's what thoughts are there patterns
in your head that right there big
activity factors in your head and I
described them by saying what would have
caused them or what they would cause
because it's no use describing them by
the activities
it wouldn't be any use to anybody okay
thank you for that all right so you okay
so that's that's what's going on with
thought but can we talk about
consciousness I realize this is getting
a little bit woolly but I know that
philosophers of mind talked about this
idea the hard problem of consciousness
actually this idea that you know the
question of how these patterns of
activity in the brain end up being
something like the feeling of what it
feels like to be standing on a stage
with Geoffrey Hinton in front of a crowd
of people so what does your research
suggest about that okay so the slides I
just put up suggest that's just all a
silly mistake that comes from not
understanding how natural language works
this is an exactly Vince Tinian solution
to the problem it says if you look how
natural language actually works these
physical these philosophical problems
were just about correct and I'm very
relieved to say I run this by Dennett
thinking he's going to trash me and he
said no I agree
he was trained in linguistic philosophy
in Oxford I'm just after a vicars I was
around so that may be a part of the
information but most people think
sensations are things inside their head
and philosophers talk about that by
saying this qualia and qualia are these
magic things you have inside your head
there they're spooky stuff but science
can't get his hands on
there isn't any spooky stuff there's red
things out there and this Panzer
activity in my head that represent that
things are red out there and there's
nothing else but so why do we have that
feeling of - where does that come from
oh there's a separate thing about
personal identity I don't want to get
into that business i stuff there enough
but if we're just talking about
perception
I didn't think there's any mystery
anymore right um the reason that this
isn't anything mysterious and notice
philosophers will often say well what if
when I look at red things I get the same
qualia as you get when you look at green
things I get the same sensation as you
get when you look at green things well
if you look if you think about how the
language works that's logically
impossible it's not just that it doesn't
happen it's logically impossible because
what I mean by the sensation of red is
the thing I normally get when you when I
look at red things and so I can't have
the sensation your green one letter code
things as long as I'm not colorblind
because that's just how the language
works so these philosophical problems
just sort of puff they dissolve so to
return a little bit to the practical
applications of some of this some of the
problems that deep learning is looking
at our speech recognition image
recognition and natural language
processing yeah
so assuming things continue to improve
in this area what's the next horizon
beyond so there's obviously going to be
things like self-driving cars and they
already worked pretty well and things
like that are fairly obvious I think
really skilled and attentive personal
assistants he's going to make a huge
difference
someone was talking at dinner about
what's going to come along that's gonna
be as disruptive as the Internet and I
think something like that would be as
disruptive if I had a personal assistant
who just knew everything and anything
they needed remembering I'm afraid I was
almost tempted to say she would remember
it but um my personal assistant would
remember it that will make a huge
difference to everybody's life
of course there's bad listeners of all
this stuff and we know that whatever we
produce nsa's can use it to spy on us
and the American military is going to
use it to invade little countries of
that any American debt and things like
that so you could say we shouldn't be
developing any of this technology
because people use it for bad things I'm
an optimist I I'm more hopeful than will
get the good users and the bad uses but
we will get some bad uses and there's
not much we can do about that except
political activity of trying to get
people to use this technology sensibly
mm-hmm
we have seen recently high profile
people in the sciences talking about the
dangers of robots in particular but AI
more generally in the far future is that
something that concerns you and do you
think that we need some kind of ethical
frameworks around that
I yeah it's very hard to see into the
far future
it's like looking a long way through fog
it doesn't work but I think it's
perfectly reasonable to think that like
in a hundred years the technology might
have developed so much that we can build
things that are better than people
they've read every book in the world
they just understand much more than us
and all these horror scenarios of us
being replaced by these intelligent
machines so that kind of time scale who
knows yeah I think it's very unlikely in
the next short timescale I think that's
not going to happen in ten years so
around two things yeah one other thing
to say about that is I think what NSA is
doing already is almost as horrific as
that scenario and so to steal a phrase
from a philosopher with rather bad
reputation the terrible has already
happened around 2006 we started to see
this big leap ahead with deep learning
particularly partly at least based on
the fact that these very large neural
networks could work faster than they
could before so is there another
technological barrier that you see that
we have to overcome to get to the next
level or what's what's the hard problem
that you're working on now so what's
kind of interesting at present is that
it looks so we might be in a phase of
normal science where business as usual
is going to make a whole lot of progress
and I can't actually see why by get you
know assuming the computer industry can
keep producing better hardware and keep
doing computations burning less energy
they can keep doing that with Moore's
law for another ten years or twenty
years I think business as usual is gonna
take us a huge way obviously if we get
big breakthroughs big conceptual
breakthroughs that'll take us further I
think one of the big breakthroughs is
going to come is we're going to
understand the brain I actually what
this is just a bet my personal belief is
we're going to get close enough to how
the brain really does do these things
that suddenly it all begins to click and
we kind of fall into a minimum where
it's just obvious how the
brain is actually doing this stuff yeah
and I think there might be quite close
to that and that would be another
revolution because that would affect all
sorts of things like education and our
sense of who we are so I think that's
that would be very exciting I'm hoping I
get to see that yeah so conceptually do
you think there will be a point at which
artificial intelligence surpasses human
intelligence oh I think it's inevitable
in the very long run yeah I mean why
should it so I mean why should it sort
of asymptote at human intelligence it's
I don't see any reason I think yeah
sorry go ahead
I but what what is done with that
technology I think is gonna be very hard
so and I think it's something it's
worthwhile philosophers thinking about
that but I don't think it's an imminent
threat given that human beings are
creatures who are embodied and emotional
and have hormones and all of this other
sort of stuff do you think that will be
an intelligence that is a different type
of intelligence from human intelligence
um it could be I should say at this
point sort of just because I figured I
had some technical tricks when you're
all networks people think I'm an expert
on the future I don't know any more
about it than you do but my guess would
be that yes you wouldn't want to create
other intelligences that are just like
people I mean it's more fun creating
people you would want other
intelligences to be complementary so
what are you excited about right now in
terms of deep learning and I'm excited
about this machine translation even
though I myself haven't made any direct
contribution to it um some of my
students are doing it and I think over
the fairly short term we're gonna get
much better translators yeah I am
excited for things like understanding
documents I think there's gonna be huge
progress there over the next five to ten
years okay and what would that look like
I think you look roughly like what I
said instead of giving Google some words
and they they'll find you all the
documents have those words in
you give Google some themes and it'll
find the documents that are saying that
even if they're saying it in different
words and so you're going to be able to
search for documents that buy what it is
the documents are claiming independent
whatever the works on and that would be
kind of useful that will be kind of
useful yeah I want I think we have a
little bit of time left I'd like to open
things up to questions there is a
microphone over there maybe somebody
couldn't pass the microphone over to
people who have questions sir anyone in
the audience who has a question there's
a question over here
right hello professor Anton I've got a
question just after watching your slides
on the on the language of thought are
you suggesting that you'd be able to
have machine or algorithms that are able
to understand or could you train these
nets to understand human emotion or
simulate emotions similar to those that
human beings simulate and there and see
why not I don't see anything special
about emotion in that sense we can
already get computers that are pretty
good reading the emotional expressions
of faces but most people say but a
computer couldn't have an emotion and I
think that's just a misunderstanding of
how natural language works you could
have a state of activity inside this big
neural net in the computer such that if
the computer wasn't exercising
self-control it would get out there and
punch you and that will be a cross
computer and it would be a genuinely
cross computer then another question I
was wondering how do you see the the
commercialization of deep learning
playing out so is there a
commercialization so I see it as a
thoroughly good thing okay
but I mean is it gonna be an API that
you would basically download and train
for your specific task or or is it just
gonna be something that big companies
like Google Flickr etc are gonna train
for their specific tasks I think it's
actually quite tricky for me to comment
on latter present okay sorry I
understand thank you for your question
and there was a question over here I
wonder is it possible to pass the
microphone over yes please show yes
yeah I do have a point of view I mean
I'm not very confident in it but my
phone interviewers will get a symbiosis
I mean there was up
I don't know biology very well but
there's a point a long time ago when
cells got other cells inside them
mitochondria or something and that made
things go better and I think you might
think of it in evolutionary terms like
that that up to now we just mean
biological cells but now you're going to
get a symbiosis of a person and an
intelligent computer and that's going to
be a far more powerful thing and I'm
hoping that that's through Ticos rather
than computers replacing people
yeah but remember the machine can learn
so as long as you've got adaptive
devices your assistant can sort of adapt
to you and you can adapt to your
assistant so I agree there's an it the
question about how they communicate I'm
sure that we all sorts of fancy
technologies for getting things tracked
doing your brain cells without having to
put electrodes in no the fact is nobody
has a clue about what's going on
yeah yeah I I haven't really thought
very hard about that problem and there I
know there are other people who've
thought much harder about that problem
and so I don't really have anything
useful to say yep time maybe for one
more question you mentioned that in
order for the networks to get better and
better they need more and more neurons
millions billions trillions and you also
said that Moore's law continues to apply
we're going to have the ability to do
that but my question is whether you
really think Moore's law is going to
continue to apply or are we going to run
it to quantum effects at some point that
are gonna create a bit of a barrier to
moving to the next level yeah the thing
about Moore's Law is very like evolution
itself that you have a narrow view of I
mean maybe 15 years ago the view of
Moore's law would be computers get twice
as fast every two years and it's the
same sort of VLSI but is shrinking and
getting faster and that's how Moore's
Law is going to be achieved and then all
of a sudden we reach a bottleneck there
there so just kind of squirts sideways
and now we have more cores and we get
twice as many cores every two years
then something else will happen and so
the the set of things that can be
developed to make Moore's law keep
holding
he's a kind of open-ended set it's not
like you're playing a game where there's
limited rules and so on we are of course
all governed by physics but we're a long
way from sort of particles here and
there's lots and lots of different
things to be exploited and what seems to
happen historically and I think will
keep happening for a while is that we'll
just find different directions to
improve in maybe it'll all suddenly go
genuinely 3d and that'll be a huge win
so I actually think Moore's Law is going
to hold for longer than most people
maybe can hold I think another 10 years
is an optimistic view and good well I
want to thank you for your questions I
want to thank Jeffrey for that very
stimulating presentation and you'll be
around people want to chat with you
informally afterwards yeah and I would
like to thank Nora for joining us to
house thanks thanks thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>