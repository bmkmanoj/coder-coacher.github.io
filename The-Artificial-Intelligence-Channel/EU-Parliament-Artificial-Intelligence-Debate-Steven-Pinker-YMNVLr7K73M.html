<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>EU Parliament Artificial Intelligence Debate - Steven Pinker | Coder Coacher - Coaching Coders</title><meta content="EU Parliament Artificial Intelligence Debate - Steven Pinker - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>EU Parliament Artificial Intelligence Debate - Steven Pinker</b></h2><h5 class="post__date">2017-12-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YMNVLr7K73M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome everybody I know you're very
anxious to you for me to give the floor
to our speakers today so I will be very
brief just explain a few things about
stove organised this event so stove is
basically the Science and Technology
options assessment of the European part
this is the unit that identifies all the
new technologies and all the challenges
that we might face for the future and
make some research and workshops and
studies to give the options and the data
to the members of the European
Parliament
I think we have a much broader audience
of course but this is the main cost that
they can make the decisions that will be
best for legislation and that we don't
stop innovation but we will also have in
our heads the implications and the
potential of course of its technology
sometimes this is not this is not common
sense we have to prepare the members for
this new technologies for example for AI
today because it's it's unknown
sometimes it sounds a bit scary and we
have to explain it we have to see the
potential we have to see if we should
control something or if we should
completely allow it and if we should
have a code of ethics perhaps on how we
fund this new technology so should we
fear the future well in fact when we
talk about this we mean all the
technological developments that have
already taken part in our lives either
we identify them as new technologies or
they are already part of our daily lives
I think we can all remember that we have
heard or seen data that said that it's
possible to automate 747 percent of all
jobs in the u.s. that was the research
in the next 10 to 20 years with great
consequences for our labor force or to
take it a bit further there are many
ethical questions arising already on how
we would treat AI machines with human
levels of intelligence we are scared
that there must be 40 or 45 percent of
job losses due to the a
of course the same time there is a
prediction that our kids 65% will have
jobs that are unknown to us for the time
being so we don't even know what kind of
jobs will be created in the near future
and of course we also have super
intelligence we can be absolutely sure
that the goals of feet will be
compatible with human beings because
human beings are creating the artificial
intelligence but in our one of our
recent events somebody who was working a
lot with algorithms and deep learning
told us that some decisions of the
algorithms he didn't even understand
because of the amount of data that this
algorithm stake and they changed they
transformed themselves the results
sometimes were even scary for the
scientists so I think we have many
experts together today and we hope that
this discussion will set some lights is
a very complex topic of the development
of AI and to contribute to make all of
us live with less fear of the future and
also maybe in our head to have a reply
to to mask and gates that even jus
kannberg that they have now a debate on
how much we should control AI and I
think it's very important to have this
answer here from the European Parliament
and before I pass the floor to the next
speakers I would also like to add that
the store or our unit is trying to
transform to a permanent committee for
the future because we actually believe
that the use of data and the
implications because of the official
intelligence is also based in data and
algorithms and mathematics I think we
need a strong committee for the future
it's great that I was delaying a bit
because you have more people coming so
we will make this effort it's already
happening in other member states for
example in Finland they actually have a
committee for the future and they have a
strategy for the future I think it would
be really important to manage to do that
and before passing the floor I would
like also to thank Michael
League of the European Parliament as a
human as part but who had the brilliant
idea for this event as well as the
Secretariat of course and mr. Philip
butcher to set up this event and also
the resume I say
see also was in charge of the poster
that we have and I think is the best
poster that we ever had in the hang
store we continue like that and thank
you very much for organizing everything
so just one more point that I forgot
this event is web streamed and when I
posted this poster
everybody from Greece were asking how
can we participate and they were really
jealous of having you with us today and
all our speakers and I told them it's
web streamed so today we have audience
also in Greece at least thank you very
much they give you the floor to
presenters tenemos que muchos assistant
is given and Espania e4k soledades de la
Vida in agora moses correcto justo in la
hora que por defecto in Catalunya a lot
lying dependency ax su momento triste
indignant a consume a la voluntad de de
Robar una constitutio noonas Laius
cattle Ana's inclusively es el rupiah's
yo chase más importante acabar con los
Desmond de catalunya esto active era muy
possible meant a suspension de la mia
dima tierra y de la tierra de muchos
otros que estan aqui é nóis momento
seville gusta tener la autonomia de su
tierra a suspended ah en los que
interesante polos friend o menos de
meses para tener aqui na
Casa de catalunya una authentica meanin
futuro yo pronto seven organizes
seminary o SE Vento's como los que vamos
a tener oh yeah key palette our Dante
comprender como un Pueblo Libre felici
Prospero consummate IDO problema tan
grande capacity rasuu bean estoppel
Osiris dicho esto vamos a empezar
bienvenidos a esta septum--ah creo que
nos a team adición de bromine yo - una
plataforma quesadilla Coquina
parliamentary or Pio Danny Thomas Amy
oficina dos y tambien mano graphic O's
public a Sione's relacionados con la
conferencia de la ciencia de las
disciplina sociales para poner la
servicio de los politico's sabemos que
todo mundo piensa que la gente es muy
importante que no parlamento pues pas de
a Liddy arconti más que tienen que ver
con an area con say coalesce into steais
Kimmy Cass con con la piel technology
yeah pero también tenemos información
suficiente para saber que las Ciencias
las Ciencias vo logica
las Ciencias pueden ayudar muchísimo
pulley al al politico para entender
otros phenomena smokerin que tienen
trellis Ian Conan - Ian Ali's moco Lima
grassy own con las cuestiones de deus ex
oh hey Nero etc ido estrosi vientos
hemos tenido
lo mejor de lo mejor como steady saben
hemos tenido
a personas que van desde richard
augustin cournot Soto's año pasado
michael shermer case - von barcelona
único que vemos en barcelona ola propia
hermana
de el ponente que tenemos sake
Susanna's to go than being at home los
meses que the Swiss ambassador present
at Yelp on NTV I know Stephen Pinkett
steady as a banana Stephen pinky they
swoon Chico loco cognitive Oh s
linguistic escrito EW God Oh científico
nacido in kannada de clases en el
departamento de sica loggia dei lanzi
bazar de harbour distintos in West's
public Odyssey
such time prospect foreign policy loss
it wanna be to Amenti in trailers
intellectualize mass influental mundo
especially saw in Keynesian visually
Ishika linguist iike public and Olli
Rose différentes trabajo Sentra vistas
especially Zara's s también un conocido
di Booga door de las ecology evolution
ISTA con la brasa grant repercussion
como la table rasa la nación de natural
semana estos republican dos mil dos en
españa y puede decir que una revolution
para muchos kudos intellectual
españoles pink in the CND KD damos una
natural de semana Astana - Doretta -
Universal manifest about a templo en lo
que llama instint Odell lenguaje
pero man tiene una visión optimist so
release story on manna talcum or Govinda
in de Italia in Los Angeles KD vamos
dentro de la violencia sus consecuencias
estas la traducción de su de su libro
en español y donde DC cosas como creo
que la idea de Progresso s compatible
con Loughran sia in like sustain Tia
de la hora de semana in store off your
Manu non-tree be stopped or de cada en
el diario pies in dos mil dolphin salty
Molly Rhoda sense of his stylistic
Ettore tratak sobre como scribbled
mientras en Thea yell próximos estamos
esperando pero emotion ah Doha roti
encargado n amazona Fiesta Mo's a kiss /
and o que salga es se llaman
enlightenment now yes - via Lobby hen
see Adele pensamiento lost Rado che cosa
tan importante para esta casa por
exemplo yo way no como como como las
cosas buenas a break' espera espera a
Leslie adelante Stephan bodis empezar -
- conferencia
I'm going to give you a preview of my
forthcoming book enlightened now the
last word of the subtitle is progress it
is a major theme of the book and I wrote
it in part because I discovered that
intellectuals hate progress and
intellectuals who call themselves
progressive really hate progress if you
think that we can solve problems then
you have a blind faith for a
quasi-religious belief in the outmoded
superstition of the false promise of the
myth of the onward march of inevitable
progress you are a cheerleader for
vulgar American can-do ISM with a
rah-rah spirit of boardroom ideology
Silicon Valley and the Chamber of
Commerce you are a practitioner of Whig
history a naive optimist a Pollyanna and
of course a Pangloss named after the
Voltaire character who declared we are
always for the best in the best of all
possible worlds
well my reply is that progress need not
be associated with any of these
temperaments or philosophies that rather
progress is an empirical hypothesis
namely their human wellbeing can be
measured life health sustenance wealth
peace freedom safety knowledge leisure
and happiness if they have increased
over time that is progress
well let's look at some of the data we
can begin with the most basic dimension
of human well-being of all life and
health and we see a pattern that is you
will see over and over again whenever
you map out some dimension of human
well-being namely before the
Enlightenment in the say the early 18th
century basically the entire world was
miserable and abject then Europe and the
Americas and at the United States North
America started to pull away from this
state of universe
so misery here we see that the average
lifespan in England in Europe in the
18th century was about 30 that's pretty
much where had it had been parked for
thousands of years before but then
starting in the 19th century the
lifespan of Europeans dramatically
increased that was quickly followed by
the Americas then Asia and more recently
Africa here you have the plot for the
entire world the average life expectancy
today is 71 across the entire world
averaging over rich and poor countries
and including all of the premature
deaths from 0 year old infants virtually
no one guesses that the world's average
lifespan is that high child mortality
follows a similar pattern in Sweden one
of the world's most advanced countries
in the 18th century one third of all
children died before their fifth
birthday
and that declined to very close to zero
over the course of the 19th and 20th
centuries that was then followed by
countries in the Americas such as Canada
then Asia South Korea even in the 20th
century had a rate of child mortality
similar to Sweden's in the 18th century
but it has come down Chile and African
countries are following suit here you
have the graph for Ethiopia which
represents sub-saharan Africa
likewise maternal mortality a couple of
centuries ago a woman had a 1% chance of
dying in childbirth childbirth in the
18th century was as lethal as breast
cancer is today Sweden brought the rate
down followed by the United States Asian
countries such as Malaysia and I now
we're seeing Africa catch up as well
that's the graph or Ethiopia sustenance
famine used to be a regular occurrence
in all parts of the world but starting
with the Agricultural Revolution in the
18th century the number of calories
available
to a person started to shoot up first in
England United States and France but
then more recently China has caught up
even India long associated with famine
now exports grain and here we have the
graph where the world as a whole the
average for the world is the number of
calories needed for an active
middle-aged man we the increase in
calories is not just going to make rich
people fatter but it is also preventing
the stunting of children the United
States for a long time has not had
malnourished children but as recently as
the 1960s 40% of children in South
America were stunted that has been
brought down to less than 10% likewise
we see a decline of stunting in China in
followed by Kenya so sub-saharan African
country and Bangladesh as a result
famine deaths have been decimated and
whereas famine used to be a threat
everywhere on earth now there just a few
pockets in Africa that are vulnerable to
famine prosperity here you have a graph
of prosperity in the world from the year
1 to the year 2000 for thousands of
years everyone was poor then starting
with the Industrial Revolution in the
19th century there was a 200 fold
increase in the gross world product once
again that did not unfold evenly across
the world's regions the UK was the first
overtaken by the United States but then
more recently South Korea has almost
caught up Chile China and you see India
accelerating as well this pattern is
sometimes called the great convergence
as a result extreme poverty which is the
inability to feed oneself in one's
family has been decimated in the
18th century 90% of the world met the
criterion for extreme poverty that has
now been reduced to 10% and the United
Nations has set the goal of eliminating
extreme poverty from the face of the
earth by the year 2030 which means that
most of us might live might live to see
that the day in which extreme poverty
will vanish from the face of the earth
as a result for all the talk of
increased inequality within wealthy
Western countries globally inequality is
decreasing because poor countries are
getting richer faster than rich
countries are getting richer here you
have two estimates of an International
Gini index showing this recent decline
as countries become richer they devote
more of their wealth to helping the
worse-off children the poor the sick the
aged every affluent country devotes at
least 20% of its GDP now to social
spending for centuries that was that
figure was 1% so here you have the data
for France Italy Sweden Germany Greece
Netherlands UK and so on it's a pattern
that no affluent country escapes thanks
to the social spending poverty is has is
being decimated with in Western
countries again for all the talk about
the problems with the American economy
the growth in the growth in inequality
what really counts namely poverty has
been in a decline here you have the
American poverty rate if you take into
account social spending such as the
Earned Income Tax Credit Social Security
and so on and the decline is even more
dramatic if you look at consumption
which is really what counts when you
consider poverty namely can people
afford to feed themselves clothes and
sew themselves house themselves and so
on by one estimate the poverty rate in
the United States was 30 percent in 1960
it has now fallen to 3 percent when
measured by consumption
peace it used to be the case that war
was the natural state of affairs and
peace was merely an interlude between
wars this graph shows the percentage of
time that the great powers of the day
that is the most powerful states and
empires fought wars against each other
from 1500 to the present and you can see
that several hundred years ago the great
powers were pretty much always at war
now they are never at war the last great
power war took place more than 60 years
ago the Korean War which pitted China
against the United States even the wars
that have taken place mostly civil wars
kill a fraction of the people that they
used to here we have the rate of death
in wars from 1946 to the present and
it's been a bumpy ride there are spikes
for the Korean War for the Vietnam War
for the iran-iraq war but we now see
that the rate of death and war which is
about one 400,000 per year has fallen
considerably from the 1950s when it was
20 to 400,000 per year freedom and
rights have been in the ascent
despite some discouraging headlines
notwithstanding the common claim that
democracy is in retreat that there's a
democratic meltdown or rollback
the world has never been more democratic
this is a score of the average measure
of democracy versus autocracy across the
world's nations and it shows that we are
living in a time in which a majority of
nations are more democratic than not and
a majority of people in the world live
in democratic nations for the first time
in history human rights are harder to
quantify but there has been one data
scientist who's tried to quantify human
rights at violations such as summary
executions in prison a dissident and so
on the gold standard for human rights
is the to be found in Scandinavian
countries and here we see that Norway
started out in 1946 as having a high
level of human rights and it's gone even
higher the Koreas have gone in opposite
directions in the 1940s there was very
little difference between South Korea
and North Korea
they were both dictatorships South Korea
has gotten as respected Human Rights
increasingly North Korea as should be
obvious has gone downhill a country like
China the opposite of a gold standard is
still has a higher level of human rights
today than it certainly did during the
Cultural Revolution and the great leap
forward of Mao Zedong the world as a
whole with all of the backsliding all of
the the turkeys and rafa's and
Venezuela's still shows an upward arc in
progress toward human rights one
manifestation of respect for human life
is in the death penalty where country
after country has abolished the death
penalty here you see a timeline from
1863 to the present over the last couple
of decades every year three three
countries abolish the death penalty if
the current trend continues not to say
that it will the death penalty will
vanish from the face of the earth by
2026 homosexuality is being abolished in
country after country again
notwithstanding backsliding in countries
like Uganda and Russia but still the
overall trend is for homosexuality to be
decriminalized and child labor has been
is being decimated in 1850 about 30
percent of English children were in the
workforce that has gone to pretty much
zero who you have the curve for England
in the United States for Italy and for
the world as a whole there is still far
too much child labour but the trajectory
is definitely downward safety we have
never been safer here you have a graph
of homicide deaths over the last 50
years showing that the united states has
reduced its rate of homicide by
more than 50% England too has seen a 50%
reduction since the in the 21st century
alone and the world as a whole had now
has a homicide rates of 70% of what it
was just at the turn of the millennium
in the United States violence against
wives and girlfriends domestic violence
has been decreasing as has sexual
assault and rape violence against
children has been in decline this these
figures are for the United States the
rate of children being beaten up or
bullied at school has declined the rate
of physical abuse by caregivers and the
rate of sexual abuse have come down the
our technology has become safer and
safer as far as I know this is a
universal law and the reductions have
been dramatic an American today has
about 1% of the chance of being killed
in a car accident as his counterpart of
a century before pedestrians are 20
times less likely to be mowed down on
the sidewalk people are about a million
times less likely to die in a plane
crash people are less likely to fall to
their deaths
less likely to drown less likely to be
burned to death in a fire less likely to
be asphyxiated by point by a gas one
exception the rate of poisoning by
solids or liquids has gone up and what
you're seeing here is the American
opioid epidemic so it obviously is not
the case that everything improves all
the time that would be magic not
progress Americans are far less likely
to be killed on the job again a
reduction of about 95 percent and people
the world over are less likely to die in
earthquakes floods wildfires mudslides
and meteor strikes here you have the
rate of
death from natural disasters my favorite
in these is if you think of the
quintessential act of God the bolt from
the blue that is being instructed being
killed by a bolt of lightning
Americans now have 3% of the chance of
being killed by a bolt of lightning as
Americans of a century ago knowledge has
been on the increase it used to be that
only about 15% of the world knew how to
read and write in the early modern
period that first we see the Netherlands
achieving universal literacy then
England Germany Italy a bit later a
United States and as with all the other
measures of well-being the rest of the
world is catching up here you have the
figure the curve for China for Mexico
and for the world as a whole more than
80% of the world is literate now and the
illiterate people are all in their 70s
and 80s when they die off the world will
achieve close to 100% literacy likewise
basic education the elementary school
here we have the British offshoots
Western Europe Eastern Europe a little
later East Asia Latin America at the
Middle East and South and East Asia and
sub-saharan Africa once again there is a
lag but that we are starting to see a
convergence there you have the figure
for the world as a whole believe it or
not we are getting smarter in a
phenomenon called the Flynn effect IQ
scores have been increasing by three
points a decade for a century with the
result that humans today are about 30 IQ
points higher than their ancestors a
century ago here you have the figures
for each of the continents what are we
doing with all of this wealth and health
well we are enjoying life as opposed to
slaving away at jobs work hours in
Western Europe and the United States
have been declining since the 19th
century by about 22 hours a week
people spend less of their paycheck on
food clothing and shelter it used to be
more than sixty percent of your paycheck
went to the necessities of life now it's
about one-third thanks to the growth of
appliances and utilities like running
water electricity washing machines
vacuum cleaners refrigerators
dishwashers stoves microwaves the amount
of time that we lose to housework has
been steadily decreasing from more than
60 hours a week to less than 20 as a
result of all of these leisure time has
increased by about 12 hours a week more
so for men than for women and that's
because women have are using their extra
time to spend more time with their
children which doesn't count as leisure
time is it making us any happier
well probably yes here's a graph that
shows the relationship between
self-assess life satisfaction and gross
domestic product and over over countries
the rich of the country the happier the
person on average this graph this data
cloud shows a number of arrows
indicating the relationship between
happiness and income within each country
and as you can see richer countries are
happier richer people within countries
are happier which means that as the
world gets richer on average it gets
happier well how is the fact of human
progress all of these developments that
I have shown you reflected in the news
I'm going to show you a graph that is
the result of a tone mapping algorithm
where thousands of new stories from the
New York Times since the 1940s are rated
in terms of their ratio of positive
words like better improve increase good
to negative words like crisis
deterioration horrible and so on and as
you can see since the 1940s the New York
Times has been getting more and more
negative
it's not just the New York Times this is
a composite of broadcasts from media all
over the world so as the world has been
getting better and better the media have
been getting more and more negative
journalism so why do intellectuals and
journalists deny progress it is just an
overwhelming fact about the human
condition and the picture of the world
given to us by the writers and thinkers
is the opposite to reality well one
possibility is a psychological
phenomenon discovered by Daniel Kahneman
and Amos Tversky called the availability
heuristic namely the human brain
estimates probability according to how
easily examples from memory pop into
mind so if you see news about a
terrorist attack you assume that
terrorism is common if you read about a
shark attack you don't go into the water
if you see a tornado you think the
tornadoes are a major cause of death and
so on if you combine that with the
famous watchword of news programming
namely if it bleeds it leads
violent stories get the most attention
the most clicks the most eyeballs then
you get the illusion that the world is
more dangerous than it ever has been I
think that's not the only reason there
is a second psychological phenomenon
behind it the negativity bias sometimes
summarized by the slogan bad is stronger
than good this summarizes the results of
hundreds of experiments showing that
people think and feel about bad events
much more than good events probably
because there are so many more ways for
things to go wrong than to go right now
and in our evolution evolutionary
history and the cost of missing a danger
is much greater than the cost of failing
to note a beneficial development a third
phenomenon is what I think of as the
gravitas market namely if you want to be
taken seriously as a social critic as a
profit that it's much
much more clever to be pessimistic than
optimistic pessimism sounds serious
optimism sounds frivolous there's one
business writer put it pessimist sound
like they're trying to help you
optimist sound like they're trying to
sell you something ah finally a somewhat
cynical explanation is that there's a
status competition among elites all of
us seek to enhance the prestige of our
tribe our profession and when
intellectuals aren't responsible for
running things they just comment when
intellectuals disparage the state of the
world it's another way of undermining
the prestige of politicians civil
servants businesspeople the military and
so on well is it good to be pessimistic
is it is it socially responsible is it
good to speak truth to power to hold the
powerful accountable to afflict the
comfortable well it has a serious
downside that I think we are only
beginning to recognize namely that
fatalism if all of the pictures of the
state of the world are that it's going
to hell in a handcart
it's a flaming dumpster it's a disaster
everything everything is a crisis well
people are gonna say well there's why
waste time and money on a hopeless cause
I may as well just enjoy life bring home
my paycheck bring up my children and
enjoy life while it lasts and cynicism
it in for people who do want to change
things if they are told that every
institution is failing it's bound to
encourage the philosophy of to smash the
Machine to drain the swamp to burn the
Empire to the ground and it lays open a
invitation for strong charismatic
leaders to say only I can fix it
now is progress inevitable I've shown a
number of curves that just keep - going
up and up and the answer is of course
not
there is no dialectic that carries us
ever upward there is no
Mystikal arc of justice and indeed any
solution will create new problems which
have to be solved in turn and history
can always throw nasty surprises at us
and there have been a number of them the
two world wars the increase in crime in
the from the 1960s to the 1980s in every
western country the AIDS epidemic in
Africa which reversed the increase in
longevity and as we are seeing today the
rise of authoritarianism in Russia
Turkey Eastern Europe and elsewhere
there are major threats undoubtedly
including prominent among them are
nuclear war and climate change although
I do have to mention that these should
not be seen as portents of inevitable
doom either that there are signs that
that these threats can begin to be
mitigated here we have the number of
nuclear weapons in the world from 1945
to 2015 very few people are aware of the
fact that the nuclear world's nuclear
arsenal has been reduced by 85 percent
and about 10 percent of the electricity
in the United States comes from
decommissioned nuclear weapons the
ultimate swords into plowshares it we
cannot expect this curve to be
extrapolated to zero anytime soon but it
is not an idle dream and as you probably
know some of the world's most vociferous
cold war Hawks like Ronald Reagan like
Henry Kissinger like George Shultz have
called for a world without nuclear
weapons likewise the world's greatest
challenge is undoubtedly climate change
but I think we are not to see it as an
unsolvable problem as inevitable doom
this graph showing the trajectory of co2
emissions suggest that the world has
reached peak coal and might even have
reached peak carbon here yet the
European Union co2 emissions the United
States China India and other regions of
the world all in all the at least the
rate of increase has come down that is
obviously not enough to address global
warming but it shows that industrial
society is not on an inevitable path of
indefinitely increasing co2 emissions ah
I'm going to just throw this out and I'm
not going to defend it because it will
segue into the next session you can't
worry about everything
we really should worry about nuclear war
we should really worry about climate
change
I think worrying about runaway
artificial intelligence of robots taking
over enslaving us for reasons that I can
expand later I think is not an
existential threat ah website so I'm
just to stay on time I'm gonna skip that
but I can go through it later if there
is time but I'm gonna cede the floor to
my my fellow panelists so progress is
not a law of nature I argue in the book
that it is a gift of pursuing the ideals
of the Enlightenment namely reason
science and humanism these ideals must
be identified and defended they are what
we have to thank for the progress that
we have enjoyed if we continue to pursue
them we can enjoy more progress if we
don't you won't uh and overall what it
shows is that human effort is not futile
despite the headlines humanity has made
tremendous progress and there is
reasonable hope for much more thank you
very much
I'm optimistic already more so thank you
gracias gee Tom was a stupid idiot here
Kindle parlamento muchas gracias
vamos a empezar una segunda parte Osito
las preguntas que ustedes a final en
esta parte vamos a tener una discussion
mode arada portals in your Pinker sobre
intelligent artificial unless boy a
person Todd inmediatamente a los
polenta's tenemos Peter John Bentley s
investigador and the campo de la
informatica universidad diversity
college the London it's a spirit or
intelligence activity Elias to the other
computer Fiona volute Eva be adaptive
Ethier sistema ximena's artificiales
your various nagar alleys artificiales
SD beluga door and pre-business come up
white and new scientists in the others
actividad s the seraglio lab LoCascio
medica their mobile state states whole
scope difficult for me I was a little
pushy Havana pasar en el or dengue lo
scream as convenient a weirdo Esther
Thomas missing it s philosopher Adam and
especially southern intelligence
division s conocido suitable de la
conciencia de llamada de el Modelo de
uno mismo enosis pucara s professor de
Ferro Sofia Te'o Rica University mcgoon
Thea
into sobre esta el TuneIn de leyva
tenemos Holly hafstrom
is Professor de mathematic estadística
la Chalmers University
remember there are Royal Swedish Academy
of Science is especialmente conocido pol
bestseller here with Dragons I read it
dedicado al futuro de la tecnología
tenemos a my brand age is investigador
an institute of future of humanity
the University Oxford sinteres 1810
estudiar las consecuencias trophy allas
de las tecnologías emergent A's in
concrete o daily intelligent artificial
illa robotica bustiers que quieran pasar
a step and Elvis Irma Dorado poor steven
pinker
okay I suggest we go in the order in
which s are listed on the program that
seems they do yeah as good an order as
any
so that would hand the floor over to
Peter Bentley from University College
well thanks very much Steven before I
start any questions for Steven mr. Noda
preguntas Paulo final para que tenemos
tiempo table I'm a computer scientist
I've followed you know instructions so I
am the only computer scientist on this
panel and this is a debate about
artificial intelligence so I would claim
to have some let's say credibility I
hope and what they say I've had a
research group in exactly this area for
20 years at University College London
these days I also have a company which
specializes in AI and we provide
solutions for large multinational
organizations so let's say I've spent
some time thinking about this area my
research group at UCL is now based in my
company and we continue to innovate and
create some of the new AI algorithms
that apparently are very scary
to some people I'm going to I I didn't
realize I have to say that Stephen had
so many graphs and had I known I might
not have chosen graphs for my talk but
mine is simpler and I've got the fewer
of them you'll be pleased to know so
what I'm going to talk about is people's
perception about these technologies and
whether these perceptions are let's say
accurate or not
to continue the theme from Stephens talk
so frequently I hear as a computer
scientist statements such as well look
at look at the curves look at the curves
if you if you think of this as the the
rate of progress in processor and
computer processes well it looks like
that it's amazing or if you think of it
as the rate of progress in our ability
to process data or only indeed even in
the amount of data that we now produce
it looks like this and there are some
people that's well perhaps quite
naturally they imagine you can follow
this curve upward and look it's it's
already almost vertical this is this is
an exponential if you if time is on the
x axis well it can't be more than just a
few days before we're going to have
unbelievable processing power I mean
processing power is clearly going to go
head towards infinity isn't it and if if
that has some implications on artificial
intelligence well clearly it's only a
matter of weeks before we've got super
intelligences and if we've got super
intelligence as well of course the first
thing they're going to think of is
aren't people a waste of space let's
kill them all now yeah it's it's good
plot lines for movies I enjoy those
movies and I'm a realist
fiction fan but we have to be realistic
here this is only a bit of the curve I
you know these days I have to meet a lot
of investors and investors love to show
these curves well you've got a hockey
stick curve and your finances it's gonna
be amazing
well let's look a little bit more of the
same curve this is actually the curve
that's pervasive in business in the
natural world and in progress in
individual solutions that we create so
actually find this throughout nature
this is a classic population curve but
you also find it with pretty much every
new idea I'll try and keep it on AI
since this is a debate about AI so every
time we create a new algorithm I also
there's a lag phase it takes us a while
to get this new AI method working but
once we've got the hang of it it looks
really good we get an amazing ability
these things get taken up quite rapidly
and then we hit a point where we realize
okay this is about what this algorithm
can do it has a finite capability I
can't do everything it's not gonna
suddenly become super intelligent each
algorithm is good at a particular thing
might be good at learning it might be
good at classifying data might be good
at optimizing certain kinds of things
and indeed we've got theories and I'm
not going to go into those theories
because you're probably not going to be
that interested but there are
mathematical proofs that say that you
need a different kind of algorithm for
each new problem there's no
one-size-fits-all so this has really big
implications about artificial
intelligence this means that number one
we have to work really hard and we do
I'm one of the scientists and we spend
our entire careers developing AI
solutions and each time we've got a new
difficult problem we go through this
kind of process it takes as ages to
figure out how to do it if we're lucky
if we're lucky we think of something
that works pretty well
and then when we apply it it works all
right it works to a certain level and
then we hit that ceiling we hit its
capability and we find ok that's about
all it can do them and as we try and
make it go further it doesn't want to go
any further that's as good as it can go
so then we have to create another
solution another algorithm and this is
really I
I've spent my career working with
biologists studying what biological
intelligence is like and this is really
our understanding of what intelligence
may be like in general there's no
one-size-fits-all there's no universal
architecture there's different neural
circuits there's different clever bits
of our brain that tackle different
problems and every time through our
evolutionary history that a new problem
has come about we've had to add new bits
of brain to solve that problem so there
are there's a breaking factor here this
is this is not to say this is a bad
thing because we can be optimistic I
want to be optimistic in this talk the
optimistic part is all this stuff about
super intelligence and AI is getting out
of our control seriously guys forget it
I'm I'm one of the computer scientists
who spend all of our time just trying to
make the damn things work I mean
seriously this curve kills us because
every time we think we've got something
good and we try and solve the problem we
hit the ceiling we hit the ceiling of
what it can do and we thought damn it we
thought we've got it this time no it's
not good enough we have to we have to
tune it we have to find a different idea
there are actually other breaking
factors too so I've only talked about
the capability limits of each different
method I see they're real constraints
there are physical constraints there are
energy constraints there are spatial
constraints all of these slow down our
ability to solve problems there's also I
have to say limits in us we don't
understand what intelligence is really
we don't know really how the brain works
and as much as we have models so deep
learning neural network based models
these are based on very very very
abstract simplified understandings of
how the brain works I've got a
neuroscientist work in my lab and
seriously when we ask her to do some wit
lab experiments to try and get a little
bit more data about how a neuron works I
mean the data is almost non-existent for
the simplest things about what real
neurons do how they connect themselves
together what topologies of network are
required to solve different problems so
our problem is a considerable one in
terms of making intelligence it's not
going to make itself believe me it's not
gonna make itself my background is
actually originally in genetic
algorithms and the whole point of that
is to make computers evolve solutions
automatically get them to adapt and
change things my goodness that's
difficult you wouldn't believe how
clever natural solutions are how
intricate the solutions in our own DNA
is to allow us to keep evolving we don't
know how to do that either we don't know
how to evolve ever more complex networks
we don't know how to do all these things
and it's not for lack of trying
we've got tens of thousands of computer
scientists now you know it's fashionable
today right so Google Facebook
every major Apple all the major
companies plus hundreds and hundreds of
smaller companies of getting the best
the cleverest mathematicians and
computer scientists all to try and solve
this problems we've also got major
research efforts trying to understand
the brain yeah guys it's difficult it's
really difficult so and yet there's even
more problems that that slow this the
tax is a breaking point and that is okay
so most of us don't create most of us
when we're trying to solve problems we
don't try and create a general
intelligence and we we don't do it for a
very good reason because we don't how to
what we tend to do is we have a specific
problem and we try and create an
algorithm that solves that specific
problem if we do try and do a general
intelligence well we run into the kinds
of difficulties but I think nature
points to I mean for me there's a real
reason why advanced complex brains are
quite rare in nature to solve most
problems you don't need a big brain you
don't see a lot of trees with big brains
so don't need them and actually to solve
a lot of problems you don't need big
complicated brains it takes a huge
amount of effort in terms of
evolutionary effort to create a big
brain a general intelligence because
every time you add a little bit of a new
capability you've almost exponentially
increased all the different things that
brain could do and that you have to
think of in terms of testing just think
how many things that you can now get
wrong how many ways it can kill itself
how many new stupid things it could do
so every time you add a little bit of
extra intelligence you've got a vast
amount of extra testing to do and this
requires a huge amount of effort well
nature can do that because it's had
millions of years it's got unthinkable
numbers of species
of different entities of different
problems a lot of time it's an amazing
parallel supercomputer the earth and
life but actually we have limited
resources and so for all of those
reasons I'm trying to as you can tell
I'm trying to inject a dose of reality
to this debate here it's really
difficult it's really difficult to make
general hugely intelligent things but
what we can do and let's pan out one
more stage what we can do at our best we
can have a curve like this what we can
do is we can identify specific problems
we can create algorithms that solve
those problems we can figure out which
which AI algorithms which AI methods are
best suited and then we apply them
properly and we optimize each approach
for each problem and at best it'll look
like this this is also at best what a
company looks like when it's got a good
market product market fit and best it's
gonna look like this often it doesn't
often it falls off rather quickly but at
best this is what we can hope for and in
AI research at best this is what we're
going to get for every new algorithm we
design it we apply it and it can solve
that problem up to that level then a new
problem comes along we adapt the album
we create a new algorithm it'll solve it
up to that level I probably spoke in a
long time let me just try and be
optimistic again about this theme what
we're trying to do where we're not
solving these problems randomly we're
solving real problems in society the
reason why we're doing this the reason
why we're creating AI is actually to
improve the life of people we've never
had more people alive on this planet
and the problem is survival you've seen
from Stephen all the nice positive
directions what a lot of this is helped
in no small part by clever technology
and today the clever technology is
becoming smart software AI so people
like me are solving these problems every
day for real reasons the reasons are we
need to get power distributed to large
populations we need to get water
distributed we need to have good optimal
food distribution we want to improve our
medicine all of these different things
we can do
we've got better data we've got good
techniques so the optimistic part is now
these aren't going to get out of control
but they're really good at solving these
rather crucial problems now some people
will argue I'm sure we're going to hear
later oh no we're going to have so much
automation we're going to lose all the
jobs well I have to say I think it's a
spurious argument that AI is going to be
doing this there's always been a push
towards increased automation increased
efficiency now I could say look at that
robot in that factory rolling around
it's replaced ten people's jobs 100
people's jobs look at the way it rolls
around on those wheels we all say oh no
wheels is it rational to be optimistic
about wheels oh they just think think of
the devastation the wheelers course
think of the millions of lives that have
been lost because of the wheel how do we
want to get rid of the wheel I don't
think so ai is smart software it's just
one component in all the different
technologies that we're creating it's
not the only component it's an important
component but you can't blames smart
software for this and to end on a
positive note the nice thing about
computing is the nice thing about what
we can do today is we rapid
spread these ideas we democratized
through the internet all of these ideas
so it used to be 20 years ago that you
had to be a domain expert to edit photos
or to create a studio music track today
anyone can do it because the software is
readily available anyone can produce an
amazing piece of music on the on their
laptop or they can edit photos
professionally if they choose now
already the same thing is happening with
AI software it used to be you had to be
a complete domain expert to apply it and
use it no longer just a few weeks ago
Apple released their machine learning
framework for all the iOS devices any
programmer can now apply these
techniques and is becoming easier and
easier now for sure if you want to do
really advanced stuff I don't want to
take my own business away so if you want
to do really advanced stuff come to us
and we'll help you and if you want to
invent new algorithms you can do it in
my lab but for everyday machine learning
stuff ai technologies it's already
available another five years this super
fashionable job of data scientists will
probably cease to exist because anybody
will be able to do so actually these
technologies just like the internet did
they're going to create vast numbers of
jobs and right now they already are
there are hundreds of AI companies at
University College London we cannot
create data scientists computer
scientists fast enough to meet the
demand there are so many jobs out there
and every company needs a lot of support
and every new technology self-driving
cars yeah we might need entire new road
systems there'll be an awful lot of
infrastructure that has to be put in
that creates jobs so actually as far as
I am concerned this is progress
this is another tool in the history of
human society it's another way that we
help ourselves to survive but it's not
people that should be worrying about AI
it's people that should be worrying
about
poor people kill each other a eyes are
not the problem
a eye is actually being designed to save
lives to improve lives now we're going
to hear Myles Brundage from the future
of humanity Institute at the University
of Oxford Myles so I feel a bit
self-conscious about my remarks now
given that optimism was described as
sounding frivolous to most people and oh
there was a lot of cold water thrown on
various extreme claims about AI in in
the last remarks but I think that there
are things to be said that aren't
frivolous and that do not depend on a
human level AI or super intelligent AI
being around the corner but nevertheless
put AI in a broader historical context
and might lead one to think with some
good reason that AI could be a critical
technology in humanity's future and
indeed help some of the positive trends
that dr. Pinker spoke about earlier to
continue go to the next slide please
but I don't think that was me so what I
mean by a conditional optimism about AI
is that if we successfully address the
technical and governance challenges
associated with increasingly powerful AI
it's likely to be extremely beneficial
in all sorts of ways that all enumerate
shortly and importantly the same
characteristics of AI that lend itself
to some of the concerns that dr. Bentley
was gesturing towards and dr. hog strim
will be talking about later I believe
are also the reasons why AI could be
extremely beneficial and I'll go into
some detail about what those
characteristics are next slide please so
it's somewhat misleading to talk about
the nature of AI and a lot of the way
that people talk about AI implicitly
anthropomorphize it but in reality AI is
a synthetic creation and it's important
to remember a idea that is emphasized by
my colleague Nick Bostrom which is that
more or less any level of intelligence
is in principle compatible with more or
less any set of goals which is to say
that AI even if it were arbitrarily more
intelligent you know within physical
limits as pointed out by dr. Bentley
relative to humans that does not mean
that it will be human-like in its
thought processes or that it will pursue
the same sorts of survival instinct
goals or mating goals as humans it could
be it could be fulfilling the better
angels of our nature or the worst angels
of our nature depending on how it's
designed if the goals of powerful AI
systems are not sufficiently well
aligned with human values then we'll
have extreme competence directed towards
potentially dangerous ends and likewise
malicious or self-interested actors
could direct AI systems towards
arbitrarily harmful ends but what I want
to discuss here is what if that doesn't
happen what if we figure out how to
design AI systems that are aligned with
human values and we keep them away in
some fashion from malicious actors or we
counterbalance those
ai is in some fashion then what we'll
have is a combination of high competence
and high scalability so by confidence I
mean the ability of an AI system to
replicate human performance in a
particular domain or potentially across
a wide range of domains either at the
human level or at a superhuman level so
the example of alphago is very timely
given that just yesterday deepmind
announced a second paper in the journal
Nature describing recent developments to
the alphago system which are
significantly in excess of the
performance which was previously
achieved and this is a common trend in
AI that while there are some cases in
which performance asymptotes below or
around or just above the human level in
this case there is an extreme exceeding
of human performance and ret whether the
performance is at the human level or the
superhuman level what's important to
recognize about AI is that we have the
ability to combine this competence with
scalability in a way that is not the
case with other forms of technology so
there are many technologies that can do
one specific task but they can't do
multiple tasks and they can't we can't
produce arbitrary numbers of units of
those technologies while having that
flexibility so in the same way that a
human is both competent and general in
the way the sorts of tasks that they can
carry out but on the other hand is not
as scalable and because it takes nine
months to produce a human and many years
to educate them it is not the case that
it takes that long to produce a copy of
software so to take an example of
machine translation once Google's neural
machine translation system demonstrated
a significant improvement over previous
statistical translation methods it was
quickly able to roll that out to a large
number of languages and millions of
customers being used many tens of
millions or more times per day
so this scalability applies both to the
number of units of AI systems limited
only by the number
and speed of computing hardware as well
as the throughput of the system so
translation but ultimately more advanced
cognitive capabilities such as personal
assistants can be produced in this
fashion and this is a very significant
development in terms of AI social
impacts when we put these together we
have scalability combined with high
performance and potentially arbitrary
goals which means that we can have
scalable competence in a way that is
equivalent in some sense to having a
large army of humans directed towards
arbitrary problems but it is able to be
mustered much faster and more ethically
analogous to slavery but without the
ethical quandaries which I'll touch more
about later so at least any problem that
in principle could be solved by humans
eventually given enough time those that
domain of problems can be solved with
artificial intelligence if we achieve
the technological limits of AI it might
be the case that there are qualitative
advantages to AI that far exceed human
cognitive capabilities but assuming that
there's nothing magical going on in the
human brain
that's at least a level that we can
expect to achieve eventually that is
scaleable human competence however we
think that they're also you know the AI
research community also believes that
there are things that can there are ways
in which we can go beyond that so AI
systems in principle can be more
transparent than humans although that it
is not the case today that AI systems
are always transparent often they rely
on opaque neural network approaches and
it's not the case that that people can
always audit these systems in principle
AI allows us to have this scaleable
competence while also having additional
beneficial characteristics such as
transparency and the ability to commit
credibly to say providing a public good
in a corruption free manner so this
means that we needn't necessarily worry
about AI systems say defecting which is
a common problem in humans this can
allow us to have more hot more just
public services because we can have the
same confidence
but without the concern about
self-interest and and survival instincts
and so forth driving us away from the
performance that we would like so to
summarize what we can get if we combine
these positive characteristics of a i-4
there are five things that all highlight
in particular and then I'll go into more
detail about three of about three of
them one is tasks expedition by which I
mean expediting the rate at which we can
solve certain tasks if we were able to
combine scalability with competence we
can direct that towards solving a wide
range of human problems secondly we can
improve the ability to coordinate at
large scales and deal with various
problems such as arms control where
there are issues around defection and
verification that AI can help next
there's corruption free public services
which I just briefly mentioned is a
byproduct of combining performance with
auditability next there's economic
productivity and finally a byproduct of
that is an ethical leisure society which
is only possible through the use of AI
at least at current standards of living
otherwise only a subset of human society
would be able to have a leisure society
on the backs of human slaves or human
workers in some fashion so these are the
three that I'll highlight a next slide
please
so tasks expedition briefly is the idea
that AI will enable us to rapidly
compared to a world without AI solve
various tasks that are physically
possible in principle so I got noting
that there are limitations on the sorts
of tasks that we can solve and often
solving one problem will lead to a new
problem to be solved but tasks that
require substantial labor and cognition
in order to solve these are some
examples of these include the
development and deployment of cheap
renewable energy technologies solving
known health problems and developing
atomically precise manufacturing aka
molecular nanotechnology these are all
things that are known to be possible in
principle but would be much easier to
achieve if we had scaleable scientists
that don't need to take time to develop
PhD but instead can be copied and work
in perfect coordination at a very high
pace the next area that I'll talk about
is improved coordination there are many
opportunities for Pareto improvements
that is to say improvements that benefit
one party without leaving any side worse
off such as in the domain of arms
control where it would be better if
multiple parties were to say destroy
nuclear weapons but there are some cases
where we haven't been able to negotiate
those additional reductions of nuclear
weapons or other technologies because
there's concern that the other side will
defect or that it'll be difficult to
monitor compliance and human mistrust
generally speaking is a sticking point
in a lot of negotiations and a lot of
efforts at coordination hey I can help
with this in two ways first privacy
preserving surveillance can be used to
monitor for defection in various efforts
at coordination so for example no human
needs to see the footage of some camera
which is aimed at a nuclear weapons
facility but an AI system could be
designed in such a way that it flags
non-compliance with the agreement
without necessarily leaking excessive
information secondly AI systems could
directly execute certain agreements in a
way that's agreed upon by both parties
this is again a benefit of the
transparency or at least the potential
for transparency of AI systems which is
not the case with humans again humans
have a lot of benefits associated with
them but they are not always as
transparent as software can in principle
be this means that we cannot always
trust them to the extent that we would
like to and this makes AI an important
lever in future coordination the final
benefit that I'll talk about is the idea
of an ethical leisure society so as
previously noted in some of his
non-fiction writing Isaac Asimov
suggested that the only way to have an
ethical leisure society is on the backs
of robot slaves I think that the idea of
robot slaves is somewhat misleading in
that they needn't be designed in such a
way that they have to suffer or that
they would
be resenting their social status or even
having any cognition or any
consciousness at all that necessary that
necessarily goes alongside their
cognition indeed AI is systems are
synthetic and therefore they needn't
have the same correlation of these
various cognitive features which come
bundled together in the case of humans
but it's important to note that as a
result of economic productivity not only
could we have the same level of
productivity and and quality of life
that is currently accessible to the rich
population be more widely distributed we
could also have an ever-increasing share
of the an ever increasing level of
societal welfare distributed as a result
of robot and AI productivity which can
grow on itself exponentially this is a
case where in fact I think an
exponential perspective is justified
because there are fairly fairly high
limits on the amount of digital
technologies that we can develop so with
silicon and some silicon being extremely
abundant there are some rare rare earth
minerals that we'll run into but I think
we will through the combination of
various innovations ultimately be able
to produce large amounts of robots and
produce a lot of economic productivity
next slide please
so just to wrap up I suggested that we
can be conditionally optimistic about AI
that's not to say that we will
definitely achieve all of the the great
things that I just discussed but rather
that if we can navigate the very serious
challenges which dr. hugs from we'll be
talking more about then these are the
sorts of things we can look forward to
and that justify not just banning AI to
begin with they are important to take
into account in an overall set in an
overall landscape of not just the
near-term applications of AI but its
long-term benefits and its long-term
risks
so just to be make clear that I am NOT
Pollyannish about the benefits of AI as
dr. Pinker noted as is a risk with
optimistic perspectives there are
several examples of very serious
challenges that are associated with the
development of AI so the same
characteristics that make the great
scenarios that I discussed previously
like combining competence and
scalability also open up a wide variety
of opportunities for misuse for eggs
again
for example automated hacking and spear
phishing attacks lethal swarms of drones
that have human level facial recognition
systems we should be concerned about
competitive dynamics between countries
and companies that are trying to develop
the most powerful AI systems that they
can including for the sorts of
applications that I just mentioned there
are many technical challenges in
ensuring the safe alignment of AI
systems with human values and combining
that height high degree of performance
with the high degrees of transparency
that would be valuable
not to mention actually solving all the
the main problems in getting AI to work
over the longer term there are issues in
avoiding a slide towards a stable
authoritarian government if we try to
make advantage take advantage of the use
of surveillance to solve these
coordination problems and to carry out
more aggressive arms control how do we
ensure that that isn't misused we need
to avoid human enfeeble meant as we move
towards a leisure society if we move
towards the leisure society and finally
we need to consider the equitable
distribution of benefits of AI so that
even if everyone benefits it's not going
overly disproportionately to those at
the top just to summarize before I
conclude the title of my talk was
scaling up humanity and I think there
are three senses in which AI could help
scale up humanity there's the sense in
which AI could enable larger scale
coordination and allow us to solve
bigger collective action problems than
ever before there's a sense in which AI
allows us to apply more confidence to
very large problems in that sense
scaling up the effort applied to very
big problems and finally in
in perhaps the most exciting vision for
AI it could allow us to more quickly
solve some of the thorny problems
associated with environmental
sustainability and space exploration
ultimately allowing us to move more
rapidly but also sustainably into the
Stars thank you I'm very glad to be here
I was initially a little bit puzzled by
the term rational optimism because I've
always thought of both optimism and
pessimism as biases biasing as a way
from from the rational realistic middle
ground but I think one can make sense of
the term and and and we've heard some
good arguments next slide
so what is rational optimism and let me
first tell you what I think rational
optimism is not mixed so it's not to
claim based on insufficient evidence
that everything is going to be alright
that's that's not the rational way to
proceed a better definition a rational
optimism is to have an epistemic ly well
calibrated view of the future and its
uncertainties admit these uncertainties
that to accept that the future is not
written in stone and then to act upon
the working assumption that the chances
for a good future may depend on what
actions we take today so now that is not
certain but but but if it doesn't toll
then it doesn't matter what we do is we
may just as well assume as a working
assumption that that by doing good
things today we can effect
future in a good way so there's a thin
line to walk here and I want to
illustrate the difference with an
example from one of evens earlier books
which i think is a fantastic tour de
force about positive development in our
society over years and centuries the
better angels of our nature from 2011
where we learn how violence has declined
so there's you saw in Stephens talk all
these diagrams of how things are getting
better and and this is really you see
the same thing in the previous book a
very impressive amount of empirical
evidence and what Stephen does is that
he summarizes so this is about the big
decline of violence that that we the
readers of the book we live in a time
and a place when people no longer have
to worry about abduction into sexual
slavery divinely commanded genocide and
so on and so forth all these bad bad
things having to do with with violence
and there is statistics to back this up
but then comes at the very end the
tricky part the prospect of a nuclear
war that would put an end to
civilization and to human life itself in
fact we don't have the or it's not clear
anyway that we have the evidence that
there's no worry about this or that
there wasn't in 2011 maybe the bore is
bigger today than 6 years ago but never
mind that in order to state that
present-day citizens live in a blessed
state of safety from violence we need in
particular to establish that the risk of
being killed in a global nuclear war is
small and that's a very difficult
statistical problem and if we compare it
to a more mundane thing such as the risk
of dying from a lethal bicycle accident
that's an easy thing I'm a statistician
so I know how to how to estimate things
from data and we have tons and tons of
data on lethal but bicycle accidents
I could give you a figure but with
global nuclear war that's a much harder
thing to do very I mean it has to do
with how do you estimate the probability
of something that never happened yet
this is something that we crucially need
to understand the state to state that we
live in this state of no risk so one has
to start somewhere so we so - as a first
model attempt we can assume not quite
realistic eight stationary conditions
meaning that every year there's the same
probability of outbreak of global
nuclear war so how many have we had so
this this annual probability we denoted
lambda we had no outbreak outbreak
during the last 70 years and this number
zero turns into an estimate that the
best estimate of lambda is zero but then
how sure can we be of that I mean you
statistical procedures to produce a 95%
confidence interval for this parameter
lambda you get that lambda with 95%
confidence sits between zero and point
oh six and that that interval contains
the value point oh five for instance
corresponding to an expected time of 1
over point alpha which is 20 years until
the next global nuclear war and for the
individual citizen this means an annual
death rate as a result of this of
several percent this is totally
consistent with the data so I'm not
saying that there is no way in principle
to rule this out because if we look at
the next slide I emphasize that we need
to look much deeper into plausible
causal mechanisms for Gloop nuclear war
we need to understand political science
and electrical engineering to do this
and we need to do detailed analysis of
incidents such as in 1962 Cuban Missile
Crisis in the 1983 so so we have nuclear
false alarm incident so I cannot give
you a precise estimate of lambda but in
my latest book here be dragons from
truth
sixteen I look at this risk and I look
at various other risks that post
existential threats to humanity and
today we're here to speak about
artificial intelligence or focus on that
so there's this thing with the most
advanced emerging technologies
artificial intelligence nanotechnology
biotechnology that they have this their
double edge they come with enormous
economic and other benefits and
especially in my presentation we saw
that all these great things can
potentially come about as a result of
artificial intelligence development and
basically it's only in the limit it's
only the laws of physics that that pose
the limits but these come together with
enormous risks there are risks having to
do with autonomous weapons arms races
there are also risks having to do with
Robo sourcing and technological
unemployment and there's also this more
exotic risk namely the issue which I
want to focus on here on whether once we
obtain an artificial intelligence
breakthrough sufficient to create super
intelligent artificial general
intelligence meaning something that
outperforms the human brain clearly
across the whole range of capabilities
so that we know humans no longer are the
most intelligent beings on the planet
can we then expect to remain in control
so that's that's a concern and I want to
give you this
cartoonish kind of example called
paperclip Armageddon perhaps you've
heard of it
what happens in this scenario is that a
paperclip factory is run by an advanced
but not yet super intelligent artificial
intelligence program to find ways to
maximize paperclip production then it
happens that the engineers improving
this machine happen to become successful
the first one to reach the critical
threshold to enter
rapid spiral of self-improvement that
some theoreticians here are have
discussed at least as a plausible
possibility known as the singularity or
an intelligence explosion so then
suddenly we have this super intelligent
machine which has the goal of maximizing
paperclip production so it goes on to
turn the entire solar system including
ourselves into a giant heap of paper
clips we don't want this so what's the
point of this paper tape Armageddon
scenario so one point of choosing paper
clips is to make it obvious that this is
this is a cartoonish example it's not
the paper clips that if you're worried
about putting more general snares but
but but the other point which is kind of
important is to stress that for some for
things to go really bad you don't need
have any ill intentions you don't need
to have a mad scientist planning to
destroy the world as a revenge of
against humanity even even mundane
seeming goes like paper typical
production can go bad so let's take a
step back look at this a little bit more
generally and ask whether anything like
that might happen and this question is
is most usefully analyzed in two steps
the first step is to ask when if ever
can we expect the super intelligent
artificial intelligence to emerge the
second is what can we then expect to
happen and on the first issue well first
of all people with a naturalistic
worldview will probably all agree that
that it's unlikely that evolution has
found the global optimum of intelligence
in the universe there are most likely
configurations of matter that that
vastly outperformed the human brain and
the question is can we find these by the
scientific method and how fast and and
when you ask experts well if you ask
Peter he says it's not going to happen
if you are asked some of his colleagues
they say that it will or it might and
they're really divided as to whether a
breakthrough of this kind you can have
and during the 21st century so the
possibility because of this disagreement
should be taken seriously so I'll skip
the technical details on this and move
on to the second issue of what will
happen so we might for precaution there
are suggestions that let's keep this AI
boxed in so that we can control it but
there are very good arguments that that
strategy is is not going to work in the
long run with an entity that exceeds our
intelligence so it we can expect it to
sooner or later it escape the the box
and then our fate depends on what it is
motivated to do because it can outsmart
us in all sorts of ways what will its
its both be the answer the short answer
is we don't know but there is some
theory about this the so-called m100
boström theory of ultimate versus
instrumental goals miles emphasize this
orthogonality thesis which says that
virtually any ultimate goal is
compatible with arbitrarily high levels
of intelligence so the ultimate goal of
this machine can be paperclip production
maximization of human happiness or
basically anything however there's also
this other thesis instrumental
convergence thesis it says that there
are a number of instrumental goals that
we can expect the machine to set up as
tools to achieve the ultimate goal
pretty much no matter what it's with
this ultimate goal is so that gives us a
little bit of predicting power so
examples of these instrumental goals are
self preservation this machine is not
going to want us to pull the plug on it
because then it's not going to be able
to work it's worth its goal it want to
acquire hardware and other resources it
wants to improve its own software and
hardware which is kind of a crucial
ingredient in the argument for the
intelligence explosion preservation or
final goal it will not want us to tamper
with its goal because then it will not
be able to
for it in the future and finally if the
ultimate goal is dis aligned with my
values it may be a good strategy for the
machine to keep a low profile for a
while until it knows how to take over
okay so this what do we do about this
there is this idea called friendly AI is
to somehow make sure that the first
super intelligent AI has values that
align well with ours so that it would do
things that are that that favor human
welfare and so on and so forth now
because of the gold preservation
instrumental gold that there there is an
emphasis and this goes back to work by
ukhov ski and Nick Bostrom emphasizing
the need to instill the AI with such
values prior to the a I reach in super
intelligence level because after that
it's going to be too late this seems to
be a very difficult project or even
small discrepancies can lead to a
catastrophe and someone if you suggest
to go to the mission that we program the
machine to maximize hedonic utility
maximize happiness - stop suffering in
the world that that may sound very
tempting but and and it may create a
very good world in some sense but the
problem for us is that solution to this
maximization is unlikely to involve the
existence of humans we are discussing
here very uncharted territories so we
need to be a little bit speculative but
we should also be humble about the our
epistemic situation we're so far from
the familiar and the well-established I
think there's a fair chance that we are
making some fundamental mistakes
somewhere in discussing these
orthogonality thesis and paper clip
Armageddon and instrumental convergence
and so on and it might be that this
beautifully did cost key Bostrom style
AI risk is mere confusion I don't quite
see why and all it what may well not be
mere confusion I think that the it's a
there's a fair chance
that the risk is real and therefore I
think that you'd come ski Boston style
AI risk is worth taking seriously and
it's worth taking seriously now not
because of the emergence of super
intelligence being imminent it probably
isn't I'd be very surprised if it
happens in the next few years but the
reason is that Friendly AI is such a
difficult project that we may need
decades or more to make it work and with
that I'll just finish by by showing you
my book where I have a lot more on AI
related and other existential risks to
humanity thank you
so can you hear me no okay how do you
feel can you still take another 15
minutes so this thing doesn't work
somebody else you do it okay which one
this one so maybe some of you in the
room know these people this is a famous
now famous you project it was the very
project on virtual embodiment and
robotic re embodiment well we try to
transpose the sense of self into avatars
and this resulted in a code of conduct
for ethics of virtual reality and I
think we need something like this for AI
2 I think we need something like a
globalized code of ethics and one that
does not come out of the industry or a
specific group of privileged individuals
but which eventually comes out of the
political institutions so just to take
this as a starting example I altered
this with a young
excellent American philosopher Michael
Midori whom are hired for the project
and this is open X's in this code of
conduct we developed in this European
project for virtual reality there are
many details but there are also some
very general philosophical points I just
pull out one or two scientists must
understand that following a code of
ethics is not the same as being ethical
I don't know if you understand that
point but we need a kind of ethical
awareness an active ethical attitude on
the point of their researchers and for
virtual reality technology there are a
number of very general points that have
a little bit to do with AI as well our
best mathematical models of human brain
dynamics
tell us that conscious experience is
itself a form of virtual reality which
is biologically grounded more people as
this technology reaches the mass-market
right now will understand this point and
this point that what we've called
conscious experience in the past is
actually a biological form of VR will
have social cultural consequences and
virtual reality environments will create
something like a social cognitive image
in which the human mind will adapt and
evolve in the future so these are
examples for general conclusions from
that report and of course they apply to
the problem we're discussing here today
as well so nastier I've found it
german-speaking country foundation of
effective altruism with a number of very
brilliant quits we have a headquarter in
Berlin right now and among other things
we've done we've published a policy
paper on opportunities and risks for
artificial intelligence and what I want
to do is not talk about any of the
details in there with you but I'll just
pull out a few issues you see there are
actually works so there are a number of
general points I think we need
institutional measures at this point
this has to be taken out of the hand of
the industry this debate and the out of
the hand of media with their own
interests and we need specific
organizing efforts worth international
research collaborations for instance but
I won't go into these general points
here are some of the the general
recommendations for the EU so for
instance we have to think about an
unconditional basic income and negative
income tax in a new way and we have to
also implement new forms of research
grants to tackle these
and we have to find found new expert
commissions and funding schemes
incentive landscapes to pull good people
into this debate but let us look just at
three very detailed points and then I'll
finish and this connects to what you
just said the first example is is that I
think pessimism or optimism really is
not the question what we need is very
fine-grained evidenced-based risk
management rationale and evidence base
not mega questions like rational as
optimism and pessimism and here's one
example it's the standard principle from
rascal rational risk management that
even if the probability of a very high
future damage is actually low it is
rational to invest resources into
investing risk minimization today even
if the probability of the risk itself is
low we have to work today now this is
counterintuitive it's a general
principle of rationality but it's
counterintuitive to most of us just
think of the talks you've just heard a
normal human comments common sense ser
come on this is all science fiction it's
a new media Java people fight for
publicity in five years all of this is
going to be gone that's then that's how
a normal person reacts to all of this
but there are real issues there namely
extreme future risks and so we in a
certain way we have to counteract our
own intuitions and tackle this in a
strictly rational way hmm
so here is a second constraint an
example pulled out of this policy paper
for you I called it how to satisfy the
globality constraint so I talked about
this code of conduct the ethics code for
virtual reality now if we want
to create a code of conduct and ethics
code for these AI issues it has to be a
global one why because we risk of
banning AI research from those countries
in which a rational debate is possible
that is we may cause a race to the
bottom if say in the EU we come to
strict safety regulations the cutting
edge research will just like with tax
evasion it will just go to other areas
in the world and the development of the
technology will take place in other
areas of the world with much lower
standards of ethics assessment risk
management and so forth
so one thing we have to prevent is that
there is a risky relocation of research
to countries with lower safety standards
that's recommendation number six but
this is also an example of something
where I think one cannot be a rational
optimist to pick up Steve's point it's
just not rational to expect that we
would man that humankind would manage
this to have a global set of rules
ethical rules for how to develop AI in a
friendly and safe way with no holes and
no areas on the planet where these rules
don't work so I think this race to the
bottom problem is a serious and real
risk and there's no rational reason for
optimism which already brings me to the
last point and the last point is
something that really sounds like
science fiction and you may know that
I'm a consciousness researcher and that
I'm one of the people found at the
association of or the scientific study
of consciousness 22 years ago I'm really
in this field and the first thing I have
to say is I do not believe that we will
have
synthetic phenomenology meaning
artificial consciousness tomorrow or the
day after tomorrow I have a very strong
addition intuition that this is not
going to happen we don't have a theory
of consciousness we could implement but
that risk of increasing the overall
amount of suffering in the universe is
one extreme risk so for a number of
years have been arguing for a moratorium
on synthetic phenomenology meaning that
the direct creation of not artificial
intelligence but artificial
consciousness should not be a target of
any serious form of academic research or
anything that is funded for instance by
the EU there are people in England and
there people in Japan who are explicitly
aiming also at artificial sentience at
artificial consciousness and for many
reasons I think we should not do this I
have also formulated criteria because AI
researchers have always asked me ok we
really see the point Thomas how can we
build AI that is safe to stay
unconscious that never begins to suffer
that never has subjective preferences
that can be thwarted in there are papers
of mind that try to isolate the main
necessary conditions for what we should
not do if we don't want to create
artificial suffering but that's this
last problem and I'll end on this shows
that the difficulty in the ethics of
artificial intelligence as opposed to
other fields of applied ethics is that
we have so very different predictive
horizons we have predictive horizons
like 2030 where we can make rather safe
predictions and discuss races but we
also have these issues like artificial
consciousness which sound really crazy
to any normal person but there are
people working on it and there
people who want to make their career
with it so I think recommendation eight
and nine are it's important to have an
understanding of which natural and
artificial systems have the capacity for
producing consciousness in particular
for experiencing suffering given the
apparent level of uncertainty and
disagreement within the field of machine
consciousness as a pressing need to
promote fund and coordinate relevant
interdisciplinary research projects that
is this ei funding has to be related to
the existing consciousness research
community and I think we should really
have ethics Commission's that prevent an
unexpected creation of sentient
artificial life we should avoid this at
all costs we should not trigger a second
level conscious evolution without
knowing what we do recklessly just
because some scientists want to go down
in history and then we have the problem
that we cannot just shut these systems
off anymore because of course they have
a consciously experienced preference for
continuing their own existence so just
these three examples I wanted to leave
you with and again the general point I
think this is not about pessimism and
about optimism
it's about very rational sane work
creating the necessary political
institutions and ethics committees and
just set the standards in the in the
spirit of enlightenment thank you very
much
well I'm going to use my prerogative as
I guess in the session share to offer
some of my own comments including some
of the remarks that I edited out of the
talk that I presented earlier today I
think there are serious threats to
humanity that we have to worry about and
nuclear war is certainly one of them
but I I teased in the this slide I think
that runaway or rogue or malicious
artificial intelligence is is not one of
them not not that the risk is risk of
nothing is zero but humanity has a
finite budget of worry if people are
convinced that the there are so many
existential threats that we're not going
to survive another generation something
is going to do us in then they'll say
well let's just have fun now and there's
nothing that we're doomed Humanity is
screwed so let's just enjoy life while
we can I think it's very important to
put risks in in in some perspective so
why do I think that the thought of robot
takeover or artificial and malicious are
artificial intelligence is one of the
things that we I don't need to worry
about well one is there there are there
have been false alarms before plausible
sounding technological Armageddon's that
in retrospect we see are ridiculous I'm
referring specifically to the y2k bug do
you remember that that in the 1990s the
big existential concern was that when
the year 2000 came all of the computers
that had been programmed to represent a
year by its final two digits would get
confused about what year it was on
January 1st 2000 and in that moment and
I'm not exaggerating airplanes would
fall out of the sky nuclear power plants
would melt down incubators would shut
off in neonatal wards nuclear missiles
would be launched from their silos now
now we and these were serious people
that warned of this threat
President Clinton in retrospect we see
that this was just letting fantasies go
well so it is a danger that not every
technological Armageddon is turns out to
be worth worrying about there is a
tendency for the pessimistic fantasies
to get more attention than they deserve
and I actually think this is true of
artificial intelligence running amok
first of all as Peter said and I agree a
hundred percent with this talks
artificial intelligence is really hard
Moore's law of a number of transistors
you can fit onto a chip does not apply
to the insight to theorizing to actual
artificial intelligence to just take a
contrast let me just talk about how a
super intelligence will help us solve
the global warming problem well do we
have a a when will we see a robot that
can do something that certainly half of
humanity would welcome namely the
ability to change a baby's diaper when
will we see a robot that can do that
when will you hand over your baby to a
robot
the answer is not anytime soon I mean
that itself would be a problem that it's
just an order of magnitude beyond
current state of robotics
and and I think that that's true for a
lot of the hypothetical scenarios taken
to the next level that we really should
not expect the concept sometimes called
Foom
after the comic-book sound effect where
hypothetically artificial intelligence
will improve itself recursively I think
that is probably incoherent let alone
not around the corner it's like we're
thinking about the development of a
machine that can do anything what I'd
even mean do anything and likewise an
intelligence that can solve any problem
I suspect is not a coherent concept
because problems are so heterogeneous
they depend on so much detailed
real-world knowledge that can only be
applied by
experimentation in real time that the
brains smarter than ours that can solve
all problems is is an incoherent concept
second reason is that be as has been
mentioned intelligence is compatible
with any goal
these are wanting something and knowing
something or desires and beliefs motives
and intelligence are two different
concepts we could program a computer to
solve our arbitrary problems but the
problems are things that we have to
decide upon in designing the system to
begin with I think there is a tendency
in some of these scenarios to think that
intelligence inevitably comes bundled
with the desire to dominate and so as
our machines get smarter it's only a
matter of time before they'll want to
enslave us look at what we humans have
done to the animal kingdom look at what
powerful civilizations have done to more
less technologically advanced
civilizations I think that's a confusion
of the particular kind of intelligence
that we happen to see in Homo sapiens
which was the end product of natural
selection a naturally competitive
process so in the human brain we have
bundled together some degree of
intelligence and some degree of
competitiveness dominance aggression but
that's just an accident of the
evolutionary process that built some of
us and there's no reason whatsoever to
think that it's in the very nature of
intelligence that it should want to
dominate in fact we know of one form of
highly advanced intelligence that does
not come packaged with a ruthless desire
to subjugate and dominate they're called
women third in the a more realistic
scenario is not that there would be a
kind of Hal in 2001 that desires to
dominate but what has been referred to
as the value alignment problem
maybe if we gave the a and artificial
intelligence the goal of
making paper clips that would turn our
bodies into paper clips if we gave it a
goal of self-preservation it would do
anything including destroy us to
preserve itself if we gave it the goal
to maximize human happiness it would
rewire our brains so that we'd have a
constant drip of dopamine I mean it
seems to me that that kind of scenario
is self-refuting I mean the way to avoid
that is don't build such a stupid system
that is don't build a system that only
has the goal preserve yourself at all
costs we don't design any system that
has one goal that that that it pursues
regardless of human cost when we design
a Cuisinart there is the danger that yes
you can chop your fingers off together
with the carrots and that's why we build
finger guards when we build a car
there's a danger that if it goes too
fast it'll crash well yeah and we put in
brakes in a steering wheel it's in a
nature of technology that it serves
human interest of course it's possible
to stupidly design something that will
pursue one goal at the expense of
everything else that we value and the
solution is don't build a system like
that
it's a self-contradictory to say that
that an intelligent system might pursue
a goal heedless of its side-effects
that's not intelligence that's not a
system that we would ever build and if
you look at the curves that I showed for
the natural evolution of technologies
they all get safer and over time that's
because we learn from mistakes we don't
let planes carry passengers until
they've proven that they're safe often
with many years and billions of dollars
of testing and that's clearly what we
will do with artificial intelligence
we're not going to build a machine that
hat that is plugged into the world's
infrastructure that has just the goal
preserve yourself that would be an
idiotic thing to for it to build what
about malicious humans the evil genius
who actually does design a computer to
to kind of weaponize artificial
intelligence well there's I think a
fallacy of thinking that's that
as follows and I've heard this argument
a number of times the natural
progression of technology is to allow
more and more to be done by fewer and
fewer people so that a eventually one
person will have the tools to do
anything and given human nature that
means destroy everything but there's
actually another narrative that Kevin
Kelly the founder of Wired magazine
points out that any technology at the
cutting edge requires a network of
people there's no such thing as the evil
genius Google doesn't just find the
highest IQ person they can find and and
have him solve problems all by himself
there's always a network with their
company with connections to other
companies with connections to the
government and the more people you have
in a network the less likely it is to
pursue some fundamentally antisocial
goal because people know other people
who know other people it's hard to have
a conspiracy that works without leaks
without defection without stings without
blunders and as a society as a
technology advances it becomes more
socially distributed which naturally
puts limitations on the single evil
genius doing something that the vast
majority of society doesn't want such as
swarms of bots that will attack an
individual based on facial recognition
they're an awful lot of people that
don't want that to happen more people
who don't want it to happen then who
conceivable who could possibly do and
therefore that's why the mad scientist
does get confined to to science fiction
in well I think I probably said enough
but that that is one of the reasons why
although I don't believe that we should
rest easy about technology we've got a
prioritized our risks and malicious AI I
think is pretty low low on the list and
in my opinion anyway I've been told to
to wrap up and let's open it up to
audience Q&amp;amp;A
well can I a music first the microphone
so can I can I jump in and say okay
clearly Steve and I are agreeing on
these issues I I tried to I tried to
sort of head off the the existential
threat of AI is taking over us in my
talk they didn't work but I'll have one
one more go and that is well let me put
it a different way I think it's very
very foolish to treat AI as though it's
one thing because it's not AI is smart
software and like all clever software
it's a series of different solutions to
different problems and each solution is
designed specifically to solve that
particular problem it may be very good
at it
yeah it may even be better than humans
at certain things certainly my computer
is a lot better at recognizing faces
than I am I'm terrible at recognizing
faces however that's all it does and so
if you want to think of AI as any kind
of thing that needs regulation and in
some cases of course it will then just
think of it in terms of any other
technology when we put in ABS systems in
cars we have to introduce new regulation
new certification a new testing make
sure it works safely so if we're going
to put in a eyes for self-driving
vehicles fine it's a very specific
application they're not going to start
forming communities of evil cars that
want to take over the world they're just
going to drives about but it's a safety
critical application
so we have to certify and regulate and
test them so we've always done this
whether it's auto pilots in aircraft
whatever it is if it's safety critical
we consider that specific application we
introduced the right regulation the
right certification the right testing
and then we make a save as Steven says
we're pretty good at this so I suggest
that we continue doing exactly this the
danger is actually if you if you start
classing a thousand different
technologies because that's what AI is
it's a thousand different ways of
writing smart solutions to different
problems if you say that all the same
thing and you start regulating against
this then I'm afraid you really will
harm progress you really will prevent us
from solving these critical problems and
we're only trying to keep people alive
here and you're trying to help people
and as we've heard from other panel
members it's highly unlikely this kind
of regulation would be made law across
the planet in which case all that would
happen is China would become Kings or
Russia would become Kings at this
technology so frankly I don't see the
problem here we're all smart people we
know how to deal with safety critical
systems why don't we just keep doing
what we've always done and think about
each problem as it arises and make sure
we do the right thing so there have been
a lot of things said by doctors Pinker
and Bentley I'll just pick up on the B
you know I don't think we have time to
get into the malicious genius so I think
just to you know pick up on the point
about the quiz inert and and safety
critical technologies I think I
generally agree with that way of
characterizing the situation but I'm
less
optimistic about where we stand today in
terms of the degree of investment and
the degree of seriousness with which
we're taking AI so I I do think it
should be treated as any other
technology in the sense that we should
invest in safety and testing the and
people are arguing that so there was a
Wall Street Journal op-ed just yesterday
by to a eye researchers at the company
open AI arguing that there could be
extreme safety risks from AI and there
needs to be more safety research the
problem as I see it today is not that
you know some are claiming that we
should ban AI and and others disagree
and that we're risking setting back
progress is that we don't know how to
put the the safety blockers on the quiz
an art of where the AI is the quiz an
art it's just a conceptually very hard
problem and some are arguing that we
should put a lot of effort into figuring
out how to solve that problem I've got
to say I just anything that's true
that only becomes true if you if you
think AI is one big thing it's not if
you if you just look at what we actually
do we we apply specific AI solutions to
specific problems and if they have
safety-critical then we introduce safety
regulations accordingly that's all it's
really not difficult folks it's not
difficult may I comment so Stephen you
brought up this y2k example and nothing
terrible happened but we actually made a
lot of preparation for this and it may
be that things could have gone maybe not
apocalypse but it turns out the
countries and companies that didn't do
ytk readiness had no problems either I
actually looked into that yeah yeah yeah
so it's like okay so so so if that's
right then the y2k was not a problem it
doesn't follow that the emergence of
super intelligence is not going to be a
problem so just saying that let's not
worry
about it that's the kind of irrational
but it's not going to emerge that's the
point it's it's entirely irrational to
even conceive that it will emerge
because it's frankly the most irrational
belief right now is to believe there's
going to be a super intelligence it's
like saying okay my pet dog which has a
remarkable brain and it has the ability
to adapt its brain it has ability to
construct its own brain construct new
versions of itself change over time
maintain itself repair itself why isn't
why isn't that taking over the world and
becoming a super intelligent it's far
better than any technology we could hope
to create for hundreds in probably
thousands of years why is my pet dog not
not an existential threat to mind oh ya
know de las personas que quiere and I'll
be very brief because I really really
want to sacrifice my time so the
audience can ask some questions I just a
question to you do you realize that
there are already players in the field
who have an interest that certain
discussions do not take place do you see
that there's a highly historical
dynamics here already right there's the
in have you noticed that IBM doesn't
speak about artificial intelligence
anymore about about cognitive computing
because they're afraid of these public
ethical debates I think this has to be
pulled into the political institutions
and done there else there are too many
players who pursue their own interests
but I'll be interested to hear what you
think
so thank you very much for the
invitation
my name is Della Valle I have study
physics and in this class excuse me
one one minute mark yes thank you 1 2
question 1 4 I don't know who came as
well do you have some experiences with
artificial intelligence and quantum
informatics technology and the second
one is do you wished in artificial
intelligence tools to discover or to d2
to have to have the information for the
next radicalization person I mean for
the terrorists and to have an alert and
to say look for this person I have a
model 40 percent probability that became
a terrorist and to give me the direction
which shall I act see excuse me
vamos a tomar I will block is the
thinkö preguntas no no vamos a tener
tiempo thank you thank you very much for
all and for your excellent presentations
my question is you all showed more or
less several graphs and and ideas how
the level of happiness at large in the
world is increasing therefore I would
like to be I would be interested in in
your views about how its then explained
all these movements in expressed radical
movements that come up quite violently
in several places in the world and if
there is any hope for artificial
intelligence to help and avoid them
thank you for your explanation my
question is I would like to address mr.
Pinker and mr. Bentley you spoke about
not classifying all kinds of artificial
internal intelligence into one category
and about submitting artificial
intelligence to regulation and testing
before releasing it onto the market in
in to the public however I would like to
refer to another novelty of that arose
at the turn of the millennium namely the
Internet's and the problems that the
internet still poses today like the
darknet hacking and crimes etc and it is
still not regulated it is still not
contained
shouldn't it be isn't it reasonable to
provide a safety net to avoid further
problems like the ones we face now with
intelligence would you agree that
mistaking machines for humans is a legal
and ethical trap and that more
specifically you cannot molest or rape a
sex doll because it is a machine not a
person thank you very similar question
to Professor finger please should the
interpreters and translators have fear
of the future when it comes to AI and
language technology with a nod to their
colleagues in the room the interpreters
thank you
okay so of those I can recall quantum
computing and AI yes they're similar
going on in that area it's very
speculative because we don't really have
proper quantum computers yet there is
some interesting work that may improve
some capabilities of some algorithms I
forgotten us that the other part of her
question radicalisation well and this
kind of relates to so many other
people's questions too there's there's
there's a danger that none of the
panelists who like to the AI bashes
perhaps are aware of but I think it's
actually a much more interesting danger
a lot of a lot of us now are relying on
curated news on devices such as these so
a lot of us around the world are now
reading information getting our
information about the world through
their little a is that they're trying to
figure out what we like and then based
on what we like to read they give us
more of the same now I happen to know
many of the researchers that created
these algorithms and they even realized
that there's a side effect of this and
the side effect is a polarization of
opinion it means that if you keep
presenting the same thing that they like
all the time they don't get a general
view of the world anymore so this is
actually a real danger of AI it's a very
specific application of AI and it points
to and some of them are claiming I don't
know if this is true but some are
claiming this could explain some of the
more radical behavior some of the more
unusual election results recently
because populations are becoming more
polarized they're no longer getting the
general information that they once did
and this they don't how can we use AI to
solve these issues well we can actually
change what we're asking it to do at the
moment we're asking it to show us things
that we like
perhaps we should add a little bit of
understanding of how to educate people
as well so shows a bit of what we like
and share a bit of what we need so that
might be a useful thing to think about
in terms of helping democracies it's
also yes it's definitely possible to use
data mining machine learning to track
potential terrorists this is definitely
something I can do I'll try to answer
the questions that are directed at my
way an excellent question of why if the
state of the world is improving do you
have these angry political movements
that act as if the world is in deepening
crisis Donald Trump being the prime
example one reason is that there is an
enormous perception gap about happiness
polls show that everyone thinks that
everyone else is less happy than they
really are by 40 percentage points and
much of the anger and political
movements does not come from personal
unhappiness
it comes from narratives or theories of
the world in which you think that other
people are being exploited or made
miserable even though you're doing okay
so it really depends on Kenaz on guiding
the the narrative the arguments the
polemics as in improving people's actual
standard of living can artificial
intelligence help with that I doubt it
other question will artificial
intelligence replace interpreters I
suspect not anytime soon for some of the
reasons that that Peter pointed out
namely problems in artificial
intelligence are really really hard and
we can get often there's like a sudden
leap to a certain level of competence
but then scaling that up to the
competence that we would need
particularly in the domain of
interpretation where there are very
subtle arguments being made in a forum
like this just knowing the general gist
or the topic of the conversation which
are translators translation systems
could already do it's just not going to
be good enough and if you use Google
Translate you probably have the same
experience that I do you get a general
sense of what it's about but if it's
anything related to your own
strong interests it 70% is just not good
enough it has to be even way up in the
90s the final point is their new
technologies like the internet always
are going to come with unanticipated
consequences solutions to problems
always create new problems that have to
be solved in their in their turn many of
which cannot be anticipated when the
technology is on the drawing board but
the tendency such as when cars were
introduced the rate of death was was us
was sky-high I mean new cars really were
a menace but the danger was brought down
as engineers started to inspect the the
wreckage compiled the statistics people
generally want things to be safe and
something that there's only appeared
last five or ten years they're
definitely gonna be problems it doesn't
mean that it's a portent of the future
because we're just starting to mount a
defense against it as for a kind of race
for the bottom where safety the argument
that safety features are futile because
other countries will simply circumvent
them I think that too is not the general
direction the technology is taken we
aren't seeing huge numbers of planes
that crash being manufactured by China
to undercut us because no one wants
planes to crash and the deleterious
effects of new technology are generally
things that people all over have an
interest in trying to mitigate is Peter
Rick's consultant in Brussels question
for Steven Pinker you said that we need
to change the narratives close the
peseta
why don't you think algorithms can help
with
he's so conference iya to stay calm okay
okay we can leave okay you neural ASEAN
and see mismo general las noticias que
las noticias que creo no ser que son las
vidas valise noticias por los cuales oh
so true no sinteres ahmo's cuando vamos
por la calle y alguien que hay un
accidente set Ragna logic when terrors
for las manos noticias que no quiero mas
a a los period ellos pero be pregunta
concrete assyria see no clue stay que en
si discuss o de la mala noticia
el periódico que lo characterize
además de el principio existence yeah
no es realmente tambien factor depta
mismo decir noah contribute osa
pessimism o ontological del periodico
una pequeña matazano in your belly
respect o algo que dijo sobre la
polarization de las noticias NOS
exactamente internet a trade hola
polarization de las noticias suppuration
de las noticias exist iya ya mucho antes
de cada uno tenía su periodico sukadeva
surah do cetera lo que se crea
SK internet Eva acabar con el SAPO a
hacer las noticias nivartante zootopia's
end if attalos que no sin complete o sea
que usted quiere amitabha mental DeVos
pero thank you my main question is the
Swamper transparency of iya process
talked about bondage for professor
Bentley and in linked with control
computing since most computing now is
the energy minimization problems and
walks within black box so we really
can't know what we do and what about the
contra on T FDI a process that use a
quantum computer and then about the
legal state status that was talked about
Tomas by Tomas Medina and
we we are ethically bound to not kill
aya
that could be sentient if they are
someday but legally there are no
standing so anybody could just shut down
a computer on that there would be no
sanctions so maybe we should do
something you should create a status for
those I thank you have a very short
question I want to ask is this proposal
which was just made about a global a
global Universal Charter not a
relatively good solution even if there
might be difficulties to monitor its
implementations in the whole world and
do people like Bill Gates from the
private sector and Stephen Hawking who
is from the fundamental physics are they
not informed enough about artificial
intelligence thank you the pertain is a
question of why why don't I think there
can be algorithms that will help us
recap there ative x' to minimize
possibly dangerous political movements
like authoritarian populism well for one
thing it's a it's an ill-posed problem
we don't know exactly what we're the
problem that were how to specify what we
count as a solution or what we're aiming
at and even if we did you know as Peter
pointed out problems and artificial
intelligence are really really hard you
can't just say well let's get an
algorithm to do it it's like saying well
to help change a to relieve mothers of
having to change diapers let's get a
machine to do it well you can say that
but actually building the machine is
really really hard and there isn't a
team of hundreds of brilliant AI
researchers being funded by companies
that are thinking about how to change
political messaging you may as well get
a team of a hundred people just thinking
about how to change political messaging
themselves using the natural
intelligence would that would probably
be a more direct way of solving the
problem in terms of pessimism and bad
news there is a a ethic in journalism
that to be serious you have to point out
what's going wrong if you point out
what's going right that's advertising
that's not journalism and yeah and
indeed there has been a benefit to
pointing out corruption and injustice
and hidden problems there's certainly
journalism must continue to do that but
any feedback signal that only indicates
when things are going wrong and never
indicates when anything is going right
can only lead to a kind of cynicism that
nothing that we do can make anything go
right it's even if it's just a question
of accurately holding authorities to
account you've got to be able to show
well in some parts of the world some
things are working
so that is a benchmark that people in
power ought to aspire to so let me just
very briefly underline your point it is
of course true that the conscious
artificial subjects of the future have
no representative in any ethics
committee or in any political process
today let's just write this in an
abstract point that is right but of
course it points to a larger issue
conscious human beings of the future are
also only weakly represented in their
preferences in the political process
right now and much more strongly the
conscious animal that the trillions of
conscious animals that are living on
this planet now it in the future their
interests are also almost not
represented in ethics committees and in
the political process so and I very much
like as a German philosopher of course
likes it if an American psychologist
suddenly promotes the ideas of
enlightenment but that Kampf
of humanism in the idea of enlightenment
is actually a weak and insufficient
component true enlightenment would take
the suffering of all creatures that are
part of a capacity for suffering into
account not only human beings that
includes animals today and that was your
point
possibly conscious machines of the
future just two quick points one is on
the transparency question related to
quantum AI so I haven't heard of
anything related to transparency for
quantum AI and I think that's just
because there isn't that much going on
yet in quantum AI and AI I think as in
other cases of transparency and AI
there'll be a sort of a catch-up process
as as systems get deployed more widely
people start to ask hard questions about
how interpretable and auditable they are
I I deal E we'd be more proactive about
it but so far that's been the case the
the other question I want to briefly
pick up on is the Bill Gates and Stephen
Hawking like do they not know enough
about AI I think to some extent that's
you know the wrong question to me the
the more interesting question is why do
experts disagree so much so there there
are very interesting surveys of expert
opinion on these precisely these
questions of what do you believe about
this argument that a misaligned AI could
you know could cause all these problems
and how soon do you think we'll have
human-level AI and all these sorts of
questions and there's a huge range of
expert opinion and more interestingly
experts are unaware of how much other
experts disagree with them so there's a
lot of variation and not a good account
of that disagreement so that that to me
is is noteworthy when anyone says that
oh well AI experts all disagree with
Stephen Hawking actually you can find AI
experts to disagree with every other
can I just speak to that so I I was very
interested in that poll I think was Nick
Bostrom who conducted it and in with in
when the hundred most cited AI
researchers were polled as to whether AI
represents some existential threat
ninety-two percent said no eight percent
said yes so there is disagreement how
you interpret the eight percent well we
don't know how to interpret the eight
percent there's a different more
authoritative survey that I'm referring
to but all I can say is all of my
colleagues and I go I you know I've been
around the field a long time I work in
this area I've got more than 20 PhD
students who've completed they run labs
all around the world I know guys in deep
mind I know guys in Facebook and Google
Yahoo the list goes on and on I do not
know anyone who works in this field
who's a computer scientist who believes
there's going to be some kind of super
intelligence
I just don't know anyone and okay that's
that's not a survey now but it's
certainly a bunch of very good clever
people who've worked in the area for
decades so many of them pioneers
including people like Jeff Fenton so you
know I I think it's sorry guys I think
is a nonsense happy to make
introductions there's also an excellent
volume actually available online for
those of you want to pursue it further
they're called what do you think of
machines that think on edge org it's
also a paperback book and it's a survey
of I wouldn't say all but a lot of the
leading thinkers in artificial
intelligence and philosophy of
artificial intelligence and I highly
recommend that collection
so Jon Brockman is the editor edgestar
org what do you think of machines to
think yes we've heard a lot of
disagreement there was one point on one
of my slides that you may have
overlooked it's called epistemic modesty
and I think this may be a good closing
word all of us really don't know what
the answer to many of these questions is
and I think epistemic modesty is
something that really should guide
future debates in this there are many
unknown unknown still
now Kusaka Barack e yo somos los minutos
de la hora yo creo casa donde bat
antenna Santissima a monster you know
spontaneous phantasticus Javier Tolo so
Jose muchas cosas de brito damos tenido
UN mode arid or deluge Oh que la se Mo's
muchísimo che estado esta mañana con
nosotros muchas gracias por venir espero
que estén todos que siguen los otros
que hacemos en el Romine este no sale
Ultimo vamos a tener actors we
interesante esta en el futuro muchas
gracias para ver venido estamos muy
pronto</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>