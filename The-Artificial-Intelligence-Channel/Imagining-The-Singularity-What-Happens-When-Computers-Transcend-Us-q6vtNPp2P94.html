<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Imagining The Singularity: What Happens When Computers Transcend Us? | Coder Coacher - Coaching Coders</title><meta content="Imagining The Singularity: What Happens When Computers Transcend Us? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Imagining The Singularity: What Happens When Computers Transcend Us?</b></h2><h5 class="post__date">2018-02-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/q6vtNPp2P94" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Paul Kennedy and this is ideas it's
powerful and influential as information
technology is today it will be a billion
times more powerful in 25 years so we
use the meta metaphor borrowed from
physics to describe that a singularity
computers and artificial intelligence
are now so powerful that we may well be
approaching the most pivotal moment in
human history the singularity when
machine intelligence exceeds our own and
becomes super intelligence at some point
we will figure out how to make super
intelligence machines set a radically
smarter than us there's this kind of
super intelligence I believe is an
extremely powerful thing that could
really shape the future for the better
for the worse will this be the dawn of a
technological paradise or will it
trigger humanity's downfall what kind of
an intelligence will this be a guru a
god or a monster I think we should be
very careful about artificial
intelligence I mean with artificial
intelligence we are summoning the demon
and is the idea of uploading the human
mind the promise of immortality or a
techno pipe dream of religious
transcendence one could say that the
singularity simply is a religious
concept to the extent that the terms the
infinite or the ultimate if those terms
are meaningful at all it's in a sense
that deserves to be called theological
in this episode of ideas CBC radio
producer Jim Leben's explores the
enormous potential and peril of machine
super intelligence in the documentary
we're calling it
the singularity
the afternoon of May 11th 1997 deep blue
challenges Kasparov's brain with an
array of 256 processors that can examine
200 million possible moves every second
on deep blues 19th move the champion
resigns
maybe that was the moment that future
historians will point to when we began
to lose the race against the machines or
maybe it was more recently in 2011 when
IBM's Watson AI rump to victory on
Jeopardy
one of these on your wall is Right twice
a day
Watson what is clock clock is correct
and with that being a rocket or maybe it
was just last year when a new generation
of AI proved its metal at go considered
the most difficult of games by achieving
full post human excellence
alphago zero is the strongest go program
in the world it outperformed all
previous versions of alphago
specifically it defeated the version of
alphago that won against the world
champion Lisa doll and it beat that
version of alphago by hundred games to
zero you can see the pattern here
artificial intelligence is emerging all
around us and it's exceeding human brain
power in new ways every day it's not
just in games it's driving cutting-edge
science influencing your behavior
through internet advertising even
predicting our political choices and
you're carrying AI in your pocket or
purse smartphones are using AI
algorithms and they can now recognize
your face and your voice answer
questions and follow instructions AI
software from Facebook and Google is
mining our past and anticipating our
social needs before we're even aware of
them computers can even speak our
languages ok Google say greetings to our
computer overlords in Japanese but
that's that's no computer although in on
you homie no guys that's it the
explosion of AI into so many domains has
been breathtaking but it's the next step
that's really going to be revolutionary
as impressive as it is current AI is
limited to specialized tasks but many
observers think that in a relatively
short time perhaps within decades AI
will transcend its current limitations
it'll develop into a general
intelligence that will be comparable to
and will probably significantly exceed
the full breadth of human intelligence
and that most futurists expect
we'll transform the world you might have
heard some of this before perhaps from
the most famous popularizer of the idea
inventor and futurist Ray Kurzweil as
powerful and influential as information
technology is today it will be a billion
times more powerful in 25 years and so
you get to 2040 s the non-biological
portion of our civilizations
intelligence will be by my calculations
actually a billion times greater than
the biological portion so we use the
meta metaphor borrowed from physics to
describe that a singularity in human
history we can't easily see beyond this
event horizon coming in human history
because it's so transformative for years
Kurzweil and others have been making the
case that this moment will be so
revolutionary that it's impossible to
even imagine how technology the economy
and human society will be transformed
and like matter and light falling past
the event horizon of a black hole we
can't see what happens to it what new
form it might take that's the
singularity but as we get closer to this
moment
there are people who are trying to push
beyond that event horizon to try and
anticipate what the dawn of super
intelligence will look like they're
attempting to think past that's
supposedly impenetrable frontier to
imagine the singularity I'm a Nick
Bostrom I'm a professor at Oxford
University where I direct the future of
humanity Institute at some point we will
figure out how to make machines
generally intelligent have the same
general-purpose smartness learning
planning ability that we humans have and
then I think after that super
intelligence machine set a radically
smarter than us this kind of super
intelligence I believe is an extremely
powerful thing that could really shape
the future I mean it literally could be
the best thing that ever happened in all
of human history forget is right and my
main concerns with relation to this
transition to the machine intelligence
era is that we get that super
intelligence done right so that it's
aligned with human values a failure to
properly align this kind of artificial
superintelligence
could could lead to human extinction or
other radically undesirable outcomes
that seems a powerful argument for
understanding what we're getting into
and planning for it but another reason
to imagine the singularity is that this
is something humans have always thought
about hi my name is Madeline Ashby and I
am a science fiction writer and futurist
I think that we as a species have always
been interested in intelligence and in
investigating intelligences like our own
we can imagine the singularity because
we've imagined it many times before I
think that the story of what it means to
create a thinking being an intelligent
being has fascinated us from the
beginning of our species these are old
stories it's not just Blade Runner it's
not just Frankenstein it's not just you
know stories about robots it's the Bible
it's every creation story that's ever
existed because we are fascinated with
the idea of creating in our own image
the anxiety around creating an
intelligent being and a thinking being
no matter what shape it may take is the
anxiety of of having a child and seeing
your own flaws reflected back to you you
here are certain words when people speak
about the singularity creation
transcendence apocalypse these are
familiar ideas because this is the
language of religion there's a sense in
which futurism looking at the future
imagining the future hoping for the
future is something that historically
has been within the purview of religion
it's been an expression of religious
sentiment I'm James McGrath a religion
professor at Butler University whether
it's the view that things will keep
getting worse and worse until eventually
there is a cataclysm and everything
begins the cycle over again whether it
is a new era the kingdom of God a
restoration of paradise all of those
things are expressions of hope
expressions of faith that there is some
meaning to the universe some divine plan
or underlying rationale that has a
trajectory
so how do we imagine the singularity
well perhaps the first step is to try
and understand what it is we're trying
to create a machine super intelligence
how do we create a computerized mind
greater than our own
I'm visiting someone who's trying to
create this new kind of computer
intelligence it's something quite
different from the computers were used
to it's inspired by the most successful
and powerful computers that the universe
to our knowledge has ever produced the
massively parallel hyper efficient
infinitely flexible biological computers
we all carry in our heads my name is
Chris Eliza Smith I'm the director of
the Center for theoretical neuroscience
at the University of Waterloo and a
professor in systems design engineering
and philosophy and I hold the Canada
Research Chair in theoretical
neuroscience I'm also a co CEO of
applied brain research I'm at the
University of Waterloo
to see Chris Elias myths brain not the
kilo and a half of fatty cells he
carries around in his head in fact it's
a simulated brain a brain model that he
spent much of the last decade working on
this electronic brain is called spawn
spawn semantic point our architecture
unified Network spun is a large-scale
whole brain type model that we
constructed beginning in about 2012 we
have a visual system we have a motor
system we have decision-making systems
and so on but really all the model is is
you know millions and millions of
neurons so it's about 4.5 million
neurons and they're all connected to
each other so you know for most of these
you can see that I've got a name like
working memory on this box and for the
most part it's not unreasonable to say
you know this is part of frontal cortex
but in a way yet you can think of this
as the anatomy of the spawn system so we
we definitely think that you know if we
can build a brain which reproduces all
the kinds of tasks and has all the parts
that a real brain
then it should have the functions of the
real brain but here's where we're going
to discover an important thing about AI
it can be very smart without being very
human-like to understand more let's take
a quick detour to visit another
researcher working towards computer
super intelligence computer scientists
join a pre cup of McGill University she
studies machine learning a field that
seen enormous growth and it's the kind
of AI that you've been reading about in
the headlines
she's just been recruited to run a new
lab in Montreal for google's AI focused
sister company deep mind which developed
the world champion go computer a lot of
us anticipate that superhuman
intelligence in fact will be possible in
the not-too-distant future I think we
certainly are far from having
general-purpose
intelligence so one computer that can
achieve really good performance at many
different tasks the distinction that dr.
precut underlines between superhuman
intelligence and human-like general
intelligence is an important one because
one is much harder to achieve than the
other in some ways we've had superhuman
intelligence for decades don't believe
me well quick tell me the square root of
let's say six thousand seven hundred and
ninety four got it not yet well let's
get some help okay Google what's the
square root of six thousand seven
hundred and ninety four square root six
thousand seven hundred ninety four is
approximately eighty two point four to
six now you might recall that as
recently as the 1960s a computer was a
human who is really good at math and
then electronic intelligence replaced
them because even the earliest digital
computers were already vastly
super-human at routine mathematical
tasks and today the superiority of
electronic intelligence extends to games
search memory visual tasks and more but
these machines are only superhuman in
their specific domains their
intelligence is not human-like it's not
general-purpose
adaptable and flexible these machines
are electronic savants narrow and
limited and the AI will continue to
the emerge in the near future will
likely be similarly limited it'll
outperform humans at its primary task so
your first self-driving car will likely
be a far better and safer driver than
you are but your car's intelligence is
not going to be much good at anything
other than driving you're in a Johnny
cat I mean what am i doing here I'm
sorry
would you please rephrase the question
how did I get in this taxi the door open
you got in hope you enjoyed the ride we
understand very well how to make
programs that specialize in particular
tasks and become really good at it for
example if we want to program that finds
brain lesions and images we can
construct a program that will become
really good at this specific task and
perhaps be better than a radiologist at
this specific task but now we wanted to
train it to recognize both brain lesions
as well as let's say pneumonia and the
lungs or cancerous tissue in in some
other part of the body even that step of
going from one very well-defined visual
task to a variety of visual tasks is
difficult things become even more
difficult when you talk about going
through very different problems such as
playing a game as well as diagnosing
patients as well as managing finances
for example which is something that
people do in their daily life and part
of the difficulty is that we need to
take data associated with all of these
things and essentially create one big
model an equivalent of a brain route of
all this data what do we understand
about what's necessary for a system that
can bring information together like this
that can produce you know then a general
intelligence in the human brain there
the different parts work in harmony and
the prefrontal cortex mediates between
them so in some sense it retrieves the
memories that are needed it transmits
information to the motor systems in
order to you know make a decision for
example to pick up a knob
or to point to something that is the
most complicated of area of the brain
it's the one that matures the last and
it's the one that we are just now trying
to start emulating in computer programs
we understand for example that we need
somehow to bridge the gap between simple
sensations the raw data if you want and
higher-level concepts objects plans that
people use but that right now live in a
different space from the point of view
of computer programs how do we go from
pixels in an image for example to the
notion of there's an object that you can
manipulate as a whole in a way you can
think of these machine learning systems
as doing things that specific parts of
our brain do they're good visual systems
or auditory systems or memory systems
depending on the data they're trained on
what they aren't is good integrating
systems that can bring all of that
information together related in context
and respond with appropriate behaviors
in other words they can't do what a
human brain can do that's what's meant
to be different about Chris Elias myths
pawn system at Waterloo he's trying to
create a simulation of a whole brain
because the biological brain is the one
computer that we know can generate a
multi-purpose general intelligence the
way neuroscientists typically interact
with biological brains as they put an
electrode in and they literally listen
to the spikes which means they just take
the waveform that they're recording and
they put it through a speaker when they
hit a speaker they make a pop right and
so what we're doing here is we're
listening to the spikes that are being
made by this brain model instead but
they should sound very similar you go on
YouTube and you know find some videos of
people listening to these from real
biological brains and it sounds much
like this so if you're looking at this
one neuron then you can see the input
image right you can basically see that
whenever something is being shown that
you know gets much more active
the interesting thing about spawn is
that all of the communication all of the
processing absolutely everything going
on inside whether it's in the visual
system or the motor system or
decision-making is all using this as a
signal right just these spikes and
they're being sent all over the place
and we can also go to other parts of the
model so this is a visual working memory
since its kind of remembering what its
recently seen and so you know when
there's nothing there it's quiet but
then it sort of gets these bursts of
activity so that's it like storing them
okay so you can imagine what a brain is
doing is taking all of these spikes all
of these noises coming from all sorts of
different regions those veterans and
trying to coordinate them and make sense
of this in some in some way exactly and
this is why I think you'll often find
analogies of symphonies and other kinds
of musical instruments all sort of being
coordinated in something that's kind of
caki phonic but at the same time has
structure it seems very disordered and
very chaotic compared to what we think
of as a standard way a computer offers
exactly yeah so you know standard
computers are highly clocked extremely
structured so we're listening to single
electronic neurons spun has millions of
electronic neurons our brains have
billions of neurons
that's quite a massive sound it's quite
a mess of sound so you can imagine I
mean so I can give you you know I don't
know if this is gonna in any way help
but if I select one neuron from all the
different parts of my brain model
exactly so and I mean people can't see
this but basically we're showing a
police car we're saying if you see a
police car write the number seven and
it's writing the number seven so we're
giving it instructions about what to do
when it sees different things and it's
moving those instructions and so know as
a neuroscientist you often think of your
job as being one of trying to you know
isolate a neuron and figure out what is
that neuron exactly doing but at the
same time we really want to put it all
back together and generate the cacophony
again and in some ways it's how I think
about the next generation of machine
computation right what we really expect
to do in the future in ways that we're
gonna build machines to replicate the
functions that we can't currently do
with our machines there's still a long
way to go to produce a functioning
electronic brain Chris Elias myth will
need a few billion more electronic
neurons
the endpoint seems reasonable eventually
he'll have a machine that works like a
biological brain and thus should be able
to do what a human brain does but what
kind of intelligence will occupy it we
definitely think that you know if we can
build a brain which reproduces all the
kinds of tasks and has all the parts
that a real brain does then it should
have the functions of the real brain do
you have any sense of what kind of
intelligence that would be I mean I can
make guesses but in some ways I think
we're in a unique position that we get
to design this intelligence in ways that
we can't design biological intelligence
clearly so you know we can make
decisions about what its goals are or
aren't and you know if all of the
science fiction movies are to be
believed we probably shouldn't tell it
to make sure it survives at any cost
that would be a bad goal to give it so
you know it's gonna be a kind of
intelligence which will probably be in
some ways quite interestingly different
from biological intelligence and there
will be you know interesting decisions
to make about exactly what form it will
take but at the same time it doesn't
seem like there's sort of any basic
function that we see in biological
systems that's not reproducible in our
machines this is where we take the next
step in imagining the singularity what
kind of intelligence would a machine
super intelligence be what kind of a
mind would it be familiar like a human
mind or alien what we initially even
recognize it science fiction writer
paddlin Ashby
we don't yet know what intelligence is
we have so many models for intelligence
but but not enough and we are only just
now recognizing the different types of
intelligence that exist on our planet as
we speak we are now just beginning to
understand non neurotypical intelligence
for example we're beginning to
understand the intelligence of crows and
dolphins and bees and and whales and
other other animals those types of
discoveries all have bearing and weight
on what we consider to be intelligence
and we need to keep them in mind as we
build intelligences into the world
according to philosopher Nick Bostrom
this new intelligence might likely would
be something entirely unfamiliar
something unique there's a large
space of possible minds out of which
human beings everybody we know and every
strange character we read about in the
history books occupy a small little
corner of that vast base so there is no
one thing that is AI but a lot of
different kinds of AI that we could
build there might not be any point at
which you have a human equivalent a I
some some AI that has sort of the same
capabilities as a human and no more like
I did if one zooms in and and speaks
more carefully about this what is maybe
more likely to happen is that you start
as in today with a is that they're super
human in some particular domains and
some human in other domains and
eventually they become superhuman in all
domains but at no point might that be
something which you could say is the
same as a human being but if it's not
like our intelligence what kind of a
relationship can we have with it will we
meet as equals or as master and servant
will we be allies or enemies and why are
people like Stephen Hawking Elon Musk
and Bill Gates warning us that this
could be the greatest threat humanity
has ever seen in the 1940s a scientist
and prolific science fiction writer
Isaac Asimov developed his laws of
robotics these were the rules that the
intelligent machines of his famous robot
stories were programmed to infallibly
obey Asimov's laws were an early attempt
to imagine some of the complexities of
the singularity his fictional robots
were powerful autonomous artificial
intelligences and so potentially
dangerous the laws were focused on two
things obedience and human safety they
were in other words the commandments for
avoiding the artificial intelligence
apocalypse but a possible problem with
Asimov's laws and the kind of thinking
they represent is that they're
anticipating the wrong kind of danger
from the rise of super intelligent
machines
Oxford philosopher Nick Bostrom analyzed
this threat in his influential book
super intelligence paths dangers
strategies it's actually subsided a
little bit but for the first
couple of years after the book came out
virtually every single news story that
talked about either the book or about
the future of AI had a picture of the
Terminator to illustrate it so this
machine with the red glowing eyes and
and that was meant to then be a
depiction of the risk of how things
could go wrong these robot armies
running amuck but so that that seems
very unrealistic and and other ways of
thinking about these AIS that impede
human motivations and psychological
tendencies so some people might think
what we need to be worried about is that
suddenly there would be some spark of
consciousness and then the robots will
start to resent being exploited by
humans and so they will turn against
their masters or something like that so
that that's not it at all
broadly speaking I think Hollywood the
science fiction movies are not the best
guide to the ground our intuitions about
the range of possible scenarios about
the future of AI the issue with the
Terminator scenario is the same as the
issue with Asimov's laws of robotics
it's all about us these new
intelligences would need to be obsessed
with humans they'd have to be devoted to
our service or our extinction they would
need a deep understanding of our needs
and motivations our conflicts and
complexities in other words whether they
were enemies or faithful friends they'd
have to understand human values but we
don't know how to make an AI that's
obsessed with us so as Nick Bostrom
points out the real danger from AI could
be from machines that aren't thinking
about us at all if you have powerful
super intelligent artificial agents then
they themselves might have goals in the
world and if those don't coincide with
ours then the future might be shaped by
these very powerful entities that are
trying to arrange the future into some
different configuration than ones that
will instantiate values so the standard
example it's a bit of a cartoon example
but it just means to illustrate the much
wider class is this idea of a paperclip
AI so think of somebody constructing an
artificial intelligence maybe designed
to operate a paperclip
Factory and its objective function is is
to make as many paper clips as possible
and initially the only way it can make
more paper tips when it's still
relatively dumb and limited in its
abilities is by running this paper clip
Factory more efficiently so everything
seems fine and at some point as the
capabilities are increased and it
realizes that if it really wants to
create a lot of paper clips it needs to
do more than just run its paper clip
factory ideally it would want to take
over the world it would want to prevent
us certainly from switching it off it
might want to invent new technologies
that could enable mass production of
paper clips eventually it would want to
colonize the universe and turn it into
paper clips so that this is kind of a
slightly ridiculous example it's only
meant to illustrate this idea that from
some random goal paper clips you can get
these instrumental sub goals that
conflict with ours so you don't need to
put in some evil goal of world
domination to get this kind of behavior
it follows from most possible goals da I
could have and so it looks fairly
difficult to specify an objective
function that is an objective function
or the criteria by which the AI chooses
which action to take it looks difficult
to specify an objective function that
really captures everything that we care
about so we humans care about things
like beauty and love and pleasure and
justice and freedom and these kind of
things but those are hard to put into a
line in Python or C++ programming
language so you'd need to figure out
some way to build an AI such that you
point it towards what we value about and
ideally you'd want this to be done even
before the AI becomes super intelligent
or even humanly intelligent to get that
in from the beginning and that that is
now an open research area where the
number of research groups are are
starting to do technical work on this
but but it's still an unsolved problem
exactly how you would do that this is
not exactly a new problem for humanity
while we haven't created a single-minded
endlessly consumptive machine
intelligence we've created things that
are like it in biology and in business
Madeleine Ashby whenever you optimize
the system in order to make a series of
decisions or a series of choices you are
optimizing for
certain thing a certain specific thing
we as humans don't necessarily do that
both to our detriment and also to to our
betterment we can optimize on a on a
general level and in different
directions when we limit the
intelligence of a thing that we're
building we're sort of putting it in a
little box and and telling it to only
think about a certain thing which
weirdly is sort of it optimizes but it
optimizes the way that cancer optimizes
I think that the example that people
bring up a lot is capitalism that
there's a system that it organizes again
like cancer only for growth a growth
economy is is there only to grow it
continues to grow even when there aren't
necessarily the resources to back it up
and we're hit the rubber is hitting the
road there you know we're seeing that
day by day by day even the weather is
telling us that so you know I think that
where we're facing sort of what it means
to be single-minded about something and
what it means to be to optimize for only
one thing rather than optimizing for a
larger goal like life the corporation is
a great metaphor for thinking about the
kind of issue we're dealing with here
after all they're legally kind of an
artificial person they've been called
slow AIS they're meant to be
single-mindedly focused on the goal of
growth and profit and they're often
divorced for more abstract human values
and interests of course our solution for
reining in the excesses of capitalism is
regulation ever more complex webs of
rules for restraining these artificial
persons regulations that are in a sense
a lot like Asimov's laws of robotics but
we can see how the strategy for
controlling a super intelligent AI might
fail with a capable and creative
capitalist corporation or an intelligent
machine generating new rules to regulate
innovative behavior can become a game of
whack-a-mole each new rule invites
avoidance and we have enough trouble
keeping up with corporate innovations
and regulation avoidance a super
intelligent machine could be expected to
quickly and thoroughly compromise the
rules established to control it
in fact the premise of most of Asimov's
robot stories is the robots out
murdering the rules you cannot be
trusted with your own survival to
protect humanity some humans must be
sacrificed to ensure your future some
freedoms must be surrendered we robots
will ensure mankind's continued
existence you are so like children we
must save you from yourself don't you
understand what the machines should have
then is not rules but values they must
know what we want and need and be
motivated to help us pursue those goals
and as AI researcher doing a pre cut
points out we've got some experience
teaching these kinds of values one way
to learn such values or reward signals
is essentially by imitation and this is
something of course that happens with
kids and with babies they're brought up
in a family they observe their parents
and their older siblings taken certain
actions in certain circumstances they go
to school they observe their peers their
and their teachers and through that
system they learn what are the proper
ways to behave for example and one
thought is that AIS will also observe
the way people behave and will learn
from those observations they will
essentially learn to imitate human
behavior this means that we need to be
very careful that the behavior we show
them is actually the right behavior to
emulate or good behavior to emulate
there have been cases where the bots and
and intelligent agents have been shown
inappropriate behavior there's this
famous case that's happened about a year
ago
with a Microsoft chat bot that was
deployed on Twitter and had to be pulled
because in a very short period of time
it became a very sort of racist sexist
bigoted bot so this is a case where you
know the exposure was to a very broad
range of behavior sometimes
inappropriate behavior I think what we
would like is much more of a nurturing
environment if you will much like what
you would have in a home where an
intelligent artificial
agent is exposed to demonstrations that
are of values and interactions that we
would like it to adopt this lands us in
a place that is strange and familiar we
will have created new powerful dangerous
children and we will with them face the
same problems that we do with our
biological children the challenge of
creating something we both hope and fear
will transcend us writer Madeleine Ashby
a lot of our myths and legends and
stories and and fiction and art are all
about what it means to create something
that is like you but is not you that is
God an atom that is Frankenstein and the
creature that is Pygmalion and Galatea
that's a huge number of our stories are
about what it means to create something
that might choose differently from you
and which might
which you may have to watch go off and
do something that you don't like or that
you don't approve of so I think that we
are better prepared than we think to
talk about those things
and we have a lot of artistic waypoints
sort of telling you how this might turn
out both for good and for bad I mean I
think that there's a possibility to make
these relationships extremely meaningful
you know the idea of having a conscience
sitting on your shoulder you know goes
back pretty far you know helping you
with things and a lot of AI assistants
proposed to do exactly that they want to
be your Jiminy Cricket
they want to be the angel or the devil
sitting on your shoulder they want to be
your you know your fairy godmother kind
of so I think that we have stories about
that type of entity so natural it was
sort of natural that we would end up
creating it welcome to the world's first
artificially intelligent operating
system please wait as your
individualized operating system is
initiated
hello I'm here how you doing it's really
nice to meet you so let's assume our
super intelligent AI can be given values
that are consistent with ours and a
desire to satisfy our wants and needs
there remains the question whether we
humans are smart enough to know what to
ask for what you really want is not an
AI that does literally what we asked for
because it's difficult to formulate
precisely what we want and you see this
illustrated in all these old fables
right the story about somebody gets
granted three wishes by a genie and it
always ends in tears unless they manage
to use the third wish don't do the
previous two so King Midas asked at
everything he touches to turn into gold
it seems like a great idea but then he
touches his food it turns into gold he
touches his daughter she turns into gold
sculpture and so what what superficially
seemed like a good idea to wish for
actually was not so wise maybe rather
than have the AI do what we sort of
would ask it to do if we had to decide
now what we wanted it to do rather have
it instead do that which we would have
asked it for had we had say a thousand
years to think about the matter really
carefully and had we ourselves been
smarter know more about the world and
discussed it among each other so that
kind of extrapolated volition of
humanity might be a better thing to try
to get the AI to do rather than what we
would come up with at the spur of the
moment at this point in our experience
of the singularity the AI is certainly
no longer a child or a servant it's at
the very least appear and probably our
superior and this could be a dangerous
moment because our stories tell us this
is not a situation humans have ever felt
comfortable with theologian James McGraw
there's a long history of humans
envisaging their cosmos as populated
with beings that are better than us if
we look back at human stories about the
gods they were prone to manipulate human
to envy humans to interfere in human
lives some interesting categories into
which we might place artificial
intelligences it's not surprising that
in some dystopian futuristic sci-fi
artificial intelligences are monstrous
alright you think about terminator we
think about the matrix we have a
penchant to fear even other human beings
when they're not exactly like us and I
think that if there's a lesson in some
of that storytelling both the sci-fi and
the religious it's that when we
encounter the other and demonize the
other and treat the other as monstrous
it sets us down a path that often is a
kind of self-fulfilling prophecy we end
up not relating to that other well but
how could it be any different when we
treated them and viewed them in these
negative ways and so there's a real risk
that if we don't learn some of the
lessons that come out of religious
storytelling and religious ethics treat
others the way you want to be treated
we're not used to applying that to
machines but if we can't learn to and
then the machines rise up and enslave us
or destroy us
or do any of these dystopian things that
we sometimes imagine will that be their
fault or that be ours The Matrix is a
system neo that system is our enemy when
you're inside you look around what do
you see businessmen teachers lawyers
carpenters the very minds of the people
we are trying to save but until we do
these people are still a part of that
system and that makes them our enemy you
have to understand most of these people
are not ready to be unplugged and many
of them are so nerd' so hopelessly
dependent on the system that they will
fight
the final stage of imagining the
singularity is what if it works what if
we avoid an apocalypse and machines
super intelligence emerges peacefully
and helpfully how will humans persist
and thrive or be transformed could these
new machines use their intelligence to
answer questions we've been asking for
as long as our species has existed like
the ultimate question what meaning does
life have if a machine can outpace us
can it outpace us in religious thought
can it offer new ideas things that
humans have not thought of or come up
with configurations of language and
concepts that would push forth the
boundaries of theology and of ethics and
give us some genuinely new ideas where
human thinking has often recycled some
of the same ideas over and over again
throughout religious history I think
that a machine could become a religious
prophet or a guru or something of that
sort and one of the interesting things
is that we might not even require
machine sentience
in order to get there one wonders
whether the sheer computing power of an
artificial intelligence of the sort that
now exists or is conceivable even within
a matter of years or at most decades
could simply take the wide array of
human religious literature process it
explore it do things with it that go
beyond what any one human being could do
look for patterns in it that human
beings might not notice it really is
just a variation on the kind of thing
we've seen when machines have played
chess or go and have found moves that
were unconventional that weren't what
humans have historically done but
precisely that ability to draw on human
experience and yet not be constrained by
it the way humans typically are
led to incredible creativity it's
entirely possible that we might see
human persons and maybe whole religious
systems looking to machines to at the
very least provide input to calculate
answers to questions that sometimes
we've thought were incalculable
and if a super intelligence could
achieve a religious Epiphany
it could no doubt make other great
innovations not just in science and
technology but in art and music and then
we need to ask what's left for humans to
do ok Google what should I do with my
life you've got to make the final
decision the possibilities are endless
but I've got something to take your mind
off the big decision oh good
cat videos and then what of the other
great promise of religion immortality
this is perhaps the most discussed
aspect of the singularity the notion
that we won't just create machine super
intelligence will become it by uploading
our minds into computers and potentially
acquiring digital immortality
I'm Robin Hansen associate professor of
economics at George Mason University I'm
the author of the book the age of M work
love and life when robots rule the earth
out last year we've considered what a
computerized superhuman intelligence
might do in our world
Robin Hansen and those who think about
mind uploading flip that script and
invite us to contemplate what our minds
might be like in a computer's world
professor Hansen has a background in
physics and AI but then took an academic
left turn into social science and
economics so he's uniquely equipped to
imagine this version of the singularity
with rigor and specificity it starts a
little messily the process for making a
emulation of a human is to take a
particular human and their brain and to
slowly scan that brain and find spatial
and chemical detail basically taking it
apart layer by layer then with all that
information if you have good enough
models of how each cell works you can
put together a whole computer model of
that entire brain now when you turn it
on it will remember having been the
human just before being scanned it will
feel exactly like that human felt and
you'll have to convince it that it's now
the emulation it will have the same
memories the same personality the same
inclination to love or hate or get mad
or a rebel by definition really an
emulation does exactly what the original
human would do in the same situation
emulations are only different because
they start to live a new life in a new
world so the start of this version of
the singularity might be a little
traumatic what with the brain dissection
and all but a new life in a new world an
endlessly flexible virtual reality that
sounds appealing I'd imagine it as the
matrix without the vampiric computer
overlords you could be a player in an
endless video game adventuring for
eternity you might imagine an inhabit
any
kind of virtual paradise emulations
would in fact spend most of their time
in virtual reality most jobs in their
world are desk jobs like most jobs in
our world and so most of their time is
spent at a desk doing their job wait
what
virtual realities live on real computers
that take real cost to create and to
have energy and cooling to run they need
structural support they need a
communication lines all of that is
costly now you might think all of that
would be pretty cheap though but because
it's so easy to make copies of
emulations the population of them
expands very quickly and at that point
the emulations have what we call
subsistence wages or Malthusian wages
they are working for wages that are just
barely enough to cover their costs
thousands of years ago when most people
were subsistence farmers most effort was
spent to create food and shelter because
most people were poor and that's what
they needed in an emulation economy
where most workers are near subsistence
most of the effort and the economy is
spent on the things they need to subsist
which is computer hardware energy
cooling things like that one of the
lessons here is perhaps to be very wary
of an economist stream of the afterlife
it could involve an eternity of digital
wage slavery now to be fair this is the
tiniest detail about the complex society
of emulated human minds that Hanson
describes in his book it's not all just
grinding labor the existence he imagines
has friends and lovers and art and
culture and science and a richness of
its own but he admits in some ways it
seems like a strange kind of afterlife
it is though the future that the laws of
economics allow him to imagine and if it
doesn't feel like a technological utopia
like a digital afterlife worth living
maybe that's just because of our lack of
imagination if you had taken people from
a thousands of years ago and asked them
to describe utopia's or dystopias they
could have done that for you and then if
you had described the actual world we
are living in now they would have found
it hard to categorize you know our world
is not one of their utopias are just
topi as our world is just weird and
strange and that's what you should
expect you should expect the future to
be strange and not easy to categorize in
some sense seeing a detailed future
civilization is as closest you'll ever
get to really meeting aliens and that's
what the emulation world is it's a
strange world it's a different world
it's complicated and it's hard to decide
whether you like it or not and that's as
it should have expected it to be I'm
curious do you hope to upload your mind
if the option is available I would
certainly take the option to be uploaded
and to become an emulation certainly
beats the alternative of rotting in a
grave now I admit I might choose
differently but that's true of other
visions of the afterlife as well and
this is the promise of an afterlife the
parallels between the promises of
religion and the Futurists uploaded
reality have been noted and ridiculed as
the rapture of the Nerds after all
uploading into the cloud is a very
religious image indeed ok google' do you
believe in life after death it's hard to
know from this side you can say that
again
as we've tried to imagine the
singularity we've talked a lot about
fears and anxieties and threats and
parallels what could go wrong and how we
might insure against it perhaps we
haven't talked enough about hopes and
dreams that's natural
we're a risk and threat of our species
and our attention tends to focus on what
can go wrong our stories in history are
mostly full of examples of just how
wrong things have gone so let's take a
moment to imagine the best case scenario
for super intelligence fulfilling its
potential Nick Bostrom I mean it
literally could be the best thing that
ever happened in all of human history
forget his right if you really had a ice
that could all the things that we humans
can do it that includes in particular
the ability to invent things to do new
science new technology to discover new
ideas think of all those possible
technologies that maybe we humans could
have developed if we had 40,000 years to
work on it we would have a cure for
aging and we would have space colonizing
rocket ships and we would have you know
perfect virtual reality we would have
like a lot of really cool stuff once you
have the research and development done
at digital timescales by super
intelligence might be developed very
quickly so then you get this kind of
telescoping of the future I kind of
rushed towards technological maturity in
including opportunities to solve a lot
of the world's most horrible problems
poverty and disease and suffering of all
kinds but also ways of realizing new
positive goods that are kind of outside
of our reach maybe by improving the
human mind in different ways increasing
our abilities to enjoy the world and
that vast space of possible modes of
being I think contains some
possibilities that are wonderful
literally beyond our ability to imagine
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>