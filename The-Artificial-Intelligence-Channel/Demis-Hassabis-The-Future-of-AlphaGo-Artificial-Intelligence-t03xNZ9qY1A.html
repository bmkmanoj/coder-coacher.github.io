<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Demis Hassabis: The Future of AlphaGo &amp; Artificial Intelligence | Coder Coacher - Coaching Coders</title><meta content="Demis Hassabis: The Future of AlphaGo &amp; Artificial Intelligence - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Demis Hassabis: The Future of AlphaGo &amp; Artificial Intelligence</b></h2><h5 class="post__date">2017-09-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/t03xNZ9qY1A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone ladies and
gentlemen and distinguished guests a
warm welcome to the AI forum and the
future of NGO forum and in will Jen I
hope today is going to be very
interesting and informative and I hope
you're going to enjoy the interesting
talks that we've lined up today and I
hope today will actually stimulate a lot
of collaboration between Western
scientists and Chinese AI scientists to
progress at the future of AI together so
I'm going to begin today by talking a
little bit about intuition and
creativity and how we might give
machines these capabilities I'm also
going to give you a bit of an overview
of what my company deep mind is about so
deep mind was founded in 2010 in London
we have around 500 people now including
over 250 research scientists we joined
Google in 2014 about three years ago to
turbocharge our mission of solving
intelligence and the way we can think
about deep mind is as a kind of an
Apollo program effort for AI so trying
to bring together the world's best
scientists in all sorts of different
disciplines from machine learning to
neuroscience together in one place with
all the resources they need in terms of
compute power and data and try and make
us faster progress towards solving AI as
possible another thing that we do at
deep mind is we've designed a kind of
new organizational way to do science
science and scientific research and you
can think of it as a kind of hybrid
combination of the best from academic
labs and fusing that with the best from
startup companies and creating a unique
culture that has the best aspects of
both long-term blue sky thinking from
academia and the energy and focus that
you get from the best startups
so what is our mission at deep mind well
the way we describe it is a kind of
two-step process so firstly we would
like to fundamentally understand what
intelligence is and we create it
artificially
so we want to solve what intelligence is
and then once we've done that we believe
you could use that kind of technology to
solve almost everything else so we think
this is going to be one of the most
important and powerful technologies that
humanity will ever invent how do we
propose to do that more practically well
at deep mind we talk about trying to
build general-purpose learning systems
let me just unpack a little bit about
what I mean by that so firstly and most
importantly is the idea of learning so
all the algorithms that we work on a
deep mind have learning at their core
they all learn automatically how to add
to master tasks they learn from raw
experience and from raw data they're not
pre-programmed with the solutions in any
way the second thing is this notion of
generality so this is the idea that a
single system or a single set of
algorithms can operate across a wide
range of tasks straight out of the box
perhaps even working on tasks that it's
never seen before now of course we have
an example of such a system it's the
human mind we do this all the time
humans do this all the time use their
learning from one task and translate
that learning to a new task even a new
task that they've never done before and
they're able to do that task reasonably
well straightaway and that's because
they usefully use their prior knowledge
they've built up on previous tasks and
this is something that machines are not
very good at at the moment and we would
like to make them better so some of the
key techniques that we use in order to
build our general-purpose learning
systems are deep learning which are
neural networks hierarchical neural
networks that many of you are familiar
with and reinforcement learning which is
allows the system to learn for itself to
try and maximize the rewards it's going
to get in any particular task
so we
this kind of general-purpose learning
system artificial general intelligence
and we call it that to distinguish it
from most of what people call artificial
intelligence today which is usually
still of the pre-programmed variety so
we're very interested in this idea of
general learning now one of the best
examples still are the biggest most
famous examples of narrow AI is IBM's
deep blue system which famously beat
Garry Kasparov at chess in the late 90s
now this was a very impressive feat
obviously is an incredible technical
achievement but deep blue was a
pre-programmed system so a top you know
a group of top programmers sat down with
some chess grandmasters and they figured
out what the knowledge the chess
grandmasters had in their heads and then
they codified those that knowledge into
a set of rules and heuristics which the
deep blue then used by using brute force
search to figure out what movie should
make but if you think about it although
this is impressive technical achievement
where does the intelligence of the
system reside and I would argue it's not
in the program or the machine it's
actually in the mind of the programmers
it was the programmers that solved the
problem of chess and solved how the
machine should play chess and then
codified those rules the machine itself
just thumley executed those rules it
didn't adapt or learn or find out new
knowledge for itself so by contrast we
want to work on systems that learn for
themselves and we think of intelligence
within the framework of what's called
reinforcement learning and I'll just
briefly explain what reinforcement
learning is in this diagram for those of
you don't know
so reinforcement learning if we start
off by thinking about the AI system here
on the Left which we call an agent and
the agent finds itself in some kind of
environment and is trying to achieve a
goal now the environment could be the
real world in which case the agent will
be a kind of robot or the environment
could be a virtual environment like a
game in which case the agent would be a
sort of avatar
now it's trying to achieve this goal but
it only interacts with the environment
in two ways first of all the agent gets
observations through its sensors about
the environment so in most of our work a
deep mind we use vision and we use
vision as the main sense but you could
also use sounds and touch if you wanted
and the first job of the agent system is
to build up a model of the environment
out there based on these observations
and this is difficult because in a real
world setting you never have a complete
set of observations the observations are
always noisy and they're incomplete so
you have to do your best to estimate and
approximate what the environment is out
there and once you've built up of this
model of the environment you can then
use it for a second thing which is you
can run a plans in your head in the
agent's mind and decide which is the
right action to take what's the best
action to take in the current moment to
get you towards incrementally towards
your goal and once you've decided what
the best action is you output that
action you execute that action and then
that may or may not make a change in the
environment and then that drives a new
observation and this sort of happens in
a real-time circle so that's the essence
of reinforcement learning and it seems
quite simple on this diagram but
actually there's a huge amount of
complexity and difficult technical
challenges that have to be solved to get
this system working really well but we
know that if we can solve all of those
challenges then this is enough for
general intelligence and we know that
because this is the way actually humans
and animals learn from their experiences
and in fact in humans is the dopamine
system in the brain that implements a
form of reinforcement learning so our
first big success was building agents to
play Atari games if some of you remember
that from the 1980s classic 8-bit Atari
games and I'll just show you a video in
a second of
the agent learning for itself how to
play an Atari game and mastering an
Atari game but before I run that video I
just want to make clear what it is
you're going to see the only input the
agent gets from the environment is the
raw pixels on the screen so that's
around 30,000 numbers per frame per 50th
of a second and all it's told is the
goal is to maximize the score get the
higher score possible everything else
has learned from scratch from first
principles so it doesn't know what it's
controlling it doesn't know what gets it
points it has to learn all of those
things by observation by experiencing
the environment that it's in and finally
we insist that one system can play all
the hundreds of different Atari games
the same system so this is the idea
again of generality so we built this
system called dqn and we invented this
technique called deep reinforcement
learning which combines deep learning
and reinforcement learning together and
we used it on this game breakout which
I'm going to show you here so breakout
you control the bat on the ball at the
bottom of the screen and you're trying
to break through this rainbow coloured
brick wall and you can see here after
100 games or practice games the agents
is still not very good at the game it
missing the ball most of the time but
after 300 games you can see now the
agent is a lot better and actually gets
the ball back most of the time even when
the balls coming back at very fast
angles from the wall so we thought that
was pretty good but what would happen if
we just let the machine play another 200
games and what happened was this
unexpected thing as it found the optimal
strategy was to dig a tunnel on the left
and send the ball behind the wall if you
can see that with like superhuman
accuracy and of course that's the best
strategy to solve this game but the
interesting thing is that the
programmers and the researchers who
created that system they're brilliant
researchers but they're not so good at
playing Atari games and they didn't know
that strategy themselves so they learned
something from their own system which is
quite funny so that was about two or
three years ago and then now of course
we're reason we're all here is our new
system and later
system alphago we've been working on
alphago now for about three years and
with a sort of large team for about the
last two years and alphago of course is
it's been designed to play go but we've
also tried to design it to be
general-purpose so that eventually we'll
be able to do a lot of other things too
and I'll come back to that at the end
but first of all why is goes such a
great challenge for computers and why
did we decide to take this challenge on
well the complexity of go you know which
we talked about yesterday is so immense
it actually makes brute force search
intractable there's no way even if you
had all the computers on the planet and
you ran them for a million years you
still would not have enough compute
power to calculate all the possible
variations in go and the search base in
fact is so large it's actually there are
more possible board positions in go than
there are atoms in the universe so
that's one problem the search space is
really huge but a second challenge
probably even bigger challenge is that
it was thought to be impossible and in
fact it's still thought to be impossible
to hand write an evaluation function to
tell the system who is winning in a
particular position so an evaluation
function is a critical part of these
computer game playing systems you really
need to be able to understand where the
black or white is winning in a
particular position to be able to
determine what is the right move to play
and because go is so complex and so
intuitive actually it's very difficult
for programmers to figure out what are
the right rules and heuristics to build
into an evaluation function it's much
much tougher than it is to do for chess
because of the nature of the game of Go
so go is a much more intuitive game than
say chess which is more about
calculation and in fact if you ask a
great go player you know why did they
make a particular move they'll often
tell you that it felt right
you know they had this feeling that it
was the right type of move in this
position whereas if you ask a chess
player why did they make a particular
move they'll usually be able to
tell you a very explicit plan you know I
was planning to do a because I thought
my opponent would do B and then I was
going to do C now that plan may turn out
not to be good in the end but they
usually have an explicit plan in mind so
it's very different as far as I
understand it from playing chess and go
myself the ways that the players
approach playing these games and this
evaluation function you know why is it
so difficult to write for go well I
think there are lots of reasons why go
is harder than chess in this aspect one
of the reasons is that there's no idea
of concept of materiality and go all the
pieces are worth the same right they're
all stones
whereas in chess you know the queen is
nine points the rook is five points the
knight is three points so you could as a
first approximation you can just add up
all the points on both sides of the
board and that will tell you as a first
approximation who's winning the game and
go there's no way of doing that secondly
go is what I would call a constructive
game whereas chess is a sort of
destructive game so in chess all the
pieces start on the board and then as
the game goes along you take off pieces
so the game becomes simpler as the game
moves on whereas in go the gut the board
starts empty and you fill the board up
so when you're trying to make an
evaluation in a particular position in
the middle of a game of chess let's say
you have all the information already in
front of you the current board position
contains all the information that you
need whereas in go in the middle of the
game the game's only half constructed so
in fact if you want to understand who's
winning and losing you have to project
forwards into the future you have to
predict the future and make some
prediction about what's going to happen
in the future it's not enough to just
assess what is currently on the board
and obviously predicting the future is
much harder another issue in go is that
a very small local change in the
position one stone in a different place
one Square different place can totally
change the entire evaluation of the
position
so it's very small changes can make
large changes to the evaluation and you
can see that the idea of go being a much
more intuitive game because actually
first century is now in the history of
go there's been this idea of a divine
move or a God move and move so profound
and so beautiful it must be as if it's
inspired divinely inspired there's no
concept of this in chess this is only in
go so how do we get round these two
immense difficulties the search space
and the evaluation function well we use
two neural networks called a policy
network to help narrow the distribution
of moves that we have to consider and
the value network which learns for
itself how to evaluate particular
positions I won't go into the technical
details of this I'll leave it to my
colleague david silva who will be
talking next to go through the technical
details of how alphago works and why it
works so well we published all these
details and a front cover article in the
international journal Nature last year
and in fact we're pleased to see that
many other companies including some
Chinese companies took these this these
technical details and created their own
versions of alphago and in fact all the
experts in AI and Ingo proclaimed that
it was more than a decade before its
time and for those of you who work in
technology or science you will know that
things never arrived a decade before you
expect them it's usually a decade after
you're hoping that they will appear so
this was very unusual in the history of
AI research something to breakthrough to
come so quickly like this on a really
tough challenge like playing go of
course we won the match but actually the
most important thing was the ideas that
came out of the match and the beautiful
moves that were played so for alphago my
favorite is move 37 from game 2 which I
think really astounded the world and
announced to everyone that alphago
really could come up with creative ideas
so here's the position for
game-2 and this is the move that alphago
played is black on move 37 and it's a
shoulder hit but it's a shoulder hit on
the fifth line and this is kind of
unthinkable in this position I've been
told from professionals and the reason
is sort of just the intuitive reason is
is there are two important lines in go
the third line where if you place a
stone on the third line what you're
really saying to your opponent is I want
to take territory to the side of the
board instead of that if you play on the
fourth line then what you're saying to
opponent is I want to take influence and
power into the center of the board
and the idea is that you hope that that
influence will later on translate into
territory elsewhere on the board that
will compensate for the territory you're
giving away locally in this area so for
thousands of years the the received
wisdom has been that an exchange on the
third and fourth line is about equal for
the two players the turret the territory
you get on the third line is about equal
to the influence that you get on the
fourth line so if that's true then
playing on the fifth line would be very
unusual because playing on the fifth
line to get influence into the center
gives away territory from the fourth
line you're giving away a lot more
territory but it seems as though one of
the things alphago and prefers in its
style is it really likes influence and
it really values influence into the
center of the board
so perhaps for thousands of years we as
human players have been slightly under
estimating the value of this influence
in the center now the cool thing about
go is as we all know go is more than
just a game it's an art form but what I
like about it is one of the many things
I like about it is that its objective
art because unlike most art where it's
subjective and you decide aesthetically
whether you like it or not
though has a objective purpose which is
to win the game so you can value and an
objectively value of whether a creative
move is good or not whether as to how it
affected the ultimate outcome of the
game
and in fact we know this movers was very
creative and beautiful because
ultimately it did turn the tide of this
game around 50 moves later at Stone on
move 37 affected the fighting that
happened in the bottom left hand corner
here and these two stones in the bottom
left hand corner black stones ended up
running out into the center of the board
and connecting up around 50 moves later
with the move 37 stone of course this
inspired Lisa doll to even greater
heights too and he came up with his own
divine move in game 4 and mu 78 the way
to move that confused alphago and won
him the game it's another very beautiful
move from the incredible creative genius
of Lisa doll so the impact of the
alphago matching and soul was huge he
had 280 million viewers of the match
online and 35,000 press articles and the
thing I'm most pleased about is it
really popularized go in the West so the
online board sales of go boards in the
West was up by 10 times in the couple of
months following the alphago match so
hopefully many more Westerners now are
learning to play this beautiful and
elegant game so what was even more
inspiring was the reaction from the
players
so Lisa doll told us that he found new
inspiration from playing against alphago
it was the greatest experience of his
life and he said I think this will bring
a new paradigm to go I feel like I found
the reason to play go which is really an
amazing thing to hear and still sends
shivers down my spine when I hear his
voice on that other people commented on
this too and I will talk about that in a
second
so let's just go back to the idea of
intuition and creativity so what is
intuition
well one operational definition of
intuition is that it's implicit
knowledge that's acquired through
experience
you can't consciously access it or
express it to someone else so it's
knowledge you have but you can't really
access it consciously so you might ask
if it's this kind of unconscious
information how do we know it's even
there well you can test it behaviorally
right so you can test the existence and
quality of that knowledge behaviorally
so in go this is very easy you can give
someone a go position and ask them to
tell you what is the move they would
play in this position and then evaluate
that move and then you can tell from
that how good their intuition is on the
game of Go so we think we've mimicked
this human behavior at least in the
domain of go with alphago so what about
creativity well again one operational
definition of creativity and I don't I'm
not claiming this is all of creativity
I'm just saying this is one pragmatic
definition of it would be the ability to
synthesize new knowledge to produce
sorry synthesize knowledge you already
have to produce a novel or original idea
so your synthesized knowledge you've
already collected through experience and
you send for you app you output it a new
idea or a new piece of knowledge and I
think alphago clearly demonstrated these
capabilities so we continued without
forego over the last year and there are
many reasons why we did this there are
many other scientific questions we
wanted to answer but one thing we wanted
to do was to try and reach perfection
and to see if we could fix the knowledge
gaps in alphago that Lisa doll
demonstrated it still had in the match
in Seoul and see if we could build an
even better system that was even more
general and had fewer gaps in its
knowledge we called this new version
alphago master master version and we
tested it for the first time online on
the ghost servers in January of this
year and alphago went on a 60 match
winning streak won all its games and
also created some new beautiful ideas on
the way which I know many professional
go players have been
studying these 60 games and actually
using some of the ideas that alphago
created and here's two of them here the
idea of playing in the three three point
into a into a bear corner like this and
the idea of calling on the second line
both of these things I think would have
been pretty unthinkable before alphago
did them in these games and successfully
won these games the Coogee himself said
you know after he saw these alphago
games humanity has played go for
thousands of years and as yet AI has
shown us we have not yet even scratched
the surface and I particularly like this
next statement the union of human and
computer players were ushered in a new
era together man and AI can find the
truth of go I think that's really an
amazing journey that we're on and
obviously that's partly why we're here
this week Anna fat iris I had the honor
of meeting Gosai against daughter last
night at the the garlic dinner and as a
real honor and pleasure for me because
I've read a lot about ghosts I again
obviously an incredible player who
revolutionized go in the 30s and 40s and
some professional players have told me
that maybe alphago will advent be the
advent of a new revolution a new era in
go playing like ghosts I ended in the
1930s and 40s and what is interesting to
me is that chess programs I would say
the top chess programs are better
tactically than the best human players
but there is really the tactics that
they're better at they're better at
calculation whereas I think
interestingly alphago may come up with
more interesting strategic ideas and I
think what's cool about that is that we
as human players can look at those
strategies and incorporate some of those
ideas into our own play and actually use
that I hope as inspiration to come up
with even better strategies themselves I
do
to reviewed a book by Carrie Kasparov
who I know well and he was writing a
book about his experience of playing
against the deep-blue in the 90s and he
had a great quote in there that I was
pleased to see which he said that deep
blue was the end alphago is a beginning
I really believe that is true because
out of the way alphago is built it's
built to be this general-purpose system
that can do many things and hopefully
we'll end up doing many things whereas
deep blue was built specifically to play
chess and only chess so I think in the
future that's what we're going to see
more and more the power of the union of
humans and machines working
collaboratively together with different
strengths and weaknesses and I think
together you know human ingenuity
augmented by AI will unlock our true
potential of what we can truly do so I
see AI and and and programs like alphago
as tools they're a little bit like you
know a Hubble telescope or a microscope
so we use tools all the time to advance
our civilization physical tools and we
use things like telescopes to explore
our universe around us and try to
understand the world around us better
and that's how I see AI being as a tool
for us as humans to use to explore the
scientific world around us and to make
faster breakthroughs in areas of science
and medicine and that's what we really
wanted to do with alphago is we wanted
to try and push it further and see how
far off optimal we were you know what
would perfect play be and you know it
turns out that 3,000 years of
professional players not sufficient yet
to find optimal play and I think alphago
has helped us explore some of these
mysteries and you know I think there are
many other domains in science and
technology and engineering they're also
suffer from this combinatorial explosion
of possibilities like the game of Go has
so many possibilities that you think you
know it's impossible to explore all of
them so I think hei could be this
ultimate tool for
to investigate and explore the universe
in some areas of science that I'm
thinking about and that we're going to
be working on areas like material design
designing new types of materials with
the right properties or perhaps drug
discovery discovering and designing new
types of drug structures that target
particular diseases these are both kind
of big search processes that have lots
of combinations and we think their
processes like alphago might be able to
help and we also want to apply this to
the real world we love games as a
training ground for our algorithms we
think it's the most efficient way to
train our algorithms but ultimately what
we're doing this for is not to play
games but to actually apply it to real
world so we're looking at areas of
healthcare smartphone assistance or or
education and we already had our first
success applying alphago techniques to
optimizing the data centers at Google
and the energy they use and by using
these AI techniques we managed to save
15% of the power that the data centers
used and the energy they use by saving
40% of the cooling systems the energy
the cooling systems used so here's a
graph of what happens when we switched
on the power and and the amount of
saving that happened and then when we
switched on and off the AI system and so
now we're thinking and my colleague
Mustafa Suleiman will talk more about
this later this afternoon of applying
this to a grid scale to an entire energy
grid I'm just going to finish by talking
about going back to the initial mission
of the mind so we think of a GI as maybe
a kind of meta solution so you know if
we think today what are some of the
biggest challenges we face today
well it's information overload there's
just so much information and data and
the systems that we're trying to
understand are so complex it's very
difficult for even the top human experts
to understand these systems and master
these systems unaided you think of
things like climate change the economy
or diseases things that
you know we desperately need solutions
to but are very very difficult and
complex systems so we think solving AI
in this general way is like a meta
solution to all these other problems if
we solve AI then we can use it to help
us solve these other problems and for me
personally my dream is to make AI
scientists or a I assisted science
possible and of course one word of
caution here as with all new powerful
technologies and artificial intelligence
is no different we must make sure that
it's used ethically and responsibly and
for the benefit of everyone and finally
as a neuroscientist I'm very interested
in our own minds and how our own minds
work as well as building artificial
systems and I think that this journey to
build general intelligence might end up
being one of the best ways to understand
our own mysteries of our own minds
things like consciousness dreaming and
creativity and us to truly understand
what these capabilities are thanks for
listening</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>