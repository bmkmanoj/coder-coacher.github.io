<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Rise of Artificial Intelligence: Status, Thresholds, Attack Surfaces | Coder Coacher - Coaching Coders</title><meta content="The Rise of Artificial Intelligence: Status, Thresholds, Attack Surfaces - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Rise of Artificial Intelligence: Status, Thresholds, Attack Surfaces</b></h2><h5 class="post__date">2017-10-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YHy3ZZG4b0s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome ham pity he is a computer
science professor at Arizona State he's
also the president of the triple AI the
Association for the Advancement of AI
and as he's setting up here I'll mention
that he is also close to where he took
his PhD at the University of Maryland
College Park so welcome back to the DC
area thank you okay so I am actually not
going to talk just about my research
although I will show a couple of videos
on human robot timing that sort of you
know the direction that I go through I
you know based on what fred was asking I
have decided that we will talk about
sort of represent the field for you guys
and you know talk about how we got there
I think you know Rob did a great job for
example of pointing out what's going on
in deep learning and then I want to sort
of talk about some of the intellectual
fallouts of those in the currently in
the field and talk a little about the
thresholds that you know that we still
have to class before we need to worry
about human level intelligence and then
since after all this is a intelligence
community studies board thing I'm going
to talk about attack surfaces and how
people can actually do bad things with
good technology you know which is the
life that we're on will need so i
basically i'm going to start by talking
at slightly high level about the fact
that there is no such thing as a single
intelligence we all really realized that
intelligence is multifaceted one very
useful thing that I find in explaining
you know how AI is where it is right now
is to realize for example that there is
perceptual and manipulation intelligence
the ability to see the world the ability
to move around you know manipulate the
objects the emotional intelligence the
social intelligence and of course the
cognitive intelligence the interesting
thing is you see this little kid here if
you think about human babies and how
they start showing about what we see
glimmers of intelligence of various
kinds you see that they go
first they see the world then they sort
of start putting everything into their
mouth you know amazing beautiful
manipulation that is needed to put
things into your mouth then please show
some emotional intelligence show social
intelligence when they go to a great
school and then finally only when you
know later on use they start showing of
glimmers of you know the cognitive
intelligence the SAT tests and how to do
well at so try those and keep that in
mind and interestingly is progress
towards intelligence has been somewhat
different actually the first time you
heard about AI in big time was in around
80s when there was this whole export
systems where we were trying to replace
exports no legal scholars or doctors and
so on in 90s we had reasoning systems
Kasparov for example got dethroned chess
is no longer the thing that we
considered our domain and it's in only
no 2000s in fact late 2000s that we
started making really good progress on
perceptual tasks so for example now
speech recognition has become
commonplace image recognition has
improved significantly as an Arab as
pointed out and of course there are lots
of interesting issues that still need to
be done in combining these progresses
but at this point I want you to notice
that the arrow for the machines the
human the AI has done the opposite way
we actually figured out at least to some
extent how to do some breakthroughs in
cognitive and reasoning tasks and only
recently have gone to perceptual tasks
and I think it's a useful thing to keep
in mind because it turns out that at
least based on you know if you are
somewhat on the outside of the
peripheries of the field it explains a
whole lot of what's going on about what
people are talking about AI so why did I
develop in this reverse way it turns out
that it's easier to program computers
and aspects of intelligence for which we
have conscious theories and how many of
you heard of polanyi's paradox
Palani michael polanyi is this polymath
who basically pointed out something that
we all know that we actually know more
tacitly then we can actually verbalize
it turned out that that's not all the
thing that we know but there is enough
that we only tacitly
and the stuff that we know tacitly we
couldn't make progress on it in AI by
just telling the computers to do because
we don't know ourselves how we see the
world how we manipulate objects and so
on
in fact the theories of vision the
theories of robot grasping have fallen
by the wayside and in fact now they have
become just learning-based but in the
beginning of course since we do have
theories of you know certain other kinds
of higher-level reasoning tasks and
that's the ones that we program the
computers for and then we are not
particularly conscious of the perceptual
and manipulative intelligence so we have
to depend on making the less machines
learn exactly the way we wind up
learning so you know I don't know
whether you notice it or not kids you
know human babies those of you who had
human babies right they basically hang
around doing nothing for a long long
long time and being just cute right and
what are they doing in essence they are
sucking up the examples in the world
they sort of figuring out without you
telling them how to talk how to you know
do grasping and so on so that's the kind
of thing that you know the basically we
had to do it now you know we actually
started having to do it with this
learning now this also actually explains
why a I caught public imagination now so
earlier on this morning and the sword
and I were having breakfast and now
we've been you know in AI for quite a
long time for the longest time and we
say we working eyes you know they be a
sort of sigh of disappointment you know
this is the technology that didn't seem
to go anywhere
now it's please don't hurt us you know
apparently apparently I can actually
take all the world so why did that you
know we always had intellectual
satisfaction in in doing work in a high
I always felt sorry for my colleagues in
the department that they are not working
in the eye for the last 30 years but why
is it that everybody is interested in
the eye well it's because early I was
blind and deaf Socrates so if you want
to think of a kid who can do chess but
can't actually see the world or can't
manipulate things that's the kind of
thing that you had in AI know and so
perceptual abilities allow the eye to
come to all the people and so in now you
know it's now we have speech recognition
on the cell phones and Alexis and
Tesla's and now of course people is that
the technology has reached people and so
they see AI you know as a big thing but
they also lead to large number of myths
and misperceptions in particular as if
intelligence only means seeing videos
and seeing pictures and recognizing dogs
in them you know that turns out is the
imagine a task I will talk about in a
minute so so that's sort of something
that I want you to keep in the back of
your mind and you know Rob mentioned
that you know a lot about deep learning
and this is huge deepening war in terms
of you know how the depth of the
networks have improved improve our
ability to do good perception you know
that's the perceptual intelligence part
and and you also mentioned something
that I'm just going to quickly remind
you that you know some of the large part
of the theory of those of us in the eye
and when I teach courses in AI I tell my
students that this is the third coming
of neural networks the ideas have been
around for quite a long time what
actually has changed in fact basically I
think three years back at triple-a I and
pointed out well there's a 10,000 X
speed-up in training the networks and
then said there are theoretical that one
says there you know some things that
just happened in the infrastructure and
then after everything we would hope that
is the theoretical advances that led to
a huge amount of this improvement it
turns out actually the infrastructural
advancements were just as important how
many of you have seen Blade Runner the
movie if you now if you didn't please go
and see it but those of you have seen it
go back and see it again and you would
be surprised at how impressive the movie
is in figuring out a far future but they
couldn't imagine that the cell phones
would be thin and iPhone like are that
TVs won't be huge big bricks for example
so what happens is that as I was going
about doing its own thing the rest of
the technology progress and that
infrastructural improvements have
actually wound up being extremely useful
in the success of deep learning not just
a huge theoretical advances itself but
these infrastructure improvements that's
what while keeping in mind
now of course deep learning has as
Robison pointed out well and has had a
significant set of industrial successes
and so this also has led to I what I
would like to say irrational exuberance
and I don't know how many of you know
Archimedes and in addition to what you
know running around naked in Athens
apparently he would say that if you give
me a river and a place to stand I can
move the world because he figured out
you know the idea Falcom right and so
now the version of that for AI is if you
give me a big enough GPU a large enough
data set and a deep enough Network I'll
create your super intelligence that's
exactly what's happening right now
because people see that in a 150 layers
you do imagenet 395,000 layers Navy
robots will take over and there won't be
any harm they would be Independence Day
the movie in Washington DC now this
subtly irrational exuberance is
important for us to understand both
within the community and especially
outside of the community in the
policymakers and so on I want to mention
this this is a write-up about alphago
which actually Rob mentioned are towards
the end of his talk alphago turns out is
not just perception it's perception plus
reasoning it actually brings two
different parts of you know your
interrelations together no less a are
technically sub supposedly technically
savvy a paper magazine then I triple
spectrum says google deepmind pass this
self-guided method reinforced learning
which itself like turns out is the wrong
word
but it's really another word for deep
learning so essentially it's become a
situation that now everybody assumes
everything that works are that needs to
work is just deep learning and so it's
important to understand that it does
something about perception but there's
so many other things that we need to
make progress on that's what we all try
to talk about so the intellectual follow
out of this particular kind of
exuberance has been that you know AI has
always been famously full of pendulum
swings we argued about logic versus
probability we argued about whether a I
supposed to replace where people are
should admit the people and of course we
famously argued about whether AI is a
huge disappointment or it
doomsday right away but one of the most
useful intellectual threshold a pendulum
swings has been between symbols and
neurons at the beginnings of AI Newell
and Simon made this physical symbol
system hypothesis which basically says a
physical symbol system has the necessary
and sufficient means for general
intelligent action now of course geoff
hinton who has very you know ably held
the other side of the food said symbols
are but luminiferous ether half AI those
of you have physics background remember
what what we're talking about now the
now clearly neurons you know of its
human brain does seem to work with
neurons there's large amounts of
questions as to whether neuroscience has
any connection to deep networks that
exists right now but you know there is
at least over neural in it and then the
symbols on the other hand while we have
the basis of our cognition our
intelligence is neurons from Greeks on
human knowledge has been codified in
symbolic fashion we talk to each other
in symbolic ways and there is so much
that's basically decorative and symbolic
about it to put this in perspective and
also put you know Stuart Russell on the
spot because it's all his problem you
know this is the textbook anonymously
popular textbook in AI the third edition
and these are the table of contents of
AI textbook and so I'm going to start
teaching these floors again two weeks
from now and it turns out the neural
networks part of a falls within learning
within these parts about ten and a half
pages out of thousand pages is basically
taking the view that we really care only
about neural basis not just symbolic
basis I want you to keep this in mind to
understand where AI was and where AI is
what are the you know the things that
you're hearing about in terms of
breakthroughs that are happening so the
fact that there's a lot of interest in
in this neural approaches you know I
think again it's great that these things
are working and as
i person i take you know great pride
that we can finally do perception well
but it also anything that works we tend
to think that's the only time that we
ever needed you know it's important to
keep in perspective what i was that we
are leaving on the table so I mentioned
Polonius paradox that we know more than
we can tell it's interesting to note
that the most recent improvements in AI
have all been for tacit knowledge
because we don't know how we do natural
language processing we don't know how we
do perception those are the things where
all we can do is here are examples you
know figure out yourself just the way I
figured out while being a cute baby and
machine separately can do it fast recent
advances in a are made AI synonymous
with learning from massive amounts of
data I could be rich if I just found
every industry person who says so you
work in the eye how big a data do you
have as if intelligence is all about
huge amounts of data that's you know
what while understanding that the data
basically won't of being useful for
perceptual tasks now in fact I recently
saw that somebody showed you know it's
like if all you have is a hammer no you
can base everything looks like a you
know a nail
so somebody wrote a deep learning
approach for pseudocode
Sudoku is this game obviously which I
hope you know it just can be described a
few symbolic rules and then there are
ways of solving it but somebody point
out that if you just give instead of
those two rules you should go gazillion
billions to Doku you know beginnings and
endings the network will figure this out
now if I'm thinking in terms of
autonomous intelligences that sort of
populate Mars and they don't have to
deal with me that's okay
but I think many of you especially in
the intelligence community or the
government agencies etc you I think how
these things called doctrine and if you
have an employee come and you say you'd
like to say this is the doctrine that we
go by currently if you just go only with
the sort of example based learning
technology what you are supposed to do
is convert that actually include 10
gazillion billion examples and then give
it to the machine now I'm obviously
being partly facetious the important
question is how do we combine this
ability to
learn from examples as well as learned
from higher-level knowledge that's going
to be a huge important issue so I have
gone through in the time of AI that I've
been in we went through hey what is this
rule based in expert systems all rules
of X exceptions to now what do you mean
rules what is this rules what are these
models
everything is just examples and the
machine will learn something the machine
will learn something and we'll do
something also leads to this idea of
interpretability
a Bugaboo so feature or one deep
networks learn their own representations
as Rob pointed out there is very little
especially for you know image and speech
sorts of tasks there is such a thing
called complete input so everything that
is supposed to be in this photograph is
in the pixels of the photograph
everything that's supposed to be in what
I am saying in my you know the speech
signal is in the speech signal so
presumably if you give that as the input
without actually trying to extract human
engineered features out of it which is
pretty much what the whole history of
vision and speech has been it turns out
that neural networks show that the
networks actually bring out features
better than we can now for cases where
we have no clue how we do something it
doesn't matter
I don't really probably mind that the
intermediate features of a deep network
are not understood if it is a vision
past although I will point out some
problems with that too but there are
things where we have theories and we
want to understand what the machine is
doing and there it does matter that the
representations that these networks are
making is completely their own so you
know I like this between stand for that
if a line put speed we could not
understand him so there is this issue of
shared representations that wind up
being important especially when you
start talking about human AI our
symbiosis and collaboration and that's
something that we want to keep in mind
another challenge of course when you
don't know what the machine is actually
representing while you can marvel at
when it is right you have no clue what
happened to it when it is wrong so the
failure modes wind up being quite hard
to understand and this is important for
this community so humans have
problem if I show you an example right
now if I show you
you know I throw like a ball and it
falls in the you know trashcan light at
the end of that room
you start thinking now must be an
athlete wow must be a basketball player
I can do this I can do that we do huge
amounts of example closure when a new
network are any technology shows one
example we tend to assume it can handle
many such reasonable examples
unfortunately when it fails neural
networks failure modes are not yet
understood I'm not sure that this is the
end of the world but it's important to
know that we can't understand why they
fail if you have for example systems
that have symbolic basis whether they
are probably are no logic based
approaches we can understand why this
mistake happened for example so here for
example is well-known he says made let's
say there is a school bus and you just
act imperceptible noise this is actually
magnified but when it's added to this
this thing looks like this how many of
you think this is an ostrich how about
this how many of you think this is an
ostrich it turns out that we can make
anything into ostrich apparently there
is nothing sacred even South Indian
temples can be made to look like
ostriches I was really unhappy about
this ok now the point about specs so is
something that I can talk about outside
the things I found some of you know that
just because the system shows a
particular behavior we tend to put this
huge example closure around it and we
might actually wind up miss and we'll
miss estimating what it is actually
capable of doing now it is possible that
the world is full of ostriches and you
just don't see and it's also true that
human visual system can be fooled too
you know we are not exactly even as you
know snow so this example how many of
you see this picture by the way ok so
this caused a large amount of
controversy in our way because some
people basically looked at this and said
oh my god there's so many both applied
women in Norwegian buses and they
started having this humongous backlash
about we should stop immigration and we
should stop
etc now of course Islamophobic and you
know gino phobic these people might be
you can almost see those are Bertha trad
women do you understand what I'm saying
can you tell me as an ostrich so you
understand what I'm trying to say the
failure modes you can at least
understand our failure modes we have no
clue whatsoever about the failure modes
of these deep neural networks showing
amazing our performances so that's
something that you want to keep in mind
now given these kinds of problems you
know you can imagine how great it feels
when you see things like this paper
which says oh just strain you know you
can remove supreme fertility supreme
court apparently we can't come from
anybody under the court so we can remove
courts and judiciary just train you know
neural deep neural network with large
number of examples of mugshots
and who and people who have been finally
caught and people who haven't yet been
cut and so they are not criminals and
then see whether you can actually
predict from the held out data and
apparently it turns out that
convolutional neural networks will
predict with 95% certainty you know
whether or not a mug shot responds to a
you know a crime criminal and it's not
just in China it turns out there was an
Israeli company which was saying we can
use facial imaging to identify
terrorists and pedophiles now I want you
to understand it's it's probably you
know even if you don't care about
whether or not phrenology is a science
there is this worry about the failure
modes and what are we doing trying to
run with a technology just because they
have shown some couple of good examples
ok it's important to also think of data
bias versus algorithm bias because many
of these systems are going to be trained
and large amounts of data and figuring
out whether or not that data is actually
representative is actually a pretty darn
hard problem Rob talked about image net
it turns out image net has thousand
categories 200 of those are dance
200 how many of you can recognize 200
dance even those of you are dark
fanciest
so no wonder humans actually are only at
a 5% level because it's I can't imagine
or recognize more than about five
different types of gods so the point of
course is what are you training these
systems for winds up being very
important and so you're going to have to
ask people show me your data and then
how exactly are we going to do that and
that's something that we want to keep in
mind I want a second the next point I
want to make is thresholds to general
human level intelligence so I think deep
networks are extremely useful in doing
perceptual tasks but we have to keep in
mind that intelligence is multifaceted
and all these other pieces have to be
brought in so some of the thresholds
that I want to mention are common sense
incompleteness sample efficient learning
and of course interaction with humans
that you know manual also talked about
common sense is elaborates the partial
specification of facts of the visions
norms and goals my favorite example is
Madeline the Explorer went around the
world three times and one of his trips
he died which GBD died in okay if you
can't answer you're probably a robot
then there are vinegar add schema
challenges for example you know
sentences are extremely similar
the women stop taking pills because they
were pregnant who are pregnant the pills
are the women and the women stop taking
pills because they were carcinogenic who
are carcinogenic pills are women you
don't seem to have any problem I'm not
going to ask you who got what
interpretation but we don't seem to have
any problem and it's because we bring in
humongous amounts of common sense even
into what we think is a simple
perceptual task and that's what while
keeping in mind sample efficient
learning and in fact having a pipeline
to your robot that's more than
converting what you know into 10,000
million examples that points are being
very important currently successful
learning techniques are all purely
data-driven and as Rob pointed out it's
very important to try to have you know
you widen this pipeline human learning
is so much more sample efficient at
least that's what I hope when I'm giving
lectures to my students because imagine
if I have to tell them how to
how a star search works by providing
exactly 10 million a star search traces
that will be and of my life so we are
still far away from McCarthy's advice
take a dream you know McCarthy at the
beginnings of the field basically said
we need an advice taker which where you
can provide high-level advice and it
sort of takes it in connects it with the
existing knowledge that it has and
operationalizes it we are still far away
from that and so and notice that is also
connected to this data doctrine pendulum
we need to be able to have the ability
to take higher level knowledge
incompleteness Minds have been extremely
important thing all these machines are
they are machines we are going to be
stuck with incomplete knowledge about
the worlds that they are going to live
in and and so how we do robust reasoning
and robust behavior in the face of
daunting incompleteness is going to be
an extremely important issue
I like path time different secretary
full time philosopher about the fact
that there are known unknowns that you
say there are things that we know we
don't know but they're also unknown
unknowns those are things that we don't
even know that we don't know and we need
to talk about all these things and we
need to handle this and that's a
threshold I'm not saying I have a paper
that I can send you and then finally
something that's closer to my heart just
as it is to Immanuel us is I like humans
okay and so the question is what
somebody please think of the humans when
we are into developing this autonomous
technology can we start thinking about
someone's in the loop here has a curious
ambulance treat humans whenever we
supposedly want to be helpful to people
but anytime we are in the news is
because we you know cream somebody like
this guy is Carrie Castro
these are the people playing poker and
this is of course lizard world and cagey
so apparently that's the thing that we
take ah
when we are stuck on Mars and don't have
to deal with humans at all that's the
spirit for you now it's almost as if
Journal and said as general and said we
won't help humanity it's the people that
we apparently can't stand now I want to
give you a reason
why human-in-the-loop human a very high
systems didn't get as much of an
attention in the field to some extent
it's partly because from the beginning
we had this worry that if you put the
human in the loop human will do all the
work and the robots don't have to do
anything okay and it's not surprising
it's not a useless fear because remember
this guy this is the the mechanical
original Mechanical Turk those of you
who think Amazon is the only one which
has Mechanical Turk this is the original
Mechanical Turk which was the history's
most intelligent machine at the time and
it had a little person there okay so we
were always worried and in fact in the
beginnings of AI even during the time
that I've been working in AI when people
try to put humans into the loop it was
always as a crutch to help a system
that's basically you know to slow okay
so I had in area like planning that I
work in we had humans in NASA helping
the planner by going into his search
queue and then shifting nodes around
it's as if they don't have a life you
know robots are the only ones which have
life but I think he has progressed much
farther now and we have much more
effective technology and now we need to
start thinking about what does it make
sense make what does it mean for them to
work with us and when they work with us
it's no longer cheating it's actually
expanding the scope of the AI enterprise
it reduces of course some of the after
talk worries about AI and then brings up
very interesting challenges in
particular even symbols versus neurons
pendulum swing minds are becoming
somewhat of an academic problem because
while I might well be made up of neurons
I don't have a USB connection it turns
out and so if a robot has to talk to me
it has to talk in symbolic means and it
turns out explanations explicable
behavior all these things that we take
for granted when we work with each other
the robots better do that we I think
it'll be really really depressing as a
human if we grow up and go to the land
of robots we want them to come to our
land so that if the robots and AI
systems come Dave we are designing this
future we are not just sitting there and
so we should be designing a future where
we get to be what we are and
I figure out how to deal with us and so
in fact I and I show this thingy that
you know one of the pet explanations of
why humans have apparently this
ridiculously large brain size is not to
run away from the Tigers of Savannah but
to deal with each other we are always
constantly modeling each other's
intentions the desires beliefs and you
know we do this to some levels of depth
actually so the two things that actually
connected to the research that goes on
in my group that I want to mention is
teaming of course requires model in the
human those videos just show that there
are videos in my group but more
importantly we need to be able to do
intention recognition the robot needs to
figure out what the human is trying to
do and it needs to also give a heads up
to the human as to what it is trying to
do both wind up being important
otherwise steaming is not going to
happen now it turns out actually teaming
also requires modeling the humans model
of your own capabilities it turns out
that if I right now in the middle of
this talk I start jumping up and down
you would be surprised because you had a
certain sense of what I am likely to be
doing and what are my capabilities and
you know my behavior becomes
inexplicable because it's not in
conformance with what you are expecting
me to do and if I must jump because a
huge bug fell on my leg right now I will
jump and I provide an explanation and so
it turns out that explanations and
explicable T wind up needing the ability
to model the other person and what the
other person thinks about you and this
actually is a pretty AI complete problem
these are important thresholds that we
need to cross to be able to have
machines work with us and then somebody
mentioned trusting autonomy the holy
grail of human a very existence is
engineering trust in you know that for
the machines to engender trust in the
humans mechanisms for long-term trust
are complex we don't completely
understand how humans trust each other
however just like what they say about
repetition it takes a lifetime to build
but can be ruined in a couple of bad
deals it turns out that trust also can
be lost
if you start doing inexplicable things
are providing pretty bad explanations
okay so that's about the class on
autonomy I'm going to make a couple more
minutes okay because I do want to
mention the attack surfaces part so I
want to say something about attack
surfaces of course you know in the
beginnings of AI nobody worried about
attack yeah i attacking because we are
not doing anything then you know Steve
Hawking and Elon Musk think we are going
to do something and of course Hollywood
has always been telling us that AI is
going to take over now New York Times
also tells you and these lots of worries
about this issue I do you know as a
person in a hide I like this oh my god
it almost - now as I said please don't
hurt us and so where did this attack
surface concerns them safety concerns
come from now it's worthwhile
remembering that every tool is a weapon
if you hold it right and of course if
it's a sophisticated weapon it can be
held in much more sophisticated ways it
provides the additional attack surfaces
so I want to separate between three
types of what is accidental malfunction
of AI technologies bad actors forcing AI
technologies to malfunction and of
course super intelligence control I
don't have too much to say about
accidental malfunction our super
intelligence control but I want to
mention bad actors for senior
technologies to malfunction is something
that intelligence community must be very
worried about and in fact is something
that is already happening
we don't need robots to take over we
will do damage to ourselves extremely
well using even primitive internet now
we can use AI technologies so in fact I
want to mention that in March we had in
su audience Institute has a backup and
three-day two-day workshop and AI and
envisioning adverse outcomes of AI
technology and thinking of ways to deal
with it that's really a two and a half
day workshop and the report on that is
coming out and it's something that's
going to be useful to the people in this
of course when we did do this you know
the process and he said AI scientists
gather to plot doomsday scenarios that's
the way we live in right now but in fact
we are essentially thinking of fighting
AI with the eye you know you can use the
eye technologies to actually fight some
of the adversarial uses the kinds of
things that are possible already now are
why spoofing image spoofing identity
spoofing of course I like this cartoon
of internet taking over Internet of
Things taking over and some of the
examples include you know there was
something just two weeks back basically
pointing out as Rob said there is a
cottage industry of people trying to
come up with examples that will fool
deep neural networks and in the
beginning there were very specific
examples that you change the network
won't be fooled but it's not more robust
Mouse so this one is a cat image that is
respect robot you do in terms of value
change it for engagement cetera it keeps
everything looking like a desktop
computer to the deep network robust
physical attacks people are worried
about you know how you can take
something like a stop sign and make it
look like it's a goal speed-up connect a
sign and there is a paper that's coming
out on that and it also of course
synthesized videos with lip sync and
gesture control and you know the part of
it that I want to mention last week much
parties here I can be part of the
solution here this is some of the work
that we did that's under submission
where it turns out that the network's
the way nature handles wider is
basically attacking us was having
diversity being so that I don't fall say
my wife might fall sick for the same
virus for exam so we can actually be
looked at multiple deep networks and you
know trying to see how they have they
have differential immunity to the
attacks and when they have and it turns
out when they have differential immunity
you can use what's called moving target
defense which is sort of a game
theoretic technique
to increase the overall performance even
if you like one or two up the networks
are pretty badly affected by some of the
examples so I would not go into this I
was not also going to this and I'll
summarize and just say that having made
most progress and declarative tasks AI
systems in recent years have found
significant success on learning tacit
knowledge from data I want you to keep
that in mind
the only learning that's in the world is
not just learned it from tacit knowledge
you also want to learn from people
telling you a few sentences and if you
don't do that you are in trouble this
has had some interesting intellectual
ramifications in the field and also the
perceptions of what AI is from outside
of the field they're still far from
general intelligent intelligence
significant thresholds remain to be
crossed including common sense and human
aware systems and AI remains a potent
tool as well as a weapon and the new
breakthroughs in perception present of
course some attack surfaces not
surprisingly and those of you who were
reading this instead of listening to me
and say oh the poor spirit you are the
problem because we will ultimately feel
too sorry for the robots so when the
robots come and take over it's because
we actually feel sorry for them
so we ran a little bit over time but we
probably have a time for maybe one or
two questions yes yeah good yeah
so so first of all let me point out the
following thing
the thing about adversarial examples in
machine learning actually has been a
positive thing you know this is deep
learning researchers being ahead of the
game I'm trying to see since we don't
understand exactly why it said yes to
begin with what are the conditions under
which we can make it say no it's not a
dog when it's a dog okay
and so what actually winds up being you
know the theory of deep networks is
actually much simpler than the rest of
the huge AI textbook that most of what
has written it turns out it's basically
change rule of differentiation being
used for backup you know the changes in
weights and what you wind up doing in
getting the adversarial examples is you
keep the learn network structure
constant and you keep fiddling with the
feature the image changing its
intensities in various places until you
make the network do the wrong thing so
it's like I show you a picture keep
changing it slightly slightly slightly
until I see ask you do you now see burqa
clad women okay and if you do then
that's suddenly that's going to be a
adversarial example for you except it
turns out that the adversarial examples
that I can make for you you have a sense
of why it happened for the machines we
don't yet have and and so it provides a
great adversarial attack surface right
now so that's
yes sorry actually how much of those
adversarial attacks are the result of
max pooling within the convolutional
neural network I cannot be sure I think
there have been a variety of in fact
this basically shows the variety of ways
people have used in developing you know
the adversarial examples and you know it
doesn't look like there was any single
piece of the network configuration that
can somehow we magically change so that
you can get robustness if so we would
have been ahead of the game
that's why in the work we did we
essentially try to use the differential
immunity across the network's to provide
the an sample have higher robustness
than otherwise but I think you know
there may well be an answer but it
doesn't exist right now if so at least
that would be taken care of and there
would be other kinds of adversarial
examples that might still remain okay
okay so I think we've just hit time we
can pick up some more questions on the
panel please join me in thanking</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>