<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Max Tegmark - Artificial Superintelligence is Coming - Life 3.0 | Coder Coacher - Coaching Coders</title><meta content="Max Tegmark - Artificial Superintelligence is Coming - Life 3.0 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Max Tegmark - Artificial Superintelligence is Coming - Life 3.0</b></h2><h5 class="post__date">2017-12-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Pb69HAslMAI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">here are two words you've heard a lot
lately that my next guest thinks are
often misunderstood artificial
intelligence dr. max tegmark thinks
that's a real problem
dr. tegmark is a physicist and AI
researcher at the Massachusetts
Institute of Technology and president of
the future of life Institute he thinks
that AI is a technology that has the
potential to transform life on Earth
maybe even what we mean by life on Earth
and dr. tegmark thinks that the
decisions we make today about the future
of AI will shape life in the next 30 the
next 100 even the next billion years so
we better understand what we're talking
about and not be distracted by fantasies
about killer robots he explores all of
this in his new book life 3.0 being
human in the age of artificial
intelligence
dr. tegmark welcome to quarks and quarks
thank you it's a pleasure so what is
life 3.0 so that's a great question
first of all what's life my kids school
books give a very narrow definition of
life that requires it to be carbon-based
and made of cells but from my
perspective as a physicist I really
don't like this carbon chauvinism
because I think I'm just a blob of
quarks and electrons like all other
objects in the world and what's special
about living things is what they do not
what they're made out of so I defined
life more broadly this is any
information processing entity that can
retain its complexity and and replicate
and you know when a bacterium replicates
it's not replicating its atoms but
information the pattern into which the
atoms are arranged so I think based on
that you can think of life is 1.0 2.0
3.0 depending on what the deal is
whether hardware and software so life
1.0 it has both its hardware and
software fixed by Darwinian evolution
like bacteria can't learn anything
during its lifetime you know boring life
2.0 that's us we're still stuck with
evolved hardware but we can learn so we
can effectively choose to install new
software modules like if you want to
become a lawyer you go to law school and
install a bunch of legal skills into
your brain and it's this ability to
design our own software that's really
enabled
cultural evolution and human domination
of our planet and finally life 3.0 you
can guess what it is now it's it's when
you can design not just your software
but also your hardware they're really
completely break the shackles of
evolution we humans are kind of heading
in that direction everywhere life 2.1
right now because we can make little
upgrades like cochlear implants and
artificial knees but as much as I'd love
to I still can't install a million times
more memory or or think a million times
faster worse if you could make an
artificial intelligence version of us
humans then there's no limit whatsoever
so how you can upgrade yourself well
that interest that you have in our
artificial intelligence future are
shared by a lot of big names Stephen
Hawking Elon Musk and other great
scientists and technological leaders why
is this such a preoccupation for you and
people like them a lot of people who
don't think this is a big deal are stuck
in this traditional view of intelligence
is something mysterious that can only
exist in biological organisms especially
humans but from my perspective as a
physicist intelligence is just another
kind of information processing performed
by elementary particles moving around
according to the laws of physics and
there's no law of physics that says that
we can't build machines more intelligent
than us in all ways so I really don't
like this sort of carbon chauvinism that
says that the artificial intelligence
can't be as smart as us and I think
we've only seen the tip of the
intelligence iceberg and that there's
really this amazing potential to unlock
the full intelligence is latent in
nature and use it to help humanity
flourish or just grew up in new ways
well what about what about some of the
dangers that people express especially
people like Elon Musk and Stephen
Hawking that this stuff could do some
harm to us if it gets out of control
it's the same with any technology really
that you can create a great future with
it as long as you win this race between
the growing power of the tech and the
wisdom with which we manage it now the
difference is that in the past when
we've invented fire for example we learn
from mistakes to keep our wisdom up we
and after a while we went to the fire
extinguisher and with more powerful
technology like nuclear weapons or
superhuman artificial intelligence we
don't want to learn miss for mistakes
it's a terrible idea we want to plan
ahead and get things right the first
time is that because it's probably the
only time we'll have and that's what I
think you're so interesting to do today
not to quibble about whether you should
worry or not but to ask what things can
we do right now to increase the chances
that we'll get things right get things
right the first time
exactly this is not a safety engineering
to Holly back up a little bit you know
when we sent astronauts to the moon for
the first time it wasn't very shocking
that they didn't die or the things
worked out rather it worked up because
NASA had planned ahead it was good
safety engineering trying to figure out
everything that could possibly go wrong
and then make sure it went right and I
think we're a little bit too flippant
now with AI and not being quite careful
enough anyone who has had their laptop
crash on them at some point probably
just felt that was annoying right but if
this computer that crashes is in charge
of your self-driving airplane or your
nuclear weapon system or so it's not so
funny anymore
and we really need for starters to
figure out how we can transform today's
buggy and the hackable computer systems
into robust AI systems that we really
trust these are research questions and
we should really focus a lot of research
effort on them so we get the answers by
the time we need them well let's get to
the core here the definition of this
term artificial intelligence your book
is called life 3.0 so what does AI mean
to you I define intelligence simply as
how good something is at accomplishing
goals what we have now is machines that
are getting better better at very narrow
kinds of intelligence like driving cars
or recognizing images but nothing that
can compete with a human child still in
terms of broad intelligence the ultimate
goal of the AI field is to create
intelligence in machine form it is as
broad as human intelligence and can
ultimately learn anything if that
happens it's obviously going to
transform the world as we know it and
poses a whole set of new interesting
challenges and it also of course opens
the possibility of great things
happening because everything I love
about civilization is a product of
intelligence so if we can use artificial
intelligence to amplify our own then I
think we can use it to solve all these
pesky problems that have stumped us so
for well how do you see this sort of
general intelligence artificial
intelligence manifesting itself that
goes beyond just self-driving cars we
already know what general human level
intelligence is like in some examples
because people around us have it right
if you imagine that you could build a
machine that could do exactly everything
that a person could it would immediately
transform the economy because you could
hire these machines and they would work
24 hours a day for just the electricity
it costs to power them and dislocate a
lot of jobs you could also use these
machines just figure out much faster
than humans can how to invent new
technology the technology is very
powerful but that doesn't mean it's
necessarily good or bad that entirely
depends on what sort of goals we put
into the machines and I find Hollywood
movies they keep making us worried about
the wrong thing about evil wrote some
robots turning evil and conscious and
deciding they want us or whatever the
real concern I think is not malevolence
but competence since super intelligent
machines by definition much better than
we are at accomplishing its goals
whatever they might be right we have to
just make sure that its goals are
aligned with our goals like we humans
for example at least me I don't hate
ants I'm not gonna go out of my way
stepping on one if I see it in my garden
right but if I'm in charge of a
hydroelectric project in Canada and I
noticed there's an anthill there just
before I flood the valley you know too
bad for the ants and I want to make sure
that when humans don't end up in the
position of those ants and rather than
we when we make machines we make sure
that they have goals are aligned with
our own goals so that they end up
helping us well what's the difference
between designing a machine to do a job
and one that has goals and where are
those goals gonna come from if you build
very intelligent robot and just give it
a very simple job like go shopping for
me and cook a really delicious
week dinner now it has a goal because
you gave it a goal right and it's smart
so it's gonna break this into a bunch of
sub goals like go down to supermarkets
pick out stuff and so on and now if
someone tries to stop this robot and
destroy it it's gonna resist this and
defend itself because it knows if it's
destroyed it's not gonna accomplish his
goal of making you dinner right so what
this shows is it's things that we might
think you're just typically human goals
like self-preservation for example
they'll emerge very naturally so it's
very crucial to make sure that we have a
way of making the machines actually
understand our goals and then learn them
and that's harder than you might think
if you tell yourself driving taxi to
take you to the airport as fast as
possible and you get there covered in
vomit and chased by helicopters and you
say no no that's not what I asked for
and the computer replies thought is
exactly what you asked for then you
realize how hard it is to teach goals
the computer is right because a human
taxi driver would have realized that you
had additional goals besides just speed
of delivery because it's also he's also
she's also a human but a machine knows
absolutely nothing about what it's like
being human and there's a lot of
research now trying to crack this nut of
how machines can actually by observing
us and so on figure out the whole
picture what we really want well you
talk about super intelligence in your
book that where the machines become so
advanced and so sophisticated that
they're beyond human intelligence so
what about the Machine coming up with
its own goals
that's another fascinating challenge
because even if the Machine first adopts
your goals and then gets a way smarter
how do you ensure that it retains its
goals and we don't want machines who
initially want to take care of us to get
as bored with us as they my kids got
with Legos as they get smarter so this
is another fascinating research question
and what I think is kind of a shame is
that the governments of the world are
asleep at the wheel here these are
technical research questions that a lot
of AI researchers would love to put
their best grad students on but there's
almost no funding for it almost all the
funding is just for making machines
intelligence very little is focused on
how we can ensure that we have the
wisdom to operate things rightly and
getting goals and so on and it's a great
opportunity
right now if we go in and fund this sort
of research to get the answers by the
time we need them because even if super
intelligence might only happen say over
30 years from now we want to make sure
that if it happens we have the answers
by the time we need them and it could
take 30 years to get the answer so I say
let's start now will we be able to
control the super intelligence there are
two schools of thoughts on this some
people think that what we should do is
box super intelligence and have it
basically locked in so it can't break
out and use it as a kind of enslaved God
to do whatever we want for us and just
hope that the people who control it or
good people with the best intentions
other people feel that that's either
immoral towards the AI or not a good
idea for other reasons and instead want
to have an AI that's very smart and free
but just make sure that it actually has
its goals to help us yeah that can also
be okay because little children tend to
be in the company of intelligent beings
are actually smarter than them namely
their parents and that's fine right
because the parents have the best
interests of the children in mind so if
we can crack this goal alignment problem
that can also work well you do look into
the far future I mean you you look out
billions of years into the future and
it's in your mind not just a human
future this is artificial intelligence
our our evolutionary future on a cosmic
scale I certainly think that if one day
life from Earth ends up spreading to
other galaxies it's much more likely to
have gotten there with with a lot of
help from AI as a physicist I find it
kind of fascinating that it's actually
easier to say sensible things about what
might happen in the billion years then
about what might happen in a hundred
years
they are totally mind-blowing there is
just an incredible potential for the
future of life and most science fiction
writers have been much too pessimistic
and what we can ultimately do because
they've been so limited to this idea
that if you want to go far away have to
send a bunch of meat bags there and
figure out a way for them to survive
these ridiculously long journeys when in
fact ultimately light I think life is
information and the much more a way to
do it is to basically email the
information about your mind or whatever
other places and have yourself
reassembled there with future tech so
sky isn't even the limit here if we
really can harness AI for good doctor
tech mark thank you very much for your
time thank you for yours it's been a
pleasure dr. max tegmark is a physicist
and AI researcher at the massachusetts
institute of technology and president of
the future of life Institute his new
book is called life 3.0 being human in
the age of artificial intelligence</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>