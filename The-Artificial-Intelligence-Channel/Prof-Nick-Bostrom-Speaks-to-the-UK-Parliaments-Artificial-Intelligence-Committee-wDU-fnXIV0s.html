<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Prof. Nick Bostrom Speaks to the UK Parliament's Artificial Intelligence Committee | Coder Coacher - Coaching Coders</title><meta content="Prof. Nick Bostrom Speaks to the UK Parliament's Artificial Intelligence Committee - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Prof. Nick Bostrom Speaks to the UK Parliament's Artificial Intelligence Committee</b></h2><h5 class="post__date">2017-10-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wDU-fnXIV0s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well a very warm welcome to you all
three I think we're just going to we're
opening the floodgates here and this is
the sort of public session so while the
members of the public are coming in I'll
just do a few introductory points just
to say the session is open to the public
a webcast of the session goes out live
and is subsequently accessible via the
parliamentary website err a verbatim
transcript will be taken of your
evidence and this will be put on the
parliamentary website and a few days
after this evidence session you'll be
sent a copy of the transcript to check
it for accuracy and we'd be very
grateful if you could advise us of any
Corrections as quickly as possible and
if after this session you want to
clarify or amplify any points made
during your evidence or have any
additional points to make you're very
welcome to submit supplementary evidence
to us and perhaps we could kick off by
asking you to introduce yourselves
humanity Institute thank you I wonder
who all I'm a professor of computer
science at the University of Southampton
and I'm co-chair of the AI review my
name is Mike Aldridge I'm a professor of
computer science and head of department
of computer science at the University of
Oxford's and I've been an AI researcher
for 25 years thank you very much indeed
um as you know the usual processes we
will take a series of questions I think
you've had sighted from them beforehand
but what we'll be doing is is taking
around a number of members of the of the
committee as we go forward and I know
that we have to conclude this session
sharp at 4:45
we are we know we're under instruction
so perhaps I could just ask you a very
general question to begin with what in
your opinions are the biggest
opportunities and risks associated with
AI over the coming decade perhaps I
could start with you
professor Bostrom yes I think that over
one decade time scales are exciting
opportunities both in terms of basic
research it's really beginning to open
up the box of how you produce
intelligence that indirectly she had
slide on how the human brain works it's
an interesting thing in its own right in
terms of economic applications I think
there are many the first and most
obvious locus of applicability is with
these big tech companies if you're
google you can immediately apply it to
make a better search algorithm and if
you're Facebook you can serve better ads
and so forth 10 years maybe not to start
to see an impact in terms of
self-driving cars it's it's a little bit
hard to say exactly how long it takes
for that to be rolled out you know large
enough scale to sort of start to affect
society but it's possible surveillance
is another area where there are obvious
applications you have massive datasets
of text interactions or voice recordings
of people and being able to date online
that more effectively facial recognition
software that is being rolled out in in
China and so forth to monitor the public
would be another strategical irrelevant
application area within ten years and
perhaps autonomous weapons would be
another but as with any new general
purpose technology it might well be that
the most exciting applications are not
obvious at the outset and normally
discovered as aesthetic as people can
start to play with the technology thank
you I'm gonna come on to ask him out
some of the limitations but Dame Wendy
perhaps you'd like to answer the same
question just to suggest a certain
context AI
been around for a long time as a concept
and we are in I don't know how my
colleagues would describe it the fourth
or fifth wave of AI I cut my teeth on
Prolog in computers and education as MSC
masters for my computer science thesis
and and I think through science in 1984
I think and that was because there's AI
and there what's happening now is that
the we actually can build systems that
learn because of the huge amounts of
data that's available which is what Nick
was talking about and the you know the
machines and compared to when I started
computing in the 80s the machines are so
much more powerful in terms of
processing power and storage ability so
that's why that's why we see this huge
surge now there have been surges before
and actually AI is already in use in
society in many ways I mean in the
financial area so lots of artificial
intelligence been used in the algorithms
that they apply to predicting
forecasting exchange rates and so on and
and already in the health arena there
are a number of applications will I
think what we're looking at is an
escalation and acceleration and I think
you know that the genie is out of the
bottle
we will see an increasing amount of
automation in every walk of life
actually I think over the next 10 years
how much of it will lead to great
breakthroughs like the automated car
most of your examples were pretty
negative actually surveillance and
weapons and so on but there will be lots
of positive benefits in terms of health
and discovery of knowledge there's lots
of it but the downsides are something
that we need to get a grip of because
it's happening so fast and there are
lots of issues about algorithmic
accountability
bias in datasets or in algorithms and
and just generally of course how this is
going to what it's going to how it's
going to impact society in terms of
future jobs that clearly gonna be there
will be job losses but there will also
be a lot of new jobs we're going to
tease out some of those issues later on
and professional music where do you come
in on this largely agreeing with what my
colleagues have said and so in terms of
opportunities AI I think the way that I
would think about it is that it's a new
software technology and what that means
is it's a software technology which lets
you do things with computers that they
couldn't do previously and a whole range
of things I mean we heard literally just
last week that a long dream division of
automated translation of speech is now a
reality in a product that you can buy
that's a new capability that wasn't
there before which is entirely due to AI
so whenever you've got these new
whenever you've got this capability to
build to get software to do things that
it couldn't do before then that means
there's new products new services new
economic opportunities so that there are
huge opportunities there this new
software technology creates new economic
opportunities for products services and
so on and the UK if I just take a UK
slant for a for a moment is in a really
unusual position a position which as nay
eye researchers have already mentioned
for 25 years I would not have guessed
even a decade ago that is we are
absolutely at the center of that AI
revolution this city is at the center of
that AI revolution and so those
opportunities are really in our hand as
a nation right now and we can make use
of those opportunities and we can
exploit them for the national benefit or
we can we cannot exploit them so AI is a
software technology lets computers do
things they can't do and that provides
you with new services new economic
opportunities that you can then exploit
in terms of specific opportunities I
think at Wendy's absolutely right one of
the most exciting ones over the next
decade is health
personalized health so more of us as
they're becoming gradually more
affordable or buying things like Apple
watches and fitbit's and all these kinds
of devices which are amassing huge
amounts of very private data about us on
a moment-by-moment basis and that data
gets fed to a supercomputer in your
pocket your mobile phone because it's
not really a phone that's the most
trivial thing it does it's a super
computer and that computer has an
incredible capability to process that
data and learn things about you that you
would never have predicted with AI you
can do things like predict the onset you
potentially predict the onset of
dementia of heart disease all of these
things long before you would ever become
aware of the symptoms or think to visit
a GP it would be like having a doctor in
your pocket I mean there's a real huge
opportunity there for us in terms of
health over the next decade that's great
I'm sure you'll we'll give you a chance
to expand on that later I just want to
ask you very quickly just to say what
you think briefly are the limiting
factors Nick right now it's very limited
ability to do reasoning common-sense
through the understanding concepts and
language the strengths are in pattern
recognition it's an open question how
much advanced that will be worth solving
those as yet on some problem over the
next decade do you agree with that I do
we turn we use the term artificial
intelligence which has become a noun
recently you talk about an AI but which
I think came from Hollywood anyway the
the thing is it's not artificial
intelligence as in its broadest sense we
haven't we can't yet we haven't got
something that mimics what our brains
can do but in particular circumstance in
specific circumstances
we can now create systems that are that
can do more than our brains can do
because the system's can learn from the
data from data sets over and over again
can be trained to be very very accurate
in particular circumstances like
Diagnostics in diseases and I think you
know health care could be revolutionized
just in terms of you know I'm sure you
we all now look to Wikipedia or Google
before we go to a doctor's surgery when
I was a child you had no idea what the
doctor was gonna say when you went to
the surgery now you have a conversation
with them when you get there you think
I've got so-and-so and actually that's
only going to increase our first
interaction with the Health Service and
we've got a problem could be online with
the right support and then you know if
the UK takes that on board we can really
begin to have more efficiencies it could
lead to all sorts I love it I asked you
a question about limitations and you
come up with more positivity it's
wonderful just very quickly yeah in
terms of the technology right now
absolutely agree transparency is a big
issue so alphago the famous go playing
program plays world-class go but it
can't tell you how it plays you can't
extract the strategy all that knowledge
that it has is somehow embedded within
it in a really opaque way and this is
going to get to be an issue if you're
going to put this software in
circumstances where it's making
decisions that have substantial
consequences for people going back to
the UK again again I want to emphasize
just we're in this incredible position
but to capitalize on that we need
capability a DPhil student from Oxford
right now who does a PhD in machine
learning has a reasonable expectation of
being made for life in terms of being a
millionaire within a very short number
of years after their DPhil why because
there's so little capacity in this space
so few people have the right expertise
so if we are going to capitalize on it
we need to build that expertise base and
other nations are busy doing that right
now thank you and we saw you in the
opening scene of alphago by the way
by count Ridley first and then Lord
Gideon's well I just wanted to pick up
on on something here before I move on to
the second question that's alright is it
yeah yeah supplementary yes this is some
good good that's what I was checking I
want to pick up on
I mean dem Wendy quite rightly said that
what's new is that these things can
learn from scratch without having
expertise injected into them they in
that sense can learn anything but what
well okay maybe not but it's programmed
to learn to learn but not to learn not
to have the expertise not to be an
expert on the subject not to generate
the expert from the experts
whereas professor Wooldridge in your
written evidence you say there's
essentially been no progress in general
wonderful tease out the distinction here
so general AI is the kind of the the big
dream of AI it's the dream that you see
in Hollywood it's the dream of conscious
machines machines to the self-aware that
they can discuss may have conversations
like we're having right now and that's a
very nebulous goal and I would say
possibly provocatively and this would be
the kind of discussion over a pint of
beer I think but actually there hasn't
really been any substantial progress in
generally AI we're beginning to get
there with better ideas about the brain
but all the progress in AI over the last
decade which is real and substantial and
exciting has been on narrow AI which is
like on very narrowly focused tasks like
recognizing faces or doing a very very
very specific task where you can get
lots and lots of data about this is how
you do the task you just repeat and
repeat and repeat this is how you do it
right this is how you do it wrong and
the program can learn from that data
over time so general AI is the big
nebulous dream of sort of conscious
machines and it is my belief that we're
not that is not insight at the moment
doesn't mean it's impossible but it's
not insight at the moment
you'll get it so how does I agree with
everything my friend and I can't really
always says I had just picked up on the
same issues because I see it is rather
central thing your assertion there's no
progress towards general a I don't know
we need to be clear about what I'm in my
my question is really is that uh just a
question of lack of Advanced motorists
there are logical issue here since we
know that John soules Chinese room
argument has been around for 40 years I
mean as myself like a bit of a vicarage
stone you and I find it quite powerful
there is a distinguish between certain
tactics and semantics to be able to
master meaning you have to be in the
real world you have to be an agent you
have to have a saturated knowledge of
human society I just don't see how I a I
could ever get to that so that's my
question Larry that's not a small
question to ask I have to say and I
think probably why don't you far away
what treat this treat this is a seminar
- yeah so one paradigm I think it's a
really big issue though actually
structurally important for things like
you know how far it intrude into job
markets yeah but I think that one of the
things that are different about the
current generation of machine learning
progress compared to the old good old
fashioned AI is that at that point in
the past he had symbols that didn't mean
anything you had the letter a could
stand for Apple but you could then make
simple logical derivations on that but
the computer didn't really know what an
Apple was it couldn't recognize an apple
if it's so on in front of itself whereas
now you have these grounded
representations where the representation
of an apple is learned from looking at a
lot of pictures and you can build
artificial agents that run around in an
environment acting and behaving and
learning
maybe interacting with virtual apples or
if you build a physical robot you could
have it interact with real apples so
that the representation behind the
symbol a as it were
now it's linked to motor programs and
and representation visual recognition
algorithms inside the AI in in a way
that wasn't present in the sort of
traditional AI system thank you Lord
ravine earlier you said that some of the
intelligence which is in the system now
is embedded and it'd be quite difficult
to explain whether they've come from now
I find that interesting because I wonder
to what extent any of you believe that
this will be transformed over time
in in human evolution the reason I asked
that question is this if I'm trying to
learn how to use a new piece of software
with great difficulty and I turned one
of my grandchildren they do it
immediately and if I said them how did
you do that this it was obvious now it's
obvious to them because to me somehow
rather the way they've been taught and
brought up their minds are wired
differently from ours so I'm just
interested in at what extent do you
think that human evolution will be such
that the understanding of how to use
this know-how which we lesser mortals
amongst us struggle with to two
generations down will be self-evident
right off the bat anybody want to tackle
that one I think they're certainly human
learning and figuring out what the
capabilities are I think one common
error that people make when they see a
robot performing a particular task is
that they assume that if the robot could
do this particular thing then it
probably can also do all the other
things that the human would be able to
do if the human could do that one task
that doesn't necessarily need to be so
so that bundles of competence that we
find in biological creatures humans or
even animals might be very different
from the bundles of capabilities you
find in AI and we will learn more about
that as we get more experience but there
is also an active research area that
tries to make these big neural networks
more transparent and maybe make it
possible to extract out simple explicit
logical rules from the big patterns that
are learned and so that's I think the
sense in which these are less
transparent than the old AI systems is
that with all their systems that was a
explicit rule saying that if you saw x
y&amp;amp;z then do a particular action where as
was now that is kind of embedded in a
big complex neural network that then the
cross-product processing to read out
that thank you very much professor will
be huge so absolutely agree absolutely
agree with what Nick said and actually
this this challenge of extracting that
knowledge and being able to sort of
reason about it in the kind of language
level in the way that a human would be
able to rationalize what they were doing
is one of the defining challenges for
for AI of our times if not the defining
challenge for AI of our times we've had
these incredible accomplishments but as
I say they can't explain what they're
doing or why they're doing to go to your
question about sort of human evolution I
mean where I think AI is increasingly
going to play a part and it is already
doing is essentially in augmenting our
intelligence I mean intelligent
prosthetics I mean Google glass didn't
quite work but something like it will
and will overlay reality with a version
of reality which is augmented by all
sorts of information that's produced by
artificial in
and that I think is something realistic
within the next 20 years I've been
reminded that all of us including myself
have failed to declare any interests we
have that which were meant to do when we
first asked a question at the very first
session of this committee and so I'm
going to declare my interests and I
think Matt if you do that back out
really if you do that on the second
question then we can come back and not
not yet when you when you ask your
question or get in sir that'd be fine I
declare my interest as non-executive
chair Ron woodsmen services chair
counsel of Queen Mary's University
partner in DLA Piper UK LLP co-chair
all-party parliamentary group on
artificial intelligence bike out ridley
question - in addition to those interest
listed in the register
I declared that I was flown to Mexico to
debate professor boström last year and
we had an enjoyable time doing so the
second question second question is is
the government well this fall is very
much on from what Professor Wooldridge
was saying in his rather eloquent
remarks about how well placed this
country is possibly to take advantage
here so the question is is this
government doing enough to maximize the
opportunities and minimize the risks
associated with artificial intelligence
if not what more could be done can i
I'll take that first just in terms of
the AI review that we've been conducting
unfortunately I can't talk to you as you
know about any of the detail it is it is
it will be published very soon and I'm
happy to come back and talk to the
committee when it has been published
I've been talking to Luke about this and
go into more detail
and I think when you see it you'll see a
very thorough review of job creation ah
Makka portunities and potential for job
creation and grasping then the
initiative and the opportunities that
that might was talking about so I from
my point of view I've seen a lot of
activity from government in the last
four months because it's been very
intense and I think will continue to be
intense for the next week or so but I'm
afraid I can't share that with you just
yet no and we're going to make the
assumption that that there will be other
forms of activity by government
following on from your recommendation I
hope so yes the professor will reach you
but I think I mean I'm just gonna
perform perform according to stereotype
I mean I think clearly education plays a
key role here if you walk around the
deep mind officers basically everybody
you meet has a PhD either in computer
science or mathematical subjects many
many of them are from overseas so we
need capacity in it's not just enough to
turn out programmers that's not it we
need programmers with very specific sets
of skills and there are kind of a level
above just raw programming skills so we
need we need more PhDs with these right
kind of skills we need to create a
environment which is friendly for
startups because that's where I mean
there is at the moment incredibly
vibrant startup culture in London again
not necessarily something we would have
predicted 15 20 years ago but there is
it's extremely healthy but it's fragile
and it needs to be nurtured so
government needs to create an
environment which is friendly for those
startups I'm gonna use the word nobody
else has used it but breaks it as an
issue there's not that many British
accents in deepmind you know if if you
want to protect that and create I mean
believe me Berlin and Paris would love
to have deep mind working for them and
would give them all sorts of breaks
available
have them based their I beg your pardon
not working for okay pressure boss
manana went to this yeah I think I think
if one looks around the world there are
a number of countries which have sort of
caught a eye fever and are going in
quite ambitiously to support this with
me sitting in Asia with with China and
South Korea Canada is another nation
that has been at the forefront they have
a very strong basis in machine learning
and they've decided to double down there
saw that the key University people were
hired away by American companies and
rather than just sit back and sort of
lose their lead that have recently
launched a pan-canadian artificial
intelligence strategy with 125 million
Canadian dollar funding from the
government and just a month later there
was an announcement of the vector
Institute with another 170 million
dollar funding from the Canadian
government and the Ontario government
and as well as a group of 30 industry
partners and there are a number of
initiatives to try to support the
Canadian startup scene in AI to support
Canadian universities a senior academic
active in this field could easily move
into industry and get a half million
dollar a year salary for many of these
big tech companies so it's to make it
attractive for those people to stay in
academia one needs something different
than business as usual okay
back I'm really just quick back quick
pass in recognition of what you just
said professor boström what what what
how does Britain look in that
international comparison is it trying
hard enough compared with say Canada so
I I don't necessarily know all the
different things that are going on
within the but in particular I haven't
seen this this I I think there has been
a long investment over decades in
computer science in Britain and that is
sort of the soil out of which these
recent successes have gone but I my
impression is that there there is a
aside from deep mind that would be a
risk of kind of losing the lead without
doing what all these other governments
do
see this as a massive national authority
and very very quick one from Lady
bake-off the talkies of phd's and all
this startup levels which all begin in
your late teens at the earliest and go
on through your twenties are you aware
that the government is doing anything
thorough in terms of starting young
people early in the understanding of AI
is there any evidence that they are
acting on that already well the
government has changed the curriculum
for computer science in schools we've
looked at this as part of the AI review
so now you know computer science is
taught through out from primary through
secondary that's still rolling out that
was only changed what two or three years
ago and we it's it's very important that
that includes knowledge and awareness of
AI and AI as far as I'm aware looking at
the curriculum that that is being
addressed it's very it's very new that
these rollouts are very new that this
really was only to tell I think it's
very important we talk about interview I
think it's very important that we keep
an eye on that I would also like to make
the point that whilst we need to grow
aggressively for PhDs and masters in
this area to give industry the machine
learning programmers any I think there's
a there's a huge amount we can do to
upskill all sorts of sectors in the
population well I hopefully will come on
to that Lord Dean thank you I determine
interest of chairman fellow dynamics in
the UK given the possible impact of
artificial intelligence on the labor
market do you think that the government
should be considering how to mitigate
this now or was it still too early and
if you should start planning now more
options my to consider
well I've thought about this quite a lot
one could be quite radical and
opportunistic because I think it's clear
there are those as with all big
technological revolutions over all over
time there'll be more jobs created than
lost but that doesn't help the people
whose jobs are going to be lost in the
short term the truck drivers the anyone
whose job is repetitive and can be
replaced by some form of automation is
that jobs likely to go in the next 10 to
20 years and you know we see the fight
about taxi drivers in London actually
with automated vehicles you won't you
don't need a driver suppose that's a
short-term issue but I do think we could
be quite radical as part of social
reform and think about because the jobs
I firmly believe that whilst automation
is going to can help with a lot of
things in terms of caring for people I
don't see in the next 10 years robots
are gonna be able to help care for my
mom when she was 96 and needed a lot of
help and now that's gonna need people
with empathy that robots can do you know
that the process things maybe even make
a cup of tea but not the empathy in
there and the care that's needed and I
think what we should be doing for social
reform is taking the opportunity to say
what are the jobs that need people to do
that and value those jobs and think
about so not trying to say well we're
going to make everybody into an AI
worker
we need lots and lots of those but I
think we need what can't what is what is
AI not gonna be able to do and how do we
fill those gaps I think we could be
quite radical about that but I'm not a
politician thank you I absolutely agree
I think I think when you make some very
nice points very eloquently I mean I
think we can either race to the bottom
or we can race to the top in terms of
jobs and I think I would much rather see
us nurture those startups
build the next tech giants and create
wealth and create jobs through that to
offset these losses which will come I
mean so I mean I'm more bullish than the
Nick is about driverless cars I think
within the next 20 years that will just
be the norm
I think driverless driverless car
revolution is right here right now the
technology is solved it's just a matter
essentially rolling it out and the big
social and legal issues of course that
go with that but within the next five
years I think driverless cars driverless
vehicles on our motorways I think is
entirely plausible within 20 years I
think it will be the norm and within 50
years and you know our grandchildren
will laugh at the idea that we actually
use to drive our own cars
don't start retraining truck drivers
context drivers do something else I
think my my I mean I think what do you
see but what about my you know there's
all sorts of jobs that need doing to
support people why not yeah where do you
stand on all this I think it makes sense
to try to position the UK to take
advantage of the economy I think that
over time scales ten years I'd expect
although there will be impacts on the
labor market from automation it's not
clear that it would be a dominant driver
of worker displacement so I think rather
than specifically targeting AI as a
source of unemployment I think there
should be a general labor market policy
and there will be other factors
offshoring say Amazon displacing
retailers like all kinds of other things
other technical another just economic
factors that may be bigger over a ten
year time scale than the impacts from AI
interesting thank you very much and we
move on to a little colleague is it out
in the register of interest
it data is one of the key feedstocks for
AI so the ownership of data the
ownership of data sets your personal
data and how how you transact with
bodies and organizations that want to
use your data becomes a really critical
issue and I think this lady's concerns
came to the fore when we saw that the
Royal Free Data deepmind
have 1.6 million what in your view is
the right approach to this what are the
right terms of trade how do you protect
privacy how do you protect public
interest
do you allow this once we once released
to be available for everybody which
possibly means that it would go straight
facility value and they would benefit
the economic consequences of this how do
you have you think about that
relationship and that multifaceted
relationship to protect and to ensure
that we this country and the public
sector benefits as much as possible from
the use and exploitation of data which
should we start with you so the first
thing to say is that this country since
1984 has had in place robust and quite
farsighted data protection legislation
which actually if you look at and that
that legislation has been updated I
think twice since then in part through
through European initiatives and
actually it's pretty robust it's pretty
sensible it's pretty pragmatic it's
pretty it covers quite a lot of the
basis and already deals with quite a lot
of the issues that are thrown up by AI I
think so AI specific legislation about
this is not the right way to go I mean I
think I would look at our existing data
protection legislation and ask yourself
what what then does AI add into this mix
that we need to start thinking about I
mean so for example suppose Facebook
just looking at your Facebook feed
predict that you are coming down
with dementia to use an example that I
care Amelia do they have some kind of
obligation to release that information
to you this is not information that you
provided it's information that they've
derived from information that you've
provided there they're smart services
have come to the conclusion yeah and you
can think of endless say for example
about that that potentially is something
where we need to look at existing
legislation and think about how it
impacts it but I say we have excellent
data protection legislation in this
country if we apply it it is not I have
to say being rigorously applied
throughout throughout the country at the
moment you agree with that well
so issues about where your data is
stored I I suspect that we wouldn't have
to leave this building to find examples
where people were using a data storage
services which actually meant that the
data was in well actually it would be
difficult to find out where it was
whether it was California or Montana or
or or some other obscure place you use a
service like Dropbox dozens of those
things would be very hard for you to
identify where your data is actually
stored but one email that you that you
that you exchange that for example that
I exchanged with my students and if I
store that on a server that was outside
the EU then potentially I'm in breach of
that legislation now can we all put our
hands in our hearts and say no we're
completely compliant with that
legislation and of course we've got GDP
coming in so I think that but I would
like to say to you firstly the issue of
access to data is really crucial and a
level playing field for small companies
and research institutions have access to
data that the currently only the big
silicon valley-based companies have it's
something we addressed in the review I
can't talk about it here but I'm happy
to come back when the reviews released
and talk more about the ideas we've got
we've got some quite interesting ideas
about how we can tackle that and I also
I think but I'm subscribed to the view
that we need to move to a point society
needs to
to a point where we take ownership of
our data it's still unclear what the
path to that is because that you've got
market forces and government regulation
and societal issues and personal views
to take into account on this path but at
the moment your data spread all over the
place I mean you talked about the
Facebook example you're absolutely right
but also I've got this data in Google
and Twitter and the government and
Amazon I mean it's data about me all
over the place and the digital me is
completely distributed and that's an I
don't think sustainable over time so I I
subscribe to but that hat so there's
lots of people working on personal
databases including its Tim
berners-lee's big passion these days is
you know the whole issue of how we
retain our personal data and then have a
contract with with the world just
through whatever legal framework to
allow other people to access that data
Peggy grandpa and Nick perhaps you'd
like jobs for this hmm
so I'm gonna take very specifically an
example of the NHS because the NHS is
kind of unique in the world in the sense
that it is such a large organisation
with so much potential data and I wonder
if in a hundred years time would we look
back and say this was a almost you'd
almost describe it as a natural asset
that we that we sold on the cheap at a
particular moment in time by releasing
data on a piecemeal basis by not
ensuring that we recognize that this is
an extraordinary deep mine of data and
and one that we could commoditize and
realize a significant asset from in the
future
I'm not sure what the answer is but in
terms of data as a something that is
valuable one off to have a big base of
training examples to trade an algorithm
that you cannot apply that might be a
limited shelf life in as much as there
are many other places where medical data
exists I think China just put up nothing
online for free some data set with like
one or two million health records or
something
so at some point there might just be
nothing the public domain if all you
want to do is to train your algorithm to
recognize x-rays of chests to see if
there is like some pathology that may be
incremental bit of data that NHS is
sitting on might not be valuable but
there is a different model which would
be that if you actually want to serve
the British people then obviously you
need access to their health data to be
able to sort of on a continuous basis
make recommendations to particular
people and in that model did this this
data retain salya and would create some
bargaining strengths that could be used
to get the deal with private writers
that that would get value for for the
taxpayer or for the patients in NHS I
would add though that there is also
another important way I think to provide
value to the citizen which would be
giving trusted partners access to this
data enabled new kinds of services
enabled NHS to provide quicker diagnosis
better paths through the medical system
better indications of what might be
needed dead rather than maybe trying to
tap every last penny of the economic
value of this if you could actually
provide better medical care and advanced
medical research through this maybe
requiring that companies publish some of
the findings
in scientific literature and so forth
that that would be another path to try
to eke out value from from this then
we'll go on to the floor the ship my
interests I'm treasurer have the
all-party parliamentary group and
artificial intelligence and my eldest
son Paul Croft is co-founder and
creative director have a cluster of
games development companies at which the
largest is media tonic I'd like to ask
about ethical questions how could the
ethical issues associated with
artificial intelligence best be
addressed should some form of regulation
be considered either now within the next
decade and if so what should this
regulation seek to achieve or would an
industry-led voluntary approach that
changes to corporate governance as it'll
be preferable and could you also comment
on the need to educate the next
generation of computer scientists in
ethical practices and what's happening
in universities it seems to me we're
still reaping the effects of a
generation of bankers not learning
ethics as part of their formative
education
I'd like some assurance about what's
happening in computer science
just I was president a British computer
science he wants and I can say
absolutely that if you if your degree
computer science degree is accredited by
the British Computer Society you have to
be teaching your students about ethics
it's really reassuring that I think
that's I think most degrees in the UK I
don't know folks for this point most
degrees or accredited by the BCS but
anyway that soon as you know we're not
[Laughter]
but I'm sure you do ethics the it is a
hugely it's a major issue i I think that
we absolutely need to instill in not
just in the students that we teach but
in in companies growing in this area
some sort of accountability know there's
a move in the EU Commission about
looking at algorithmic accountability
and as Mike said you it's very hard once
these are these algorithms are let loose
to unpack exactly how what they're doing
is the old old expert systems you could
in some way ask them how did you get to
that conclusion the way we're building
these things now it's very difficult and
I think all companies need should be
aware of their responsibilities in this
area because it's it's apart from the
ethical issues of what they're doing and
also the fact that it's very easy for
bias so my quote you want to comment on
that Wendy says I think if you do a
computer science degree in this country
you will almost certainly get training
on ethical issues the BCS code of
conduct the Association for Computing
Machinery has a more elaborate detailed
code of conduct which you can boil down
to don't do bad things when you write
computer programs think about the
consequences of what you're doing and so
on and we we as I'm sure they do in
Southampton we expose our students to
various different case studies and so on
and talk through the issues that these
case studies are eyes and actually again
I think it's a similar situation to what
I mentioned earlier those existing
codes of practice really cover a lot of
the bases and certainly it would be go
worth going back and looking again at
those codes of practices and saying you
know are there AI specific things but my
suspicion is they would be different
there would be different case studies
but actually the kinds of issues that
arise would be I think would be very
very similar so those codes of practices
are out there I think AI specific kind
of ethical guidelines I'm not convinced
is is something that's that's
particularly necessary I don't see I
think about more regulation at kind of
AI law I think no I think look at
specific areas health care the data
protection legislation that we have
these are specific areas
I think the insurance industry is waking
up to the value of all that data that
fitbit's and so on a gathering about us
and they can do some things which make
me slightly squeamish when I stop to
think but it's so looking at specific
kind of areas I think would make sense
but a general AI law I think my sort of
anecdotal observation is that there is
actually a lot of appetite in the
machine learning community in the
culture of really wanting to to see AI
be used for the social good like a lot
of technical people they are not really
primarily focused on maximizing their
income or providing a military edge to
whatever their country is going around
the world these conferences and there is
really a sentiment here that we want to
be responsible people and I still lack
of clarity exactly what that means but
but I think that the foundation is there
for this and so I think especially as
one is considering the longer-term
prospects for AI these more radical
visions of what will happen if if one
day this really succeeds I think it
might not be Turley to start to try to
articulate the vision for how this could
be for the common good and sort of begin
to bake in that commitment like it's not
something that is relevant right now
today I systems it's not the law that
we're going to put in place next year
but we are ultimately committed
ái this transition to the machine in
telling us era being bigger than does
something that would benefit one
corporation or even one nation it should
be something that benefits all of
humanity the Royal Society produced two
very good reports I'm sure you're aware
of them and the machine learning report
which we get to be used a lot for the AI
review talks about the whole scope of
this and their data governance report
which recommends a stewardship body for
data and there was a commitment in the
manifesto conservative manifesto for
data Ethics Commission these two out
these ideas haven't landed yet but
they're being talked about and I'm sure
someone will come and talk to you about
absolutely thank you happy and over to
Lourdes Holmes good afternoon I'd
declare my interest to set out in the
register let's turn to the international
collaboration question to what extent
should the UK be working with other
countries to shape the development of
artificial intelligence and should the
UK be looking to lead that debate or as
I imagine other countries got lessons
which we can learn from well so I
stopped I mean you've already mentioned
a bit about International and Mike said
we are in a very privileged position
here at the moment and I think we
artists it's a bit unusual but because
of the situation in the u.s. there is an
opportunity to grasp here there really
is no buddy running science in the US
alone
the Obama White has produced two very
good reports on AI which we have used
but this there's nothing really
happening there we it we need to
collaborate we all scientists want to
collaborate to move the subject forward
but this is also very competitive as I
think it was Mike said the demand for
the skills AI skills is huge from the
companies the salaries this is the new
big salary job you know the new this is
where people will go to earn to earn a
significant amount of money and it's
very competitive every country you
talked about the success of Canada but
Singapore and China and America the
companies in America based in America
ourselves other European companies are
all little for the brightest in the best
so it is very competitive so we need to
be able to attract the bryson the best
from everywhere to come here to train
and then to try and keep them here it's
really important the other thing I
wanted to say that if it fits into this
question but I saw a graphic recently
it's London has as many startups in AI
as every other European country combined
we need absolutely the appropriate point
to say that do that either of you two
want to add to what game where do you
had to say I don't think I could have
said it better so I have you were pretty
upbeat earlier on Thank You Anthony that
that rocket you want to come in Lord
swing for them a declaration of
interesting that I run a charity they've
elected Charlie on email to provide
specialist medicals advice to people
overseas other parts of the world that
we should not be working with for
security reasons I'm thinking of course
at the moment of time some of the
communist countries I thought you're
gonna say China who China China China
obvious and I
I mean I just I was out there week ago
week before last I was in China and
Singapore I'm on the advisory boards for
both Xinhua University AI and the
Singapore AI activity and I mean you
know the Chinese absolutely have set the
target of being the top in the world in
computer science for the next 10 years
absolutely have set themselves that
target and that includes building up the
AI so you know we have a huge the issue
at collaborating with China of course is
some of the security issues of sharing
data but they have huge amounts of data
to train algorithms on so it's an
amazing country and they are this is a
big area for them as that's the work
that's the country I'd first think
probably that's and I've got a very
quick one from by count Ridley I think
yeah just to follow up on the
international collaborative
collaboration point in the written
evidence from the future of humanities
Institute you said the UK government
could begin by making a commitment to
fostering a or a certain develop for the
common good such a commitment single
signal UK's leadership in AI governance
at subject cetera there's an analogy
here with what we did in reproductive
technologies with the Warnock report set
out a sort of right we've sorted the
ethical question we know what we're
doing we're doing it the right way come
and work here if you want to is that an
appropriate way to look at it you can
actually steal a march if you get that
kind of thing right I'm just gonna say
Lord Gideon's no that's fine and I'm
gonna ask get them to ask to answer both
supplementary z-- Antony did you want to
do my question ah no that's fine no
thank you
I'll just lined up for my question
though that's perfect okay so quick
answer to Vikon Ridley and then we'll go
on to Lord Gideon's
maybe not exactly in as much as I don't
think with a I kind of worked out all
the FX and can just put it in place but
I think there might be an analogous
thing that we could do which was be to
occupy the moral high ground and we are
here in the UK in a very strong position
to the debt in terms of research on
ethics and social impacts several after
the world leading maybe I should declare
a conflict of interest there but we are
active in that there is a group at
Cambridge deepmind is very engaged with
these issues up to the senior levels and
it might be a comparative advantage in
as much as if there is this appetite for
a lot of the reading research talent to
feel that they are working for
responsible and employers for good
purposes then being able to have this
parallel track not just of the technical
expertise but making sure we're gonna do
this right responsibly safely ethically
would actually I think enhance the
ability to make progress on the
technicals thank you quick response very
really I think one area for
International Cooperation involving the
UK would be in autonomous weapons and
I'm not talking about autonomous weapons
that look at a human being and think
this is Mike Waldridge he deserves to
die but actually much dumber things than
that essentially things like flying
landmines
I mean imagine that drone the kind of
thing you can buy for 20 pounds from a
local shop with a lump of high explosive
on it and it's got a camera and a
Raspberry Pi and the AI software simply
has to I I recognise a human being fly
around the streets of London when it
sees a human being not identify the
individual just that it's a human being
fly down there and explode so there I
think in the way that the international
community has to a certain extent steps
up with respect to land mines I think we
could do something similar and ask
ourselves about how we feel about
British companies manufacturing these
and selling them on an open market that
kind of thing I think there's a there's
a debate to be had there I think which
should be happy thank you very much
and the AI community is already trying
to self-organize in this respect thank
you yes that capability to do that is to
have some of you there now a smart
master student what are they I see I've
got we've got two questions to fit in in
about two minutes so I'm just gonna get
Lord sunjin to ask his question and then
I'm actually going to ask Lord Gideon's
also to ask his question and then we
have a a coder at the end to pair from
the three of you in a couple of
sentences hopefully it'll be quite
tricky as all sons and I'll be very
brief I declare my interests as in the
decoration interests and also until
recently an advisor to Silicon Valley
Bank professor Boston you mentioned
about the funding initiatives in Canada
and Dane when do you mention about we're
in the fourth and fifth wave of AI and
the limited amount of funding you will
reference to what's happening in
Singapore professor what did you respect
me about the need for more support in AI
startups my question is simply the UK
clearly need a much clearer strategy for
AI how should that be in how should have
be promoted and then log Ian's your
final question well I have no interest
in you Claire apart from being an
academic economists and sociologists
interested in the digital revolution and
my question I won't ask the one directly
on here because it's more or less been
covered I think but I'd like to ask how
you think it's possible for people like
me to work with people like you because
it seems to me there's a divided field
you've got the experts in the
technological areas then you've got
other people working outside pretty hard
to get effective collaborations between
them and it seems to me really important
that we try and do that but I think it
was a really informative session I'm
sure everyone is very
grateful thank you and I will actually
ask you simply to say what you think the
most important thing that should be done
is actually I'll start with you
professor wasn't no but I think that I
think it still needs asking at the end
of the session yeah so I think in terms
of developing some kind of national
strategy one could look at examples like
the Canadian and see what one can just
derive from that I think in addition to
government funding I think they also
know I'm not sure all the details but
facilitating these industry academia
collaborations some of this funding is
coming from industry I think enabling
say the government data sets to be more
accessible in a responsible way so with
the NHS maybe having people in
government or in IHSS or have some
competence in this area so that they can
help facilitate and the application of
these machine learning advances to to
provide better services and I think for
that relationship to work that needs to
be people who know their stuff on both
sides both on the industry side of
course but also somebody who can kind of
carry the public's interest and and have
some technical expertise and then
finally emphasizing that this parallel
track of in addition to securing kind of
the lead in technical capability and
entrepreneurship also doubling down on
being a kind of leader also in the
morale space with a vision long term of
AI as being for the public good
so we've wrapped up the answer to all
three questions in your answer game
Wendy so three points firstly yes the
government needs a strategy and I hope
when you see the review you think
there's the beginnings of that strategy
there and I'm happy
come back and talk to you about that
secondly I don't necessarily having the
most money is not the best solution it's
like the toss in the hair I think
spending that money wisely is the most
important thing and I hope again that
we've put some suggestions into the
review about that and finally in terms
of translation you're not going to put
people like us in front of the general
public and say this is AI well of course
we can all do our outreach lectures but
I mean talking at the level we are here
you know that there's some very clever
journalists so coming up next who can
help with that that translation lovely a
very good segue into the next session
thank you I would say I think my just by
wrapping up comments would be I think
what we need to do is is to leverage the
UK's extraordinary position it is a
really extraordinary position that we
have right now we should do everything
that we can to get the most out of it
for the country and I think concretely
what would I recommend build capability
I said this earlier I think we need
capability that's not the same as having
people who can program they need
higher-level skills than that these
machine learning startups are not based
just on programming skills it's people
with master's degrees PhDs and so on
support and nurture the startup culture
which we've already talked about today I
say we have an extraordinary startup
culture in the UK we should do
everything that we can to nurture that
and not drive it away because it is very
very very fragile I think there's
another a whole set of different debates
which I'm sure you will discuss around
data and leveraging the data that we
have and doing that in a responsible way
but that's a that's a potential real
source of economic growth as well but in
short leverage the UK's extraordinary
position that's what we need to do well
thank you very much indeed
I'm afraid it's been an incredibly
high-speed set of questions but that
you've given some very high speed
answers so it's been very satisfactory
all together and I hope that then when
you go to catch your plane as a result
but thank you very very much indeed we
really appreciate your your coming today
thank you suspended
the proceeding is currently suspended
the proceeding is currently suspended
the proceeding is currently suspended
the proceeding is currently suspended
the proceeding is currently suspended
the proceeding is currently suspended
the proceeding is currently suspended
well a very warm welcome to our media
witnesses we have ser O'Connor
Rory Eccleston Jones and Andrew lot ski
thank you very much indeed for coming
today
I should just remind put it on the
record again the sessions open to the
public a webcast of the session goes out
live and will be subsequently accessible
via the parliamentary website a verbatim
transcript will be taken of your
evidence and this will be put on the
parliamentary website and a few days
after this evidence session you'll be
sent a copy of the transcript to check
if accuracy and we'd be very grateful if
you could advise us of any of the
corrections as quickly as possible and
if after this session you wish to
clarify or amplify any points made
during your evidence or have any
additional points to make you're very
welcome to submit supplementary written
evidence to us and perhaps we could
start off by asking you to introduce
yourselves to us starting with them
Andrew Orlovsky yeah
senator lofty I write for recycle
register I've been a technology
journalist for around 20 years 70 of
which was in the Silicon Valley my
name's Sarah Connor I'm the employment
correspondent at the Financial Times
I'm Rory Katherine Jones I'm technology
correspondent the BBC has been lost my
career in covering business and came
into towards technology in the late 90s
during the dot-com bubble and have been
doing it full-time for the last 10 years
thank you well we're going to kick off
with a sort of fairly big question
really what in your opinions are the
biggest opportunities and risks
associated with AI over the coming
decade should I start with you Andrew
I've agonized house--it certain you want
this question Dame Wendy left and she
said she'd hoped we'd give a fantastic
success story of Britain and AI I think
one of our jobs as journalists at least
is to ground things in reality and I
think we've been very complicit in
creating the kind of dream world or
fantasy world in 20 years of writing
about technology this is a very unusual
story in that almost every time the
technology industry pushes enormous fan
Fahrenheit this is one which really
started with opinion formers wanting to
talk about employment not directly
answering the question but I'm trying to
in the expectations of AI that we may
have heard earlier today far exceed what
we could be seeing in five or ten years
and so I am NOT a technology journalist
I'm the employment correspondent so I
kind of came to AI and come to it
looking on it through the lens of what
does it mean for the labor market and
clearly the opportunity the potential
for AI is that it could mean a step
change in productivity I'm sure you all
saw the Office for Budget Responsibility
is latest updated forecasts we have
terrible productivity in this country
it's a massive problem basically if you
don't have productivity growing in a
decent clip then you can't have
sustainable increases and Livingstone
and so being able to do things more
efficiently to be able to create more
economic output with the same amount of
people is obviously really good news so
that's that's the opportunity really and
as for the the risks I mean I think
there are more than one but the big
question that I think people in the kind
of economics and labor market world are
thinking about is how how will those
gains be distributed so if if indeed AI
leads to vast increases in efficiency
using fewer workers then does that mean
that all of the kind of wealth that's
created from that will go to the people
who own the AI the intellectual property
the data that feeds into it if so what
does that mean for the people who might
be displaced out of jobs
will there be new jobs to replace those
old ones and if there are will they be
of the same quality so I think those are
the that's the main risk thank you yeah
I slightly echo what Andrew has said
although perhaps not not in so extremal
way there are trends in technology and
trends in technology journalism and I
think it's Deloitte's that produces
something called a height cycle where by
technologies go through this sort of
wave and they reach a peak of hype and
then they amount they they fall into a
slough of uncertainty and then they rise
again into sort of fulfillment and we're
possibly at the peak height stage I I
look at my inbox every day and five
years ago it was all about big data
three years ago it was all about the
cloud and and now it's AI just picking
out a couple a I wearable solutions for
ageing population this is popped into my
own box Lloyd's of London signs
first-ever a ideal in a decade a
significant part of the insurance
industry will be powered by AI Welsh
artificial intelligence firm has
produced a report in to North Korea's
bio weapons capabilities so all sorts of
extraordinary claims being made for AI
now that's not to say that this isn't a
time of great advances I think we've
seen
yeah the people who've been in this
business a long time in the a our
business will talk about AI winters they
came out of a winter about five years
ago and began to find ways of harnessing
the huge stores of data to which they
had access to new algorithms and and
have produced some interesting results
and you think of all sorts of
possibilities that could come from this
you know more effective ways of treating
cancer organizing the way cities work to
minimize congestion improving the
delivery of education but I think there
is possibly a bit of over-excitement I
heard the distinguished scientist sort
of disagreeing about for instance how
quickly we're going to get autonomous
cars on the road and I think that that
is the area of of risks I feel partly
responsible for the hype in that three
years ago I did an interview with
Stephen Hawking in which he said that AI
was likely gonna kill us all in 40 50
years time I think those countries what
we're trying to do attribute blame yeah
yeah I think I think those I don't think
we probably need to worry about those
those kind of issues in the near term we
do need to worry about things like bias
in algorithms being built in and and
about you know what sort of
infrastructure we need to make things
like driverless cars work I think we've
been far too optimistic in in thinking
how quickly we'll get there that's very
useful because there in a sense you've
gone from talking about the hype side to
the limit limitations in a sense I mean
Andrew do you agree that there are I
mean one of the reasons for your being
rather skeptical is because of the
limits the limitations with AI currently
I think so I mean it's important to
distinguish AI has spent most of its
history in ignored and and derided
and as Rory says he gave great long
winces and then was the summer's day and
then everyone drifts off again and
they're not interested anymore but
there's one enduring paradox was coined
by wrote offices to add some more about
30 years ago where after a I had already
been research for 20 or 30 years and
moravec pointed out that it's relatively
easy for a computer to play adult level
games but is extremely difficult to
replicate the perception of mobility of
a one-year-old now to me this is the
biggest discovery looking at this
current AI high which is that until
about 1930 seventies robots were an
expression of AI but today the machine
learning community and robotics
community existed in the state of
antagonism the machine learning people
say your data's dirty this real-world
dated we want nice clean data and the
robotics people say well you isn't ooh
too slow there too messy they don't stop
is hitting an old lady crossing the road
now this is why I conclude that huge for
huge leaps in productivity from AI we
need a huge lease qualitative leaps in
automation we're getting great advances
little by little every year but it
doesn't involve the one big innovation
of the last five years machine learning
thank you are you conscious of the hype
aspect Sarah I am I'm very conscious of
it and the way that I know that it's
true as partly as Rory says the sheer
volume of press releases that come into
your inbox and I suspect lots of things
that five years ago companies might have
described what they did is big data or
data analysis and they've just simply
rebadged what they do is AI because they
know that it's sexier and that
journalists are more likely to open
their emails if that's what the subject
heading says and the other way that I
know that it's overhyped is that if you
ever write an article that has robots or
artificial intelligence in the headline
you're guaranteed that it will have
twice as many people click on it people
are just really interested in this topic
and I think that's not to be sniffed at
I mean if people are interested then we
as journalists have a responsibility to
tell them about it
but I think for for some organizations
and I wouldn't include the FT in this
there's probably a temptation to kind of
chase the click
and so the more you can write and
probably the more dramatic things you
can say about it the more clicks you'll
get and therefore the better you'll
think we are warned Lord folly you
referenced productivity why is it do you
think that the very significant
investment in digital technology
computers over the last five in ten
years it's a really good question and
it's a I mean that's a puzzle that is
taxing the the best minds in technology
and economics right now I mean I think
there's a one possibility is that it
simply lags and then actually if you
look back through history at the
introduction of big impressive
technologies actually the point at which
it is adopted and people figure out how
to use it best in order to boost
productivity it just takes some time so
it could be that or it could be that
we've simply maybe we've become more
efficient at some things and we found
other pointless things to fill up the
rest of our time thank you
to look at the nature of your audiences
and how they respond to that to the
pieces or them that you write about on
on our AI and particularly do you see
difference in the understanding of the
risks of AI between the more mature and
the younger audiences I think it's
difficult to know we don't put out a
piece on the 10 o'clock news or write a
piece on the website and then send
people an exam to see what they've
understood and what they haven't we it's
one of those things that journalists
rather arrogantly think they know they
they we think we know what's interesting
we think we know what's a well sold
piece that will fascinate people well I
would I find more more difficult to do
on on particular on high-profile outlets
with big audiences is to actually find
an excuse to tell the long run story and
you know daily news outlets a very
event-driven you might go down to the
editor of the ten o'clock news and say
listen a is going to have a nice huge
impact on health
care and that person will say yeah but
what happened today so I think our job
is to find ways of getting arresting
stories that tell the longer-term story
in in accessible ways without either
hyping or under estimating the the
impact of the technology if you have a
slightly different sort of journal
though don't you Andrew people will seek
you out to read about AI were there yes
I mean we were all misled the British
technology to me who she goes and I
think they're out there are very
experienced audience naturally skeptical
because I think the right way to
approach artificial intelligence is
through skepticism
there's let me give you an example to
risen I'm not aware of one self-driving
truck that can park so now to me if all
the truck can do is drive along their
clean lane straight nice clean road in
sunshine or too much sunshine in nice
weather for a few miles that's exactly
what cars on the marketplace do now
that's not all Thomas a semi autonomous
in the vehicles we have today are
sending autonomous they have lane
warnings of the driver and so on but I
think the desire to anthropomorphize is
is everywhere in AI it sits there in the
term learning one of the great British
computer scientist Christopher straight
she really objected to the word learning
being used for this because he said
they're optimizing to optimizing
themselves slightly they're not learning
learning assumes that it will reach a
certain level then it will be able to do
everything that he was sent to do Sarah
do you have a perspective on this so we
can't really segment segment the kind of
response of our audience by age as such
but I would say that when I kind of read
letters that have been sent in after
I've written about this or I look at the
comments that come in under the Articles
I would say probably more than half of
our readers are really worried about
this so I think rather than perhaps
you're you know the kind of technology
audience might be quite excited but I
think a lot of my readers worry about
the
applications and particularly the
economic implications there are lots of
people as soon as you write it by a eye
that will instantly start commenting
saying this is why we need a basic
income you know the capitalism is going
to eat itself I think there are people
that are sort of looking very far ahead
and reaching slightly scary conclusions
we we did a sort of AI week a couple of
years ago and the most popular feature
was a rather inventive graphic which
allows you to ask with a robot eat my
job and put in your um your various
professions I think politicians came out
and Kay and barman pretty well but
luckily the accountants are doomed
because the journalists but I mean
there's an interesting point that the
the data that went into that that
graphic came from a an Oxford study
which has been very widely quoted over
the years which said more than 40% of
jobs are potentially at risk over the
next 10 to 20 years that data has itself
been questioned I think by the OECD who
brought it down to a figure of seven or
eight percent so perceptions are
changing pretty rapidly here
thank you okay good you wonderful I've
got a bike out Ridley and I've got a
lady Bakewell trying to reconcile the
extreme skepticism of u3 with the
extreme excitement of the previous three
and I know I'm exaggerating but that I'm
a journalist I'm wondering and I'm
thinking of Amara's Lord you know
Amara's or Ray Amara a computer
scientist who said in the short run we
overestimate the impact of new
technology but in the long run we
underestimate the impact is that
possible is it possible that that's what
we're seeing here that you guys are
gonna be right in ten years but
Professor Wooldridge is gonna be right
in 20 years I think that's entirely
possible I mean I I've come across as
very skeptical and you know I think we
as technology journalists who've who've
been bombarded with this tidal wave of
hype kind of recoil slightly but on the
other hand we also like to excite our
audience
so we're split on this and and
definitely that sort of is the term
presbyopia does it does apply to
technology and and you know we've seen
for instance the smartphone revolution
over the 10 last 10 years we just happen
much faster than many predicted so
perhaps we're wrong about how rapidly
this this one what really strikes me
though is how rapidly software is
advancing and how slowly hardware is and
in fact we're going backwards you know
to 10 15 years ago I could fly to New
York in three and a half hours on
Concorde in Victorian age they built a
railway in five years and and there's a
there's a big divergence here are
chasing audience is now the BBC as we
know is desperate to recruit young
listeners I wonder whether you yourself
have a arenas in which you can use
extremely simply worded explanations
intended for younger generations does
that happen on Cravens Newsround for
example I mean does that kind of speech
occur in your profession well I think we
to be honest have the opposite problem
in that you know you know there is there
is a great appetite and perhaps an
awareness of this amongst our younger
audiences and this is one of the few
areas of our coverage where that is not
so much a problem this is seen as
something that reaches out to young
people
I wondered about the simply the
simplification of things so that mass
audience can understand is that possible
I think it is possible and in a way
that's our jobs as we sort of sit
between those guys and the general
public and I think our job is to
understand enough of what they say that
we can sort of translate it into plain
English but in a way that doesn't
simplify and actually loses some of the
reality and there's that's a really
difficult job that's difficult whether
you're writing about economics or really
any sort of
located topic but I mean there it is
what we should do maybe we don't always
get it right but I mean at the FT
clearly we don't have many young very
young readers but but we do yes but we
do I mean you know what we try and do is
write something I always try and imagine
could a kind of intelligent 18 year old
understand this someone who has a decent
grasp with the English language but
maybe doesn't know anything particularly
technical yet so that's that people
clearly react to your articles too I
mean you mentioned earlier that you know
they get they come back at you on that
absolutely ready yeah yeah which is good
law didn't discuss I mean from what you
said so far I mean the digital evolution
has really transformed journalism in the
most extraordinary ways lots of
newspapers would find it difficult close
to difficult to survive you've got
massive platforms some of them organized
through box rather than people this is
very widespread has a massive impact on
politics so what you're saying to me
sounds a bit sanguine against that
backdrop because this is surely changing
the very climate the climate in which
journalism works and transforming the
whole business in ways which we don't as
yet fully understand and which are only
some way through probably yeah I I mean
certainly in terms of the impact on
journalism I mean it's whether you wear
AI comes into that
yeah the digital revolution has
obviously transformed journalism and and
for many people not in a good way and
there's a long hunt for sustainable
business models there's the recent
arrival of the Fate news phenomenon and
the what some might see is the malign
power of giant not media companies like
Facebook and Google I'm gonna interrupt
24 oh I love breaking news which is
really pretty recent and we just don't
know what that does to people's
consciousness yeah yeah available
everywhere
immediately yes I suppose we as
journalists don't necessarily think day
to day about our impact on the psyche of
us except I hope that I hope for
heaven's sake that they're watching and
listening straying well beyond AI and
this point but Andrew just a quickie on
line is healthy at the moment there's
far fewer journalists and they used to
be and maybe we incentives aren't there
to do long term kind of long term pieces
but I think one of the one of the ways
we can act is whether market is
particularly porous titles like us where
we act as a kind of bridge we know the
technology community very well but we
can't translate it to a it doesn't get
picked up by the wider audience because
they've got so many other things to do
just one example Geoffrey Hinton who's
the father of machine learning really
the one big breakthrough seen in four
years time but a month ago he said we
need to rip it up and start again to
achieve what's now accept expected it is
two or three titles say that the
technology of East business titles
picked it up in the state size but it
hasn't gotten to the mainstream yet
alright so thank you
this builds on what I asked before
should the efforts be made to improve
the public's understanding of and
engagement with artificial intelligence
and if so how and could you answer
beyond journalism I mean how are we to
do
broadcasting I mean where are we to take
a government effort to expand public
understanding or indeed just social
effort Universal academic effort where
can it come from so to begin with I
think you know journalists clearly have
a responsibility to do that and I think
that we have you know we have a
difficult balancing act because we don't
want to fall into the hype trap but we
also you know as one of you was saying
we don't want to underestimate what
could potentially be really important
and so we we need to try and get that
right and that's not always easy
and I mean one way to do it that I've
tried to do is to give readers a sense
of what's really actually happening now
so rather than simply report on these
various studies that Rory mentioned
about 40% of jobs might go no it's 50
you know it's 10 you know basically
nobody knows and there's only so far you
can go with that so I try to go out and
meet people who are using AI now and
figure out well what does it mean right
now how does it work what are the
pitfalls and and just on Lord giddens
point about the impact on journalism
I actually last year challenged an AI
journalist to a journalism battle scale
of alphago as well I wouldn't put myself
in quite that intellectual category but
that's sort of that's the idea of that
is that it's fun and it's engaging and
people want to kind of read about it but
also that it's a genuine it's an attempt
to get to grips with where are we right
now and how much further do we need to
go before we should really worry and for
me a lesson of that battle was that you
know I definitely won and that for the
time being I don't think we do have to
worry about AI replacing journalists do
we want the public at large to be better
informed yeah of course I mean um by
expanding it better by having more
intermediaries who can speak the
language of the technologists and also
speak human and maybe kind of get the
academics out and about Morton and teach
them how to communicate in plain English
we are always trying to find good
communicators amongst the the technology
community which is can be a huge
challenge you actually had three pretty
good communicators on before us who we
we try to put on air a lot but I mean we
I obviously see it as a public role to
educate but also to entertain along the
way and I think we couldn't be careful
about being preachy about this saying
you know you've a duty set up to sit up
straight at the back you
learn about this I think we could be
honest you know III think a more
important role certainly for government
is is in in preparing people from an
educational point of view for these
challenges
I've been reading extruding but called
Janesville about the impact of a town in
America on the closure of a motor
manufacturing plant and what they found
is that quite young motor workers made
redundant car workers made redundant in
their 30s were completely incapable of
going through or starting an educational
program because they didn't never use
computers there's still quite a lot of
people out there who are uncomfortable
with the computers because when they
were at school that wasn't a big thing
so I I kind of think along with you know
a public education program which sounds
slightly question yeah anything that
then that's even this position of a
contrarian again once again but the
children my children go to an
outstanding primary school in North
London they get taught they taught
algorithms every week but they took now
tour history once or twice a term and
are maybe once or twice a term there's
not machine she cost there's only so
much time we can do educating with
people and I'm just question the value
of teaching them algorithms yet that's
probably part of the parents curriculum
but if they don't know culture and
history how can they account for the
world how do you account for China's
relationship with career it's
complicated and cultural and historic
you need those things probably more than
you need to know how to use a computer
you're slightly echoing something that
Dame Wendy said earlier that she taught
some of the creative skills were going
to be needed in the future as well as
those technical skills thank you Tom
Lord Swinton I run a charity that uses a
secured system to provide specialist
medical advice
to doctors and other medical workers in
77 different developing countries but
I'd like to ask you do you believe the
media is generally covering develops in
artificial intelligence in an accurate
and responsible way and how could this
be improved that is that is a biggie I
mean given how broad our media is and
how vibrant it is still whatever the
challenges in this country it will
it ranges far and wide from killer
robots are going to eat your lunch too
you know learning disquisitions in the
pages of the FT about complex Studies on
the patterns of employment so I would
say this but I think when I look at the
stories we do at the BBC I did a quick
search the weekend we had a story a day
from various parts of the world a story
about Chinese peach farmers who brought
in AI experts from Beijing University to
help them sort peaches more quickly
stories about the impact on women as
opposed to men of advances in automation
I think we're doing a pretty broad and
generally sensible job with the
occasional bout of alarmism I I thought
it was almost a concept of exciting
skepticism which we had earlier you know
from you I think Rory which is quite
interesting Sarah pretty much agree with
Rory I mean the the quality of the
reporting on a I varies from media
outlet to media outlet much as it does
on every other topic so if you read the
tabloids you're not going to get a
massively subtle view of the impact on
AI but you ain't get a subtle view on
anything else either probably and I
think there is a lot of really good
reporting that's out there but one thing
that I'm conscious of is that
and even when you want to do a good job
and be responsible you do have to take
the time to really really understand how
it works and get into the nuts and bolts
of it and that's you know that's time
consuming and journalists don't have a
lot of time so sometimes it's easier to
sort of skim over the details and write
up there they're kind of big top lines
but I've been trying to make an effort
to actually sit down with people who do
AI and who create AI systems to to make
sure that I really get what I'm talking
about
earlier in which I thought we were
creating if I kind of fantasy world and
we weren't reflecting that the
limitations are very real limitations
that robotics is going to progress at a
very steady rate it's nothing we don't
not gonna see a giant step change Rory
refer to a doubts cast dollar employment
report and I don't know if we have a
equivalent in Britain of this wonderful
American phrase check-kiting which
refers to a kind of check fraud where
the checks constantly signed but the
funds are never there in the in the
account and the report P referred to
quotes written of the primary source for
that most quoted and I think in Google
is the most quotas reports on employment
1,300 citations is a book in 2011 by Ben
Olsen and McAfee so that's the primary
source
Bruno than McAfee other source for
things improving exponentially today new
book quotes james martin report it's
beginning to look very very circular
you want to ask the supplementary yeah I
don't think so um I mean who do you
think this is tricky question who do you
think is leading the field in terms of
anticipating issues and communicating
them ski definitely we wanted a bit of a
love-in yeah yeah yeah are you talking
about journalists or I think I was in
the media broadly well to be honest I
think maleic Lee - the best communicator
in this whole area is Dennis hassabis
from deep mind yeah who as you know is a
very engaging and obviously brilliant
and interesting communicator I it's just
been a film a documentary made about the
alphago so thoroughly yes yeah and you
know whatever you think about the pace
of this innovation you know he is
probably if you if you were to ask the
public and not many of the people I'm
sure would quote any name I would have
thought he was the best communicator
around the subject but Andrew had you
respond to that flattery from your yeah
well I'd agree dennis is a phenomenal
showman but we need more with the
showmanship really for this and then we
must remember these are games and as we
were saying 30 years ago playing games
is fantastically easy and impressive but
if we're talking about productivity
gains we need you know a robot and it's
a fine aim a robot like this process the
dirty dater of the world and make sense
of it and we make much less sense of
data than they're the names I scribbled
down were Jaron Lani a who knows his
stuff he's using writes very well-read
there's a tremendously and realistic
sceptical piece by Gary Marcus he's a
science writer a neuroscientist it also
has his own I think use head of a I
thought Hoover and Ian bogus writes very
well about
he's not a technologist but he's a
professor in Georgia Sarah do you have
any favorites in this area so in the in
the sort of world of work which I guess
is where I focus I would say that the
people who are doing interesting things
are really the sum of their think tanks
that sort of sit in that public
journalism facing space so the
resolution foundation has done some very
thoughtful
quantitative research at the Royal
Society for manufacturing in the arts
let's just put out a very interesting
report Andy Haldane the chief economist
of the Bank of England another very good
communicator he's starting to think
about that now and there is some
economists at the bank that are doing
some sort of decent work on the impacts
on the labor market so those are the
people I would say great thank you very
much Joan quick one for you what's the
impact of these great fantasy films and
television series entirely fantastical
but they encouraged people to think
about AI don't they you're probably
right I would imagine that films like
x-men you know and what was the Channel
4 series was equal human human dreams
whether that that no yeah but there was
there was a kind of more populist drama
about people that acquiring a set of
domestic robot that went kind of they
made human as humans I'm sure I'm sure
actually they for good or ill have a
greater impact on public understanding
stroke fears stroke interest and
excitement in this subject than than we
can happen you know
thank you that's not a crime and if I
count Ridley it's not your job to write
government policy but we did ask the
other panel this question and it's worth
asking you what is the government
currently doing enough to maximize the
opportunities and minimize the risks
intelligence if not what law could be
done well as you say it's not my job to
advise the government but III would look
at to it two areas ensuring that we
continue to be a place where this
research happens and we've heard you
know how strong we are and you think of
the people who had SwiftKey the people
behind deepmind but also thinking about
the implications of the design of our
cities in terms of if this driverless
car revolution happens about which I am
pretty skeptical but obviously will
there will need to be a lot of work done
on rules about insurance rules about you
know how people drive what stage are we
going to allow people to take their
hands off the wheel it's a strike me
that we are frankly doing them pretty
well that we are thinking about it
actually the fact that you're having
this inquiry suggests that we are
thinking about it pretty strongly and
possibly faster than we on this side of
the table might think quite necessary
yeah I sort of get the feeling that
governments at the stage of trying to
figure out like we all are how seriously
to take this how far along the track are
we I mean government probably doesn't
know any more than the rest of us on
exactly where this is going and I mean
my feeling really is that obviously you
need to start anticipating and thinking
about what the impacts might be but you
can't predict the future and you don't
want to put in a solution too quickly
that actually isn't the right one and
but one thing that I think government
can know now is from the labor market
point of view which jobs are definitely
gonna continue to exist which jobs are
we going to need in 10 years time in 20
years time and it's actually really easy
to do that I can tell you now that one
of the ones we will definitely need is
social care work
health assistance people to look after
people robots will never be able to do
that doesn't matter how good they are no
I think should we really want them to
and so if I was the government I would
be thinking okay these jobs are going to
be more and more in demand because the
population is aging AI is not going to
solve that problem for us so if more and
more people are doing these jobs how do
we make them good jobs that people can
build a life on because otherwise we'll
end up with an awful lot of people doing
jobs that actually I don't think can
really sustain them in the long term
thank you Andrew that little briefly as
he as you know - terrific system is kind
of different than slightly more subtle
so in my risks column I've have
liability issues where nobody actually
carries the camper sort of things and
very specifically the Silicon Valley
ideologies if that can't own our own
data so these are quite subtle things
how would a government plan for that
well I think it's Rory said you've
already thought about this a lot I just
should caution that in the 1980s know
Japan put an enormous amounts insert
into artificial intelligence only to
find it was a complete waste of money so
one suggestion around that is red teams
you may come across the idea of red
teams when you really have a kind of
almost a professional naysayer within a
leading a group of a project who points
out everything that's wrong and probably
the world's most annoying person is the
journalist should be doing that back in
Cleveland we love this dream world we've
constructed if you you're sort of
watching yourself a job there Android
Lord Holmes and then Lord Holly so
interested it's a commonly held view
that you seem certain that AI robots
where they won't be able to do certain
roles and particularly in the caring
field but I'm not suggesting that they
will I don't think well what evidence do
you base that certainty on
um just health okay two things one just
where the technology is now so to look
after someone you need to be extremely
dexterous you need to be able to help
someone get out of bed you need to be
able to hold them gently without
bruising them I mean these are all
things that robots I mean with all my
robotics now rather than AI but robots
are just not capable of these things I
mean there's a reason that we have low
paid migrants flocking soft fruits it's
because robots crush them they just they
don't have they can't do those sorts of
things so that's the kind of physical
side we're really far away from that
I mean robots can't tie shoelaces they
just can't do these things that unique
human hands and and then on the sort of
emotional side I think part of looking
after someone is actually kind of being
a human being and showing them some
compassion and I you know AI is nowhere
near being able to replicate that green
I I went to an event last year where a
chinese robot sees was showing off
fantastic robot with an incredibly
lifelike face and gestures and he said
this is going to be used in care homes
and it's going to be particularly good
for people which is treating people with
alzheimer's because it can listen to the
same story a hundred times and not not
lose its rag and I actually found this a
rather horrific vision that we would we
would think of putting that kind of
device in a home thank you Lord Holly
yeah
our session witnesses describe
themselves as reasonably sanguine about
the issues of privacy and the issues of
exploitation of the data I think
professor Waldron said that he felt that
the law was adequate do you share that
view or do you share the view that many
have the concerns around privacy and the
exploit exploitation of data sets unduly
favors sort of digital mega corpse I
think these are well-founded concerns
mentioned in my last answer if there's
one consistent kind of political thread
that comes from Silicon Valley it's that
they wants to exploit data first
you know virtual property or
intellectual property and it's got to
the stage where I think the incentives
are so lined up with large Silicon
Valley companies is that they don't
think of it as a property based market
where that that data is traded now when
you get into the area of health data
that becomes it's not an easy subject it
becomes a prickly subject but if we
remember that the individual is
sovereign here they can have contractual
relationships with the private sector
with the state but the individuals
sovereignty is kind of paramount here
that's probably the basis to proceed
if we go any other direction I just see
a disaster for example I mean let me
give one example at slightly concrete in
soft in software it's possible to use
data on a some model some licensing
models quite freely so a teenager in
indeed in their bedroom can play with
the data but since it starts to be
exploited commercially and has value to
the user then they pay for it that seems
quite a royalty so that seems quite a
conventional idea that we've never
really tried with data maybe wendy is
looking into elementary
if an airplane flew over your garden you
had a right to a fee from it we kind of
had to you know that was never gonna
work like was it other not unrealistic
aims around personal sovereignty here
that we have to grapple with there are
and I mean there's also the idea that
that information doesn't have value
unless an algorithmic company is
processed it's it's meaningless it's it
doesn't have value so therefore that
company should exploit it and I think
it's a case of where the individual
ought to be able to not force a plane
off its route they also be not able to
say you're not going to use this data in
this context because I have I don't want
my insurance company knowing this where
do you stop if you if you if you have
the most optimal system in which the
individual sovereign rights negated
somehow then there is absolutely no
privacy we have to find a balance
between the two thank you we will be
exploring those just another
supplementary on this point I mean this
government engage with you on issues
relating to a I mean how much chewing
and throwing is there in in in terms of
engagement well I'm trying to think
whether I've welcomed a lot of turn in
frame with government on this on this
subject or not I mean not not much but
then I've not sorted out I have to say I
was invited by the Treasury last year to
take part in a kind of labour market
conference day where AI and the impacts
on the labor market were one of the
things that was being discussed that's
probably the most engagement I think
I've had with government oh yes yep good
okay we settled that one then right and
over to Lord Gideon's I'm supposed to
ask you about impact on labor markets
but you've been talking about all the
time so I'll put it in my own inimitable
fashion yeah you have these amazing
sways of changes before right seventy
percent of the adult population works in
Agricole
so now 1% amazing 40% of the labor force
I don't know the source abuse to work in
manufacture now 9% is in this country 8%
in the u.s. amazing now you've got
mostly a white-collar service economy
the question is how far will it really
be invaded by especially AI and what do
you make those consequences as to
government policy for the future what
should government be doing now because
to me this is very real you mentioned
Carl phrase study in Oxford where the
47% figure was just an analysis a job
breakdown analysis it wasn't a
prediction of the proportion of people
who reduce their jobs but to me if this
is really don't know territory people
make do you know just like rehearsal in
the previous people we're talking to it
just said all new jobs will be created
what it's possible but really it's don't
know territory it's moving so fast so
what exactly should government do what
kind of policy recommendations would you
make for example let's say a different
sex than labor force because you
obviously gonna get much higher level of
job churn then you've probably ever had
before I think in service and
white-collar jobs then it's bound to
invade professional jobs - I mean yeah
and so yeah I mean your statistics about
the proportion of people used to work in
agriculture and that sort of thing
I think they're kind of useful to remind
us all that normally what happens is
there are these technologies that change
everything and that new jobs are created
you know the employment right now is as
high as it's ever been and even though
no one works in farms and not many
people work in manufacturing so I think
it's still plausible that new jobs will
be created but you're totally right that
it's don't know territory that we just
don't know and what's different I think
part of the reason to be honest that we
all are sitting here is
actually people in blue-collar jobs have
been disrupted for decades but the
thought that it's going to hit the white
collar middle classes I think is what's
got a lot of people skinned it um and it
is it is already happening and I went to
see a big lorry because these really
jobs left yeah partly that and partly
because it's us now right I mean I think
let's be honest I think that's part of
where this this sort of sudden set of
fears has come from and so it is
starting to happen I went to see a law
firm recently that's developed an AI to
do effectively to kind of automate the
due diligence stuff that they do when
there's a big M&amp;amp;A transaction rather
than having 20 junior lawyers sit in a
room for two nights drinking red bull
you know eyes like this reading through
every page the AI will scan through look
for things that it thinks looks
potentially problematic and then give
them to more senior lawyers to take a
look at so that you know that's the sort
of disruption that's already beginning
and you can see that that will continue
I mean for the government my big
question with this is what do you do
about training and allowing people to
cope because we can't predict the future
and but we probably can predict it as
you say there'll be more churn and that
people will need to adapt more quickly
so you know do we need to think about
giving everyone some kind of personal
training budget that they can then spend
on Reese killing themselves I mean those
ideas have been tried out in the past
they haven't always been successful but
I think rather than trying to predict
where the economy is going which is
always a mug's game trying to think how
do we equip people to be as resilient as
possible to the changes as it's probably
the best way to go thank you any
addition to what Sarah said only that I
think we will as well as these
forward-looking studies there have been
a couple of looks back at what's
actually happened over the last 20 years
and what we have found is is you know
not entire professions wiped out
but though then changing the tasks
certain tasks being worked and that the
law is a perfect example we might like
to imagine that lawyers will be wiped
out by automation but it doesn't appear
to be happening that the dull work is is
not sure I approve the dull work is
being done increasingly by machines but
they are finding new things to do and
there's the the classic line about bank
tellers in in America which I've not
quite sure where it comes from but
apparently there are more bank tellers
today in America than there were 20
years ago despite the arrival of the you
know the ultimate you know the the the
the cash machine and so extremely
important not the same as net new jobs
don't you know because such high level
of job destruction now I think Sarah's
point that this story kind of took took
life because it was middle-class jobs
that were under threat is a really
important one I mean you've essentially
created that where we are today with AI
and Dai panic if you like that of today
I've got just a dumb case really
interesting here that that we have
nobody's mentioned universe Universal
income which has been proposed by
Silicon Valley leaders as almost like
the saying when we were creating this
problem for you but oh look we've got
this solution I'm relieved not to hear
it cuz I think it's a very premature
debate to have now you know there are
huge implications for social mobility
and so on if you expect everybody to be
on the dole their lifetimes thank you um
and final question from Antony my
question I just make a comment that many
organizations which are currently using
robots would argue that they're doing it
more to enhance their service offering
rather than to replace jobs but my final
question wrapping up is if there was one
recommendation at the end of this
inquiry that you'd like to see us make
what would that recommendation be
recommendation a so if you can move we
can we can come back yeah I think I've I
just realized that point about red
team's it's really exciting to have that
robot that can that can do what's what
people were being promised today but
it's not there it's not there possibly
even with today's scientists not today
not there today with today's techniques
of machine learning so that's kind of if
we take RIT let's let if we're going to
do research let's take real risks with
really strange ideas and let them run
for years rather than looking for
instant payback well one of the problems
with this debate is almost everybody has
skin in the game even the universities
want spin-offs and they want venture
capital investments in their latest big
idea often this toughest takes years and
it's very painful to do a little courage
from the funders and I think I just
repeat that point that rather than
trying to second guess which jobs will
go
bear in mind which jobs are going to
stay and make sure they're decent jobs
that people can make a decent wage on
and I was to make a general point about
education and not not about teaching all
kids algorithms but about having a more
flexible attitude to what what kids
learn combining creativity with with
digital skills I mean the
the growth industries things like the
games industry they employ all sorts of
people that employ artists they employ
designers and they employ some
mathematicians and physicists and too
often we seem to be producing you know
very rigid schemes of Education I think
gonna need people to be more flexible in
a more flexible world thank you very
much indeed and that concludes some at
the second half of our evidence so thank
you very much that was really really
good session the proceeding has ended
the proceeding has ended the proceeding
has ended
the proceeding has ended the proceeding
has ended the proceeding has ended the
proceeding has ended</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>