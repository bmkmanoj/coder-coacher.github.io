<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Artificial Intelligence and Its Implications - Panel | Coder Coacher - Coaching Coders</title><meta content="Artificial Intelligence and Its Implications - Panel - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Artificial Intelligence and Its Implications - Panel</b></h2><h5 class="post__date">2017-11-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fIGLvsfgxDg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">also has a hard stop to catch a plane at
4:30 so we are gonna be done we're gonna
be done at 4:30 okay
so mostly we'd like to produce some
interaction with the audience so if
anybody has a burning question please
step to the mic otherwise all kind of
start a little bit of the conversation
let me start with the with a question to
two Stuart Russell kind of you know as
it relates to your your comments that
ultimately computers will make better
decisions than humans and I wanted to
ask you that question
in the context of analysis so the the
task of analysis is a hard one and human
analysts perform the task of analysis so
in terms of these better decisions do
you ultimately think machines will make
better decisions than human analysts
would be able to make can you sort of
comment on that expand on that so I have
to yeah I think so partly because they
they don't suffer from either short-term
or long-term memory limitations so they
literally can ingest everything the
human races ever written and then
synthesize integrate that information
find connections but doing that you know
one of the characteristics of analysis
is that nothing is taken at face value
that you never assume that the identity
of the speaker is known you know there's
always uncertainty about everything and
so this is one of the things that
probabilistic programming language is
actually handle very well and that's one
of the reasons it works so well for the
seismic data interpretation because
precisely the the identity right you
know is this blip you know that that's
measured you know on the Falkland
Islands is that coming from the same
event to some other blip
measured in Greenland that's uncertain
and what it does is it sorts out all
those possibilities across the entire
planet
why essentially look looking for the
combination of assumptions that is both
self consistent and highly supported by
the data so I think the the big gap
right now between what these systems can
do and what a human Alice it does is the
background knowledge of of human
activities you know of economic
activities and again I just don't see
how deep learning is going to do this
you know I work a little bit on
financial data analysis and modeling the
financial behavior of individuals so if
you take a model-based approach you can
build in the fact that there's such a
thing as conservation of money so if you
spend $100 you have $100 less in your
bank account deep learning systems don't
know that right so that means they need
you know and for every one of those
things they don't know about the world
that that multiplies the amount of data
they need by another factor of 100 and
so the dream that goes back in AI to you
know the early 80s and Doug Leonard
psych project of developing that
background knowledge that common sense
of how the world works I think it's
still unfulfilled but it's it would be
it would have to be solved in order to
build something that was a huge
superhuman analyst in the meantime could
you could you find ways of combining
some of the capabilities of the machines
which is superior in in sifting through
hypotheses and finding ones that are
consistent detecting inconsistencies and
so on with human understanding of
background knowledge that that's an
interesting question so at some point
it's the case that humans would have
sort of insight that machine's when but
ultimately you see that crossing over I
think that's what you're seeing yeah ok
round each one win yes the two issues
one is at least in the beginning
well sometimes somebody might actually
do a better position than the human
analyst the real question is can they
sort of convince the human analyst that
they are actually made a better decision
and we can't until we come to a point
where there is like a hundred percent
certainty that the machines are having
have all the knowledge and are actually
coming to the right analysis conclusion
we will always need to be in the loop
and we need to be convinced and that's
actually a technically challenging
problem as I was pointing out you know
convincing a human in the loop is not a
soliloquy it's not machine talking to
itself saying yeah it just makes sense
because I did this I did this because
humans hopefully have lives and they
don't want to know what the actual
step-by-step reasoning of the machine is
but you know getting a compelling
explanation that's one aspect in the
second is well I completely agree that
there are you know we may not get 100%
certainty with the exploitability
explanation sort of things there may be
a possibility of triage in the systems I
think we were talking to somebody I was
talking to somebody earlier that you
could actually use analysts even with
lower experience lower level of
experience to sort of see whether the
machine is making completely stupid
errors and in fact the interesting thing
is because of there is no shared
background common sense knowledge that
you have these are all essentially
narrow savants and so they could make
truly horrific you know errors which
people can spot even without having
humongous background in analysis of that
area so it might actually open as an
area where you'd have less experienced
analysts working with these machines but
for that to happen the machine should be
able to kind of provide a proper
interpretable reason as to why it came
to experience so yeah sorry yeah okay
excellent respond a little bit what she
was saying there Pat the analysts in
likely was saying that some of the
capabilities will just be difficulty
trying to do so I think you know I
suddenly do you agree with you know what
some of the previous
were saying purely you know if you have
explicit knowledge you should trying to
use that rather than changes you know
create a whole bunch of examples and
then get the D playing system to learn
it but the difficulty is off in many
situations and I think now Miss example
it's a good one the information is just
not provided to you in sort of nice
explicit kind of you know formal rules
you know for example you know it's true
that the machines have the potential to
ingest information from all over the you
know the web and so on and so forth but
it's in it's in unstructured format
right and so converting that took sort
of some sort of logical representation
you can reason with in the mid self is
just an enormous endeavor and completely
impractical it's an internet scale and
the site project which still referred to
I mean that project actually I think
most people regard have some just bias
because I mean deep learning part of the
world community but the regardless a big
failure I mean that was a attempt to
sort of build this very structured
knowledge representation so hopefully
will be some sort of emergent property
from it but doesn't it just never
happened and so I think you know Peter
the use of deep learning crowd are sort
of betting on the fact that you can
actually try and reason without me you
know perhaps having huge amounts of
structured knowledge available to you
okay so and so of course it means that I
mean there are tenant problems of course
which means you now no longer have the
ability to so so clearly delineate the
reason to path by which you reach your
conclusions and so on but it does give
you the ability to you know properly
ingest you know you can scalable ingest
huge amounts of information with it you
know from real-world sources not from
sort of idealized you know knowledge
basis which you would have to use if you
just think that these these concept of
decision making is quite complex because
in some sense the data analysts the
human making decisions is never a
one-shot kind of decision you kind of
gain confidence that people make good
decisions over time so you make a
decision today then it proves to be
right you get some reward you build
trust in these decision making and
eventually people can explain why and
it's kind of a relationship that has of
a nature of temporal nature I mean it's
not
is something that immediately we are
proven to have made the right decision
or the wrong decision except in maybe
some few cases and another thing that is
actually fundamental for us to
understand and I can't wait that then AI
system helps me do make goodness else me
support or recommend decisions is that
if you think about the alphago program
one of the things that it did remarkably
was what we call in from a technical
point of view they explored the space of
things that could be done beyond what
was being taught as the ones that would
make sense
so machines segai systems will have this
amazing ability of following the data
for sure but eventually also trying
maybe in simulation hopefully things
that are of great kind of like deviance
from what has been done before and
that's how in some sense are forgotten
it up like beating the humans because it
didn't play things that the humans were
expected to play I was talking with them
is a service recently and he was
explaining how in some game that the
third game the second game these human
who was playing with the machine listed
or saw kind of a move of the machine of
Africa and was puzzled how in the world
did these machine played this and he
took off went like for 15 minutes to
think about how to respond to that
because it was so unusual that type of
like move so I think that which ended up
to winning the game so maybe one day if
we think about these decisions are
trying to cure cancer or do something
that is extremely hard for humans maybe
we have to let the Machine in the
machine
try in some sense to explore the space
of things that are not even conceivable
by us but eventually may lead into
solutions that were not in the path of
our reasoning but end up achieving the
objectives that we wanted so I see a
great potential for AI to enable us to
explore a space that we kind of maybe
don't have the
ability to explore and of course it
cannot be on the real world and there
are researchers colleagues of mine that
work on this safe exploration problem
but it has a very beautiful concept from
the point of view of decision-making
because maybe to lead us to find
completely new avenues of solutions to
our problems so I'll pause to see if any
there any follow-up questions yeah I
think it's a challenge it's a challenge
but on the other hand you know one of
the things that Demi's was telling me
also that means Asami's was that the
moment of a go warn to lisa dull
Lisa doll was fascinated by what he had
missed and he became like he became a
learner now of how in the world is did
machine come up with this and open like
all these mind of Lisa doll eye and
Demi's was telling me alphago was
stopped didn't care at all whether it's
world or it was and Lisa though was
fascinated by even like rediscovering
the game by seeing what this machine
eventually showed so I don't know
exactly to tell you frankly from a risky
point of view this was a game this is
like things that people do it I mean it
but on the eye and it has an implication
potentially in your kind of life meaning
worlds of great risk that maybe we'll
find methods to solve the problem
without hurting so much somewhere else
maybe we there is this concept that I
mean just to wrap this up there is this
concept eventually that there is kind of
like the perfect solutions
we're and we are like applying gradients
to our solutions and improve them
slightly we're really the solution is
miles away in another hill and maybe if
someone just jumps is there then we can
as humans do the gradient and polish but
in some sense the machine may help us
may help us jump to the other places
other place that we did cause if and we
could always not jump there I mean we
it's our choice but I think that dem is
made me understand that the great hero
was Lisa Dahl who after all was now are
fascinated by learning more and that's
really how I see that humans and
machines may interact humans may
actually ask these questions to the
machines the machines may come up with
his solution something that fascinates
us that was outside of our scope of the
reasoning and then magically we know
more and then we start working on that
and then we challenge the machine with
more things then magically the machine
puts us somewhere else and in some sense
we are in these kind of like using the
computers for our benefit and we drive
these questions and the machines end up
like making us think about phenomenal
things that maybe we didn't think about
them before or and using different math
but concretely I don't know but I just
know that these machines will be able to
do this type of interaction with humans
so so I think it's a at the point that
you make is how does one explain how
does the machine explain when in fact
the human doesn't see that there that's
a very important point in fact
oftentimes we are talking about
explanations when the machines are
making stupid errors and humans have to
catch them but the real hope for AI
technology is that they will find things
that we actually didn't see and there
are two aspects to it one is in computer
science we understand that generation is
harder than verification so things that
we may not generate if somebody else
points out to is oftentimes we might be
able to see sometimes okay that's one
aspect the second is of course we are
actually reasonable learners so if it's
you know in the case of this at all
actually I think in the entire go cam
you
as I understood spent a bunch of time
figuring out exactly why did this work
and then they have sort of the newer
technologies and that sort of thing that
could happen in the in the end
essentially the I mean I kind of
remember this Jack Nicholson character
in I guess a few good men that sometimes
you can have this you can't handle the
truth you can't have the truth because
you can't handle it so I hope that won't
come to that in the sense when the
machine does say something rather than
just assume you know if you know that
it's wrong we may be able to actually
with a verified in a spend time offline
and once you sort of learn that it was
right it increases your trust next time
around you might click white fewer
explanations yeah I just briefly wanted
to add so alphago knows the rules ago
and they actually pay a why I didn't buy
the human it doesn't learn them and so
it has a correct model of the domain so
if it says this move you know moving on
the on the fourth-ranked instead of the
third-ranked is better you know it's
explanation is well because iran seven
hundred billion simulated games and i
win more often which is not much help so
the human has this or pick apart the
underlying reasons of course if you
don't have a model domain there's no way
it can it can you invent you know a new
you know a new plan for subvert in the
north korean government because it it
doesn't have a model of governments and
and humans and and weapons and and
subversion and it's it's completely
meaningless and so i do i do think that
in some areas for example tax avoidance
is an area where we can write out the
rules we can write out the route you
know the rules of financial transfers
and transactions and taxation and we can
actually invent new forms of tax
avoidance right we can say this if this
set of laws has the following loopholes
right and then we can fix the laws to
prevent those loopholes but that's a rel
thats a domain which is relatively
precise and can be written down formally
i think in the areas an intelligence
analyst deal with it's it's much more
difficult to write down the rules
the game and then fine you know without
that the process of finding unsuspected
solutions to the rules you can't even
begin okay let me explore another topic
a little bit
so Rao towards the maybe the back third
of your presentation you kind of skipped
through a slide where I think you're
going to talk about video spoofing where
I assume that basically these machines
can study YouTube videos and after doing
so can produce a video that is
essentially imperceptibly different from
somebody speaking something that they
didn't speak so I guess the identity
spoofing is something that is actually
quite easy quite you know at the
possible level of technology right now
they're great examples some of which I
was a showing there I think they had for
example Obama say something that he
didn't actually say in at a particular
speech by and you can't tell because the
lip movements are exactly the right ones
and then they also had in another
example they had actually I think you
know the an actor would be essentially
making gestures and Trump would actually
be making those gestures in a recorded
video so this is kind of very
interesting advent of our great strides
in you know perceptual intelligence
there was this funny we spent a bunch of
time in that workshop that I mentioned
at in March at ASU on you know attack
surface SME I and you know one of the
cute things that came up was I don't
know how many of you remember but there
was this story that Charlie Chaplin took
part in a challenge happily in
look-alike contest and came in second
and there is this possibility that in
future we'll all be Charlie Chaplin's
will all be poor imitations of ourselves
somebody else actually can spoof us the
real question is you almost need like an
anti Turing test you need to sort of
figure out how to differentiate you know
between you know the machines of the
imagined reality versus real reality and
it can become quite hard so these are at
in attack surfaces that are actually
becoming easy so if you have I mean you
know somebody call you
you know with your mother's wise and say
I you know knowing at least some
background on your history and say you
know I need the following such-and-such
help it's you know it's going to be
pretty hard for you not actually know
deal with that issue and then that sort
of an additional angle and the
cybercrime that's just being opened up
because we can do y spoofing and videos
could be the amount of attacks and no
matter what we can do with our
technology seems to be unbounded and
bounded we we really can do millions of
things and I believe that these examples
that we know that even like for example
in my co bar who knows when they put the
coffee on the basket that's not a bomb
that is going to be delivered to the lab
I mean I don't have a bomb detector on
that on the x-ray of the actual basket
so it's clear that I mean we are
creating these a high technology
extremely powerful so I also think that
it's clear that this technology did not
come from the sky it was invented by
humans human minds it's in the clear
path of computing when it started in the
early 50s or maybe 40s so this is not
the fact that suddenly we they became
it's just it's normal what I believe it
happens I mean when we talk about these
things that this is a kind of a call to
humankind
it is a call to us and we want to make
good uses or bad uses I mean if someone
invents away that this video is telling
something and now what I say now is
going to say the same words and its
identity and these all of these well
then what I mean we can try to have
mechanisms to try to filter these things
and try to find them out but you know
the human mind will be even better at
whatever so what I'm trying to say is
that our only chance and I mean I keep
saying these maybe it's because I'm
becoming older
I keep saying these is that the only
effort we should put on is in fact on
letting our on educating people nothing
else I mean it's the people are going to
be the inventors of the use of the
technology let the technology advance
with its like I mean with what we need
to still develop the combining the
reasoning the perception the learning to
try to actually how do you say manage
these humongous amounts of data that we
became now master producers of data fit
beats and cell phones and nests and Alex
is I mean what in the world are we
inventing we are inventing millions of
things that unless I processes these
data who is going to look at all the
videos that are taking in a city if not
an AI system who is going to process all
the data we are collecting are our
transactions and so forth so it's kind
of like we are on one side producing all
these anons amount of data we are on the
other side think are going I can be that
bad
but who is going to handle what we are
producing so the best way for us to
think about beat in a military beat in
government being in our homes is to
really have people invent good uses of
this technology so not we cannot do
anything the technology is extremely
powerful
so it's investing on people education
people that's it that I mean so I tend
to be less sanguine about people's good
intentions than my friend Manuel ah I
think they will find adversarial uses
but I think the big plus point is that I
can be part of the solution you know I
mean when you open it attack surfaces
it's not that only the bad guys have a
are the good guys have AI too so in fact
if in fact your mother does call at some
point of time we shouldn't be reading
our emails we shouldn't be taking our
phone curves it should be personal AI
which screens so your personal AI will
call my personal AI and try to spoof it
and if I have the best version then it
will then let the call through so Mike
my point is I think we cannot assume
that technologies won't be misused
because come on
see what we do I mean you know as a
human kind and and I think human kind
but I think we have to but it is indeed
possible that it opens up more
interesting research problems which is
you know how do you use the AI as a
solution to the adversarial things that
were made possible by AI not very much
know what doing so that's one of the
things that very brief point it yes
there are people who do bad things but
there are many other spheres where
people do bad things and we have laws to
make those things illegal in these new
areas there are not laws so it's
completely legal to produce a voice
synthesizer that appears to be your
mother asking you to do something it's
completely legal to make a video of
anyone doing anything right you know
just a simple rule thing you know even
if you want to allow that at least say
if this is synthesized or not real it
should say so right it should say you
know just like for political ads you
have to say if you pay for this ad right
that's a rule even though it's politics
which is very little regulated right if
you make a fake video of an actual
person doing something that wasn't real
and it has to say so that seems like a
very minimum that we could do but at the
moment nothing everything is it's a
free-for-all it's a Wild West you know
automatically without any it's still a
copy as a way but it's certainly you
know very much on surprise and then I
mean and then she's this arms race now
if you were didn't have legislation
between your AI I mean soon as you the
summary our technology for blocking for
detecting the the fake video and you
couldn't also then train the method the
generating bill to circumvent it as well
okay that that generated some questions
regular
part of me part of me this is webcasted
so wait for me because they're portable
it's a report well Mike yeah there is
thanks several speakers have talked
about you know transparency and trying
to get the vai you know basically do the
right things stuff like that so there's
a kind of a expanding thought experiment
I just want to kind of talk about the
section because I you know I kind of
view as a long time AI guy you know
deception is one of those human
behaviors and to me actually it was was
what 25 plus years ago at Georgia Tech
they they basically did the squirrel
experiment and I assume most the people
are familiar with that but basically for
those who aren't you know squirrels hide
nuts so they have to make it through the
winter so they hide their little nuts at
different places so what they did was
they model the behavior so you have one
AI who's the squirrel is burying his
nuts the other AI is trying to find
those nuts and so the squirrel he's
burying his nuts basically starts to
deceive and goes to locations and things
where he doesn't have nuts to basically
fool the other squirrel where he may be
hiding the nuts and so what I thought
was kind of interesting to take up the
next level is really what you're
starting to see here is said the AI is
not only looking at the deception part
but also looking at how you would view
that deception so I want to talk about
that well so we see this in polka right
so you know howyou is Bluff on double
bluff and so the game theoretic
solutions for games of partial
information automatically produce that
that type of behavior so they would do
what the squirrels were doing you know
but obviously the squirrel spends all
his time going to places where he
doesn't have nuts he's gonna starve to
death
so you know he's gonna figure out what's
the right
right what's the right balance and and
then you see the same thing so I looked
a little bit at this reputation
falsification for example in eBay where
you you create thousands of fake logins
it's called a civil attack you you
create thousands of fake logins and they
do transactions with each other to raise
their reputation as being honest and
then they then they'll start transacting
with real people and rip them off until
the reputation disappears and then you
make another thousand logins and with
the right detection capabilities you can
you can see these patterns of behavior
and snuff them out so then you know the
solution ends up being that yeah they
can still do it but only at a very low
level if they try and do it too much
they're gonna be detectable so they
can't look too different from an
ordinary person than an ordinary person
it's fine right so it's a very it's a
very complicated game but AI systems I
think you know have no problem creating
18 levels of deception all right so they
could watch the inception movie and they
understand what's going on so I think
you could get you you could get AI
systems to concoct schemes that could be
extremely difficult for for people to
understand and detect yeah so I think to
me deception is a higher level of
intelligence honestly I mean I think
there are actual you know studies
showing that the kids only learn to lie
they figure out that their mental models
are different from other people's mental
models so it actually cognitively higher
up and I know and I think so
again the ability to track what you are
writing in the other person's mind and
what their current status is is
extremely important and that is you know
if I can cooperate with you cooperate
with you I can also deceive you and the
second thing is in that workshop that I
was talking about earlier we talked
about this fact that sometimes you might
actually use sort of White Lies to get
people to do write things you know for
example we all know
is healthy living healthy eating but we
don't do it anyway and so the question
is if there is a way in which people can
essentially you know do some white lies
and deceive you into doing the right
thing now of course you could say well
you're opening a huge Pandora's box but
the reality is we are being deceived
anyway in other ways so it's a deception
is not always just a bad thing and it
requires it's a very interesting extra
capability you get when you are able to
handle the mental models for the others
which is an important thing and and I
think again in fact I mean unlike what
Stuart is saying currently it's not very
clear to me that the I systems that we
currently have
have the ability to model other people's
mental state so when you get there which
I believe we will by not doing research
then they will essentially do this
deception so when I go to this pristine
autonomy workshops that military runs so
I'm actually sitting sometimes and
thinking do you guys realize that you
are opening up yourself for a second
order you know end of the world where
essentially I mean the best Hollywood
movies like sting are the entire movie
is to kind of let you get you to get to
a particular mental model in the last
minute deceive you and so you could have
you know machines which can do that too
they can essentially engender long-term
trust in you only to change it and of
course if they don't have to be evil
machines they could be just controlled
by somebody smart who is just know
making this machine do that so those are
issues I think the gentleman did you
have a question go ahead
so you talked a little bit earlier about
our inability to understand the failure
mode of certain of these algorithms and
I want to take it up a level and think
about the failure mode of the system of
systems we know that complex systems
fail chaotically high frequency stock
market trading energy electrical power
grid and so on
is there research or are you involved in
a research looking at the failure mode
of these systems of systems that our
ability to detect and perhaps prevent or
perhaps create chaotic failure in these
systems so I mean I was only personally
asked in my own talk I was just talking
about the fact that perceptual systems
have individual systems or failure modes
that we can't particularly analyze the
fact that general complex automation
systems can have failures that will take
a long time to analyze I mean so for
example the flash crash on the on the
Wall Street that's not don't put it on
AI and at least as far as I can tell and
it still took a long long time for
people to understand exactly what crazy
interaction between eighteen thousand
pretty non intelligent systems led to
this particular flash crash and so I
think people may very well be working on
these sorts of things but I think within
AI we are focusing that the specific
part I was mentioning is even for a
single system when it makes an error you
just can't see why it made an error this
is something different from what we are
used to sometimes as I said in that
other the Norwegian Bus example when you
when I say I see burqa clad women you
can almost see why I sighed and that's a
big issue because internal
representations are not at all aligned
and that's going to be an interesting
issue so that the great conference in
deep learning is called International
Conference on learning representations
you know if you had that name of that
conference like even seven eight years
back people would have thought that
means representations that people might
have something to do with such as logic
and probabilistic logic and so on and so
forth right now it is the machines learn
their representations you don't have to
be part of it and of course you also
don't get to be part of the
dialog with them so that does open up
interesting new challenges so one one
thing along these lines that we have
been working on if you ask about
research and people have been working on
is this detection of anomalies so
basically people try to look at the the
way that the system is functioning and
they at least alert that the actual
statistical performance of the system is
diverging from the act from the usual
performance and so that's why we detect
anomalies actually in per watt or in the
robots that were not really find for
example if a motor starts failing we did
not have a condition to detect that
but somehow the behavior of the system
starts diverging from the residual
behavior and you can alert that
something is not according to normal so
somehow we cannot explain why that
divergence comes up but again the human
plays that role of interpreting what is
these failure all about or the the
Machine also can provide support maybe
like more cryptic about that anomaly but
that's how we interpret a lot of failure
so there are many of these kind of
filters for failure detection on these
robots of course they are all kind of
based on normal execution and you assume
that you have the concept of normal of
execution but for example if you unplug
the camera so the robot starts seeing
many in some sense completely black
images in its input to the reasoner and
that never happens sometimes it it so
you have this detection that there is
something anomalous and of course if
it's really just a black building they
would do which didn't happen to be part
of the normal perception it's going to
detect an anomaly and it was not but
there is this concept of normal versus
abnormal and we can identify those as
deviations from normal and a lot of
research is on that anomaly detection
and they enough
the explanation part and why this is
anomalous is all with respect to some
normal behavior and why and so it's
always about this differential this
deviation from normal and that's the
research we do in this type of like
detection of failure the question for
Stewart for variance income and
accumulator is a very end that is way to
I'm just paraphrasing it has way too
much deep learning being done now that's
really of course crying through the
University of Toronto and their spin up
this is the old Marvin Minsky versus
Toronto and without knocking the
University of Toronto system they did a
wonderful job of course but there's a
lot more to their efficient intelligence
you pointed out a machine learning then
deep learning so what is your assessment
based on that where you know where's the
developer to asking it way of asking is
how much attention should I pay to the
NAM deep learning part of AI as you
probably know there is some commercial
start 90 plus percent of the commercial
startups are in deep learning but those
are a few gamma long the cheese in MIT
spin-off is looking at Beijing produce
so why is that now I get blogs mention
my commercial folk so they tell me one
story but from your perspective versus
where Saigon Eve anywhere well so I I
say this for a number of reasons one of
course is that I'm not a deep learning
researcher so that piece of you have to
discount that part but I ran into a lot
of CEOs of large corporations who have
needs for AI that deep learning is not
even in the business of being able to
meet and part of what happens is that if
a problem is just completely not
amenable to deep learning you know for
example you know I have a factory and I
want to schedule manufacturing for the
next six months which is 200 million
operations and personnel assignments and
movements you know deep learning is not
even that business so what tends to
happen is that the problem is defined
the art of existence
I did it's not a it doesn't exist for
deep learning community because not
something they can address and and
that's really dangerous another another
symptom for example so Francois shali
who who just wrote a pretty
well-received deep learning textbook he
has a blog about the future of deep
learning so he talks about all the the
failure modes of deep learning and and
the walls that it's running up against
and then he talks about what you know
what might happen in the future to to
get around this and it's distressing
that he seems to be unaware that you
know so he talks about the need for you
know representation and reasoning about
objects but he seems to be unaware that
anyone has ever thought those thoughts
before and that there's two and a half
thousand years of literature on that on
that problem you know and he talks about
the fact that we might we might have you
know generative models with the
expressive power of Turing machines well
that's exactly what parable istic
programming languages are and that
technology is twenty years old and so
he's he's talking about a distant future
for deep learning where they've made it
to 1997 and that's that's kind of
worrying and I see this over and over
again the younger generation thinks that
all there is to AI is chain rule and you
know that's it right there's nothing
there's nothing else and then there's
you know diddling fiddling around with
layers graduate student descent and
there's no way that that approach by
itself I mean it's incredibly useful
part of our toolkit but by itself it
cannot get us anywhere close to human
level AI you need these you need the
ability to have knowledge is an
important concept that's absent from the
entire deep learning literature so we
still need those capabilities and I
think the deep learning community can
learn the hard way or they could read
something
and the easy way I anticipate a couple
of responses here so I think partly what
you know we were trying to do some of
ours I think in my talk too is that it's
a extremely useful tool deep learning
and if you're talking to companies
asking them to work on you know
technologies that might be useful
potentially much later is not going to
fly but I think we are in a crowd here
we are also talking about longer-term
investments it's important to remember
that neural networks were given up for
dead twice at least okay it's also
important to remember that essentially
the people who supported neural network
research were a Canadian sefa
organization I mean US has large amounts
of funding agencies but there can be
sometimes collective group thing and
it's very important to sort of trade off
exploration and exploitation you know I
think we you know that it's great to use
the deep learning for what it's good for
but it also to realize that there's lot
more to intelligent behavior than just
being able to do immediate perception so
it's important to see what it can and
cannot do and touch what I was hoping
you know we will get across so it's like
you know there is been great ski time
famous quote of don't go where the park
is but where the is going to be and
it's not clear to me that either Stewart
rir manual are you know Rob knows where
the park is going to be but it's if we
knew how to predict future well then we
would have been actually doing deep
learning work long before and it
shouldn't have taken that long to come
by fall starts so why do we think that
we suddenly become smarter now and this
is the only thing that will work and and
so funding agencies in particular and
policy agencies should be taking a
longer view and then diversify their
investments and I think that's very
important and it's really important for
AI researchers of course to be you know
not to reinvent wheel every evening that
just makes no sense
yeah all right so I guess some just to
you know just just Russell but at some
points are some age so I think if you
have problems where there is a formal
definition of the task then of course
you should use all that that formal
definition I think anybody in Japan with
ever so you shouldn't okay now the catch
is that there are so many problems out
there in the world which just you can't
easily sit down and write things out now
so I gave some examples in my talk of
like recognizing you know image objects
and images right so it's just very hard
to write down a formal information of
what a cat looks like okay so people did
try I mean they tried it okay maybe we
can fit a cylinder for its body and you
know a little sphere for its head and so
on this was a valid approach in the
1980s and it just it's just falls apart
these think things are just too brittle
so this is why the deep learning thing
is proven very successful when you don't
have a precise definition
okay now the catch is if you want to
create a truly intelligent thing do you
think you know for example it's possible
to write down a set of formal rules that
govern human behavior okay so I would
argue actually it's gonna be pretty
difficult to do that okay and so that
leaves you with you know two options so
one is you could try and do the whole
thing end to end with deep learning
right so you could try and the Matteson
there are some sort of deep learning you
know pure true believers who will
believe that your bills just hammer the
whole thing with some giant you're met
and you know train all all this all the
interactions and you know observations
on YouTube and Facebook and so on and
you'll be done there's sort of more
compromise solution which I think most
people will come to is that you know you
should try and learn use use the
deboning to sort of capture
representations which you then
subsequently can you know using some
sort of more structured reasoning system
okay so that's a sort of hybrid between
the two or two schools so I think you
know depends exactly you very much talk
to as to where you'll be between the
sort of end to end the deep learning
community you know people would be
somewhere between those two things I
described and something would kill on
the deep learning end of things
agree with with Rob in the sense and I
agree with Stuart and Robert I've been
doing symbolic reasoning and planning
forever
but I have to tell one thing that I find
fascinating the difference between the
past and these days is the data thing in
the old days we used to think that the I
would rely on knowledge that we would
acquire from people or from models we
would write by hand we would ask how did
you make the diagnosis that this person
has some disease and the doctors would
provide that knowledge and the
architects would provide the knowledge
how they design these and everything was
about extracting from the human minds
this knowledge that then became our
logic and yes I pick up the block if the
block is clear and all sorts of like
knowledge that came from a lot of like
pupil spelling out what in you I think
that currently we are leaving a
signature a footprint of everything we
do through these data every so somehow
it's it's a very interesting concept
that we are revealing everything the
pictures we taking that in the GPS we go
out SAR revealed everything so it's a
big difference for a guy to really
ignore we cannot just ignore these data
and deep learning in some sense is
extremely appealing and powerful like
Rob is saying to really look at data
maybe we know models maybe we can use
them but magically now we have how we
use and when we do laundry at home our
meters capture the whole thing is data
that now becomes available when we can
magically learn and predict at what time
is she going to do her laundry tomorrow
so what I'm trying to say is like this
we cannot avoid thinking that the
challenge and the opportunity and
somehow the excitement involves data it
probably also will will have to be
merged with models and other knowledge
of people even Africa use
tree search algorithm it was not just
data but the fact is that we are in the
infancy also of knowing how to process
data effectively we are because we have
all these data and we have to actually
look at cameras in the city of New York
or in the city of Pittsburgh or in the
city of whatever and figure out what's
happening from those images and we don't
really can sit down and write the logic
for yes the car is going to ten percent
of the cars turn left 90 percent turn
right now the data tells it a lot so I
actually believe that a lot of what we
do now has to do with data even like I
it has to do with data and the ability
to process data may be driven by I mean
we may put knowledge on top of it but
it's fascinating to think that data will
reveal so many things that we may not
have known before and yes the models
will come and yes eventually everything
will be about but what is initial these
startup companies these new companies
need to know is that we actually have to
become extremely proficient at
processing data with biases with
underlying models or not I don't know
but what matters is that these data is
available and we cannot afford to
disregard the data and deep learning is
giving great tools for processing these
data we are there but don't forget that
every single thing we buy new with our
cell phone beat our thing beat anything
is producing more data it's everything
that we have is about data and I think
that we have to embrace that as the AI
challenge now also which is process that
data so yep I like models I like logic I
like probabilistic programming languages
everything but yes there is data and we
do need to be very very smart about the
valuing techniques that processes that
data whether that solves all problem I
don't know but we can just not ignore
that we cannot ignore that the data is
there which has embed
a lot of knowledge because as opposed to
date in the past that could be capturing
what are the images on satellites these
data is capturing how humans function
it's my GPS that's there if the pictures
I take it's at what time I take
breakfast is the things I buy in the
supermarket it's revealing humans how
humans function not just how the
satellites or the planets move in space
it's not it's our life now the doctors
the health the the tests I have my
Fitbit
it's our life that is being digitalized
it's the human life it's the human
processes not just something else so
that's what I think it's exciting and we
cannot deny it yeah so III I think it's
it's it's not we wouldn't be accurate to
say that the model based AI community
denies the existence of data of course
right you know machine learning machine
learning predates deep learning by many
decades and lots of work has gone into
learning model-based representations you
know that goes without saying
but learning into what right this is the
fundamental scientific question right
sure there's data but what is what is it
that you extract from data and one of
the clear things about the world we live
in is that there are things in it things
chairs people right and relationships
and events and unfortunately deep
learning is just circuits so in circuits
there is no representation of things and
Relations it has to be it has to be
supervened on top of that and so to me
it doesn't make sense to expect the deep
learning system to in discover that the
world has things in it to invent the
notion of relational representations and
and then logical or probabilistic
inference on top of that
know these things we know the world has
things in it why don't we take advantage
of that in our formal representations
and our learning algorithms one you want
the last word so there are I mean there
are systems that run you know in real
practical problems which do take you
know which do model using deep learning
methods relationships between objects
you know you they have quite
heterogeneous collections of things and
so on and so forth so for example this
is a project of Facebook which you know
Yanis talked about which is well you
know every single different objects in
Facebook image post you know people
everything are just represented as a
high dimensional vector in some space so
some of the deep learning parties taking
that thing in the real world turning it
into just a high dimensional vector okay
and then in that space you can review
all kinds of reasoning tasks you want to
do about you know who's friends with
somebody who might like something and
things like that and so you know that's
it's not it's somewhere between you know
completely abstract you know and took
representation and it's a purely formal
you know logical representation of that
that individual of that entity okay so
it's soft it's continuous it's just a
bunch of numbers but if you take you
know nearby vectors in that space that
means they're probably the same thing or
they might war if you have in relational
operators that apply to the pairs of
objects they can tell you whether you
know some relationship between them is
just no it's not a physical scenario but
you can imagine are other versions of
this would be like these two objects you
know relate relates to one another or
they somehow physically connects it or
you know to one another and things like
that so it is possible to do a kind of
reasoning to outside a kind of reasoning
tasks I think and to substantiate real
things in the world using deep learning
in a way that you can actually achieve
you know do real things with them and so
these these things actually used all
times like you know finding for Geling
activity you know making all kinds of
predictions and stuff like that so you
say
real route did you want the final 30
seconds okay I guess I can say something
non-controversial come I think we are
not actually arguing again as any
subjects here I think it's this there
are two different things we talked about
one is data versus knowledge whatever is
available you want to use it okay it's
silly to say give me data when I want to
give you knowledge it's also silly to
say convert your data into knowledge and
give it to me
ai technology should be able to use both
of them and that's the point that I was
trying to make the other question of
course is which technologies are likely
to be able to be better at using data
versus knowledge that's a research
problem that we have not completely you
know solved I think you know I find both
the arguments you know reasonably
compelling that there may well be other
interesting ways where continuous
representations might have modularity
properties but we do want to get there I
don't want to be forced to give my
knowledge in has bazillion examples just
because that's all the machine knows how
to use so we need to be able to use both
of them data and doctrine and that's
what I would like to see okay
almost to the to the second so we
promised a 4:30 adjourn time thank you
for being here I hope this whetted your
appetite on this important topic please
join me in thanking our panelists</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>