<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Richard Sutton of DeepMind &amp; Steve Jurvetson Discuss The Future of AI | Coder Coacher - Coaching Coders</title><meta content="Richard Sutton of DeepMind &amp; Steve Jurvetson Discuss The Future of AI - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Richard Sutton of DeepMind &amp; Steve Jurvetson Discuss The Future of AI</b></h2><h5 class="post__date">2017-11-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QqLcniN2VAk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well it's a great honor to be here on
stage with the you know the father of
reinforcement learning and many other
new things that were going to hear about
today but let me start with a very broad
and general question we've been hearing
a lot of dystopian and utopian visions
of AI and as we transition in the
afternoon to the big picture of the
future what are your views about human
centric or alien AI thank you very much
Steve
yeah I would like to present a view that
AI is really much more human centric
than we usually think about we really
think about more like us versus them the
machines can make us obsolete every
competition is man versus machine but
that's that's one view but it's only one
I think it should be balanced so is it
us versus them or is it more of us are
we are we them and so so let's let's
think about that how does it it it it
starts with the name like the name
artificial intelligence says it's a
different kind of intelligence that's
artificial but really the the field is
defined first of all the idea is defined
as trying to show abilities that are
similar to humans so really even the
definition you know like the Turing test
is all about you know can we make a
machine that's that that can imitate a
person and many people are defined
artificial intelligence as machines that
can show a abilities that normally we
would call intelligent if they were done
by people and so so look at the
definition of our field is is
human-centered it's defined in terms of
humans and so maybe we shouldn't have
called it artificial intelligence maybe
we should just call it intelligence and
I think it's really a mistake that's
that's been haunting us that all all of
us now think of it as artificial we
think of it as an engineering thing and
or we don't think about it as a human
thing but I think it's AI is actually
among the most human of all fields most
human-centric of all fields perhaps
psychology is a little bit more human
centric
it's like the study humanities abilities
now if you think about this this is what
is really happening today it's not just
a long term philosophy thing although I
love philosophy and I'm I'm really glad
that we have this this it's just an
opportunity to discuss philosophical
things I don't know maybe maybe I'm old
and so I'm permitted the we have sort of
a philosophical title to our to the
section I think it's a Jay's fault and
so I'm taking AJ's philosophical title
as a chance to be somewhat philosophical
and and it's not bad maybe he's trying
to prevent something bad maybe he
thought I would have it show slides with
equations in something which I normally
I do but it was part of the the setup
for this this talk was that there would
be no slides and so so that's been
prevented now the nice thing about
philosophy is well you know we all feel
we can do it right anybody here feels
they can at least participate in
philosophizing about AI so let's let's
do that a little bit and let's just note
how human centric it is like all the
things that people are talking about all
the modern cutting-edge applications
like speech recognition that's about
getting people so they don't have to
type and they can just get their
thoughts onto paper and communicated and
recognizing images is to save you from
having to write write words about your
family vacation you know you want to
have your pictures automatically
classified and even things like language
translation is about people
communicating to each other
sweb search web search is where AI is
used you look at all the places where AI
use it's all about enhancing us as
intelligent beings enhancing or and
entertain sometimes entertaining us but
enhancement is is the fact the fact of
how a AI is used today why it's
commercially important and it's not
about you know it's not about beating us
it's about enhancing us
the game playing that you all know about
which is it's just it's really useful we
do the games because it give us a way of
measuring of the the effectiveness of
our AI systems it's not because we want
to make something that repeats people
it's because it's really a methodology
and the the point of the technology is
not to beat people but do to enhance
people and make them more effective at
what they want to do I'm fascinated by
this and if I may want to ask some
follow-up questions so maybe someone I
just heard it sounds like much of the
work is that of the sensory cortex by
analogy the interface to the modalities
were used to and yet the inner workings
of these artifacts maybe an alien
intelligence meaning we understand the
inputs understand the outputs we
purposefully train them with datasets we
understand and what allit is we
understand but do we understand the
inner workings would you say the core of
a reinforcement learning that is in any
way a human-like thing the trick I'm
going to use may be throughout all this
in to answer Steve's questions is to
relate it to people and so people also
have a neural network and they they
learn and they form some reflexes and
some responses and some intuitions and
we have no understanding of how we do it
or how others do it and yet we trust
them so I really think it's the same for
our machines we don't understand how
they work in detail as someone said we
understand how they were made but really
why do we understand people and why do
we trust people to be taxi drivers and
drive us around or about flyer airplanes
or to make critical business decisions
that's what I do I'm actually yeah yeah
we started dude we don't we come to
through experience and by the fact that
they're risking their own lives as well
the taxi driver I guess but it's
experience we learn what we can trust
what we can't trust I want to go one
step further and if if
look at humanity what is I'm saying AI
is very human centric so we have to
decide what is human you know and if you
look at humanity what what are we you
know what is what what is our place in
the universe I mean we're the animal
that has become most technologically
powerful that's been the tool using
animal the language using animal we have
throughout our history built technology
to enhance ourselves I mean going back
to like really powerful things like a
pencil and our eyeglasses these are
really super powerful a language itself
is what our most important tool and we
are the tool building animal and we are
the communicating cooperating animal
collaborating animal in our place in the
universe
is is to build tools to make us better
and and so what we're doing now with AI
is exactly that we are enhancing
ourselves it's way to do with eyeglasses
I just waved it with language to to to
to be smarter to communicate better to
cooperate better this is our place and
and there's you can't separate I the
technology from what we from the
humanity so if I hear that that that has
been the path to date of augmentation
and extension of our senses and
modalities our capabilities
do you believe research along the domain
of autonomous agents robotics emotional
systems will one day be a path to AGI is
that and it's so I think that will come
and then if that does come why does that
end up being human-like it says alien
but understandable let's let's just take
the start with the fact that there there
there is AI research that's trying to
make the system more autonomous have its
own goal systems and and that's you know
it's not it's not so obviously like
enhancement so I'd like to harken back
to AJ's introduction we talked about
time and you talk about prediction
diction is really important I agree I
agree with him the only disagreement I
have I have about prediction is that I
think it's more important than than he
does and it's a more it's a more subtle
and complex thing than that but
prediction is is it's a it's it's
appealing for this group because it's
it's sort of something we all understand
as business people and as ordinary
people that if you could predict things
better now that would be better than if
I could find better predictions I could
make better decisions so it's clearly
just enhancement
it's just prediction makes you able to
make better decisions but but AI is
moving beyond that and it's integrating
the decision-making and the goals in
with the prediction and this is this is
the slightly more this is this is more
well I guess it is more scary but I'm
not trying to I'm trying to claim that
it's not scary because we have the same
problems also with people again like
when you raise kids you raise kids
they're autonomous and you have to worry
about what goals they have and you you
try to raise kids so that they are at
least counterproductive to what you want
but but at the same time it's valuable
that that they're not entirely under
your control
yeah reinforcement Myers specialty is
all about building up something like an
emotional system and absolutely autonomy
and decision-making so so it's it's it's
close to my heart so you mentioned goals
a couple time it seems like that may be
a key element to bootstrap this whole
process and it also I see the mapping to
reinforcement learning whether you
thinking of the gameplay metaphor we can
all understand intermediate goals
long-term goals reinforcing it across
the chain is that your opinion as well
if that will be the path to higher
higher levels of intelligence yeah yeah
we're gonna have higher and higher more
and more abstract goals and that's
important part of it you can't really
have goals without having a system that
cares about achieving its goals which
means really something akin to emotional
responses so so these things fit
together in autonomy is do we face as
humans a binocular gap there were often
folks in the room right here was like
or caring and wonderful is describing
some sort of you know the Nano centric
overlay or if that actually is what's
going on and we're just gonna learn
gradations of these that there's
something finer grained than just human
level caring human level goal-setting
there's a whole spectrum now goals it's
just a simple word but you can be misled
by by it as such a simple word so the
only way to handle that is to replace it
with longer phrases like goal-seeking
ness or purposiveness purpose I like
that's only a few more syllables so the
general idea of purpose of caring about
the outcomes or optimize your outcomes
being able to influence things towards a
towards one thing rather than other
obviously this is essential to
intelligence if you had if you had just
something that could sit there and
predict it could be very smart in a
sense but it wouldn't be nearly as
powerful as something that would act on
its predictions and which had a goal
that was trying to achieve and I tend to
define it that way
now before we run out of time I want to
mention one more thing about the general
thing of worrying about AI because I
want us because I've said that it's much
more human centric human centric then
most of our press stories and our and
our worries reflect but still I have to
acknowledge that there are these words
it's really almost overwhelming in the
press coverage of AI that it's us versus
them and are we going to be obsolete and
and we're going to be and has it
happened yet and all things like that
and I think that is as I said I think
that's a mistaken way to think about it
has to be at least balanced by the other
point of view that it's us being
enhanced and it'll be us making our
former selves obsolete but I there is a
tendency I acknowledge there is this
tendency to classify it as us versus
them so we have to ask why that is now
I've blamed it a little bit on the name
we've chosen a name which makes the
sound alien which makes the AI sound
alien because we're calling an
artificial intelligence but it's not
just the name I think it's it's a little
bit deeper than that and I think it's
something we can all relate to as people
and that is
imagine that we so what I would say is
that we are making new people a new kind
of people that are that are designed
okay and so what's happening with a fear
is this is the normal human response to
a new kind of people like over and over
again we learn you know we need a new
kind of a new class of people slightly
different maybe a slightly different
color or a different religion and we get
scared of them we have fear of them
because they're different and we're
gonna what do you always see that
they're going to take over you know it's
not that we're being bad it's just that
they're going to take over the I don't
know whether it's it's the the native
people of the place you've arrived at or
in the West you know fear of Japan and
I'm sure or China the different kind of
people over there and we always it's
very natural human thing to be fearful
of others that are slightly different
from us and yet it's also human
particularly in Canada to find a way to
celebrate diversity and and welcome the
others to celebrate their
accomplishments and not just as they're
doing well so that's bad for us but
they're doing well and there they are
like us and I think that's what we have
to get over with with our machines so
alphago has been a really interesting
test case
alphago you know in the West it still
tends to be presented as man versus
machine but in the NGO community it was
it was like here's this amazingly
amazing system amazing machine it can
understand go it's joining us in the the
the infinite task of understanding this
elegant game and so the response to the
the alphago beating the world champion
was that there was an enormous greater
interest in go and more go boards were
sold than than ever before and when you
look at many of the pro players would
say you know alphago it's very
interesting he's got these new moves and
he's teaching us we are learning about
go from the machine and it's a good
thing it's a good thing and so I think
we have to learn find a way to to
welcome this different kind of people
and their strengths are different from
ours they'll have it will be much more
diverse and but why can't we celebrate
that I think as Canadians we should
celebrate yay we have to and err to be a
time for hope not anyway sometimes yeah
so this is a great segue to alphago and
I especially wanted to get your thoughts
and alphago 0 and for those I'm sure
most of you notice in the room but the
newest version learned how to play
interestingly by not studying human
moves but starting from just de novo
here the rules of the game go to town
and within 72 hours trained itself to a
state where the old alphago hundreds of
0 and correct me if I got any of that
wrong my question to you is throwing
away the human training set seemed to be
the way to make a better product how
does that fit in this framework in other
words it did so much better by ignoring
the humans right there if anything held
it back we need scalable methods Steve
and I both like to show and we just do
it today and no one did it say I'm
surprised we no one showed the
exponential growth of computer power why
did those my opening slide yeah yeah
Moore's law came in just a minute late
so I'm good I'm glad I'm glad you did
because you know that's kind of mundane
now but it is it's a profound effect and
it's hard for us to recognize how
profound it is and we need so we need
methods that will scale with computer
power I mean that's what I mean by it I
don't mean that they they scale with
problem size I mean they will scale with
computer power you get more computer
power you can have a more effective
system and so we have to ask is computer
power the bottleneck of your strategy or
not so learning from human training sets
the bottleneck
pretty soon becomes your training set
but I'm gonna try this question is
slightly different angle so early work
in computer chess found that having the
Grandmaster accentuated by computer was
not nearly as good as just using the
computer and if I understood the least
work with alphago zero it did better
without the encumbrance of the human
training cycle and doing average
learning with other computers just
philosophically seems very foreign to
what you were just talking about that is
a humano centric approach well um not
really we as humans we learn we don't
learn really here we learned in school
we learn a little bit in school but we
learned most about how the world works
you know when we're very very young and
probably can't even talk yet so we
learned by trial and error the systems
that were so I should say the word
reinforcement learning which is my area
of expertise my favorite favorite
subject kind of learning and reinforce
learning is what is learned in these
trial what is used in these trial and
these self play methods where you get to
try out many many games and so this is
it's not learning from people it's
learning in the same way that people do
it's more it's it is like in this very
human like this learning from from
trying is it it's it's it's true that
you can in game playing you can play
massive an amount of experimentation and
and and these methods and do leverage
that but the general idea of trial and
error is is doesn't require simulations
now let me just say one more thing about
that which is games are special because
just for this reason because we have the
rules of the game that we can build them
in and so we know how they work and and
we really need our I forget who who
talked about like the the vase on the on
the table and how it was about to fall
off so we know the way the physics of
the world we know how objects move and
we need to be able to plan we mean it
was like alphago for the real world and
for that you'd have to replace the the
moves of the game the rules of the game
with the rules of the world how what are
the laws of physics what are and more
important than the laws of physics are
intuitive things like well if I if I hit
my friend you know they'll be here may
might hit me back okay that's not laws
of physics or if I scream maybe maybe my
caregiver will come and help me so we
need to learn how the world works and
then we need to be able to plan with
those things way we can't plan so well
in chess and then go and in poker as
well so I'm circling back with the time
we have left
um
I do like this larger philosophical
question about AI futures and I love
this criticism of dystopian views if
suddenly this alien intelligence comes
out of nowhere and scares lesson takes
our jobs and does whatever as opposed to
the notion that you grew up with them
like a parent and that parenting analogy
to me is powerful because if you think
of parenting the next generation you can
ask the question would you want your
grandchildren to be smarter and
healthier than you metaphorically right
and then I think the human sentiment
shifts from supremacy like we are the
endpoint of evolution the buck stops
here to use symbolic immortality that I
think is what we are as agents for a
culture and humanity is to advance the
ball and if we could parent something
greater than ourselves I think we would
take great pride in that well I know
there's a lot of people normal world
work in the room working on that very
well sets Steve let's take pride in the
accomplishments of it of the things we
create collectively as a as a society</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>