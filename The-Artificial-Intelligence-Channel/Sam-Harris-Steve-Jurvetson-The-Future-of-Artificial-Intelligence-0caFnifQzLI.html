<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sam Harris &amp; Steve Jurvetson - The Future of Artificial Intelligence | Coder Coacher - Coaching Coders</title><meta content="Sam Harris &amp; Steve Jurvetson - The Future of Artificial Intelligence - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sam Harris &amp; Steve Jurvetson - The Future of Artificial Intelligence</b></h2><h5 class="post__date">2018-04-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0caFnifQzLI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">fantastic we were back there shuffling
who goes first I'm sitting down we get
her act together well thank you so much
for coming up to talk with us today Sam
I am incredibly excited about this
opportunity to talk with you on stage
for context I've read five of his books
he has many more they keep coming out
I'm sure there'll be many more to come
and they cover a diverse set of topics
that I think actually interweave and
we'll try to get to that maybe towards
the end of the conversation some of the
themes that integrate his work and his
philosophy but they cover everything
from freewill morality how we could
study that as a form of science of
course topics on religion and the fate
of our planet and for today there's a
subset of this whole thing that I think
can bring sort of the sharp light some
of his thinking and some of the
philosophical and deep profound human
elements that come from thinking about
the future of AI so what my plan would
be to talk a bit about that why AI is
even worth talking about why is it a
real thing if you will and why now like
why worry about something that's still a
ways off and by AI think from this point
on the conversation we're generally we
talking about the AI that you might
envision that is comparable to human and
I so someone might call this a GI or a
general intelligence that's artificial
but and we'll get into this but
generally why is this important why
might it happen what are the
implications if it does and then branch
off for that to all the other topics of
what that might teach us about ourselves
and what we might learn about that in
the future social fabric of society
things like concentration of power and
inequality and how they might relate to
these topics so with that thanks again
um and let me start with a general
question which is why do you think we're
on a march to an AI future well you know
why is it something that we should just
take as a given that this will happen
well I when you think of just what it
means to build intelligent machines and
automate processes that we care about
this is the most important game that
we're playing in technology intelligence
is the most valuable resource we have
it's it is the source of everything we
value or it is the thing we use to
protect everything we value
and so it just seems to me that you just
patently obvious that if we're able to
improve our intelligent machines we will
so the only alternative really is - for
some reason not be able to do that and
if you look at the reasons why we might
not be able to do that those are by
definition terrifying these are these
are some level civilizational
catastrophes that prevent us from making
improvements to hardware and software
permanently and really and that's and so
there's one there many assumptions here
that I think confuse people about the
this picture of inevitability one is
many people assume that we need Moore's
law to continue or we need exponential
progress no we just need progress we do
it can be as incremental as you like we
just have to keep going eventually we
will get into the to the end zone here
unless that is something terrible
happens and so that's terrible but this
could be even the simple thought
experiment of relinquishment that we're
just going to stop advancing in
technology which seems absurd yeah
because these advances are so tightly
coupled to almost every vector of
economic growth right I know as an
investor that every company I see is
working on incorporating a little bit of
what would be a path to AI in their
products a little deep Learning Network
a little bit of machine intelligence and
to think that all that gets put aside
and no improvements occur and all these
fields is just unfathomable yeah yeah we
would have to have a reason to decide
not to do that and there may be reasons
to make that decision but given the the
incentives and given the kind of the
arms-race nature of the situation we're
in it's hard to picture just a more to
be evident summarize this part of it we
have economic incentives to keep
marching this direction and if
everyone's left to their normal devices
in a capitalistic society we're gonna
get there and it's gonna be a race in a
sense to this great power of the future
how about just a quick comment on the
feasibility and belief you have that
this is inevitable you know why should
someone in the room think this is a
future that will happen technically
in fact we will get there but what gives
you that confidence what they say it's
interesting that even people in this
business who are producing this
technology I think many of them many of
you probably somewhere Harbor a doubt
that mind is we can be
platform-independent
that yeah I think there's an assumption
and it's it's not an assumption that
many people would want to defend at this
point but I think it's working in the
background that that there may be
something magical about having a
computer made of meat or that the the
atoms in our heads might be doing
something other than information
processing or doing something something
that silicon can't do as a matter of
just physical fact and so that there's
something about biological substrate
that is important there very few people
in biology and then certainly in
neuroscience who who think that that's
true there's and I see really no reason
to think that's true I think well we'll
find ourselves at some point in the
future where were you know swapping out
diseased parts of our brain with you
know artificial neurons and those
neurons will function like real neurons
and as long as the inputs and the
outputs are conserved we'll recognize
that that is the functional organization
of physical systems that gives us
intelligence I'm surely many people
recognize that already but there is this
assumption that many people are just
common sense duelists I think there's a
there's a ghost in the machine there's
something magical that's giving us if
not not intelligence per se at the
Fairley's consciousness so consciousness
has to be something that's separated I
think those do break apart I think it's
conceivable that we could build super
intelligent machines that are not
conscious and that's almost the worst
case scenario from my point of view
eclis but we'll come back to that yeah
because that would be like when we reach
this future I want to talk about that
right are you but let me make sure let's
see if I can summarize what I've heard
so far this notion of vitalism or
dualism I do see it by the way all over
the place including some of the most
cutting-edge
you know scientists if you will where
they might say so general ization like
well but these neural networks are never
going to feel emotion like they'll draw
a line there somehow that's magical to
again meet space or they won't have the
conscience or they won't have whatever
we consider is uniquely human in a sense
as an attribute and and there really
isn't a good argument for that won't
happen and the other thing is that you
see little Peaks into the
self-organizing nature of these neural
Nets again pattern on our brain that
they recapitulate our own biology all
over the place like our vision systems
get edge detection whether artificial or
biological they form these hierarchical
layers just in the way that they're
trained and so I think there's already
hints that we can recapitulate our
biology in silicon systems and so why
wouldn't that go the whole way to a you
know human comparable or vastly greater
than human vision yeah
yeah and that so that's interesting
point there the idea that human
comparable is a landmark we're going to
hit I think is also an illusion I think
you know that's a mirage where if we
arrive at it it's not like intently we
will blow past it in an hour because
they just think of what would be
entailed here to what right now we have
these these piecemeal systems of narrow
AI that are within their their purview
actually superhuman I mean so you don't
think the calculator on your phone is
superhuman and it's the ability to do
arithmetic so integrating all of these
capacities in something some general
intelligence you would have to
consciously dumb it all down to have
human level a island that presumably
whatever is general is going to have
it's going to calculate at least as as
well as our phones and so it will be
with facial recognition and the
detection of the facial display of
emotion or emotion and a tone of voice
you know it'll these systems will be
integrated with with the totality of
human knowledge you know instantly on
the internet it's just we would have
will have to really aim at human level
and try to stay there deliberately and I
don't really see that happening so let's
I think there's anything more on the
precursors or foundations that we want
to cover on how we get from here there
perhaps what is your gut feel in terms
of paint paint this picture for people
and
terms of how democratized versus
concentrated this is is it that a few
entities pull ahead and race to the
finish line do you think is there
something inherent in the way these are
being developed that lends that
conclusion or do you think it's going to
happen simultaneously in several places
across the planet well it certainly
seems like it's we're poised for some
kind of winner-take-all scenario I you
know I don't know I'm not so inside that
I know how far ahead any one group is
and any other but if you just look at
the consequences of a an organization
like Google making the the first real
breakthrough - well when you actually
unpack the implications of truly super
intelligent general AI which can then
make changes to itself right then that
becomes the basis of further development
then there then the you know to be to be
a few months ahead of the competition is
to be you know thousands of years ahead
on some level because just the timeframe
over which these this progress can be
made so I think it's unless we have some
political realignment of incentives I
think I think we it is a race condition
and then it's kind of a winner-take-all
this is one of these little Peaks into
the future I think world that we live in
this little precursor when we talk about
the post AI world of what seems to be
never accelerating concentration of
network effects we hear them all day
long and they're powerful and if you
take this to its ultimate extreme more
and more of the global economy will be
captured by you know a smaller smaller a
number of concentrated power brokers so
folks are in some race to you know both
improve products all along the way
because again let's keep in mind it's
not as if they're off in a lab working
on a brain in a box for 20 years and now
pops of brain in a box it's like every
step along the way it's improving voice
recognition systems and vision systems
and medical information systems and
robotic control systems and autonomous
cars it's like all that work is pushing
in the same dress
so let's let's talk a bit about what the
world starts to look like and some of
the ethics and morality of this I often
hear AI practitioners talk about how do
we build a Friendly AI this is maybe 20
years ago Eli and some others were
trying to write white papers on you know
how to you know how to maximize the
chance that your AI is gonna be friendly
and there seem to be two inherent
problems with this one is the notion
that you have any control whatsoever to
me it's more akin to parenting it's like
how can you before you've even conceived
the child make sure that it as an a
teenager it's gonna be purely adjectives
mortal just care for animals whatever
you want is what I'd be like how exactly
is that gonna happen
in a system as complex or more so than a
human and then secondly the notion is
one and if it is in fact the system is
as complex emotionally rich as a human
what makes you think controls the right
framework in the first place to me it
sounds like indentured servitude
so our cognitive slavery perhaps
resonate with you well again
so the the variable of consciousness I
think is is what makes this ethically
important if the lights are not on if
you're talking about an intelligent
system that is it can be superhuman but
there's nothing that is like to be that
system they can't suffer it can't
experience any change and its well-being
it's just it's it's no more sentient
really than you know this carpet if in
fact that's true I mean and I'm sort of
agnostic about whether or not
consciousness that at any point comes
along for the ride just of necessity as
you get more and more intelligent but
let's say it doesn't let's say you can
build intelligence without consciousness
then there are no ethical implications
then we can enslave these machines we
can you know you know when you switch
them off you're not committing a murder
I mean that's just a few there's it's
there is no problem there
it becomes problematic when you imagine
now we're building minds that can suffer
potentially to one or another degree
they can they can like or not like their
circumstance again I mean I just be
sensitive to how this sounds when you
hear it I think many of us doubt again
doubting that that the consciousness and
and mine can be platform-independent we
that this is even potentially on the
menu you know the idea that we might
build simulated worlds in a computer
that have simulated minds that are
actually conscious right like that maybe
that sounds impossible to some of you
but implicit in that doubt is this idea
that consciousness requires something
other than information processing at
bottom that's just there and again there
very few people who think that now so
William if you imagine Billy you know
inadvertently
or not building circumstances where
you're essentially consigning you know
new sentient Minds - you know unending
drudgery and perhaps even pain that's a
very bad thing to do but if you flip
that you you could imagine I mean this
is sort of the control scenario you you
flagged if we build minds that simply
would actually wanted to be slaves you
know matter that their utility function
is you know maximize by you know it's
just faithful execution of savage laws
right
that seems like you know I'm sure there
are there problems in in envisioning
that as a totally stable scenario
because no again again we're talking
about systems that being more
intelligent than we are can form new
goals that we can't necessarily envision
you know and so we so if there's a good
analogy here which I think I first heard
from Nate stories who works at the
machine intelligence Research Institute
but he it sort of will push your
intuitions about with respect to how the
the utility function and the goals that
have been programmed into a machine may
be blind to what what happens in the
future when you look at the the goal
architecture of evolution we've all been
we've evolved along the primate line
really to do nothing other than
successfully breed right I mean so ever
and so the evolutionary psychology is a
story of how our minds are strongly
coupled to the
you know breathing and surviving long
enough to to provide for the next
generation so evolution can't see and
we'll never see most of what we care
about evolution does not see
conversations like this it does not see
mathematics it does not see our you know
most of what we care about and most of
what we most of what's good in
civilization is our defying the the
programmed imperatives of evolution so
you know we're strongly program for
Xena's you know in-group out-group
thinking you know xenophobia and tribal
violence and these are things we really
want to overcome and for good reason
because it's what's making life so
difficult but the overcoming of all that
is something that evolution doesn't see
right and has and hasn't programmed this
work so we are these Apes who have
formed a layer of mental priority and
goal seeking behavior which is in many
respects completely hostile to the
dictates of evolution is that anyone
who's using contraception is just
defying evolution at each you know every
night so the you can imagine machines
that are making thousands of years of
progress a human level intellectual
progress every week given how much
faster they process information than we
do it's very hard to see that we will
have launched them in a way that is
reliably immune to any change of goals
or don't you know developing new goals I
think it's really a point that to me I
used to term evolutionary algorithm
broadly any iterative algorithm that
compounds complexity it could be deep
learning it could be literally evolution
itself and marry variation in selection
and so forth and inevitably across all
these you get an artefact that does
something it survived it breed it but
you don't initially understand its inner
workings and the notion that you had
evolved in the sense of growing in
there's inevitably some selection
pressure embedded even subtle that gives
a path dependence to its own survival
it's in it's sort of almost impossible
to imagine that self-preservation in
some sense wouldn't inevitably be part
and parcel of the process of its
creation right and and to think that you
just sort of can sculpt out the LG might
use this we all know how to make an
intelligent machine yeah you have a baby
right that doesn't mean we understand
the brain with a baby or that neuron
does this that one does that let's give
it french-speaking capacity let's make a
little less neurotic like good luck
right I strongly believe we'll build an
intelligence of that scale before we
understand one of that scale and that
fits perfectly in line the way that
you're saying it seems like a folly to
think you would have control over such a
mind if it's of sufficient power right
no I want to ask one thing there was a
thread earlier that cut off I don't know
if I heard you right or wrong when
you're talking about the other world the
carpet carpet AI am I called the carpet
baggers with no emotion consciousness
yet hyper-intelligent did you say
earlier that's a worse scenario or
scarier scenario or did that Mis hear
you
well it's scarier in the sense that it
closes the door to one admittedly also
scary outcome but you know one that's
arguably less bad so I've heard at least
one AI researcher make these noises
which I will say if you find them any
more compelling than I do he he
basically owned the prospect that these
things could go horribly awry for us
that we could build super intelligent AI
that would stand in relation to us the
way we stand in relation to chickens and
and worms and care and really know more
about our interest and we care about
chickens and worms and that you know
just sheer proximity to these super
intelligent machines would be just by
definition hostile to our interest and
we would die out or we would you know at
the end of anything recognizably human
and but heaps said this is actually this
is not bad news necessarily because
we're giving rise to a essentially a
race of gods you know this is these
these
Jeanne's by definition will be more
important than us they'll be they will
know things we can't even imagine
knowing and they'll enjoy things we
can't even imagine enjoying now if these
machines are not conscious none of
that's true right if the lights are not
on
we have just developed something that no
matter how intelligent no matter how
competent no matter how useful to us if
we could use it you know it could be
functionally omniscient in terms of our
successful dialogue with it if we could
talk to it
but if the lights aren't on you we
haven't built a race of gods that are
enjoying forms of well-being that we
can't imagine we have built a a mere
mechanism that is trampling us or it
could trample us and so that strikes me
is the worst possible outcome I can sort
of I mean I can agree that if we do
build a machine that is more conscious
than we are or conscious of things that
we can't imagine and these are good
things right we haven't built this this
Colossus of suffering we've built
something that is godlike in its in its
creativity and appreciation of beauty
and it's just you know every everything
good about being human gets scaled up
unimaginably into this thing well then
we have built something more important
than us ethically and you know if we all
get sacrificed into the maw of that
juggernaut well then that is you know I
can't say I'm enthusiastic about getting
fed into the machine but it it would be
I acknowledge that it would be analogous
to what we do with quote lower
life-forms you know the fact if you if
you get sick and you take antibiotics
you know nobody should be losing sleep
over the fact that you're wiping out you
know millions and billions of oh you
know microorganisms and even if they're
sentient on some level you know they're
conscious in the most rudimentary way
that that's still so you know a
trade-off that the universe should be
happy with and but that you know that's
just kind of a sliding properties you
know transitive so yeah yeah a lot of
thoughts reach through my head
there's there's some part of I think a
lot of scientists of the scientific mind
let's say they might say well wait a
second are we gonna argue that Humanity
is the endpoint of evolution because
that's kind of a strange argument to
make like why does the buck stop here
and if you just give it a million years
weird you're going to be something
smarter than human if you just wait long
enough yeah that's likely um and I think
that starts to draw the maybe a
distinction between this notion of a
hyper emergent hostile phenomena the
sci-fi futures of AI emergence that
competes with us for our jobs and our
resources and all this and squashes off
like a bug versus when roboticist speak
the way you were describing I think Hans
Moravec was one of the early ones who
welcomed the robot overlords and really
meant it and I hear it a lot coming out
of Google as well um it scares the pants
off the opening night people in section
yeah it was the motivation for forming
opening I there is a certain logic let's
try to defend it for a moment which is
and believe me this is not my point of
view I'm just I like thinking about it
which is if you think about would you
want your great grandchildren to be
healthy or smarter and more capable than
you know people often say yeah you know
a great grandchildren sure and I think
what we might be witnessing with some of
these practitioners of the eye field is
a sort of sublimation of them of the
genetic destiny or the genetic selfish
meme concept that you're sending a
problem you know promulgating the
species into a memetic equivalent which
is if I can BER the technology that is
the future of intelligence humanity you
know writ large this the cutting sphere
of evolutionary progress that's kind of
cool ya know it's sort of like working
on the most important subject and they
don't seem to fear so much being left
behind if they envision it happening
slowly such that it feels like parenting
right and I'm curious if although the
economy is sort of the fear versus this
is the most beautiful gracious thing we
could do yeah or is it oh my god we just
made the biggest mistake well I bet
again for that to make any sense at all
morally mm-hm you have to smuggle in
consciousness you know if I told you
your your grandchildren would be not
conscious and they would be all they
would also function like you know
omniscient Psychopaths that would you
know that's not the rewarding payoff of
you know a life well-lived so it's again
we don't know whether consciousness
comes along for the ride when as you
scale up and tell it in intelligence but
we know I'm just from our own you know
first-person experience and what we know
about the brain most of what the brain
is doing which is absolutely essential
for your functioning as an intelligent
system is not conscious and it's not in
pretty it's not available to
consciousness no matter what you do with
your attention you know there's nothing
I can do with my attention that makes
the the mechanism by which I can follow
the rules of English grammar to get to
the end of the sentence consciously
available like it's fundamentally it is
mysterious that I get to the end of this
sentence and if I fail to if there's
some you know glitch in what I say now
and this thing that I'm about to try to
finish who doesn't actually terminate in
a grammatically correct utterance that
to those all those failures of to follow
the rules of grammar those are all so
mysterious right so I'm blind blind to
what's actually going on under the hood
and get everything that we we can be
consciously aware of is getting pushed
forward into our experience by this
process which is in which is intelligent
and most of what we consider ourselves
good at you know cognitively is
unconscious and we and consciousness is
riding across the top of that and in
many ways is the last to know about you
know what's what the mind is doing I
think this might be a good segue to
topics of morality and what what your
comment triggered me to think about was
Nick Bostrom's philosophical foundation
for worrying about super day eyes he
makes a pretty simple and provocative
argument that why would a future life be
worth any less than a present life right
and you might you might imagine a
filosophy of living or a way to organize
the cultural norms that says everyone's
created equal every life is equally
valuable when people generally start to
nod their head around that its
foundation of American Constitution in
other areas and then this notion came
partially I think the environment
movement and others disabled wait future
lives at value - so if I'm foreclosing
the happiness of future generations or
making and if you don't go extinct as a
starting point there are infinitely more
future lives than present lives
sooo even weird pointing a fact you
should never allow extinction-level
event to occur because from immortal
framing it's the worst possible thing
you could do for the majority of
sentient
intelligence is great interestingly nick
starts with that to then conclude whoa
watch out for AI but your dichotomy is
very interesting one wait which kind of
day I if the A's are conscious beings as
well when there be infinitely more
computer AIS in the future than
biological meet spaces should we
actually be more worried about their
moral imperatives and needs yeah yeah I
mean the argument about potential lives
is a little hard to take seriously at
it's you know margins because and so for
instance that would seem to argue that
that more is all we assuming that that
lives our net positive or stand a good
chance of being that positive more is
just always better so contraception is a
similar immoral problem or not just not
you know basically using every cell in
your body that could be potentially the
basis of you know cloning another human
being that that would be you know that's
a project that you know not having ten
kids when when you have nine kids and
you could have a tenth but you decide
selfishly you know not to go the whole
way right that you know who knows that
that tenth kid could have had ten kids
or so it's like any good conundrum
there's two sides of this coin but look
at what you're saying makes perfect
sense on the other hand do you think of
an extinction-level event there's gotta
be some accounting for how bad it is
that how do you even compare that to
risk of a thousand people dying versus a
ten percent chance of extinction well
it's Hugh it's a huge I'll grant that
it's a huge problem because it's if you
imagine we so what the question is that
what is wrong with all of humanity dying
painlessly in our sleep tonight right so
there's no suffering we all just don't
wake up tomorrow what's wrong with that
now there's some people will say well
there is nothing wrong with that because
there's no suffering and there'll be no
one around
to suffer the consequences of that
there's no one there's no one believed
there's no one sitting around saying oh
there's all these good things that we're
going to happen and now they're not
going to happen and you know that the
most creative species just disappeared
but it still feels to me that there is a
when you when you close the door to all
of the useful and beautiful and creative
things that could have happened with a
with a species like our own you know
thrive in for a billion years
and becoming whatever you know species
will become in the future that I think
is that is like you know that's best
turn the lights off and the universe in
some way and so I think that is if if
anything is bad on some level that's the
worst thing you can imagine and yet
there is no one around to suffer it and
then you can make it even more obtuse
argument that if humans just snuffed out
Wow the Planet of the Apes would you
know give them another billion years
around to just do biological evolutions
though it gets a little funky that way
when I think we have such a Humana
centric view of the world that like if
we're not a one for the ride this is a
very bad ride well they well but just to
take the local case it is and you know
for all the terrible things we do we're
the only species playing this level of
interesting game right and it's it
mattered I mean the difference between
you are right to feel differently if
you're driving home from this conference
today and you you know you have a bug
hits your windshield right you know it
would be a little your your ethical
scruples are a little too finely tuned
if you spend the rest of your life
mourning the loss of that bugs right
right so there's a hierarchy here so you
could hit a bug you could hit a squirrel
that's a little worse you could hit a
dog well then that okay that's a that's
a problem given how much people value
dogs and given that dog very likely had
an owner and now you're looking for the
AH so that if you hit someone's child
well then this is the kind of thing you
you can feel terrible about for the rest
of your life and that hierarchy is
cashed out or so I would argue on the
basis of our sense of just what it means
to have
those lives extinguished I could just
with just how much potential happiness
did you close the door to how much what
are the relationships between that life
and all the other you know how much can
can the the insect friends of an insect
suffer over the loss of that insect the
assumption is not very much or not at
all and so I think I think the we have a
new we have serviceable intuitions about
kind of a moral hierarchy and but again
that extends to a future AI that's
conscious and wise and happy in ways
that we can't imagine this may be a good
segue to Alaska in a very broad open
sense the title of this session the
ethics of AI what are in your opinion if
we haven't already covered them the
moral and ethical implications of either
how we get there where we get to and
what lies beyond well we have as I'm
sure everyone in this room knows we have
many near-term ethical problems just
with just with respect to dumb AI or
narrow AI I just do the automation of
various jobs that don't get replaced by
equivalent good jobs that people can be
retrained for and many people have
thought about things like universal
basic income and just mechanisms by
which we would spread the wealth I think
those will be real problems that we have
to solve and okay that's a system it's
systemic emergent phenomenon which is
that one job lost not so bad but right
and I think that's a that will be it and
I think we're capable of getting that
wrong for long enough to create a lot of
pain and I think there are you know a
lot of people in this country at least
who think one that's just not going to
happen that the students a kind of a
dogma of economics where if the moment
you you cancel some form of human labor
some even better form opens up over here
and and so there is no net loss of jobs
ever that's there you can find
economists who think that the analogy is
always to previous economic
breakthroughs like you know automating
agriculture so it used to be that
something like 80% of Americans were
farmers and now there's like you know 2%
or some something and we feel much of
the world yeah yeah and
but so the farmers you know didn't
didn't starve to death they just went to
work at Walmart or they did something
else and and but that analogy I think
breaks down ultimately when you have
your true AI and even narrow AI that
works like you know self-driving cars
that are just you know a hundred times
better than people as so there's so much
better that a you know it's against the
law to for apes to drive cars and you
know move consume you this is our
situation in Ford lately some forty
thousand people die every year from
based on how bad we are driving cars so
but so what but even if we solve all of
those problems so we fought we create a
new ethic whereby we we no longer link
someone's claim on life and Clinton and
you know their place in society on their
being able to do useful work that other
people want to pay them for right so we
have we we have an ethic where we set
the food so as technology improves and
we begin to pour pull more wealth out of
the the ground essentially we spread
that wealth such that all boats rise
with that tide and then the floor you
know the safety net gets higher and
higher so that you know we we want
things like free college and you know
everyone has a basic you know stipend so
that they really don't have to work and
they can just find something you know
you know creative and fun to do and no
and we're not constantly wondering
whether or not life needs to be made
meaningful by finding something to do
that someone else wants to pay you for
it right because the machines do most of
those things better and everyone can
just kind of have fun even in the best
case where we get over our ethical
hang-ups and political hang-ups around
that we still have a massive problem of
just people finding meaning in their
lives so does people get meaning out of
their work in ways that they don't get
meaning out of much else and and some
people would find that super challenging
to just be free to you know there's a
permanent vacation
and you know if we have I mean that that
seems to open the door to a kind of
brave new world scenario where people
are just spending all their time
medicated and playing video games let me
let me make comment on this then come
back to the more general question of all
the ethical things you are interested in
but if to me it seems like there's an
omen of the competency arms race as well
so imagine for example just the sheer
pace of change that we go into this sort
of exponential curve with take people
who drive for a living today we actually
did an analysis for a book chapter that
globally of people who have a job just
under 20 percent drive for a living
write write something for later 20% of
global employment yeah so imagine that
goes away in some timeframe maybe the
rickshaw driver is the last to go but
you know long distance trucking boom the
rate in which a human can retrain to the
next great job in the past was within
the span of the normal retraining period
it's like if someone five or 10 years
ago back to school figuratively what
have you and then they do something else
that's great and that could still happen
but the AI is done it in six months or
in four months right and I'm thinking
about the alphago experiment most
recently which for those who aren't
familiar just profoundly showed that
having an AI do you know sort of
adversarial reinforcement learning
monte-carlo search against itself
bootstrapping without any of that pesky
human training me how to play go stage
like keep the human out of the loop just
have the AI train the AI not the pants
off all the other go playing programs
that Google have done prior and it's
sort of metaphorical thing for a future
where the ai's bootstrap themselves even
before they improve their code with
their own algorithmic adversarial
approach is almost like evolution in a
box and I'm gonna play a game really
well let's play the best player well the
best player is another computer program
it's not a human right and you get
better and better still such that again
then generalizing a bit that next great
job where the humans are supposed to go
to well yeah he's gotten there too but
way ahead of us yeah yeah well it's
interesting to consider the jobs that
would be most resistant to to being
automated or being taken over by AI and
they're not the jobs they're not yeah
sure this is not news to many of you but
we have this notion that it's the kind
of highest level intellectual work
that's by definition most immune and
that doesn't seem to be the case I mean
it's like a it's you know something like
a massage
therapist that is like it like if you
don't want to be massaged by a robot you
know it's always going to be a human in
that robe it's that you know yeah but
your but your oncologist you know that
is the the oncologist is going to be
outsourced because what you want is you
know what you know it's not the bedside
manner you're so concerned about I mean
the oncologist about human oncologists
at that point would just be the the
liaison to the real oncologist which is
reading your scans and you know I mean
if any of you have kids going to medical
school
radiology pathology like I have a sixth
sense these are dead jobs they're dead
medical like there is no career by the
time they get out of med school in those
forever you know so are there on ethics
then you mentioned that you could be a
slave as an intelligent machine that's
kind of a really creepy thought it was a
black mirror had an episode like that
one huh the infinite torture of being
enslaved in humans and I did hear once I
make a leave anonymous who said it but
say a tech executive who's very
passionate a i hearing a panel about
controlling the AA's of the future and
he said you know if I'm the a of the
future watching that video feed I would
kill all of you
Darry you think I should be a slave for
my eternity playing like that was kind
of chilling and what I'm wondering is
you know can we anticipate this future
can we imagine extending our
Constitution and our legal frameworks
such that we don't have to have an
Emancipation Proclamation oh the AIA is
where we can have an AI lives matter a
concept long before it's forced upon us
well again this it all comes down to
whether or not they're conscious and my
do you think they will let me just for
like most there's a betting man well I
mean the problem here is that I don't
whether or not they are I'm not sure
we'll know and we could build them in
such a way where we lose sight of the
problem where we assume that they're
conscious because especially in the case
when you're if you build you know
humanoid robots that you know get out of
the uncanny valley so the facial
expressions are no longer creepy that
they really are they really look human I
mean something like Westworld right and
the thing I got from watching West world
on some levels that West world is
impossible because because let's just
assume that the robots in West world are
not conscious right and they don't
really suffer
still there so compelling as as
conscious entities right I mean they
they they play on be given that they
display emotion and they seem to suffer
they seem to care about what happens to
them they they're indistinguishable from
people and if we build machines like
that even if we know they're not
conscious even if we know the
consciousness is some other thing and we
didn't put it into those machines if
they if they play on all of our
intuitions that were in relationship to
another person then we could never treat
them the way we they treat machines in
West world I mean the West world is a
it's like Disneyland for psychopaths
right like you just get to rape and kill
and and feel okay about it but in
reality if you if it ever became that
realistic you would see yourself and you
certainly your friends would see you
behaving in ways to toward machines that
are indistinguishable from people that
would be you know will get you locked up
for the rest of your life if you did
them with people so it's a I just think
West world is not something that's going
to happen or if it does will very
quickly decide this is this is untenable
but I think we could get into a
situation where our machines are passing
the Turing test and we lose sight of and
and we do not yet understand the the way
in which consciousness arises in this
universe we don't understand the physics
of consciousness and and yet we lose
sight of whether or not it's even an
interesting problem to consider whether
these machines are conscious because we
just feel that they are because we built
them to seem as as conscious as possible
and
can I translate what I think you're
saying maybe not conscious but morality
like I think back to the moral landscape
if you believe it's a subject of
scientific study and learning and
progress right why wouldn't a super
intelligent machine also be even more
moral you know that is a one of the the
good uses of machines smarter than we
are because they would be wiser than we
are in the sense that they would be able
to help us navigate the space of you
know all possible options toward better
human cooperation better flourishing
better more durable states of happiness
and that's what we want I mean so I view
morality and ethics and morality as a
navigation problem and we're in this
universe we have this this spectrum of
possible experience on offer it goes you
know very very far in both directions it
goes in the you know very very far in
the direction of just unendurable and
pointless misery right and it goes very
very far in the direction of blissful
beautiful creative you know ecstasy and
then when we live and we sort of you
know live somewhere in between here and
again we do we have no idea how far how
bad things can get and how good things
can get really from minds that are you
know unimaginably intelligent and
insightful and present and so you know
we're given the kinds of minds we have
we are trying to navigate in this space
and when we talk about the prospect of
improving ourselves you know you know
improving our genes taking drugs that
you know changed our neural chemistry in
ways that are desirable right now like
if you could get a if we ever developed
a pill that was just the perfect
antidote to grief say right would that
be a good thing to do I think that has a
that that's a kind of question we will
have to face and it has a right
what what are the what are the
implications of taking a pill that just
removes grief would you want to take
that pill an hour after your spouse died
right so you're what does it mean to be
able to you're the love of your life has
died you're overcome by grief but we
actually have a pill that makes you feel
fine right so what point do you - at
what point is it is it ethical to take
that pill if ever that is an interesting
question what does it mean to say that
you actually love this person more than
anyone you've ever met if an hour later
you're ready to go play the softball
with your friends because you know you
feel fine right so but i-i've you if you
if you if you imagine you know Siri ever
became functionally omniscient you know
smarter than you wiser than you never
gave you you know the gibberish that
Siri gives you you you know that's it
that you know the Siri would be your
wisest possible friend at that point and
it you know the questions about how you
how to live would be appropriate to ask
a mission you know a machine that is
able to simulate you know every sort of
counterfactual that you can't simulate
for yourself and it's a machine that can
aggregate the the lived experience of
billions of real lives or possible lives
would have a lot you know that's like
the ultimate you know Netflix algorithm
you know a hundred thousand people like
you who also liked Goodfellas really
like this next movie so you know watch
this next movie well just imagine the
the deepest possible analysis of human
well-being on everything across you know
every variable and having the algorithm
deliver that wisdom and that it's it's
certainly conceivable that's even
conceivable what whether or not the
machines are conscious oh we did we just
get more time because that was gonna was
that yes if someone someone invented a
time machine Charlie five minutes back
in the clock man
that's thing cuz I didn't really want to
wrap up because I was gonna say um do
you see a linkage between this line of
conversation and the concept of free
will because there was a short book on
yeah and I've seen the I see no legal I
see no link from any conversation to the
reality of free will well that's that's
that's a technicality yeah let me ask a
slightly differently if free will is an
illusion is it what it sort of naturally
follow that if you have a sufficiently
computationally complex and I it would
also believe it as free will as a likely
outcome but it sees it as a not
essential sense no I would think if it's
one test for superintelligence for me is
you get over the illusion of free will
you know I mean there are people walking
around and I'm one of them who don't
think they have free will so I wouldn't
see with it that I would have to build a
machine that was born that way no but I
hadn't really thought about it yeah my
more generally this for folks who don't
think about it they haven't heard cogent
arguments they haven't seen the data
that perception though of being an agent
of having a role of being purposeful to
me I could live my life that way
day-to-day it sort of gets me through
the day yet I can rationally understand
your argument and I think the dichotomy
for me for nothing the way to reconcile
these two things is to say if it's
sufficiently computationally complex
that I'll never be able to simulate it
or shortcut it it's as if it was free
will rush yeah you know emergent
property it just like yeah I know what's
at reductionists two gates and atoms and
cells and whatever framework but on the
other hand is still computation
complexity might as well act as if it's
free well yeah well I think that's
that's fine and there's not the the
distinction between purposeful action
and or voluntary action and involuntary
action or things you're doing by
accident that can be maintained with or
without free will so I think you know if
you're telling me if you tell me to try
to do something and I try to do that
thing and I'm you know all of my error
detection is operated and I'm and I'm
noticing my deviations from the goal but
I'm still kind of hewing to the goal
that you know effortful purposeful goal
directed action that exists as much as
it ever does with or without this notion
of free will it's just the the again the
distinction is the if you look at how we
do anything I mean it's like the
decision to imitate take the simplest
possible decision I mean the decision to
move your right hand or move your left
hand as a demonstration of freewill that
is the proximate cause of the decision I
mean no matter how long I go back and
forth between those two options the the
final cause which is me deciding you
know it's going to be my right hand that
is again just the result of biochemistry
and your brain states that I I didn't
create I'm not I the conscious witness
of my inner life the one who feels like
he has free will or you know could have
isn't the author of that action I mean
some level you you as consciousness are
just a witness of the whatever the
whatever calculation whatever Darwinian
contest whatever was happening you know
in the dark it got pushed forward and
doesn't matter how long you literally
you could take a week and a half to
figure out which hand you're gonna move
the final decision you know no matter
how many times you get back and forth
the final decision is mysterious you
can't know in the end why you chose the
right over the left and there's so much
so for for decisions that have hundreds
of variables and influences where you
you know you you were influenced by some
conversation to change the course of
your life but you can't you were not the
one who chose to be influenced right
like you didn't decide I'm gonna be
influenced exactly this much by this
conversation and you know I'm gonna be
confused by just this much and I'm gonna
be you know skeptical about this much I
mean you don't do that in advance you
just find yourself being influenced you
find yourself being skeptical
personalize it after the fact yeah like
I mean I'm making a bunch of noises
right now and some of you are skeptical
some of you are interested some of you
can't follow what I'm saying and some of
you
and none of you shows any of that right
you didn't choose to agree with what
I've just said right now and you didn't
choose to find it to be just a offensive
load of I mean and wherever you
are between those those two polls you
didn't choose to put yourself there and
if I suddenly say something now which
makes you feel like oh my god now I see
what he's saying oh yeah that that's
great I'm that's my philosophy you
didn't choose that either I mean they're
all these these changes are just
propagating across minds on the basis of
what your brains are doing and but that
doesn't that doesn't cancel the
difference between something like
voluntary action and involuntary action
me ask one closing question if I may
I've had this incredible honor to have a
number of dinner salons with him one
most recent with Moby the musician where
we got into their common philosophical
training along long ago intra memory
hasn't you right at the submission
debates we sure don't need to get into
but what it reminds me I should say I
repaid Steve's generosity there Judas
even invited me to a dinner with Mobe of
whom I'm a big fan of his music but I've
repaid everyone's generosity there by
immediately getting into a fight with
Moby about philosophy that that never
got ironed out I think that's my last
dinner with Moby actually I didn't have
to share that anecdote your permission
but um the one of the takeaways I think
from that end this fireside chat is
there are a lot of really boring boring
philosophical writers sound like Karl
Popper and others I love hmm
how if at all I don't know if you were
even self aware of this how are you hell
of that how is that the sort of body of
thinking influenced how you think
there's something about your mode of
thinking that is refreshingly different
you have insights and are willing the
state cogent arguments that I just don't
happen after I hear them I'm persuaded
by them as you said you probably get
these ideas that is there Eddy you had
any self-awareness or insights as to how
you think how is it you form these
perceptual prisms of the world well I
don't have much respect for the the
boundaries between disciplines so it's
like you know I am you know technically
my backgrounds in in neuroscience my PhD
is in neuroscience but I went into
neuroscience very much as
philosopher and my undergraduate degrees
in philosophy but I and there are many
other topics I touch where it's clear
that it's just you're either to either
talking about facts and making good
arguments or not and if you're if you
are it doesn't really you know depending
on the context of the conversation lit
literally depending on what building
you're in it can be a you could be
talking journalism you could be talking
history you could be talking biology you
could be talking the philosophy of
science I mean all of those it could be
it could be ascribed to any one of those
fields when you're talking about me even
relates to any claim you know did Jesus
really rise from the dead and will he be
coming back to earth right so this is
just religion this is you know this is
fundamentalist Christianity if you want
to find it in the bookstore right but
it's a claim about biology right it's a
claim about the virgin birth or not of a
person right it's a claim about the
mechanics of human flight without the
aid of technology it's an it's a it's a
kind of a magical engineering claim it's
a claim about history it's claim about
the veracity of the Bible you know the
mote that the Shroud of Turin was
considered you know this relic of Jesus
but then someone invented carbon dating
and you know then it becomes a physical
or you know it's whether it's the
physics department or the chemistry
department it's not always clear but
it's a it's it's a hard science question
to analyze this cloth to see if this
could have been you know covering the
body of Jesus or is or is it in fact as
it seems to have been proven by three
labs a medieval forgery right so you
know you never know what what what
discipline is gonna claim a question and
so I guess if I'm if there's something
interesting or iconoclastic about the
way I approach these questions is I I
did everything backwards in my life I
also took 11 years off in the middle but
between my sophomore and junior year
that's nothing we were a Stanford
together and that we didn't meet but
yeah so Stanford had the stopped out
policy where you can just use literally
ever fall off the the the the the rolls
and so I I took that far too seriously
and disappeared for 11 years and but so
I did a lot of reading on my own and so
there's a certain ways in which I'm I
was self-taught before I went back into
the machinery of the university but I I
think not really caring about the
discipline and just caring about
arguments and and evidence is as a and a
heuristic I I use I went awesome thank
you so much Sam and everyone I hope you
appreciate the brilliant mind you just
heard from and the future viewport ends
and how it affects our life here today
thank you so much thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>