<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Impact of Artificial Intelligence on Governance - Austan Goolsbee, Larry Summers &amp; Susan Athey | Coder Coacher - Coaching Coders</title><meta content="The Impact of Artificial Intelligence on Governance - Austan Goolsbee, Larry Summers &amp; Susan Athey - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Impact of Artificial Intelligence on Governance - Austan Goolsbee, Larry Summers &amp; Susan Athey</b></h2><h5 class="post__date">2017-10-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/T3AwTXRuUj8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">straight in alright so we are where
we're coming our way to the final panel
today this is going to be a panel on the
impact of policy there in kind of take
it take a seat
the of course the usual NBR rules I'm
gonna sit given the topic here specify
we we love to make policy
recommendations but things that will
inform us as to the policy-making
environment and assists policy makers
and of course just fine there been
several issues raised today and so I'm
going to guide the panel through a few
of them I think if one thing that has
come out clearly in a number of
discussions both this morning and it
certainly at lunch is regarding
different predictions of the speed of
adoption of AI and obviously something
that hangs in the middle of that as we
saw with discussions of privacy and
trade is what the government response is
either to speed it up or slow it down so
I thought that would be a good place for
us to start with the panel in terms of
what they think the first order issues
there and I'm gonna start with Austin
and we'll go through okay I think we all
understand why the speed of adoption
would make a huge difference whether
it's you know if four million auto
drivers of professional drivers are
gonna lose their jobs
you know we create five and a half
million jobs a month and we have 5.3
million lost per month so if that if
those four million jobs were lost over a
decade in a way we would barely notice
if it all happened this month then then
we would notice quite a lot I guess I
find myself a bit skeptical about the
speed of adoption of AI on a broad on a
broad basis in the economy and part of
it was Larry's point in his question
where he said well is it really faster
on the jobs front than it than it has
been in the past
but part of it to me is it feels like
the economics of that adoption decision
is premise on that essentially it's a
winner-take-all these are
winner-take-all markets and all we have
to do is get the AI to have a quality
superior and then everyone will switch
to that and I just don't think that's
true I think in a lot of these cases
it's easy to think of these as being
heavily segmented markets I think if you
think that then you gotta explain a
whole bunch of other things in the
economy like why is so much money still
going to actively managed mutual funds
and and not index fund and it's so
people do things that aren't that are
not in quality we would tell them it
doesn't make financial sense and I think
the second aspect about that is sort of
to our discussions about Facebook and
essentially your AI is only as good as
your training sample if the training
sample is not representative of all of
society then it's gonna it's gonna
accentuate this segmentation problem and
I can't remember if it's 2005 whenever
the Segway is invented you remember
there was trumpeting when mm okay
trumpeting including major names John
Doerr said this product is gonna be the
fastest product to 1 billion dollars of
sales that has ever existed and if you
thought about it why not I mean
transportation is a huge part of our
lives and the president the United
States falls off of the Segway breaks
his elbow people look kind of ridiculous
driving around in it it weighs a hundred
pounds so if you get to a staircase you
can't go up the stairs and the Segway is
largely a dud
I think AI has a lot of opportunities
but the we ought to be a little careful
with the Silicon Valley version of this
is the most efficient
I don't know that we have car sharing
programs I don't know that we will ever
have shoe sharing programs even though
in theory that that would be more
efficient most of the day most of my
shoes are not being used and so you know
people should should be wearing them I
don't think there are many types of
forecasting that haven't actually gotten
any better over the last 50 years as our
computing power has dramatically
improved economic forecasts haven't
gotten that much better oil futures
themselves are not that much better at
predicting what what oil prices are
gonna do and you may have seen the news
Panasonic just invented a fridge that
will come to you if you call it it will
bring you both that it's on wheels and
it drives to you to give you your your
drink I I just think a lot of these
things maybe we'll be segmented and the
the islands matter because if there are
a lot of people who either don't think
that the AI will choose vegetables
better than they will at the grocery
store there will be large numbers of
people who don't adopt it and if they
are correlated with a bunch of other
economic attributes what's almost
certainly they are then the AI training
sample will make the AI really great for
people who are very educated or who live
in the Bay Area or whatever it may be
but there will be large numbers of
people who don't adopt it so the speed
of adoption might might not be near as
fast as the optimist one there are many
many hard policy questions about AI and
about technology this is not one of them
slowing down technology is a dumb idea
it used to be that we explained in trade
classes that trade was kind of like a
new technology and it would obviously be
a bad idea to turn off a more productive
technology and therefore protectionism
was obviously a bad idea
it's the wrong thing to do one it's the
wrong thing to do because it reduces our
potential to be wealthy and with more
wealth and income we can achieve more
and do more for more people too
it's the wrong thing to do because even
if we turn off technology others will
not and our firms and our producers will
be poorer as a consequence relative to
other nations 3 it's the wrong thing to
do because it's very hard to predict
what the consequences will be and what
the timing will be two examples there
are roughly as many bank tellers in the
United States
today as there were in 1985 before there
were even 5% as many ATMs as there are
right now who knows there are a variety
of factors that can be adduced to
explain that but it says something I was
on a jet plane that was flown 6,000
miles without without its controls being
touched by a pilot for takeoff or
landing in the year 2000 I have not
noticed any reduction in the number of
pilots that fly on jet planes so what
the pace of this change will be very
hard to know forth there's a presumption
that we're not starting at the optimum
in anything we're the center of it is
R&amp;amp;D and the dissemination of ideas
there's a presumption that the market
solution is doing too little R&amp;amp;D and
speeding things up so relative to a
calculation of the first best we're
already in all likelihood slowing it
down and what's happened to public
science budgets in the United States has
reinforced that effect
so I am completely aware of 17 theorem
Joe Stiglitz will have tomorrow warning
about logically possible circumstances
under which it could be desirable to
slow technical change I regard those as
illustrative of a broad Metta
proposition that given any normative
proposition Joe Stiglitz can articulate
conditions under which it will be true
not as an illuminating statement about
what public policy should be and I think
this is an area where the economics
profession would do a substantial
disservice if in its preoccupation with
exploring interesting intellectual
subtlety it were to give aid and comfort
to the idea that an active policy is
slowing technical change would be
desirable you've actually thought very
much about the instruments that might
actually speed up technology adoption
especially with its interaction with
competitive forces and I was wondering
if you could comment on that sure I mean
let me let me back up a little bit
though and address some of the earlier
issues as well so actually I'm delighted
to be here to listen to these guys
because I have to talk about this topic
a lot and it's wonderful to hear from
from people with a different variety of
knowledge and perspective I think
actually I don't hang out with the right
people though because I've never sat on
a panel where someone said we should
slow down the technical change so like
the tax the robots taxing number that's
a little bit different I guess that's a
slowdown but it's also a way to think
about about you know redistribution so I
think it's some I think I agree with all
the things that were said but I think
there's a few things that also make me a
little bit worried like I would say why
could this time be different and I
like to be reassured that this time is
not but one thing that's kind of
interesting about this technological
change is is actually the industry
structure for how the technology is is
being adopted so on the one hand you
know we antitrust economist we spend a
lot of time worrying about like you know
the googles and so on and how they have
proprietary algorithms and it's was very
hard to catch up with Google and search
and so on but then on the other hand
we're seeing this like competing
industry structure transformation from
cloud computing which i think is
incredibly productive and
underappreciated and under measured but
at the same time perhaps exposes us to
more risk so basically like things that
in 2008 and 2009 Microsoft spent
hundreds of millions of dollars doing
the R&amp;amp;D for and was other than Google
one of the only companies in the world
that could do like understanding you
know being able to do all the spell
correction the entity recognition and
the language understanding and all the
things that you can do when you watch
people searches all day a lot of those
those things are now offered for very
low price or for free through cloud
services so if you want to start a
ride-sharing app you know you can plug
into the Google Maps API
you can use all sorts of services you
can use the machine learning services
that were state-of-the-art and being a
couple of years ago and that were
developed through years of learning by
doing to perfect and that's just all
like available and so part of why that's
all available is that Amazon and
Microsoft both think that there's going
to be a very concentrated industry
structure in cloud computing therefore
they're giving away a lot of services to
attract people to the cloud so that's
their motivation but the consequence of
that motivation is that it's actually
incredibly cheap to be a start-up even
me personally I have a bunch of data as
terabytes of data of mobile browsing and
I've got a budget of a couple thousand
dollars a year to store it and analyze
it which is just kind of stunning so
which and I can I I'm using all these
api's with maps and locations and things
like that to analyze it like like a like
basically Bing couldn't do itself ten
years ago so what is that what does that
mean well generally a lot of firms are
getting to the point where they can
mourn
we adopt software they're buying
software as a service in the cloud so of
course the banks are like the slowest of
that a few banks globally are moving to
the cloud but you know there's a bunch
of institutions that are very slow with
that but there's a bunch of them that
are quite fast and then what that means
is that once you're buying software as a
service and you're not tied in with
these huge switching costs with your
applications and so on if it turns out
that you can get great speech
recognition as a service in the cloud
and you know great AI services then
maybe a lot of smaller scale companies
could adopt it and there might be a
stronger correlation than the timing of
their adoption than there was in the
past so this is something that concerns
me and then when I look at specific
companies that I work with I've had
several companies over the last year and
a half come to me and say Susan what do
I do
I'm gonna basically decimate this
particular region of my country because
I'm gonna lay off I'm the biggest
employer in that region and I've got you
know customer service agents of various
sorts and it is no longer economical
today to have them there I'm just
waiting to figure out what to do when I
lay them off and so you know I think
some of these this will happen and it's
gonna happen in a bunch of different
countries at different times and then
when you think about what am I gonna do
with the former call center employees
bank tellers retail operators and so on
well these there's this sort of
correlated shock that's going across all
of these industries so of course in the
long run it's all good we have more we
can buy more stuff we can make more
stuff with less inputs and how could
that be bad but I think in the practical
transition you know I actually don't
quite know what to tell them I don't
know quite quite right to tell the
governments of those countries that are
gonna go through that I don't feel like
we have good retraining programs I don't
think we really none of us really know
what industries they should be going
into exactly so I feel like we're
incredibly unprepared for that and I
think it's actually a failure on all of
our parts both in our roles in
government and and in our roles in
academics that we don't actually know
some of the basic facts about what works
or what policies would be effective so
it may or may not be a big deal but I
think there's a risk that a lot of it
could come
the same time and we're not prepared and
that is scary so maybe this will give us
a little bit of a framework I think
there's three questions they're all
important and that are worth separate
and they're worth keeping clearly
separate because you can I think you can
have all eight you can have serve a lot
of different possible views question one
is is there a big threat that half the
population is becoming the economic
equivalent of horses because of
Technology a horse is just as productive
as a horse was a hundred years ago and
the economy is able only to support
about a twelfth as many horses as it
could a century ago and how serious is
the specter of that threat my instinct
tempered by the empirical observation I
discussed with Vinodh
despite not having a great
rationalization for that my instinct is
that that's a potentially very serious
problem and the fact that the share of
men 25 to 54 who aren't working has
already tripled is in the last
generation is evidence that that is a
very serious problem and I think the
answers to that have to lie in the
retraining area have to lie in the
supporting people who aren't working
have to lie in the recognition that
there's probably all kinds of productive
work to be done that may or may not have
a viable for-profit business model to
support it tutoring children one-on-one
taking care of the aged and all of that
which I think points to a larger
government but having people do what is
the moral equivalent of building
pyramids by performing tasks that can be
performed automatically by technologies
that cost very little seems very
unlikely to be the right answer so I
think that is a very serious problem but
probably not a problem that's usefully
address
by antitrust a second problem is is the
general availability of technologies
that are replacing what clerks do what
retail people do what wholesale people
do what radiologists do what nurses some
fraction of what nurses do is the
general pervasiveness of that 'no
sociated with large amounts of monopoly
power and profits maybe but sure seem
like there are a lot of different
companies that Vinodh was pointing to
sure seemed like these algorithms were
gonna be kind of available off-the-shelf
sure seemed like a lot of people were
going to be able to enter very easily so
maybe that's gonna be associated maybe
though the coming of that is gonna be
associated with large profits but
doesn't seem obvious to me that the
introduction of that technology is then
I think there's a third question which
is what about five big companies that do
a massive amount of information
technology related stuff in ways that
have networks in ways that seem to have
some economies of scale and are now the
five most valuable companies in the
world and whose activities also have
broad social consequences you know we
always the one hand you can say we're
like a free knowledge society on the
other hand you have to get a license to
start a radio station or a TV station in
America and so whatever the principle is
on which you need a license for a TV
station it seemed to have some
similarity with what's involved with
social networks and what
should our policies be with respect to
those companies with respect to others
who are trying to emerge as those
companies to what extent is it an
antitrust issue to what extent is that a
broader regulatory issue I think that's
a huge issue and but one that's somewhat
separable from the first two issues my
instincts are sunlight so my instinct on
the first one is big problem social
policy more government education the
answer my instinct on the second one is
probably not a big problem flourishing
ecology of a lot of people trying to
disrupt a lot of different industries is
probably a good thing and on the third
my instinct is that there does need to
be a lot of thought I tend to think that
you know we launched it begins I trust
suit against IBM and by the time we were
done with our antitrust by the time we
were done not winning our antitrust suit
IBM was looking a lot less potent than
it had been we launched a big antitrust
suit against Microsoft it wasn't looking
quite as potent by the time we were done
with that
I'm not sure that classic antitrust is
the right remedy but I very much doubt
that there is an adequate set of
regulatory frameworks in place with
respect to the very large technology
companies and I think that's an
important issue I don't think although
there are people in this room who know
much more about it than I that that is
entirely or even largely an AI issue
that is on denotes account we don't yet
have that much AI and it's coming and
the largest part of these issues you
know search we've had now for a bunch of
years and one companies had much of
search for a
years large part many of the issues
posed by Facebook are not centrally tied
up with AI so I think one should not
associate the Horsemen of the major
horsemen of the internet issue in a
precise one-to-one way with just a phone
and I think Austin has something to say
in in that regard just in terms of to
Larry mentioned want to accelerate you
know nobody agrees that we should hold
back innovation in an AI per se but if
we've learned two things from this
discussion and and other things before
they're possibly two things that are
obvious things to promote AI
specifically one would be to pour an
awful lot of money into artificial
intelligence research you know of a
moonshot type level and the second would
be to have a set of laws that allowed
you to collect massive amounts of data
from an entire population and be able to
put it to them use in training a eyes
and and doing other things like that
now those seem to be the two policies
that China has announced and that they
seem to be well aligned with pushing as
much AI as possible and so I wonder in
that regard how one would advise the
u.s. and/or other governments around the
world to think about whether they want
to be promoting AI in such that way in
that way absolutely any other unintended
consequences from its adoption like
employment I have no idea I don't have
an insight into that I think as you
describe what is the Chinese
government's policy which I didn't know
that then that it's everyone must
provide their genetic data or well you
know they have the ability to I mean
that seems not planetary in a in a
democracy such as ours I think it
strikes me that there's a decent chance
that our regulatory antitrust and legal
policy
toward the five horsemen of the internet
or whatever you want to however we want
to think about that will be driven the
same way that our antitrust laws were
driven in the past that is they will be
motivated by perceived abuses and
obvious examples and people say look at
what they did and the the Sherman Act
and and others were largely defined just
what is john d rockefeller doing let us
declare that to be illegal and that's
how they came up with a list of
behaviors that should be should be
banned I think that you will see things
like there was a time when the New York
Stock Exchange attempted to ban
newspapers from reporting the their
stock prices because they said that's
our data and you can't share our data
and we went through legal battles where
they define the law to just forbid them
to be able to do that
likewise radio stations getting paid by
the radio labels to play the music
because they knew if they played the
music would lead to more sales I think
they're gonna be a series of a what I
would call abuses but maybe they're just
economic behaviors of the following form
that I think will lead to to changing
the law say say Alexa you say Alexa I
need a new charger for my iPhone and
alexis says we have the amazonbasics
charger for $9.99 you say well I'd like
the I'd like an Apple charger I'm sorry
I don't understand
we have the amazonbasics charger for
$9.99 so the the bias the incorporating
bias into the into the general-purpose
technologies in a way that makes you
told taker on the Internet
I think it's gonna rise in importance
it's obviously in their economic
interest to do that and I think that
will lead to to to some legal addressing
that sometimes in the wrong way it can't
delay the adoption of new technologies
as you do that but at the same time I
don't think in a democracy
that that they're gonna have you send
your 23andme genetic information to the
University of Toronto so that they can
perfect their their their machine
learning tell that's the citizens of
Iceland yes president ask ask me about
the kind of question you ask I think I I
think I would I think these would be the
answers I would give as best guesses I'd
say probably no need for a massive step
up in research spending financed by the
federal government on AI you know half
the the most popular course at any great
university is already computer science a
little hard to believe that we got a big
shortage of talent being drawn into the
field a lot tons of efforts being made
by extremely rich companies to do
research in research in this not at all
clear that the government's going to be
good at figuring out what the right
research to do is so I would you know
should should NSF funding be adjusted a
bit probably but if you said should we
have the equivalent of the war on cancer
to have more better AI federally funded
I'd say I would be skeptical should we
have big new databases created by the
government it would make me nervous I
would have a bias towards pressure
towards open access with respect to
databases that were being created but
I'd be very open to various kinds of
regulation around the use of large
databases that gave people advantages
and I think I would discourage maybe I'd
be wrong but I think I would discourage
the john d rockefeller analogy because i
think i'd say you know gee
what exactly what exactly who exactly is
google ripping off how they give search
to the population for free maybe they're
ripping off a bunch of companies who use
it to advertise in some way but that
doesn't seem like a great populist that
doesn't seem like a great populist cause
on which to put the masses so I would be
looking more at the privacy and
exploitation of data questions would be
more my prism than the antitrust prism
would would be my prism at least the
only percent differently than the
consumer antitrust prism would be would
be my prism and I would want to know the
answer to the question which is not
obvious to me which is if you made it
you know Vinodh had probably 150
companies represented in his slides you
know little companies that were starting
things that we're gonna if you made a
rule that said Amazon and Google
couldn't buy those companies because
when they did it was competitive for all
these reasons would that make it more
attractive or less attractive to start
those companies maybe it would make it
more attractive because you could then
grow them and you wouldn't they wouldn't
be able to be competed with so easily or
maybe it would make them less attractive
because there'd be less likely to be X
would be harder to have an exit and I'd
want to have some well-informed people
with a strong view with some reason
behind their view before I'd want to go
make a lot of policy that was changing
things in radical ways actually I I know
the answer to that question
it's no wouldn't be a good idea to have
that band and we've done research in
that geoff hinton you're waving I think
you wanted to weigh in on on this yes I
want you to know what data you were
using when you said we didn't need more
government money to go into training
people because there's a huge gap in
Toronto I don't know the exact numbers
I'm afraid but there's a gap of about a
factor of 10 in the number of educated
people in machine learning that the
companies one employee and the number
that are going to be available it's not
just a factor of two it's a factor of
ten well so I have no opinion about
Canada because I'm American
but the more substantive answer I guess
I could give you to you I guess I'd give
you the economist and I guess I'd give
you the Economist answer which is at
some wage rate that's true and so I
imagine if it's really true that they
absolutely need those people that the
wages will be bit up fairly
substantially and I suspect if the wages
are bit up fairly substantive fairly
substantially than more people who are
talented if they're able to do it will
move into this field but the idea that
the government I mean I actually think
the rationale is a terrible rationale to
be perfectly honest with you the idea
that Google thinks it has a problem that
it can't hire enough high-quality
software engineers okay but fun the idea
the idea that a phenom --ax which is a
startup that has 22 million dollars of
venture funding for 17% of it can't get
software engineer engineers but the idea
that the idea that everybody's taxpayers
money should be used to support startups
Silicon Valley startups having to pay
lower wages seems to me nuts
so maybe so unless there's some bigger
extra now
then companies are experiencing
difficulty hire and all the people all
the people that they want I mean the
Celtics can hire as many great
basketball players as they like but
that's not a reason to have basketball
training programs right you know Jeff
and I are well placed to know that well
position to know that there is a huge
amount of investment by industry and AI
research and are indeed et cetera but
it's not sufficient we get all students
from universities we both keep a foot in
University for that reason and also the
style of research that's being done in
university is very different and most of
the good ideas in machine learning come
from academia still come from academia
even though the the fruits of it the
result of it are developed by you know
or research labs or or startups so I
certainly agree that it's not the job of
the government to you know make
engineers cheaper for startups but it's
certainly the job of the government
unless and mistaken to do what he can to
you know invest in the economy so the
economy grows faster and if there is a
shortage of machine owning graduates by
a factor of ten or two doesn't matter
what it is it's large we see this
everywhere including in the u.s. that
means the economy is not growing as fast
as fast as we could
it's not it's not if there were no
government the government had no subsidy
is the price the fixed factor why aren't
more students signing up if there's all
this if there's so much demand for
machine learning graduates it's got to
be something that it's really hard to
get outstanding people in the right area
but where do where do those percent more
like I mean they're where where do those
poor guys come from academic research I
think by the government I think Eric
wants to broker this
it's very brief the answer is it has to
be around externalities we sometimes
thinks they're externalities in
education and you have to make argument
along those lines which I think there is
a good argument you made well my
question was different actually another
thing that Larry said about privacy and
it seems to me like a really important
first tertiary over the past couple of
years hundred years we've had some
privacy but we heard a little bit from
Kathryn but I think even more you know
you guys know probably know the new
Apple has faced ID so it's recognize
your face to unlock it and I do they
don't have ID card you just walk in and
it recognizes your faces I'd be
surprised if China doesn't have a
database of pretty much everyone's faces
the UK has cameras everywhere which
probably shortly if they don't already
are feeding into that the IOT Facebook
has more data about all of us and can
infer our sexual orientation and
political beliefs and a lot of other
things whether or not we disclose them
so I think we're rapidly entering a
world has got me feelings that where
there is no privacy unless you you know
unless you move to a cabin in Montana
and disconnect but for practical
purposes it's a very different kind of a
world than what we've been used to and
I'd like to have you guys go a little
further on what kind of policy should we
have should we should we nationalize
Facebook's data they know more than the
government does perhaps about a lot of
things should we have some other kinds
of rules about how data is used in
insurance and health markets does it
mean we have to change the way that's
done it strikes me as a really quite
different kind of a world than what we
had just a few years ago and I'm not
sure that economists have grappled with
a world with with really no prospect of
privacy like what we've been used to
Susan you thought about that right yeah
maybe I'll take that in a slightly
related direction which is you know what
what are the policy questions that are
gonna come up practically about data
because we're practically we're not
gonna make Google share all of their log
data and we're not gonna like open up
Facebook's why not data the log data
because it wouldn't be useful and it's
it'sit's in it it's that's not the way
log data really works on the inside of a
company what is what is useful is there
are things
Facebook knows it actually would be
really quite useful so like one of
Facebook's strategic advantages is that
it knows who you are all the time it
knows exactly how many ads you've seen
while if you try to piece that together
using say like Oracle Blu Kai cloud type
of stuff you try to advert you think
you're advertising to ten different
people I mean and actually they're all
the same person and so you can't run
experiments and you can't evaluate your
advertising effectiveness and so on so
what would be really useful to firms
would be the ability to have the same
kind of identity understanding that
Facebook has but Facebook won't share it
and of course half the room would be up
in arms if we did that it would be much
more efficient for publishers we would
have a happier news industry and more
effective advertising but it would all
be all the much less private because I
just said what you really need is to
link everybody together but that is a
piece of data that would actually be
valuable and have market value and so on
but just like kind of trying to backward
engineer what's going on inside of
Facebook is really not not very easy but
I think there is actually something
coming where if we if we changed what we
do now we could actually have these
kinds of big databases in a way that
would have big social consequences so
I'll put out to you to all think about
this so I'm obsessed with transportation
I'm obsessed with transportation because
I think that if the if we automate
everything faster than we fix our
transportation infrastructure then a lot
of displace people who could otherwise
come to cities and provide services to
rich people in cities will not be able
to do so effectively because they can't
the cost of living is too high if we
reduce the transportation costs you
increase the land area at an r-squared
rate therefore you reduce the costs of
land which is one of the biggest pieces
of the cost of living for people trying
to provide services to people in cities
so if we can fix the transportation
infrastructure faster than we displace
workers then there'd be a natural
transition path for a lot of people to
basically you could a city could
basically get much bigger and much
cheaper so I'm interested in
transportation
what is that industry going to look like
well one question and it's like are we
what what is gonna owns the data of when
all these cars are driving around if you
if it evolves the way kind of search and
Facebook evolved and all the log data
for each company will be proprietary
there won't really be
way to cut sort of come back and share
it but if you imagine just like we do
with the electronic medical records or
something else if we kind of put some
data structures on it early on and got
some of that data kind of to be publicly
shared that could actually change the
shape of the industry and it could also
change the shape of the infrastructure
and so on so I guess the bigger picture
question that I think everybody should
think about is how are we going to
regulate cars transportation drums all
the all the imagery all the video all of
the the accident events is that I mean
you can tell everybody to share it later
but if the data is not compatible and
not meaningful you won't be able to do
anything with it
so we'll actually have to think about
that architecture relatively early and I
think it will matter in terms of the
speed of the the innovation the entry
the competitive structure and so on Joe
I want to just briefly refer to Austin
and Larry's point about Janet it would
be nuts to use your term Larry to
advocate slow time of technological
change and anybody knows my work
realizes that I'm a techno optimist and
written books how great technological
has been for mankind but I want to make
play devil's advocate just for a second
Larry did you think about something
there's a book my man called Edward
tenner called when technology bites back
in which he goes over a large number of
cases in which unanticipated in fact the
consequences of technology actually have
had very serious effects and and there
are few examples that he brings in which
one could actually make a serious
argument that the net social benefits of
a particular invention have been
negative one example that I think you're
familiar with is the addition of LED
compounds to gasoline introduced by
General Motors in 1924 or you know in
invention of chlorofluorocarbons for
spray cans by the way same inventor by
the way Michael Thomas Midgley long long
long story but listening to V not this
afternoon
you know if somebody who's really
worried about these bite
Effects of technology we're listening to
him examples could easily multiply and
the reason I think we should take too
seriously a lot of very smart informed
intelligent people were scared to this
by AI we haven't raised that issue yet
in this conference but I wonder you know
if there is really completely no basis
for the concerns of people like Elon
Musk Stephen Hawking and Nick Bostrom I
mean there's a whole people rioting
against AI as an existential threat and
what they must be worried about is
exactly the kind of bike back effects
that Turner is worried about now I don't
know what these bad back effects could
be I'd like the panel to think about
because really see what you see we
shouldn't I think we could agree we the
economists that we should not primarily
think of the bike bag defects as being
about jobs okay and that's what mostly
when people say that by all this is a
disaster because these guys are if the
world were going to end then after the
fact we could agree that was a bad
technology if we could have banned we
should have because I'd say so I'd say
three things um one so I've read
Tanner's book so I thought about what
you said I thought about what you said I
don't think the late gasoline or the
chlorofluorocarbons are such a great
example everybody would agree that
environmental Bad's that are recognized
as environmental Bad's it's well within
the government's right to mandate so I
don't think that you'd think about
regulating that as part of a general
effort to slow down technical change the
problem is at the time those were
invented nobody knew they were harmful
so I think the question then would be do
you think that we're so bad at figuring
stuff out that we're better off just
slowing technical change down in general
and I think the answer to that is no and
so I mean I you know you should should
we have figured out quicker the CFCs
were bad yes but you know that's the
first thing I say second thing I'd say
is I've been there a fair amount it is
whatever this group thinks that if we
were the council for regulating
technology we could achieve in
technological regulation I promise you
that any government well I don't think
this group could do so great and any
government constituted with the mission
cannot do a tenth as well so the problem
with all Joe Stiglitz is things is there
all right logically the problem is that
they assume a degree of knowledge a
degree of ability to insulate from
interest and an ability to interact in a
streamlined way that is not realistic
and that one has to bet it the economics
tends to talk about the first best
versus the second best and one of the
first things you learn in government is
that it's about the fifth best versus
the sixth best and the government's
ability to figure it all out right it
seems to me is is quite limited so I
also know something about sort of
Hawking you know we'll get to the
singularity and it'll be evil stuff and
I sort of relate to that as a concern I
kind of think the answer to that at
least in the world we live in for the
United States is it's like saying we
shouldn't do H we shouldn't do research
on fusion of any kind because it'll lead
the really bad weapons and there are a
lot of countries and if we don't do this
research that doesn't mean this research
is not going to get done and having
every having others who are potential
adversaries do it and us not do it
because we've decided it's bad it seems
kind of League of Nations II and so I I
guess I think as a practical policy that
doesn't seem that doesn't seem to me to
be real to be to be realistic and so I
think you have to approach these things
with a kind of bias that doesn't mean
there aren't some areas you know there
to take take a field I know a little a
little bit about there was a quite
systematic and thoughtful effort years
ago around the issue of recombinant DNA
it was a genetic technology and maybe if
you did it wrong it could accidentally
produce killer bugs and there was a set
of thoughtful conversations between the
government and the relevant biology
community around the rules that would
govern experimentation in those areas
and I could imagine that there was some
aspect of AI technology where it would
be sensible to proceed in that way but I
think it's different and and I may have
spoken in an effort to be vivid which I
think I did succeed in I may have spoken
with insufficient care I think the right
a more careful statement would be
generic slowing down is misguided that
there should be a very strong
presumption against resisting what
people think of as inquiry but with
sufficient grounds it will damage the
environment or have some set of external
consequences clearly in those cases you
would want to have you want to have
policy just a few comments on that one
thing that that I'm I think is
legitimate to be afraid of
is the people using the AI and not quite
figuring it all out so just as a simple
example like if you're stuck in traffic
some time apps will suddenly tell you to
turn left but then like everybody turns
left and there's a backup getting back
into your main road and so that's like a
simple example of feedback effects
inside the search engine we made lots of
mistakes we tested something on 5% of
traffic we shipped it to a hundred
percent of traffic like all ads stopped
we lost millions of dollars you know and
and and so over time the people in those
complex systems learned how to manage
them and learn the feedback effects and
you get these sort of rules of thumb of
why you know small experiments don't
extend and when their budget constraints
involved and when you're really changing
the slate of ads that are being shown
then you know you change your training
data and these things happen or so that
we gained over a period of years the
collective wisdom about mistakes but
those were totally not obvious to the
people at the beginning in some cases
people like me warned and weren't
listened to and and so I just think that
you know there's really nothing about
the science of basic machine learning
and simple AI that trains you to think
about those feedback effects the idea
that the a AI is themselves will learn
their objective function completely
doesn't work if you're thinking about
you know some of these more complicated
equilibrium feedback effects so so I
think it is we I think it is probability
one that we will make some sorts of
purely major mistakes when all the cars
are out there driving with each other
and so on I mean I hope that we'll
figure it out but these are really hard
for that's why having people like you
working in this area you're a national
treasure but that is not we don't slow
it down the conclusion of that is not
just slow it down
it's not it is not a compelling
rationale for the government and the
government can't really think I want you
to just think about the fact that
because people understood and they'd
understand for a long time that big
financial institutions were dangerous in
2008 on any given random Tuesday the
government was so committed to keeping
Citigroup and JP Morgan and whatnot safe
that on every random Tuesday there were
500 government employees spending all
day at Citigroup engaged in the process
of keeping Citigroup safe and they did
and so the idea that if the government
recognizes the danger
establishes rules and regulates
extensively the dangers will be
protected against is one that we should
have some caution some of you will say
well that's because co-opted the
government then you can argue about the
extent to which that is or is not true
but maybe big IT companies will co-op
the government too so it's not an answer
to say so - I just think we need
skepticism about what the government is
able to do but the government will
regulate transportation I mean they will
so we hope they'll do it can I just just
with one final Hannah and Manuel I think
wants to come in but let me just just
before a Jason Furman unfortunately
couldn't be here one of his last acts
well not quite because one of his last
acts was released for reports on the
effects of AI four reports were released
and of course no one except for a Jaguar
will read them on that and I'm just
wondering and and Manuel maybe can step
in and actually answer this as how
dim-witted politician in the room would
you which what what did he know that
caused him to feel that he had to
release the four reports on AI and rush
that out why did that you know that in
other words signaling this should have
been a priority and it's a shame it
won't be what did he know because as far
as I can see we've talked about the US
government not spending any government
money on AI exactly a conspiracy that he
knew Donald Trump was no no I think the
US government may well be spending more
on AI than anyone else it's just not
open I'm just wondering in in that
environment is there something that
there was a broader understanding of
this going on no I I could I can speak
in an informed way in an informed way
about this Jason was a responsible
chairman of the Council of Economic
Advisers the job of the Council of
Economic Advisers is to think about
economic issues of the future
a bit ahead of the curve this was such
an issue and so a variety of staff at
the CEA worked hard thinking about it it
was important that their work have
visibility Jason was gonna lose the
ability to give the work visibility and
to release it when the administration
went out of office and so as a final
part of doing the job of the Council of
Economic Advisers responsibly and having
a legacy all that they had learned in
their work she was shared I don't think
there was any deeper sense of either
alarm the precise timing is best
understood in terms of our electoral
rhythms but I think what's important
there is to say that there there will be
things coming there will be put on
transportations there will be policy
decisions like we are going to have to
decide whether to build highways and let
cars go right next to each other and you
know we're gonna have to think about
insurance there's so many policy
decisions we're gonna have to make just
in that one area and so it's important
to have a whole community of informed
people who can guide against bad
regulation and yeah well a few comments
actually are first of all I share
completely Larry said skepticism about
government being able to do good perhaps
you know once you are there you realize
that but but at the same time I went I
want to comment on on that one is that
we haven't talked in this room and we
should about deploying AI for the
benefit of government governing you know
we are talk about health care and this
and that and transportation and whatnot
but the government is an important
sector in the economy you know the
public sector and and there are many
many functions of government that they
are really backwards I mean the other
that they need innovation and they're
clamoring for it and we should pay
attention to that because it can make a
big difference I've been advocating that
in a certain context but you know we
won't get into that now so
let's not oversee that important aspect
I think that's one point the second
point I want to go back to the comment
about the shortage of AI scientists and
programmers and what not and whether the
government truth can do something about
it
well let me very briefly relate you to
what's happening in Israel and Israel is
a huge demand for that kind of people
and there are rigidities in the
university system if I hated the
university system in Israel okay and you
know university cannot pay the
professors in Computer Sciences enough
to keep them from a competition from
industry and so you know there is nobody
to teach I'm excited you know there are
not enough faculty to teach more or does
that stay at the university their
incentives is not to teach or to train
is to you know come here and promote
their own research so this is
institutional rigidities don't square up
with the needs of the economy so there
is room for you know clever policies to
overcome those rigidities and they
another rigidity is that you know the
flow between universities and Industry
that is more necessary than ever now
okay we see a few cases here but you are
the exceptions you know they are the you
know I keep hearing that all the time
okay there is a need for a much more
flexible systems you know the tenure
system of universities with their
incentives that come attached to that
the way that universities are managed
okay and so forth are not really when
adjusted to the realities of opening of
of a reality where the boundaries
between research being done here and
there are completely blurred okay so
there is a lot to do in that there is a
lot to do in terms of bringing AI okay
into into the government with all the
skepticism in terms of more general
policies that I completely completely
me with you in terms of adopting the new
technology and Ed Glaeser and Mike Lucca
have a nice recent survey paper about
that if you're interested I'm a torn on
that one because on one hand I could see
the government using AI to figure out
whose water meters were gonna go out
before they went out and getting out to
fee and optimizing the garbage but I
could equally see the voter suppression
I shouldn't call it for the voter what
did they they call a voter integrity the
voter integrity commission using AI to
figure out who are their political
enemies and and thereby going out and
and trying to get them D listed and D
registered to vote so I people are going
to use whatever technologies we have
sometimes for good sometimes for
partisan sometimes to show off to their
neighbors and I don't think we should
think that the better AI gets we're
gonna abolish those those aspects of the
human personality for sure let me say
three let me say three things one on
government using the technology I am
inclined to agree with you pretty
strongly but the people really like
discretion look Sentencing Guidelines
are a really good idea they make things
fair it's pretty obvious that they make
things fairer and less arbitrary you
could probably make them even fairer if
you had like a computer algorithm that
would take all the facts of the
situation and judge and appropriate an
appropriate sentence but already
discretion of judges with sentencing
guidelines people are upset
I'm sure the rules about which medical
care reimbursements would be approved
and which would not be approved could be
made substantially better with the use
of AI but the already relatively fluid
regulations with human discretion are
known throughout America as death panels
and are rejected so I am in sympathy
with what you're saying pretty totally
but the politics would become which are
already difficult in that direction
would become much worse what the
government functions that our prediction
based an AI would be great for them
there are many functions a lot of being
tax returns that are not really
fundamentally about prediction there
they're about value judgments and it's
not going to help us with on university
rigidities I'm glad to give me a chance
to say that look one of the half-dozen
one of the many positions I took during
my time as president of Harvard that
wasn't so popular with large parts of
the Harvard faculty but where I guess I
think right now I was still think I was
probably right was I used to say that
when a professor had a really good idea
that drew on his research and could be
the basis for a commercial product that
was sold Stanford thought it was a
fantastic thing and Harvard thought it
was a real risk of a conflict of
interest and the fact that Stanford had
its view at Harvard had its view had a
lot to do with why Silicon Valley which
Boston thought would happen around Route
128 in fact happened 3,000 miles away
and that Harvard really it was really
imperative for Harvard to change that so
on a whole set of things about
rigidities of universities I would I
would completely I I would completely
agree with you I would just be nervous
my my point was really just about
spending the money on the training of
people who were going to get high
salaries paid by people who were very
wealthy that stepping up the government
financial commitment to that training
seemed to me to be a problematic policy
all right we've had I know there were
plenty of questions out there that's a
hallmark of a great
we've actually come over actually over
time so I want to thank the panelists
for their thoughts thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>