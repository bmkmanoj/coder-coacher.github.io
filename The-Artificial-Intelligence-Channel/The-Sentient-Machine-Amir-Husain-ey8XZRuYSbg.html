<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Sentient Machine - Amir Husain | Coder Coacher - Coaching Coders</title><meta content="The Sentient Machine - Amir Husain - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Sentient Machine - Amir Husain</b></h2><h5 class="post__date">2018-01-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ey8XZRuYSbg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right hello everybody thank you all
for being here tonight at the Elliott
Bay book company we have a very
interesting night ahead of us
we are joined by Emir Hussain here
tonight to discuss his new book the
sentient machine the coming age of
artificial intelligence which was just
released last week by Scribner using his
vast knowledge from his time as an
inventor and technologist Amir explores
the increasingly relevant matter of
artificial intelligence from many
uncommon angles his book is part
demystification of these very new
technologies which are often feared by
laymen for their seemingly endless
capabilities part reflection on the
existential questions raised by the
pursuit of such technologies and part
exploration into the many applications
of artificial intelligence from the
military to healthcare to finance and so
on as well as those which will develop
as the age of sentient machines draws
nearer and nearer Amir is an inventor
and serial entrepreneur based in Austin
Texas he is the founder and CEO of spark
cognition an award-winning company which
specializes in providing a I powered
software solutions to many of the
problems faced by industry and
government from cybersecurity and beyond
he is also the funding member of IBM's
advisory board for Watson and cognitive
computing Amir has presented at South by
Southwest as well as numerous other
conferences and his work has appeared in
many publications including the New York
Times wired Forbes and Fast Company the
sentient machine is a Mears first book
so thank you all very much again for
being here and thank you also to book TV
for broadcasting tonight's event after
Amir's presentation we'll open up the
floor to some questions feel free to
step up to the microphone to your left
over here if you have a question in mind
books will then be available for
purchase and signing right in the back
of the room so without further ado
please join me in welcoming amir hossein
well thank you very much for that
generous introduction and also for your
kindness and hosting me at this this
lovely bookstore and I was I came in
here early and was really enjoying the
ambience here so it's a wonderful place
to be so what what I think I'd do is I'd
start with a reading a passage from the
book and then perhaps we can start to
explore some of the themes that the book
covers because the book goes through
these sections where we start off by
asking some of the existential questions
the advent of AI what that might mean
for us and then we talk about some of
the fears around the eye and we say well
two of them are that AI might kill us
another one is that if it doesn't kill
us it will take away all our jobs and it
might lead to mass unemployment and
instability and so we talk about these
things and and we try to quantify
whether these outcomes will happen only
with a certain level of artificial
intelligence with AGI or they can happen
even otherwise and is there something to
you know pushing a ban is there value in
pushing a ban those sorts of discussions
and the book really separates that out
into multiple vignettes across what we
call hyper war the application of AI in
the battlefield healthcare the future of
cognitive spaces the future of
architecture where intelligence is
imbued with in these buildings and also
mind hacking which is a a I powered
psyops campaign that's used to transform
and shape thinking and will in a society
for example potentially to hijack an
election and there's a lot that's being
talked about now with this last election
and we'll find out here shortly
hopefully how much of a role some of
these technologies played but
they didn't play an insignificant role
so AI in many ways is here and it's
having broad impact across all of these
different areas
so I'll start perhaps with the reading
we'll get into a few of the chapters of
the book but then beyond the book really
what I want to focus on some other
slides and ideas that build on what's in
the book the book you can read but I
also wanted to take our time today to
bring in a little bit extra to have some
ideas that perhaps enrich or expand or
otherwise elaborate on what's in the
book and then we'll take some time for
questions okay so for those of you who
do have a book I'm going to read just
five minutes worth of text here from a
section that's called decoupling work
and purpose which is on page 169
decoupling work and purpose what
differentiates humans from apes in his
book sapiens a brief history of mankind
historian Yuval Harare argues that one
of the reasons we are singular and
different is that we can tell collective
lies other Apes couldn't do this
believing in these collective fables
allowed us to create forms of mass
cooperation organized religions tribal
affiliations and trade that became
larger than what any other animal or
organism could sustain the combined
power of this mass cooperation through
fictions provided a means of sustaining
and perpetuating our interests and form
of life and it made us dominant over
individual organisms that might have had
more power otherwise so what is the
essence of this humanity as we discussed
in part one our current debates over the
future of artificial intelligence tend
to get stuck with either the loss of our
jobs or a fear for our own mortality
today our sense of identity
so intrinsically tied up in our ability
to produce economic output that we still
call ourselves by the last names of our
mode of productivity Goldsmith farmer
and Miller but these identities are not
fundamentally human they evolved over
time when Homo sapiens first appeared as
a species some 200,000 years ago we
existed as fairly small and independent
bands over time we evolved into larger
and larger groups bonded together
through the narratives of religion and
tribal affiliations until we created an
organized macro organism the human race
when we didn't have any other mechanized
devices to perform labor initially we
enlisted the brute force of our own
people we organized muscle in ways that
we now describe as subhuman the value
did not exist in any one individual or
another pushing the block or laying the
mortar it was contained in the
organizational process that transformed
people into cogs in the machine through
this unique combination of large-scale
muscle power and the fiction of various
belief systems humankind created
pyramids temples city-states and
ultimately entire empires in the modern
era the age of capitalism this systemic
structure is no different in the
framework of capitalism most humans
provide atomized specific and repeatable
tasks these culminate in one global
macro process in which the vast majority
of humans are mere cogs it is to this
very basic labor that we now associate
all of our self-worth today's fiction
the prevailing cultural belief system of
global capitalism exhorts us to take
pride in this work whether this work is
to wake up at 5 a.m. and Dyl the fields
or to enter an office at 9:00 a.m. and
pull up a spreadsheet on
laptop our faith in the fiction has
gotten the better of us
modern society is now contending with
the fraying mythology of capitalism as a
system it continues to progress in an
iterative process so that the numbers at
the top the top 1% becomes smaller and
smaller and smaller until it is the top
0.1% and then the top point zero one
percent in 2016
Oxfam reported that the world 62 richest
billionaires had as much wealth as 3
point 6 billion people or the bottom 50%
of the world's population in 2017 that
number had dropped to the world's eight
richest billionaires fewer than one
dozen people have more wealth than half
the world's poorest population in total
the same report assessed that the annual
income of the poorest 10% of the world's
people had increased by less than a
single cent every year in the last
quarter century so we see different
cultures attempting to adjust their own
storytelling in response to these
fissures in the global system Finland is
currently experimental experimenting
with universal basic income and
Switzerland is in the midst of
considering it like everything else in
culture political ideas artistic
movements food choices
the myth that our worth is intrinsically
tied to our productivity is a fluid one
at one time in our recent past this
fable involved the existence of robber
barons the story then morphed into a
belief in FDR's New Deal the mythology's
of Ayn Rand followed along with that
with the revision of Darwinism in the
economic context and this too will
change as the planet's population make
such notions completely unsustainable
all of these ideas are malleable in
accordance with the times in which we
live and the fable we tell ourselves
most often that our worth comes from our
ability to create objects of economic
value is no different
whether we are farmers marketing
directors truck drivers or commodities
traders in the near or far future the
vast majority of our products of
economic value our work will be
completed by some form of artificial
intelligence for our purposes here the
final part of the journey together I
invite all of us to use our cooperative
skills to create a new fiction together
imagine decoupling a meaningful
existence from these notions of more
conventional employment in the real
world of course this vision involves
countless policymakers politicians
educators and leaders to be successfully
achieved but as a thought experiment
imagine our social system our societal
mythology has embraced this decoupling
this allows us to move beyond the
shorter term feelings of alarm and fear
that arise with the increasing powers of
artificial intelligence the triggers of
the amygdala that spike with panic how
will I feed my family and where will we
live again
I do not wish to denigrate these real
world concerns regarding the rise of AI
in our world but I contend that this is
the least interesting place for our
discussion to end since the origin of
our species human values truths and even
traits have all changed there is no such
thing as a fixed State human being there
is no such thing as a fixed State human
being six million years ago
when our ancestors first roamed the
planet we were not like like what we are
today and only ten thousand years from
now we will not maintain our present
state our humanity is on an evolutionary
trajectory all of the notions that we
cling to as essential to our being human
values truths and even fundamental
traits are in a permanent flux just as
we evolved from something different we
will evolve into something different
something unrecognizable we must accept
the
as a fact of our existence and from this
acceptance then we can identify our
greatest purpose so I wanted to end this
there and just to say a few words about
why I chose this for the different
readings I've been doing I've I've
chosen different parts of the book and
because the book is fairly varied and
the topics that it covers the start of
many of these sessions can have a
distinctly different tone this one is a
little bit more philosophical it ends
with the question of let us take for
granted that machines will indeed
perform the labor as the economic
Labor's that we lay claim to today and
feel so proud of and even associate with
our identity does that capability the
capability to do these labors in a
better way
does that make us less human because was
the high quality execution of a set of
tasks that we collectively call labor
was that really what defined us and of
course to me the answer is no and from
here on the book starts to explore but
what is fundamentally human so for
example we get into things like what
people say look this was very humane
behavior you know and what does that
mean what that means is that there was
an element of charity in this behavior
there was an element of love in this
behavior there were two participants in
a relational exchange where one was
given something from the other without
wanting anything back an act of charity
and we find that if you start to think
about things in a purely philosophical
way the exchange the idea of that
exchange exists even if the people don't
exist and that exchange as a pattern can
be seen in many many other places so
what is fundamentally human is a very
difficult question
and it's something that we will discover
of course but but one thing that I think
makes human beings very unique in that
they are the only sentient form of
creation that we know of thus far is
that they are able to perceive this
unlimited universe of all possible ideas
and in that perception there is value
however our society is structured in a
way that doesn't allow that value to be
recognized in any tangible terms to give
credit to to help in the day-to-day
needs of an individual that is surfing
and uncovering newness from that
ideological landscape infinite landscape
so these are some of the questions that
I don't want to get into any further but
just to give you a short sense these are
also the types of things that we talk
about in this book but I also explained
to you what genetic algorithms are and
what supervised learning and
unsupervised learning are and what the
latest state-of-the-art in many
different industries and autonomous
weapons and healthcare advancements so
it's a it's a pretty varied book ok any
questions on this so far before we move
on to the other material any thoughts
that anybody wants to bring up ok so so
this is sort of the bonus material and
obviously you know my very strong view
is that a new form of intelligence is
coming again I'll tell you why I think
this is a new form of intelligence why
this is fundamentally different from how
we think and I'll explain that to you in
detail but where we are now is close
enough to where the question doesn't
need to be asked hey when can you build
commander data from Star Trek
you know the general purpose
intelligence that can go solve all types
of problems these AI systems with narrow
capabilities in in areas that are
meaningful the most obvious example is
driving a car but really maintaining a
way
house flying a fighter plane looking at
a larger number of radar feeds and more
accurately determining where all the
enemy aircraft are being able to
identify packages that go into the hold
of a plane or into the hold of a large
truck more accurately than 10 people
running you know around and trying to
find those packages there are
innumerable tasks that these systems can
now begin to in to automate in very very
viable and competent ways so those niche
areas already represent livelihood for
human beings so it's not a question of
when we'll get commander data it's a
question of when will we get to 25 30
and 40 percent unemployment right so the
reason I want to raise this question is
because whenever this question is
generally raised in the context of AI
you suddenly a slap down with some sort
of a random platitude which is that oh
don't worry technology always progresses
and of course in the past also it
progressed and at that time you know we
had the Industrial Revolution and so
other jobs came up and there'll be other
jobs in future that you don't even know
about maybe but the way I look at it is
that there are only two meaningful
things that the human race has really
done or attempted to do so far in the
history of the human race
one is the replication of physical
muscle in the late 1600s and early 1700s
with the steam engine where we were able
to create through our mechanistic
prowess a muscle that could move things
that no animal or naturally-occurring
muscle could move we built train
networks of trains and we built you know
cars and we brought steamboats and we
built warships powered by all of this
and now we have come to the cusp of a
period of time where we have a pretty
good chance of being able to replicate
the mental muscle
and if you think about a human being
there's muscle and then there's mind so
with these two things replicated it's
very very difficult to argue then that
there will be jobs that will be of a
sufficient quantity that will neither
require better muscle nor require better
mind so what does that mean what that
means is that the AI debate is almost
absent of policy and this is where I
want to get to so what qualifies me to
talk about all of this right why did I
write this book I wrote this book
because I've been passionate about the
space for a long long time but really
what qualifies me to talk about these
things is that I'm the founder of spark
ignition which is the fastest growing AI
company in Austin and one of the fastest
in the u.s. I serve on the Board of
Advisors of UT computer science which
was just named the number one computer
science department by us world and also
I serve on a think-tank in DC as a
member of their AI committee so I bring
the three elements of I do business
every day I work with the largest
customers in the world from Boeing to
Raytheon to Lockheed to Duke Energy to
NextEra Energy and flow self cooperation
and all of these very very significant
companies on a daily basis
I also am involved with moving the
science of AI forward and I care deeply
about the implications that all of this
work has in the area of policy so I
spend quite a bit of my time going
around meeting with for example the NATO
leadership about three weeks ago I was
in Brussels meeting with the Deputy
Secretary General of NATO explaining
some of these concepts which will need
to be integrated and it looks like there
will be in the NATO strategy going
forward I've spent a lot of time at the
DoD and trying to create sort of this
the impetus really to
think about AI in a very different way
not just as yet another technology and I
think that's working so policy science
and the practical element of the
business all coming together that's what
I've been doing and I feel that that's a
good combination so just very quickly
now many of you may be wondering well
you know we've been saying machines
think so what does that even mean how do
machines think now machines can think in
various different ways and this slide is
not designed to explain to you all the
various ways and which machines can
think but I wanted to show you something
that's pretty simplistic that one can
follow along with in graphical terms so
one way that machines can think is that
given a very simple set of rules they
can apply those rules to create large
graphs and these graphs represent all of
the states that could exist in that
world that the algorithm is modeling so
let's take tic-tac-toe as an example
right and in the world of tic-tac-toe
you can have a machine very easily
generate all of the possible states and
they're not very large so a machine can
do this very quickly and then you can
start you can make a move and at that
point the machine already knows that one
move that you've made where does it fall
in the tree and is there a connection
between there and a state in which the
machine wins and if so the next node
that comes after your move that gets the
machine closer to its win is the logical
step for the machine to take now this
comes again from a very different kind
of thinking the computational excess
that a machine has access to it can
pre-compute
the world and then the rest of it is
just search it just waits for you to say
a thing and then it already knows what
of the twenty nine parts it has options
to to go down it'll pick a path and
it'll go down that path okay this is
simplistic why because the tic-tac-toe
space is not very large right so
it's useful it'll make a great
tic-tac-toe game player but and it
doesn't need to be told much but it's
not very you know broad it can't scale
to very large spaces so let's look at
another one like pac-man and you must
have seen that now generic AI software
using a technique called reinforcement
learning has been able to play most
Atari games not just pac-man but most
Atari games and in most cases the AI
just trashes the human opponent I mean
just with no competition and the way
that this is done is that even though in
pac-man there's a huge number of
additional choices and options you know
where exactly is miss pac-man where all
the enemies did you eat the berry how
many of the gold nuggets are left where
are the enemies coming from and so on
and so forth it's a huge number of
potential cases which are not as easily
model able as a state space as
tic-tac-toe so they're the reinforcement
learning learning technique what that
does is it says okay so I'm going to
start knowing nothing and I'm only going
to look at one factor which is how far I
got and in games I'm going to use score
as a proxy of how far I got and I'm
gonna play this darn thing at machine
speed and I'm going to keep going on and
on and on and on and on and every time I
play and fail I'll remember what my last
score was and I will then take that
score say I got to a hundred I played it
for the first time just random nonsense
moves I got to a hundred so those moves
were up up up left left right left left
and die right so it looks at that and
says okay well I started with your
completely random moves now my I might
make somewhat less random moves because
the value of the very first move I made
was a hundred that very first move got
me to a hundred then the value of the
second move I made was however many
points that first move gave me - that
and what's left that's the value so what
does that tell you as you come closer
and closer to your death the value of
the moves close to your death is by
definition pretty low so at that point
the thing says well heck I don't have
much value in these moves anymore let me
just try to start trying different
things and in this way it in a self
experiential way running very very
rapidly at machine speed it's able to
train itself
it goes through these reinforcement
learning cycles to rapidly train itself
and this is the kind of methodology
that's being used for self-driving cars
this is the kind of methodology that's
being used for as I said these game
players this is the kind of methodology
that was used for alphago that defeated
the world's number one go player so this
is a mechanism that's showing a lot of
progress and it gets around the problem
of having to provide these algorithms
with all the data right so they can
generate a lot of their own data this is
just a tree fully worked-out so we were
talking about the you know the knots and
crosses tree and you can see that
basically the only three things the
algorithm knows is that for every
successive generation you can only add
one symbol at a time I mean the rule of
this game is that in one shot you can't
add two cross L crosses so one symbol at
a time the winning state is when there's
a line diagonal or straight or
horizontal and every time you go from
one row to the other row you have to
alternate symbols right so first you get
a cross then you get an art then you get
a cross then you get a knot that's it
those three rules are the only thing the
algorithm needs to do to learn to be the
world's best knots and cross player
that's it
okay so here I want to pivot to
something I deliberately came here
because I want to pivot to something now
think about it this way three basic
rules and that's it and computation so
three
basic rules multiplied by computation
create this large tree if I was to draw
those three bullets inside the graphical
outline of a seed you would see that
that seed plus some computation gave you
a full developed strategy now that
actually turns out to be a very powerful
concept because it turns out that in the
universe in reality much of what we see
works the same way in fact a tree
physical tree is encoded for the most
part in a seed and there are processes
that then run on the information that's
contained on the seed and resources are
extracted from the outside and those
iterative recursive processes ultimately
create a tree but this happens in
mathematics also this happens in
computer science also so this is
something that's called the game of life
how many of you are familiar with the
game of life okay so in the game of life
there are incredibly simple rules for
example that if you have two or three
neighbors then you live if you're a cell
which is colored in and you have exactly
two or three neighbors then you live if
you have more than three neighbors you
die as of overpopulation okay if you
have less than two neighbors you die as
of overpopulation and if you have I
think what what is it exactly three
neighbors and you're a dead cell then
you can come back to life that's it okay
four rules any child you write them down
any child can color these based on those
rules so but what you see happening here
is a complex ecosystem just based on
what those four rules and some random
patterns it turns out that there are
repeatable creatures that get created
from
many different start conditions given
the same rules there are things called
gliders which glide they look the same
they glide through this surface there
are things called spinners that
alternate between a star and then
they'll go back to being a circle there
this guy over here you see this so there
is a notion of self stability in these
structures but constant motion then you
also see parts of this collide with each
other and when that collision happens
it's very hard to figure out what's
going to happen sometimes you get a
bigger structure sometimes you get many
fractured structures and sometimes from
a mass that didn't look anything like a
glider you can get 18 gliders running
out of that one big mass okay
so what this tells you is that really
really simple rules and really really
simple computation can be the source of
incredible amounts of complexity this is
actually not that complex if you pick up
a book by Stephen Wolfram that's called
a new kind of science
Hiba Labor's to a great degree in the
first many hundred pages and gives
examples of many many many kinds of such
automata where he shows absolutely
beautiful non repeating patterns started
from a seed which is so simple and the
other thing about them is that they're
really not predictable so I mean with
with something like this it would be
incredibly difficult to run this for a
few million generations and then figure
out whether this would be blue by then
this is so many so many interactions
happening now these aren't the only
types of structures that we can extract
that we can take from something very
simple and make into something very
complex what you're seeing here is we're
diving into a fractal this actually is a
Mandelbrot fractal and the French
American mathematician Benoit Mandelbrot
is responsible for the tiny equation
that generates this massive structure
this structure has been
generated in computers to where the
dimensions of the structure are now
larger than the known universe the
complexity in the structure is no less
than what you would see in the picture
of a galaxy so think about that two
things you can take something really
really simple and apply computation and
make it into an emergent system where
things start to come alive and they have
behavior and they start interacting with
each other and then from a tiny little
equation with the power of recursion and
iteration you can get to a point where
you can create a virtual space which by
the way is beautiful you can create a
virtual space that is larger infinite
it's like but even now we've generated
these structures larger than the known
universe you mean us
we all could spend our entire lifetimes
just traversing this entity and we would
never ever ever get done we would see an
infinite decimal part of it it doesn't
exist anywhere in real life but then
what is real life so why do I bring this
up in the context of artificial
intelligence because it's very important
to figure out where a lot of this magic
is coming from any AI because a lot of
times I hear people say well come on now
27 lines of code and it's doing
something intelligent how the heck is
that possible
it's maybe because the 27 lines of code
are doing things in a way in which the
Mandelbrot fractal is taking an equation
this large and expanding it out into a
completely unique beautiful structure
that is infinite larger than the known
universe so size doesn't matter in these
sorts of situations and in particular
you can actually encapsulate a lot of
intelligence in very very little code
because code is something that doesn't
just run once go to something that can
iterate and continuously improve and
that's where recursion and iteration and
all of these things make things so
powerful so where we are now
is that we can easily now generate
landscapes simply computationally on a
on a generational basis so so using
algorithms like Perlin noise for example
Perlin noise is an algorithm so let's do
a quick experiment but if we wanted to
take a grid it's a grid
imagine a graph paper and somebody said
look make a three dimensional surface
that kind of looks like mountains on it
but do it one bar at a time maybe
they've given you straws that sit
exactly on each grid and you can cut the
straws at different lengths so you've
got to make you know this three 3d
topology well how would you do it or one
way would be to just sit in one place
cut the straws at random lengths and
then just randomly put them on the grid
so what do you get you get a structure
but something that you wouldn't really
find in nature which is also a very
interesting thing in nature you
generally don't find hills that go up
down up down up down up down they don't
look like the Bitcoin you know price
curve so there's there's some
normalization in all of this and there's
a very specific kind of normalization so
there's an algorithm called Perlin noise
generation and what this does is it
takes the averages of your of what's
around you and just by doing that it's a
simple heuristic just by doing that it
can create structures that look very
lifelike but we can do as many of them
as we like we can create a billion
planets and have Perlin noise drop
mountain ranges of all types on these
billion planets we can go to explore all
of them so now beyond that I've given
you some examples of how you know
machines do things differently they
a lot and they choose a little bit they
generate a lot of ideas and they choose
a little bit now why is this the case
the mind of a machine is fundamentally
different from the mind of man first of
all we are constrained by the ability to
consume no more than 20 watts our brain
cannot consume more than 20 watts we do
a heck of a lot with those 20 watts but
as our hand engineered silicon based you
know gallium arsenide based systems
become faster and faster the issue will
be the 20 watts is a pretty hard you
know it's it's it's a barrier and so
because the brain has only 20 watts of
power and a small cranium within which
to contain itself what it has become
amazing at is pruning so what we do is
we basically ignore stuff and that is a
special kind of expert laziness which
allows us to be incredibly effective at
the things we need to do in order to
survive but it's interesting that the
world that we've now built is a world
where much of what we have to do is not
because we have to survive but because
we've progressed past those phases of
you know those levels of Maslow's
hierarchy of needs to a point where we
have to solve problems
that yes they don't have anything to do
with our evolutionary survival but they
are intellectually important to us
because they can yield benefit based on
the complex constructs and conceits of
our new social and economic systems but
we weren't evolved to do that we weren't
evolved to think about string theory in
11 dimensions none of us can really see
11 dimensions the only people that can
are really qualified mathematicians that
in the math can see them but because
we've never physically had that
experience we can only describe
and sort of loose ways that you can kind
of communicate but communicating that
verbal description will never do
anything for therefore the other person
because they won't get the mathematical
concept and ultimately it's a
mathematical concept so perfect recall
machines can see everything remember it
forever and the importance of this is
that as they get better as they get more
mature the original memory is preserved
and they can go back and reapply their
advanced intelligence to that perfectly
preserved original memory and come up
with a different conclusion we can't do
that
second it is disembodied machine
intelligence can be at 11 different
places at one point in time machine
intelligence has no desire or no
overwhelming desire to protect a body
doesn't make any sense
we are all about protecting our body
because you know a brain hasn't existed
outside of a body to the best of our
knowledge and so the only way to keep
alive is to keep the body going -
there's no issue there in fact you can
exist in multiple places then there's
this issue of no physical size
limitation there's no physical size
limitation you know if a guy could be 50
times as smart by having a brain that
was 3 times as big society wouldn't
really be very accepting of that it
would look I would look weird you know
but with with systems there's no there's
no such limitation and I make a joke
about the guy looking weird biologically
also there's lots of challenges in such
a person ever being born obviously and
then future processing right so brains
can compute and at the level of that
there at which is a huge amount of power
computers are getting there
computers are getting there they're
expensive they're big they produce a lot
of heat it's not the same amount of
return if you will on a per wattage
basis but computers are getting there so
there's fundamentally different types of
ways of thinking and now just a couple
more on what this is doing
so you know Marc Andreessen said a while
ago software is eating the world but my
corollary that is AI is eating software
how the software eat the world this is
what an engine used to look like before
Tesla it used to have Pistons and valves
and a block and carburetors and timing
belts and and spark plugs and EF eyes
and many many other things physical
number of parts that's what a motor
looks like now
everything else is software efi was
about ingest controlling the level of
fuel that actually went in to the engine
to give it power increase RPM and so on
and so forth that's all just a
solid-state regulator in an in in a
board so all of this has moved to
software the physical parts have been
eaten up by software this is happening
all over the world so what does that
mean what that means is that if you
think about where the jobs are going and
I apologize that part of the slide
probably is not very readable but that's
basically from a study of several AI
experts that suggests when a specific
job will be doable by artificial narrow
intelligence so for example in five
years AI will be able to assemble any
Lego and now when we say any Lego really
assemble anything that's a Lego like AI
will be able to do your laundry that's
one of my personal favorites I'm looking
forward to that in the next five years
in the next ten years drive commercial
trucks Tesla has already got their
prototype out I would at this stage
hazard a guess that that's probably not
too far out maybe ten maybe twelve the
largest number of people employed in the
US by the way are in that profession
their drivers the largest number of
women are in the profession of
assistance of various types assistive
technology is another area where AI is
making very very rapid gains so when I
look at this chart and then people tell
me some people in policy some people in
politics it's nothing
worried about this happened when you
know the Industrial Age came about and
when when people established large
automated factories you know sure we had
people move from the farms and they got
jobs there at the factories when mind is
replicated and muscle is replicated what
the hell is left for us and so to
leverage that do not say ok we'll stop
the robots and go you know not I'm not
arguing for a Luddite movement I'm
arguing for the exact opposite which is
to say if that's happening good for all
of us let's go and figure out what the
right set of policies is that can allow
us to live in that world
properly excuse me
so again you know there have been many
revolts in the past they say that the
history of China is punctuated by
stability followed by peasant revolts
and this is not just about China
there's about many parts of the world
when you make it very difficult for
people to make a living you're asking
for instability I cited a number where
the current mechanism of this techno
capitalism and Finance capitalism has
gotten it to the point where eight
people in the United States control the
wealth equivalent to 50% of the bottom
and at the same time we're automating
not the jobs of those eight but the jobs
of the bottom 50 there is no social
structure put into place now there is no
renewed social contract that can take
care of these people and that is
something that can cause a catastrophe
when that catastrophe god forbid if it
comes that catastrophe will not be a
catastrophe caused by AI that will be a
catastrophe caused by our leadership and
that's something that many of us need to
start talking about now because they're
they're reflexive respond
in a lot of these things is what how
about we banned this how about we limit
this how just like in the Bush era we
had curbs on stem cell research the next
year China established the world's
largest genome sequencing facility and
this year I believe three CRISPR cast
nine cases in live humans are being
tried in China we're not anywhere close
we are not the leader in genetics
anymore so with that let me just leave
you with one question and a visual right
so what the hell do we do you know if if
we're gonna build a better mind and if
we're gonna build a better body if not
now in 10 years 15 years 20 years it'll
happen at some stage so what do we do so
you know there's this idea that I have
of this infinite landscape of ideas
think about this as the plane upon which
all ideas that are discoverable all
concepts all ideas rest and think about
our journeys in life not as journeys in
this three-dimensional space in these
linear spaces coming into contact with
people and opening a door and going
through it and crossing the street
but think about it as a timeline along
which we acquire a view of more and more
of this idea scape we grow and if you
think about it that way then you see man
and a robot and you see that the man's
purple circle is tiny and the robot the
supercomputer the artificial
intelligence is growing at a much faster
rate but you know what you keep zooming
out and you discover that this landscape
is infinite look there's another
computer way in the
distance doing its calculation somewhere
else in ideas space so what I realized
was that and the way that I put my angst
well at least it subsided for me was
that when the race is infinite speed is
irrelevant it's only perspective that is
relevant it's only where I am in the
idea space and what I take away from it
is what's relevant the supercomputer
this AI discovering ideas a million
times faster than me on an infinite
landscape what percentage of the
infinite landscape does a million times
whatever I've done represent 0% and what
does my exploration represent 0% so in
that sense there's a tremendous amount
of value in any sentient perceiver in
any sentient perceiver now how we
incorporate some of these ideas which
are philosophical ideas into society I
have some thoughts on that but I think
this session has gone long
so let me pause this here and maybe move
it to questions and see if there's some
elements that you'd like to discuss
how does the computer eventually get you
said there's no limits well in physical
terms there are limits because I mean
look to the extent that the universe
isn't infinite which we don't know maybe
you know there's a substance called
computronium which is a theoretical
substance where you can convert matter
to the most optimal configuration
allowing it to carry out the largest
number of compute operations per density
and that that hypothetical perfect
computer is called computronium so you
could convert the entire universe into
computronium and you would have a very
very large computer what do you mean by
how large is it that's my question you
said you would have a very large
computer so how large in terms of what
like RAM and hard disk size and well
that would be a very tough calculation
it would be you know the level of I mean
it would be powers that would
essentially be unfathomable I mean if
you think about the brain in just the
one human brain which is not even an
optimal computer we have on the order of
10 to the 14 connections and something
like 10 to the 10 or 10 to the 12
neurons those are huge numbers and
that's in a imperfect brain so now if
you imagine that even at that efficiency
if we converted the somewhat unknown
mass of the entire universe into brains
not even computronium what would that
look like
I mean it would just be it would it
would be the kind of thing that for all
practical purposes while it would still
be a number and technically you couldn't
call it infinite it would be just the
most massive number that would be
inconceivable but I but I'm more curious
as to why you're asking the question is
there something beyond this or you you
just wanting to know like the absolute
limit of computation well it seems like
it will eat up the universe that we're
in
it will its own mind will determine what
goes on in this universe right well so
so if we want to transform everything
into computronium it would use matter
from the universe to do that
there are many scenarios that people
have thought of where you know this
malevolent AGI escapes and it starts to
confound people and it goes around them
and then it starts to consume matter and
make more and more compute systems of
course this is completely hypothetical
it's exactly as hypothetical as that ai
becoming you know the Wizard of Oz or
that ai becoming you know little pony
there's absolutely no precedence to
something like this and the assumption
is that there is a case in which a I can
go bad yeah there are cases in which AI
can go
good too and we are not at that point
where we've achieved AGI technology so
the point is do you stop work on this
technology and if so how do you enforce
stopping work on this technology with
that scared of that you know outcome
because I can tell you bands don't work
the United States was the first country
that you created a nuclear weapons
capability they didn't want Russia to
have it Russia got it they didn't want
China to have it China got it they
didn't want most recently North Korea to
get it North Korea got it and on and on
and on and by the way all along the way
most of these countries were saying oh
no we don't have a nuclear weapons
program but we will sign whatever you
need we don't have a nuclear weapons
program because that's how you build a
nuclear weapons program when nobody else
wants you to build a nuclear weapons
program so that is a situation from game
theory that's called the prisoner's
dilemma which is that if I act honestly
and we both suffer equally in that
environment I can't trust that you will
act on
as long as by you acting dishonestly and
me acting honestly you go scot-free
and I pay twice the price that's what
these countries find themselves in all
the time there's no verifiability so
unfortunately these things will continue
and my own focus and my own interest is
in working in areas that are referred to
as safety I explainable AI which is that
by the time we get to a place where AGI
is a possibility or really sophisticated
Ani systems for example that could be
autonomous on the battlefield I have
written extensively about that once
those systems are a possibility at least
there is a level of accountability
ethics and control that that can be
mathematically guaranteed in these
systems
yes and or question that I'm not expert
AI but I just see it's one where I read
questions a little bit loaded because
and confirm this but the power of AI is
that it has it can't be defined by
physical space that because directly
it's everywhere
so I mean that's sort of the power yeah
it's not you know tubes like you know
that the old cray-cray computer I mean
it partly AI it's almost like operates
like our whole neural network so it's
you can't I can't contain it can't
contain that power that's what I'm
saying yeah so so you do need obviously
some sort of a computational substrate
to run the algorithms of Nai
those computational substrates may
change over time I mean tomorrow you
might invent a quantum computer and that
quantum computer might become you know
hundreds of thousands times more
powerful than today's one Neyman
architectures but you still require some
computational substrate to execute your
your code on but I take your point your
point is that there is so much power
even in systems that are relatively
small that really the question is what
is the specific issue that you're
worried about because the one question
is well how big can it be problem with
that is we don't know how big the
universes I mean every day you read a
different story about dark matter dark
energy how much here how much there I
don't even know how heavy the universe
is I don't even know what to start with
like saying or how much for Bitcoin be
to next month we don't know the answer
is it's a heck of a lot and for all
practical purposes we wouldn't know what
to do with that level of computation
other than simulate this universe is
right again which is why a lot of people
think that this universe is a simulation
I don't personally think that this
universe is an actual simulation I think
that this universe is real but many of
the things that happen in this universe
are consequences of computation
it's a precautionary principle just such
two words ain't good enough on that a
little bit I mean you're you're in a
position you're you're dealing with a
lot of people who are in positions of
power to apply this technology in ways
that will affect us all you're involved
with a lot of researchers who are
furthering this technology which even
you admit could potentially be extremely
dangerous or extremely beneficial as a
scientist I would think you would have a
judgment your own personal judgment on
the precautionary principle whether it's
a valid principle to apply and and and
within this context well I think I'll
tell you my view is first of all a lot
more has been done than we know the
second thing is that the implications of
what these capabilities will give to the
practitioner of those capabilities those
are such significant advantages that
human nature and Marlies my study of
human nature suggests that there is
absolutely no principle or anything else
that's going to prevent a full-on
program desire focus to obtain these
capabilities there are two things that I
think as scientists we can do one is to
think about for example how the guys
that designed the block chain thought
about trust Trust was something
ephemeral and yet they showed that in a
distributed system trust can be very
much made into a mathematical formula so
now you don't trust somebody but in a
certain way more trust exists between
two parties that wouldn't
to trust people the other in a human
sense then has ever existed even amongst
two parties that claim to be ready to
die for each other okay so there are
ways in which we can take some of these
concepts and implement them
mathematically one area of work that we
are engaged in and I think this is very
promising is around using mathematics to
define agent societies so in many
environments where for example in war
when you have a large number of drones
going out they will literally be in a
swarm right so one of the issues is well
a drone can get hacked you know even if
you built the right drone a drone can
get hacked and a drone can be turned on
you it yeah a drone can make a mistake a
drone can you know go off kilter and
might have the wrong navigation software
and six or eight of them can start
destroying the rest of the swarm or they
can start crashing onto civilian you
know locations so what we've designed is
a blockchain based self policing
mechanism where the swarm has been
converted into a flying no man in the no
man in the center
totally federated democracy and there
are two different aspects to each agent
one is that it can make observations
about other agents and it can report
them back all those reports are stored
in a blockchain so in other words that
more than half the agents would have to
be corrupt in order for this for the
view that's being developed to go bad so
you have a pretty good guarantee and the
second thing is that when the system
decides that the majority view is that a
drone is either acting badly took an
action that nobody else knew that it was
authorized to take or started firing in
a location where it was not authorized
to fire or
is going slower or faster or exhibiting
any sort of non-compliance they can on
an out-of-band channel disable that
drone so we actually we have a very nice
that algorithm we've implemented the
algorithm it at just to show it to
people this is hard to show it to people
with fly flying drones but we do that on
a screen with a real program and what
happens is that you have these you have
these objects and then you can click on
any one of them said ok I've hacked this
guy and instead of him moving in this
direction and carrying whatever he's
carrying in that direction he's gonna
now start ruining everybody else's life
he's gonna take he's gonna travel in the
opposite direction and he's going to
just make a huge mess he's gonna take
everything that other people are sorting
and he's gonna make a huge mess
so you'll see very quickly other
citizens other agents observe that
they're like what the hell is this guy
doing and they report all of that and
everybody then agrees there's no judge
there's no jury
there is only federated blockchain style
agreement on global perception and as
soon as that happens there is a
containment mode and the the actual
containment mode depending on where you
implement this algorithm can be
different containment mode comes into
play and they go and they just they they
prevent that bad entity from doing
anything else once containment is
guaranteed everybody else goes on their
merry way and starts to act again with
no human intervention the analysis of
what's going on in an environment
high-security guarantees on that
enforcement mechanism not being hackable
because again it uses mathematics it
uses blockchain and a totally variable
sense of how you're going to control
things like that obviously I've done
this whole thing in justice because I've
tried to verbally describe to you an
entire algorithm a simulation and much
more but you know to me those are the
kinds of things that do give us hope in
where we need to invest
that is where I think I can contribute I
mean you know I'm not I'm not a fan of
bands I don't think they I don't think
they get anything done do you feel that
though this technology should be
weaponized and the reason why I asked
that is because right now the DoD's
stance on that technology that supports
our current troops is that decisions of
life and death would be made by its
handlers so at the current and current
state let's know they will not be
weaponized but do you think they should
or will they that's I I hope not because
I think the child China I just said John
you said right me if I'm wrong but I
don't think the technology is there that
we can allow that to have it hoped it's
not what the technology is gonna get a
lot better but I'll give you three
examples you stances no it's it's
they're not weaponized like the drones
you're talking about they're just mostly
purely for surveillance every label can
be done by its human handlers every
naval US ship has one or two systems
that are called phalanx close-in weapon
systems
CIWS they are Gatling style cannons
they're completely independent they fire
on the order of two thousand rounds a
minute up to more than two miles out and
they have their own radar that's slaved
to an alt azimuth motorized mount with
the gun and it all sits together okay
totally autonomous so there's an off
mode and an on mode and when you turn it
on an on mode in autonomous mode it is
designed to take out sea-skimming cruise
missiles why do you think they made it
autonomous because people can't do the
job that is a system that in a limited
context it has a two-mile range it's
designed to take off or take down
low-flying aircraft and sea-skimming
missiles but
is an autonomous system it's deployed on
every Navy ship there is a mode with the
aegis class where the sm6
the Raytheon sm6 can operate in a
autonomous mode for BMD defense probably
developing an autonomous nuclear
submarine as we speak if it's alright
not public information but I'll tell you
that the Chinese and the Russians have
put out videos and reports on two
autonomous systems that they've just
filled it so so I think it's pretty this
disparity I think that the benefit of AI
will be more efficient war your CAI
developing like powers up persuasion or
like we have enough ideas and solutions
you know they solve all our problems but
we can't this isn't like there's anyone
you know like there's like God giving
you how the 10 commandments yeah oh yes
do it it's a rather than seen AI just
you know salt you know come up with new
ways to do anything but do actually be
able to persuade you see anytime when
people listen to oh yeah absolutely
there's a there's an entire chapter in
this book called mind hacking and that
whole chapter is about using AI to
automate and persuade so the challenge
about persuasion of course is you can
persuade people either way right because
I mean you that really that intent is
being supplied by you the human user and
you can choose to cause a swing one way
or the other
now there are three elections where we
know that stuff like this had happened
the brexit stay leave the US election
and the Indian election and in all three
of them there were data science tests
done that data is also shared in the
book so the science of persuasion and
using artificial intelligence to craft
messages to persuade people absolutely
that's a possibility if you want to use
it for good
great other be
want to use it for bad currently there's
nothing defending against that and my
concern is the technology that's this
advanced can be used for so many
different things not investing in
technology that can keep us safe is
ludicrous to assume that the construct
of a ban you know
ban ki-moon or Kofi Annan showing up and
telling a hundred ambassadors to hey
guys stop building those autonomous
weapons that's not going to stop
building autonomous weapons so the the
work really is about building more
technology I hope that the purpose is
that people put this technology used to
our good purposes but I also don't want
somebody to try to put this technology
to a bad bad use and for us to find out
that we never thought about that case we
never had the defensive capabilities to
really even deal with that so in that
mind hacking chapter I also talked about
AI shields I talked about the problems
that AI driven mind hacking and this
merger of modern psychology and
psychoanalysis with natural language
generation and AI and what causes
they're driving and how we can develop
AI shields that could protect us from
these kinds of threats in the future
how significant dealing US leadership is
in setting the rules of the road for AI
you see I just wrote an article with
General Allen in foreign policy just a
month ago and in the article we laid out
exactly what the issues are but here's
the net-net the US government spent in
2014 1.1 billion dollars on AI in 2015
it spent 1.2 billion dollars on AI
China has announced a hundred and fifty
billion dollars on AI just government
will spend over five years China has
announced a national 2030 AI plan where
the official goal is to dominate the AI
space and to be the number one provider
of AI technologies China is putting in
immense amounts of money
China's putting in is taking full
measures to bring the best talent from
all over the world
for example the Stanford professor
Andrew Inc went worked at a Chinese
company developed a vision capabilities
then came back but many others are
starting to do this students of Chinese
origin the rates at which they used to
stay in the US because the US policies
have been made so difficult that the
smart students that used to stay are now
no longer interested China is also a
developed country it's not like they're
getting peasant wages in China they're
getting damn good wages in China and if
they're not being treated well here and
they're smart people why the hell would
they stay I mean at some level the kinds
of market economics that we talked about
and we're so proud of our understanding
of market economics at the level of our
leadership it's the same market
economics if you want somebody that's
bright and is a rare commodity and you
treat them like crap and they're getting
more money not being treated like crap
somewhere else what do you think is
going to happen and they've made h-1b
visas harder because the h2 spousal work
deal that Obama did has been cancelled
so it becomes more expensive for smart
students who aren't very rich to even
live in the United States so it went
from you know we should take every AI
machine learning master's PhD student
and just stamp a green card to his to
his graduation
you know documentation it went from that
rhetoric to bands and your wife can't
work and you know let me do three you
know sort of very intrusive you know
looks at you and everything that you
brought in and let me go and figure out
where you came from and why you as it's
not interesting anymore
what we have to do is we have to become
that shining city on the hill again a
place that people want to come to and
all of the current discourse politically
has gone down the path of making this
not the signing shining city on the hill
not the place where people are looking
to for their solutions that's the big
tragedy the biggest advantage that
America has is its ideology that
optimism that post World War two
optimism the volumes of boy mechanic and
the projects that were printed in
Popular Mechanics and kids doing stuff
in garages that no other kid in no other
country was doing and we could do it and
a president that went off and said we do
these things not because they are easy
but because they are hard
thank you okay other questions I'm
curious if you have any pretty develop
thoughts about the the idea of a
basically a cultural war coming into
play Hugo de garis ooh he writes and
presents himself as sort of a goofy sort
of away but I find his ideas very
compelling I'm not sure if you're
familiar with his book The Art of War
but he basically he predicts that time
in the very near future where a few of
us are thinking about it now but I think
maybe 1020 years from now it might be
what we're all thinking about is there
will be a certain number of people who
really like the idea of AI and there
will be certain others certain number of
people who have an allegiance to
biological life and they will come into
a conflict which will make the war
between Christians and Muslims look very
moderate I wonder if you anticipate that
if you think that's just a paranoid pipe
dream you know I was very young I read a
dr. Seuss book I think it went something
like you know the star bellied snitches
had stars on their bellies right you
remember that one there you go so it's
that sort of a thing the point is it's
not about technology or it's not about
the color of your you know your
complexion or where you came from the
reality of the human condition is that
you put 18 of us all of us together here
in a room you leave us here long enough
pretty soon we'll start to figure out
where we're all from and what our
traditions were and what our religions
were whether we have a religion and
we'll start to group up and then you
take one of those groups at the United
group and you take them to the next room
and after three days they'll be at each
other's throats and on and on and on
until we're looking for the star buried
sneetches and the ones that don't have
stars on their bellies so this can be
yet another form of how people choose to
differentiate themselves but I think we
already know that whether it's this or
whether it's something else we'll always
find ways this is the human and that the
problem is that you know it's a bug in
the human brain that you can't decode
and rewrite and just fix you know it's
not like an Apple update well once you
discover it you know next Thursday you
could fix it this is not gonna get fixed
it the only way it will get fixed is if
you kind of manage around it and one of
the ways that at least in my observation
is that people descend to being
animalistic when you pressure them so
these wars and so on and so forth at the
end of the day they involve some level
of putting such pressure on people that
they no longer can hold on to this
imagined sophistication that they aspire
to and they feel that they've arrived at
I recently read a book which I read and
then couldn't do anything for two weeks
it was incredibly depressing so don't
read the book but the book was called
man's search for meaning by Viktor
Frankl who was a survivor of Auschwitz
and going into Auschwitz he was a
psychologist of 30-some so he was a
mature person and he describes which I
will not describe what he went through
for years
and then he says that in analyzing my
own self with what little sanity I had
left and what little remembrance I had
of my faculty and of my experience as a
psychologist I am Telling You that I was
no longer a man that it took me a long
time to become a man again okay so when
we pressure people to where they're no
longer men
if we take that 57 year old truck driver
who's done an honest day's job every day
of his life has never had an accident
and we tell him listen we've decided
we're going to replace you with a Tesla
semi and you know what here's two weeks
but you can go and you know you can join
the University of Washington UT Austin
and why don't you go learn bio
engineering I mean I hear that's the
next cool thing it's 57 years old
there's a thing called bio plasticity
okay he might be an outliar and he might
do something there but it's unfair
that's not what society is supposed to
tell somebody that served society well
for 57 years we can't even get that just
simplistic idea in our head when it
makes sense for society to head in a
direction that at a macro level is
beneficial for society which automation
and AI etcetera are okay then those who
are disaffected and paying the price for
that shift which they could not have
force on society owes it to them to take
care of them it is part of the cost of
the shift we keep making shifts and we
keep making orphans and we keep
pressuring people and we expect that
there will be no blowback there will be
no problems well there will be problems
when eight people own as much as the
bottom fifty
it will be the blowback it's not going
to be you know we're not gonna sit
together and have tea and crumpets I can
tell you I mean it's it's going to be I
think ugly I think you saw some of that
you know in the recent days with the
race riots but those groups were small
but if you think about you know huge
numbers of those disaffected middle
class people that don't consider
themselves to have done any wrong and
society suddenly changed their agreement
with them where are they going to go
these are mature societies look at these
issues in advance and plan for these
issues in advance which by the way
America used to be a mature society and
the GI Bill was a great example of this
kind of maturity
so there's you know sitting here it's
clear that AI is gonna there's not you
know an inch of humanity this is one
effect when you talk about the the
policy implications and you know what's
gonna happen to truck drivers and
marketers and assistants and even
doctors what what countries what states
are doing policy well and the Senate you
know they also some reason always end up
doing policy pretty well they're already
experimenting with a variety of
different schemes where you know they
have sort of this minimum payment that
they're doing they they've taken up so
much of the cost of living a high
quality life and kind of made that
integrated that with the state which of
course here people say well that's
communism that socialism and maybe it
has elements of communism and socialism
but to me what is important is not the
label of socialism or capitalism of
communism
to me it's the combination of the best
set of things that work for where we are
now and if some elements have to be
borrowed after all we are not really
purely in a robber baron type
free-market I mean there are curbs even
here so it's not like purely
free-for-all whoever has the more money
can just go do whatever the hell he
wants
so balances make sense in every society
and I think they've found different
kinds of balances I've been very
impressed with how the Germans have used
automation to create very high-end
brands so they've kept a small number of
people employed but they've kept a huge
export you know going over the last many
years
I don't know how viable that is because
Europe is having trouble and also maybe
one country can do that but if all
countries start doing that by definition
what's being exported wouldn't be
high-end so so the other part of this
the way is that the large highly
populous countries that are developing
countries that thought that they were
going to get a huge demographic dividend
the assumption was all these people
these young people millions and millions
of them will get educated they'll get
educated they'll enter the workforce and
there'll be work for them to do and
we'll reap that demographic dividend I
don't think that that's going to happen
because by the time that demographic
dividend peak comes about I think so
much automation would have happened even
if not in their country in countries
from that buy from them that the use of
that labor may not be as important
unless they are somehow magically able
to redirect it all to local needs
so maybe the follow-on book is AI and
global instability because one of the
things that we've talked about often is
as this technology starts to play out
the world will change politics will
change countries that could have been
stable won't be countries that couldn't
have been stable will be countries that
are rich that are very small can use
autonomous weapons in large you know in
in large quantity of man a country that
size could never have implemented so
these are like the fundamental things
that change how the world works
there's no parallels in history for this
so let's see let's see
thank you very much oh you had a
question sure I think that is the last
one yeah okay since no one else has one
um Yellen must had one on the record
yeah you pry heard that the greatest
threat to mankind is not pollution or
North Korea but it's AI do you want do
you agree with them no the greatest
threat to man is was and always be man
thank you guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>