<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>US Congress Artificial Intelligence Hearing - Hearing III | Coder Coacher - Coaching Coders</title><meta content="US Congress Artificial Intelligence Hearing - Hearing III - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>US Congress Artificial Intelligence Hearing - Hearing III</b></h2><h5 class="post__date">2018-04-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oTny--vbkx0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the Subcommittee on information
technology will come to order
and without objection the chair is
authorized to clear a recess any time
good afternoon
I welcome y'all to our final hearing in
our series on artificial intelligence
I've learned quite a bit from our
previous two hearings and I expect to
hate today's hearings going to be
equally informative this afternoon we're
going to discuss the appropriate roles
for the public and private sectors as AI
artificial intelligence matures AI
presents a wealth of opportunities to
impact our world in a positive way for
those who are vision impaired there is
AI that describes the fiscal run around
them to help them navigate making them
more independent ai helps oncologists
target cancer treatment more quickly
ai has a potential to improve government
systems so that people spend less time
trying to fix problems like social
security cards or in line at customs as
with anything that brings tremendous
potential for rewards there are great
challenges ahead as well hey I can
create video clips of people saying
things they did not say and would never
support AI tools and cyberattacks can
increase the magnitude and reach of
those but these attacks to disastrous
levels in addition both our allies and
potential adversaries are pursuing AI
dominance it is not a foregone
conclusion that the US will lead in this
technology we need to take active steps
to ensure America continues to be the
world leader in AI on the home front
biased privacy ethics and the future of
work are all challenges that are a part
of AI so given the great possibilities
and equal great potential hardships what
do we do
what is the role of government and
stewarding this great challenge to
benefit all what should the private
sector be doing to enhance the
opportunities to minimize the risk while
I do not expect anyone to have all these
answers today
I think our panel witnesses will have
suggestions for the way forward when it
comes to AI well this is the final
hearing in our a I series this work does
not in today and our subcommittee to be
releasing a summary of what we have
learned from the series in the coming
weeks outlining steps we believe should
be taken
in order to help drive AI forward in a
way that benefits consumers the
government industry and most importantly
our citizens
I think the witnesses for being here
today and look forward to learning from
y'all and we can all benefit from the
revolutionary opportunities ai offers
and as always I'm honored to be
exploring these issues in a bipartisan
fashion with my friend the ranking
member the woman the myth the legend
Robin Kelly from the great state of
Illinois thank you so much
Thank You chairman herd and welcome to
all of our witnesses here today this is
the third hearing as you've heard our
subcommittee has held on the important
topic of artificial intelligence or AI
our two prior hearings have shown how
critical the collection of data is to
the development and expansion of AI
however a eyes and luck reliance on the
use of personal information raises
legitimate concerns about personal
privacy smart devices of all kinds of
collecting your data many of us have to
look no further than the Smart Watch on
our wrist to see this evidence in motion
the arms race to produce individual
predictive results is only increasing
with smart assistants like Alexa and
Siri in your pocket and listening at
home for your next command sophisticated
algorithm algorithms help these machines
we find their suggestions and place the
most relevant information in front of
our customers these systems however rely
upon vast amounts of data to produce
precise results privacy concerns for
tens of millions of Facebook users were
triggered when the public learned that
Cambridge analytic improperly obtained
to potentially use their personal data
to promote the candidacy of Donald Trump
well the Congress passes new laws the
industry adopts new practices clearly
consumers need and deserve new
protections to help us understand what
some of these protections may look like
dr. Ben Buchanan from Harvard
University's Belfer Center for Science
and International Affairs is here with
us today dr. Buchanan has written
extensively on the different types of
safeguards that may be deployed on AI
systems to protect the personal data of
consumers advancement and AI also posed
new challenges to cyber security
due to increase risk of data breaches by
sophisticated hackers since 2013 we have
witnessed a steady increase in the
number of devastating cyber attacks
against both the private and the public
sectors this past September Equifax
announced that hackers were able to
exploit a vulnerability on their systems
and as a result gain access to the
personal data of over 140 million
Americans a recent report co-opted by
open AI represented by Mr Clarke today
expressly warns about the increased
cyber risk the country faces due to ai's
advancements according to the report
continuing AI advancements are likely to
result in cyber attacks that are quote
more effective more time more finely
targeted more difficult to attribute and
more likely to exploit vulnerabilities
and AI systems as AI advances another
critical concern and its potential
impact unemployment last year the
McKenzie Global Institute released the
findings from a study on the potential
impact they are driven automation on
jobs according to the report and I quote
up to one third of the workforce in the
United States and Germany may need to
find work and new occupations of the
studies indicate that the impact on US
workers may even be higher in 2013
Oxford University reported on a study
that found that due to AI automation I
quote about 47 percent of total US
employment is at risk to ensure the ai's
economic benefits are more broadly
shared by US workers Congress should
begin to examine and develop policies
and legislation that would assist
workers whose jobs may be adversely
affected by AI driven automation as AI
advances continue to develop I'll be
focused on how the private sector
Congress and regulators can work to
ensure that consumers personal privacy
is adequately protected and that more is
being done to account for the
technology's impact on cybersecurity in
our economy I want to thank our
witnesses again for testifying today and
I look forward to hearing your thoughts
on how we can achieve this goal and
again Thank You mr. chairman
appreciate you ranking member and now
it's a pleasure to introduce our
witnesses our first guest is known to
everyone who
who knows anything about technology mr.
Gary Shapiro president of the consumer
and Technology Association thanks for
being here mr. Jack Clark is here as
well and director and open AI we have
miss Tara Lyons the executive director
at partnerships on AI and last but not
least dr. ben buchanan a postdoctoral
fellow at Harvard Kenny School's Belfer
Center for Science and International
Affairs say that three times fast I
appreciate all y'all's written
statements it really was helpful in
understanding this issue and pursuant to
committee rules all witnesses will be
sworn in before you testify so please
stand and raise your right hand do you
solemnly swear or affirm that you're
about to tell the truth the whole truth
and nothing but the truth so help you
God thank you please be seated and
please let the record reflect that all
witnesses answered in the affirmative
and now in order to allow for time for
discussion please limit your testimony
to five minutes your entire written
statement will be made part of the
record as a reminder the clock in front
of you shows your remaining time the
light turns yellow when you have 30
seconds left and when it's flashing red
that means your time is up
also please remember to push the talk
button to turn your microphone on and
off and now it's a pleasure to recommend
to recognize a mrs. Shapiro for your
opening remarks
I'm Gary Shapiro president CEO of the
consumer Technology Association and I
want to thank you chairman herd and
ranking member Kelly for inviting me to
testify on this very important issue
artificial intelligence our association
represents 2,200 American companies in
the consumer technology industry we also
own and produced the coolest greatest
funnest most important and largest
business and innovation event in the
world the CES held each January in Las
Vegas our members develop products and
services to create jobs they grow the
economy and they improve lives and many
of the most exciting products coming to
market today are AI products CTA and our
member companies want to work with you
to figure out how we can ensure that the
u.s. retains this position as a global
leader in AI while also proactively
dressing the pressing challenges that
you've already raised today
last month we released a report on the
current and future prospects of AI and
we found that AI will change the future
of everything from health care and
transportation to entertainment security
but it will also raise questions about
jobs bias and cybersecurity we hope our
research along with the efforts of our
member driven artificial intelligence
working group will lay the groundwork
for policies that will foster AI
development and address the challenges
AI might create first consider how AI is
creating efficiency in improving lives
the u.s. will spend three point five
trillion dollars on health care this
year the federal government shelters
over 28 percent of that cost by twenty
forty seven the CBO estimates federal
spending for people aged 65 and older
who received Social Security Medicare
and Medicaid benefits could account for
almost half of all federal spending AI
can be part of the solution each patient
generates millions of data points every
day but most doctors offices and
hospitals are not now maximizing the
value of that data a I can quickly sift
through and identify aspects of that
data that can saves lives
for example Qualcomm's Alert watch AI
system which provides real-time analysis
of patients out of during surgery
significantly lowers patient's heart
attacks and kidney failures and it
reduces average hospital stays by a full
day cyber security is another area where
ia I can make a big impact according to
our study AAA technologies can interpret
vast quantities of data to repair better
for and protect against cyber security
threats in fact our report found that
detecting and de curating deterring
security inclusions intrusions was a top
area where companies today using AI and
AI should contribute over 15 trillion
dollars to the global economy by 2030
according to PwC both the present and
prior administrations have recognized
the importance of prioritizing AI but AI
is also capturing the tension of other
countries last year China laid out a
plan to create a hundred fifty billion
dollar world leading AI industry by 2030
earlier this year trying to announce a
two billion dollar AI research park in
Beijing
France just unveiled a high-profile plan
to foster AI develop in France and
across the European Union I was there
last week and it was a talk of France
today the u.s. is the leader in AI both
in terms of research and
commercialization but as you said mr.
chairman our position is not guaranteed
we need to stay several steps ahead
leadership from the private sector
supported by a qualified talent pool and
light-touch regulation is a winning
formula for innovation in America we
need government to think strategically
about creating a regulatory environment
that encourages innovation in AI to
thrive while also addressing the
disruptions we've been talking about
above all as we note in our every port
government policies right now I need to
be both flexible and adaptive industry
and government also need to collaborate
to address the impact AI is having and
will have on our workforce for us the
truth is most jobs will be improved by
AI but many new jobs will be created and
of course some will be lost we need to
ensure that our workforce is prepared
for these jobs of the future and that
means helping people whose jobs are
displaced gaining the skills that they
need to succeed in new ones CTAs AI
working group is helping to address
these workforce challenges we just hired
our first vice-president of US jobs and
on Monday we launched CTAs 21st century
workforce council to bring together
leaders in our industry to address a
significant skills gap in our workforce
we face today in addition to closing the
skills gap we need to use the skills of
every American to succeed CTA is
committed to strengthening the diversity
of the tech workforce full
representation our workforce will go a
long way to making sure that tech
products and services consider the needs
and viewpoints of diverse users we as an
industry also need to adjust data
security we also need to do welcomed the
opportunity to continue to work with you
on that in other areas we believe that
the trade agenda the IP agenda and
immigration all tie into our success as
well in nai there's no one policy
decision or government action that will
guarantee our leadership in AI but we're
confident we can work together on
policies will put us in the best
possible position to lead the world in
AI and deliver the innovative
technologies that will change our lives
to the better Thank You mr. Shapiro mr.
Clark you're now recognized for five
minutes
chairman herd ranking member Kelly and
of members of the subcommittee thank you
for having this hearing I'm Jack Clark
for strategy and communications director
for open AI we're an organization
dedicated to ensuring that powerful
artificial intelligence systems benefit
all of humanity were based in San
Francisco California and we conduct
fundamental technical research of the
frontiers of AI as well as participating
in the global policy discussion I also
help maintain the AI index and AI
measurement and forecasting initiative
which is links to Stanford University
I'm here to talk about how government
can support AI in America and I'll focus
on some key areas my key areas are
ethics workforce issues and measurement
I believe these are all areas where
investment and action by government will
help to increase this country's chances
of benefiting from this transformative
technology first ethics we must develop
a broad set of ethical norms governing
the use of this technology as I believe
existing regulatory tools are and will
be insufficient but technology is simply
developing far too quickly as I and my
colleagues recently wrote in to report
malicious use of artificial intelligence
forecasting prevention and mitigation
this unprecedented ly rapid
proliferation of powerful technological
capabilities brings with it unique frets
or worsens existing ones and because of
the nature of the technology traditional
arms control regimes or other policy
tools are insufficient so we need to
think creatively here so how could we
control this technology without stifling
innovation I think we need to work on
norms and what I mean by norms are
developing a global sense of what is
right and wrong to do with this
technology so it's not just about
working here in America it's about
taking a leadership position or norm
creation so that we can also influence
how AI has developed worldwide and
that's something that I think the United
States is almost uniquely placed to do
well this could include new norms around
publication as well as norms around
safety research or
having researchers evaluate technologies
for their downsides as well as upsides
and having that be a part of the public
discussion and confident this will work
we've already seen similar work being
undertaken by the AI community to deal
with our own issues of diversity and
bias here norms have become a product of
everyone and by having an inclusive
conversation that's involved a wide set
of stakeholders we've been able to come
to solutions but don't require specific
regulations but can create norms for
condition the wave of the innovation
occurs so a question I have for you is
you know what do you want to know about
what are you concerned about and what
conversations can we have to make sure
that we are responsive to those concerns
as a community ii workforce the u.s. is
currently the leader in AI technology
but as my colleague gary said that's not
exactly guaranteed there's a lot of work
but we need to do to ensure that that
leadership remains in place and that
ranges from investment in basic research
to also supporting the community of
global individuals but develop AI I mean
part of the reason we're sitting here
today is because of innovations that
occurred maybe 10 to 15 years ago as a
consequence of people I could count on
these two hands so even losing a single
individual is is a deep and real problem
and we should do our best to avoid a
third measurement now measurement may
not sound hugely flashy or exciting but
I think it actually has a lot of value
in is an area where government can have
an almost unique enabling role in
helping innovation you know the reason
why we're here is we want to understand
AI and its impact on society and while
hearings like this are very very useful
we need something larger we need a kind
of measurement moonshot so that we can
understand where the technology is
developing you know where it's going in
the future where new threats and
opportunities are going to come from so
we can have not only informed
policymakers but also a more informed
citizenry and I think that having
citizens feel that the government knows
what's going on with AI and is taking a
leadership role in measuring ai's
progress and articulating that back to
them can make it feel like a collective
across America effort to develop this
technology responsibly and benefit from
it
some specific examples already abound
for ways best works you know
DARPA wanted to measure how good
self-driving cars were and held a number
of competitions which enabled for
self-driving car industry two years ago
it held similar competitions for cyber
defense and offense which have given us
a better sense of what this technology
means there and even more recently di UX
released vertex V used satellite data
set and competition which is driving
innovation in AI research in that
critical area to national security and
doing it in a way that's inclusive of as
many smart people as possible so thank
you very much I look forward to your
questions Thank You mr. Clark well
you're in the right place measurement
may not be flashy but we talked about IT
procurement as well which isn't sexy
either so you're right here you're in
the here in the with good company miss
Lyons you're now recognized for five
minutes
good afternoon chairman herd ranking
member Kelly thank you for the
opportunity to discuss a very important
set of issues I am the executive
director of the partnership on
artificial intelligence to benefit
people in society a 501 C 3 nonprofit
organization established to study and
formulate best practices on AI
technologies to advance the public's
understanding on AI and to serve as an
open platform for discussion and
engagement about AI and its influences
on people in society the partnership is
an unprecedented multi-stakeholder
organization founded by some of the
largest technology companies in
conjunction with a diverse set of cross
sector organizations spanning civil
society and the not-for-profit community
and academia since its establishment the
partnership has grown to more than 50
partner organizations spanning three
continents we believe that the
formulation of the partnership could not
have come at a more crucial time as
governments everywhere grapple with the
implications of technology on citizens
rights and governance and as the
research community increasingly
emphasizes the need for
multidisciplinary work focused on not
just the question of how we build
technologies but in some cases whether
to and also in what ways the partnership
seeks to be a platform for collective
reflection and importantly collective
action my remarks this afternoon will
focus first on some of the potential
opportunities and challenges presented
by artificial intelligence
second on how the partnership hopes to
engage with policy makers with industry
the research community and other
stakeholders artificial intelligence
technologies present a significant
opportunity for the United States and
for the world to address some of
humanity's most pressing and large-scale
challenges to generate economic growth
and prosperity and to raise the quality
of human life everywhere while the
promise of AI applied to some domains is
still distant AI is already being used
to solve important challenges in health
care already mentioned AI systems are
increasingly able to recognize patterns
in the medical field helping human
experts interpret and scan and detect
cancers these methods will only become
more effective as large datasets become
more widely available and beyond
healthcare AI has important applications
in environmental conservation education
economic inclusion accessibility and
mobility among other areas as AI
continues to develop researchers and
practitioners must ensure that AI
enabled systems are safe that they can
work effectively with people and benefit
all parts of society and that their
operation will remain consistent and
aligned with human values and
aspirations world's changing
technologies need to be applied and
ushered in with corresponding social
responsibility including attention paid
to the impacts that it has on people's
lives
for example as technologies are applied
in areas like criminal justice it is
critical for the partnership to raise
and address concerns related to the
inevitable bias and datasets used to
train algorithms it's also critical for
us to engage with those using such
algorithms in the justice system so that
they understand the limits of these
technologies and how they work good
intentions too are not enough to ensure
positive outcomes we need to ensure that
ethics are put into practice when AI
technologies are applied in the real
world and that they reflect the
priorities and needs of the communities
that they serve this won't happen by
accident it requires a commitment from
developers and other stakeholders who
create an influencer technology to
engage with broader society working
together to predict and direct ai's
benefits and to mitigate potential harms
identifying and taking action on
high-priority questions for AI research
development and governance will require
the diverse perspectives and resources
of a range of different stakeholders
both
inside and outside of the partnership on
AI community there are several ways in
which we are delivering this a key
aspect of this work that the partnership
has so far taken the form of a series of
working groups which we have established
to approach three of our six thematic
pillars with the other three to follow
soon these first working groups are on
safety-critical artificial intelligence
fairness transparency and accountability
and AI and also AI labor in the economy
the partnership will also tackle
questions that we think need to be
addressed urgently in the field and are
ripe for collective action by a group of
interests and expertise as widespread
and diverse as ours our work will take
different forms and could include
research standards development policy
recommendations best practice guidelines
or codes of conduct most of all we hope
to provide policy makers and the general
public with the information they need to
be agile adaptive and aware of
technology developments that they so
that they can hold technologists
accountable for upholding ethical
standards and research and development
and better understand how these
technologies affect them we are
encouraged by these hearings and the
interest in policy makers in the US and
worldwide both toward understanding the
current state of AI and the future
impacts they may have I thank you for
your time and I look forward to
questions appreciate you miss Lyons on
dr. Buchanan you're now recognized for
five minutes for your opening remarks
Thank You chairman herd and ranking
member kelly for holding this important
hearing and for inviting me to testify
as you mentioned I'm a fellow at Harbor
universities Belfer Center for Science
and International Affairs and my
research focus is on how nations deploy
technology in particular cyber security
including offensive cyber capabilities
and artificial intelligence and recently
with my friend and colleague Taylor
Miller of the Icahn School of Medicine
at Mount Sinai we published a report
entitled machine learning for
policymakers and to help open today's
hearing I'd like to make three points
one on privacy one on cyber security and
one on economic impact and I'll try to
tailor this to not be repetitive I think
we're in agreement on a lot of these
areas to simplify a little bit we can
think about modern artificial
intelligence as relying on a
of parts some data some computing power
and some machine learning algorithms and
while we've seen remarkable advances on
the computing and learning algorithm
side I think for policy makers such as
yourselves it's data that's most
important to understand and data is the
fuel of machine learning systems without
this data the system sometimes produce
results that are embarrassingly wrong
and incorrect gathering relevant and
representative data for training
development and testing purposes is a
key part of building modern artificial
intelligence technology on balance the
more data that is fed into a machine
learning system the more effective it
will be it is no exaggeration to say
that there are probably many economic
scientific and technological
breakthroughs that have not yet occurred
because we have not assembled the right
data sources and right data sets however
there is a catch and a substantial one
much of that data that might and I
emphasize might be useful for future
machine learning systems is intensely
personal revealing and appropriately
private - frequently the allure of
gathering more data to feed a machine
learning system distracts from the harms
that collecting that data brings there
is a risk of breaches by hackers of
misuse by those who collect or store the
data and have secondary use in which
data is collected for one purpose and
later re-appropriated for another
frequently attempts anonymization do not
work nearly as well as promised it
suffice us to say that in my view any
company or government agency collecting
large amounts of data is assuming an
enormous responsibility too often these
collectors fall far short of meeting
that responsibility and yet an era of
increased artificial intelligence the
incentive to collect evermore data is
only going to grow and technology cannot
replace policy but some important
technological innovations can offer
mitigation to this problem technologies
such as differential privacy that
approach can ensure that large datasets
retain a great deal of their value but
protecting the privacy of any one
individual member aanda vice provost and
of data in the first place this is an
area in which much remains to be done
second AI is poised to make a
significant impact in cybersecurity
potentially redefining key parts of the
entire industry automation on offense
and on defense is an area of enormous
significance we already heard about the
DARPA Grand cyber challenge which I
agree was a significant seminal event
and we've certainly seen what I would
describe as the beginnings of
significant automations of cyberattacks
in the wild in the long run it's
uncertain whether increased automation
will give a decisive cybersecurity
advantage to hackers or to network
defenders but there's no doubt of its
immediate and growing relevance AI
systems also pose new kinds of
cybersecurity challenges most
significant among these is the field of
adversarial learning in which the
learning systems themselves can be
manipulated oftentimes by what we call
poisoned datasets to produce results
that are inaccurate and sometimes very
dangerous and that's another area which
is very nascent and not nearly as
developed as mainstream cybersecurity
literature again much more remains to be
done
a more general concern is AI safety and
this conjures up notions of Terminator
and AI systems that will take over the
world in practice it is often far more
nuanced and far more subtle than that
though the risk is still quite severe I
think it is fair to say that we have
barely scratched the surface of
important safety and basic security
research that can be done in AI and this
is an area as my fellow witnesses
suggests in which United States should
be a leader third AI will have
significant economic effects my
colleagues here have discussed main them
already the ranking member mentioned two
notable studies I would point you to two
other studies both I believe by MIT
economists which showed that while
theory often predicts the jobs lost will
be quickly replaced in practice at least
in that one instance that did not
immediately occur without I will leave
it there and I look forward to your
questions
thank you thank you dr. Buchanan and now
recognize the ranking member for five
minutes or so for your first round of
questions Thank You mr. chair and thank
you to the witnesses again the recent
news they' Cambridge analytic I had
improperly obtained the personal data of
up to 87 million Facebook users
highlights the challenges to privacy
when companies collect large amounts of
personal information for use in AI
systems dr. Buchanan in your written
testimony you state and I quote that
much of the data that might and I
emphasize might be useful for future
machine learning systems is intensely
personal revealing and appropriately
private is that right you just said that
that's correct compliment and can you
explain for us what types of risk and
threats consumers are exposed to when
their personal information is collected
and used in AI systems sure as you'd
expect congressman it would depend on
the data certainly some financial data
if it were to be part of a breach would
lead to potential identity theft there's
also data revealed in terms of
preferences and interest that many
members of society might want to keep
appropriately private we've heard a lot
about AI in medical systems many people
want to keep their medical data private
so I think it depends on the data but
there's no doubt that in my view if a
company or a government organization
cannot protect the data it should not
collect the data in light of these risks
and your assessment on the majority of
companies that do collect and use
personal data for the AI systems are
they taking adequate steps to protect
the privacy of citizens speaking as a
generalization I think we have a long
way to go
certainly the number of breaches that
we've seen in recent years of including
a very large data sets such as Equifax
suggests to me that's a lot more work
that needs to be done in general for
cybersecurity and data protection and
also in your written testimony you also
outlined different types of safeguards
that could improve the level of
protection of consumers privacy when
their data is collected and stored in AI
systems one of those safeguards is the
use of technical approach you referred
to as differential privacy can you
explain that in layman's terms sure
simplifying a fair amount here
differential privacy is the notion that
before we put data into a big database
from any individual person we add a
little bit of statistical noise to that
data
and that obscures what data comes from
which person and in fact it obscures the
records of any individual person but it
preserves the validity of the data in
the aggregate so you can imagine if we
asked every member of Congress have you
committed a crime most Congress people
and most people don't want to answer
that question but if we said to them
flip a coin before you answer if it's
heads answer truthfully if it's tails
don't answer truthfully flip another
coin and use a second coin flip to
determine your made-up answer we're
adding a little bit of noise and we
collect the answers at the end and using
a little bit of math at the back end we
can subtract that noise and get a very
good aggregate picture without knowing
which members of Congress committed
crimes so the broader principle
certainly holds again with the fair more
math involved that we can get
big-picture views without sacrificing
the privacy or criminal records of
individual members of the dataset I have
not committed a crime by the way but do
you feel like if more businesses adopted
this differential privacy this type of
security measure would be more effective
in mitigating the risk to personal
privacy would something like
differential privacy the the Devils in
the details it has to implement it well
but as a general principle yes I think
it's a very positive technical
development and one that is fairly
recent so we have a lot of work to do
but it's it's shows enormous promise in
my view thank you in addition to this
you also identify in your written
testimony another type of security
control known as on device processing
can you again in layman's terms explain
on device processing should how it
operates to protect senator sensitive
and personal data sure this one's much
more straightforward
I said essentially the notion that if
we're going to have a user interact with
an AI system it is better to bring the
AI system to them rather than bring
their data to some central repository so
if an AI system is going to be on your
telephone your cell phone rather you can
interact with the system and do the
processing on your own device rather
than at a central central server where
the data is aggregated again as a
general principle I think that increases
privacy and in your assessment what
reason what are the reasons why more
company
in general or not deploying these types
of security controls certainly as a
matter of practice they require enormous
technical skill to implement frankly I
think some companies want to have the
data want to aggregate the data and see
the data and that's part of their
business model and that's an incentive
for those companies not to pursue these
approaches what recommendations would
you have for ways in which Congress can
encourage AI companies to adopt more
stringent safeguards for protecting
personal data when consumers I think mr.
Clark has made excellent points about
the importance of measurement and I
think this is an area that I would like
to know more about and measure better of
how our American companies storing
securing and processing the data on
Americans that'd be chairman heard
mentioned measurements a topic of
interest to this committee and I think
that would be one place to start and
just lastly a part of the struggles that
companies has is it because they don't
have the enough of the expertise because
it's not in the workforce
yes congresswoman I think I think that's
right there's a enormous demand that has
not yet been met for folks with the
skills required to build and secure
these systems that's true in AI and
that's true in cybersecurity generally
and with the rest of the witnesses agree
with that also yes the last comment yeah
we need ten a hundred times more people
with these skills thank you then Thank
You mr. chair Thank You ranking member
mr. Shapiro you know I had the fortune
of attending CES the Consumer
Electronics Show this recent January
thanks for putting on such a good show I
learned a lot about artificial
intelligence and how that how important
data is in training the the the actual
training the algorithm and one of the
one of the the questions
that we have come up or we have heard on
the issues we've heard is the importance
of data and and we've learned about bias
and preventing that we learned about
being audited all we know we have to
invest more money in AI we also know we
need to train people better who should
be taking the lead
all right like who who is the person who
should be driving kind of this this
conversation or or maybe maybe let me
narrow that the question who in
government should be driving kind of the
investment dollars in this and I know
you have peer research at universities
you have the National Labs you know who
should be coming up with that with our
investment plan in AI well I think first
of all we have to agree on the goals as
I'd like the idea of measurement as well
and I think the goals are number one we
would like the u.s. to be the leader -
we want to solve some fundamental human
problems involving health care safety
cyber security and others and we could
define goals with those and third we
want to respect people's privacy and I
think there has to be a national
discussion on some of these issues
because let's take the issue of privacy
for example and we've we've we've heard
a lot about that today the realities
culturally were different on privacy
than other parts of the world in China
the concept of privacy is especially in
this area is that the citizens really
don't have any they're getting social
scores their government's monitoring
what they do socially and and certainly
there's doesn't seem to be much legal
restriction on accessing whatever people
do Europe is taking it very different
there they're really focused on private
they the right to be forgotten they have
the right to erase history something
that it seems an anthem to us how could
you change the facts and take them off
the internet and they've really clamped
down and they're going forward in a very
arguably bold and unfortunate way on
this this gdpr which is really you could
argue is for privacy or you could argue
was to shut Europe out and
in a competitive fashion and it's it's
when I look at the u.s. and our focus on
innovation and our success and I compare
it to Europe I see they have maybe a
handful of unicorns you know billion
dollar valuation companies and you the
u.s. has most of them in the world over
150 and why is that there's many answers
it's our first amendment it's our
diversity it's our innovation it's it's
the culture we have of questioning
there's many things go to it but part of
it we're a little more willing to take
some risks in areas like exchange of
information
Europe's going frauds UDP are and
frankly it's it's it's a it's gonna hurt
American companies I was just in France
last week it's gonna hurt European
companies they're terrified of it
they're talking about trying to delay it
but it's also going to kill people
because if you can't transfer for
example medical information from one
hospital to another in the same region
that has life consequences so we talked
about the issue of privacy and who
should lead on it I think we should do
it in a common-sense way and we
shouldn't let HIPAA for example be our
model the model should be what is going
to be what kind of information is once a
situation we've done a lot of research
we have found for example that Americans
are willing to give up personal
information for a greater good that
they've done with health information on
our Apple watches they're willing to do
it for safety they're willing to do it
for the security of their children
they're willing to do it for their own
safety involving for example where your
car is if it hits a car in front of them
so in the privacy I think we have a
pretty good cultural sense I think the
Federal Trade Commission is has the
broad mandate to do a pretty good job in
that area and then I don't want to take
all the time but you could those other
two errors I talked about in terms of
the measurements and artificial
intelligence and what you should do it
goes into how you get the skilled people
what you do how you change your
educational system how you retrain for
jobs there's a lot of things that
government can do in current skidoo and
I applaud you in this committee for
taking the first big step and having
hearings to raise the issues but what I
would expect Congress to do in the
future is rather than come up with
immediate solutions is instead to focus
on what the goals are and how we could
do there and I would look at two
examples that I was both personally
involved with which was government
setting big goals but working with
industry who came up with private things
actually I'll give three quickly one is
incur expenses very aware of this
because he was part of it the transition
to high definition television that was
we set the goal we wanted the best
in the world private industry no
spending of government money we did it
second is the commercialization of the
internet doing business Everett we it
was done in Virginia with bipartisan way
and the goals were there and it worked
and the third is you talking about
privacy for wearable devices healthcare
devices which came up earlier at CTA we
got everyone in the room that made those
devices and we agreed on a regimen
saying this is what we should
voluntarily do this is what we should
follow it should be transparent clear
language opt-out and you can't sell
information or use it for without any
permission from your customers and the
Obama administration seemed pretty happy
with that and even they didn't act
because that was industry
self-regulation got you Thank You mr.
Shapiro I'm going to come back to up for
another round of questions but now I'd
like to recognize my friend from the
Commonwealth of Virginia for his first
round of questions Thank You mr.
chairman and and Gary you were doing
speed dating there and welcome good to
see you again
I want to give you a little bit more
opportunity maybe that those three
things you were just talking about if
you want to elaborate a little bit more
because this idea let you catch your
breath further this idea of the zone of
privacy and some of its cultural bound I
think it's absolutely true but I
couldn't remember going to Silicon
Valley but nine years ago to meeting
with Facebook people and their view
about privacy was we Americans need to
get used to shrinking
boundaries for privacy and that the
younger generations were already there
older generations needed to just learn
to suck it up and accept it and I think
watching what happened to mr. Zuckerberg
here in the last couple of weeks one one
needs to not be so facile not you're not
being but I mean I think you're raising
though those questions
some of us cultural bones some of it the
rules of engagement aren't quite there
yet we debate do we get involved if so
what do we do and and so I think your
thoughts are very helpful given your
experience and your position in
providing some guidance so I want to
give you an opportunity to elaborate
just
well thank you very much crying son I
appreciate it I guess my view is that as
a nation we're not China where we
totally don't devalue privacy and we're
not Europe where we use privacy as a
competitive tool against other countries
frankly and but we also have been also
tamps down innovation in our own country
our competitive strength is innovation
that's what we're really good at it's
the nature of who we are so the question
is how do we foster innovation in the
future in AI and in other areas and also
maintain our correct our citizens view
that they are entitled to certain things
now to sirness and it's educating
everyone has an obligation the
obligation of business is to tell our
customers what it is we're doing with
their data in a clear and transparent
way and frankly we haven't done a great
job at it
even if I had my way I wouldn't want to
have to click on those I agree just to
get to the website I want to I'd like to
click on platinum gold or silver
standards there's some standardization
would probably help and government could
play a role in that but we also want to
make it sure that we could innovate and
if and consumers should understand that
they're giving away something in return
for free services you give a tailor your
information on your body size data
clothes it fit you give your doctor
information about your health and you're
always giving away something and you
know the truth is if you're going to get
a free surface like Facebook or Google
and you want to keep it free they are
using that data to get people to know
you but it's like I shop at Kroger's in
Michigan actually because that's where I
commute to and Kroger's knows a lot
about me they know everything I buy and
they give me coupons all the time and I
value those coupons but they know what I
buy and I am willing to do that the same
thing with other frequent user programs
we're doing that all the time we're
giving up information about ourselves we
get discounts we get deals and we get
better service if we do it with our eyes
open and we're educated about it that's
fine now the role of citizens is done by
the way we know you shop at Kroger's
last Thursday and that fondness you've
got for frozen rolls has frankly
surprised us so in Christ in terms of
the role of government I think it's the
role of governments to start out by
having hearings like this one define the
goals and the measurements culturally
for the future that and the role frankly
the administration in my view is to set
the big goals and to make sure that we
buy in into them on a bipartisan way and
I love the idea of some big goals as Mr
Clarke suggested because we need big
goals in this area you know for example
having
self-driving cars by 2025 or not saying
some dropping the death rate from
automobiles down by half by a certain
date would be a very admirable goal that
everyone in this country Carell around
thank you so much Gary mr. Clark another
time I've got left you said in the
report on open AI that artificial
intelligence continues to grow
cyberattacks that will utilize AI and
will be on and you said quote more
effective finally targeted difficult to
attribute and likely to exploit
vulnerabilities and AI systems I want to
give you an opportunity to expand a
little bit on that
so how worried should we be so you can
think of AI as something but we're going
to add to pretty much every aspect of
technology and it's gonna make it more
powerful and more capable so this means
that our defenses are also going to get
substantially better and as dr. Buchanan
said earlier you you weren't in the room
it's not clear yet whether this favors
for defender or the attacker and this is
why I think that hosting competitions
having government measure these
capabilities as they developed will give
us a kind of early warning system you
know if there's something really bad
what's about to happen as a consequence
of an AI capability I'd like to know
about it and I'd like an organization or
an agency to be telling us about that so
you can you can think about that and
take that and view it as an opportunity
because it's an opportunity for us to
learn in an unprecedented way about the
future before it happens and make the
appropriate regulations before harm
occurs if the chair will allow I don't
know if dr. McKenna to miss Lyons might
want to add to that and my time is up
thank you I think we probably can return
to the subject later but I was just
we've seen some indications already of
increased autonomy in cyberattack
capabilities and there's no doubt in my
mind we will see more of that in the
future a distinguished gentleman from
California is now recognized for his
around the question you know this is
what happens when you announce your
retirement to become distinguished
you know I I know on these hearings that
there's sort of an exhaustive repeat of
a lot of things but let me let me skip
to something I think hasn't happened and
I'll share it with each of you but I'll
start with mr. Clark the weaponization
of artificial intelligence there's been
some discussion about how far it's gone
but it's inevitable the tools of
artificial intelligence
disproportionately favor us companies
now when that happened in satellites
nuclear capability and a myriad data
processing we put stringent export
control procedures on those things which
may have a dual use we've done no such
thing in artificial intelligence would
you say today that that is an area in
which the Commerce Department's export
assistant secretary doesn't have
specific authority but needs it thank
you I think this is a question of
existential importance to basically the
world the issue of AI is that it runs on
consumer hardware it's embodied in
software it's based on math that you can
learn in high school you can't really
regulate a lot of aspects of fundamental
AI development because it comes from
technology which 17-year olds are taught
in every country if the world and every
country is developing this so well the
US economy favors the development of AI
here and we have certain advantages
other countries are working on this so I
think that export controls arms controls
do not really apply here we're in we're
in a new kind of regime because you
can't control a specific thing with this
AI technology instead you need to
develop norms around what what is
acceptable you need to develop shared
norms around what we think of an AI as
safety which is about being able to
offer guarantees about how the systems
work and how they behave and we need to
track those capabilities so I think that
your question is a really important one
I think it touches an area where much
more work needs to be done because we
don't have the right tool today to let
us let us approach for problem and let
me follow up quickly when we look at
artificial intelligence we look at those
using advanced algorithms and I I went
to a different high school apparently
than you did mine wasn't Caltech so
let's assume for a moment that it's
slightly above high school level the the
creators of those and let's assume for a
moment hypothetically they're all in the
first world and the first world defined
as those who want to play nice in the
sandbox us Europe and a number of other
countries do you believe if that's the
case the government has a role though in
ensuring that when you make the tool
that is that powerful the tools that if
you will allow it to be safe to safely
controlled are also part of the
algorithm in other words the person who
can make a powerful tool for artificial
intelligence also can in fact design the
safety mechanism to ensure that it
wouldn't couldn't be used clandestinely
do you think that's a social
responsibility of let's say the
Facebook's and the googles I think we
have a social responsibility to ensure
that our tools are safe and but we're
developing technologies relating to
safety and reliability in lockstep with
capabilities you know that's something
that the organization I work for openly
I does we have a dedicated safety
research team as does google google's
deepmind veda as well so you need to
develop that but i i think to your
question it's how do you if you have
those tools make sure everyone uses it i
think there you're going to deal with
all kind of tuesday you know as as we
discovered today that we've sent our CIA
director to meet with kim jonghwan
because he can't be trusted with the
tools he's created that got to him i
might have a different view on the
export controls but mr. Shapiro since
you've you've given me every possible
look on your very creative face as these
answers came through let me allow you to
answer that but i want to shift to one
other question you mentioned a little
bit HIPAA now the history of HIPAA is
pre pre computer data it is in fact a
time in which basically pieces of paper
were start were locked up at night and
not left out on desks so that one
patient didn't see another patients
records and that you didn't arbitrarily
just
or anyone over the phone the reality
though today is that the tools that your
industry the industry you so well
represent you have tens of thousands of
tools that are available that can gather
information and and often they're
limited by these requirements from
really interacting with the healthcare
community in an efficient way do we need
to set up those tools to allow
healthcare to prosper in a interactive
cloud-based computer generation and I'll
just mention for example the problem of
interoperability between Department of
Defense the Veterans Administration and
private doctors that has been one of the
it has confounded our veterans often
leading to death to overdose for a lack
of that capability do you have the tools
and what do we need to give you to use
those tools well it's probably fair to
say that the promise of Obamacare which
was very positive of allowing easy
transfer of electronic medical records
has not been realized I think even the
American Medical Association which urge
that it be passed as now has now
acknowledged that and it's been a great
frustration of doctors as I think you
know in terms of the tools that we have
today to allow easy transfer there you
know the administration hasn't endorsed
this blue button initiative which allows
medical records especially in emergency
cases to be transferred easily I think
it's we have a long way to go as a
country to make it easy to transfer your
own health information the old ways they
did in the communist countries you walk
around with your own records your paper
records we're actually a simpler
transaction than what we have today
where everyone goes in and has to start
from zero well you know the chairman is
too young to know but I walked around in
the army with that brown folder with all
my medical records and it was very
efficient well what's a folder but but
the opportunity we see in this and now
we're concerned as an organization about
the growing deficit and the impact that
will have existentially on our country
frankly and we see the opportunity there
in providing health care and using
technology in a multitude of ways to
lower cost to me more efficient to cut
down on doctor visits and and to just
allow easy transfer of information in
terms of what the government can do were
actively advocating for know where
things are working with the FDA
moving along we and we found with this
administration and prior administration
a great willingness to adopt a
technologies just a matter of how fast
Thank You mr. chairman we can have
another round okay I'll wait
Thank You ranking member round two given
Facebook CEO Mark Zuckerberg comments
last week to Congress how would you
evaluate a eyes ability to thoughtcrime
online from stopping rogue pharmacies
sex trafficking IP theft identity theft
to cyberattacks and whoever wants to
answer that question I'm listening I
think speaking generally here there's an
enormous promise from AI in a lot of
those areas but as I said in my opening
remarks we should recognize that
technology will not replace policy and I
think it's almost become a cliche in
certain circles to suggest that well we
had this very thorny complex
interdisciplinary problem so let's just
throw machine learning at it and the
problem will go away and I think that's
a little bit too reductive as a matter
of policy making you by yes I would I
would echo dr. Buchanan's remarks
insofar as I think part of the solution
really needs to be in bringing multiple
solutions together so I think policy is
certainly part of the answer I think
technology and further research in
certain areas related to security as you
mentioned in the specific case is the
answer and and I think also you know
that is sort of the project of the
organization that I represented so far
as the interest of bringing different
sectors together to discuss the means by
which we do these things in the right
ways thank you not to be can and what
types of jobs do you see that will be
threatened in the short term by AI
automation and what about in the long
term as well certainly in the near term
I think the jobs that are most at risk
are jobs that involve repetitive tasks
and certainly this has always been the
case with automation but I think as
you can imagine has artificial
intelligence systems become more capable
what they can do what they consider
repetitive certainly would increase and
I think jobs that involve the again
repetition of particular tasks that are
somewhat by rote even if they're jobs
that still involve intellectual
firepower are unbalanced more likely to
to be under threat first and in a long
term what do you see as we move towards
an era of things like self-driving cars
one could imagine that services like
uber and lyft might not see a need for
drivers and taxis might not see a need
for taxi companies rather might not see
a need for drivers there's some
suggestion that if we had such a world
we would need fewer cars in general
certainly members of Congress are
acutely aware of how important the auto
industry is the United States so when
you look at a longer term horizon I
think there's more uncertainty but
there's also a lot more potential for
disruption particularly with knock-on
effects of if the auto industry is
smaller for example what would the
knock-on effects be on suppliers to
companies even beyond just the narrow
car companies themselves and whoever
wants to answer what type of investments
do you feel that we should be making now
for people that are going to probably
lose their job woody how do you see them
transitioning to these type of jobs of
course so I would the prior question
about the jobs the great news is the
really unpleasant unsafe jobs most of
them will go away so for example I was
visiting a robotics company they have
something specialized which which is
very good at picking up and identifying
and moving things around using AI and
robotics the jobs one of the potential
buyers was a major pizza company that
delivers two homes the way they do it is
they make dough and the dough today is
made by people in a very cold sterile
environment there where all this
equipment to be warm and also to be
sterile and they can only work
it's very ineffective no one wants to do
the job at all and this solves that
problem there's also a you know
thousands of other conditions where jobs
are really difficult it could
picking agriculturally where now there's
increasingly there's devices which do
that and they do have to be fairly smart
to identify the good versus the bad and
what to pick and one not a bit in terms
of what investment has to make in terms
of retraining I think we have to look at
the best practices and retraining and
fare out what you could do I mean we do
have millions of unemployed people today
but we have more millions of jobs that
are open and not filled some of it is
Geographic we should be honest about
that maybe we need to offer geo you know
incentives for people to move elsewhere
but some of it is is skills and the
question is what has worked before what
skills that you can train someone for
whether it's a customer service center
or whether it's something basic
programming or helping out in other ways
I think we have to look at individual
situations further out what's out there
that's already worked and try some new
things because a lot of what has worked
in the past will not work in the future
and and the longer term investment is
obviously with our kids we just have to
start training them differently and we
also have to bring back respectability
to work which is technical work as
Germany has done and focus on apprentice
program and things like that and not
just assume that a four-year degree is
for every American because it's not a
good investment of society and there's a
lot of unemployed people who went to
college you don't have marketable skills
so I think what this touches on a pretty
important question which is where the
jobs get created because new jobs will
be created will be uneven and where the
jobs get taken away will also be uneven
so I want to refer to a couple of things
I think I've already mentioned one is
measurement it's very difficult for me
to tell you today what happens if I drop
a new industrial robot into
manufacturing region I don't have a good
economic model to tell you how many jobs
get lost for I have an intuition someday
that's because we haven't done the work
to make those predictions and if you
can't make those predictions then you
can't invest appropriately in retraining
in areas where it's actually going to
make a huge difference so I want to
again stress the importance of that
measurement and forecasting growth so
the government can be effective here
thank you very much mr. Clark you talked
about a competition
you know I can their robotics one akin
to a self-driving car what is the
competition for AI what is the question
that we send out and say hey do this
thing show up on Wednesday August 19th
and bring your best neural network and
machine learning algorithm so I have a
suggestion the suggestion is a multitude
of competitions this being the Oversight
Committee
I'd like a competition on removing waste
in government you know bureaucracy which
is something that I'm sure that everyone
here has a feeling about but I think
that that actually applies to every
committee in every agency you know the
veterans agency can do work on
healthcare they can do a healthcare
moonshot within that system that they
have to provide health care to a large
number of our veterans the EPA can do
important competitions on predicting
things like the environmental declines
in certain areas affected adversely by
by extreme weather every single agency
has data it has intuitions of problems
it's going to encounter and it has
competitions but it can create to spur
innovation so it's not one single
moonshot it's a whole bunch of them and
I think every part of government can
contribute here because the great thing
about government is you have lots of
experience with things but typical
people don't you have lots of
awarenesses of things but our threats or
opportunities but may not be obvious and
if you can galvanize kind of investment
and galvanize competition there it can
be kind of fun and we can do do good
work so along those lines how would you
how would you declare a winner
in in which aspect let's say let's say
we were able to get what we can take one
let's take HHS
let's take Medicare Medicare
overpayments perfect example and let's
say we were able to get that data
protected in a way that the contestants
was able to have access to it howdy and
you got 50 teams to come in and solve
this problem how would you grade them so
nai we have a term called the objective
function what it really means is just
for gold and whatever you optimize the
goal of the thing for is what you'll get
out so doing that goal selection is
important because you don't want to pick
for
goal because venule kind of mindlessly
work towards fat but a suggestion I'd
have for you is the time it takes a
person to flow through that system and
you can evaluate how how the application
of new technologies can reduce the time
it takes for that person to be processed
over system and then you can implement
systems which dramatically reduce that
amount of time I think that's the sort
of thing which people naturally approve
of and just thinking through it on the
spot here I can't think of anything too
bad that would happen if you did that
but I would encourage you to measure and
analyze it before you set the goal miss
Lyons what's the next milestone when it
comes to artificial intelligence from a
technical perspective or from a
technical perspective well I think what
a what a lot of the AI research
community is looking towards is AI
platforms that can be applied to more
generalized tasks than just the very
narrow AI that we see applied in most of
the circumstances that we've described
today so I would say that's that is the
next sort of moonshot milestone for the
technical community is that a decade is
that nine months is it 20 years you know
I I have my own personal perspectives on
this the partnership hasn't really
formulated one yet but I think we have a
lot of organizations involved in ours
which have disagreed viewpoints on this
and I'm sure actually if this committee
was quizzed we might all have different
answers as well but I think we are where
years and years away from that and it's
it's useful to be thinking about it
right now but I do think we're probably
decades and what are the elements that
are preventing us from getting there
I actually don't think I'm the best
person equipped on this panel to to give
you an answer to that I'm pretty far
away from the technical research at them
bring from where I'm sitting right now
but but it is a it is a they are
technical impediments that are stopping
us from achieving that at this moment
good copy
a doctor became how do we detect bias
you know I think one of the things that
we have have heard through these
hearings is bias and and we know how you
create bias all right giving you're not
giving a full data set so you can you
can
the out can the algorithm itself be bias
is it is the only way to introduce bias
is by the data set and then how are we
detecting whether or not the decisions
that are being made by the algorithm
show bias I'm not convinced that we're
looking as much as we should so when you
say how are we detecting I think in many
cases we are not detecting bias systems
but speaking generally of how do you
know the Safa Calleja we have the right
of that problem I think it's it's worth
again as I said before technology cannot
replace policy and we should first
develop an understanding of what we mean
by bias is a system biased whether it's
automated or not if it
disproportionately affects a particular
racial group or gender or socioeconomic
status and I think that most people
would answer yes and you would want to
look at what the outcomes of that system
were and how it treated individuals from
certain groups and there's a number of
different values you can instantiate in
the system that that tried to mitigate
that bias but bias is a concept that we
intuitively all feel but it's often
quite difficult to define and I think a
lot of the work in detecting bias is
first work in defining bias mr. Clark so
I have I have two suggestions I think
both are pretty simple and and doable
one is whenever you deploy AI you deploy
it into a cohort of people let's say I'm
deploying a public service speech
recognition system to do a kind of
better version of a free 1:1 service for
a city well I know I have demographic
data for that city and I know that
people would speak perhaps not with my
accent but a more traditional American
one are going to be well represented you
have an accent it's it's sometimes
called Australian Jaeger
but it's actually English so I think
that when you look at your city you're
going to see people who are represented
in that city but are not the majority so
you test your system against the least
represented people and see how it breaks
that will almost invariably surface
areas where it can be improved and the
second aspect is you need more people in
the room this requires like a concerted
effort on STEM education and on fixing
the diversity in stem
because if you're not in the room you
probably just won't realize but a
certain bias is going to be obvious and
we do need to fix that as well so we've
all oh I just try meant by summarizing
cuz I don't think I heard this clarified
in the way that I might describe it
which is in the different ways in which
bias is represented in systems and I
think that is through data inputs which
we've talked a little bit about it's
also in the algorithms themselves and I
think that gets to some of the points
that mr. Clark has made around who is
building the systems and how
representative those developer
communities are and then I think further
than that it's also in the outcomes
represented by those various inputs and
the ways in which there might be adverse
or outsize impacts on particularly
at-risk communities who are not involved
in technology development so I just
wanted to add that that's that's
incredibly helpful we we've all we've
all been talking about what should the
standards be or what is the what are the
what are the equivalent of the three
rules from I robots right and in in in
one that it seems that's but there's
most agreement and correct me if I'm
wrong on this is making sure the
decisions of the algorithm or auditable
that you have that you understand how
that decision was made by that that
algorithm there's been so many examples
of an AI system producing something in
the people that design the algorithm
have no clue how the algorithm produced
that is that is that the first rule of
artificial intelligence what are some
potential contenders for the rules of
ethical AI and and dr. Buchanan maybe
start with you go down the line if
anybody has opinions it suggests that
the first rule might generate more
discussion than you'd expect on this
panel in general there is oftentimes a
trade-off because of the
technology involved in AI systems
between what we call the explained
ability or interpret e of an algorithms
decision and how effective the algorithm
is or how scalable the algorithm is so
well I certainly think it's a excellent
aspiration to have an explanation in all
cases and while I probably believe that
more than many others I could imagine
cases in which we worry less about how
the explanation or how the algorithm
makes its decision and more about the
decision for example in medicine we
might not care how it determines a
cancer diagnosis as long as it does so
very well in general however I suggest
explanations are vitally important
particularly when it comes to matters of
bias and particularly given the
technology involved they're often hard
to get anybody else have opinion miss
Lyons I think the question that you've
raised is actually fairly central to
ongoing dialogues happening in the field
right now and the easy answer is that
there is no easy answer I think and I
think dr. Buchanan has demonstrated that
with his remarks as well but generally
speaking I I do think that it's it has
been a particular focus especially of
especially in the last several years of
a certain subset of the AI machine
learning technical community to consider
questions associated with issues
regarding fairness accountability
transparency explain ability and those
are issues associated with audit ability
as you described and Anna keen interest
I think in making sure that those
conversations are multidisciplinary in
nature as well and including people from
fields not necessarily traditionally
associated with computer science and AI
machine learning communities but also
inclusive of the ethics community law
and policy community and the sociology
community more generally so so are there
other things yeah I recognize that this
is a loaded question there's not an
agreement on this but what are some of
the other contenders or that people say
hey we should be doing this right even
even if we don't if even if we recognize
there's not an agreement when it comes
to what are the rules of ethical AI well
the partnership for it's part
a set of tenants which are essentially
eight rules that govern the behavior at
a very broad level of the organization's
associated with us and they're posted on
our website we included them in our
written remarks or written testimony as
well but generally speaking at a high
level we have as a community decided on
certain sort of codes of conduct to
which we ascribe as organizations
involved in this endeavor and I think a
central project of this organization
moving forward from this point is in
figuring out how to actually
operationalize those tenants in such a
way that they can be practiced on the
ground by by developers and by other
associated organizations and the I
technical community mr. Clark so I want
to put a slightly different spin on this
and that's about making sure that the
decisions an AI makes are sensible and
what I mean by sensible is you know why
do we send people to school why do we do
professional accreditation words because
we train people in a specific skill and
then they're going to be put into a
situation that they may not have
encountered before but we trust for the
training and education they have in
school means that they'll take the
correct action and this is a very common
thing especially in areas like disaster
response where we train people to be
able to improvise and these people may
not be fully auditable like you're asked
from why did you why did you do that in
that situation and they'll say well it
seemed like the right thing to do but
it's not a super auditable response but
it's because we're confident in the
training they've had and so I think some
of it is about how do we make sure that
the AI systems we're creating are
trained or taught by appropriate people
and that way we can have them act
autonomously in ways that may not be
traditionally interpretable but we'll at
least say well sure of that sensible and
I understand why we why we trained them
in that way mr. Shapiro you have 45
seconds if you'd like to respond you
vary so many issues that I'll pass on
this one
mr. Issa you're now recognized for round
two thank you well you were doing that I
was
well it's not 2001 anymore but it is you
know this this dialogue on on AI this
portion of it I think is particularly
for people who who saw that movie new is
important because how was able to
correspond able to have a dialogue but
it didn't have to answer honestly and it
didn't have to be if you will
proofed in other words nobody put in and
the ability in the algorithm for it to
be queried and to answer so I think for
all of us that are having this dialogue
and for those of you working in it the
question is will we make sure that we
have open algorithms ones that can be
queried and as a result can be diagnosed
and if we don't have them then what you
have to rely on as was being said is
outcome outcomes not acceptable outcome
is why the IRS shut down yesterday and
wasn't taking your tax returns on the
tax day and all they knew was they had
to fix it but they didn't know why it
happened or at least it happened in a
portion of their system so that's
something that I can't do
we can't mandate but there are some
things that that hopefully we can work
on jointly and mr. Shapiro I you know
nearly a hundred years ago the radio
Manufacturers Association formed and one
of the things it began to do was
standard setting earlier today you
talked about we should have a standard
if you will for what am i disclosing
platinum gold silver you had a way of
saying it my question to you is where
are the responsible parties as the radio
manufacturers now CTA a hundred years
ago who begins saying we if we're going
to have the flourishing of Technology
we're going to have to have standards
privacy standards
are complex but how do you make them
simple will you make them simple by
building standards that are predictable
that people can share a decision process
with their friends yes I always go for
silver if it's my medical and gold if
it's my financial you alluded to it how
do we get there knowing it's not going
to be mandated from this side of the
dais at least we certainly couldn't come
up with the examples well I mean that's
not the only choice I mean there's the
executive branch the FTC is is
comfortable in that area and sometimes I
was thinking I know the FTC they're very
comfortable after something goes bad
telling us it went wrong how often do
they actually predictively
able to say what the the quote industry
standard is before something they
certainly haven't done it in data
intrusions well there are they do have a
history of providing guidelines and in
standards and I'm not advocating that
about what I'm saying is on the issue of
privacy and click on it there are so
many different systems out there that I
am not personally convinced that the
industry could come forward together
without some concern that government
would instead I think it's always
preferable for government and industry
to work together and but sometimes the
concern that government will act does
drive industry attack that's just the
reality in this area
it's that cats out of the bag a long
time ago and we're all clicking on stuff
we don't understand that and that may be
one of the issues even in the Facebook
disclosures and things like that which I
could think cause I'm concern is it
we're agreeing on things that we don't
understand I mean I used to read that
stuff I I've stopped a long time ago
it's just you can't read it or
understand it but Gary back to but we
were talking about in the last round
when we look at the health care and at
personal information related to your
health care your drugs your your body
weight whatever it is those are not such
a large and complex hypothetical those
are fairly definable if we want to have
the benefits of group data such as a
Fitbit gives and other data and
yet protect individual privacy isn't
this a standard that we should we should
be able to demand be produced and then
codified hopefully with some part I mean
the FTC is very good if you produce a
standard at saying that's now the
industry standard they're less good at
defining it and then proactively well
thank you for raising that specific case
we have done that as an industry we've
come up with standards they are
voluntary and we haven't heard about any
data breach that I'm aware of in a
personal wearable area because I think
that was a model that came together the
automobile industry is doing something
similar and other industries are doing
it it's not too late I was just talking
about the online sure click agreements
there are there's opportunity in other
areas and I think to move forward and to
move forward look it's an opportunity
the advantage for the companies is
they're kind of safe in the herd if they
follow the herd weight and I'm gonna cut
you off but not but not finish this on
one one door down there and judiciary we
control the question of limiting
liability for certain behavior or not
limiting it where in your opinion and I
can take the rest of you if the Chairman
will allow where is that we need to act
to show that if you live by those best
practices knowing that just like that
thing I played it will not be 100
percent but if you live by those
practices your liability is in some way
limited in other words non-punitive if
you're doing the right thing because
right now Congress has not acted fully
to protect those who would like to enter
this industry well you've asked the
question and answer at the same time
obviously being in business yourself you
understand that the risk and uncertainty
or factors we're seeing that in the
trade problems we face today that
potential terrorists insert me sorry I
did have that told to me just last night
by somebody who knows about the question
of not setting prices for their
customers for Christmas because they yet
don't yet know what the tariff will be
so uncertainty in a business environment
we're seeing increasingly reflect in a
stock market but in terms of potential
liability her companies welcome
certainty and one thing for example
Congress did when credit cards were
introduced they said your liability as
an individual is limited to 50 dollars
and it all of a sudden a lot of people
to get over that uncertainty of going
from cash
two credit cards and it helped grow our
economy enormous lean take a lot of
friction out we're facing some of the
same things now as we go forward in so
many different areas because of AI and
we do have an opportunity for Congress
to address and say if you follow these
practices you have a safe harbor here
and that that's a very difficult thing
to do and especially when it gets to
debates about privacy and leaks and
things like that but everyone's looking
for best practices and the issues we
were discussing earlier having to do
with cyber and how do you protect I mean
this is game will never end you build a
better mousetrap you get smarter mice so
we're going to keep raising that bar and
if that's the challenge that Congress
will face but some safe harbors would be
certainly welcome in this area as it
grows rapidly and I think there's a role
to play and I think this is a great
amazing set of first three hearings to
start on what will be a process with
government and industry and consumers
sorry I hear that from all of you I saw
a lot of heads nodding that safe harbors
should should exist if we're going to
promote the advancement of use of data
and artificial intelligence any knows
well I there's always a caveat but any
knows in John I actually don't
I don't really have any comments about
safe harbor specifically but I think in
general the issue of generating best
practices is one which is is really
important to be considered in this field
and that again was sort of the reason
why the partnership on artificial
intelligence was created because there
is a sort of understanding I think
that's been come to in a collective
sense about the necessity of determining
what these guardrails should be to
certain extent and I think that project
can't really be undertaken without the
policy community community as well as
other stakeholders who just necessarily
need to be involved Thank You chairman I
would also put myself down as embracing
a caveat here congressman I think one of
the dangers is that we agree on a set of
best practices that are not in fact
anywhere near at best practices and we
think our work is done so while I
support safe harbors if they align to
practices that do protect privacy
advance security I would suggest we are
a long way from those practices in place
today so we should not lock in the
status quo and think our work is done
well you know I I've owned Model T's
I've owned
cars from the 50s 60s 70s 80s and so on
I don't think we we lock in best
practices we only lock them in for a
product at the time that the product is
is new and innovative and we have an
expectation for the manufacturer that
that product will become obsolete nobody
nobody assumes that a Model T is is the
safest vehicle or even a 66 Mustang but
we did we do make expectations at the
time of manufacturing you know there was
a time when years ago when a man lost a
limb on a on a lathe and he sued the
company even though the lay that made in
1932 and it was already then you know
the 50 years later and we had to create
a law that that prohibited you from
going back and using today's standards
against the manufacturer you could use
it against the company if they hadn't
updated but you couldn't use it against
the manufacturer that's an example of
safe harbor where if you make to the
standards of the day you are not held
for the standards a change on a product
that is a fire-and-forget you don't own
it or control it and so that's what I
was referring to your expectation that
yes there has to be continuous
innovation and that people have to stay
up with the standards of course we're
not and we're not expecting that but
then the question is will we see it from
your side or would we try to have the
same people who have you know who have
the system that shut down on the last
tax filing day be the ones determining
best practices Thank You mr. chairman
would the gentleman engage in a colloquy
of course what's a Model T well you know
I just want you to know that when the
big bang comes the Model T is one of the
vehicles that will still crank up and
run well I'm coming to your house
congressman I assume I have two final
questions the last question is actually
a simple question but the first question
is is I recognize we can have a whole
hearing on the topic and I lump it
generally in pre-crime you have you have
jails and that are making decisions on
whether someone should be released based
on on decisions based on algorithms we
have people make a decision about
whether they believe someone's going to
potentially commit a crime in the future
and I would lump this in pre-crime and
the question is should that be allowed
Gary
I'll foolishly take a shot at that it
depends on the risk involved for example
in an airplane security situation I
think it makes sense to use biometrics
and predictive technology and gait
analysis and voice analysis and all the
other tools that are increasingly
available to predict some of that
whether someone's a risk on a flight
Israel does it increasingly and it's it
makes sense in a you know system release
system I think we were we have more time
and we're more sensitive to the fact
that there are clearly racial
differences in how we've approached
things for in stay one it may not make
that much sense so I'd say it's
situational mr. Clark we have a robot at
open AI and we trained it to try and
reach towards this water bottle and so
we obviously expected that the robot
would eventually grab the water bottle
and pick it up but what we discovered
from robot had learned to do was to take
the table the water bottles all and just
bring it towards itself fulfilling the
objective but not really in the wave we
wanted it to so I think I'd agree with
Gary that maybe there are some specific
areas where we're comfortable with with
certain levels of classification because
the risk of getting it wrong like a
plane is so high but I think we should
be incredibly cautious because this is a
road where when once you go down it
you're dealing with people's lives and
you can't in the case of pre-crime
really inspect whether it's pulling that
table towards it it may be making
completely bananas decisions and you're
not gonna have an easy way to find out
and you've dealt with someone's life in
the process so I'd urge caution here
also this with a caveat that I provided
previously on another answer
which is that the partnership hasn't yet
had a chance to formulate a position on
this formula but I think that this
question speaks to a lot of the
challenges associated with bias in the
field right now which we discussed a
little bit earlier and and I think also
the challenges of what happens as a
result of the D contextualization of
technology and the application of it in
areas where it may it may or may not be
appropriate to have it be applied so I
think it's really important to consider
the impacted communities especially in a
case of criminal justice applications
and I think that needs to be a required
aspect of conversation about these
issues not to be canon I'd echo miss
Lyons points and mr. Clark's points I
would make three other points here the
first is that not only is there a risk
of bias but there's a risk sometimes
machine learning is is said to be money
laundering for bias in that it takes a
system that is something is dirty in it
and outputs it in this veneer of
impartiality that comes from a computer
and we don't interrogate that system as
much as we should
it's a major risk I think in this area
but in many areas and secondly I think
you pose the question somewhat of a
hypothetical mr. Clark is a measure here
but I would encourage you and mr. Clark
to investigate how much those systems
are already in place I think
ProPublica did an excellent bit of
reporting on bias in sentencing in the
criminal justice system already in place
today and that would certainly deserve
more attention in my view and the third
is that we should make sure that the
inputs to the system are transparent and
in the system itself is transparent and
one of my concerns speaking generally
here is that the systems used for
sentencing now and in the future often
are held in a proprietary fashion so
it's very hard to interrogate them and
understand how they work and of course
hard in general to understand the
outputs of such a system and I think
while that causes me concern in general
it should cause extreme concern in this
case if we're sentencing people on the
basis of proprietary closed systems that
we do not fully understand in public
view thank you dr. Buchanan and my last
question is for the entire panel and
maybe dr. McCann and we start with you
and
work our way down and it's real simple
take 30 seconds to answer it what would
you what would y'all like to see from
this committee in Congress when it comes
to artificial intelligence in the future
mr. chairman I think you've done a great
job by holding this series of hearings
and I was encouraged by your suggestion
that you'll produce a report on this I
think that the more you can do to force
conversations like this out in the open
and elevate them as a matter of policy
discourse is important I would suggest
as an academic I view my job to think
about topics that are important but are
not urgent that are coming but are not
here in the next month or two I would
suggest that many committees in Congress
should take that as a main date as well
and I would encourage you to adopt that
mindset as you approach a AI there are a
lot of very important subjects in this
field that will never reach the urgency
of the next week or the next month but
will very quickly arrive and are still
fundamentally important to virtually all
of our society at the risk of redundancy
I I also want to say thank you for the
engagement chairman I think that having
more of these types of conversations and
more knowledge transfer between those
working on technology and those
governing it in fora like this is deeply
important and and I think again I'd like
to offer myself and the rest of the
organizations and the partnership is a
resource to whatever extent is possible
in that project of Education and further
understanding and and think that it's
deeply important for policy makers as
well to consider the unique impact and
role that they might have in technology
governance especially within the context
of multi-stakeholder setting which is
especially characteristic I think of the
AI field right now well before we get to
you mr. Carter mr. Shapiro y'all aren't
allowed to thank us because I want to
thank you all we have to prevent as
we've learned in the last couple of
weeks and many of our colleagues in both
chambers are unfamiliar with basic
things like social media and
so we have to to elevate the common body
of understanding on some of these topics
and so y'all's participation today
y'all's written statements y'all's oral
arguments help inform many of us on a
topic that you know if when we when I
went around the streets here in the
capital and asked everybody what is AI
most people they're older than me
described how that's why I thought was
laughing when I saw brought that in and
people that were younger than me
referred to Ava right from ex machina
and so and so so so y'all are helping to
educate us so mr. Clark mr. Shapiro what
should this committee in Congress be
doing on AI until the first time I tried
to build a table I was a measure once
cut twice cut type of person and then
after I built that really terrible
broken table I became a measure twice
cut once person the reason why I say
that is but I think that if Congress and
the agencies start to participate in
more discussions like this and we
actually come to specific things that we
need to measure that we want to build
around like competitions it will further
understanding in in sort of both groups
like there's a lot for the AI community
can learn from these discussions and I
think for the the inverse is true as
well so I'd welcome bat and I think
that's probably the best next step we
can take mr. Shapiro last word I'm happy
to embrace my colleagues offers and
views and appreciation I have three
quick suggestions one I think you should
continue this but go to field hearings
at great places where there is
technology like Massachusetts or Las
Vegas in January CES a second I think
government plays a major role because
government's a big buyer in terms of
procurement I think you should focus on
where AI could be used in procurement
and set the goals and the results rather
than focus on the very technical aspects
of it third in terms of I think also
that while Congress may not easily get
legislation it could have a sense of
Congress it could have a sense of
Congress that it's important national
goal that we cut automobile deaths or we
do certain things by a certain date and
setting a national goal with or without
the administration could be
valuable in terms of gathering the
nation and moving us forward in a way
which benefits everyone and really keeps
our national lead in AI that's a great
way to end our series I want to thank
our witnesses for appearing before us
today the record is going to remain open
for two weeks for any member to submit a
written opening statement of questions
for the record and there's no further
business without objection the
subcommittee stands adjourned</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>