<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Prof. Max Tegmark on Life 3.0 -  Being Human in the Age of Artificial Intelligence | Coder Coacher - Coaching Coders</title><meta content="Prof. Max Tegmark on Life 3.0 -  Being Human in the Age of Artificial Intelligence - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Prof. Max Tegmark on Life 3.0 -  Being Human in the Age of Artificial Intelligence</b></h2><h5 class="post__date">2017-08-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NPHpFobqItg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">from the FLI audio files Elon Musk has
called it a compelling guide to the
challenges and choices in our quest for
a great future of life on Earth and
beyond while Stephen Hawking and Ray
Kurzweil have referred to it as an
introduction and guide to the most
important conversation of our time I'm
of course speaking of Max tegmark new
book life 3.0 being human in the age of
artificial intelligence and i'm erielle
Khan with the future of life Institute
I'm happy to have max here with me today
as most of our listeners will know max
is co-founder and president of FLI he's
also a physics professor at MIT where
his research has ranged from cosmology
to the physics of intelligence and he's
currently focused on the interface
between AI physics and neuroscience his
recent technical papers focus on AI and
typically build on physics based
techniques he is the author of over 200
publications and also his earlier book
our mathematical universe my quest for
the ultimate nature of reality max
thanks for talking with me today thanks
for talking with me so obviously I want
to dive right into your book ai has been
in the news a lot lately and other books
have come out about the potential impact
of AI and so I want to know what is it
about your book that stands out from all
these other reading materials and what
makes it an important read for anyone
who wants to understand and prepare for
our future well there's been lots of
talk about AI disrupting the job market
and also enabling new weapons but very
few scientists talk seriously about what
I think is the elephant in the room what
will happen once machines outsmart us at
all tasks what's kind of my hallmark as
a scientist is to take an idea all the
way to its logical conclusion so instead
of shying away from that question about
the elephant in this book I focus on it
and all its fascinating aspects because
I want to prepare the reader to join
what I think is the most important
conversation of our time
there's so many fascinating questions
here the owner will superhuman
artificial intelligence arrived in our
times can should it be controlled and if
so by whom you know and can you manatee
survive in the age of AI and if so how
can we find meaning and purpose if super
intelligent machines provide for all our
needs and make all our contributions
superfluous another way in which my book
is different is that I've written it
from my perspective as a physicist doing
AI research here at MIT which lets me
explain AI in terms of fundamental
principles without getting all caught up
and in the weeds with technical computer
jargon so I hope it's gonna be a lot
more accessible what is it about AI that
you think is so important to our future
we've traditionally thought of
intelligence as something mysterious
that can only exist in biological
organisms especially humans but from my
perspective as a physicist intelligence
is simply a certain kind of information
processing performed by elementary
particles moving around and there's no
law of physics that says that one can't
build machines more intelligent than us
in all ways that makes intelligence an
AI incredibly important because it
suggests that we've only seen the tip of
the intelligence iceberg and that
there's this amazing potential to unlock
the full intelligence that's latent in
nature and to use it to help humanity
either flourish or floundered so I think
if we succeed in building machines that
are smarter than us in all ways it's
gonna be either the best thing ever to
happen to humanity or the worst thing
I'm optimistic that we can create a
great future where they I but it's not
gonna happen automatically it's gonna
require that we really thinks beings to
in advance really have this conversation
now that's why I written this book and
so to go back just a little bit how did
you as a physics professor get involved
in those what drew you to artificial
intelligence ever since I was a teenager
I felt that the two greatest mysteries
of science were the mystery out there
our universe and the mystery in here in
our heads the mind and in recent years
my nerdy technical research at MIT has
shifted increasingly from the cosmos to
the physics of intelligence in my lab we
studied both intelligent organisms look
at brains but also intelligent machines
we do AI research
I find this not just intellectually
really fascinating just for the research
of it but I also think that
understanding in a more fundamental
level what intelligence is and how to
make it and how to shape it is one of
the most important things we need to do
to create a good future with AI because
if you have something really powerful
that you want to use to help you you
have to understand it so you can trust
it what made you start to think that we
need to be addressing the safety issues
that are surrounding AI and sort of
along the same lines what prompted you
and the others at FLI to establish the
AI safety research grant well first of
all taking a step back through the 13.8
billion years of our cosmic history here
you know eventually life came along and
we started developing more and more
powerful technology and I'm optimistic
that we can create a great future with
technology as well but to do that we
have to win this race between the
growing power of the technology in the
growing wisdom with which we manage it
and in the past the technology has
always been feeble enough that we could
win their wisdom base simply by learning
from mistakes we made that fires screwed
up and into the fire extinguisher thud
we invented the car screwed up a bunch
of times and vented the seatbelt in the
airbag there with more powerful tech
like nuclear weapons synthetic biology
and now ultimately I think superhuman
artificial intelligence you don't want
to learn from mistakes
it's a terrible strategy we want to get
things right the first time because that
might be the only time we have so that's
of course very much the whole idea
behind the future of life Institute
that's why we founded our organization
and when we started it when we have the
very first brainstorming meeting right
here in our house the technology that
people generally felt deserved the most
attention unless was yeah because
there's been such incredible progress
that yeah I had a real possibility of
transforming our world much faster and
much more dramatically than for example
climate change it's the biggest
technological transformation can hit us
the soonest there's a huge upside here
if we get this right because everything
I love about civilization is the product
of intelligence so if we can amplify our
intelligence with artificial
intelligence it opens the potential of
all these thorny problems that plagued
us today right but just gonna require
hard worked and that I felt that if I'm
spending so much of my time anyway
working on this with the future life
Institute's I might as well align that
with my MIT research also and they were
artificial intelligence both on my work
time and on my so-called free time there
are still a lot of AI researchers who
are telling us not to worry especially
about the long-term risks so I'm curious
what your response to them is well first
of all I'm very fortunate that MIT gives
us tenured professors a lot of leeway
and choosing what the research so I've
been enjoying for that reason doing AI
research in last few years I have a
wonderful group of students and postdocs
I'm really really proud of so if someone
has any nitpicks about the AI research I
do I'm happy to talk with him about the
geeky stuff but I feel that's enabled me
to learn a great deal about the AI field
it really helps my future license to
work second of course there are people
who say we shouldn't worry and also a
lot of very very senior AI researchers
who say that we should take these things
very seriously what I do in the book is
I don't tell people whether they should
worry or not I don't tell people what
they should think I simply describe the
controversy and the fact of the matter
is there are two very basic questions
where the world's leading AI researchers
totally disagree one of them is timeline
and a when if ever are we gonna get
superhuman general artificial
intelligence some people think it's
never gonna happen or take hundreds of
years so that it's therefore silly to be
concerned now and many others think it's
gonna happen in decades which means we
should take it very seriously
the other controversy which is equally
real is what's gonna happen if we ever
get beyond human level AI
some people think it's going to be
pretty much guaranteed to be fine and
then we should think of advanced AI is
just a natural next step in evolution I
call this group the digital utopians in
my book something machines are just
gonna be our tools they're never really
gonna be that far beyond humans and
shouldn't worry for that reason and then
there are a lot of very serious
researchers both leaders in academia and
industry who think that actually this
be the best thing ever to happen but it
could also lead to huge problems and I
think it's really boring to sit around
and quibble about whether we should
worry or not I'm not interested in that
what I'm interested in is asking what
concretely can we do today that's gonna
increase the chances of things going
well because that's all that actually
matters so that's why I have with my
future life Institute colleagues and my
other AI colleagues put so much energy
into brainstorming making concrete lists
of questions that we need to answer and
then working hard to channel research
funding into research grants so people
can actually tackle those questions so
we get the answers by the time we need
them it's important to remember that
even if we might only need the answers
to certain questions in 30 years it
might take 30 years to get the answers
because the questions are hard right
that's why it's so important that we
support and I safety research already
today and don't just start thinking
about this the night before some guys on
Red Bull switched something on that they
don't understand fully that brings me to
another question that I wanted to ask
you so within the AI safety world I hear
a lot of debate about whether people
should focus on just near-term risks or
just long-term risks there seems to be
this idea that we need to focus on one
or the other but in your book you cover
both and so I was hoping you could touch
on why you think it's important for us
to look at both even if one might pose a
greater risk to humanity than the other
yeah I think we should obviously focus
on both first of all this is the most
important issue of our time as I argue
in the book so it would be silly to be
so stingy with resources that we only
focus on some small fraction of the
questions second what you're calling the
short-term questions like how for
example do you make computers that are
robust and do what they're supposed to
do and not crash and don't get hack
stuff like that it's not only something
that we absolutely need to solve in the
short term because it saves lives
as AI gets more and more into society
but it's also a very very valuable
stepping stone towards the tougher
questions I mean seriously how are you
ever gonna have any hope of building a
super intelligent machine that you're
confident is gonna do what you want
if you can't even build a laptop it does
what you want instead of giving you the
blue screen of
or the spinning wheel of doom it's
ridiculous so clearly if you want to go
far in one direction first you take one
step in that direction and by getting a
lot of researchers galvanized to start
tackling these short-term questions
about making a robust understanding how
you can make it trustworthy and
transparent those are things which are
also going to help as those researchers
keep the momentum keep going in the same
direction with the longer term
challenges and finally you know if
you're gonna take on some moonshot
long-term challenges you're gonna need a
lot of really talented researchers
educated and interested in these things
how do you get those people well you get
them by first having a lot of funding
and so on for the community to develop
by having them work on these more
concrete near-term things can't just
start in a vacuum in 20 years snap your
fingers and expect that there's gonna be
this safety research community there
that's your service so I want to move
into what I think are probably some of
the more fun topics in your book
specifically you mentioned 12 options
for what you think a future world with
superintelligence will look like now
when I was reading these I would read
what the ideal version of each of these
is and think oh that sounds nice and
then you would talk about the pitfalls
of them and it was hard to be quite as
optimistic when you liked it so I was
wondering if you could talk about what a
couple of the future scenarios are that
you think are important for people to
consider and then also what are you
hopeful for and what scares you yeah I
confess I had a lot of fun brainstorming
for these different scenarios the reason
I did this was because I feel that when
we as a society envision the future we
almost inadvertently obsess about gloomy
stuff future visions in Hollywood tend
to be this topics fear sells more but
you know if I have a student that comes
into my office for career planning and I
ask her hey where do you want to be in
20 years and she says oh I think I might
have been run over by a tractor and
maybe I'll have cancer you know it's a
terrible strategy I would like her to
have a spark in her eyes and tell me
this is my
this is where I want to be in 20 years
and then we can talk about the pitfalls
and how to navigate around them and make
a good strategy I wrote this because I
think we humans need to have that same
conversation instead of just talking
about our avoid gloomy stuff and cancer
and unemployment and how to avoid Wars
and what we really need these positive
visions to think what kind of society
would we like to have if we have enough
intelligence at our disposal to
eliminate poverty disease and so on what
are the positive things we're trying to
build I'm not claiming to have the
answers to this nor should I what I want
to do with the book is encourage
everybody next time there are the party
with their friends and so on to talk
about not just the usual stuff but talk
about this even when you watch a
presidential election the kind of things
that politicians promise which is
supposed to be positive or just so
uninteresting crease this thing by 5%
and blah you know if you think about
Kennedy's moon speech towers
inspirational but that's nothing
compared to what you can do if we manage
to do things right with AI where
basically the whole history of human
forecasting has been a giant under
estimation of what we can do right we
thought it was gonna take be impossible
to do things or take thousands of years
if it turns out that AI can help us
solve these challenges in our lifetime
or hundreds of years what do we want to
do with them I tried to write the whole
book in this optimistic spirit to get
more people thinking but since you asked
me about what I worry about okay I'll
make a few concessions there too you
know I'm an optimist that we can create
a great future but it's not the kind of
optimism that I have that the Sun is
gonna rise tomorrow namely optimism that
it's gonna happen automatically no
matter what we do it's what my friend
and colleague Erik Brynjolfsson calls
mindful optimism I'm optimistic that we
can create a great feature if we really
plan and work hard for it so what do we
need to do I mean just give you one
example if we have very powerful AI
systems it's absolutely crucial that
their goals are aligned with our goals
now that involves a lot of questions
which we don't have the answer to like
how do you make a computer learn our
goals you know it's hard enough to make
your
kids learn our goals with let alone
adopt our goals
and how do we make sure that yeah I will
retain those goals if it keeps getting
progressively smarter kids change your
goals a lot as they grow older maybe
they get less excited about Lego and
more exciting the better other stuff
right we don't want create machines that
first are very excited about helping us
and then later it get his board with us
is it's our kids yet where their Lego is
it like Max and and finally what should
the goals be that we want these machines
to safeguard what values there's
obviously no consensus on earth for that
right should it be Donald Trump's goals
Hillary Clinton's goals should it be
Isis's goals whose goals should it be
how should this be decided I think this
conversation can't just be left to tech
nerds like myself have to involve
everybody because it's everybody's
future that's at stake here so a
question that I have is you know we
talked about and I being able to do all
these amazing things from ending poverty
to solving the world's greatest
questions and I'm sort of curious if we
actually create an AI or multiple AI
systems that can do this what do we do
then that's one of those huge questions
that I think everybody should be
discussing it I wrote this book so that
people can educate themselves enough
about the situation to really contribute
to the discussion if you take a short
term view suppose we get machines that
can just do all our jobs produce all our
goods and services for us the first
challenge is how do you want to
distribute this wealth that's produced
if you come up with some sort of system
where everybody gets at least some share
of the wealth maybe because of some
taxation and the government helping them
out then everybody basically gets a free
vacation for the rest of their life it
sounds a lot better than permanent
unemployment sounds on the other hand if
I own all the AI technology and decide
not to share any of the stuff with
anybody else causing mass starvation no
that's less fun so this question about
how we should share the bounty of AI is
huge there's a big cultural divide there
are typically between Western Europe
where there's a bit more tradition of
higher taxes and trying to have a social
safety net versus the u.s. where there's
great resistance towards that a second
question is but just because
you take care of people materially
doesn't mean they're gonna be happy
right there are many example in history
of princes even in the Middle Ages who
had all the money they needed and then
story themselves on opium how do you
create a society where people can
flourish and find meaning and purpose in
their lives even if they are not
necessary as producers even if they
don't need to have jobs those are
questions that cannot be left to techie
geeks like myself again
we need psychologists and so many other
people to contribute to this discussion
I'm optimistic that this too can be
solved because I know a very large group
of people who seem perfectly happy about
not having jobs they make kids but it's
a conversation we need to have ok and
then moving much much farther into the
future
you have a whole chapter that's
dedicated to the cosmic endowment and
what happens in the next billion years
and beyond
and so why do you think we should care
about something so far into the future
yeah I have to confess I really unleash
my inner geek I'd let her run there on
that one since I'm a physicist and I've
spent so much time thinking about the
cosmos I couldn't resist the temptation
to think about that but frankly yeah I
think it's actually really inspirational
to contemplate the enormous potential
for the future of life you know you
might have said well you know a billion
years ago we have some boring
microorganisms here on earth doing their
thing and why don't we just quit while
we're ahead and let's leave life like
that forever
that would have been a bit of a bummer
we would entirely missed out on humanity
that way right it stuck with some
bacteria life could flourish so much
more than it was doing a billion years
ago yet today also we're in the
situation where it's obvious that our
universe is largely dead and there's so
much more potential for life the vast
majority of the space up there as far as
we can tell with our best telescopes is
not alive there's not much happening
there a lot of people think from
watching sci-fi movies that they're
always intelligent aliens everywhere
having a sort of Star Trek existence but
there's precious little hard evidence
for it right now and so I think it's a
beautiful idea if our cosmos can
continue to wake up more and life can
flourish here on earth not just for the
next election cycle but for Bill
of years and throughout the cosmos we
have over a billion planets in this
galaxy alone which are very nice and
habitable and then we have 100 billion
other galaxies out there so I think it's
so pathetic when we quibble about who's
gonna have a piece of sand somewhere in
the Middle East or whatever on earth
when there's just so much more potential
array than I didn't think big for life
to flourish and I think if we think big
together this can be a powerful way for
us to put our differences aside on earth
and unify around the bigger goal of
seizing this great opportunity I also
think we have a special responsibility
as humans because we humans as far as we
know so far are the only life form in
the universe that's gotten sophisticated
enough that we've built telescopes been
able to see all the stuff that's out
there so if you think those galaxies out
there are beautiful they're beautiful
because someone is conscious of them and
observing them right and if if we were
to just blow it by some really poor
planning with our technology and go
extinct and we were to forfeit this
entire future where our cosmos could be
teeming with life for billions of years
wouldn't we really have yeah failed in
our responsibility I think this place
and this time that we're in right now
might be the most significant place and
time in the history of our cosmos I
talked about that possibility towards
the end of the book I have no idea if we
managed to help life flourished in the
future what these future life-forms are
gonna think about us billions of years
from now but they would certainly not
think it was as insignificant because it
might have been what we do here on our
planet right now in this century which
makes a difference so I'm going to go in
a completely different direction you
mentioned you know we can appreciate the
beauty of the galaxies because we're
conscious of them and you have an entire
chapter dedicated to consciousness as
well which frankly leads to lots and
lots of questions even how could we tell
if something is conscious but not
getting into that I just want to know
what do you see as both the risks and
the benefits of creating either
intentionally or not an AI that has
consciousness so first of all I'm a
physicist so as far as I'm concerned
Ariel you're a blob of quarks no offense
you know and I don't think there's any
secret sauce in
brain beyond the quirks and other
elementary particles there that explain
why you're so good at processing
information in ways that I consider
intelligent and why you have this
subjective experience that I call
consciousness I think it's just
something to do with the very elaborate
patterns and with your quirks and other
particles are moving around and so
explore in this book in great detail
what it is that makes a blob of matter
intelligent what is it that makes a blob
of matter able to remember compute learn
and even in some cases an experience
like you experience colors and sounds
and emotions and call consciousness
right I think that there is a lot of
confusion in this area if you worry
about some machine doing something bad
to you it consciousness is complete red
herring it doesn't matter if that
machine or robot or whatever if you're
chased by heat-seeking missile for
example you don't give a hoot the
weather it has a subjective experience
of what it feels like to be that missile
or whether it feels like anything you
wouldn't say to yourself well I'm not
worried about this missile because it's
not conscious all you worry about is
what the missile does know how it feels
right consciousness is on the other hand
the important for other things first of
all if you're an emergency room doctor
and you have an unresponsive patient it
would be really great if someone had a
device that could scan on this patient
and tell you whether they have locked-in
syndrome when there's you know someone
home or not and second in the future if
we create very intelligent machines if
you have a helper robot for example who
you can have conversations with and it
says pretty interesting things wouldn't
you want to know if it feels like
something to be the helper robot if it's
conscious or if it's just a zombie
pretending to have these experiences if
you knew that it didn't have any
feelings or experiences at all you
wouldn't feel at least bit guilty about
that switching it off right mm-hmm
or even telling you to do very boring
chores but if you knew that it felt
conscious much like you do that would
put it in an ethically very different
situation it could make you feel guilty
wouldn't it yes yeah and then so that
raises the question if you have a helper
robot would you want it to be conscious
or not you might say well I wanted to
just be in Zombie mode so that you don't
have to feel guilty on the other hand
maybe it would creep you out a little
bit that it keeps acting this way
and making you feel that is conscious
even though it's just faking it maybe
you would even like to have a button on
it where you could toggle it between
zombie mode and conscious mode depending
on on the circumstances and even more
importantly if in the future we start
creating cyborgs or maybe we have
intelligent beings that we you in some
sense it's our descendants that we're
very proud of what they can do we may
have our values and they go and do all
these great things that we couldn't do
we feel proud of them as our children
that whole positive outlook would get
completely ruined if you also happen to
know that they're actually zombies and
don't experience anything because then
if we humans eventually go extinct and
the cosmos is our legacy is continued by
them but there's nobody experiencing
anything it's as if our whole universe
had died for all intents and purposes as
far as I'm concerned it's not our
universe giving meaning to us it's we
conscious beings giving meaning to our
universe that's what meaning comes from
so if there's nobody experiencing
anything
our whole cosmos just goes back to being
a giant waste of space so I think it's
gonna be very important for these
various reasons to understand what it is
about information processing that gives
rise to what we call consciousness I'm
optimistic as I talked about in the book
that we can figure this out
I even talked about the experiments you
can do to try to pin things down and I
think it should be part of the list of
questions that we should try to answer
before any super intelligence so you
actually then hope that we are able to
create an anodized consciousness when I
first of all hope we can do is get
answers to these big questions I think
we need to answer a lot of these
questions before we make any irrevocable
decisions we can't take back ok so I'm
keeping you very open mind as to what
the best path for it is and what I think
we should really really do is rally
around these tough questions and work
really hard on trying to answer them and
base our decisions on them you know the
decision about whether to create some
form of super intelligence and if so
what form and what tools that you have
that's the most important decision that
humanity will ever make and we shouldn't
just bumble into this decision without
thinking about it this should be the
most premeditated and most
carefully research decision we ever do
alright so I think this sort of segues
into the next question that I have and
that's I was hoping you could talk a
little bit about probability and
especially as it relates to risks and
hopes for the future why and when should
we concern ourselves with outcomes that
have low probabilities for example first
of all I don't think and most of my
colleagues also don't think that the
probability is very low that we will
eventually be able to replicate a human
intelligence in machines the question
isn't so much if although there were
certainly a few detractors out there
bigger question is when even if it's not
gonna happen for a hundred years this is
a good time to start talking about it
we're talking plenty about climate
change effects in 100 years so why
should we talk about something much more
dramatic it might happen in order yet
second I know there are many leading
researchers you think it's gonna happen
in decades when we did the last poll at
the Asilomar meeting about this the
median death people had was you know
some decades from now yeah some people
thought hundreds of years some people
thought sooner but I think personally
it's not at all impossible look it might
happen within decades so this is perfect
time to really start working hard on our
homework if there is somebody who thinks
the probability of succeeding in the
building human level generally I and
Beyond is very small like 1% what I
would say to them is hey do you have
home insurance the probability of a
house catching fire is less than 1% they
still buy it so you can still make that
argument that we should buy fire
insurance for our civilzation just in
case but it is that I don't even think
the probability is particularly small a
lot of people I think they were
dismissive about the I progress because
they think that there's somehow some
sort of secret sauce involving human
intelligence but as a physicist I think
we are our particles that addresses
certain probability of advanced AI in
the future but what about looking at say
the different options that you consider
for the different directions that
humanity can move do you think those
have an equal probability or do you
think some are more likely than others
how should we be trying to address this
if we think one direction is worse than
another I would like to take your on all
the challenges in a principled order so
obviously we're gonna get great job
dislocations so I talk in the book about
what kind of career advice you should
give for your kids right now we're
obviously on the cusp of an arms race
and lethal autonomous weapons so we
should try right now to prevent that
from happening which is what AI
researchers overwhelmingly do want to
avoid they want to use their awesome
technology for good not just create new
unstoppable arms races as we look to the
bigger questions of the human level
intelligence if you give a society a
technology that's too powerful for their
wisdom it's kind of like you're walking
into a daycare center and saying hey
here's a box of hand grenades have fun
playing with this stuff I'm not gonna
give you instructions we've always had
people who for whatever reason had weird
grudges and wanted to kill as many
people as possible for their own weirdo
reasons and there will always be such
people in the future as well right the
difference was in the Stone Age one
lunatic couldn't do that much damage
with a rock and a stick
whereas today is we're seeing for
example with nuclear weapons one lunatic
can do a lot of damage and lethal force
weapons takes that up one notch where
you lower the cost of a technology
needed for mass destruction from
billions of dollars to thousands or
hundreds of dollars and finally if we
start getting closer to human level AI
there's an enormous Pandora's box which
I think we want to open very carefully
and just make sure that if we build
these very powerful systems they should
have enough safeguards built into them
already that some disgruntled
ex-boyfriend isn't gonna use that for
Vendetta
some Isis member isn't gonna use that
for their latest plots you know and this
isn't just sort of pie in the sky
dreaming about very far future things
these are things we can work on with
safety research right now today you know
think about how preventable September 11
was for example we have these airplanes
with auto pilots and computers on board
but nobody had put in enough
intelligence in them that they even had
a rule saying do not under any
circumstances fly into building that was
nothing that the manufacturers ever
wanted a plane to do but the airplane
was completely clueless about human
values it's not that hard do something
like this that would also stop Andrea's
Lubitz from flying this Germanwings jet
plane into the Alps when he was suicidal
by
setting the autopilot to 100 meters you
know it doesn't take more than a few
lines of code to say under no
circumstances should airplanes allow
their auto pilot to try to fly at lower
altitude than the mountains which are
right there and their math database
right so this kind of baby ethics where
you take the sort of human values that
pretty much everybody agrees on and put
that into today's systems is a very good
starting point I think towards
ultimately getting more sophisticated
about having machines learn and adopt
and retain human values I want to end on
an optimistic note because as you said
you're very optimistic and the goal of
the book is to present an optimistic
future so how can the average concerned
citizen get more involved in this
conversation so that we can all have a
more active voice in guiding the future
of humanity and life I think everybody
can contribute and people should figure
out what ways they can contribute best
if you are listening to this and you are
an AI researcher then I wouldn't
remember to encourage you to find out
about what some of these cool technical
problems are that we need the answer to
make array AI systems more trustworthy
and safe and sentient I'm working on it
if you are someone who has some money to
donate I would encourage you to give
some of it to one of the many nonprofit
organizations including future life
Institute you know that's funding a
isafe T Research which right now almost
all the funding is going into just
making AI more powerful and almost none
of it is going into developing the
wisdom to guarantee it'll be beneficial
if you're a politician or you have any
contact with your local politicians
encourage them also to make sure that
funding for AI safety becomes just this
integral part of the standard computer
science funding it's provided in your
country if you are any human at all I
would also just encourage you to join
this conversation and they would in an
informed way I wrote the book precisely
for you then so that you can get the
scoop on what's going on to the point
where you can really contribute to this
conversation as I said one of the really
huge questions is simply we were
building this one more powerful rocket
engine that can steer this rocket Co
humanity into the future but where do we
want to stay our to what kind of future
do we want to aim for
what kind of society do you personally
feel excited about envisioning for 50
years down the road performed beyond
that for future generations talk to your
friends about this it's a great party
topic the great conversation anytime and
then we set up a website age of AI
daughter word where we're encouraging
everybody to come and share their ideas
for how they would like the future to be
also and I hope you Ariel can help me
fill out some of the coolest ideas there
and they're a nice synthesis because I
think we really need the wisdom of
everybody to chart future worth aiming
for and if we don't know what kind of
future we want we're not gonna get it so
on that note is there anything else that
you want to add that you think we didn't
cover I would just add that I find this
topic incredibly fascinating and fun
even aside from being important and
that's one of the reasons I had such a
fun time writing this book all right
well thank you so much for joining us
the book is life 3.0 being human in the
age of artificial intelligence and we
highly encourage everyone to visit Age
of AI org and we will also have that on
the website so max thank you so much
thank you to learn more visit</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>