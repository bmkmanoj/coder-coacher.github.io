<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The AI Pioneers: Geoffrey Hinton, Yann LeCun &amp; Ruslan Salakhutdinov | Coder Coacher - Coaching Coders</title><meta content="The AI Pioneers: Geoffrey Hinton, Yann LeCun &amp; Ruslan Salakhutdinov - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The AI Pioneers: Geoffrey Hinton, Yann LeCun &amp; Ruslan Salakhutdinov</b></h2><h5 class="post__date">2017-10-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9RljVnT2zBY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Thank You class again okay so so I had I
learned a lot today I had a really sunny
day so far and it's gonna continue
dinner and so want to thank a few people
who've funding anymore maybe it's
possible
first the sloan Foundation has funded
the digitisation program and continues
to fund it and that's wonderful so the
NPR supports coming on slow edition so
thank you I'm up Danielle's still here
okay
Thank You Danny and some of the funding
is coming from the crit instruction lab
in rotten school so thank you
some of the funding has come from seat
bar and so and you've heard maybe a
couple of people today set C far
affiliations the Canadian it's to
programs research and so I'd like to all
three of our speakers tonight our CPR
fellows and so to introduce our speakers
I'm gonna have seat bar who is Albert
Cheney so Alan is the president and CEO
of making it super grants research they
provided our funding so thanks again and
prior to joining C far in the active and
successful life better for her so he has
been in our place in the past with an
emphasis on stem cells blood cell
formation cancer research
he's an option in the order Canada and
immediately prior to see far he was the
executive director of the global HIV
vaccine Enterprise in New York so thanks
Alan and these memories
thanks Abby and I actually I want to
thank you and AJ and Joshua for putting
together actually an amazing program I
don't know how you guys did it but
congratulations on behalf of all of us I
think it's it's fabulous so I want to
say just a couple of words about C far
so I think the best way to explain to
this crowd is imagine a university
without walls where the faculty include
people like Jeff and Yan and and the
Oxbow and Russ and an economic field
brillier with these names
including me I don't want to leave
anybody out so I can look at my
scribbles here people like their own
Alvin and I don't even have to say their
last names I don't think their own Ilhan
Torsten Dan traveler who you were to be
here today
Patrick Francois an alumnus Mendel
Trachtenberg Philippe etc and you'll get
a sense of of see far and the room were
in is actually where the program that
the economics group meets institutions
organizations and growth where they meet
and I thought you all said on the other
side of the room but he reassures me
that Joanne will appear who's an advisor
to that program always sits in the same
seat so a little confused today because
it feels like an IO G meeting but it's
actually a great meeting on AI and
economics now I'm an expert in neither
or actually put it definitely I'm an
equally expert in both well but I think
it's been a great great day so far one
other thing I want to say about C far is
a plug a little bit today was great we
are having a series of meetings on AI
and X where X is economics philosophical
implications it's used in medical
diagnostics etc and we are also going to
be having in November it will be on our
website a global call for new programs
of C far and you can talk to any of the
people in our programs to find out more
about what it's like to be in a program
but I hope some of you will look at that
and think seriously about applying
because we are particularly interested
in AI and its implications for society
Rebecca Finlay he's over to my left who
is VP of engagement and public policy is
developing a global effort around AI and
society because I think it's really
important and timely that well there's a
lot of activity going on around AI in
society but there isn't a coherent kind
of global discussion going on and I
think especially for policy makers and
for the public it's really important
that all of us in academia I'm kind of
work together not to arrive at one view
but certainly to arrive a consensus or
distilled view for for governments
around the world so with that I think
we're gonna have a great three speakers
with you Jeff so Jeff who's the man in
standing here Jeff is a CFR
distinguished call one of the handful he
was founding director of our program
called neural computation and adaptive
perception he and I shall say goes back
to our discussion that Larry Summers
raised in our the panel today I think
that it's really important that not just
see far but organizations that are
government funded at least in part fund
the long term high risk research that
companies don't fund at the beginning
they come in later and i think i think
that's one justification if you will for
why the going back to the discussions
about helping graduate students get
training in this area it is a proper
role for government simply because
companies don't do that they come in in
the case of AI Jeff and I have discussed
this about 20 years after the fact and I
think that's appropriate there's
complimentary roles the public and
private sectors in science and
innovation so back to Jeff so Jeff is I
think propria godfather of deep learning
AI has really brought to the field and
the AI winter
amazing new insights that we've been
talking about all day today and going
out tomorrow he is a chief science
advisor to the vector Institute and he's
a professor emeritus here in Toronto at
the University of Toronto moving on from
Jeff Yan laocoon yan is director of AI
research at Facebook although I think
his title is changing in facebook he
tells me he's the founding director of
the NYU Center for data science
he's a CFR senior fellow and he's now
the co-director of our learning and
machines and brains program with Yoshi
of NGO from from Montreal and our third
speaker where he is right now is there
Russ is Russ salakhutdinov he's also a
thief our fellow in in that program
learning machines and brings he's a
professor at Carnegie Mellon University
and he's the director of AI research at
Apple so I'm gonna turn over to you guys
I'm not we're all looking forward to
great discussions thank you so I gave a
45 minute talk to another conference
this morning and so I figure if I do
every third slide we'll be fine it used
to be if you wanted a computer to do
what you wanted you out to write a
program which when you have to figure
out how you would do it yourself and
then get the computer to do what you
would have done but very fast now what
you do is you tell a computer how to
pretend to be a neural network with
learning algorithms you do that one so
that's programming but after you've done
that you just show it lots of examples I
think figures it out so let me show you
the kinds of things you can solve that
way
suppose your input is the RGB channels
of an image and your output is a string
of words consider writing the program
that converts those pixel intensities to
the string of words it's not trivial
people in air I tried for 50 years to do
it and didn't even come close we can I
do that and I'm now going to explain to
you what in your own it is because how
many people here know exactly what the
back propagation algorithm is okay so
you can
I'm going to explain to all the other
people just what this algorithm is
that's responsible for all of this stuff
okay first we start off with an
artificial neuron which is a gross
simplification of a neuron but he's good
enough so that we can put a bunch of
them together and see what they can do
an artificial neuron has some input
lines it has weights on the input lines
those green and red dots and what it
does it just takes the activity on the
input line multiplied by the weight adds
it all up and puts it through that
nonlinear function you see on the right
we tried a different nonlinear function
for 30 years and this one works better
that gives you an idea of the primitive
state of research in this area and um
that's it that's an artificial neuron
now we hook them together into a net we
make multiple layers and what we'd like
to do is learn all the connection
strengths in that net and these nets are
powerful so if we could do that we could
do more less anything so it's just a
problem of what's the rule for learning
those connection strengths that's it
we've almost solved intelligence and
it's very simple how you do that all of
you can think of an algorithm it's the
first algorithm you think of and it'll
work and it goes like this you take a
representative sample of your training
data for each of those cases you're on
it forwards through the network you see
how well the network does it producing
the answers you want you have some
continuous measure of that then you take
one of the weights in the network you
change it a tiny bit and now you do that
whole batch of examples again and you
see if it got better or worse if it got
better you keep the change figure worse
you don't that's it that's the learning
algorithm and that will work that's a
very naive idea of how evolution works
it's not entirely wrong and the
evolution actually is a fact
and all I'm going to show you is
basically a way to speed up that
algorithm so notice that in these nets
the net at least knows what the
strengths of the connections are so to
know the effective of changing away we
don't actually have to measure it we can
actually compute it so what we're going
to do is we're going to run an example
through the net we're going to look at
the difference between what we got on
what we wanted and then we're going to
go backwards through the net
using the weights in the net to compute
for every connection strengthening the
net how a small change in that
connection strength would have changed
the outputs of the net and then we are
going to say do I want to change it in
that direction or the opposite direction
this is called a derivative though did
you like calculus the rule we use for
going back is called the chain rule so
this algorithm was enacted by Newton I
think and so the back propagation
algorithm you go forwards through the
net using the same amount of computation
you take your error and you send your
error backwards through the net and
after you've done that you know for
every weight how changing it would help
or hurt the output and then you change
it a bit in the direction that helps the
output in proportion to how much it
helps the output that's called steepest
descent and amazingly you can talk to
all the smartest people in optimization
or you can say let's take a small batch
of examples and run it through and just
do steepest descent and that works
actually somewhat better than all the
people in optimization almost that's
what people use your boats fine with
minor tweaks fancy optimization methods
haven't helped much and this works so in
the 1980s people investigated a lot but
then it didn't work very well in deep
nets and it didn't work
except I love the kind yan use and it
didn't work very well in recurrent Nets
and so people gave up then some people
in Canada this is the origin myth and
don't believe everything you hear
then some people in Canada made some
advances and made it work better there's
some truth to it and now what you need
to remember is that if you've got a lot
of label data you can take one of these
mares trainer and lots of label data
you've got a lot of compute back does
amazing things yes yeah your honorary
Canadians so the first amazing thing it
did was in speech recognizers we will
put in some coefficient subtracted from
the sound wave when it falls through the
net and predict in the middle of that
piece of sound wave what piece of a
phoneme someone is trying to say and it
did slightly better than the best
existing system but I was just two grad
students over a summer and the best
existing system we had to kind of thirty
years of research and so it was obvious
if it's going to work better only did
and that appeared in your cell phones
this net actually in 2012 in the Android
one thing to notice if you've done a
statistics course is that there were
just a few million training samples and
there were many more million parameters
than that so we had many parameters per
training example so don't believe what
you hear of course it's just work we
took it to Google it worked fine then we
did object recognition it's basically
exactly the same algorithm and you
showed images and you try and get it to
give the classes and it did much better
than the other methods in 2012 the other
methods were plateauing at about 25%
error this got 16% error which amazed
people by 2015 it was 5% error and now
it's below 3% error that's what happens
when you develop a technology so it's
better than people at least on this data
set we were the ones who showed that it
worked on this big public data set we've
built heavily on Yan's research we
basically scooped John with his own
research and a few extra tricks
recognizes things like that the one on
the right is interesting that's from a
catalog and if you look at the orange
line is what it thought and the other
those errors all its errors are
reasonable things you can see it needs
classrooms but you can see why it might
have thought that was a frying pan what
I'm going to talk about mainly in the
time I have left is recurrent neural s
you'll have to stop me out the corner or
now because it's you're the one with
motivation um okay I'm gonna simplify
recurrent Nets the recurrent net has
some input neurons where you share a
word for example it has some hidden
neurons which connect to themselves so
these columns are time slices and if you
look at the second time slice you can
see that that middle hidden unit is
getting inputs from the previous hidden
units as well as from the input in all
size units were predicting us so as the
words come in one at a time it
accumulates information in these hidden
units and people in Montreal and people
at Google thought up a way to use this
kind of network for machine translation
and it sounds crazy so here's what you
do for each language you have an encoder
network it's one of these recurrent
networks it takes the words in that
language and converts it into the state
of this hidden net it then says the
final state of this match is the thought
that's the thought expressed by that
string of words
Yanni's wincing because I'm simplifying
in this stuff three years out of date
but don't worry about it then gives that
thought to a decoder net that can we
either can decode it in whatever
language that decode a net training so
for example french so the encoder RNN
works like this you give it words one at
a time it converts a word into a big
bunch of features it learns to do that
I'll show you how in a minute and then
that word back don't goes to the hidden
units later on we have more layers of
hidden units the hidden units feed to
themselves they accumulate information
from all the words and the final state
of the hidden units is a thought
nobody's ever shown you a thought before
that kind of activity in that vector is
the thought and we know it's the thought
because you can get it from English and
then you could say it in French
and if you translate right you must have
got the thought right it's a very naive
view of translation so the net that says
it in French first takes the thought I'm
ignoring cultural differences I'm
supposing you can have the same thoughts
in English in French you take the
thought you then say given this thought
what's a good first word and it predicts
a distribution it says 40% lower 50
percent la 10% shot because I only knew
three words in French right and so then
what you can do is you can pick from
that distribution so with a probability
40% we think a lot and then you tell
this match hey you were right it was not
and so you feed learning there's word
well and it goes through the net and it
then predicts it just a little second
one it's a shot and so you say well it
says 60% shot so you say you pick that
with probability 60% or suppose you got
lucky a big shot you know say okay you
were right what do you think the next
one is and so on and so you could that's
a naive way of decoding you can decode
better than that but that'll do true
this after dinner talk the amazing thing
is that whole thing works the way you
train it is you have your encoder net
that doesn't know anything it's just
random weights right it's complete
garbage as Steve Pinker would say you
copy the thought across to the decoder
net but it also is complete garbage and
you get the decoder net at each time
step to give you a probability
distribution over words and let's say
that the third time step you know the
correct work is someone gave you the
translation you simply say I want to
raise the probability of that word or if
you're very mathematically if I want to
raise the log probability backward and
you can trace those arrows backwards
right just as we went backwards through
the net you can go backwards through
this net so for every connection you get
a derivative that says how a small
change in that connection strength would
increase the log probability of saying
the correct word as predicting the
correct word as words read and you just
accumulate that over lots of training
data change the connection strengths
accumulate over more cleanly in here and
change the endurance again and you keep
doing that
Hey
resto it translates better than a batch
as well as the existing technology and
then you put a lot of work into it and
it translates considerably better than
the existing technology and now when you
go to Google and Translate is doing
something like this there's a few little
tweets there's a tension which was
introduced by Yash Reis actually
introduced I think by Cho who's now at
NYU and we wouldn't like his boss not to
note with him and bharden oh and Ben geo
and they do what translators do which is
they learn as you're decoding to look
back at the previous sentence actually
the hidden states you had in previous
sentence and get some input from those
so try and find the relevant bit of the
previous sentence to help you out it can
translate together way but it's just
better if you do that we also don't use
whole words you take any language you
take 32,000 word fragments don't use a
linguist just use statistics get
thirty-two thousand word fragments which
in English as well would be a fragment
but the individual letters will be
fragments and aim and things like that
and um and that's what you feed in word
fragments and when you translate you if
you don't want records this actually
works and that's how Google is doing
your translation map okay now you can
combine that revision so instead of
feeding what you got from the encoder
that looked at an English sentence into
the network you can take the last hidden
layer of the network that does
perception then you can feed that into
the network and then you can decode the
percept so people say we don't know what
neural nets experience well let's get
them to tell us what they experience
exactly the same way as we get people to
tell us what we experience you take the
neural net and you train it so they'll
tell you what it experienced and so it
has an image and it tells you what it
sees
we don't write so you show that net and
it says a group of people shopping
electro market you showed this image and
it says I closed off of a child holding
a stuffed animal now there's a certain
amount of fraud involved because it was
trained on a fairly limited vocabulary
but it basically works and I was
completely amazed from I saw this and I
you know rush on
I'm not going to tell you about the
implement again implications for don't
embarrassing or medical images or I will
turn you breathing for that Q star how
long do I know from two minutes I can do
George John who did the speech
recognition stuff entered a Cargill
competition where you get properties and
molecules and you have to predict their
activity and he won the competition by
using a neural net that's basically the
same as the speech recognition John that
you didn't know anything about chemistry
and so mark was going to paying twenty
thousand dollars for winning the
competition and they said but first you
have to tell us what cues are you used
and George said what's Q so now two
sectors that is a field
it's called quantitative
structure-activity relationships it has
an annual conference it has a journal it
has people who work in keys kusa
reputable academics and george won't
come out without knowing the name of the
field the theme here is that this
algorithm is powerful enough so if you
give it plenty of data you don't need to
put any knowledge ask how many linguists
were needed to make the system that
Google now uses for translation I'd love
to tell you it was zero in training the
system known English really did
the less the better but for the data for
getting good data you still need
linguist for giving you good datasets I
want to do one more thing and this is
really fun so you've got to give me
extra time this is something I did with
Ilya before the translation stuff we're
gonna do a philosophical experiment the
philosophical spirit is this could you
train a model to predict the next
character in Wikipedia it starts with no
knowledge if you trained it or anything
like character in Wikipedia will you end
up understanding the meaning of life do
I have any votes for yes well you're not
very good game players are you um okay
so that's what we did we trying to look
to predict half a billion characters or
four GPUs for a month and then we gave
it and I'm hoping this works yes okay we
gave it a string and we said predict the
next character and it gives you a
probability distribution okay so you
pick for that distribution and hopefully
it said space I mean it could have been
the meaning of life Island
but space is very probable and it did
say space and so he said okay you were
right it was a space now what you
predict next and we pick from the
distribution now we did that ten times
and pick the best the cutest here is
what the net said and it's not 42 42
wouldn't have been interesting because
it's in Wikipedia it said something
that's not at all in Wikipedia you can
search the strings in Wikipedia you seen
this isn't there it just made it up this
is what it taught the meaning of life
was you run till you got a full stroke
it really did this : that's not a full
stop you're all grown-ups right now it
hasn't quite got it but it's well on the
way right okay I'm done all right thanks
thanks for your attention and thanks for
the invitation and it's been a really
great pleasure to be to be at the top
it's actually pretty hard to go out the
Jeff with all the jokes and such but but
I'll try
so I'd like to Jeff introduced
backpropagation algorithm and you can
all that works I'm going to use a lot of
that in this presentation as well so
what I'd like to just show fairly
quickly is that you know this is sort of
we live in the age of big data and
that's I think a lot of it is fueling
the deep learning deep learning research
particular in the space of images stacks
speech you just seen some examples
scientific data relational data nuts and
that's very important I also wanted to
emphasize the impact of deep learning
and this is something that's out there
it's real right this is not something
that can work
works kind of doesn't it actually is
having a quite substantial impact the
speech recognition vision language
understanding is one big there they'll
try to highlight a few a few things drug
discovery medical image analysis is is
gaining some some traction with with the
pointing and ultimately what we'd like
to do we would I'd like to do is to
build agents agents that can recognize
objects around us understand speech
understand language navigate autonomous
then display human-like intelligence and
we'll see more and more personal
assistants self-driving cars that
technology is being developed and I true
belief that we will see that technology
in not that distance of the future this
is just one example I actually stole it
from one of Jeff's slides earlier slides
this is a speech recognition development
of speech recognition technology you
know all the way up to to year 2010 and
then I think Jeff and his students
really showcase the use of deep learning
and then you can see tremendous
improvement in speech recognition
technology and pretty much all the major
companies are using that technology
neuro imaging that's another very
exciting area an area of health in
general has been some work done in
university of new mexico back in 2014
looking at fMRI scans and doing better
classification so some examples of that
as well but what I'd like to do instead
is I'd like to perhaps quickly point out
to some of the key challenges where the
current research is and where we're
trying to make some advances reasoning
attention in memory that's one area that
you see a lot of research happening how
can we build systems that can reason
language understanding that's another
huge area I'm gonna show you some
examples particularly reasoning involved
in language understanding did
reinforcement learning I think you're
during the day to data with a few people
mentioned reinforcement learning and
deep reinforcement learning I'll show
you some examples of that also
unsupervised learning
again people talked about unsupervised
learning this is the area that's we
haven't really seen a lot of advances it
doesn't work as well as traditionally
supervised learning
you know examples that we've seen with
image net transfer learning one-shot
learning so let me dive into a a couple
of these questions so Jeff showed some
examples but I just wanted to iterate
this what was done a couple of years ago
and if you look at what these systems
can do this is a model that takes a deep
neural network convolutional network and
then uses a recurrent neural network to
generate these sentences and if you look
at some of them it's actually pretty
good five years ago nobody thought that
we could do something like that in fact
if you talk to computer vision
researchers they would say oh the holy
grail of computer vision is to really
generate a description of what you see
in a image not just to classify that
there is a dog there is a cat but
actually have a description of what
you're seeing an image just like humans
will do and this is pretty remarkable
right the question that comes up is that
is it really doing something interesting
or is it just copying things from you
know some training set and not really
imagining new things so here are some
examples of where it fails right so for
this image it generates the handlebars I
try to ride a bike rack now this is
something that a human would not say
right and that was a very good mistake
for us because it really says that these
models are doing something just beyond
coffee or the two birds are trying to be
seen in the water alright so this is
again a mistake or this one the man is
holding a red apple to his mouth now
this is a failure case when we are
testing these systems in the setting
where these images are not coming from
the training samples so in other words
we never train on sports videos Oh
sports images right so if you don't see
any sports images then that's a pretty
reasonable explanation then this was
done this work was done by Jamie Kier as
a PhD student at Toronto we basically
kind of extended what Jeff was talking
about the current neural network for
predicting characters but instead we
were predicting words and you can train
recurrent neural network
can read 11,000 books 74 million
sentences there's a huge corpus there is
no linguistic knowledge no supervision
no labels not nobody's telling what's
the meaning of these words are you just
looking at statistical patterns of words
right and then what you can do what you
can do is you can take an image I don't
know what Jamie actually did is that he
trained one of these models and romantic
novels 7,000 romantic novels and then
you say well given an image can you
generate me a short paragraph in the
style of what you've trained it on and
this is what it generates for that image
she was in love with him for the first
time in the Moschino essential questions
gay things the Sun had risen from the
ocean making me feel more alive than
normal she's beautiful but the truth is
no know what to do the sound was just
starting to fade away giving people
scattering around that antique ocean
right now if you look at that it's kind
of funny because she semantically we're
not there yet but we were surprised that
syntactically
it was pretty coherent right and
generating a coherent paragraph is very
difficult without any supervision and so
then you can say well why why do we need
that how's that useful well it turns out
it's actually can be useful for a lot of
things like people are interested in
sentiment analysis in general or or
trying to look at so one particular
problem is something called semantic
relatedness where I give you two
sentences and I tell you do they mean
the same thing or not and that's
extremely useful for a lot of tasks so
here for example the model is speaking
out that the man is right is driving a
car or car is being driven by the men
two sentences mean the same thing and
again this is just done by linking at
11,000 books right a girl is looking at
the woman in costume and go costing
looks like a woman these are two
different sentences the model correctly
identifies that the meaning is different
right this is where it's failing a
person is performing tricks on a
motorcycle the perform is treating a
person on a motorcycle like so that gets
a little bit more into perhaps deeper
semantic understanding which is you know
perhaps we're missing in these models
but let me just show show
couple of examples in reasoning there is
there's a little bit of research taking
place it seemed you would imagine that I
give you this document this is one of
the stories so where's that they know
gamma Rob Blagojevich and his chief of
staff John Harrison corruption chance
the whole text and if you remember the
scandal back in 2008 and and you you
being provided with a query so the query
says president like Barack Obama said on
Tuesday he was not aware of alleged
corruption by X was arrested and so
forth the question is who is X okay and
it turns out that for this particular
data set it's not just enough to look at
one particular sentence but to look at
one particular piece and find out what
the answer is you actually have to look
at the entire article and connect little
dots to be able to answer that question
people like stream Lee good at that in
fact the accuracy that people can get
you like 98 99 percent so this is
something that's much tougher to do and
current state of the art systems are
these deep multi-layer networks but it's
interesting where each layer here
contains a recurrent neural network so
it's kind of an RNN bill on top of
another errand and built on top of
another RNN is a query you look at the
documents these are fairly complex
systems but they they work fairly well
we know them par with humans but we're
getting there
and what it actually does if you look at
attention or if you look at what model
is paying attention to it turns out that
model is picking up that alleged
corruption and seven-seat are the
important features for being able to
answer that question right and again
this is something that we're not telling
the system a priori pay attention to
corruption pay attention to the Senate
seat it basically figures out from the
corpus that these are the important
features which is which is pretty
interesting now in the last five minutes
I'd like to show you just a couple of
developments in the reinforcement
learning that we've talked about today
during the conference the idea behind
the enforcement learning is to really to
map sequences of observations what you
see two actions and you can think of it
as
an agent you take an action the world
gives you back the observation and once
in a while we get rewards the world is
telling you how good that action was
that a good action was that a bad action
typically rewards are pretty sparse and
it's been around these systems these
models been around for quite some time
one of the recent developments that I
think is really exciting is is this area
of trying to learn external memory so
these a new kind of generation of
architectures where you're actually
learning what to store and how to
retrieve it from the storage much like
our computers are storing information
you can try to learn important
information to store but before that I
also wanted to show you an example now
this example is a little bit
controversial so sometimes when I show
this example I get heated discussions
this was done by a couple of people was
published in 2017 and triple-a I and I
know Jeff is in the audience so it's
it's you know it's particularly anyways
let me show you what these guys did okay
whether it's ethical or not ethical we
can judge but let me just show you what
they've done so here's an environment of
using the enforcement one you know let
me just explain what you see I can just
pause well let me explain you what you
see what is seeing is the system this is
the input right you see a friend you
pass it through this deep neural net and
the deep neural map and predicts an
action an action is moved with a turn
left turn right go for it right and the
rewards that you get here is collecting
objects you want to collect as many
objects as possible you're not telling
the system how do you navigate you don't
tell it what actions to take you're just
telling the system try to collect as
many objects as possible oh sorry
and what this system is let me see if I
can run it again what the system is
doing is is just learning to navigate so
you know now goals get stuck in the
corner can't get out because to get out
of the corner you have to execute
actions left
left left left left the model just can't
do it after 30 minutes of training it's
kind of learning to move around in this
environment virtual invites a simulated
water but it's not the real environment
but nonetheless gets stuck because it
doesn't see the barrel after about
couple of hours of training it can
actually move around so it learn to
navigate in this environment
pretty pretty accurately it's avoiding
lava and things of that sort
again just by collecting objects so
you're giving a target collect as many
of you know telling it you're not
teaching it how to navigate just figures
it out woman's own and then you know you
can train it on different environments
though so both of these authors train it
on various environments various textures
and then the incredible thing is that
then you can put it into completely new
environment completely new math and it
will it will basically navigate in this
environment so the goal is to just move
as fast as you can through the
environment doesn't get stuck right so
it moves around and then the
controversial piece is that there was a
competition set up at the nips I guess a
year ago that basically said well can
you actually wanted to play this game so
we're gonna put bunch of people bunch of
machines and you just execute you just
gonna learn to play the best match and
this is what the system does right after
learning to play it's actually behaving
I think you often reported that it's
wanting to play way better than the
average human okay so it can now I think
they actually took the second place in
this competition and it's sort of you
know it's big sound right and this is
again just based on the first just based
on frames okay so this is something
that's yeah I just
well what's that in Britain it was not
in the US but nonetheless I mean this is
just a game again it just goes from
actions from perception to action but at
least in their simplified version
environments people have shown that you
can you know compete with human players
now let me just finish off by saying
that this notion of learning to memorize
of this notion of actually the problem
with the previous model is that it's
sort of the reactive model you know you
walk into the room you immediately
forget what happened in the past all
right well you go to one in one place
you completely immediately forget what
happened behind you so you just
completely memoryless agent and some of
that work was also developed by deep my
memory peeps but let me show you one
particular example which which is very
hard to solve
imagine that you're navigating in some
maze environment and I give you an
indicator in this environment it is an
indicator if the indicator is blue you
have to fly in the green world if the
indicator is pink you have to find the
red block okay and the distance between
indicator and where you need to go can
be fairly large so the model has to
learn to remember that there is
something that's called indicating my
environment once I know what that is it
you know I know what my target should be
and you're not giving that information a
priority to the model you're not telling
the model that these if-then rules
you're basically saying can the model
figure it out song and indeed what it
does is it learns to store the state of
the indicator and then it navigates in
the environment find the wrong targets a
completely random environment this is
the more never seen this environment it
finds the wrong target remembers from
the memory from an external memory what
it was and then moves around up until it
finds the right target right so these
are kind of little baby steps towards
you know solving something is called
long-term dependency problem where you
can actually you know find these to some
extent rules and so the question is can
we actually build agents that learn
somehow some kind of external memory
that can communicate that can reason
there is one other work the final work
that I'd like to show you is this is
another example of an agent learning to
execute instructions so you can say go
to the red pillar or go to the short
pillow without telling the system what
the short pillar is you're just giving
it the targets so if it achieves the
target you give it positive reward but
doesn't she'll be target to give
negative reward so after it takes a long
time training this system so that's one
big drawback but at the same time after
a while it figures out you know what the
tall red object is or so here's go to
the target go to the smallest blue
object so it figures out it's in some
form the meaning of the largest object
so it tends to go to the largest always
it goes to the smallest green objects
out of the green objects it picks up the
smallest ones and again this is
something that's people sometimes call
language grounded because you're not
telling you what's the meaning of the
smallest or the tallest you essentially
just saying in this environment this is
the tall can you navigate to this this
and after a while it's actually learning
to do that it's actually getting some
notion of what's the floor what's the
smallest what's the tallest and so forth
cities again it's just some baby steps
towards building these language modes
and I'll stop here thank you
alright ok this is the last talk you
have to endure and I'm really glad that
first I'm very glad to be here I'm
running a lot during in this workshop
and looking forward to tomorrow and I'm
really glad that Jeff and Russ you know
introduced the topic I don't have to to
do all that so you know by now you
certainly have some idea of what AI and
machine learning as he premieres but
there is sort of a number of different
sort of categories of AI machine Ani
that people have talked about in the
past so this is something called Goffe
good old-fashioned AI which is what Jeff
described does you know you basically
write a program to do something or you
write a set of rules and you have kind
of a inference engine that is the use of
those rules to derive new knowledge and
that's very manual and that's why it
wasn't that successful because it turns
out to be very difficult to reduce human
thought process into kind of a set of
rules it's very brittle as well in the
90s machine learning became quite
successful and it's the the process of
creating a machine learning system
basically consists in having people
massage the data design good
representation for the data and then
train a super model say that logistic
regression which I'm sure many of you
are familiar with or just regression and
a lot of work goes into figuring out the
right combination of very relevant
variables and and you know kind of how
to kind of you know transform those
variables so that your model actually
doesn't be useful so that requires a lot
of human intervention deepening
basically eliminates that step of
figuring out what the right features are
and what the right combinations of
features are you give it you give the
system the raw data and you know
training data the machine will figure
out how to combine the input features
even if there is a very large number of
them so as to produce the correct output
so that's really what took off in the
last few years and what we hear about AI
in the last few years it's just this
thing that this manual
requirement for manual work by experts
has been essentially replaced by manual
work of labeling data by non expert
right but that's not really AI in the
sense it's not truly I I mean despite
all the cute demonstration that that
have been shown which are incredible
successes and are very useful
you know AI would be slightly more
autonomous system that integrates
perception prediction reasoning decision
making and we're making baby steps
towards this but were nowhere near the
solution so you know application of AI
you know I had a few glasses of wine so
I can speak as fast as Jeff but like
he's not without speaking with a very
strong French accent so you know if you
know talked about this at lunch medical
image analysis or a cars accessibility
face recognition all kinds of stuff
which you know certainly are going to
you know revolutionize entire segments
of the economy and society but all of
this is based on supervised running
supervised running of course is like
regression you all know about this but
is the you know econometricians among
you as Jeff explained you you show an
input you show the output you want and
you adjust the parameters in the system
is equated to set so as to kind of get
the output error as low as possible and
it it's all a matter of what you put in
that box with all the adjustable knobs
and how many knobs do you have right so
a typical neural net will have you know
a couple of million or a couple tens of
millions or hundreds of millions of
those adjustable knobs and you know a
few million training samples to train
them on and the funny thing is that
everything you learn in statistical
textbooks is wrong
you actually can learn things with many
more parameters that you have training
samples without overfitting and it's
somewhere to a mystery why this works
but it does work so one of the the way
another question is how do you kind of
connect all those you know simplified
neurons that Jeff was talking about and
a particular way of connecting them is
something called conditional Nets which
I worked on when I was in Jeff's lab as
a postdoc in 1987 that was 30 years ago
and so continued that work at Bell Labs
and started having success with this
very early on just after just a few mall
so being at Bell Labs and you know
getting really good with awesome
character recognition that's the only
application for which we could have
enough data at the time there was no
other applications for which you know
there was data that we collected there
had been collected by the US Postal
Service essentially or by been
accessible collected images of checks
and in just a few years we managed to
deploy check reading systems based on
commercial neural nets probably one of
the first really large-scale
applications of neural nets that was
commercially deployed by the late
nineteen so there were two applications
the first one was deployed by NCR which
at the time was really TNT in 80s so
it's the first ATM so you could just put
your check and the ATM would recognize
the amount you have that everywhere now
but this was deployed in 1995 and as I
guess Larry Sanger was Summers was
saying this earlier the number of
terrorists actually increased after the
ATMs were deployed so this is this is
not displaced jobs the automation of
that process did not displace jobs you
see only the human contact on the other
hand and here also deployed another
machine
a year later based on our technology
that was a high speed check reader for
the the back pockets of banks and that
had the performance of being able to
read about half the checks that were
presented to it with a very low error
rate and then deciding on the other half
that it wasn't good enough certain
enough about what the what the amount
was and then sending that to human
operators so this was my first you know
personal contact with actually putting
people out of jobs because you know a
few years later the system was a whole
bunch of banks and was reading on the
order of 20% of all checks in the US and
because I was reading have no checks it
was fed basically eliminate hit 10% of
the jobs just a few years so you know
certainly technology displaces jobs we
know that I hope these people found
better jobs and then in the last years
the limitation of the system which is
why the community kind of got
disinterested in this so one thing I
should
mentioned as well is that a patent was
actually filed in 1989 and 1990 on
commercial Nets and when eighteen split
itself up and spin-off NCR it the
lawyers in their infinite wisdom
assigned the pattern to NCR which had no
idea what they had in their hands the
patent thankfully expired in 2007 and
which is good because now we can use
commercial Nets without taking anybody
and I think it would have actually
slowed down the progress of the galley
if that patent had continued so
thankfully or not the the field turned
away from machine learning turn away
from being interested in those passions
and kind of give up a little bit there
was kind of a legend which was that very
few people could figure out how to train
those those systems and you know I was
only one of them even Jeff was saying
this at the time it's not true there's
not thousands of people who can train
those networks it's just that the
software you had to build to be able to
do this was kind of complicated and it
wasn't widely available or console's
distribution was not something that
people were used to and so the
technology was not widely disseminated
at the time and he took another 10-15
years I also took the deliberate
decision by Jeff you and me with a help
of C far to actually rekindle the
interest of the community and his
methods in the early 2000 and by the and
by the early 2010 decade Jeff had with
students that figure out how to run
those things on on GPUs which can speed
up the execution of them by a large
factor and there were a few more tricks
that were invented which made it
possible to Train very very large
networks on our data sets like imagenet
and it's not like nothing had been
happening in the meantime you know we
developed things to you know drive
robots around with this with this with
this technique and do all kinds of
applications that nobody care about
there was new quite a few papers
published between let's say 2003 and
2013 where the community started paying
attention that basically nobody cared
about
so it's an interesting history for the
sociology of science that people will
have to analyze and so to much in the
middle of it you really kind of be able
to do this but since then there's been a
lot of progress in applying this to
computer vision so you saw some examples
in captioning is recent proposals from
people at Facebook and other places on
how you can use computer vision systems
to not only just recognize objects or
describe images but even outline the the
contour of every object in an image even
if they overlap a lot and if there are
so multiple instances of the same object
like you know all the sheets here are
being kind of identified separately all
the elements in the table etc so this is
a kind of task that computer vision
people again repeating something that
russ was saying earlier if you ask
computer computer vision people just a
few years ago five years ago perhaps how
long is it going to take for us to be
able to do this they would have said
like we have no idea might take 10 years
15 years it took you know much less than
that now I was really interested by the
the couple series of talks earlier today
about the not the effect of a IO society
but the effect of machine learning and
AI on economics I actually dabbled in
this a little bit I worked with
economist in Y you've enjoyed Kaplan and
John Lahey on uninteresting problems for
economists like tweeting real estate
prices high spices I'm told this is kind
of like you know very low in the sort of
hierarchy of things that people are
interested in in economics but but it
has some relevance in the late 2000
because you know and we study several
models and and I'm telling you this
because of a story I want to tell so you
know you can use very simple things like
you know predict that the price of a
house is basically the same as the price
as the house next door you can do you
know
linear regression doesn't work very well
so we can predict the price of the house
within ten percent you know about 40
percent of the time for the eight
percent of the time you can do locally
weighted nonparametric regression we
have sort of continuous surface of house
prices etc works a little better you can
train a neural net
that you just give it the
characteristics of the house give you
the price and that works okay but what
works best is when you combine this and
that so you you say the price of a house
is the product of the intrinsic price of
the house regardless of where it is and
then they kind of local desirability of
the location and you of course don't
know the disability of the location will
you infer it as a latent variable that
works kind of well and so then we turn
around and talked with our friends
economists and we said and this idea we
want to write a paper about this you
know economic journal and I said but we
can't use this because there's no way we
can explain this to economists and also
it's too complicated so we can't really
explain
you know what the dependency of the
variables is so we're just going to use
this or you know perhaps that we're not
going to talk about this at all
that's what their brother paper we wrote
a paper image you don't need to roll you
know everybody was co-author mm-hmm we
talked about this because that is not
interesting Commission on young people
and then the economy is turning around
and said you know this kind of works
well so perhaps we should like create a
startup to actually predict house prices
you know I may be useful to mortgage
people right and ask them okay which
model do you want you want the one you
can explain or whatever what actually
works and say about this one so you know
that's kind of the debate between the
explained ability and and things that
actually work and and you may not have
both right you may not be able to have
both so anyway this was applied to Los
Angeles you have it's kind of oops
continuous surface of desirability in
Los Angeles you know the Beverly Hills
you know it's alright because it's what
expensive stuff and you can even do
sensitivity analysis so it's not like
those things are completely not
explainable you can figure out like if I
add a bedroom to my house is it going to
increase the price by the significant
amount and if you are in a you know
varial heel no but if you are in
probably yes
okay so issues with supervised running
is there's a commercial of them that we
mentioned today they reflect biases in
the data you need
data for to train them on so for example
so Facebook uses those commercial Nets
and various other things for translation
image recognition you know text
classification for deciding what to show
you on your newsfeed everyday Facebook
users upload something like 1.5 billion
photos on Facebook every day every
single one of those 1.5 billion goes
through four convolutional nets when
that's used to detect objectionable
content so basically for filtering
there's actually two of those one that
just recognizes the image and no sorry a
second one that recognizes the image and
generates descriptions for the for the
visually impaired another one that
recognizes objects in the image so that
we can better decide you know what to
show people and the last one which is
turned off in Canada and Europe is those
face recognition so it tags your friends
automatically but people in Europe and
Canada are not entirely comfortable with
that so so it's turned off so you know
there's issues of testing and
reliability and liability who you know
who is responsible when a algorithm sort
of makes a bad decision or learning
system makes a bad decision is it the
person who coded the machine learning
program probably not because you know
it's very far away from the and the
person collecting the data which might
have biases in it person who trained
your system or the person who can a
package the whole thing to make the
product it's not entirely clear
you know I alluded to the question of
should a I should decisions by AI
systems be example I think it's easier
to generate explanations from deep
learning and neural net system that
people think it's just that there is
very few situations we actually need to
do this surprisingly yes everybody
thinks the you need explanations but
nobody actually does it's just a way to
kind of be reassured but it's not useful
not very often at least
so okay but really the main problem here
so we've talked about the revolution of
AI and deep learning etc I think there's
going to be two revolutions and and it's
starting by a bulb that explodes I think
it could be two revolutions the first
one is already announced it's already
happening
which is the one that's brought about by
by deep learning and supervised running
and all that stuff the second one we
don't know how long it's going to take
before it occur before it happens in the
in the research side of things and how
long is going to take to kind of you
know disseminate it in the wider society
and it's one where the technology will
be developed to make machines really
intelligent we don't have that
technology today we're not going to have
it for a while and I'm going to tell you
a bit why so as Jeff and resolutely -
there's three types of learning
reinforcement learning supervised
learning which I talked about and
something else called unsupervised
running or predictive learning still
difficult to define but it's basically
allowing machines to learn from
observing the world or by you know
acting in the world and just observing
the results without necessarily being
rewarded for it well with without being
told what the you know where the correct
action is at any one time but kind of
like you know baby humans or or or the
animals learn learn how the world works
by kind of observation human babies run
a lot by observation without acting
because they can't agree well I mean
very much you know that kind of comes
later
so reinforcement learning is a scenario
where you only tell the Machine whether
what it did was good or bad you don't
tell you the correct answer
supervised running you'd give it the
correct answer and in supervised
learning you basically ask you to
predict what's gonna happen next or or
what is it like you know fill in the
blanks for some information that's
missing you're you know you're looking
at my life my left profile right now but
you can pretty much infer what my right
profile is open if you would never seen
me before because you know that faces
are more or less symmetric it's an
entire array on your visual field that's
a blind spot but you don't realize it
because your brain kind of fills it in
so there's a lot of unsupervised
learning going on in your brain that
basically fills in the blank for all the
stuff
you can't you don't directly perceive so
reinforcement learning is great what's
really worked great for games as rest
Road so he shows examples where two
students at CMU placed second in a
competition this is the you team that
plays first that's the team from
Facebook last year and so they you know
they web web your team but this year
this year the same people that you
talked about you know actually won but
now he is because they joined Facebook
um these of student parents you know it
worked really well for defines alphago
which you know played more go games that
all of humanity in the last 3,000 years
which is how you could kind of figure
out all those things and you can do this
for games because you can gain you can
run games on hundreds of computers
simultaneously faster than real time and
therefore you can generate thousands and
thousands and millions of samples and
the problem with reinforcement learning
is that it requires millions and
millions of trials so I was saying
earlier today if you want to use
reinforcement learning in the classical
sense to train a machine to drive a car
it's gonna have to crash into a tree
forty thousand times before it figures
out that is a bad thing so clearly
reinforcement learning in itself and
supervised learning in itself are not
the answer to AI animals and humans
learn much much faster much more
efficiently than machines and we don't
know how we don't have the secret for
that that's the next frontier in AI
until we crack that nut we're going to
be limited in the sort of broad
applications of AI and we don't know it
has going to take two years five years
ten years 20 years in might take longer
now that that led me to kind of make
this slightly obnoxious analogy for
people working refrence Patroni which is
that if heat elegance is a cake the bulk
of the kang dojin was is unsupervised I
mean that's where we learn everything we
learn the icing on the cake is
supervised running in terms of the
amount of information you give the
Machine when he trains and the cherry on
the cake is reinforcement running and
you're telling people tend to get upset
when I show this
it's basically a way of telling that the
consumers running is the dark matter of
artificial intelligence you know it's
kind of like physicists right they tell
you oh you know everything we know about
in the universe is only about 5% of of
the mass of the universe you know the
other 95% we have no idea what it is
it's the same here so 10 machines learn
like like humans and animals by
observing the world can they acquire a
common sense what is common sense it's
this ability to fill in the blanks
filling parts of the visual field which
is simple predict the future from the
past in further past from the present I
mean all kinds of things like this right
and we acquire a lot of those capacities
we were babies so we do things like you
know acquiring the notion of object
permanence in the first two or three
months of life that the fact that an
object is still there it when you
consider which is what peekaboo is so
funny it you know even wrong tones they
don't have language they don't have
they're not social animals they live a
solitary life but they I'm a pretty good
model of the world you know you do a
magic trick in front of them and they
want to throw laughing cuz it it breaks
their world model right and so you know
we need algorithms to kind of learning
algorithms to discover regularities in
the world and I'm kind of parroting you
know what Jeff has been saying for 30
years or something right I mean 40 years
I mean you know whatever forever
so you know we don't basic things like
gravity and the way we can test this in
babies is or other people not me but is
that you you show something to a baby
and if it breaks is internal model of
the world the baby goes like this open
this I am like it stays like what what's
going on right pays attention kind of
like this and the disability to fill in
the blanks you know allows us to
interpret language as well so if I say
something like
- picks up his bag and leaves the room
which I hope it's not doing you know
just those few words you can infer
what's what he has to do it has to stand
up and extend his arm and you know
closes finger and then walk towards the
the door open the door
you know when once he's gone he's not in
the room anymore because you know you
can't be in two places at the same time
and you know he's not gonna fly away
it's not going to meet Angela it's not
gonna attract his bag back taken edges
so a lot of those things you know and
you can interpret the sentence and fill
in the blanks because of all the
knowledge you have about the world and
intuitive physics so or friendly manner
I do poo in France it's a developmental
psychologist I came up with this chart
of you know when it is that human babies
can learn those various concepts of
gravity and inertia and the solidity
object permanence and the fact that you
know some objects move by themselves and
others don't like this and you learn all
those things you learn that the world is
two-dimensional etc we don't know how to
do this with machines we don't know how
to get machines to just observe the
world and figure out how it works and
there's a big quote from Jeff which I'm
gonna skip we can tell you about it it's
a justification for wild supervisor on
use alrighty so now let's talk about how
this could be used you know why this is
a major obstacle to building an AI
system a fully autonomous AI system and
the AI system as russ explained is some
sort of agent that generates actions for
the world and then the world responds
with percepts but inside of this you
essentially have two or three components
one that essentially estimates the state
of the world by you know perception
there is an objective and economists
know about objective functions right
this is an objective function and
there's an agent of what the agent is
trying to do is basically keep keep
itself happy and the measure of
happiness or unhappiness is the
subjective function so the lower you
make the value of the objective function
the happier you are it's basically
trying to bring the world into a state
that will make it perceive the world in
such a way that you know it's state will
be a state of happiness if you want okay
and so this is true of artificially
intelligent systems that are autonomous
is true of animals as well they have
those modules in their brain now if you
want an AI system or intelligent system
in general to behave intelligently it
has to be able to predict in advance
play in its head a sequence of action
and predict this the consequences of its
actions you know we you know even a
simple cat cannot learn all the amazing
motor skill and and feed that they do by
jumping around they learned this you
know in a few months a few weeks in in
some cases and they do develop a very
very accurate model of the world and of
all over themselves there they're kind
of you know dynamics and what they can
walk on and you know etc so the agent
needs an internal world simulator model
of the world and if there is a statement
I would make is that the essence of
intelligence is the ability to predict
and then the other components are things
like the ability to predict the
long-term value of the cost so the
objective you you know you don't want to
just optimize the short-term objective
you want to predict what the long-term
effect is going to be over a sequence of
action and this is module that learns to
predict the long-term value of the
objective and then the actor can
generate action proposals that you know
given the predictions of the world
simulator optimizes the objective so if
you want to be stupid you can be stupid
in two or three different ways first you
can have a very inaccurate well
simulator a very inaccurate world model
you can have a quick 'add objective
function you know maybe you are
narcissistic or something like that or
you can be very bad at deciding on a
sequence of action that will actually
optimize your objective function even if
your predictor is good if your well
model is good and in some cases you can
get all three bad right you're a bad
wall simulator you have no idea what
actions to take and your objective phone
is crooked and in that case you get
elected president of the United States
so so the hard part is how to kind of
train a machine to learn those
predictive models and the problem is to
learn is the fact that the world is not
in turn
predictable you can have many things
that can happen in the world that you
just cannot predict right so if I take
if I take a pen and I put it in my in my
hand and I tell you I'm gonna let go
with my finger you can tell that the pen
is probably gonna fall but it's gonna be
very hard to tell in which direction
it's gonna fall so if I train a
supervised predictor to to say you know
predict weather and it's going to fall
by observing your future it's almost
always going to be wrong and the best
thing you can do is predict the average
of all the possible futures and it's
going to make a kind of a blurry
prediction it's not gonna work and so
we've been working on various methods
which are never going to explain but the
word was mentioned before by but you
know gas generator Universal networks
it's kind of a method for training a
system without without forcing it to
predict a single answer but allowing it
to make predictions where there are
multiple possible correct answers and
you know without going into into details
you can use this to train a system to do
prediction in videos and you know kind
of continue videos for a few frames I'm
gonna go to the details this is very
useful if you want to train a machine to
drive because you'd like to know that
the the pedestrians are going to keep
you know crossing the road or that the
car in front of you is gonna turn left
or knocking and you want to be able to
predict what's gonna happen in advance
so you don't make the mistake of you
know running into a tree and having to
crash for you thousand times before you
realize it's bad okay so my last two
slides what when will the the two area
revolution occur and as I said just
before I don't think we will have
household robots or good digital friends
or assistance until machines require
common sense you know it's gonna be very
frustrating to talk to machines until
they can do this this won't happen until
we get machines to contradict you world
models you know not completely accurate
but and this may take there may be a
breakthrough next year or it may take
5-10 years two years we don't know we
all work on the assumption that there is
a very simple principle and perhaps a
very
number of algorithms that are sort of on
July a I and you know as there is for
flight basically if you figure out there
with an NEX you to go that five you know
with stability and stuff you know for
engines it's thermodynamics what is the
equivalent of this for intelligence we
don't know we don't even know if it's a
good hypothesis it's a good working
hypothesis but we don't know if is true
so if you British people that Gary
Marcus you tell you the brain is just a
kludge it's a collection of hats and
there is no underlying principle behind
it and so it's kind of hopeless to try
to go something like this
I've personally and Jeff don't believe
in this but you know so you know how is
AI going to effect the the or perception
of value and I'm not an economist
obviously but I you know interesting
remark which I'm sure a lot of you have
figured out material goods the value of
material goods is going down and the
value of human experience is going up so
and I'm sure a lot of you I mean this is
probably the cliche and economics to me
you know so you can buy a blu-ray player
for forty seven bucks from science one
on Amazon or whatever but if you want a
authentic handmade ceramic ball ten
thousand year old technology it's gonna
cost you 700 bucks similarly you want to
listen to what our pelvic rotor and you
know we can download the recording for
seven bucks if you want to take it at
the met to listen to it the most
expensive ticket in Italy is eight
hundred bucks you know you can get them
for like two hundred bucks or so but
it's way way more expensive because it's
an authentic experience there is kind of
real stuff happening right so I think
the future is bright for artists
artisans jazz musicians I'm a big fan of
jazz so you know that's really kind of a
direct communication with all this and
it's going to give more value to
authentic human experience Thanks
the first thing I said to him was I
approve that can't work no deterministic
algorithm possibly do that
and the proof depended on having all the
weights starting at zero and no
deterministic algorithm could break
symmetry and so Rommel heart being quite
smart said yeah but if we start the
round away so we don't have to worry
about that and that that's sort of it
that that's what you have to know when
we do simple demonstrations I typically
put in full connectivity and in the
speech stuff we initially dutiful
conductivity that's just to keep the
MATLAB program soon it turns out you can
use random connectivity well you can be
a bit more principled like and say
actually for some of that vision there's
lots of information that's local in the
image so let's use local connectivity
and let's make the receptive fields get
bigger as you go and that's what Yaya is
I think the first person to use local
connectivity and back propagation and
share the weights between photos so
convolutional nets say that if I
developed a feature detector here I want
the same feature Tector over there
because I believe the knowledge should
be translation invariant so today at
lunch you know gave a fascinating talk
laying out some of those successes of
some of these companies have had and
sketched out a vision where machine
learning systems exceeded human
capabilities and lots of different
domains and leading to a lot of
disruption in the labor market you
expressed the opinion i hope i'm quoting
you correctly that it would be unlikely
for education to be able to keep ahead
of this which was disappointing chat
until i think almost all the economists
this room because that's usually the top
of our list of recommendations is you
know let's invest more in education to
to stay ahead of this what's your view
on that race between education and
technology and our
likelihood of being able to keep ahead
of it with education
I don't want to say that education is
losing because technology is driven by
people who went through the educational
system so you know there wouldn't be
technological progress unless you've had
these people I mean that there is there
different types of technical progress
right starting at the bottom there is a
good product design with essentially
existing technology and and you know
identifying a good market where you can
sell stuff and then you know putting
together there's sort of more or less
existing technology and such a way you
can build it cheaply you know a good
example at the iPhone right there were
smartphones and touch touch phones
before which was the iPhone was just
better put together let me just pause I
think you know it was especially talking
about the people I thought yeah bottom
50% of the income distributions who
aren't okay right I mean what I was
gonna talk about was the the the fact
that you know there is this innovation
by engineers who have very highly varied
degrees of education so them are college
dropouts some of them are these you know
the whole ranch and then there is the
scientific innovation which usually gets
forgotten a little bit because it
happens 10 you know 5 10 or 20 years
earlier which is you know done by you
know people who generally have amputees
and things like that we done the science
but that is the foundation of all this
right now in terms of like are people
gonna be left behind
in the technological revolution I have
this sort of folk economics kind of
picture which you know everybody in the
audience you can tell me I'm is
completely wrong and this is kind of the
picture where this is the set of skills
that are useful at a particular time for
the economy the desired skills that
people should have and then there is the
skill that people actually have and that
trails behind if you are kind of you
know in the trailing in the tail of that
you're out of a job because your skills
basically are not value you know
valuable in the current
now as technology accelerates the the
set of skills that people actually have
trails behind a new part of is that you
can't retrain people faster than a given
ray and so as technology progress is
faster and faster there's me more and
more people trail behind me I'm just
kind of basically expressing what you
know some people call technological
unemployment which is a side effect of
this but so you know are we going to be
able to make all those 50% of people
kind of useful for the economy or come
up with ubi I mean I I'm not you know
yeah I mean Ivan that's a question for
you from me to you yeah while ago there
was a lot of talk and even hype about
the brain start in brain research and of
fitting into your area of research and
the universe speeding up progress
perhaps towards the real AI that we were
talking about but you know none of you
who mentioned a brain research in your
presentations and not throughout the day
we haven't helped of that so what has
happened I mean is there close relation
is the neutral kind of a impact of these
two lines of research or they are going
separate ways there's a lot of interest
in the relationship between back
propagation in the brain in the early
days of back propagation in the 80s
people said there's no way the brain
could do it it's just ridiculous
Francis Crick in particular said they
just wasn't on but now that it works so
well people have got much more
interested in how the brain might be
able to back propagation so evolution
you can figure out how to turn the same
cells into teeth or iBox
if it can do that why can't it figure
out how to do the chain rule I mean it's
crazy if there was so much selective
pressure to implementing the chain rules
surely you would do it and I used to
believe very strongly that the brain
must be doing it somehow recently I've
come to believe that actually the brain
is not doing back propagation and I now
believe that pretty soon we won't be
doing back propagation either because
there's a better algorithm out there
that the brain is using and I'll tell
you about in December
but it's probably not rhythm to it
to estimate gradients in some ways so so
there's something that we didn't talk
about here which is that things like
conditional Nets are actually very much
inspired by biology neural Nets in the
first place are somewhat inspired by
biology but right but there is but there
is something that we must pay attention
to which is that you don't want to be
blinded by the by the biology so if you
talk to a bird biologist and you know
asking about how birds fly they'll go
you know hours on end on on how feathers
are so important and how complicated
they are and how you have to get every
single detail of a feather right if you
want to build a you know a flying
machine which obviously is not true and
the other lying principle of flight is
you know aerodynamics and you know lift
and drag and stability and stuff like
that right which you know you can
understand through engineering
approaches or theoretical approaches but
not by copying biology so there are
people in the field some of them in
Europe that who got lots of money who
believes that somehow by studying all
the details of how the brain works and
building a simulation an accurate
simulation of how the brain works
somehow we figure out how to build
intelligent machines and I don't want to
speak for my colleagues here but I think
it's completely nuts now let me let me
ask a question here does anyone here
know who claim or idea is claim or idea
you have no idea
clÃ©ment Ader okay like a quiz French
here it's some freshmen you don't know
what came over there is yeah right okay
Kumar there is a guy who built a
steam-powered airplane in the 19th
century in 1893 he actually managed to
have it take off by its own its own
power this is 13 years before the Wright
brothers 10 years before the Wright
brothers and
and you know he was a real secretive so
the things so they didn't get the huge
amount of publicity but some but the
thing is that he copied bats so his
airplane was shaped as a bat you know he
hadn't built models he hadn't built
kites and riders like the like the
Wright brothers he just built a airplane
he was a steam engine designer and just
expected it to fly because it was shaped
like a bat and you don't know about him
he's forgotten it
at least outside of France is not
completely forgotten in France because
he actually called is his airplane a
view and that's actually the word used
in French Spanish and Portuguese for an
airplane so he had a heritage but his
engineering heritage was zero because he
got hypnotized by biology without
actually understanding the underlying
principles and so that's what we say we
are not making but other people are
making can I just say a couple of things
for a younger generation when when it
comes down to your science and machine
learning when I was two experiences when
I was in the job market some of the work
that we're doing deep learning is indeed
inspired by neuroscience just just like
Janna mentioned when I was on the job
market I had a picture of the brain the
whole presentation and just kind of
highlighting where where the connections
might be the feedback that I got from
the computer science department
it's basically lose the brain picture
fine so that's the attitude generally
within the machine learning community
the second point that I want to point
out is during my PhD work I think at
some point I remember looking at some
algorithm and I told Jeff isn't that
something you know how the brain could
work Jeff said you know when it comes
from me
it's okay when it comes from you it
looks fishy so so general I do believe
that so in general I think that there
needs to be more connection absolutely
between machine learning and
neuroscience and a lot of what we do is
inspired by how the human brain works
but I guess that connection hasn't been
there yet at least in our community
because machine learning community
itself is a little bit more Statistics
oriented and it's a little bit more you
know optimization statistics probability
rather than making connections to
neuroscience like I don't know what you
guys are feeling but that's generally
how I feel this evolving so I have a
very a question that I ask every single
time I've asked rich the supposed to me
didn't know the answer why Canada sorry
why Canada is the question how did it
come to be that this entire field got
generated strewn between three
universities in Canada and not elsewhere
okay so the frenchman leaving the u.s.
is going to answer the question well
it's because of Jeff because of yahshua
and also because of Richard Sutton who
used to be a colleague at AT&amp;amp;T and you
know sorry about you know Edmonton in
the early 2000s and so there are three
presents these are you know people who
were very influential in the neural net
and at the time this topic was not
particularly it's not particularly
popular you know when so what happened
in 2003 and Jeff might have a different
interpretation of the story but around
2002 2003 I started you know I left
industry and join academia I became a
professor at NYU and you know Jeff had
come back to Canada for he was in
England for a bit and we kind of
deliberately got together and say like
we should you know really try to make
this work like we we know it's a good
idea in the long run we know it's gonna
work eventually let's let's get together
and decide what is the best path for
getting those neural nets to work on
real problems and maybe derive new
algorithms etc and fortunately CFR was
had the foresight of essentially you
know starting this program that you know
Jeff was
managed to convince e4 to start this
program and yes on neural nor
competition at the T perception and that
had an enormous catalytic effect because
because this topic was very unpopular we
had a hard time publishing papers and so
this was really bad for students you
know we couldn't convince them to work
on this we had to let them you know work
on other things that were more popular
for them to get jobs but that created a
community you know we had kind of a safe
space if you want and I hate this term
but we could you know we had two or
three meet for meetings a year we had
summer schools and we started basically
building a community around this idea
that ended up being big enough so that
we would submit a paper to a conference
it would be reviewed by other people
from the same community and this is how
community started you know this is a
natural process and around 2006 with the
effect of paper that Russ and Jeff
published in was that science or nature
science and a couple of the things that
all the papers that can I had some some
importance people started paying
attention so in 2007 we proposed to have
to hold a workshop that nips the big
Michigan in conference on the crowning
and it was already the case that the
committee was gonna go in and our
workshop was was denied you know people
told us no you can't have a workshop on
this you know this is I mean they didn't
tell us why but basically they thought
it was a stupid topic and so is we went
to see far me.we tells you Whittle
Safari would you fund a pirate workshop
aside for nibs we could just buzz people
and you know from the conference to the
ski resort and we take it on Thursday
afternoon we could have our pirate
workshop and we can get c5 to pay for
buses to leave at the end of the parrot
workshop and make him free and so what
happened is people bought it some places
to go in the afternoon and then they
figured all they could say 30 bucks if
they came to our workshop and went on
the free sea purpose
please and we have by far the biggest
attendance of any watch for the workshop
resistor night it was a sound you say
yeah I think the whole conference that's
something like 600 or 700 attendant and
the workshop that 300 so I was a half
the conference take for the workshop
basically and and then and then it took
her from there so you know we started
having kind of entire sessions that were
devoted to the topic and then and then
you know around 2012-2013 speech
recognition and computer vision
community basically just completely
flipped to come you know taking this
over let me say one more thing because I
don't think people quite understand how
around 2005 that kind of time this field
was regarded as complete rubbish and so
quite a long time after that
yoshua bengio submitted a paper to I see
them out sometime maybe 2008 two
thousand a month he's he submits a paper
twice a amount and one of the referees
that gets rejected one of the referees
says um this paper um should be reject
you because neural networks have no
place in the machine learning conference
it wasn't just that it was they thought
was about making thought your networks
is known to be rubbish it shouldn't be
we shouldn't even refereed in fact one
of the journals had a policy and I'm
told that if they go to your level
object but they just wouldn't review
let's just send it back so this really
was about there's complete nonsense
sorry I just wanted to see if there was
a way to reconcile or understand that
two views that came out of the
conference one from a lot of the
economists recent patients that it's
very important to understand why
algorithms work or what goes into them
and we think that there we you know
there's the argument that when systems
change there's the Lucas critique and
it's very important to understand what's
going on and then a theme from the
discussion tonight is that it's less
important to understand what goes into
the algorithm is is it just that we're
different types of prediction problems
that kind of a theory might be more
useful for economics problems but a lot
not for facial recognition or perhaps
we're just misinformed or so I think if
you're if the process you're trying to
model is simple and now if you can use
simple enough models that will be easily
understandable whose function would be
easily understandable but as you get to
things like you know image recognition
and driving cars and stuff like that the
complexity of the decisions that are
made and the perception system or search
that you know you're not going to
produce completely detailed explanation
but of course it's very easy to analyze
the system you know you can figure out
exactly the effect of every single
variable every single way to every
single input you can do sensitivity
analysis one of the examples I showed
now I would actually I'm not
particularly happy about the use of the
word algorithms the machine learning
system versus train is not an algorithm
the algorithm itself you know is one
page of code the to run a neural net the
code to simply simple code to another a
neural network it's basically one page
of code in whatever language you have
the algorithm itself is very simple it's
you know multiple nested loops that do
multiple multiplications addition and
comparison that's all there is that's
you know doesn't even qualify as an
algorithm in in computer science what
makes the complexity of the function is
the value of all those weights and the
result of learning so you're not we're
not talking about nagas rhythm we're
talking about the training system that's
that can I just say couple of couple
things with money to your question I
think it many times it depends what your
goal is I can give you an example for
example I know that in banking industry
when you buy for long yeah a number of
banks I actually use a very simple model
exactly using something like linear
regression models and the reason why
because they have to explain to the
customers that you know you own is
denied because this variable is below
this particular threshold and this
variable is above a particular special
your depth to something ratio is 0.5
that's why we deny in the law whereas if
you look at something like fraud
prediction you don't really care about
that much about the explain ability you
really care about
cases because you really want to catch
you know like two versus that one error
and I agree with you having many of the
systems like perception system visual
systems state-of-the-art models are
based on these deep neural networks it's
very hard to come up with alternative
algorithms that you can easily explain
what's going on and and just basically
say well the reason why I'm detecting
this car is because you have these wills
will have something precise explanation
even though just like you know saying
you can do sensitivity analysis supposed
to figure out what what it is but
nonetheless in many cases it's just
there is no other alternative that's why
a lot of big companies are spending you
know designing new chips designing new
hardware as well as designing you know
watch scale training of these complex
systems because there is nothing better
that exists out there okay thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>