<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Energy Strategies to Decrease CO2 Emissions - John Platt's NIPS2017 Keynote | Coder Coacher - Coaching Coders</title><meta content="Energy Strategies to Decrease CO2 Emissions - John Platt's NIPS2017 Keynote - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Energy Strategies to Decrease CO2 Emissions - John Platt's NIPS2017 Keynote</b></h2><h5 class="post__date">2017-12-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/nLcmzr4u_sA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well I want to thank the organizers for
inviting me this is quite a delight
I love nips and I'd like to tell you
about some of the work I've been doing
in the last couple years being
colleagues about how to power the next
100 years of human civilization so let
me start by telling you the world I'd
like to live in I would like to live in
a world where everyone on earth can use
as much energy as I do as a u.s.
resident and why do I want that
well because it's relatively evident
that a high level of energy use is a
necessary condition for a high standard
of living and I'd love to have everyone
on the planet to have a high standard of
living now is this an unreasonable goal
is this something that would never
happen well let's look at the historical
graph of how much power is consumed by
all of humankind here it is over the
last 50 years y-axis is in a log scale
and it's in units of terawatts or
trillions of watts and if you look at
this it's a log linear scale and so it's
rough line and power consumption has
been increasing by about 2.2 percent per
year if you extrapolate that for the
next 100 years you'll see right now
we're using about 18 terra watts of
power and by 2100 we if we keep going at
this rate we'll use about 113 terra
watts of power which in fact is very
close to the u.s. power rate for eleven
point two billion people which will
Hoover the expected population in 2100
so my goal that I'd like to reach it's
it would just be an extrapolation of
priam past energy growth now it's very
easy to have a graph with 18 terra watts
and 113 terra watts but it's you really
have to viscerally understand how much
energy that is it's a tremendous amount
of energy here's a picture of Mount st.
Helens up near where I live in Seattle
it erupted in 1980 and spread ash and
blood flows every which way and so it
released a lot of energy human
civilization right now uses one Mount
st. Helens amount of energy every 93
minutes that's all of us collectively
and by 2100 that's going to speed up to
one Mount st. Helens every 15 minutes so
you know we're this is a very very
challenging problem how to deliver this
much energy to the people on the planet
now of course power is a flow rate it's
an instantaneous rate so energy is the
integral of the power so how much power
do we need well we're gonna need
something about a yachtie Joule I don't
know if you know what Yatta it's beyond
EXA and Zetas we need we're gonna need
about point two yata joules or 0.2 times
10 to the 24th joules over the next 100
years that's a lot of energy a yachtie
Joule is a lot of joules point to yata
joules is enough energy to boil off the
Great Lakes three point four times over
and in fact according to my calculations
0.2 yana joules is about five times the
amount of energy consumed by humans
since the beginning of civilization so
we're gonna need a lot of energy in the
next 100 years where is this going to
come from
well one natural question to ask is you
know we have a lot of energy
technologies on the planet today will
they be able to cover this point to yata
joules can we use fossil fuels they're
pretty abundant can we do that or if we
don't to use fossil fuels how about low
carbon technologies or zero carbon
technology as well will those be able to
generate point two yata joules well
let's consider these in turn so the
unfortunate thing about fossil fuels is
they don't scale it's not that they're
not abundant they're extremely abundant
for example humankind extracts one cubic
mile of oil out of the ground every year
but unfortunately when you burn car when
you burn fossil fuels you
generate carbon dioxide and you place it
into the atmosphere and the best climate
models that we have say that there's a
severely limited amount of carbon
dioxide that we can put into the
atmosphere without warming things up so
here's a chart or a table of how much
fossil fuel energy we can use after
today and the corresponding rise in
global mean temperature over 1850 and
there's general consensus there's a the
Paris treaty yet that we want to keep
the global mean temperature no higher
than two Celsius above 1850 which is at
the end of the Little Ice Age and that
unfortunately means we can only supply 8
percent of the next 100 years
consumption with fossil fuels that's it
then we read in we run out of budget and
even if you decide to be even more
dangerous and go to three Celsius it
doesn't doesn't actually make that much
of a difference we have to use some zero
carbon solution okay what about zero
carbon technologies there's a number of
them that exist solar power is getting
increasingly common people extract a lot
of power from wind there's other other
technologies you may not have heard of
there's a series of advanced fission
technologies in the lower-left graph
that's an example of something called a
molten salt reactor or you can take
electric plants that generate that are
that are used fuel that are fossil fuels
and then just capture the carbon you can
scrub the carbon out of there flus just
like the carbon dioxide out of their
flue is just like you scrub sulfur
sulfur dioxide or nitrogen oxides so
will any of these be able to cover 0.2
yata joules so here's here's the thing
all those technologies I mentioned all
those zero carbon sources they're all
they all generate electricity not fuel
and it turns out electricity generation
is limited by its economics so let me
give you a brief tutorial about how the
economics of electricity works a very
brief tutorial it's a very deep subject
but just enough to sort of give you a
sense of what the limits are of zero
carbon energy so let's say your your
utility and you want to build an
electrical plant your costs are gonna be
one of two styles on the left their
capacity costs those are costs you would
incur even generated no electricity you
have to build your plant and you have to
incur fixed costs you have to hire
people to work at your plant even if you
generated no electricity so the units of
that kind of capacity cost are dollars
per peak power and they're linear in the
peak power so if you built a one
gigawatt plant it would cost about twice
as much if you wanted to build a to
gigawatt plant now let's say you wanted
to start generating electricity then you
start incurring output costs so if you
have to burn fuel to make electricity
that's a linear amount of fuel for your
electricity and often maintenance is
proportional to the amount of
electricity that you generate so again
the units of that are dollars per unit
energy out of now I'll show you a i'll
rheic splain this using a tool I call a
power profile so in a power profile that
shows you a time series of the output of
all the plants of a certain type but
let's say this is all the natural gas
plants in California that are connected
to share a grid so on the x-axis is time
here it's just spanning a week and the
y-axis its power output and you see
these typically have diurnal cycles they
go up and down every day now that green
line is the capacity you can't generate
more electricity than the capacity of
the plant and the capacity cost is
proportional to that how high that green
line is or the peak the output cost is
proportional to the area that blue the
integrated area under the curve and so
you get these two different costs one
that's proportional to the peak and the
other one is proportional to the area
and a very useful numbered think about
is something called the utilization or
sometimes called the capacity factor and
that is the total energy produced as the
area under the blue
/ the maximum energy you put have
possibly produced which essentially the
area under the green line and that
utilization is how you reconcile the
capacity cost the output costs because
they have different units so you do is
if you take the capacity cost you're
good you're going to amortize it over
each unit of output and so you have to
divide by the utilization and when you
sum that with the output cost you get
essentially a system cost per unit
energy so so the reason why I'm telling
you this is I'm going to try to explain
to you how electricity gets expensive
and when renewable energy gets expensive
so let me tell you two ways that
electricity can be expensive to generate
you can take the same electrical plant
here let's say you have one plant that
operates at 60 gigawatts and if you
operate it mostly at capacity its
inexpensive because you amortize your
capital across many many joules of
output on the on the right hand side
let's say you only run your your plant
occasionally in fact there are such
plants they're called peaker plants they
only turn on when you have a peak in
your demand then each Joule of
electricity is much more expensive
because your amortize that the cost of
your capital across many fewer joules
the other way of making electricity more
expensive is to waste the output of your
plant so this is listen to this in the
context of solar power which is
something called a variable power source
in a variable source you don't get to
choose when to turn your your energy on
and off so for example you don't get you
don't get solar power at night sorry
so let's consider solar power on the
Left there's a new curve which is the
red curve which is the demand that is
imposed by people so people are
consuming power and again in the middle
of the day they consume more and in the
middle of the night they consume less in
this case you the utility can choose to
have the capacity of theirs
their farms be about the same as the
daily demand and that's good and you
have inexpensive solar generation
because all of them solar tools are
being used the trouble is there's a gap
between the solar generation and the
demands you have to fill then with
something else like fossil fuel so
that's not so good so you might want to
decrease the amount of carbon in your
grid by increasing the amount of solar
so we do on the right is you would
triple the capacity of the solar and
that's great for that's great for cloudy
days like here at our sixty you've
tripled the number of output joules but
on the sunny days you actually haven't
tripled the number of output joules
you've just wasted it this is called
curtailment and this is a way of
actually making a solar power more
expensive if you force it to be on when
the joules are needed so it turns out
I've given you analysis I've shown you a
couple of graphs where the utilization
of the electricity was done in isolation
but that's not right really utilization
is a system property you have to
estimate it for the entire grid you have
to estimate it for all technologies
together not just one technology in
isolation so here's an example you have
a green source let's say it's renewables
it's some sort of variable source and
you have a blue source which is called
dispatchable you get to turn it on and
off like you who as you wish and that
might be natural gas electricity or
hydropower so the the lesson here is as
you increase the amount of variable
generation you get lower utilization and
therefore you increase the cost of your
electricity so here's here's two
examples on the left the variable source
in green is low and so the the peak
required for the blue energy is that the
height of that yellow arrow and the
utilization of the blue energy is quite
high you can see that it the blue energy
is mostly odd now if you want to
increase the amount of variable
generation you have
for example to decrease the carbon you
end up not decreasing the capacity of
blue very much at all but you end up
decreasing its utilization so
essentially by changing the amount of
green energy you have you're actually
affecting the economics of the blue
energy that's why you have to take an
end-to-end view when you analyze the
cost of electricity so you can do that
there has been a number of papers in the
field of modeling and n system costs we
have a paper to the way those kind of
end-to-end models work is you can model
a grid for every hour of year and that
is just a big linear program it's not
surprising it's a linear program because
all of these costs are linear in these
quantities like the peak or the the sum
and an extra thing we added in our paper
was what if what if you wanted renewable
energy to be sixty percent or 80 percent
well you can add a cutting plane
algorithm to force the system to find
the minimum cost given that you need
eighty percent renewable say so you can
see our paper look for the keyword dose
CO or if you curious
we have a live two lon github called
energy strategies that you can play with
if you want to try different what-ifs
try different policies or costs so I
welcome you to try that out and learn
more so let me tell you about one result
we've got from do you you're running
this model so first I have to tell you
the assumptions from the model so these
are plausible assumptions from of what
the future might be like so solar power
is decreasing in capital costs so let's
assume that it's going to be about sixty
percent of today's cost the cost of
storing electricity in giant batteries
of some sort have is going way down so
let's assume it's going to go down by a
factor of three we'll also assume that
natural gases is pretty inexpensive
internet in the United States it's one
of the cheapest natural gas on the
planet so let's assume it's good to go
up a little bit twenty percent and then
we're also gonna model
having high-voltage power lines that
will ship renewable energy across the
country from places with a lot of wind
to a little bit of wind and then we're
going to ask the model to compute what
the marginal system cost for renewables
in California but when you force them to
have a fixed fraction and you can import
any renewable energy and from other
regions so here's the bottom line the
x-axis is the fraction of renewables
that's you enforce it in some way they
may have some policy and the y-axis is
that system cost the remember the sum
between the capacity and the output
costs so there's a few lines here to
take note of the the solid black line is
the cost of electricity from a new
natural gas plant that's the cheapest
plant it's about four cents a kilowatt
hour and you have to and that four cents
counts paying off the capital cost and
also paying for the fuel if you already
have a paid off
natural gas plant then the price drops
to about two cents so you don't have to
you don't have to advertise the capital
cost the blue and green lines reflect
the marginal cost for adding the next
kilowatt hour of renewables at that
fraction blue is without storage and
green is with storage and you can see up
to about Oh 40 percent renewables
actually beat new natural gas for
electricity that's that's great in fact
we're seeing that people are
preferentially building renewable power
plants because renewables aren't very
common but as you start to approach a
hundred percent renewables the costs
explodes and that's because of those two
effects that I told you about that they
caused the other variable the other
dispatchable power to be more expensive
and you have to start curtailing you
have to start wasting renewable power
many people hoped that storage
inexpensive storage would solve this
problem and make renewables gray and
they helped they add like five ten
percent to the to the fraction of
renewables if you stay at the same cost
but they don't solve the problem so
this is a bit disappointing but here's
the bottom line
it's just repeating what I just said
that they are competitive up to about
40% but you can't expect renewables to
compete with paid off fossil fuel
they're not below that black dash line
and there's another factor where there's
something called industrial heat where
steel plants and concrete plants just
burn fossil fuel just for the heat not
going through electricity that's also
about that same cost as that dashed line
and again renewables can't displace that
so we can't rely on renewables to supply
all at the point to the auto joules we
can rely on its or support to supply
some of it so what are we gonna do we're
gonna need to change the game you're
gonna need to do something kind of crazy
so let's talk about radical research
into zero carbon energy so now we're
gonna have to look at less certain or
technically risky energy sources and so
we've been looking at ones that are
enabled by new ideas or technologies
that were that weren't around 20 or 30
years ago and what we're doing is we're
hoping to accelerate this radical
research with all the advances we've had
in computer science recently so to put
it in context I lead a group as Sammy
mentioned called
Applied Science at Google and that's
more general than energy what we do in
Applied Sciences we try to attack
various high impact scientific problems
in biology or physics and we work with
domain experts in university industry we
find the people who have some new idea
and then we take our expertise and
large-scale computation or machine
learning and go and help them on their
scientific problem so energy is one
example of this so we've been looking at
energy looking for four different places
to help and we found one interesting
place to help and that's in fusion
energy so let me now tell you a little
bit about how fusion energy works and
why I'm hopeful about fusion energy and
also I can get into the nitty-gritty
detail of of how we're using machine
learning to help Fusion which might make
you happy since this
learning comforts okay so let me tell
you about fusion fusion is why the Sun
shines so that's promising so if the Sun
is hot enough where it's not made out of
atoms it's made of plasma where the it's
so hot that the electrons separate from
the nuclei and if the Sun's core it's
very intense
it's got a temperature of about 15
million Kelvin and as if pressure about
250 billion atmospheres and under these
conditions the nuclei actually fuse
together they smash into each other and
they form they form and they split into
different nuclei and those output nuclei
have less mass than the input nuclei and
because of Einstein's equals MC squared
you get energy out you get a lot of
energy out in fact this is incredibly
energy dense so this point to yata
joules we need for the next hundred
years if you if you could have used
deuterium that only requires 100
thousand metric tons of deuterium which
can be found in six cubic kilometers of
water that's for a hundred years that's
really very feasible or if you if this
proton boron reaction turns out to be
feasible you only require 3.3 million
metric tons of boron that sounds like a
lot but it's only seven months of world
production of boron so this Fusion has
the potential of being an inexhaustible
energy source so here's the problem no
one knows how to make it work it's been
pursued by 70 for 70 years and it's a
very very very difficult engineering
problem right because creating
conditions like at the center of the Sun
is incredibly tough here's a picture I
found from 1951 of some physicists
making a plan ring a plasma and on the
right hand side you can see it starts to
get kinks because plasma likes to go
unstable it's very difficult to make a
stable shape of plasma
another problem that happens with plasma
is you get heat loss because remember
we're trying to make these objects that
have tens of millions of degrees
temperature and it's
easy for the heat to just leak away and
and a system to cool off
so despite literally decades of research
no one has ever gotten more energy out
of a plasma than if used to maintain a
plasma condition now there are many
approaches to fusion we're working on
one of them but just to review them
briefly there's sort of tokamaks these
have to do with like the shape of the
plasma that's the common one that's used
for example in the European eat herb
project us other people are thinking
about inertial confinement where they're
actually take a little pallet of
deuterium and shoot laser beams at it
and compress until you get their fusion
conditions on the lower left there's a
set of plasmas called compact alright so
I'll talk about that more in a minute
and interestingly I don't know if we've
heard of this there's something called
the Farnsworth fuse or it was actually
invented by the 60s in the 60s by the
same person who'd been in the television
set and you can actually do fusion on
your desktop but you are forever doomed
to never get any more energy out than
you get in so what are we doing well
we're not fusion experts so we've teamed
up with a company that are a bunch of
fusion experts if company is called t-ae
and they've been around for almost 20
years and they have specialized in this
specific plasma architecture called an
FRC a field reverse configuration and
they've been doing progressively larger
higher energy experiments into the FRC
there's a diagram of one of their
machines on the right and so we're
working with them to help apply computer
science to see if we can accelerate
their progress here's a picture of their
latest apparatus from end-on it's
actually quite a long apparatus it's
more than 20 meters long this is the end
the the apprentice apparatus it's named
Norman because it's named after a Norman
Ross talker who is a plasma physicist
and one of the cofounders of ta so why
why did we choose TA e well they have
two really nice properties one is they
have speaking as a statistician or
learning person they have they can they
can do rapid experimentation in the last
20 years they've built five machines and
they've accumulated 70,000 experiments
they can actually do an experiment by
once every 10 minutes
in fact on that Normand machine I showed
you they've done about 3000 experiments
since July so it's a nice way to gather
a lot of data into a lot of exploration
the other reason why we like working
with tae is the data they've gathered so
far suggests that good scaling law so
let me tell you what I mean by a scaling
law I'll describe it but in summary it's
how difficult is it to get energy out of
fusion you can actually write down very
simple formulas that try to predict that
so let's get into that here's it's
always nice to be in a field where you
have a metric and there's a metric
confusion because a success and it's
called Q it's very simple it's the ratio
of the energy out that you get from
Fusion divided by the energy in the
energy you require to maintain those
plasma conditions and everyone is
chasing after something called breakeven
or scientific breakeven and that's when
Q is greater than one that will be a
quite an accomplishment the highest Q so
far was done by the jet tokamak very
briefly it attained Q equals 0.67 back
in 1997
now remember way back to the beginning
the talk we want to compete vs. fossil
fuels so it's not enough to just get one
extra Joule of energy out after spending
a billion dollars so you really need to
get a lot of energy out you have to get
a Q of five or even higher because the
higher the Q is essentially for the same
capital cost you get more watts or
reciprocally you have less capital cost
per watt so remember the capacity cost
goes down and that means the system cost
goes down which means maybe we can
compete with fossil fuels so the hope is
that that that this FRC will give you
very high Q now what's the criteria for
Q equals one it turns out that the
fusion
the plasma physicists worked this out
back in the 50s and 60s there's a
another criteria called the triple
product which is predicting when fusion
can predict net energy and that is a
product of the density of the of the
plasma which is the number of nuclei per
unit volume times the temperature of the
nuclei times something called the
confinement time the confinement time in
the units time it's the amount of energy
that's in the plasma divided by how
quickly it lose your heat and depend
depending on what your your fuel cycle
you have there's some constant you have
to be bigger than and so if the product
of those three numbers is bigger than
some constant you should be able to get
Q equals one so now this is where the
scaling all comes in because these three
numbers aren't independent in fact it's
not surprising that because one taw is a
heat loss and T is a temperature they're
related so you need to have plasma
that's both stable enough another it has
to be long enough it has to be hot
enough and then you can actually get a
net energy out and it turns out there's
two different kinds of scaling loss if
the if the world is friendly to you you
get the green scaling law where they're
positively correlated where as you make
the temperature as you make the plasma
hotter you make it more stable otherwise
if you're in an unpleasant world as you
you have to trade off temperature
and heat loss so since you're trying to
make the product both of those be high
that's kind of unpleasant as you make
your thing as you make your plasma
hotter you lose on on time or vice versa
so it this is a very unpleasant place to
be in preliminary data from tae shows
that this FRC plasma has this surprising
scaling law where the the confinement
time actually goes up quadratically with
the electron temperature that's that is
counter intuitive it says that the
higher your temperature is the lower the
heat loss rate and it's a strange
property of your plasma
it's it's it's sort of like saying that
you have a bathtub and the more water
you put into the bathtub the less water
comes out the drain but it's a property
of the specific architecture the frc if
you go back and look at the same scaling
law for tokamaks you do get your back
into whack Amole in other words you have
to trade off temperature and confinement
which is again a really tough problem
this is why tokamak engineering is not
at all easy so we're collaborating with
te and may have two main goals the first
goal is we're helping them with computer
science to try to verify that scaling
law remember that they've only verified
it up to about a million Kelvin we
really need to verify it up to tens of
millions of Kelvin so about 1/2 to kill
electron volts and then once we verify
that scaling law we really want to
estimate that Q for the commercial
reactor in other words we're trying to
estimate is this actually going to be
able to displace fossil fuels or not so
that's the collaboration and that's a
little tutorial about fusion now you may
be wondering well a Kentucky machine
learning help well there's two different
projects we're working with tae-won is
essentially optimization but it's really
about exploration and the other one is
about inference so let me go through
both of those projects so the first
project is a little bit like hyper
parameter tuning but not it that this
Norman here's a picture of the Norma
Knepper at is it has thousands of
parameters and they're not well
characterized because the way Norman
works is you first inject gas at the two
ends and then you ionize the gas to make
a plasma and then you you accelerate the
two plasmas from both ends and you have
to choose how quickly those accelerates
so there's a bunch of magnets that are
accelerating the plasma and once the two
plasmas collide you have to maintain
that plasma in the center with a choice
of magnetic fields and electric fields
and on top of that you're shooting that
plasma with neutral beams or neutral
beams of hydrogen and you have to set
the parameters of those neutral beams so
I mentioned it was like type of
parameter shooting but it really isn't
and I think actually what I'm about to
describe is that
more general infusion I keep running
into this you don't really have a known
space not like you have an icebox that
you can draw samples from the physicists
say let's start here where the green
star is and you just don't know you'd
know would that there's you know certain
things because they built the machines
so there are certain parameters sayings
you just don't want to use you know you
don't want to overload the power
supplies or the capacitors so don't go
there don't go past the where the red
hyperplane is but there are other
settings that you can set the machine to
be that actually purge the machine so
you have this beautiful machine and you
run an experiment and a bright flash
goes off I've seen this and then the
physicists looked very worried and they
run out and they examine the machine and
they might have to spend hours or days
or you know in very worst case weeks
repairing the damage listed by doing a
bad experiment so we want to be very
careful about setting parameters that
but we don't want to break their machine
so really this is not an optimization
problem this is an exploration problem
we're trying to figure out what's the
shape of the polytope that that is sort
of safe to do experimentation and it's
not completely hopeless because it's as
you get close to the edge that you can
tell the physicists in the room get
nervous so they will tell you when
you're getting close to the edge they
just don't quite know where the edge is
so in fact we came up with something
called the optometrist algorithm which
is essentially a Markov chain where
DeCarlo but with human preference on the
inputs let me give you a little
animation of how it works they start
someplace and then you add a bit of
noise with some parameter setting so you
set all the parameters you add a little
bit of noise and the physicist said that
was great never do that again so you
walk back and you do another
perturbation and that's better it's more
interesting and it might be there might
be an objective metric or there might be
just subjectively the physicists like
that more so you perturb that again oh
that's not as interesting you go back
and you that's even better so what
you're doing is you're sort of climbing
a hill of human preferences with the
physicists in the loop in the
in the control-room sighting and how to
set the parameters and this seems to
find both interesting regimes that were
unexpected and avoids unsafe areas so in
fact we did this on the previous machine
to Norman and we found this unexpected
rising temperature regime that the TA
physicists didn't expect at all they
didn't expect their ion temperatures to
actually grow to be one kill electron
volt and they were actually very happy
because that gave them confidence in
actually building Norman which is now
built so we published that that's the
first machine learning project the
second one has to do with inference and
it turns out that when you're trying to
do this experimental plasma physics you
spend a lot of time debugging your
plasma here's an image of your FRC
plasma and ideally it's perfectly stable
in the center but sometimes things go
wrong the plasma tilts or wobbles around
or there's some pathway that lets the
plasma cool off or it might bounce and
touch the walls and the physicists want
to know why did that happen
well it turns out they're not just doing
things totally blind there's many
sensors or what they call Diagnostics
available you can measure the magnetic
fields it's impossible by the way to
touch the plasma because it's millions
of degrees Kelvin but you can do all
these indirect measurements you can
actually use high-speed video cameras
which have very wide field of view but
they are very narrow spectral band or
there's these things called bolometer
z-- which can look at a very small field
of view but integrate across all of the
spectrum there's even a property called
Thompson scattering you can shoot a
laser beam into the plasma and estimate
its electron temperature along one line
so these are very sparse informative but
very sparse both in time and space
sensors and so of course we decided to
do a Bayesian inversion where we're
trying to infer the hidden state of the
plasma which consists of where it is
what's its shape what's its temperature
and what density does it have again
going back to that triple product and
the way this works it's it's what you
might expect from
Asian setup we we have a 3d
probabilistic model of plasma or two and
a half D if we're trying to make it be
faster and we have a generative model
based on the actual this the physics of
the sensors we have a generative model
of the sensor data we compare what the
with the generative model is predicting
to the actual sensor data and we use
that as a feedback loop to update the
probabilistic model but of course that's
sparse data we can't we're not doing
maximum likelihood estimation so we use
a prior over the plasma state that
involves physics knowledge so example we
enforced smoothness along magnetic flux
lines and the way that works is we do a
relatively large scale stochastic
variational inference so we assume a
functional forum over the posterior so
you may be familiar with this from
racial inference we maximize the elbow
the lower bound of the evidence and we
use stochastic gradient descent and the
nice thing of we use is tensor flow
tensor flow is a nice way to parallelize
gradient descent so we map this Bayesian
inference to ten GPUs and essentially do
variational inference and the automatic
differentiation part of tensor flow is
very handy because we have to take
derivatives through this this physics
code the nice thing about Bayesian
inference is you can get error bars
which is helpful to tell the physicists
like whether your you actually know
what's going on in the plasma or if
you're just positive or if the algorithm
itself is puzzled but with variational
inference that doesn't give you a good
error bar so we calibrate it using
simulated plasma the nice thing is we
can get a solution in less than five
minutes so we're actually keeping up
with the pace of experiments that the TA
is running here are just some
preliminary results given two cameras
and all the magnetic sensors we can
reconstruct the emissivity of another
how in 3d how much the plasma is glowing
and what the magnetic field is in inside
the chamber and this is ongoing work
we're going to place this plasma divide
bugger
inside of their their their experimental
loop so looking forward to this
collaboration next year I called the
year of science because going back to
the scaling law we're gonna try to do
everything we can to maximize that
electron temperature and we're gonna try
to verify the scaling laws up to high
temperature where we're getting close to
actual fusion temperatures and the
outcome will be a precise estimate of Q
at commercial-scale
then after that T he will build yet
another machine that will if all goes
well will actually demonstrate breakeven
fusion so that's exciting and that
engineering will also help us get more
precise costs about what fusion how much
fusion power will be so I worked on this
project so it was really fun are there
other projects like this well it's
tricky right you want to salt you want
to work in a problem that has a lot of
real-world impact you don't want to just
solve point oh oh one percent of the
climate problem so you want to find a
problem that can somehow displace or
negate say 10% of the fossil fuel usage
but we're also machine learning and
computation and statistics people so we
want problems that have a large number
experiments it turns out it's kind of
hard to find projects in this
intersection but when you find them
they're really interesting so I guess in
conclusion just go back we're gonna have
to figure out how to get point to yata
jewels of zero carbon energy somehow one
there may be possible any possible
pathways one that we've identified is
fusion energy and we have combined
fusion energy with machine learning and
hopefully will have a large impact in
the world we were not done yet but we
have hope and the question I want to
leave to the audience is where else can
ml help there might be other pathways to
get to the point to yata joules so
that's my talk
thanks John for this great talk and a
bit scary as well we have a plenty of
time for questions so there are mics in
all the ales please come to the mic and
ask all the questions you would like to
hey couple questions first just you
talked about fusion what about fission
oh you can't hear me yeah but I actually
I have another question I'm a little bit
more interested in this is just a basic
question about the mechanics of fusion
so as you as the fusion is taking place
the original molecules or would it be
molecules that you had are being
replaced by these other molecules right
that's how the energy is produced so do
you need to like add more of the
original mixture of molecules that
that's right there's something in fusion
the question was do you have to keep
feeding fuel in well it's slow because
it's so high energy density but it does
have accumulate something called ash
that's what they call it I mean it's
like a wood fire except it's fusion and
so you do have to occasionally restart
the reactor and have more I mean it
depends on the fuel right deuterium
tritium is complicated I can tell you
off line but but you do have to it's not
it's not a it's not a professional
motion machine you do have to you know
keep heating fuel and and you asked
about fission or just do you think that
has a role to play as well just because
you didn't mention it at all in the
original talk said oh yeah sorry if I
had a limited amount of so I keep going
I can go on for this up for hours
advanced efficient the future cost of
advanced fission is very uncertain the
most optimistic estimates say that it
could displace solar to renewables new
plants but not old plants so part of the
reason why I didn't bring it up is I've
been scratching my head there doesn't
seem to be a very good large experiment
thing to
hi there so it just wasn't you know
there just wasn't anything I could try
but it does have a future in the it does
have a future and as part of that point
to yata Jules
if it becomes cheap enough I thanks so
much for a great talk I was wondering
about the renewable energy the graph
where you showed that the cost of
increasing renewables in actually
increases the cost of per unit of energy
produced only because of the mainly
because of the variability of renewable
energy and so I was wondering if you
think it's realistic to target the
variability of renewable energy and if
that would give like similar gains to
any other pros proposed solution yes you
exactly identify the problem it's the
variability if you could figure out how
to get renewable energy that was what
they call base load which is 24/7 that
would solve the problem in fact that
model that's part of the reason why I
mentioned the hv deceive hv is for high
voltage DC lines across because if you
import wind energy from the Midwest to
California it actually balances it's
sort of a the noise balances out and
their variance reduces so that actually
does help and you definitely need to do
cross-continental
wind importation above about 50% wind
but it's just hard to get it to be a
perfect flat but if you could somehow
come up with renewables that was base
load
problem solved what about geothermal
okay so the question was what about
geothermal so I wish okay two thermals
great but it's only cost-effective in
what they call hydrothermal areas so in
other it's areas which are very that
already have a lot of water passing
through them there's something called
dry rock geothermal where you actually
inject water down and there's been some
work on it the trouble is the the
economics just don't work out there it
just will it'll be roughly as expensive
as
today's nuclear power which is very
uncompetitive because you're right I
mean there's there could be a vast
amount of geothermal if you can do
trouble
it all boils down to five kilometer
wells which get you down to 300 Celsius
cost a lot of money and it just isn't it
just doesn't compete economically it's
just a shame so you're limited to the
amount of geothermal you get enough
hydro thermal hi uh I'm gonna define
this Michelle and my question is what
are the thoughts on distributed energy
generation and distributed grids and a
lot of people see it has a big potential
opportunity for machine learning and
deep learning to optimize grids
the question was about distributed
energy I had to cut that for my talk for
time that might raise okay
there's good and bad things that might
raise the amount of renewables because
the cost point is not the cost of the
natural gas it's the cost that you pay
the utility which residentially might be
11 cents a kilowatt hour or if your
industrial at 7 sets the the downside is
is that you can't average if you're just
hoarding the electricity by yourself if
you're not part of a grid you have to
you have to make your own capacity that
covers your own piece now there have
been proposals in fact back in 2014
there was a invited yeah 2014 there was
an invited talk by Arun Majumdar about
bottom-up grid where he was talking
about that but but it when it does it
might be able to increase the renewables
above 40% but then you actually have
this thing called it's like adverse
selection where as more and more people
detach from the grid the grid the grid
becomes more and more expensive and that
means more people will detach from the
grid so it's I don't know how it's going
to end up but it is possible it might go
above 40%
if distributed things like distributed
PV become common just a quick follow-up
question you see there's an opportunity
for machine learning
to optimize peak loads for disparate
groups of if the question is is there
machine learning maybe there might be if
you're trying to predict I mean if you
for distri you might be trying to
predict how to charge and discharge your
own battery maybe I don't know thank you
we have to go on to the next event and
let's thank John once again if you have
if you have additional questions come up
now now I'd like to invite everybody to
the Pacific</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>