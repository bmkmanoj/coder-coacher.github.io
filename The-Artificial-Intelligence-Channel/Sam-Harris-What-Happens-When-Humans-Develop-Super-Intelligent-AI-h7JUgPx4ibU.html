<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sam Harris: What Happens When Humans Develop Super Intelligent AI? | Coder Coacher - Coaching Coders</title><meta content="Sam Harris: What Happens When Humans Develop Super Intelligent AI? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sam Harris: What Happens When Humans Develop Super Intelligent AI?</b></h2><h5 class="post__date">2017-09-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/h7JUgPx4ibU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">on a show today future consequences how
our decisions about science and
technology today will impact our future
tomorrow and in a lot of ways one aspect
of the future has already been imagined
for us three billion human lives ended
on August 29th 1997 I mean this has been
part of our culture for decades the
survivors of the nuclear fire called the
war
Judgment Day they lived only to face a
new nightmare the war against the
machines okay so you might recognize
this scene it's Sarah Connor in
Terminator 2 describing how artificial
intelligence sparked a nuclear attack
and then waged war against the surviving
humans which is something that should
terrify all of us right yeah and what
especially worries me about artificial
intelligence is that I'm freaked out by
my inability to marshal the appropriate
emotional response which should be what
oh I think potentially it's it's the
most worrisome future possible because
we're talking about the most powerful
possible technology this is Sam Harris I
am a writer and podcaster and
neuroscientist and also armchair
philosopher and Sam says our inability
to react to this future with urgency
poses a big problem the quote from
Stuart Russell the computer scientist at
Berkeley is imagine we received a
communication from an alien civilization
which said people of Earth we will
arrive on your planet in 50 years get
ready right now just seven but just
imagine that now that is the
circumstance we are in fundamentally
we're talking about seeming
inevitability that we will produce
superhuman intelligence intelligence
which once it becomes superhuman then it
becomes the engine of its own
improvements then there's a really kind
of just
a runaway effect where we can't even
imagine how much better it could be than
we are Sam picks up this idea from the
Ted stage at a certain point we will
build machines that are smarter than we
are
and once we have machines that are
smarter than we are they will begin to
improve themselves and then we risk with
the mathematician and I J good called an
intelligence explosion that the process
could get away from us now this is often
caricatured as a fear that armies of
malicious robots will attack us but that
isn't the most likely scenario a it's
not that our machines will become
spontaneously malevolent Dickason
concern is really that we will build
machines that are so much more competent
than we are that the slightest
divergence between their goals in our
own could destroy us just think about
how we relate to ants okay we don't hate
them
we don't go out of our way to harm them
in fact sometimes we take pains not to
harm them we just we step over them on
the sidewalk but whenever their presence
seriously conflicts with one of our
goals we annihilate them without a qualm
the concern is that we will one day
build machines that could treat us with
similar disregard it's crucial realize
that the rate of progress doesn't matter
if any progress is enough to get us into
the end zone we don't need Moore's law
to continue we don't we don't need
exponential progress we just need to
keep going so we will do this if we can
the train is already out of the station
and there's no brake to full
you believe that that it is inevitable
that at some point we humans will create
the technology to more or less replicate
humans yeah I think that the moment you
recognize that intelligence is
platform-independent
then you just have to give up this idea
that there's any barrier to machines
becoming superhuman and when they do
become superhuman in their abilities to
design experiments to engineer new
machines then they will be the best at
doing that but we're not there right I
mean I mean at this point there are a
lot of things as humans do that machines
and robots just can't do yeah I think
this notion of a goal of human level
intelligence is quite misleading we're
living with what's called narrow AI
which is super human in its area of
application but is not at all general
and therefore isn't nearly as good as
the human mind is nowaday are you the
best chess player in the world as a
computer and now the best goal player in
the world as a computer the best facial
recognition system is a computer and yet
none of these systems is good at
anything else really so I think the goal
is to have general intelligence which
allows for kind of flexible learning
across many different tasks and in many
different environments but once we have
something that's truly generalizable and
seamless it won't be human level it will
become super human and it won't be human
level unless we consciously degrade its
its capacity to be human level and we
would never do that right right because
that's just not a normal human response
because when most people hear about AI
or talking about it it's with this
incredible optimism I mean this
technology will enable us to do things
we can do we're gonna be able to crunch
numbers and in ways that we can't right
now and solve diseases through data and
machines are gonna be able to do tasks
and do them much
so I mean there is a sense of wonder
about the future of artificial
intelligence yeah I think that's
appropriate because intelligence is our
most important resource and we want more
of it just think about it in terms of
every problem you see in the world has
some intelligent solution if a solution
is compatible with the laws of physics
right and so it's just we want to figure
out the solutions and we want to improve
human life but yeah we are racing toward
something we don't understand and the
scary thing is that many people thinking
about the potential upside here don't
seem to aware of the ways in which we go
wrong and in fact are just deny that
there's really anything worth thinking
about here imagine we just built a super
intelligent AI right that was no smarter
than your average team of researchers at
Stanford or MIT well electronic circuits
function about a million times faster
than biochemical ones okay so this
machine should think about a million
times faster than the minds that built
it so you said it running for a week and
it will perform 20,000 years of human
level intellectual work week after week
after week how could we even understand
much less constrain in mind making this
sort of progress the other thing that's
worrying frankly is that imagine the
best-case scenario so imagine we we hit
upon a design of super intelligent AI
that has no safety concerns we have the
perfect design the first time around
it's as though we've been handed an
Oracle that behaves exactly as intended
well this machine would be the perfect
labor-saving device it can design the
machine that can build the machine that
can do any physical work powered by
sunlight more or less for the cost of
raw materials okay so we're talking
about the end of human drudgery we're
also talking about the end of most
intellectual work
and what with the Russians or the
Chinese do if they heard that some
company in Silicon Valley was about to
deploy a super intelligent AI this
machine would be capable of waging war
right we're at weather terrestrial or
cyber with unprecedented power this is a
winner-take-all scenario is it to be six
months ahead of the competition here is
to be 500,000 years ahead
at a minimum okay so it seems that even
mere rumors of this kind of breakthrough
could cause our species to go berserk I
mean it seems like one big consequence
of not taking this seriously you know is
that we will essentially be giving up
control over our own destiny as a
species
yeah well potentially and that is so
that you know obviously there are the
people who say well we would never do
that we would never give up control
right right but there's just no
guarantee of that but particularly when
you imagine the power that awaits anyone
you know any government any research
team any individual ultimately who
creates a system that is superhuman in
its abilities and general in its
abilities well then no one can really
compete with you in anything it's it's
really hard to picture what the the
intellectual and and scientific
inequality that suddenly could open up I
mean based on on you know the the pace
of this technology I mean how much
longer will humans be the sort of the
dominant species on planet earth well
you know III really I have no idea I
just think that the pace of change
suggests that the next 50 years could
represent an astonishing epoch of change
just look at the pace of change in our
own lives in the last 20 years you know
most of us have have only been on the
internet for about 20 years 20 years ago
you had people saying the Internet is
going to be a bust right I mean
there's no there's no there-there right
no one's gonna you hate this thing
right yes look at the world we're in now
and this is a comparatively old kind of
breakthrough and we're not nothing of
the last twenty years has been
transformed fundamentally by artificial
intelligence so I think the next fifty
years could change everything
now unfortunately don't have a solution
to this problem
far from recommending that more of us
think about it I think we need something
like a Manhattan Project on the topic of
artificial intelligence not to build it
because I think will inevitably do that
but to understand how to avoid an arms
race and to build it in a way that is
aligned with our interests when you're
talking about super intelligent AI that
can make changes to itself it seems that
we only have one chance to get the
initial conditions right and even then
we will need to absorb the economic and
political consequences of getting them
right but the moment we admit that
information processing is the source of
intelligence that some appropriate
computational system is what the basis
of intelligence is and we admit that we
will improve these systems continuously
then we have to admit that we're in the
process of building some sort of God now
would be a good time to make sure it's a
god we can live with thank you very much
righter neuro scientist and philosopher
sam harris he's also the host of the
podcast waking up with sam harris you
should definitely check that out and you
can watch all of Sam's talks at ted.com</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>