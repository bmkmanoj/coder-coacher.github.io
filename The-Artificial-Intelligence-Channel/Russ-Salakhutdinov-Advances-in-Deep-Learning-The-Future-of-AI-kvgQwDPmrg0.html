<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Russ Salakhutdinov - Advances in Deep Learning &amp; The Future of AI | Coder Coacher - Coaching Coders</title><meta content="Russ Salakhutdinov - Advances in Deep Learning &amp; The Future of AI - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Russ Salakhutdinov - Advances in Deep Learning &amp; The Future of AI</b></h2><h5 class="post__date">2017-12-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kvgQwDPmrg0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">rustle hakuna tov was a professor u of t
was part of the creative destruction lab
and is now a professor at carnegie
mellon university absolute leader in the
field of artificial intelligence he has
this small side gig where he runs AI for
Apple that also he has that small side
gig and Steve Laura from the New York
Times up here today
take it away gentleman Russ is here to
basically sort of set the scientific
table for the day and he's got a
presentation and it's it's that he's
going to show how it actually works
including some videos I gather so this
is this is you know where the technology
the progress it has been has made what's
its trajectory and what are the
challenges so with in less than 20
minutes rest take it away yes I'll try
to be I'll try to be very quick to keep
us on time thanks thanks by the way to
AJ and organizing what I'd like to do is
I'd like to tell you a little bit about
some of the recent advances and some of
the key challenges so the impact of
deployment has been quite tremendous and
that's came as a surprise to a lot of us
as well working in that area speech
recognition computer vision recommender
systems language understanding is
something else say a few words about
drug discovery medical image analysis
and health is something that's going to
be transformed in the near future some
of the key challenges that a lot of us
and scientific communities are working
on as this three bullet points that I
wish I'm listing here one is reasoning
attention and memory how can we develop
systems that can reason not just do
pattern recognition which is what's
happening a lot today language
understanding is another big area and
I'm gonna show you some examples of that
reinforcement learning as well as
unsupervised learning one-shot learning
and transfer law there's a few concepts
that I'll try to elaborate just a little
bit on let me show you a couple of
examples this is sort of a success story
these systems were developed in the last
couple of years so I give you an image
and what I'd like to do is I'd like to
build an AI system that can generate a
caption and if you look at these
captions these are pretty remarkable
right and that is too many of us in the
vision field that's a holy grail of
computer vision getting a system that
can tell a story about the image not
just say there's a dog in the
was a captain the image but then you
know you also get these examples just to
show you I particular like the second
one so you can see it says the
handlebars are trying to ride a bike
rack now why am i showing it to you
actually to us it was very exciting and
the reason why is because that means
that these systems are able to generate
something that that's different from
what humans are generating even though
it doesn't make much sense and sometimes
you get these kinds of examples and the
reason for that is again it's a cool
problem in machine learning in general
is that if I show you the the systems
were not trained on on images of sports
but that's that's what you get let me
show you one other example is this
notion of building systems that can
reason imagine I'll show you this this
particular document this is coming from
CNN news story about the rest of the
Illinois government Rob Blagojevich
there was this scandalous story about
corruption charges of rope Liguori
trying to sell Obama's sanity imagine I
give you a query of the form president
like Barack Obama said on Tuesday he was
not aware of Irish corruption by acts
and so forth and the question is who is
X and people can solve these problems
very easily right in the right answer is
Rob Blagojevich because that requires
you to go through the whole document and
try to understand what what are we
talking about and what's the question is
asking and what we've seen in the last
couple of years is evolution of these
very complex systems these are multi
layer system they have something that's
called recurrent networks deep networks
and and so you can see that people are
trying to come up with a more and more
sophisticated systems that can actually
try to reason and not just do pattern
recognition and in particular what's
interesting about those systems is that
in this particular case the mall is able
to figure out that alleged corruption
and Senate seat are the two key
components that I need to pick up from
the document in order to be able to
answer the question this is not provided
by humans that's a system learning on
its own
what is it important that I need to pick
up in order to be able to answer that
question
the last thing just couple of minutes
I'd like to show you a couple of
examples of this idea of reinforcement
learning or learning behaviors
I get an observation and I try to get an
action and we've seen a lot of success
stories alpha girl for example is one
success a story of these kinds of
systems what's one of the things one of
the big innovations in the last couple
of years that came out in our field is
this notion of learning memory or trying
to equip our AI with with memory
mechanisms so that we can store
important information we can retrieve
important information this beautiful
work that was done by unexpected mind
let me just show you one particular
example of why this is a hard problem
imagine that I give you a very simple
random maze and and the rules of the
games are if I see the indicate is
something that I'll call an indicator if
Vindicator is blue I have to find a
green block if they indicate is pink I
have to find the right block now this is
a very simple problem but it turns out
to be very difficult for machines
because I have to remember the state of
the indicator and to navigate in this
random environment to figure out what
the right target is so here's an example
of what these systems can do the
indicator is is blue so the system goes
to the wrong target it remembers that
it's the wrong target and backtracks and
tries to find the correct target and
there's a memory mechanisms that the
model is learning what to write in the
memory how to read from the memory so
that in this random environment it can
actually you know find find the right
target and ultimately we want to be able
to build systems systems that have this
external memory mechanism systems that
have knowledge base systems that can
reason and communicate and remember
information to store so that you can you
know act optimally in the future one
last thing I wanted to show you is this
example that was done at seeing you on
trying to learn to execute instructions
so here I'm showing you a system that
says you know go to the go to the red
pillar and they and the agent has to
figure out what does it mean the rat
killer or go to the short torch it has
to understand what's the meaning of the
word short without us specifying what
there is
and as the system learns in this virtual
environment eventually it starts
figuring out things like what's the
meaning of the word tallest but what's
the meaning of the word shortest or
what's the meaning of the word red or
Red Bull and any such so these are
little baby steps but at the same time
you know so here goes to the largest
option for example these are baby steps
are nothing about 72 hours of training
you can handle occlusions you can figure
out you know how you should be acting in
the environment they can really ground
some of these some of these concepts one
final piece that I want to say is one of
the big challenges for a lot of what
we're trying to do is how can we develop
systems that can learn from pure
examples or they can learn from few
experiences right now when we train
these systems in virtual environments we
can simulate millions of environment
billions of environments alright so how
can we actually do it in the real world
it still is a very open question and
it's you know I see a lot of research
done done in that space thank you thanks
Russ but there's been a lot of attention
recently the last few weeks to alphago
zero which is for those of you don't
know about it it's the the deep mind
program deep mind which is acquired by
Google that has actually that came up
with the original alphago project which
which beat the best go player human go
players in the world but alphago was
able to do the else equal zero is able
to do this apparently you know truck you
know showing you a lot of games a lot of
tagged information and this is the sort
of this unsupervised learning that
people talk about are sort of teams but
it's in a very it's you know still in a
mathematically bounded world it is not
learning as in the field people talk
about learning as you know a child
learns to walk you know or the classic
examples uses of it and show you a video
there's the water glass at the edge of
the picnic table what happens next well
humans know that it's likely to follow
the water spills it's hard for computers
I mean put that alphago zero achievement
in perspective yes I think that it's
it's it's a really good achievement I
was
you impressed with what they were able
to do one remarkable thing about alphago
zero is that it can learn to play goal
just from doing self play so there is no
human sort of involved right you just
just creating self place to be the agent
place against against itself many many
times and you can basically surpass
human level performance which i think
was was was a really impressive
achievement one thing that I'd like to
point out is that in the game of go here
you basically have a fully but what
sometimes people go fool observed
environment right you can see the state
of the entire game and so this is that
this makes the problem a little bit
easier there's a lot of work now
happening in the space of how can we
build these kinds of environments but
unfortunately observable environments
where you don't actually get to see the
entire state much like what you've seen
in you know examples like doing for
example when you try to navigate you
don't really know where your opponents
are you don't really have the full full
information but this idea of self plates
it's it's an old one
I see rich Sutton in sort of pioneered
some of some of that words it's it's
it's been around for a long time but at
the same time I think it's a very very
impressive achievement I know that
there's also was wonderful boss done by
open the eye on the game of data which
is a sports game and they were able to
show that also by doing self play you
can achieve very impressive results so I
think that's that's to me it's it's a
really good advance going forward at the
same time it comes back to one of the
points that I was mentioning is that
when we working in a simulation world is
we can simulate the board game we can
simulate the video games and and what's
happening really is that you you
building billions of simulations so you
try to analyze as much responsible and
in one key question again remains how do
you take that and put it in in some
real-world application so that's that
still is an open question thanks Pam how
do you play AJ's timed game the
obligatory timed game that we've
that is the theme of the conference yeah
obviously a turns to trade here you
can't talk about anything you're doing
at Apple but you you know what we have
seen is these real advances in
capabilities image recognition speech
recognition you know language
translation for example and people then
build businesses on those capabilities
and those capabilities have really
improved you know in the last five years
certainly but more so than people
thought right speak to capabilities I
mean what what kinds of capabilities you
know do you see happening first take the
next two years then five and you know
not predictions but what's your best bet
about what would be be able to do and
then maybe a hint of what we're not able
to do yeah so I think that in the next
couple of years it's it's very hard to
predict because you know sometimes you
have these really great advances that
are coming you know alpha alpha girl for
example Iphicles zero that nobody nobody
expected I think that in the next couple
of years we'll see more and more work
done in the space of language
understanding or building dialogue based
systems building stronger and more
intelligent personal assistants being
able to build systems again that can
perhaps answer more complex questions
will be able to maintain a dialogue so
that's something that I think is going
to be happening in the next in the next
couple of years can I just interject on
that one just a little bit on the agents
you know Larry Smarr of UC supercomputer
heads for the United States figures I
talked about you know where are we going
for the movie and Scarlett Johansson and
2025 it said um I think most what are
our are you and that has this whole
human emotion thing which Danny Kahneman
can speak freely about because he
doesn't know how hard it is to do right
yeah um but you know it what I we're
likely to see verticals in other words
vertical in in specific domains whether
it's you know it's a conversational
chatbot for legal or
some of what in in these next couple
years what do you as it's a it's an
interesting question i it's it's hard to
speculate but i think that what we will
start seeing is is we're gonna start
seeing this these verticals in the space
one one example could be a medical
domain right where i'm talking to what a
personalized doctor another domain that
i think we'll see some examples in the
next couple of years is is you know you
go to and are some technical questions
like you know my TV doesn't work what do
i do or in the case of you know you try
to compile some code and you can't and
you're trying to ask somebody how do i
compile the code and you're gonna have a
bot an agent that looks at i don't know
you're going to manual and answers you
how how could proceed so i think that in
these very specific perhaps technical
domains we're gonna start seeing more
and more these dialogue based deaths
dialogue based agents that my prediction
is that within the next couple of years
we'll start seeing automation in that
space and as well as for big IT
companies a lot of work on on you know
getting helping and ordering things and
such and some genuine flexibility yes
you know today's chat bots are kinda
voice recognition on on top of faq yeah
they'll be the last questions that's
right oh all like templates a lot of it
right now stand plates right like i'm
asking you know how do i buy this
product and then there's a template well
you go to this website and so and so
forth the question is can we build
systems that can actually you know look
more like humans and and then be able to
kind of communicate with you i also
think that in the next few years we're
also gonna see some strong applications
of reinforcement learning i can't
predict when they gonna be a client in
the real world but i think we're gonna
see in terms of algorithmic developments
we're gonna see more and more evening
developments in the reinforcement just
because there's so much interest and so
many groups are looking at at that very
important problem and that might be able
to let us do what well anytime you have
a system that takes a perception which
is the world around you and this
you know where the chairs are where the
tables are indexed in action so you can
navigate in the environment that's where
we will see some advances of course it's
probably a little bit longer than a few
years but this is this is the hope makes
your building autonomous autonomous
systems that can perceive understand
surroundings and then execute taking
action and executing this partially
observe and certain environments what
last question and then we'll conform to
time if not better here again you can't
talk about anything you're doing at
Apple but one of my questions when you
joined with why Apple I mean it's you
know somebody with your set of skills
it's pretty much pick of the litter and
you could have gone anywhere right and
you're gonna retain an academic mooring
at Carnegie Mellon which you've done and
you know you joined a place that was
famous for being closed not publishing
papers you know not yeah not opening up
to the world and this is you know this
is in the academic world this is how
innovation progresses and so what you
know obviously there was a lord it
wasn't you know it wasn't money you know
I mean you know you coulda gotten it
anywhere right what are the you know
what makes Apple an interesting place to
work other than you know building on you
know Tom Gruber's work at Siri or
something but you know what what was the
nexus that really got you right right
well that's a that's a very good
question you see how I asked that
question so one thing maybe I can just
say a few things one thing that really
drew me to to Apple is the fact that
it's a very dynamic place and there are
a lot of smart people once you actually
get to talk to those folks and then the
other thing that really attracted me to
Apple are the problems that they're
trying to solve so the problems that
they're trying to solve i extremely
difficult problem they're very
challenging from technical standpoint
and from a research standpoint the fact
that machine learning is being used
pretty much everywhere at Apple across
all different products but again the
technical difficulty on the problems
that we're working on I think it's it's
it's will advance
you know the the field of AI I so that's
you know a few things that drew me there
but but but really the other thing that
I think is important is that what we're
working on there will end up in in the
products and will be shipped and will
impact you know millions of hundreds of
millions of users and that's something
that I think is unique to a company like
Apple one final thing I wanted to just
say is I was extremely impressed when I
was talking to some of the senior
executives at Apple you know we had a
conversation and imagine you and I we
have a conversation and these are very
senior folks within the company and and
one of them started asking me about LS
DMS how many of you know what is it an
STM a few of that a few of you it's like
a recurrent neural network it's a
driving force behind a lot of models or
sequential decision making imagine this
executive is digging into details of
these very specific models and asking
specific mathematical details I was
really really impressed and it's exactly
the person is he or she's still there
yes yes yes so that's that that really
is that really is kind of you know I was
I was very impressed intense and again
just to summarize I think that really
what drew me there is is the complexity
of problems that they're trying to solve
I mean they try to do something really
amazing and that's that's what really
and and is a matter of fact I'm myself
and learning is learning a lot about
these kinds of problems and and and how
we can actually build something that
works in academia you know we publish
the papers we say well here's
seventy-seven percent accuracy we're
bidding everybody at a company you
actually have to deliver something
that's you know 99.999% accuracy right
and that's that's very different which
is which Tamizh is super super exciting
good problem as they say in computing
thanks for us appreciate you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>