<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Prof. Roman Yampolskiy - Superintelligence is Coming | Coder Coacher - Coaching Coders</title><meta content="Prof. Roman Yampolskiy - Superintelligence is Coming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Prof. Roman Yampolskiy - Superintelligence is Coming</b></h2><h5 class="post__date">2017-09-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/y4zIMBnYleo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome back everybody I hope you all
enjoyed the poster sessions I see some
very active discussions were happening
people almost forgot to eat lunch we are
back with the second half of this
retreat where our first talk is going to
be by dr. rouhani on Polaski he is an
RIT alum so I am very happy to introduce
him today he is an associate professor
in the Department of Computer
Engineering and computer science at the
speed School of Engineering University
of Louisville and he is also the
founding director of the cybersecurity
lab there his main areas of interest are
in AI safety and cybersecurity and he
has authored artificial
superintelligence
a futuristic approach so that should
give you an insight of what the talk is
going to be about dr. M Polaski has been
recognized as distinguished teaching
professor professor of the year faculty
favorites leading in engineer leader in
engineering education and outstanding
early career in education award and he
was I was just asking him when did you
actually graduate from RIT and it was
only in 2004 so that isn't quite a bit
of accomplishment in a short period of
time and he is also an author of over
100 publications including multiple
journal articles and books his research
has been profiled in popular magazines
such as New Scientist Science Vol
magazine and hundreds of websites and he
was also giving TV shows and part of
radio shows today he will be presenting
to us on the future of artificial
intelligence dr. young
thank you so much you can hear me now
this is awesome mics didn't work out for
me thank you for inviting me back it's a
great honor being an RIT graduate I'm
happy you're not embarrassed of me this
is this is a good sign so very special I
learned a lot from RIT and hopefully I
can bring some knowledge back and share
with you
I'll start my presentation the same way
I always do I tell my students I have a
lot of interesting information to share
for free with you so if you like you can
follow me on Twitter you can follow me
on Facebook but you cannot follow me
home it's very important so make sure
that's the case
funny thing so there is 250 registered
for this maybe one will actually do it
so lately I've been doing this mixed
model where I go today we're trying
reverse psychology you are not allowed
to follow me and that produces better
results so whatever works for you do
that I love that I'm following lunch I'm
not competing with hungry hungry people
this is great also we have some amazing
speakers in the morning who did a
marvelous job of building up my case
it's very hard to convince people to
care about super intelligent machines if
they don't think we're going to get them
but the first two speakers just amazing
my first couple slides have all covered
I'll start by saying something not very
controversial I'll say that artificial
intelligence as we always defined it in
the field is here we have machines
capable of driving us around
transcribing speech doing some very
interesting things which for many years
were considered to be
hear me now just as well
freedom all right can you see the
pictures the lighting here is for
security purposes impossible to see from
the window IBM Watson and such can we
all agree we have artificial
intelligence as we did research on it
for the last decade or so I say another
statement maybe a little more
controversial robots are here we don't
have them in this room but we know how
to make them how to build them some
places have more than than ours bodies
say easy next and I mentioned that we
know how to make robot bodies so the
interesting questions are what's next
what's happening afterwards ok so this
is not honey this is better sweet so I'm
gonna claim that next step is super
intelligence which means intelligence
more capable than any human being in any
domain why do I say that
there is a number of factors which kind
of come together and make me conclude
that first of all levels of funding we
seem to have billion-dollar projects
from governments from industry all
pouring money into inverse engineering
the brain understanding how intelligence
works we have the most intelligent most
interesting people working on this
problem whatever is google deepmind
facebook research in AI really top
researchers are all devoted to that
problem there are now conferences on
this topic books coming out so it's not
completely insane to think we might
succeed at some point how soon is a
completely different question I don't
usually make predictions about timing
but it seems like it's going to happen
at some point I'm still gonna tell you
soon
but just to make it interesting Ray
Kurzweil who's director of engineering
at Google is famous for making those
beautiful exponential curves predicting
what's going to happen and how soon he
basically takes computational capacity
we have at the point and maps it against
things like mouse brain human brain and
so on so looking at history
addictions and I guess you can see any
other tax we're looking at something
like twenty twenty three twenty forty
five in terms of getting to human level
computational capacity now that doesn't
guarantee that we have algorithms
capable of supporting that performance
but it's a good sign that at least we
are not limited by the brain capacity of
those machines I'm not gonna say too
much about power of supercomputers
quantum computers how they work because
again we have those amazing speakers who
assured us we're gonna have quantum
computing very soon so computational
capacity is not going to be a problem
all I want to point out is where we are
today in our place in terms of
performance so we are at that stage
where human performance dominates
computer performance and most domains
but that's changing more and more for
different narrow domains things like
chess go poker every week we hear about
something no longer being human sebastio
machines are becoming first as good as
humans and very quickly way better that
time where we are the same as almost
another second so I'll cover different
properties of vers machines super
intelligent machines which make me very
much interested in researching the more
at this early stage so obviously by
definition we're super smart
you all seen jeopardy you know about
recent success with poker yes you heard
humans are no longer the best at playing
poker ah robust spoke about specifically
game of go moves 78 and 37 I'm not going
to go into details of the game covering
that but something I want to point out
so move 78 was it was great comeback for
Humanity supposedly if you look at move
37 later on it spells out the humans at
the end that's that's what happens there
but what I'm trying to say is last month
I had a chance to speak to creators of
alphago and the system is still training
it's still
it's still playing against itself it's
getting better every day it defeated 50
top players last month in this game
there are no humans who are competitive
against it today and never will be again
Lisa doll can practice because I'm sure
the best goal player but he will never
be twice as good as he is today
alphago will be it is important to
understand that again that point where
computers caught up to us and stay at a
human level
it's a tiniest of points as soon as we
learn how to get to human level we go
beyond that that move 78 that one game
humanity one lost that was exactly that
not a second record it was awesome and
we can learn a lot from machines to
improve our game to become better but we
are no longer competitive in that domain
what are the features which make
computers so dominant well speed of
course we know about standard speed
computers the faster we do millions of
operations per second but think about
their impact in the world
they are super fast they're capable of
ultra fast extreme events you can crash
stock market and bring it back and you
won't even notice it happened trillions
of dollars of wealth disappear show up
again you won't even know what's
happening complexity of machines we are
at the point where we could no longer
take control back
no human can control modern systems
responsible for let's say nuclear power
plants they're just too complex so there
is no undo button in the sense of let's
let's see what we can do with just
humans in charge this is what I refer to
the super controlling properties of
those machines a lot of times we talk
about well it might be dangerous to put
machines in charge if you give them
control in the future they might do
things to us we gave him control years
ago they're controlling on every aspect
of our life stock market is like 85%
automated trading it's happening
power grids our plants military all it
is control my software now depending on
your definition survey I am super
intelligence we can argue about how
intelligent that software is but the
point is the amount of control is only
increasing and because of complexity we
cannot undo it as a cyber security
researcher I have a lot of interest in
understanding how AI and security
interact if you look at trends in
computer viruses in terms of increase in
number of computers impacted amount of
damage cost we see sort of exponential
curve already but what happens then will
have human level intelligence paired up
with viruses the weakest point is every
security expert knows is the human
social engineering attacks pretty much
any attack becomes possible with that
combination and of course we all know
that the biggest founder of my research
is the military they have some good
projects rescue robotics but we also
very much of interest in creating killer
robots soldier robots automated drones
so those are all different properties of
this technology which make me somewhat
concerned about I'm not gonna tell you
that there is no amazing benefit to
begin from AI it would be wrong
release and we can't even understand
just how much good can be done with this
technology for science for health for
economy we have free labor physical
cognitive we can pretty much do anything
we we can dream about
in fact some things is so outside of our
understanding there will be good things
we can't even know unknown unknowns
that's pretty much the last positive
slide I'm gonna have because everyone
else will always tell you about all the
awesome benefits of AI it seems to be
somewhat biased coverage I want to make
you at least think about water other
alternatives same technology but what if
it's used in a different way
so negative impacts again say economy
same exact thing free labor
what happens to all the people who lose
their
and I mean all the people I don't mean
just the guy giving you a ticket in the
parking what happens in terms of
politics that might be an improvement I
need to update our slide small sub slide
I'm concerned about is they are known
unknowns a system which is smarter than
me can come up with really big problems
they didn't even consider so that's why
I'm very concerned I'm not alone for a
long time I was alone and nobody really
cared about what I had to say until
those famous people said the same thing
and now everyone invites me to give
keynote it's nice some of them are not
experts in AI research but they are
scientists intrapreneurs politicians and
they all had expressed at least some
level of concern in terms of what really
advanced artificial intelligence can
bring us people like Elon Musk are
concerned enough to actually start
funding research so I got some of that
sweet Elon Musk money for that but more
and more we're starting to see ours get
involved in this research and I talked
about how much exponential growth we saw
in the research in this area recently so
what of slides so okay so what makes it
a problem like why is this something to
worry about I'll give a few examples and
I'll leave time for questions to really
bring it home but let's look around us
so you guys did a great job with
diversity you have a really diverse
crowd here different cultures religions
genders you name it but if you think
about our brains how they are made
designed the values we have we're all
part of this tiny little blue dot right
here that's the universe of possible
Minds things which can optimization
powers you can have optimization powers
over certain problems and there are
preferences there are values don't have
to have anything to do with us
whatsoever so that's a really
mind-blowing statement right like you
always think that
everyone would want a big house in a
boat like and I would so go for that but
reality is no it's not the case at all
and if we don't specifically control for
what values we instill in those systems
and just randomly do it or involve them
to succeed at any cost
no end up somewhere else in that space
and that space most of the time is not
compatible with human flourishing so I
call it a singularity paradox problem
you have super intelligent systems
they're capable of optimizing for
solutions in all domains but they have
no common sense things the five-year-old
would know they don't know them and that
creates really significant problems I
can give you countless examples of very
trivial situations where a machine would
get it horribly wrong and I'll talk
about how a eyes fail closer to the end
so what do I do in my research hey I'm
trying to understand what the problem
domain is it helps to figure out how the
eyes can fail us what is the pathway to
a dangerous machine a lot of people talk
about kind of standard engineering
problems we fail to design machine
properly we fail to implement the design
properly maybe the data was biased so
all those are significant issues no
doubt about it a lot of them are
unsolved lately I become more and more
concerned with a problem I call
malevolent design of purposeful
malevolence and that's basically a
situation where you have bad actors
using good software on purpose so we
heard max give example of drone
collision avoidance software which with
the flip of a sign became drone
destruction and military happiness
software that's just one example you buy
software out of a box but what you do
with it is up to you and you're all very
ethical researchers nice people but
there are crazy people out there are we
having it's me it's not
thank you so we actually have a workshop
coming up at Oxford on bad actors in AI
and I'm not talking about Schwarzenegger
like what are the possible types of
people who can misuse this technology
and the scary thing is the answer seems
to be everyone even if you don't know
how to program if you get kind of access
to a nice GUI you can do a lot of damage
with technology we have today as
technology improves this situation only
gets worse you have insider threat you
have all sorts of problems with it and
almost no one is looking at actually
addressing this problem so recently to
my delight some people started working
on this problem publishing books many of
you probably seen Bostrom's book
superintelligence there are other books
and superintelligence I highly recommend
the good news is it's no longer just a
positive work like Kurzweil would always
talk about infinite life spans free
money and all but people actually start
to consider well you have a system
smarter than us with no controls is that
smart the response in the last two three
years was truly amazing
it went from ok few people with blogs
doing science fiction - now centers with
multi-million dollar budgets going up at
all the top universities Oxford
Cambridge Berkeley MIT University of
Louisville they all now have people
working on this problem you may be heard
there was a conference in Asilomar
earlier this year brought about a
hundred people top AI researchers all
interested in addressing this problem
solving this problem so it is a great
time to to consider this area of
research at the intersection of
cybersecurity and artificial
intelligence - to help people jump into
that area one of the first things I did
with a colleague of mine was to survey
the state of the art in this field so
what have people done what has been
actually considered as a possible
solution for controlling intelligent
machines and
surprisingly a lot we have a paper it's
open access you can get it for free you
don't have to buy my book we surveyed
about 300 different references we try to
be very comprehensive classified and
analyze them the interesting part is
look at the dates so some of the
earliest work we found was from 1863 so
it's been in the back of our minds for a
while but interestingly with a lot of
interest there are still very few actual
solutions so it's not like it's a solved
problem and I want to give you kind of
flavor of what people have proposed in
terms of solutions not necessarily the
best solutions
I cannot survey all 300 of them I have a
few minutes but I'll give you kind of
highlights of the most common most
popular ones and then we can have some
question answers about so one solution
people suggest is do nothing I don't
like the solution for a number of
reasons one it's very hard to get
funding for it
- basically the logic is we're not gonna
succeed at building super intelligent
machines it's never going to happen and
if it happens we're gonna be super nice
to us because smart people are nice I am
not convinced another idea anyone knows
who that is
professor Kaczynski yeah
his publisher emailed me a few weeks ago
he's like do you want to get a copy of
his latest book and I'm like okay I'll
review it sure whatever and the package
comes from Unabomber
I ordered it but do I open it it was
interesting so his idea was a solution I
really don't like it was to kill
computer scientists as a computer
scientist I'm against it people
recommend things like integration with
society
we can tell robots to follow our legal
system because it works so well and
makes perfect sense for machines to be
sent to prison and such so there are
people writing about it but I'm not
convinced as well this is an interesting
one so we talk about competing with
machines but we are not very capable we
don't have perfect memories we're not
super fast what if we can update our
brains if were uploading them to
software somehow or having what Elon
Musk lately been trying to sell is this
neural lace idea human brain interface
which gives you the powers machine has
it makes you more competitive if you get
all the benefits of a human with over
power of the Machine two problems with
that I'm not sure you still become
remain a human if you become a piece of
software
sounds like you become part of a problem
to me and doing that human machine
hybrid it seems like you have a
bottleneck you can tributary little and
you will be removed very soon we'll see
how it goes probably the most famous
solution Three Laws of Robotics how many
of you heard of as Moore's laws that's
the worst solution ever like if you
learn anything from this talk that's not
a solution it's a literary tool
to write really interesting books and
it's designed to fail every single time
there self-contradictory
the ill-defined they just don't work and
increasing the number of laws to ten or
anything like that still doesn't work so
just some of the projects I'm interested
in so this idea of formal verification
we headed for software for a very long
time but there is really no idea how to
do it for intelligent software in novel
domains how do you verify behavior of an
agent independent agent capable of a
agent in a environment you are not
controlling ahead of time so that's one
of the things we're looking at is it
even possible how to do it and there are
some research grants available in this
domain another the kind of subdomain of
solutions I'm looking at is containment
so if you study computer viruses you
would put them in an isolated computer
area but from the internet try to get as
much information as you can from from
that machine see what that that virus
try to analyze it figure out who wrote
it how it works
so we proposed something similar for
intelligent systems so you can study
them safely limit access to data they
can learn from limit output they can use
for social engineering attacks we got
some initial funding for this work so
that's one of the projects I'm working
on right now so I'm getting closer to
kind of a question/answer portion of
this I want to give you a few big level
ideas and they could be controversial or
not one thing I want to say is we are
scientists accepted idea that unethical
research exists some things are just not
a good idea to work on like biological
weapons for example or nuclear weapons
experimenting and humans those seems
those things seem to be outside of what
we as scientists I'm interested in doing
we seen with artificial biology
synthetic biology we put moratoriums on
human cloning for a few years because we
feel like it's a good idea to do that we
just don't know how to say
we create a human clone we don't want to
mess up somebody's life in universities
it's common to employ ethical review
boards especially in medical research to
make sure that whatever it is you're
proposing to do meet some sort of
standards then I propose doing same
thing for AI research it sounded weird
we're just doing software who's gonna
get hurt
since then companies like google
deepmind lucid AI and some others
started a ifx boards i was part of a
committee for major engineering
organization 3-play i and we got just
last month first version of ethical
guidelines for super intelligence
released telling all the engineers in
the world what not to do and what to try
to do so it seems like this general idea
of considering at least that
intelligence can be dangerous and we
need to think twice before just
releasing it or developing it is gaining
ground personally I never want to ban
research that's not a good idea so I'm
trying to understand if we can separate
the two kinds of research narrow AI
research were you working a specific
domain you making great progress but
there is no chance your software will
ever learn anything outside of a domain
if you're doing pattern recognition
addresses and envelopes that's great you
increasing your accuracy it's awesome if
there is a chance that your software is
capable of self improving capable of
writing next level of software capable
of transferring knowledge between
different domains and really has no
limits to where it's going very quickly
maybe you should slow down and ask
yourself do I have a safety mechanism
for this can I control it this is
equivalent to first designing a car
putting it on a highway and as you going
85 going did we make a break for it so
again it's probably hard to see but I
put together a timeline of different AI
failures over the years and you probably
can see details but there is an
exponential pattern to it as we get more
successful at building AI systems
whatever it is they do whatever domain
they work in they fail if it's a go
playing software it will lose a game
it lost the game if it's a self-driving
car it will kill someone will have an
accident you all have out a correct you
know what that does
so the pattern is pretty obvious as we
give more power and more responsibility
to those systems they will fail at a
higher rate and with more damage and
very few people even care about
introducing a safety mechanism in place
so kind of advice for IT in terms of
what you guys can really do to put
yourself as number one in a world take
advantage of your cybersecurity
expertise very few people are doing that
right now it's hard to compete in pure
AI between Google Facebook MIT Carnegie
Mellon there is a lot of players in that
game but there are very few players in
AI safety in the next 5-10 years that's
going to change all those companies are
hiring right now specifically in that
domain i think google deepmind team is
now up to FOIA safety researchers and
they just started this year so if you
want to analyze those specific failures
we can look at the papers talk about
details
I mentioned my book a few times you have
to buy it my publisher is charging way
too much all the papers are available
for free get them on my website Google
Scholar
all works beautifully if you want to buy
it people on Amazon like it it's a great
book
I will leave lots of room for questions
and answers to the best of my ability
thank you for that stimulating talk now
the floor is open for the audience to
ask questions I start by saying read the
survey paper with 300 ideas you're
proposing chaining a eyes it's been
suggested it makes the problem worse you
have multiple levels of control instead
of one level so now you can fail at some
some additional level in communication
so it's unlikely to work if you can
control one AI you're not going to
control multiple the eyes of different
level of capacity did that that's right
good question yeah
just applying an optimal pattern towards
helping problem and the actual
formulation of strategy and tactics to
accomplish a goal and
so your second question sounds like it's
looking at adversarial data that's been
pretty hot area in neural networks we
discovered that we can train an avenue
on network to fool the first one and the
fake images or movies and whatever we
send in look very realistic given to
humans so yeah that's the hardest area
right now like if you're doing
adversarial neural networks you good the
interesting area with those adversarial
the images and such is we are neural
network what is the equivalent for
humans and how you can use them it seems
to be there are some possibilities to
cause epileptic seizures or things of
that nature just by showing you
something yeah your first question I
think was kind of telling between narrow
AI and generally AI and it's not easy to
do because it's just a neural network
quickly becomes a senora Network for
designing neural networks so it's an
open problem I don't have a clear
solution yeah
I don't see employment as an existential
threat it's an inconvenience we can
solve it politically with unconditional
basic income and other welfare like
policies are more concerned about
military militarized AI weaponize the AI
yes sir
so there are no solutions if someone
tells you there is a solution to this
problem they're lying to you no one has
a solution there is a ways to buy us
some more time delay it seems to make
sense to review what you're doing before
you do it and if you did it to be able
to safely experiment on it they will
fail if you read the actual papers and
the I boxing all that it's a guarantee
to fail after amount of time just
because of how capable it is in social
engineering attacks and we've seen
humans design ways to bypass arrogant
computers and it won't be surprising
self-regulation is not a bad thing you
can have external regulation my hope is
that people who are really capable
enough to design an AGI are also smart
enough to realize the issue and self
control based on who's funding those
efforts and coming to those conferences
it seems like top people and like deep
mind I in agreement with that
which is a good sign but they have
conflicts of interest obviously tell me
one time is included look at my yes sir
all right so it's a great question there
is some effort to create FGA for
algorithms examples we saw with biased
algorithms in criminal justice system
and things like that before you deploy
them
somebody has to check that they are not
ridiculously racist government did put
out guidelines for things like
self-driving cars and some startups
actually shut down because we couldn't
meet those requirements I think what
Tesla did they basically said if
somebody dies is gonna cost us 10
million dollars in a lawsuit we're
getting a million miles an hour and data
it's a cheap purchase of data set let's
let's do it objectively that's what they
did Google said no we have to take it
slow and get it right so it seems like
there are different ways to see this
problem and to get there as far as the
International component of it it seems
like there is only a few big players
capable of this type of work I'm not
concerned about like North Korea
developing super intelligence in your
computers for that so you know it could
happen and then we need to figure out
whose values we want the I to have North
Korea ours I think we can continue this
discussion offline because it's a nice
time to segue into the discussion focus
group discussions thank you dr. Ian
Pulaski
actually we have one more thing oh yeah
so do you have your ticket song I have
mine does that mean I can't see yours if
I pick mine
oh my god it's mine I always check the
raffle zero one zero two zero three
well let's see that's not you know it
can be no yes you got lucky minute thank
you okay I probably</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>