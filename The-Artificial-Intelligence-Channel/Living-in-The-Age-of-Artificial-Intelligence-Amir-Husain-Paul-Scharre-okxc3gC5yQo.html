<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Living in The Age of Artificial Intelligence - Amir Husain &amp;  Paul Scharre | Coder Coacher - Coaching Coders</title><meta content="Living in The Age of Artificial Intelligence - Amir Husain &amp;  Paul Scharre - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Living in The Age of Artificial Intelligence - Amir Husain &amp;  Paul Scharre</b></h2><h5 class="post__date">2018-04-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/okxc3gC5yQo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">great well welcome everybody today to
our last panel to finish out the day
here at the Annapolis Book Festival
we'll be talking about living in the age
of artificial intelligence so I'm very
pleased my name is Carol appoint I'm a
senior fellow at Georgetown University
and we have the great pleasure to have
amir hussein and paul shari with us
today so we talking a little bit about
the emerging role of artificial
intelligence in society so amir hossein
is an award-winning serial entrepreneur
and inventor as well as the founder and
CEO of spark cognition he's the author
of the sentient machine the coming age
of artificial intelligence and paul
shari is a senior fellow and director of
the technology and national security
program at the Center for a New American
Security
he's a former Pentagon official and an
Army Ranger who is a veteran with
multiple tours to Iraq and Afghanistan
he's the author of army of none
autonomous weapons and the future of war
so we're gonna start off today by giving
each of the authors here a few minutes
to talk about their book and talk about
their view and how they frame the idea
of artificial intelligence and society
both in terms of civil society and
military so we'll start with Amir well
thank you very much Kara it's absolutely
wonderful to be here in Annapolis it's
actually my first time and it's a
wonderful city as far as the motivation
for the book for the sentient machine
when I wrote the book the concern that I
had was that I couldn't see much in
literature that approached the topic of
artificial intelligence from a truly
philosophical perspective there are of
course many scientific and technological
aspects that one must consider but at
the same time this idea came to me that
artificial intelligence and the advent
of artificial intelligence in fact could
be seen as a mirror unto society many of
the problems many of the exist n tional
concerns that we worry about for example
will these machines with great powers
and great skills will they be able to
undo us will they kill us which is the
Terminator scenario if you know from the
famous Hollywood movie but then beyond
that will these machines that can now
perform all forms of labor almost all
forms of labor that humanity has taken
millennia to master
will this mean that our economy will
crumble and that there won't be any jobs
for us to do and so I realized in many
of these discourses the reaction was
always one of these machines are
deluding us these machines are taking
something fundamental away from us if
you think about over the last many
centuries even the way that we named
ourselves we have last names like Porter
and farmer and goldsmith we are so
invested in the economic Labor's that we
are capable of performing that we
confuse this skill with some intrinsic
value and when we are told that look
beyond the horizon this skill of yours
may not be very valuable that creates
some sort of an inherent angst
so with those questions in mind I set
about looking at the sentient machine in
two ways one very practical really
talking about what artificial
intelligence is doing right now and the
one difference that I may bring to this
this book is that everything I talk
about almost everything I talk about in
the book I'm involved in building that
so spark-ignition is an artificial
intelligence company based in Austin and
almost every collaboration with London
Stock Exchange with the US military with
State Street bank with large hedge funds
with large power generation companies
the largest utilities in America and
Europe all of these things that run
through the various chapters of the book
providing vignettes on what artificial
intelligence can do these are not just
secondhand in my in my case you know we
build them so we have a pretty good idea
of where these things are going and
based on where these things are going
both in the political and military
sphere as well as frankly just as an
existential question I think it will
become impossible for societies
trees polities individuals to do not
understand artificial intelligence and
do not deal with the idea of a synthetic
creation surpassing humanity in many
ways and a synthetic creation doing for
the first time things that we thought
only human beings can do because this
attacks the very root of our ideas of
soul and frees you know free will and so
on and so forth
so these were the two discussions that I
attempted to balance in the book the
very practical what's happening now what
are we building now and then the
philosophical underpinnings and I'll
save the conclusion of the book for
maybe a subsequent subsequent question
but one of the chapters in the book
actually two two chapters really focus
on where artificial intelligence is
being applied to warfare my colleague
general John Allen who's a four-star
retired Marine Corps general him and I
worked over many years and about two
years ago we published a piece in the US
Naval Institute proceedings journal
called on hyper war and from that this
whole idea of what hyper war is and the
modern age came about so that has been
captured in this book as well as much of
what we hear today now about our
election being hacked and Cambridge
analytical and so on so the book also
talks about these threats and also talks
about how we can mitigate these threats
also by using AI so these are just some
of the things I've covered in the book
I'll stop here and maybe give Paul an
opportunity to talk about his book
well thanks Mary you've given us a lot
to delve into but Paul if you can talk
about army of none and on the military
side thanks i'm paul shari offer of army
of none autonomous weapons in the future
of war and and what army of nun digs
into is the the issues that i'm ear
raised kind of at the end about what
artificial intelligence means for a
conflict in warfare that steps entirely
the focus of the book so one of the
world today aware ninety countries
ninety countries have drones including
many non-state groups like the Islamic
state and sixteen countries and this
number keeps going up every month
I already have armed drones so they're
already weaponized and one of the things
we see in science fiction like the new
season of Westworld just just came out
is that a lot of our visions for where
this is going is that we build these
more intelligent machines and then we
have these fears that someday they'll
turn against us what we're seeing in the
real world is actually increasingly
advanced robotic systems are being born
with a gun in their hands we already
have these armed systems and each
generation of them they're becoming
increasingly autonomous much like
automobiles so you get into a
top-of-the-line car today and many of
them have features like automatic
braking self-parking intelligent cruise
control automatic lane-keeping
same thing in military systems each
generation they have more autonomy more
intelligence with the book grapples with
us what happens when a Predator drone
has as much autonomy as a self-driving
car what are we willing to delegate to
these machines we're talking about
life-and-death decisions
so the first half role that digs into
what our military is building around the
globe looks at the United States it's
got interviews with researchers at DARPA
and the Pentagon and the Office of Naval
Research looks at what Russia and China
and Israel other countries are doing and
how some of these systems what you see
both deployed and then in research labs
where they're kind of taking us right up
to this threshold of this ability
technologically to cross this line and
allow machines begin to make their own
targeting decisions on the battlefield
right now humans are still in control of
sort of deciding about who to attack but
a lot of these technologies that are
being innovated would allow someone to
just flip a switch or install a software
upgrade and take the human entirely out
of the loop of this decision-making
process and in the second half of the
book really deals with what is that what
does that mean looking at the law the
law of war and what those criteria are
ethical principles different ethical
argument people have made both for and
against the technology there are I think
our or obvious reasons they come people
don't have to look very hard to imagine
reasons why this
be a bad idea certainly there are plenty
out of science fiction and pop-culture
but there are arguments that people have
made for these kinds of weapons and they
draw upon analogies like looking at
self-driving cars
the idea being well just as automation
in automobiles might reduce accidents
and save lives
could there be ways that machines in
warfare could make better decisions than
humans and could spare civilian lives so
that's one of the things that I crapple
within the book and then I look at
concerns about stability and
interactions between states when you
look at something like stock trading we
actually have a domain now of stock
trading where most of the trades are
done by machines and by BOTS and we've
seen accidents that come from that
things like flash crashes were these
unexpected interactions between
algorithms lead to sort of these is you
know horrifying catastrophes and in
stock trading what they've been able to
do is mitigate these challenges by
installing what they call circuit
breakers they take the stocks offline if
the price changes too quickly and that's
a way to manage the problem it doesn't
stop these problems but it it reduces
them from causing too much trouble but
there's no one to call time out in war
there's no referee and so what happens
if there's a this interaction is
autonomous weapons interact and there's
a flash war how do we deal with that
problem and then the end of the book
deals with the history of regulations in
warfare there's an international effort
underway led by nongovernmental
organizations and in about two dozen
states now calling for an international
treaty to ban these kinds of weapons and
I look back at the history dating back
to ancient India and attempts to ban a
poison and barbed arrows and attempts by
the Pope to ban a crossbow in the Middle
Ages which was not very successful up to
the modern age to try to talk about you
know how can humanity deal with some of
these technologies and other ways to
come together to cooperate to avoid some
of the most harmful outcomes thanks Paul
there's certainly a lot to think about
in there and and you bring up some of
the things that people are definitely
afraid of right and a mirror can turn
to you one of the things you say in your
book is you say that we are starting our
contemplation of AI from a place of
existential fear rather than one of
opportunity right can you tell into a
little bit in terms of what are the real
opportunities that we have in society
with AI sure let me actually start from
the point of fear
there's two very important things to
really think about there one like I said
artificial intelligence for me
personally has been a mirror it's
allowed me to understand myself and
dynamics in human society better than at
least I thought I understood them
previously and you know we're all aware
of cognitive biases that exist in human
brains we think something but the
reality suggests something different we
make mistakes so our brains are also
subject to cognitive bias and sometimes
and in in in in books multiple books
that have been written on this subject
like Thinking Fast and Slow there's a
huge list of such biases that are
described and you can actually just read
the book and the author plays tricks on
you and says over think about this and
then asks a question and you realize you
made the wrong call it's a it's an
easily confused mind so that exists
within within humanity so the second so
there's something to improve their point
is this is a pretty big gap and there's
something to improve there the second
reason for this fear is that you know we
think that artificial general
intelligence and here I'll define two
terms artificial general intelligence
being the kind of AI that is human or
human plus level AI that can solve
general problems it can learn anything
like a human being can it can be
athletic it can sing it can read books
it can compose poetry it can drive a car
it can do all the things that humanity
does and then some general intelligence
artificial narrow intelligence is where
we are right now so the systems that my
company bears or what Google and Amazon
build these are all they all fall into
the domain of artificial narrow
intelligence within a certain domain
these systems can
outperform human beings for example a
computer program has beaten the world's
best go player the world's best chess
player the world's best Atari game
player right so within certain domains
we can we can completely obliterate
human performance with these artificial
narrow intelligence programs but they
are just what they were made for they do
some learning but within that domain
they're very narrow now that alone has
the ability to impact the economy in a
very substantial way for example there's
a price waterhouse report that came out
about the UK economy which is similar in
terms of its sophistication and their
view is that in the near term like a by
the early 2020s there'll be about a two
to three percent reduction in jobs in
the UK due to automation but by the mid
2030s just about 15 years later that
number will rise to 30 percent and for
this we don't require Commander data
from Star Trek okay we just require
narrow intelligence the kinds of systems
were building now self-driving cars and
self-driving farm equipment and turbines
that predict when they're about to fail
so you need less technicians and
aircraft that thirty minutes before they
land they tell you exactly what's wrong
with them and then one maintenance tech
comes up with an iPad and looks at a
list of step by step exactly what to do
to fix the aircraft no thinking involved
by the way that system we built in
partnership with Honeywell
so these things are already out there
this is all narrow intelligence and it's
making a difference so these are
positive things on the one hand and they
have an eco Namit component on the other
in other words what should that truck
driver that's had a pristine career
that's never had an accident is now in
his mid-50s and he's worked hard all his
life and done an honest job and we look
at him and we say you know what
technology's arrived autonomous trucks
are here too bad I think you should go
back to college and maybe get you know a
chemical engineering degree we need to
educate you it's not that sort of a way
of thinking doesn't jive with a
fundamental understanding of who we
humans are there's mental plasticity
that changes over time and you can't
treat somebody like that in society if
you if you want to create a stable
society you can't do those things so the
real challenge is that delivering the
benefits of automation and AI through
many of these things that I described in
healthcare and green energy in better
efficiency in getting people out of
hazardous situations like Fukushima
there are a litany unending list of
things that these machines can do for us
but what that is connected to is today
we have human beings performing that
labor so immediately the benefit of
getting a human being out of that loop
is immediately connected to oh you're
taking somebody's job away
so the solution isn't to ban the
technology it isn't to stop progress the
solution is to come back and say what is
value value beyond the needs of the
human flesh is essentially human
agreement we agree now that rap music is
very valuable and people that sing rap
music make a lot of money or people that
can hit a baseball out of the park
should make a lot of money or an athlete
that runs or jumps at a certain you know
level of performance should make a lot
of money but if you went back 500 years
these weren't the collective agreements
of society so value in these cases is
purely a consequence of the agreement of
society and if that's the case it is
something that can free us in developing
new models evolved models where we are
able to compensate people not just for
what we call labor today but compensate
them for things that we didn't think
were valuable previously but really are
valuable what are those things the book
gets into quite a bit of detail in a
nutshell they are our unique
perspectives our ideas that ultimately
is what we bring to the table so the
question is how do you take an amorphous
thing like an idea
perspective and how do you create a
monetary system around that and that's
some of what the book explores also
that's great I want to go back to what
you're talking about with with
artificial general intelligence versus
artificial narrow intelligence and Paul
I want to jump to you because a lot of
what people think about when they think
about military and I think about
artificial intelligence and autonomous
systems is what they learn in popular
media they think about Skynet they think
about terminator can you help us kind of
walk through what Smith versus reality
in terms of what do AI and autonomous
systems actually look like today and in
the near future yeah I think you could
almost start with the assumption that
anything in science fiction is just sort
of myth when it comes to this I mean
what what we're really seeing is is
increasingly advanced robotic vehicles
so boats aircraft drones underwater
ground vehicles these are most advanced
in the air or underwater it's
particularly challenging on land because
of just the difficulties of navigating
around obstacles on the ground and a lot
of the things that they make
self-driving cars possible like GPS or
the ability to map the environment very
well those things may not exist in a
military environment many of them don't
look like what we think of as robots
though so it look like advanced missiles
so next-generation missiles that can
adapt in flight to their target that can
move around any threats that can talk to
one another and coordinate their actions
so swarms of intelligent missiles and
they also of course look like cyber
weapons which don't look like anything
but have tremendous effects there's a
just incredible program that DARPA the
Defense Advanced Research Project agency
ran a couple years ago called the cyber
Grand Challenge where they brought
together competitors to build these
computers that could scan software all
on its own for vulnerabilities that
could be then either hacked offensively
or they would patch them defensively and
these these computers competed in
basically a tournament and capture the
flag sort of tournament to find these
things and the able to do this all on
the room and they are now at the level
where they're not they're not as good as
the top human
in the world but there's no top 20 which
is pretty good and is enough to have a
lot of value in in military operations
so the Pentagon is already deploying
this technology to prove its own
software to patch it up so all of these
things though are things that they're
not they're not intelligent like us they
don't understand sort of the broader
context for what they're doing they can
act with great precision when they're
being used in the way that they were
intended they can be quite reliable but
if the if the environment changes
somehow and they're not prepared for
that they can't see the bigger picture
and that's where a lot of the risk can
come from which is you can build these
things that they work very very well
that's exactly what the program to do or
exactly what they were taught to do but
then if the situation changes a little
bit they don't understand that the war
has ended or this person might be a
civilian they don't understand maybe the
environment has changed and that's one
of the concerns about some of these
weapons so to dig into these concerns a
little bit right in your book you do a
really balanced job of talking about all
the reasons why we may want to leverage
AI and on tournament systems in military
context but also all these fears that we
have around it so let's think what what
really is the moral issue that's at the
heart of all of this the I think the
central moral question that people are
trying to grapple with this how do you
use technology in a way that might be
beneficial without losing our humanity
in the process without you losing the
human role in warfare so I'll give a
story about my time in Afghanistan that
might might illustrate this I was in a
ranger sniper team a relatively early on
the wars and we're up on the Pakistan
border in a hide site and the Sun came
up with infiltrated at night onto the
mountaintop and the Sun came up and
there's not a lot of trees in this part
of Afghanistan so it turns out the rocks
did not give us quite the cover we
realized we thought we were hoping for
and it was pretty clear that the village
beneath us saw the war work and it
wasn't very long before a little girl
came out and it was cool that she was
sent out by someone to scout out our
position she had a couple goats behind
her but
she wasn't obviously hurting the coach
she was she was looking at us and she
was reporting on us
she had a what we later realized was a
radio on her she was reporting back to
the position and she came up but she
kind of walked this long circle around
us she's maybe five or six she's not
particularly very sneaky look staring
right at us so we watched her and she
watched us and eventually she left and
it wasn't long after before some Taliban
fighters came so we would took care of
them and the gunfight that happened sort
of brought off the entire village she
was pretty loud and and eventually we
had we had two exit rate we was pretty
clear that the village was was full of
more people growing in a crowd and later
on we're talking about well how would we
deal with that again so we talked about
okay if we could we would try to maybe
if there was a civilian that we saw up
on the mountain herding goats or
something we would come up to them we'd
see if we could you know grab ahold of
them Pat that down see if they had radio
if they were reporting on us so we would
know if we were compromised or not if
someone else with the enemy fighters
would know would work I can tell you one
of the things that never came up
was the idea of shooting this little
girl there wasn't that topic of
conversation among the people there
what's interesting is that under the
laws of war that would have been legal
the laws of war did not set an age for
combatants they determine your combatant
status based on your actions so if
you're participating in hostilities if
you're scouting for the enemy you're an
enemy combatant and it will be legal to
kill you so if you built a robot to
perfectly comply with the laws of war it
would have shot this little girl and
she's participating and I still it's not
her fault she doesn't know any better
she's been sent by someone to do this
and I think that would be wrong morally
but it would be allowable under the law
so this is the kind of challenge that
humans in this case intuitively
understand and there are other other
situations that warfare that people
might face that are I think much more
difficult actually that way very hard
competing tough moral choices and what
do you know I think the fundamental
question is do we want to enter a world
where humans on all of our making those
decisions we've handed them over to
machines and what would that mean
for warfare or what would it mean for us
if we did so I think this idea of human
judgment right and the ability to
intervene in machines making decisions
this corresponds into the civil space as
well right Ahmir you and your book talk
about lots of examples where they're AI
can really help Society but you also
talk about some of the existential
issues with it so how do we go about
regulating and starting to mitigate all
of these potential negative concerns
well not squashing the innovation and in
letting a I and autonomous systems help
us do all the things we need to do in
society you see there's two things one I
think in general if you look at it in
very objective terms if you look at it
in things like HDI Human Development
indicators the fact is that an increase
in the wellness of humanity broadly
across the world is correlated with the
development of scientific and
technological progress there's very
little argument in that so the overall
thrust is heading in the right direction
and artificial intelligence is not just
an area of work artificial intelligences
the area of work it now underpins new
innovations and discoveries in a broad
range of Sciences so attempting to curb
or stop or drastically reduce the amount
of effort that people are able to apply
to artificial intelligence will be
disastrous I think for scientific
progress now you know what Paul talked
about this is obviously a very difficult
moral call I'll tell you another
difficult moral call from again the book
that I was citing earlier a lot of
research that's been done judges in
Israel that were adjudicating cases of
folks that were up for parole and there
was temporality there was sort of this
timeliness to whether they would accept
or deny the cases around noon they would
start to have a very high rate of
rejection in the morning it was high it
tapered below and then after one o'clock
it started to increase again and after
the psychologists involved did a study
they discovered that this was because
the brain requires glucose in
to think through hard decisions and when
the brain lacks that glucose we default
to fast thinking system one thinking and
so the default in this case was just let
it go whatever the status quo is just
let it go and the implication of that
little bug in the human brain that
little deficiency in the human brain is
ruining dozens and dozens and hundreds
of people's lives so this is just one
example with every cognitive bias there
are issues and concerns like this so I
think on both sides we will find
examples that are absolutely terrible
one of the things that I say is that I
don't worry about the malevolence of a
machine that does not exist at a level
of sophistication to where it can
exhibit malevolence I worry about the
malevolence of man ultimately all of
these systems that exist today nuclear
weapons all of these non intelligent
systems if you will that are completely
controlled by human beings there is a
fundamental existential risk posed by
them - so given that balance there are
many examples of what Paul is talking
about there are many examples on the
other side as well
I don't think that that alone qualifies
us to stop or curb or end development in
this area and the other part which is my
last comment on this is that during the
time of George Bush george w bush he
imposed a ban on stem cell research in
the united states some of you may
remember that the consequence of that
was the china became the largest genetic
sequencer in the world and this year
close to I believe close to a hundred if
not a hundred several dozen human stem
cell experiments were carried out in
China they are now the leader in that
space so what I mean to say by that is
that if you decide you're not going to
do something it doesn't mean that thing
won't happen so then the question is if
you can't guarantee by you not doing
something that the thing won't happen
then it's it's not a simple decision
then you're in what's called game theory
this is sort of the
dilemma there's two people that have to
make a decision there's a perfect good
outcome but no two parties have perfect
information about each other's motives
and so by assuming that the other person
is doing the right thing you lose by
taking a middle course you gain and so
the the optimal decision never really
happens because nobody can assume that
the other person who's not communicating
information to them is doing the right
thing this is the problem with nuclear
weapons nuclear weapons you can fly a
satellite you can fly you to sr-71
drones whatever and you can photograph
large areas of land where big nuclear
reactors are being built so it's easy to
tell a country you're running a nuclear
program and you agreed that you wouldn't
and now sanctions or whatever the the
payback is but how can you verify that
in an entire country in every computer
connected to or present in a country
some lines of source code aren't present
it's an fundamentally unverifiable
activity artificial intelligence is not
a big building artificial intelligence
is not a large aircraft or parked in a
hangar artificial intelligence can be
lines of code that I might have in my
pocket right now on a five-dollar USB
disk and there is no way to validate the
lack of presence of such technology in a
country so that creates the situation
where you have to assume that it's there
and when you assume it's there I think
that kills the whole idea of a ban you
can't ban it then because the the folks
that shouldn't be having access to this
technology probably will behind closed
doors and I want to follow up with that
in a second but I do also want to invite
any audience members who have questions
we have a microphone in the middle so
please feel free to use it so I want to
follow up on this idea of the
inevitability of using AI but at the
same time this this lack of transparency
when AI is even used right I mean we
hear a lot about the black box issue of
not really understanding what's going on
in
side algorithms but often we don't even
know when they're being used so how do
you start to deal with us the
malevolence comes from human minds and
I'll tell you that if you think about
this is my position on it I've said this
before for example social media has
caused a lot of harm recently in terms
of individual privacy in terms of being
able to you know become a platform for
entire elections to be hacked and many
many other documented things that
they've that they've done the solution
is to so what how does that happen that
happens because you've connected to a
number of people those people post news
updates so on but you don't get to
decide what you see there is a Facebook
algorithm or a social media algorithm in
the middle that sits there and decides
you can't directly influence that album
that algorithm why why is it not
possible to give you complete control
over that filtering algorithm and this
is the deep question to ask because if
Facebook's model is ads that's one thing
but if Facebook's model depends on
fundamentally understanding your
psychology to such a deep extent that
they are unwilling to give you any
control to be able to change the filter
that they've created to target you that
is far more dark than just trying to
optimize the sale of an ad and the
solution of this sort of a problem is
Democrat Democrat is the algorithm give
the algorithm away give the algorithm to
the user give control of the algorithm
to the user so yes this is I'm not I'm
not asking for a ban on social networks
I think that ultimately technology wants
it's out of the box you cannot put it
back in the box but there are fixes
there are things that we can change
sorry there was a question so I don't
know if you address the social
consequences of all of this in your book
in your book but it occurs to me
listening to you today that my father's
prediction to me when I was 11 years old
in 1965 and he brought in a mini
computer into our home
and said the world will never be the
same again and we're not ready for the
consequences is really true so first we
saw the hollowing out of the middle
class as technology changed how we
manufacture things and how we grow food
and it seems to me that as AI comes more
into the world that it is going to
profoundly change how professionals who
see themselves as part of the
upper-middle class work and whether or
not they're able to work and how many we
actually need to work and so you said at
the beginning that we need to figure out
how to value something else but we have
never had a society at least as far as
I'm aware of in humanity where we have
rewarded for people for anything other
than work and so if we don't need as
many people to work what do we do with
them yeah that's a that's that's the
multi trillion dollar question there are
lots of on the practical side there's
lots of proposals you've heard about
universal basic income you've heard
about a robot tax there are concepts
around going back to the basic concept
of rent each one of us owns a bit of
earth as a human being and rents
accruing from what is ours on earth that
can be a way to provide us with funds my
own suggestion is what I call idea coin
I don't mean this to be a literal piece
of currency but the idea is that that we
are connected on a network already we
contribute ideas that may be valuable to
other people and as people find value in
these ideas a design a painting whatever
that happens to be some idea other
people's judgment of how valuable they
find sets a value to that particular
concept and because I anticipate that on
a system like this there will be both
AIS and human beings operating at the
same time you could argue that well the
fastest AI we'll just take all the good
ideas and we'll take all the money away
so in this system I've also proposed
embedding a logarithmic
function in other words for the first
good invention you make you get den for
the next one you get eight and seven and
six and so on so that this kind of issue
that we have in finance capitalism now
where there are no holds barred massive
collections of money because money wants
to collect in one place it's sort of
like columns ring and in that sense this
logarithmic function can to make that
fundamentally part of our economy I
think can mitigate that effect there
will still be rich and poor because we
don't want to make everyone equal it
takes away incentive but I think what we
can do is we can say look when this
thing gets absolutely into its extreme
edges this logarithmic function can
really prevent that from happening so
I'm not suggesting to you that that
solution has occurred what I'm worried
about
is that the government's aren't even
properly talking about this what's
happening today is that you have Russia
thinking about this primarily on the
military side China more holistically
France somewhat allistic Lee but with a
small amount of money Dubey I was there
two weeks ago and I met with the world's
first AI minister so they've gone and
done that but here in the United States
there's still a lot of work to do Paul
and I both serve on an AI task force
that Cena's established with deputy
secretary Bob work and many other
notables in the space we're trying to
get something going but it's not at the
level of Xi Jingping
talking about a 2030 strategy we don't
have that level of traction so we can
find a solution but I think we're behind
the times even behind other countries so
good afternoon I had a question what you
spoke about you know the the question of
whether a eyes has malevolent ends or
not I was wondering more about sort of
the gray space of unintended
consequences of things doing exactly
what they are supposed to do or how to
sort of split the difference you think
about I mean it was target had a
sophisticated AI that correctly
predicted a 16 year old girl was
pregnant before her parents knew and
started sending you know baby
notifications or you think about
yeah or you think about autonomous cars
and you know how they handle the the
infamous trolley problem is you know
you're gonna crash and you hit the bus
full of nuns or the orphans or or you
say the driver and how do you go about
doing those things where it's not
clearly there's a right or wrong but
there's a middle ground that even all of
us in this room wouldn't necessarily
come up with the same answer about and
similarly in the military sphere is it
enough to put one person in the middle
of the kill chain and we've satisfied
the moral necessity or is it something
else entirely Paul II would start out
yeah I mean certainly putting a person
there just to push a button or be a
scapegoat is not an effective solution I
mean we've seen examples in the military
context where there have been people in
in the loop if you will in highly
automated lethal weapon systems and we
still have accidents if the humans
surrender their judgment to the machine
if they engage in automation bias
another type of cognitive bias for
people over trust in the automation and
so what we're really looking for is
humans to be actively engaged to engage
in this sort of a slower type of
thinking I'm understanding the context
and for humans to feel morally
responsible for the actions that then
occur you don't want a situation where
the humans say well you know I'm just
here to push the button the machines
doing work there were there were two
fratricide incidents in 2003 where a US
air defense system the patriot shot down
to from the aircraft and humans were in
the look for those that push the button
and afterwards when investigators
interview the operators one of the
things they said was that their belief
was that if they overruled the
automation and they let the the it was
they were trying to target sort of
salams missiles Scud missiles that was
the intent if they let a missile come in
and people died then they would be in
more trouble than if they just trusted
the automation and and they just said go
ahead and do it and there was the what
accident
so that's a place where it's not just
about what we design but how we use it
and then how we train people and the
culture that we put around these systems
to ensure that humans still ultimately
feel responsible
for the decisions that are made did you
wanna yeah look I'll answer it Paul give
you a fantastic answer maybe I'll answer
it from a different angle and that is
that you know I often think about where
we are in terms of improving human
nature and you can ask me what is
improving and what is human nature but
look even now my belief is just my
belief that we here in America are
blessed with a lot geography has been so
incredibly kind to us that if we start
to enumerate just the blessings of our
geography it would fill a book and in
fact Robert Kaplan just filled a book
with exactly that so we have a lot to be
thankful for and our situation is not
the average situation across the world
now we could have been somewhere else we
could have been born in a place or we
could be living in a place where there
are lots of stresses what I have
observed generally is that man women
when subjected to stress start to lose
the higher level functions of their
brain and start to degenerate very
rapidly and very quickly the reason why
I am interested in autonomy and
artificial intelligence is because I
feel that short of the reprogramming
humanity's brains the only way to create
a better world is to reduce the amount
of ancient stresses that cause us to
activate the reptilian part of our brain
and start to act like a snake or you
know some other form of malevolent
reptile which we do very often and we've
done worse we've done worse so that
whether that proves to be true or not in
social engineering we've seen that that
happens we say that look people in
richer countries and I'm just loosely
using language here so forgive me in
richer countries people generally behave
better well what does that mean does it
mean that being richer makes you a
better person or because
in a certain part of the way I've
traveled the world I can tell you there
are wonderful people everywhere what
makes people better is when they know
that they have food on their table that
there's fundamental security that
nobody's coming after them and banging
down their door in the dark of night
that their children have a future there
is very consistent
you know reactions to that kind of
security
so using automation and using AI to
build that kind of security by the way
that's what Buckminster Fuller many
years ago had argued for he said
technology has already arrived at the
juncture where we can take care of our
population we can supply them with what
we need now it is our choice that we
don't do it because we lack the
political will we used to go and dump
grain in the ocean because we wanted to
keep the prices of grain high as opposed
to factoring in that if I gave this for
free to some part of the world that
needed the grain could that overall
reduce anxieties reduce the negative
behaviors create stability and maybe
plant the seed of a new vivacious
society that could one day become an
economy and could one day become a
customer so this is a way of thinking
and my way of thinking is that our best
bet is not the politicians our best bet
is not you know self-styled messiahs our
best bet is science technology a lot of
people working on a lot of Science and
Technology because through history
science has proven to be a friend of man
and that's my view thank you ma'am
um first of all thank you for being here
this is all super fascinating um I
actually have a few questions if that's
okay
um but I'll see the floor if anyone else
wants to ask any I guess the first one I
want to ask is around the difficult
choices you mentioned that maybe might
remove some psychological toll on those
people and I'm thinking in particular
with regard to policing in America
right now it's become very clear
especially of late that bias plays very
heavily into the decisions that law
enforcement makes and maybe AI would be
a way to alleviate some of those
conditions but the problem that I have
with that is that the group of people
who are programming AI is not very
diverse and right now we're seeing that
in a comical level with like you know
hand dryers and bathrooms that don't
recognize people of a certain skin tone
and I am wondering how you would address
that in situations where you're creating
AI for something like law enforcement or
anything where it has to deal delicately
with situations like that where the bias
of the person who programmed it may
cause it to essentially malfunction in a
given situation how do you account for
that how do you remedy that yeah I'll
quickly give you an answer the issue
sometimes it's not just about the bias
of the programmer most of the current
machine learning techniques being used
are supervised learning techniques in
other words they give you you know you
require thousands millions of examples
that are labeled of some object in some
state maybe an individual of a certain
ethnicity or an animal or a door or
whatever it is with a label and you
require a large number of those in order
to properly train the model so the issue
is not actually getting a broad enough
set of data when you're talking about
images that are you know human images
the quality control problem manifests
itself as poor recognition for certain
types of ethnicities but this
fundamental problem is it goes beyond
just faces you know you if you hadn't
trained pictures of enough doors it
wouldn't recognize a door pretty well so
I think this is quality control and more
data the programmer isn't actually
programming any rules here the
programmer isn't going in and saying if
these things are true then it's
Caucasian male or a black female or
that's all those decisions are being
made by a neural network that has been
trained by data so I think again better
quality control and much more data
and and we need to demand that so I
think you've got it I think you got a
layered set of problems a lot of the
problems are about as a mere talked
about you have the set of training data
the training machine on and then you
applied to the real world and it's a
different distribution of things that
you're interacting with so maybe if your
training data doesn't have enough people
of ethnicities or something right in the
real world your system doesn't know how
to identify them properly
another problem might be that the if
sometimes it's it's not that the
programmers are trying to be bad or
themselves or biased
it's that yes that's simply you have bad
data another type of problem might be
that the goals the programmer says so
there was an interesting article that a
that a journalist did recently looking
at YouTube videos and what she basically
found was that as she started watching
YouTube videos of a certain type of
content she started initially with
political content YouTube started
recommending more inflammatory content
so really really started watching like
during the election of videos of Donald
Trump and then a campaign rally giving
some speeches and then eventually it
started recommending more extremist
right-wing kinds of speeches and like
sort of really extreme like neo-nazi
kind of stuff sounds crazy so then she
goes creates a separate account such
watching Clinton videos and this was
recommending a bunch of extremist loved
wing material then she could in another
workout started watching just jogging
videos and you start seeing up
ultramarathon so there's something about
the algorithm that starts teeing up why
is it doing this or suspicion is is it
is trying to maximize the amount of time
you spend watching YouTube for
advertising purposes and the algorithm
is simply learned that people tend to
click on more inflammatory types of
content regardless of what it is so you
know here's the situation of the goals
also matter who's designing the system
what are their goals in this case their
goals are to sell ads right and then how
does that get instantiated in the way
the machine learns so I think that
there's a whole range of things some of
these are though about when we have
we're living in this world where these
tools are being built by a small subset
of people and they're affecting all of
us and the tech community is not very
diverse at all or
looks very white it looks very male and
then of course to be driven by corporate
interests you get a whole range of other
societal problems that come as a result
thank you we have time for one more
questions we have a gentleman in the
back who has a question yes this
question has to deal with the social
aspects of AI and what you're saying you
had mentioned that by the 2030s or there
abouts a large percentage of at least
the u.s. population won't have jobs that
they have today given that our federal
government earns most of their tax
revenue from income tax from our labor
how do you see in the future federal
government at least our federal
government earning a large portion of
its revenue do you see possibly a robot
tax yeah what you know sure can you
discuss that the statistic that I gave
of 30 percent unemployment was from a
Price Waterhouse report about the UK in
the 2030s but the u.s. number is
actually even worse so but just a minor
clarification there my view is that
there's going to be a few different ways
to sort of compensate for this and I'm
not suggesting that all of this can be
compensated but here's what I'm thinking
I think that as we've migrated toward
services and within services a lot of
caregiving type professions now employ a
lot more people than they used to I
think that trend is going to continue
there's going to be a lot of personal
services caregiving things that we
always want human beings to do because
they're associated with the human touch
and they make us feel better the other
thing that I find and you'll see this
even on YouTube so many people now are
YouTube content creators so many people
have big Instagram channels and they
monetize those Instagram channels I mean
these were jobs that didn't exist before
now how many are there I don't know but
I can tell you that the independent
coder the the programmer who doesn't
work for a company and can live anywhere
in the world running through companies
like Elance for example and oDesk and
companies like this
can earn hundreds and hundreds of
millions of dollars of foreign exchange
for their countries all these stats are
out there so there's some
democratization of work Federation of
work that's already happening there's
some types of jobs that will always want
people to do health care is another big
one right but in fact the doctor will
probably be mechanised before the nurse
now what how will we make up the
difference I think where we make up the
difference the things that have been
talked about for a while that are
already being experimented with one is
universal basic income which is in the
Scandinavian countries that I believe in
Iceland also can you give $10,000
$15,000 as a base income the country has
some fundamental assets you know
different countries have different
assets but the US as we were talking
about is the richest country in the
world and I don't mean that in terms of
the dollars we have I mean that in terms
of the natural gift that we've been
given so focusing the discussion on this
country there are things to monetize
there are resources to monetize through
machines that we can share the bounty of
that automation with individuals so a
reverse tax or you can look at it as a
robot tax that's then yielding resources
back to back to humanity the idea coin
concept that I talked about is another
one of these of these concepts which
could lead to something so there might
be five six seven eight of these
proposals that come about and some will
be shot down but ultimately the fact
that some of them are already being
tried gives me some hope the Emiratis in
the UAE they're also very very
forward-looking they're also thinking
about ways in which they do things and
and their environment is very different
they're not Scandinavia their
environment is very different so it's
good they'll come up with other ideas
and over the next five seven years
that's what we have to do technology has
outpaced policy innovation and now is
the time for some policy experimentation
the world is a lab and let's figure out
how we
can can come up and try a lot of these
kinds of economic policies that might
work so there are a range of predictions
on sort of what automation will mean for
the future of work the I do not think
and never there are anywhere from people
predicting depression error level
unemployment to people saying they'll be
you know so many jobs created by AI that
we'll all be millionaires or whatever
the best analysis that I have seen is by
a work by McKinsey that basically said
roughly half 46% of tasks being
currently done in the US economy are
automatable with existing technology now
there's actually hold jobs that's tasks
that people are doing as part of their
jobs and it's only a very small fraction
of jobs less than 5% that are entirely
replaceable by machines you can see some
of them things like Tollbooth operators
that person taking your ticket when he's
in a parking garage but most jobs will
see some disruption and so you'll see
some tasks being eliminated handover
machines but then of course new jobs
created now what does that mean net the
best work and this I've seen by as by
Erik Brynjolfsson and Andrew McAfee in
the second Machine Age they argue that
automation has already been responsible
for the suppression of median wages the
United States so you're seeing a sort of
slow decline of median wage for many
people particularly for lower skilled or
lower educated workers that automation
picks up routine physical and cognitive
labor and that's generally been
performed by people with less education
and so particularly for people with like
a high school education we've seen you
know a really stark drop-off in in wages
a most difficult for them we've done
some work at the Center for a New
American Security this is not in the in
the Army of none but we've done some
work there that'll be coming out later
this summer when we've looked at this
automation data and compared it across
demographic categories in the US economy
and it shows that a lot of these
actually fall on the youngest people in
the workforce so we tend to think we
weren't worried about we think about
people than their mid-50s that this hits
them because it's hardest for them to
adjust that's gonna happen obviously to
some people but the ball keep it's gonna
land on people
in sort of their that are starting to
enter the workforce because they have
the least amount of education the good
side to that from a societal standpoint
is that those who were most you know the
best place to adjust who have the most
time on the challenges that we need to
have education policies things like
affordable college education to make it
possible for them to get a good
education to do so and in particular if
you're thinking about people who are
using that lower-income job or lower
skilled job to pay their way through
school one of the things we're doing is
we're taking away that that step ladder
they're using to get educated now but
there are you know potentially policy
solutions that that could help mitigate
that well polynomial I want to thank you
for a very interesting conversation
today you've given us a lot to think
about and I have 30 seconds to give to
each of you to give one last thought you
want to give to the audience as we walk
away okay I got to think of something
yeah I think it's this idea from the
sentient machine which is that a lot of
people worry that as computers become
faster and they can think everything
then there's no value of the human mind
and consider that the landscape of ideas
is infinite there are infinity ideas for
machines and humans to go and discover
so regardless of the speed of any
machine they will discover about as much
of the idea scape as we will which is
almost nothing so what matters when
speed doesn't matter is really
perspective and that's the reason why we
continue to have intrinsic value as
human beings regardless of how fast the
machines think thank you you know I
think in a similar line sometimes we get
caught up in is the machine better than
humans that this or that one of the
questions that I like to ask in a
variety of domains is if we had all the
technology we can imagine in the world
what we want humans to be doing and why
and what types of decisions are ones
that we want humans to make in our
society and why do we think that's
important well perfect and with that I
would say thank you to our panelists and
thank you to the audience thank you
and that wraps up Book TV's coverage of
this year's Annapolis Book Festival now
if you missed any of the events from
today you can watch them tonight
beginning at 12:30 a.m. Eastern Time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>