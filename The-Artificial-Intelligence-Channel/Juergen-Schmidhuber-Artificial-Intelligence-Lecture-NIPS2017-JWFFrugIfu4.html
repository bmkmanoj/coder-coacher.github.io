<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Juergen Schmidhuber - Artificial Intelligence Lecture NIPS2017 | Coder Coacher - Coaching Coders</title><meta content="Juergen Schmidhuber - Artificial Intelligence Lecture NIPS2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Juergen Schmidhuber - Artificial Intelligence Lecture NIPS2017</b></h2><h5 class="post__date">2018-03-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JWFFrugIfu4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so it is my great pleasure to introduce
jurgen schmidhuber who whose omission
since the age of 15 has been to create
an AI that's more intelligent than
himself and then retire thank you so
much this is the cover that I made for
my first publication ever my diploma
thesis 30 years ago in 1987 it was all
about meta learning I wanted to solve
the grand problem of AI by building
something that not only alarms a little
bit here and learns a little bit there
but also learns to improve the learning
algorithm itself and also the way it
improves the way it improves the
learning algorithm and so on recursively
recursive self-improvement without any
limits except for the limits of
computability and physics and and this
is my name and how to pronounce my name
and the basic approach is always the
same and principle we are doing similar
things that as what we did back then you
start with a general purpose computer
and you have a universal programming
language that allows you to implement
arbitrary learning algorithms and then
you need some sort of force that makes
sure that learning hardens that you're
testing are getting better and better
over time and back then I used concept
which was first published by Kramer in
1985 genetic programming which is just
genetic algorithms apply to programs but
then I said ok let's have a second level
on top of the basic level which allows
the system to search the space of
arbitrary new learning algorithms that
can combine existing knowledge and
existing programs in new better ways and
arbitrary computable ways and then on
top of that another level and so on
because of Liam and this was rather
general compared to what you often see
today because many of the things that
are called meta learning today I would
probably prefer to call transfer
learning for example you have a deep
neural network
convolutional Network and you train it
on 100 different trade and data sets
image data sets but then you take one
more data set and of course it is going
to allow the new one much more quickly
than the old ones because it already has
learned so much about vision from the
previous data sets so that is not in my
point of view real learning to learn or
meta learning why not because the system
is still stuck with the same basic
algorithm which in that case is back
prop and and and so you want to go
beyond that radical lying to learn is
really about closing the loop as you
have a universal computer that allows
for computing arbitrary learning
algorithms you want to make it self
referential such that such that the
system has an opportunity to inspect its
own learning algorithm and make it
better and without any limits so this is
an example here in the neural domain
where I would not say that this is meta
learning although some people would say
that what you see here is a slow Network
to the left and you see a fast
wait Network to the right and that was
from 1992 and it's end-to-end
differentiable it's processing sequences
and the slow Network learns to very
quickly adjust the weights of the fast
network and that's how it can learn to
solve problems where you have to
memorize stuff so the fast weight
network is like a memory and external
memory that is controlled by the slow
Network now this is kind of cool but if
that is meta learning just because
there's one network that is learning to
control another way and one of the
parameters of another one then all of
lsdm also would be meta learning because
in LS TM you do have a fast wait at
least since 1999 since my second PhD
student lsdm PhD - student felix gears
introduced these four get gates c z
Gators recant units as they are
sometimes called now so here we see a
fast weight which is controlled by a
part of the Elysium and all the time if
you have a large network with many
Elysium cells then of course a
substantial fraction of that a whole
network is fast weights that are being
trained or quickly adapted by by a slow
part of the network and if that is meta
learnings and all of these applications
like Google Translate and Facebook
translate and what Apple is doing in
quicktype and so on they would also all
be meta learning I don't think they are
meta learning he is a real meta learning
system at least a supervised meta
learning system not fully general and
not reinforcements lying but at least
self referential this is from 1992 or
1993 you have a week on network and you
want to make it self referential such
that it can run arbitrary learning
algorithms on itself so we know that it
every cannot I can run average for a
hundred owns including learning
algorithms but we have to set it up such
that it really can express this power
and then what we do is we give it a
bunch of output units to address any of
its own ways suppose you have 1,000
units in your network then you have 1
million connections if everything is
connected to everything which means you
need about 20 units to bind to address
in binary fashion every single way break
number 5 and 76 you need an extra output
unit to say ok change now very quickly
the value of this weight of myself from
0.5 to minus 7.6 or something like that
then you need a couple of additional
output units to address the weights that
you want to read so you have another 20
output units for doing that and you have
an input where the system can see what's
going on within itself so it becomes
introspective then you can do that you
can make the whole thing differentiable
and you have an end to end the
friendship or meta learning system which
you just train on our standard task but
now it has the opportunity to come up
with its own fast weight change
algorithms running on itself
a meta meta meta learning system in a
certain sense and what you really want
to learn is the initial weight matrix
which tells the system how to start this
meta learning process basically and
Menem in a meta learning process now
back then and not done with Elysium but
with iron ends but with standard onions
but just a couple of years later I said
pork I died in 2001 he but maybe he
didn't have a fully self referential
system but he showed at least that one
network can learn and learning about
Rosen on another recurrent network so it
wasn't Alice iam actually which learned
to solve quadratic functions through a
new learning algorithms itself invented
learning algorithms rhythm 30 times
faster than background what which was
the technique that was used to a train
the whole system so things like that are
possible I thought this is really crazy
back then when I have 20 binary or year
binary units to change all these
connections sequentially
what are we humans doing well we have
learned to learn new languages how do we
do that well we say for example we want
to learn a certain word say house and we
want to enlarge the French translation
which is Maslin so somehow we put how is
in our head in our spotlight of
attention and a few seconds later or
milliseconds later we put mezzo in our
spotlight of attention and then that
this forces our fast weights to
associate these things together I said
we can build that with return networks
too so that was an alternative better
way of addressing through an outer
product rule all these fast weights in a
self-referential system like that and
the cool thing about that was that if
you have 1,000 units and a million
connections normally if you and have no
fast weights then you have a really bad
ratio between the slow variables themes
the things that you train and the time
varying
valuables it's worth 1,000 to one if
every connection can also be used as a
fast way then the ratio is one to one
much better a similar paper was there
last last year nips 2016 and there is
one here tomorrow I think at the nips
meta-learning workshop and it's my in
Manoa flock my PhD student yes I am more
complicated in fastweight system which
is more practical and certain sense
senses and and you might want to check
that out now fast weights can also be
used to reinforcement learn things and
and that's what Faustino gum has showed
in 2005 with robots that reinforcement
learned to do a rather complicated
complicated things back then and he used
fast ways to him to achieve that to
learn deep memory pom DPS
where you had to memorize stuff for a
long time
one important interesting concept that
you is not meta learning by itself but
can be used to build practical meta
learning systems is you collapse what
one network has learned into another
network which has already learned lots
of other things and and that's what we
did in 1992 so a recon network is
trained to do something in that case it
was prediction trying to compress
sequences by predicting them and then
another network learnt something else
which the first network couldn't do and
then the first network was able to
imitate the higher-level network and was
able to collapse its behavior into
itself while being retrained on the
previous stuff so that is something that
your heart and often see now in in
cloning policy is as it was called or
distilling networks back then it was not
get caught distilling yet but it was
called collapsing one net into another
compressing it let me now come to the
thing that really gave the title to
title to this present talk which is the
same title that I used in 1994 and
for learning how to learn learning
strategies for this tech report and it's
doing lots of things that I'm not yet
seeing in today's meta learning systems
it has a single trial a lifelong trial
and all the intermediate trials are
actually part of this one lifelong trial
and what's happening there the system is
a pro list a programming language could
also be a recon network but back then
there was something else and then it
learns to change yourself change the
probabilities of its own instructions
given the positions of instruction
pointers and so on and there it can
implement arbitrary learning algorithms
and now obviously it's the case that
whenever it changes its own learning
algorithm in the beginning of its life
this has an impact of what happens next
on later learning algorithms and how do
you make sure that the learning
algorithm self-referential
self-mortification algorithm is getting
better and better over time well there's
a particular instruction that the system
can execute which is called the
checkpoint instruction whenever it
executes the checkpoint instruction then
then then the success story algorithm
kicks in what is that it is an algorithm
that keeps track track of all the self
modifications of the system over time
and it always measures did I get more
reward for time since the last
checkpoint then during all the
checkpoint intervals before so that's
something that makes sure that you
always have a reward per time
acceleration and to the extent that this
condition doesn't hold at a certain
point in time you undo these self
modifications that were executed by this
system itself which means you need
something like a stack to keep track of
the previous self changes and only the
good ones survive and so you get then a
stack which gets deeper and deeper and
in any at any moment of its life however
the system is still ready to
to consider the possibility that
something that happened at the very
beginning of its own life was
responsible for what's now going wrong
and stuff like that
so it is really doing lifelong credit
assignment through a single lifelong
trial and this is what in principle you
have to do if you want to do the real
meta learning where you're taken to a
County effect of purely learning
algorithms until later algorithms so
here are a couple of pictures which
illustrate the operation of the system
and this is an an old example where two
agents equipped with that system around
to solve a rather complicated task what
you had to find a key and then open a
door and one of the agents had to go in
and grab another key and open another
door and open it and and the whole life
back then was long by the Backson
standards because computers were so slow
back then ten thousand hundred thousand
times slower than today but it was able
to look back over it's four billion step
life or whatever and do the credit
assignments that really came up with
really stable learning and
self-mortification algorithms then
somebody's now telling me I have only
one minute left so I just say then we
then went crazy and tried to find
optimal self-mortification algorithms
and that is the girdle machine and I
don't have any time anymore to talk
about the girdle machine but let me at
least mention one important thing if you
just have these user given teacher
define tasks then there is a lot of
freedom that you don't exploit in which
you can give to freedom which you can
give to systems that may invent their
own goals and their own tasks and may
invent their own experiments and to
figure out how the world works like
little babies do most of the time they
invent their own little goals and try to
solve these self-invented problems and
the good thing is that many of these
self invented problems are much easier
than what you get from your parents the
problems that other people and other
users
and - um so you want to become a more
and more problem more and more general
problem solver by playing around and
inventing the easiest problem that has a
solution which you didn't know before
but such that none of your previously
learned skills gets weakened or deleted
or forgotten and power plays a general
way of achieving them here's a little
robot that uses a restricted version of
power play to learn from revision - just
through playing one new skill after
another based on its experiments that
it's inventing by itself both our
academic lab and our commercial lab
nations are hiring thank you for your
attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>