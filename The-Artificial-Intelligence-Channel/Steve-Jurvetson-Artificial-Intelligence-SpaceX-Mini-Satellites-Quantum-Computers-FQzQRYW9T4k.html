<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Steve Jurvetson - Artificial Intelligence, SpaceX, Mini Satellites &amp; Quantum Computers | Coder Coacher - Coaching Coders</title><meta content="Steve Jurvetson - Artificial Intelligence, SpaceX, Mini Satellites &amp; Quantum Computers - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Steve Jurvetson - Artificial Intelligence, SpaceX, Mini Satellites &amp; Quantum Computers</b></h2><h5 class="post__date">2017-11-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FQzQRYW9T4k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">can you all hear me okay Rick oh this is
exciting I have to ask without any
introduction how many people have seen
120-year version of moore's law this is
an abstraction time and I just wanna get
a quick kind of half maybe 15 frames oh
okay now that's less than number of
people who said they were here last year
and I show this light every presentation
I ever give so someone was either not
paying attention or left the room and
the reason I keep showing it now for
over a decade is I think it's the most
important thing that's ever been graphed
and I think it will motivate much of
what I have to say that follows and in
fact the motivates much of everything we
invest in almost every investment thesis
we've ever had in some way revolves
around this abstraction of Moore's law
but abstraction if you notice the y-axis
I'm just looking at how many
calculations per second how much
computation can you buy for a buck I for
a buck could have been storage those are
the two things you usually buy you don't
buy transistor counts but Gordon Moore
actually observed in the belly of the
semiconductor industry was a refraction
of this much longer-term trend okay now
there are these different technology
epochs in these gray bars these are
everything from mechanical devices a tip
that census in 1890 the vacuum tube
based computer that predicted
Eisenhower's win in 56 or even back in
World War two the relay based computer
that cracked and knots the enigma code
if you watch the imitation game well
what's interesting is that if you plot
all the computers the best price for
home computers of the day over 120 years
they fall on a slightly up ticking line
on an exponential curve a logarithmic
curve but you'll notice the axis on the
left these are hundred axis improvements
with each tick mark all right you only
knew there on the curve until Gordon
Moore gave it a name and called that you
know and George Gilder called the
microcosm instead it's something special
to do with semiconductors it didn't
humanity's capacity to compute has been
compounding continuously from the
beginning of measure time why it's
almost a cosmological question having to
do I believe with the recombination of
ideas and really speaks to the
Technosphere and why it's so powerful
why it's so different from other parts
of the economy
notice it's exogenously the economy will
do one will door to the Great Depression
had no impact the humanity's capacity to
compute it's compounding innovation in
these domains pretty amazing you stop
think about it it also gives us great
hope what if this curve continues for
just another 20 years this is what
Kurzweil and others conclude we'll have
machines that exceed human intelligence
and within 30 years machines in
the intelligence of all humans on earth
combined in a single machine they cost
about $1000 so available to many people
in room um it also bends what is the
next substrate is it like electronics is
a quantum computing is it something
that's not just CMOS silicon the way in
to make you believe it so the thing to
realize if you label these curves is
until about ten years ago gave up the
mantle and it caught up okay labeled
here the last ten years it's been Nvidia
no surprise to anyone in this community
if you're gonna buy a compute engine you
don't really care about Intel CPU as
much anymore other than the UI and all
of course all the other windows the
lights that you they're still covered
with you've actually doing worse but
research you want to be on a substrate
that in normal sort of closely mimics
the human brain its massive connectivity
its local memory its ability to do much
more because that's really what deep
learning and neural networks all about
but for anyone that's having hard time
reading it just it's that yeah the GPUs
you can buy for a couple thousand
dollars today that are really the
workhorses of deep learning now but I'll
come back to the computational substrate
later the main point I want to make now
is that we rely on this when we invest
in new startups as the capacity to
compute reaches thresholds you can
simulate something that wasn't available
before a trial-and-error science becomes
a real information science and I believe
every industry on the planet will
eventually become an information
business something where the basis of
competition is how good's your software
how good is your algorithm you've seen
that of course with cell phones you're
starting to see that with cars the best
car of the future will be the best AI
you won't care about how many cylinders
you know your engine task of course
would be the electric car um that won't
really be the point of differentiation
you can see the advanced form of what
hardware becomes software-defined
hardware in the phone in your pocket
that's what satellites robots cars and
almost every other physical product will
become over time which has all kinds of
front implications on a winner-take-all
economy and network effects but I'll
leave that for another talk I just give
you some examples of companies that
we're investing in that obviously
leverage deep learning at the basis of
competition with their competitors and I
think you might be able to make a
similar comment as what you might have
made 10 years ago well let's say twenty
years ago if you don't have an internet
strategy as a new tech startup what are
you thinking
and maybe 10 years ago if you didn't
have a mobility element to your tech
startup strategy you're a little out of
touch and I think today the same can be
said for deep learning and artificial
intelligence in general if there isn't
some machine intelligence elements to
your business proposal for anything
launching today what are you missing
right and so any non-traditional you
might ask yourself that um across many
different sector this is just a random
sample by the way we by no means have a
representative portfolio but everything
is going on out there
in FinTech and a bunch of areas there's
a lot of Spanish detect that is a lot of
innovation to be played okay there's
some visuals of some of these you know
robots taken robot use all that
off-the-shelf components that you get
from cellphones accelerometers and six
axis accelerometers and put them in
every joint you make a dirt cheap
hardware device where all the software
updates of course or what people buy and
the reason you've got a one product over
the next is a based on the software not
the physical change you know but again
keeping your phone the next phone you
buy will look just like the phone you're
on right it's just gonna be Moore's law
and better software for services the
cars you've already heard some about
this these are a couple in our parking
lot that I love um I've been a lot of
these vehicles there are times when you
want to you know sort of be a driving
machine as some add compute companies
might advertise and there's times when
you want to be driven by machine and
believe me it's an increasing percentage
of mike and the thing that's interesting
about this of course is where it will go
them in your future there are many
vehicles driving all around San
Francisco and the world fully
autonomously in urban environments and
the frequency at which they need to sort
of bail out for a human tella operator
to make a judgment call is increasingly
dropping and I think it's it is
realistic to think that these will be in
service at a couple years of an uber
life service it's it's a compelling
vision no driver no ability to have a
driver just get in and you'd be taken to
where you want to go with a higher
safety reliability and of course luxury
than you've ever had before
the thing that these companies all need
to make their driving algorithms better
are huge data sets right so there's an
issue thing in the whole economist
driving community who's gaining the data
who is the most miles with which to
transitional networks and some might say
the cars in the road with these features
I have a clear advantage right one of
the techniques many of the new entrants
are using those who aren't yet on the
roads is to train entirely within a
simulator built in many cases off the
grand theft auto and so I find that
somewhat humorous
now over and across correlating of
course like what they really see and
what all the sensors would have seen in
the 3d rendered world they feed that
through the sensor that's an entirely
physical simulation and cross train with
the real world so I think the good news
is that if the zombie apocalypse comes
the vehicles know exactly what to do
it'll be up on the house a sidewalks
they'll be taken out everybody and maybe
I can Easter Egg if you will then the
algorithms will leave that for the for
the rapid fire session on AGI later okay
um not too far from now we're gonna have
all kinds of satellites that's giving
around this guy within a couple years
you'll see the broadband networks
providing broadband gated connectivity
everywhere on the planet ubiquitously
with a 200 our ground station it's
coming from a couple different companies
that are in development that's going to
extend global Internet connectivity from
two to six billion people much more
rapidly than anyone is forecasting um
just take that into account also
anything about new business propositions
the developing world is gonna come
online on mas but this time that I want
to talk about first is one that is
actually shipping as we speak this year
and that is a huge array of hundreds of
satellites that are observing every need
of the earth every day you know choose
this as one of the examples of how one
of our portfolio companies is using deep
learning in a way that they have to and
is becoming the basis of competition an
industry an industry in transition
that's an earth observation by taking
pictures of the earth whether it's
visual spectrum infrared synthetic
aperture radar there's all these
different modalities but you're just
basically looking at Earth through the
telescope there's an example just of how
the industry changes instead of these
huge expensive mainframe sized and
mainframe priced computers you're using
again cell phone components
off-the-shelf every part is a commercial
off-the-shelf part in these in these
sort of flock of doves that they call
them satellites at observe the earth
this is a company but planet labs in San
Francisco what they can do though when
we go back to Steve see this visual
imagine you have hundreds these
satellites blanketing the earth imaging
every meter of the earth every day right
you immediately start thinking I have to
switch from human analysts like eyes on
Kuwait eyes on Afghanistan to a blanket
algorithm that's looking everything for
change detection for there's something
just happened and then you automatically
task a high-resolution satellite to zoom
in on anything that's changed change
could be environmental change could be
natural disasters could be conflict
zones
it could be new construction new housing
starts globally measures every day it
could be where people parking count
every car every parking lot every day no
human will do that it becomes computer
vision tasks some of the reasons that
we've done just in the last couple of
months is to automatically detect any
new wells that are being built or any
oil and gas development going on
anywhere in the world butter that's
newest ivory or you pick it and you'll
be sliders what's new what's changed
what are people doing or who's got
swimming pools but most people for you
know insurance adjustment they just
wonder stand where the swimming pools
which of our insured properties happen
which don't simple stuff like that or in
terms of national disasters you can look
at reflectivity of the water and
actually the depth of the water using
synthetic aperture radar to figure out
what's new flooding what's not where our
roads passable where are they not for
relief workers you can also identify
when there's new roads there's a lot of
places in the world that don't quite
keep up today on their Maps especially
places like India Syria just discovering
worse where's a new road pop up and be
able to use the difference between
before and after with daily imaging now
well let me just end that section to say
there are many areas like this where the
point of differentiation shifted from do
I have the best resolution do I have I
don't know what um some other parameter
metric - who's got the most data and all
these algorithms really only kick in on
massive datasets and that's what we're
not getting more data streaming out from
these satellites than you could ever
imagine and you start to want to put the
deep learning networks and the inference
engines into the satellites themselves
because what you can do is avoid sending
down all the data that's exactly like
what you had before so let's say you're
going over the open ocean unless you're
trying to measure ocean levels just send
datasets if there's a ship in the photo
right so two-thirds of the Earth's are
gonna be over water don't even send down
the images unless something's there
worth seeing and that kind of
intelligence many little devices that
are everywhere is important I'll come
back to that later that I think you're
gonna see an enormous explosion of
intelligence on the edge how in the
satellite not just in the data center
out in the remote sensors and in the
light bulbs in your home and every
appliance in your home will have a
little neural net than it's soon in
oldest in the next 3-4 years that will
allow you to speak to it will allow it
to be much more intelligent than any of
the nest of dropcam's are today on is
that really someone you should be taking
a picture of or is it just someone
household all that intelligence moves to
the edge I think because the
computational substrate is gonna allow
it to so let me switch to that last year
for those here you were that were here I
showed this slide of a general and I
won't belabor it today of the migration
that's been going on in Bitcoin mining
at check that I said this is what's
going on a Bitcoin mining of course
we're on the far right side of the page
and it's happening and deep learning as
well right we're we're somewhere between
the GPU FPGA and a sixth I write
Microsoft in the last year's finally
really embraced the FPGA research
they've been doing for years like four
years now they've been trying to
incorporate FPGA these are these field
programmable gate arrays each of their
servers they're now putting one of those
in every server they put in the cloud or
there are cloud services and then the
ISA company since last year both Nirvana
which we invested in and move idiots
which we invested in were acquired by
himself in the same month for the same
amount of money which is really weird
it's like a like a chip of $400 nope
here you go
both companies same amount um and that's
being incorporated into in those product
line and we'll see a lot coming out of
that I also mentioned mythic let me just
tell you just a reminder what they are
that sort of you start to break the ASIC
category to digital chips and now I
think maybe increasingly analog and
quantum chips or quantum processors you
see some interesting work I'll just
summarize for anyone who didn't see
mythic last year they're building an
analog deep learning harness and the for
a sense of the power of this and how its
again one step closer to the biomimicry
of the brain they're putting all of the
country computation in the memory rate
cell so the memory is the computer and
for a sense of how radically different
this is from any other chip and
development they can do matrix multiply
nad which is a thing you are you over
and over again right they can do an
8-bit matrix multiply and addition in a
single transistor so usually a big speed
what yeah 8-bit multiply and addition in
with one transistor in that array and
it's in a standard flush now a rate
that's one of the kinds of architectures
I think that you put a forty cent chip
into anything right into Europe irobot
roomba or your microwave oven or your
video camera it's cheaper than the
plastic buttons you might otherwise have
to put in a device to give you control
over its functions you speak to it in
natural language so the kind of how are
you see with Alexa home product it needs
internet connection
means a lot of power would fit into you
know a watch it could be doing
translation on-the-fly within hearing it
just get a sense of very low power but I
want to spend most of the rest of my
talk on a building of something you just
heard about how quantum computers might
affect this as you know CDL a Devaney
entire quantum machine learning track to
their usual machine learning sort of
accelerator program they're going
through and that was really exciting
yesterday budget companies were
presenting on how the using quantum
machine running new things like better
chip design quantum chemistry and so
forth the thing on the far right you've
heard a bit about just from the last
talk but there's a lot of potential to
do more than we have done in
unsupervised learning in generative
types of architectures and the reason in
a way they've been held back is because
of the computer architecture just like
hitting the team had a major
breakthrough in 2012 in deep learning
powered largely by the GPU realization
that oh my gosh CUDA and Nvidia's it
allows us to do so much more than we
could before and they really knocked the
socks off competing algorithms and
computer vision similarly I think
quantum computers kid allow you to knock
the socks off an unsupervised learning
and general design I'll show you a
couple examples so oh boy this is build
ok so think whoa and there's some people
you know unsupervised learning
I had a great catalytic effect most of
the research you've been hearing about
today is in supervised learning but
these folks who have my apology oh there
they are white white white white keep it
a suspense
folks you know well right from the local
community really believe in general
there's a lot of opportunities so to be
done you know unsupervised learning this
is largely the way babies work right you
don't say Cat Cat Cat ha
Cathleen delicious they just bootstrap
from a start know whether it's the
incredible work we'll hear more about
later - with alphago zero or others when
you have some of these minimal that's
not entirely good comparison when you
start from scratch you can do so much
more now some of you may know this but I
think this is the first and maybe the
only Canadian company to be on the cover
of Time magazine
do you wait um on the other coast so you
uh well you know a lot about d-wave so
um what I love about this article that
came out you know a while ago
years ago is that they call one of the
patron saints of quantum computing David
Deutsch it was his book that first
inspired me to invest in do way back
2012 and I've been on the board there
for 15 years but it really does provoke
your thinking to perhaps ask the
question is this unlike anything you've
seen before that's now something
completely different something frame
breaking perhaps that framework of
Moore's law that we saw earlier so the
examples about this there's this fellow
on the right Jordi Rose he's here in the
idea this summer he was judging you know
here he is
yeah the big black bus yeah he's a
wonderful fella but he's at a new
company called kindred but his first
company was this one we met back in 2002
he had one qubit and he was very excited
that his second qubit was in fabrication
didn't that that not be characterized as
hard to have entanglement with just one
qubit so um but he's convinced that the
number of qubits would double every year
right so he had one data point the
second one was coming divided a year
apart it's kind of like you know Gordon
Moore had five data points in his
original article and he just sort of
plotted the line forever
well Geordi made that virtual plot in
his mind so I pulled this slide together
actually 2012 based on the blue dots and
was kind of impressed you know ten years
later it held true um
and then we've added the yellow since I
first called it roses law because he's
too humble to call it in his OMA I've
got a big yellow dots as well and so
there is a separate question which is a
really hot discussion in the research
community which is does the power of
these systems scale linearly with number
of qubits what would be the worst case
to to the enth power which would be the
case in a serving pure gate model
quantum computer that as you add qubits
the number of representational memory
states you can you can represent with
your computer goes as grows as 2 to the
nth power if it were that it would leave
Moore's law behind once you've crossed
there'll be no looking back there'd be
no way for a classical computer to ever
compete with a clone computer once the
quanta computer sort of crosses over
those lines are are do you believe it
already crossing over or depending on
the application or about to depending
again on the software later which is
where all the excitement is right now
now um
Google's been using these things for a
decade and they've been publishing
results for quite some time
I find this question this quote to be
really fetching and
and provocative in so many ways I mean
of course there's the unknown laws of
physics begs that question but long as
we just go with what we know they think
there's no better way to do creative
problem-solving now this is stuff that
they published in 2009 and they've been
continuing to publish result saying oh
by the way the d-wave machines that we
use currently outperform our data center
in machine learning classical machine
learning as well as some new stuff and
Boltzmann sampling and weirdly none of
Google's competitors have bought a
machine yet so I I don't quite know why
they are alone in this but they bought
one of every machine do ways ever made
and they put a horde contract by
monitoring machine they will make and
they're making them internally as well
so they're all in and they're getting
some great results in fact one of their
papers just a couple years ago found
that in a particular I should put this
almost like benchmark test that they
purposely made the show the maximum
differential advantage possible so it's
a trumped-up example of sorts but they
found a hundred million fold speed-up
over their data center that's the kind
of thing that you say is frame breaking
right those are the tines of order meant
to improvement to catch people's eyes
usually and it didn't at least in the
u.s. it's kind of interesting to me that
every customer of do wages in the United
States in Europe let me just mention
that's all the Canadians nevermind I
don't know what the hell's going on but
but everyone outside of Canada love them
and they've got some amazing work here's
one on quantum Bolton sampling relate to
what you just heard in the prior prior
talk where you have classical algorithms
in bloom green that in some cases don't
even converge to the right answer and
they certainly don't do so as quickly as
a quantum machine where you want to
sample from a probability distribution
and you want to do so in the minimal
number of samples this recently has been
shown for example and it's completely
different pieces of work to be a way to
dramatically improve ray tracing and
computer graphics like if you have Toy
Story or some movie based on
three-dimensional objects you want to
light and shade the scene they realize
that I drop in a basically a Boltzmann
sampling engine not a quantum one in
that case you can dramatically improve
the results of even mainstream
applications like ray tracing so if you
could get a further improvement still
thanks Barney for that example that's
not under the credit for that submarine
goes them
this could be a big widely applicable
area I think Boltzmann machines in
general have menus nearly as much as
they could simply because they're so
computationally inelegant on a single
processor now oh I want to go let me let
me come back to this original section so
the point of this was in native sampling
and in a bunch of areas a quantum
computer might get to an answer with a
sparse or data set or more quickly or
both and more accurately so this is
really exciting a lot of areas we're
reducing the amount of training needed
to bootstrap the algorithm is pretty
exciting and so here is some results
from yesterday there just just came out
and the application was to go back at
the data set that certain gathered
looking for the Higgs boson so you know
we have all this data with a quantum
computer have found the results more
quickly and amazingly they found that
going on a much smaller data set if you
looked at it by the way I mean this
graph notice that it's say 10 to the
third power so between the point one and
the one this is like a thousandfold
improvement you the curve that gets up
more quickly up on the lower error rates
is the one that's used in quantum
samples you can take arguably a
dramatically lower sample set to get to
the same results are better no oh it
accidentally covered up the there's a
little formatting area there sorry about
that
okay let me just end with something
that's really interesting to me as a
generalization of the power of all of
these systems so if you look at
everything in the blue boxes and some of
these are very of course familiar to
everyone in the room biological
evolution you know traditional plain old
evolution as well as artificial
evolutionary systems directed evolution
of sometimes using microbial design if
you look at 7-liter tammana that stephen
wolfram wrote about a little picture on
the top right there remind you so a tom
is a very simple piece of math applied
iteratively over and over and over again
to generate in some cases very complex
and non repeating patterns genetic
programming a field that came and went
my ship it'll come back but it literally
involved mating and selection pressures
on pieces of code that would cross swap
with each other and it sends program a
solution that in my opinion had the most
application and that little things like
that little antenna that looks like a
bent up paperclip it actually flew on a
NASA satellite it was the most efficient
antenna at a particular task
Euler you know passed an English
frequency no engineer can understand why
it's a good incentive they can't learn
from it all I know is that using a
generative process they can generate
antennas over and over again that exceed
human design they can also do it in an
analog chip design where you have a
number of resistors capacitors inductors
what combination of these let's say
might make a bandpass filter or whatever
you're trying to design and they've
actually generated patented results that
exceed human design capacity and the
thing that that method uses just to
explain one of the bible evidences you
have a very easy testing mode is this
circuit like in a similar you can
simulate does this circuit do what i
wanted to do or not how good is it at
that great you can test all day long the
generation part what is the circuit that
would give me the features I want no one
knows
so you either use human design in some
case you can pencil it out or you use
these generative methods it basically
tests millions and billions of
variations and slight permutations you
get to the design space that's unlike
anything human its design before and the
lots of general design is the animated
gif that you're seeing there Autodesk
and others have realised that you apply
some of these methods more broadly to
manufacturing in general you can come up
with stronger things like a motorcycle
trust in this case or an entire dune
buggy or a bridge then anything a human
is designed but you look at them it's
it's striking in a number of ways hey
they're almost all organic looking as if
it grew out of some garden be the a
little hard to manufacture in many cases
with modern methods you think in many
case you have to go to a 3d printer to
make these things but you could
constrain the general space they have to
say well what if I only had straight
beams and connectors and you can give
you sort of tinker tinker box like
things that just job as well again
better than human design
now the reason I'm listening all these
is that I think all the iterative
algorithms the deep learning no network
service is an iterative and right matrix
multiply in a back propagation gradient
descent all these things are do some
simple math over and over and over again
and in the complexity of billions of
these things eventually trillions of
these things you get the emergent UT of
what we are all here today to celebrate
but I think there's something to realize
that what they all have in common the
artifact of creation is inscrutable as
to its inner workings so I think when we
for example use deep learning to grow
and artificial general intelligence and
AGI which we'll talk about more in the
afternoon that's perhaps comfortable and
complexity to the human brain it'll be
easier to build a new one - than to
reverse-engineer its of workings I think
we'll build an artificial general
intelligence that exceeds human
intelligence before we ever understand
the human brain itself reverse
engineering and on brain is more
difficult than building any one and you
see that in small cases today throughout
the industry but the practitioners in
this field have a tough time sometimes
integrating of the west of rest of the
development environment where engineers
ninja managers say well how do you know
it works tell me how it works and I
don't know how it works I can tell you
how I made it and say I make better one
next time the locus learning switches
from artifacts of creation to the
process of creation and it's so
different from normal engineering
modalities it's not like the Germanic
approach of it does what I say in any
variation from what I say is a bug right
this new design modality is more like
parenting right you don't go in and
tweak the neurons your teenager the best
you can hope to do is a better job
parenting next time around you know and
that's this long game that takes years
and decades but we get slightly better
culture evolution and what-have-you we
gonna get better over the eons and then
this task but you don't go in and ever
imagine me to tweak the artifact on a
sometimes e-bill conflating those they
imagine that they're gonna grow an
intelligence there's something that
feels like deep learning and then when
they're done looking to cut and paste on
the subcomponents no no it'll be like an
alien intelligence defined by its
interfaces and all the beauty within is
as inscrutable as the brain so I think
for a lot of reasons that metaphor is
important and I'll leave it at that
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>