<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NVIDIA's Artificial Intelligence GPU Revolution - TITAN V - GTCJapan keynote | Coder Coacher - Coaching Coders</title><meta content="NVIDIA's Artificial Intelligence GPU Revolution - TITAN V - GTCJapan keynote - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NVIDIA's Artificial Intelligence GPU Revolution - TITAN V - GTCJapan keynote</b></h2><h5 class="post__date">2017-12-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/tWReDtkt-YE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm a visionary exploring a universe of
data to sharpen our view of the most
distant galaxies
in studying black holes to help prove
Einstein's theory of gravitational waves
I am a healer
finding a range of diseases in a sea of
data
identifying lung cancer earlier
and fewer false positives
and finding new ways to bring cures to
market faster
I am a helper
empowering the disabled in their homes
and breaking down barriers she's so
beautiful
who is she across languages and
generations I am a protector
keeping our data safe
criminals
and helping the lost
to find their way home
I'm a navigator mapping our world one
millimeter at a time
and making even the largest self-driving
vehicles
I am a teacher Annalise
half a million player moves every game
to identify strengths and weaknesses
and a learner
discovering new strategies from complex
games
I am a creator learning to paint from
the Masters
and applying their styles to create
original works of art
I am even the composer of the music
you're hearing
by Nvidia deep-learning brilliant mind
ladies and gentlemen please welcome
nvidia founder and CEO jensen huang
ohayo gozaimasu I love coming to Japan
great people great food great culture
great ramen I love coming to Japan thank
you for all thank you all for coming to
GT c GT c is for scientists researchers
and Vela pers whose work is so
computationally demanding that it is
impossible to achieve with normal
computers they seek out our style of
computers because it gives them an
enormous boost in the capacity and the
performance of the work that they do
over the last several years as cpu
performance has begun to slow and yet
the computational demand of their work
continues to grow GT c has expanded and
exploded in just the last five years
attendance of GT c has grown by a factor
of 10x it is now a global event the
number of developers of GPUs has grown
by a factor of 15 times in just five
years and in fact the developer
architecture the computing architecture
we created twelve years ago called CUDA
and it's SDK has been downloaded
millions of times and just this year two
million times there's no question there
is a computing movement in front of us
and yet we know that new computing
architectures and computing proaches
don't come together very often it is in
fact extremely rare and the reason for
that is because developer investment and
the entire industries in vex investment
behind a new computing architecture is
incredible and that's why new approaches
and new computing architectures don't
come along very often the
it has to do is deliver extraordinary
performance if the performance that it
delivers is only incremental then it is
better of course to just wait for the
next generation of computers it has to
have sustainable capability that we
developers in the industry needs to
realize it needs to trust that every
single year and every single generation
this performance advantage is
sustainable and will continue it is only
then they're willing to invest importing
and developing their architecture now
hundreds and hundreds of important
applications have been developed
developed for our CUDA architecture
they develop for CUDA because the
performance is excellent they develop
for CUDA because they realize that every
single year without any additional
effort the performance of their
application will continue to grow and
more importantly and the most important
is they realize that this architecture
is literally everywhere so that their
customers the people by which they write
the applications for can access the
incredible work that they do they need
to know that this application can be
accessed the investment that they made
can be accessed in every single country
from every single computer maker in
every single computing form whether it's
cloud datacenter supercomputer or just
PCs getting all of these things working
together until it creates a positive
feedback system so that more
applications drive more computer makers
to make available this architecture so
that more users can benefit from it
this flywheel
happen very often in fact this flywheel
and this positive feedback system that
is driving NVIDIA GPU adoption this
flywheel hasn't happened in 30 years
today
the computing model that we used largely
is still based on CPUs with the
exception of what's happening at GT C
the driving force behind the GPU that
made all of that happen is computer
graphics real-time computer graphics
real-time computer graphics has two very
important characteristics that comes
together in a very powerful way the
first is that computer graphics is
computationally unbounded it takes an
enormous amount of computational
horsepower to create an image so subtle
so beautiful that we believe it's real
it is basically recreating virtual
reality it is basically doing physics
simulation the ultimate scientific
computing application
simulating physics generating a virtual
reality that is so beautiful that we
believe it's real and yet the second
characteristic about computer graphics
is that it is an enormous ly large
market usually high-performance
applications are small markets and low
computational requirement applications
have large markets it is very very rare
that the two of them come together in
this unique way computationally
unbounded on the one hand enormous
market size on the other hand the
combination affords us enormous R&amp;amp;D
budget to advance this computing form in
fact today
no processor in the world can afford the
level of R&amp;amp;D budget that we invest in
any single generation billions of
dollars could be invested into this
NVIDIA GPU because the market size is
enormous and because the computational
demand is utterly unbounded computer
graphics has come a long ways since we
started today
Nvidia pioneers and we are at the core
of what defines modern computer graphics
from material simulations beautiful
lighting and shadows the reflections
modern computer graphics is nothing
short of astounding and yet what we
really want to do is do this completely
in virtual reality so that we could put
ourselves into this world virtual
reality has been the holy grail of
real-time computer graphics for a very
long time in order to achieve virtual
reality the performance has to be
utterly incredible because the moment
you move your head you need all the
pixels to move instantaneously you need
to be immersed in an environment that
you believe to be real and so what we
decided to do was to create the world's
first holodeck the NVIDIA holodeck but
the Nvidia holodeck has several
characteristics the first thing of
course is that is physically modeled
physically modeled means the materials
are physically modeled the surfaces are
physically modeled of course all the
geometries are physically modeled the
lighting systems physically modelled so
that it looks as real as possible the
goal is not to make it just look
beautiful it has to be beautiful but the
goal is to make it also look real it has
to fit has to simulate the laws of
physics when you touch something you
have to feel like you're touching
something when you drop something it has
to fall to the ground because in virtual
reality like it is in reality you have
to believe that you're touching and
feeling and engaging and interacting
with something that is real you want to
be able to share this world with a lot
of people that are completely in
different places virtual collaboration
the first example of virtual presence
people from different places around the
world can come together in one place and
feel like they're there together and
then lastly it has to have AI in this
future in this future
some of the characters will be real
they're your friends and colleagues from
another from faraway places and some of
the characters in this world will be a
ice maybe it's a robotic assistant maybe
it's just another character wandering by
having AI in this world helping us
collaborating with us allows us to
create just anything we can imagine and
so with that let me show you the NVIDIA
holodeck hey guys John hey guys hi Sean
how you go
hi Johnson and everyone welcome to the
holodeck okay hey guys so just like well
introduce yourself first of all who's
who I'm Sean I'm right here in the mesh
on and this is Kyle hi Kyle all right
and I'm Yuka here and you guys could be
of course you guys are all here in Japan
but you can be anywhere isn't that right
absolutely you can be anywhere and you
could be together in this place and when
you're in this place together you can
interact with each other hey give each
other high fives it's okay of course
they feel like they're inside this
environment together shunt show us what
you have in the holodeck for us sure
well I mean first it's a holodeck so it
can be any place in any environment we
could possibly imagine we've built a
laboratory here so that we can explore
objects with realistic Lighting's and
shadows and get a real experience and
real feel for a design let's check out
what we can do what we can show off
so this is a Alexis and it's the first
luxury coupe
from Japan Wow it's beautiful let's take
a look inside Kyle why don't you hop in
the driver seat there
sure so using MDL we're able to define
mathematically how light should interact
with the different properties of
materials so that our car paint looks
like rich car paint with multiple layers
of clear coat and base coats and
metallic flake that's appropriate if we
go to the interior Kyle can see some of
the details of the the leather and the
other finishes that really make this
design pop and so of course you could
imagine designers and engineers working
together on a major project together and
they don't and because these are these
are amazing products and they're heavy
products it's hard to transport them all
over the world would it be amazing if
the Lexus is in a virtual world called a
holodeck and all of the engineers and
designers can come together and just
talk about it and enjoy it together so
that's some beautiful graphics but let's
explore with something that's pretty
unique to the holodeck using our x-ray
vision we can take a look inside of the
car to see the beauty that's underneath
wow we have the entire drivetrain all
the mechanics of the system's detailed
out so that we can really explore it but
let's take a closer look at the engine
now here's the thing about the greatest
thing about virtual reality sometimes
you wouldn't want it to Abbaye the laws
of physics sometimes you don't want it
to obey the laws of physics and now you
have x-ray vision you're like Superman
absolutely hey you go could you pop the
hood for me please sure here you go
great now my favorite part of the
holodeck is this is way easier to do
than would be in real life now ladies
and gentlemen what you're looking at is
actually the entire design database of
the Toyota Lexus so every single
geometry is inside this design now of
course this is
not a video game we've seen video games
before and video games can be very very
beautiful
however video games are fake it's not
useful for design holodeck is designed
in order to make it possible for us to
really create real products inside and
we can go deep inside of how the
mechanics work as well we can take all
this engine apart select an individual
component and see what it does how it
fits together with the other suit parts
of the system and what makes this system
really work Sean do you know what it is
oh this yeah yeah this is the crankshaft
oh thank shopped it transfers the energy
from the combustion engine into the
movement through the transmission may I
take a look of course okay oh you're
very strong I am well let's clean up our
mess a little bit here
that's incredible and so ladies and
gentlemen the nvidia holodeck and what
really makes it special give it a second
hey guys thank you very much well hang
on a second hang on a second and so so
what really makes makes the holodeck
special is first of all it ingests it
takes in the original design database of
the product in all of its incredible
complexities it obeys the laws of
physics unless you don't want to obey
the laws of physics it has the ability
to render the materials so physically
accurately that it looks like the real
material that leather looks like leather
bless you leather looks like leather
brushed aluminum looks like brush to
them steel looks like steel and car
paint looks like car paint beautiful
headlights look like beautiful
headlights the computer graphics is
physically accurate and then lastly it
is has the ability to support virtual
presence so that engineers and designers
from all over the world can come
together in this one place and gives you
the sense of virtual presence hey thanks
a lot guys you did a great job thank you
thank you I'll be the same sound all
right so ladies and gentlemen the NVIDIA
holodeck we can accept design databases
from CATIA and Siemens and Creon alias
you imported into the the CAD design
package is then imported into the
styling package DVD yes max or Maya then
it's imported into the holodeck these
are all industry standard tools with all
of the industry standard formats as a
result almost anything can be imported
into the Nvidia holodeck once it's
imported into the Nvidia holodeck you
can have virtual reality experiences
that are far and wide apart and so that
engineers and designers can come
together in this environment and share
it managers could then look at this
design and be able to make trade-offs
trade-offs and what is try different
materials and different wheels and who
knows one of these days we'll be able to
use this to even purchase and design
your own car
the Nvidia holo
Dec the computer graphics industry with
its sustain with this incredible
computational unboundedness this
incredible computation demand is such
enormous market size is what created the
GPU and that GPU is the world's most
advanced parallel computing processor
and then one day in the year 2012 in the
year 2012 three things came together
which ignited the modern Big Bang of AI
and those three things was created as a
result of a young researcher whose name
as Alex Khrushchev ski at the University
of Toronto experimenting with deep
neural nets running on a GPU and he
submitted his results to the imagenet
contest the cvpr contest and as a result
he won the computer vision image
recognition contest of 2012 the
achievement is utterly unbelievable and
it's utterly unbelievable because he has
no special training in computer vision
and in one single stroke he was able to
defeat decades of computer vision
experts with image recognition using
computers to recognize images the
network is called LX net by today's
standards it is absolutely tiny
however in year 2012 it was the single
best computer vision algorithm the world
has ever seen now it uses a technology
called deep learning and deep learning
is something that almost everybody has
heard about since in the last five years
and has swept the computer industry deep
learning has been invented decades ago
in fact however it has one enormous
handicap
it's handicap is that it requires an
enormous amount of data to train the
network and it's a large network with an
enormous amount of data to train and as
a result it needed supercomputers with
weeks and weeks of computation time in
order to
train and develop that software and has
prohibited deep learning from becoming
effective until the advent of the GPU
the GPU discovered researchers all over
the world discovered around that time
that using Nvidia CUDA GPU could train
their deep neural nets in a very short
period of time a short period of time in
2012 was about a week's time literally
out computer would develop software by
itself running calculations after
calculations after calculations for one
week's time
the final network was the best computer
image recognition software the world had
ever seen
the effective effectiveness of deep
learning was realized the power of deep
learning is that the more data you give
it the greater the network and the
greater the computational capability the
greater the effectiveness now that we
realize the power of deep learning we
can invest and build ever more complex
networks gather more data and build ever
faster supercomputers that three
combination the three combination deep
networks larger networks more data and
more compute the combination triggered
and ignited the Big Bang of modern AI
and the effectiveness continues to grow
since then amazing things have been
achieved we've now Wreckage superhuman
recognition of images computer vision
recognition has now surpassed human
abilities we can now achieve superhuman
abilities in speech recognition what
goes in as spectral information of sound
can be interpreted into natural language
what goes in as just an image could be
recognized with objects and detected in
the image in
recognition speech recognition and so
many other examples that I'm going to
show you have now achieved superhuman
levels really really incredible this is
this software technique that I've
simplified here has profound impacts on
the industry and is the reason why we
have dedicated our entire company our
full resources to advance this computing
field and build the AI computing
platform for the industry this year our
engineers our partners all over the
world have been incredibly busy
the Year Volta Volta is the first GPU
that was architected from the ground up
to fuse numerical computational
approaches with deep learning approaches
for the first time it introduces a new
type of instruction called tensor core
and as a result was able to achieve a
computational throughput for deep
learning that has never been imagined
before a hundred and twenty-five
teraflops of deep learning training
performance from just one chip it's
built from twenty it's built from twelve
nanometer FinFET 21 billion transistors
HBM to memory 3d packaging Volta which I
have one right here
Volta is the most complex chip the world
has ever built
over two billion dollars of our D
necessary to build Volta this year Volta
was announced and it is now in full
production at the Nvidia Volta a hundred
and twenty-five teraflops of deep
learning tensor core operations per
second the Volta processor is also
incorporated into a new type of
supercomputer this processor is
incredibly complex and to build
supercomputers based on this processor
is also complex and so what we've done
is we've integrated all of the
complexity into a simple appliance to
purchase a DG X as well as the DG x
station a DG X is the world's first one
pedda flops ai supercomputers one
petaflop s' inside just one box all
fully integrated with eight Nvidia
vultus connect it with MV link which is
ten times the bandwidth of PCI Express
all integrated with software all you
have to do is take it out of the box
plug it in and your AI researchers can
be productive instantaneously DG X we
also put Volta in every single cloud
every single cloud service provider has
adopted Volta every single computer
maker in the world has adopt a Volta
because they all recognize this enormous
opportunity contribute to the future of
artificial intelligence they all
recognize the enormous market
opportunity of artificial intelligence
every single cloud every single computer
maker the software of deep learning is
incredibly complex you're talking about
software that is essentially running on
multiple GPUs multiple servers and it
runs for days if not weeks at a time it
is the largest computational problem we
know today this software stack is a
high-performance computing software
stack and there are so many different
types of framework
framework is a artificial intelligence
neural network development system there
are so many different frameworks in the
world and so what we decided to do is
optimize integrated and performance
tuned every single framework every
single layer of software integrated on
top of our Volta and we containerized it
and put it in the cloud every one of
these software stacks incredibly
complicated performance optimized we've
containerized and we put it in a cloud
registry we called the NVIDIA GPU cloud
the NVIDIA GPU clout is not a cloud
service it's a cloud registry it's a
container it's a store it's an app store
if you will of deep learning frameworks
software that cloud ng see each one of
the containers are virtualized and these
virtualized software stacks can run on
every cloud and they can run in every
server so that the Nvidia architecture
could be hybrid cloud it could be on
Prem or it could be multi cloud and GC
container eise's all of this complicated
software and put it into a cloud
registry from training the software this
year we also announced tensor RT for
inference the software once you're done
did once you're created the neural
network you can ask this neural network
questions what is this what did I say
where is the car you can ask it
questions asking the artificial
intelligence and network question is
called inference the computational graph
that comes out of these frameworks are
incredibly complex the computational
graphs are enormous
we created an optimizing compiler called
tensor RT that takes the computational
graph from the frameworks
and compiles it for all of our products
all of our processors volta pascal dgx
servers cloud and we introduced a brand
new product just last week at nips this
is a GPU the voltage GPU developed for
researchers we call it the Titan V let
me show you to you the Titan V is the
most powerful PC processor the world has
ever created ladies and gentlemen this
is the Titan V the Titan V it's
available online it's available online
now for three thousand dollars two
thousand nine hundred ninety nine
dollars 110 teraflops peak nearly ten
times the performance of the highest
performance GPU in the world today
called the Titan X the Titan X was based
on invidious last generation Pascal this
is based on Volta and this is now
available for researchers all over the
world and so now the software container
NGC will run on Volta go to the cloud
whatever framework you use register for
the container downloads it does
complicated software stack and now
you're doing AI development when you're
done with that AI development
you could run ten so RT and it will
optimize the software and make it run
lightning-fast let me show you what it's
like to run deep learning on Nvidia's
Volta thanks Paul
so we the tensor RT takes this
computational graph and runs it through
an optimizing compiler and outputs a
Volta CUDA program this Volta could a
program was written by software so
software wrote software and this Volta
could a program for a deep neural
network could predict many things
depends on what you taught it to do the
performance that we've been able to
achieve is nothing short of amazing if
you were to use tensorflow which is
google's AI framework and take the
output and run it on the fastest cpu
four images per second ResNet which is a
relatively small network is a hundred
and forty images per second on V 100
with ten so RT is five thousand seven
hundred forty times the speed up for
natural language translation from
English to Chinese from English to
German Germans to French all these
different natural language it's called
open nmt natural machine translation a
CPU runs at four sentence per second and
V one hundred with ten so RT a hundred
times faster now looking at bar charts
is very impressive however ultimately
what you buy our servers this is what it
looks like when you want to run 45 from
thousand images per second now remember
45,000 images per second is not that
much and the reason for that is because
you have mobile customers all over the
world you have mobile customers all over
Japan and they're maybe doing a image
recognition request they're looking
taking a picture and say what is this
product I want to buy it
millions of people are using their cell
phones at the same time and so 45,000
images per second happens all the time
and with 45,000 images per second it
would take a hundred and sixty CPUs and
sixty-five thousand watts to achieve
okay a hundred and sixty CPUs sixty-five
thousand watts that's basically four
racks
one two three four racks so four racks
of servers would allow you to inference
predict recognize forty five thousand
images per second well if you were to do
that would volta it would look like this
what it would look like with Fulton with
invidious Volta all it would take is one
server one server with eight GPUs inside
45,000 images per second and it only
consumes 3000 watts 3000 watts one-sixth
the cost 120th the power for racks for
racks in just one box
the more GPUs you buy the more money you
save that is the best technology in the
world
so please tell all your friends the more
GPU you buy the more money you save so
share it with your friends tell your
family it's Christmas time the more GPUs
you buy the more money you save very
simple equation so old way new way all
the way new way
okay so bar chart you cannot feel it
this you can feel the servers but now
let me show it to you this is what it
looks like
hey Ryan are you back there and let's
show them tensor ort so this is the this
is the miracle this is the miracle of
deep learning first of all these are
flowers of course you recognize that
these are flowers but very few of you
can recognize exactly what the flower is
remember the computer only sees ones and
zeros from the ones and zeros from the
ones and zeros the computer has to
figure out what first of all that it's a
flower but more importantly what kind of
flower it is it's a Ryan let's take a
look at this what flowers are we looking
at okay so that's a pin cushion flower
that is a love in the mist okay
that's a water lily I knew that and
that's bromelia and that is a clematis
these are flowers these are words that
has never left my mouth before and yet
this software can recognize these
flowers they were trained to recognize
these flowers and now for flower
recognition this software this program
has achieved superhuman levels I can
recognise the flower but I don't know
what it is now this is a CPU this is the
latest generation CPU is running at
about five images per second five images
per second
that means that means five different
consumers on their mobile phone can
request
what is this flower and in one second in
one second this CPU will return the
results to those five people but as you
know how many people are in mobile cloud
there are millions and millions of
people there are billions of people in
the world with mobile cloud capability
so this performance is obviously not
fast enough
we need much higher throughput and so we
have a solution for that Ryan let's take
a look at what it looks like with Volta
you might notice this is resident 152
this is a much more complex deep neural
network the other network that I showed
you in the benchmark was resident at 50
which is 50 layers 50 layers of deep
neural net I think alex net only had
about 12 the original alex net that was
able to beat every defeat every single
computer vision engineer in the world
had 12 layers i think something like
that eight layers eight layers okay
eight layers even less than 12 this
ResNet 50 that i showed you in the
benchmark has 50 layers this neural
network has a hundred and fifty two
layers each one of these layers
increases the ability and the accuracy
of the software to recognize images and
now with Volta we are running resonant
152 at 913 frames per second 913 frames
per second basically almost 200 times
faster almost 200 times faster the
larger the network the greater to speed
up the greater the advantage of the
voltage GPU but this is just one Volta
what you're looking at is this this one
chip this one processor is making it
possible for us to predict for 900
people in one second the object they're
looking at imagine if we could scale
this up further Ryan
this 7000 images per second is running
on 8 voltage GPUs so what you're looking
at is this this box right here this is
the nvidia d GX 1 there are 8 volt Eze
inside this one box this one box is
doing this for seven thousand people for
seven thousand people another way to say
it is it only takes 1000 boxes 1000
boxes for seven billion people
unbelievable unbelievable the more GPU
you buy the more money you save okay but
the amazing thing is this this is what's
amazing
remember this is two thousand this is
seven thousand and the original back to
the CPU
take your time and so so the
this.remember 7000 is that one box one
CPU one CPU is five two CPU which is one
server node is ten one server node
versus one dgx seven hundred times
slower seven hundred times let's divide
that by forty four simple math because
each rack of server is somewhere between
thirty to forty so 20 racks one two
three four five six seven eight nine 10
11 12 13 14 15 16 17 18 this entire
stage replaced with one dgx the more
GPUs you buy the more money you safe
okay that thank you it's very simple
several billion dollars of Rd enormous
amounts of invention the more money you
save okay and so that's volt Ryan thank
you very much
anytime computer vision was the first
computer vision image recognition was
the first great breakthrough of deep
learning and and inspired everybody to
think about what is what else is
possible we were so fortunate in our
company to recognize the potential of
deep learning and several years ago we
started to invest and started to do
research and deep learning all over our
company first we created the platform
that allows us to have the most powerful
platform most productive platform that's
literally everywhere for deep learning
researchers but we used to platform
ourselves to advance deep learning so
that we could see what are the
unsolvable problems what were the
previously unsolvable problems that we
can now solve it is so exciting that for
the first time in all of our careers in
30 years time
we now see this new tool this incredibly
powerful tool that allows us to solve
problems we simply could not imagine
solving before now this is really an
amazing thing this is ray tracing this
is a form of computer graphics that
creates photorealistic results it is
very very slow even on the fastest
supercomputers it's called ray tracing
and global illumination what you're
looking at here is on this side each one
of the pixels are slowly being rendered
as the raised bounce off the surfaces
eventually comes to our eyes but there
are many black dots the black dots is
the photon has not reached it using
artificial intelligence our Nvidia
researchers were able to predict to
predict what is the right color what is
probably the color of that dot and as a
result we can complete the image almost
instantly second Nvidia research worked
with remedy a game developer to do
something that is really really hard to
do to create animation computer
computer-generated animation that looks
like they're talking but unfortunately
there's so many things that we say and
there's so many different types of faces
how do we teach computer graphics
animation to speak and to look like it's
speaking so we developed the network
that allows us to use audio to
automatically generate the appropriate
animation of the face nasa konichiwa GTC
chip hi Yoko so okay no kotoba dkdt
Mosca no kata TTC Silicon Valley no at
all you know do tone insisting my stop
all this cuff mucking up - all finished
mo Jenson saw no College up qui this net
every single phrase you give it the
character will animate in a new way
because it has learned how to animate
properly this is using computer graphics
using computer graphics first to create
a scent segmentation of semantics what
is the meaning of every single pixel and
from the meaning of the pixel we will
generate a photorealistic image so
computer graphics generated image input
the output is photorealistic images okay
so first we start with computer graphics
every single pixel has been given a
meaning otherwise known as semantics
what is that pixel this is a pixel of
road that's a pixel of car this is the
orientation of the car this is a pixel
of tree this is a pixel of people and
the background the gray is pixel of
buildings and for each one of those
pixels you can see there's an
orientation opposed the pose of the car
the pose of the people from that we gave
that input to an artificial intelligence
network and the network has to draw to
image to generate a photo realistic
image unbelievable right okay so let me
just show you this is the input we use
computer graphics to generate a
segmentation and the semantics map from
this map we create a photorealistic
image the artificial intelligence
network drew this image by itself
the artificial intelligence network
generated this image by itself this one
next one is just incredible this next
one this next one most artificial
intelligence network called a Gann which
is a breakthrough by a researcher called
Ian good fellow Gann starts for
generative adversarial networks it's
basically a neural network that knows
how to create the future create
something in this case we ask this
neural network to create an image
unfortunately gans are very difficult to
control
if the Gann is too bit began is too
small the resolution of the image is too
coarse however if the resolution
requirement is very high and the Gann
Network is enormous then the stability
of training is very low this balance was
very difficult and Vidya invented this
new gang called progressive man the more
you train it the larger the network
becomes and it's eventually able to
generate every single pixel of this face
we then take celebrity faces and we
trained our network to generate new
faces these faces do not exist these are
not real faces these are artificial
intelligence generated faces an AI
created this face and it created these
faces
single near every single image every
single pixel was drawn by an artificial
intelligence network
pretty beautiful huh not only is that
realistic
photo real the resolution is incredible
and it's very realistic using artificial
intelligence we can now generate and
create artificial humans we can use
artificial intelligence to make the
artificial humans talk and we can put
them into artificial intelligence
created worlds incredible what do you
guys think artificial intelligence was
responsible for the introduction movie
music that you guys heard it's called
Imai we created recently a new piece of
music as you know it is Star Wars time
and I understand I have tickets for
Tuesday night I'm so excited to go see
it artificial intelligence was used to
do something very special here what we
did was this IVA and Nvidia worked
together on a neural network that was
that learned the composition techniques
of traditional classical great composers
Mozart Bach Beethoven it learned
classical music so it recognizes it
knows how to generate the next note
given previous notes what the
appropriate next note would be for
classical music then we gave it some new
artistic styles and the artistic style
we gave it was John Williams I selected
several beautiful pieces of scores of
John Williams and with John Williams the
scores we additionally trained and we
biased this network to generate what
something that John Williams might
create this what I'm about to show you
is an original piece
never heard before score generated by
artificial intelligence this original
score is then given to a symphony and a
symphony we worked with is John built
the famous John Beals in Hollywood
Symphony Orchestra and he arranged and
conducted what you're about to see this
score is an original piece completely
created by artificial intelligence and
joy
John Beale and the Hollywood Symphony
Orchestra
what do you think incredible right
artificial intelligence was able to
generate this beautiful music and
working together with human Orchestra we
could bring it to life this is the
future of software this is the future of
computing where computers could write
software by itself that is so
complicated no human could possibly be
imagined writing and by working with
humans it makes possible new realities
our mission first mission first and
foremost is to create a computing
platform that is powerful for training
and inference that accelerates every
single framework that's available in
every single cloud on Prem and from
every single computer maker and just one
architecture one architecture so that
all of your investments in software will
be leveraged across this entire base of
platforms one architecture so that every
computer maker can put their full might
behind this architecture and know that
there's a large market for them and one
architecture so that all the work that
we do today will continue to benefit
tomorrow and the day after and the day
after the work that we do today will
just get more valuable every single day
because the architecture will continue
to be backwards compatible and the
architecture will continue to grow
one architecture the NVIDIA AI platform
NGC all the software in the cloud and it
can run in every single cloud it is
multi cloud Amazon Google Azure Baidu
Alibaba $0.10 every single cloud it runs
on Prem and it runs on the Titan V in a
PC the most pervasive AI computing
platform in the world
ai is the most powerful force that all
of anyone has seen in all of our careers
and I feel that it is also the most
powerful technology force that has the
benefit that finally the benefit of
revolutionising the industries of Japan
I've had the benefit to see the server
revolution the workstation revolution
client servers to pcs to mobile to cloud
but pcs can't help the car a cell phone
can't help robotics and the cloud can't
help large heavy industry construction
Japan is the land of robots this is the
land where the country become the
companies the leaders of this country
are the world leaders in transportation
the world leaders in manufacturing
robotics the world leaders in heavy
industry and heavy construction
and surely applying the robotics
technology to the future of healthcare
whereas the IT industry moves bits the
industry of Japan moves people and it
moves earth very large challenges the
fundamental technology necessary for
these industries as it turns out is not
PC it's not mobile it's not cloud
they're all important but the
fundamental technology that's necessary
is artificial intelligence and that's
why I am so incredibly excited now for
the future that's the reason why this is
such an incredible time for Japan this
is the golden ages of IT technology in
Japan and we're incredibly honored to
partner with some of the best technology
companies in Japan the most important
companies in Japan let me introduce you
to some of the work that we're doing we
partner with Fujitsu the number one
computer company in Japan
Yoshi's ass on the head of zen rai has
worked with us closely to adopt the
nvidia Volta into the Fujitsu servers a
heritage of supercomputers the largest
IT company in Japan is now with 200,000
professionals serving this nation we're
now partnered with them to bring the AI
the NVIDIA AI computing platform
throughout japan ntt communications is
the number one cloud service provider in
Japan has now also made available Nvidia
Volta the NVIDIA GPU in their cloud
the advanced industry advanced industry
Science and Technology Institute a ist
responsible for some of the great
breakthroughs in collaboration between
science government and industry has
adopted the Nvidia architecture to
create the highest performance
supercomputer for AI in the world 550
petaflop s-- almost one exaflop it is
the closest computer to 1x of flops of
computing for AI 0.55 XO flops exa flops
XO flops exascale computing we thought
would not happen for another many years
and now a IST partnering with us to
build the a BCI supercomputer Sekiguchi
sun is leading that effort in amazon and
i dr novice on and i announced last year
that fanuc the world's leading
manufacturing robotics company would
partner to create a new type of AI for
manufacturing phone Oakes famous field
system is now infused with AI so that it
could predict downtime in advance so
that customers has zero downtime that
has the ability to teach robots how to
bin pic and has the ability to detect
surface very minor surface defects if
long before it affects the products
Fanuc
with field incorporating AI is now
powered by the NVIDIA GPU it was
announced and shipped just this October
incredibly proud of the work that we're
doing there
PFN preferred networks
a young startup with a genius CEO
nishikawa's on who was working on AI all
over it all over Japan and created an
excellent framework called chain er
chain er has been able to train a neural
network in 15 minutes across 1,000
nvidia gpus distributed training was
able to create and train this newer
network in literally 15 minutes the
amazing thing is this neural network the
resonant 50 would have taken that one
month just three or four years ago just
three or four years ago it would have
taken one month and now with all of our
collaboration the advancement of NVIDIA
GPU computing were able to now bring
down the training time to just 15
minutes the power of doing that is
really profound as a result researchers
could iterate and explore new ideas more
quickly but one of the most powerful new
ideas is to use a is to create a is
using AI to create AI so in the future
there will be another AI that sits on
top of these frameworks and it will
invent new forms of AI that is then
trained and tested for effectiveness so
the fact that we can take training time
down to 15 minutes is an incredible
achievement and we need it in our
partnership with PFN also resulted in us
putting the PFN chainer Network fully
optimized fully tested and containerized
and now put on the NGC the NVIDIA GPU
cloud
rasaan and his researchers at University
of Tokyo had doing some amazing work in
fact the researchers here in Japan has
contributed 55 groundbreaking works into
AI this last year and she moves on and
his team did something really quite
amazing this is one of the futures of
scientific computing where scientific
computing numerical computing physics
based computing is fused with machine
learning physics based computing first
principle based computing algorithmic
computing
can accelerate the discovery of new
science Ichimura science work is related
to earthquake simulations it takes a
long time to simulate an earthquake but
combining and fusing to these two
approaches and using NVIDIA GPUs they
were able to accelerate their training
time their discovery time dramatically
there's so many startups here that we're
working with some 60 startups here in
Japan 60 startups from PFN to a bj who's
also developing a deep learning
framework X Excel wizard Excel wizard I
think it's an exoskeleton company that's
teaching robot robots how to articulate
L pixel for medical imaging there are so
many companies here doing amazing work
many of them doing work in the field at
the intersection of artificial
intelligence robotics and manufacturing
and industrial designs industrial
products industrial machines which makes
perfect sense because that's the
industry of Japan
as you could see AI from the most
important company's computing companies
Fujitsu and entity communications to the
Research Institute AI st to the world's
leading manufacturing robotics company
to AI startups pfn to research
groundbreaking work is being done here
in Japan at this intersection AI and
autonomous machines autonomous and
machines is really the next generation
of AI it's the next step of artificial
intelligence and the first contribution
of artificial intelligence to autonomous
machines will be the self-driving car
the self-driving car is going to change
society completely it's going to make
possible of course cars that are easier
to drive safer to drive we will save
lives but because of the nature of
autonomous cars long-term the car will
no longer be a place that you go so that
you can go to another place long-term
the car will be the place we want to be
in for some time each day we would enjoy
our one or two hours of personal time
inside a car it is our time for
relaxation it is our time for an
entertainment because of the autonomous
car other urban design decisions will
likely change the shape of
transportation and the shape of society
could very well change as a result of
this groundbreaking work autonomous
vehicles is incredibly hard to do
however the impact of society is
gigantic and enormous the problem is
simply stated as the most challenging
computer problem the world has ever seen
it is rich with high dense
high-performance sensors the software
has never been developed at four from
very complex system software computer
vision software artificial intelligence
software the algorithms have never been
developed before this car with this
computer can never fail it's not like
your cell phone it's not like your PC
you can't hit control-alt-delete the car
has to be perfectly safe and it has to
be able to navigate and drive and
operate in such a diverse and complex
world the self-driving car is simply the
most complex computing project the world
has ever undertaken it is also a
software-defined computer the number of
applications that we have to write is
really countless whereas the previous
way of designing cars is to connect many
specific functionalities into a car the
future autonomous driving car the future
car is surely a software-defined car
with a powerful computer a capable
functional safe operating system
incredible algorithms and all kinds of
applications on top the same thing that
happened to the mobile industry when it
went from being a cell phone to a mobile
computer from one application just
camera to thousands and hundreds of
thousands of applications in the App
Store today the same thing will happen
to the car the complexity is enormous
from level to where the car is basically
the autonomous vehicle is helping you
drive but you're in control to a level 3
and level 4 car where the car is in
control whenever it knows how to drive
in those conditions to a level 5 robot
taxi where the car has no driver at all
and its functionality directly affects
the economics of the service and of
course the enjoyment of the users the
range of autonomous vehicles is really
quite daunting and every single car
company every surely every single major
car company has to create the entire
line of cars they need to have a
scalable architecture that allows them
to develop software that is largely
related for a range of cars as the
sensor complexity grows the
functionality grows and of course the
functional safety requirements continue
to grow this entire range of
capabilities has to be developed in an
architectural sense and you have to
think about it from a software level we
created a computing platform we call the
Nvidia drive the Nvidia drive is a
supercomputer on a chip a supercomputer
on a chip and it's able to scale to
level 2 level 3 level 4 to level 5 it is
able to understand the type of
functionality
it could include sensor fusion computer
vision deep learning high-performance
computing in a very small energy
efficient package so that it's able to
perform
all of these different types of
applications at the same time it has to
run them all at the same time in a very
high-performance state so that the car
can be as responsive as possible to all
of the environment around it and it has
to do so from level two with just maybe
front and surround cameras to robot
taxis with tens of cameras and light
ours and ultrasonics and radars all
around the car because downtime is
simply intolerable and so the range of
functionality the range of sensor
richness and as a result the scale of
computation necessary it's really
daunting in this new world of autonomous
vehicles we've been working on this
technology and I want to show you some
of the work that our engineers have done
they've made a home movie for you and so
let's run it
using deep learning we're able to
recognize the world around us what are
the objects we should avoid it also
recognizes what are spaces that are safe
to drive we have to figure out what is
the trajectory of our car using cameras
or using light ours the future
self-driving car computer has to be able
to process sensors of all different
types it has to localize even to a
sensor we call the HD map localizing
allows us to then drive using
computational approaches or deep
learning approaches
you
you
surround perception in all kinds of
different weather conditions rain snow
highway urban one of the powers of
artificial intelligence deep learning is
the ability to Train one network and it
now recognizes the objects around it
ladies and gentleman video driver
autonomous driving will revolutionize
cars but AI will revolutionize not just
driving but also our user experience
remember we now have sensors all around
the car we're gonna have sensors and
cameras around the inside of the car so
this car our future cars will have
contextual awareness of the world around
us and it will have contextual awareness
of us so the question is what can we do
with artificial intelligence computer
vision augmented reality and how do we
fuse those fundamental technology to
change to revolutionize how we enjoy our
car and we think that in the future not
just the inside of the car not just the
outside of the car the functionality in
the car will be revolutionized
but how we enjoy the car and how the car
interacts with us will be revolutionized
the amount of software that we have to
write the amount of software that we
have to write is really quite boundless
and we've imagined several and we've
imagined several applications we could
create and so what we've done is we
created a SDK that fuses the sensors of
the cameras outside the car the sensors
and the cameras inside the car and we
created a brand new SDK we call the
drive IX intelligent experience drive IX
is an SDK that software developers all
around the world could then create the
next generation of user experience drive
X Drive IX includes eye tracking head
posed estimation speech synthesis speech
recognition gesture recognition facial
recognition fundamental technologies
that are then used to create next
generation applications let me show you
some examples this is a this is Janine
Janine one of our employees and here's
an example where she's coming back from
an airport and she's carrying all these
different bags and she could be coming
out of a shop out of us
or and the car Cesar recognizes your
face and opens the trunk of course it
should your car is an AI of course it
should there's other things that it
could do it could just it tracks your
eyes we use artificial intelligence deep
learning and a very special technique
for labeling we can now track eyes very
carefully and so this way we know that
as we come to a stop that somebody who
is crossing the street has made eye
contact with us before we decide to go
further
so wherever she looks we can calculate
an estimate what is the angle of her
eyes and remember we're doing this only
from two-dimensional cameras how do you
predict the path that you're looking at
the orientation that you're looking at
just from a video here we're detecting
that she's being distracted so we wrote
a small application traction distraction
so if you have a car and the car's
driver is required to be in control
distraction we could create an AI that
allows us to remind you that you're
distracted
we can create an AI that recognizes that
you're sleepy and that in fact you
should probably have a cup of coffee or
pull over
this is Jeanine pretending like she's
sleepy so all of a sudden this car is no
longer just a autopilot but it's also a
co-pilot a copilot that watches after
you while you are the pilot in command
and then lastly remember this car has
perception all around it surround
perception and so how many times have
you tried to get out of a car and you
shouldn't have if a car is coming if a
bicycle or a person is coming the car
door simply doesn't open and so this car
is not only driving for you when it can
when a when you're driving it's also
watching out for you and so as you can
see the future car is just rich with
software and we need a we need a basic
computing platform that is able to do
the type of processing necessary for the
future autonomous machine and the
autonomous machine basically has to do
three things it has to do sensor fusion
sensor processing and sensor fusion it
has to do artificial intelligence and
parallel computing artificial
intelligence and parallel computing and
it needs to be able to then take that
information and take action recommend in
action autonomous machines in the future
has these basic capabilities these payza
capabilities is basically a
supercomputer on a little tiny chip much
much more powerful than any computer
that you currently have that you own and
so this new computer requires a new type
of processor and in addition to that
this new computer has to be programmable
because there are so many applications
we can imagine every single week your
engineers are going to create more and
more
more applications you're going to put
them on to the store and you're going to
download it into your car and the car
gets smarter and smarter and smarter
over time so we believe that the future
car is software-defined we believe that
we need to have an architecture that can
run these type of applications and we
believe that we have to create a
computing stack for the industry so I
can take advantage of these capabilities
the first thing that we have to do is to
invent the processor so what we did was
we created a Xavier Xavier is the most
complex chip NVIDIA has ever created
even though this is the largest even
though Volta is the largest xavier is
the most complex the number of engineers
that have worked on xavier to create the
world's first autonomous machine
processor is in the hundreds i'm happy
to say that xavier is coming out of the
fab momentarily and i can't wait to put
in the hands of autonomous vehicle
partners car companies roboticists
autonomous machine makers all over the
world supercomputing capability computer
vision capability deep learning
capability rich with sensor processing
abilities all in just 30 watts 30 watts
of power 30 trillion operations per
second 30 trillion operations per second
incredible amounts of performance we
also created Xavier so that it's a
scalable architecture you could use one
chip one Xavier processor for your super
level 2 which surround perception and
all of the capably O's I've just
described you could also use multiple
Xavier so that you can have more sensors
functional safety for redundancy and
resiliency or if you have tons of
sensors all over the car you could use a
computing platform we call Pegasus with
multiple xavier z' and multiple GPUs in
one computer as you could see the future
of autonomous vehicles is about
supercomputing for real-time processing
of the world
it is a brand new type of computing but
with something like Xavier and the
software platforms we're developing
application developers all over the
world can create the next generation of
magical cars now creating the car starts
with developing the software and even
developing the software is intensely
different for those who are already
working on deep learning you realize
that the way that deep learning is done
is very different than the way that
software development was originally done
in the world of deep learning and here
I'm using the example of a self-driving
car you use 3d simulation to simulate
the extreme cases that the car would
experience we have a training
supercomputer we have a training
supercomputer to train and recognize the
millions and millions of images that we
are going to provide the neural network
we use a supercomputer to regression
test against a large body of tests
before we can release software we call
that resem and then when we're done
the final neural network could be run
and Xavier in the car altogether that
represents the end to end in the future
data is the source code data is the
source code and so it stands to reason
that in the future we need to have a
rich infrastructure to manage to track
to curate to process and to reprocess
terabytes and terabytes and petabytes
and petabytes of data that we will
collect the future of computing is
radically different if you're engineers
and IT department we like to learn more
about this reach out to us I'd love to
talk to them about it this future
computing platform is really worthwhile
to take a look at and we've invested a
great deal in this well this is the era
of autonomous machines the self-driving
car is the first one it's the first and
the most impactful to society of the
autonomous machines we can create but
there's so many more I believe that
every single machinery that moves
we'll have autonomous technology in the
near future it could be an excavator it
could be a plow it could be a truck it
could be a dump truck it could be a
tractor there could be a robotic arm it
could be a little tiny robot that's
helping you manage your warehouse or
delivering pizza to you
delivery pizzas and so all of these
different types of machines in the
future will have autonomous capability
the fundamental computing is the same as
a self-driving car but the application
is radically different the applications
and demands of it is radically different
in many of these types of examples the
actual processing sensor fusion sensor
processing deep learning artificial
intelligence reasoning and then
actuation is fundamentally the same as
self-driving cars we believe this is
going to be the next era of AI and the
opportunity to the market is quite large
four hundred billion dollars autonomous
machines market from manufacturing
agriculture industrial construction to
packaging and processing enormous
markets the future that we imagine
is a world where the entire construction
site in the case of heavy equipment is
completely reimagined we're gonna have
drones in the sky that is scanning and
mapping the construction site every
single one of the heavy machinery will
be autonomous and it would be able to
recognize the world it will use slam to
scan to localize and map its
surroundings and through its surround
perception capability it will keep the
operator it will keep all of the
construction workers out of harm's way
it will be easier to for the operator to
manage this very large equipment and it
would even learn from the operator how
to do certain tasks these future
autonomous machines will extend of quote
extend the usefulness of these
autonomous machines in these very
expensive heavy equipment and also very
importantly improve the safety of
construction sites one of the things
that we're really excited about is the
possibility of course of uniting
artificial autonomous machines with the
work that we're doing with holodeck it
is possible for us in the future to fuse
the minds of machine and people to
literally fuse them together using
virtual reality and artificial
intelligence a person an operator could
be miles away inside holodeck and yet
the operator will think that he or she
is literally inside the equipment in the
construction site the autonomous machine
will scan and beam the world to the
operator the operator will operate the
virtual instrument the virtual equipment
and the commands would then be beamed
back to the autonomous machine in the
field and now the two are fused together
using virtual reality and artificial
intelligence
we could fuse autonomous machines and
humans this future world is really
really exciting and I'm incredibly
excited to say that the leading
industrial equipments company in Japan
Komatsu and NVIDIA are partnering
together to discover this future dr.
Yamamoto the CTO of Komatsu is leading
this charge to invent the future of
industrial equipments to invent the
future of construction mute fusing AI
fusing 3d fusing mapping the type of
technologies and experiences we can
create is really quite exciting so I'm
super excited to announce that we're
partnering with Komatsu a
hundred-year-old company one of the
world's great companies one of Japan's
great companies is now inventing its
future inventing the future of
autonomous machines I'm super excited
about that
this is the land of robots and you can
just tell from IREX the land of robots
every two years I Rex the International
robotics Expo hundreds of thousands of
people come together this year there
were 200 industrial robot companies
showing robots a hundred and fifty
service robots Newton company showing
robots and there were robots of all
kinds and we're doing robotic things of
all kinds they're serving beer they're
making salad they're folding towels
picking up a car like it weighs nothing
lifting it up in the sky that's the
fanuc best of fanuc robot and have a
sons robot over there this is a service
robot helping somebody in a hospital
this is SOTA SOTA is a little tiny
social robot that talks to you this is a
toyota robot that is working on
articulation this lady here is really
interesting HRP 4c her name is HR p4 c
she is the girlfriend of c-3po
autonomous humanoid robots there are all
kinds of robots there making salad
serving beers and they're all learning
how to be robots the future of robots is
surely bright and as you can see we're
gonna infuse artificial intelligence
into all of it the challenge of robots
is unique unlike a deep neural network
that learns how to recognize speech
where you give it a ton of speech and
this simply tries and tries and tries
and tries until it gets better and
better in the case of self-driving cars
we teach the self-driving cars held to
avoid the world around it how to stay in
the lane and what
to follow in the case of robots and
remembered the self-driving cars mission
is simply to avoid obstacles to avoid
obstacles teaching an autonomous machine
how to avoid obstacles is fundamentally
different than teaching an autonomous
machine how to interact with obstacles
the interaction with the world is a
fundamentally new problem to solve it is
incredibly complicated to interact with
the world you have to be able to of
course perceive the world you have to
recognize the physics of the world maybe
what you're trying to lift is too heavy
maybe your grip is too strong
maybe the object is too slippery
understanding the physics of the world
is a very complicated thing and yet the
halation of our digits is something that
we don't know how to write program sport
so how do we write programs for all of
these computers and so the question is a
deep one we believe there are three
things we have to do the first thing
that we have to do of course is to build
a processor for autonomous machines we
know that every single one of these
autonomous machines will have sensors
cameras 3d cameras depth cameras lied
arse sonars pressure sensors temperature
sensors sensors of all kinds the second
thing we know is that these autonomous
machines will all be powered by AI and
the third that AI has to actuate motors
of tremendous complexity not just six
degrees of freedom not just two degrees
of freedom a twenty thirty forty degrees
of freedom basically every degree of
freedom that level of complexity is some
AI that we simply don't know how to
write and so we imagine that the third
component the third pillar of the future
of autonomous machines is to create a
virtual world a virtual world that looks
like the real world a virtual world
where robots can learn how to be robots
a virtual world that obeys the laws of
physics so that when we're done training
this robot in a virtual world we can
take the brain and move it out into a
physical robot and that physical robot
will know exactly what to do that
physical robot will be borned this
virtual world we call Isaac Isaac Isaac
is a future world where a robot is
learning how to be a robot so this is
Isaac we named Isaac Isaac after Isaac
Newton and Isaac Asimov hi Isaac
Isaac has eyes the eyes of Isaac the
sensors of Isaac will be programmed and
ideally it will mimic the real sensors
the Isaac ice will see the world that is
computer-generated so it will learn the
neural networks necessary in this case
what we're teaching Isaac how to do is
golf as you can see right now Isaac is
not not super good okay it's looking at
the ground looking at the ball and it's
trying to learn how to play golf now let
me show you how I first started to learn
let's go to the beginning in the
beginning Isaac doesn't even know how to
hold the golf club and what it means to
putt however whenever it touches the
ball and the ball moves in the right
direction we told Isaac good job
every single time it does something
smart we give it positive reinforcement
just like a child and Isaac tries and
tries and tries and every time it does
something good we say good job and then
it tries for a long time let's move
forward a little bit Jeffrey there it
looks like it's stir-frying
okay Jeffrey we'll move forward a little
bit after Isaac trains for a very long
time it's getting smarter
a little further please okay and after a
while longer
Wow Wow
artificial intelligence never make
mistakes Wow Wow
okay now you know the green oh wow look
at that the green that's not flat
because the green obeys the laws of
physics okay one more one was just see
it's just too mesmerizing to watch okay
alright good job thank you thank you
eyes a good job so we create a virtual
world where the hardware mimics the
hardware simulates the hardware of the
physical world the processor the sensors
the actuators we then use artificial
intelligence in this issac world to
train to teach Isaac held to be a robot
today we're teaching Isaac how to play
golf in the future we'll teach Isaac how
to fold clothes how to full towels in
the future we'll teach Isaac all kinds
of things how to put pieces of things
together how to manufacture how to work
next to us
I could be inside in holodeck and I
could say Isaac pass me that screwdriver
and Isaac Google pass me a screwdriver
and someday when we come into the
physical world
I tell Isaac to pass me the screwdriver
Isaac will pick up the screwdriver and
hand it to me
this virtual world has to allow robots
helped to learn to be robots without
destroying everything and this virtual
world needs to behave at super real-time
because we want to teach the robots as
fast as possible this is just an
incredible time ladies and gentlemen
we're looking at a technology deep
learning that has made it possible for
software to write software for computers
to write software that is so complicated
that no human can write and now the
computer is starting to become an
artificial intelligence this artificial
intelligence has proven to solve many
problems from image recognition speech
recognition natural language translation
- even generating music generating
photographs generating virtual worlds
generating art it is used for diagnosing
medical images for radiologists for
pathologists to detect early signs of
cancer deep learning is now spreading
throughout every industry and here in
Japan I'm so excited that deep learning
has the opportunity to revolutionize the
future of manufacturing the future of
industrial equipment the future of
robotics and help create the next
generation of autonomous machines this
year has been super busy for us we
started by creating the fundamental
platform the fundamental platform we
call Nvidia AI it is multi cloud it is
hybrid cloud it is the most powerful
training system in the world and it's
the most powerful inference system in
the world is available all over the
world it is the most accessible AI
computing platform anywhere in the world
we call it the Nvidia AI the next part
is Nvidia Drive where we applied this
computing platform ourselves to solve a
very difficult problem and this
difficult problem called autonomous
vehicles we believe as Software Defined
the number of applications we have to
create for the future of autonomous
vehicles is uncertain and in my opinion
unbounded the future car is going to be
a computer on wheels and the type of
applications we will write for the
future of cars we haven't even imagined
yet our job is to go explore that with
you explore that future with you the
first part is to create the computing
platform we call it Nvidia Drive Nvidia
drive has a brand new processor a brand
new processor called Xavier it's a
little tiny computer it is scalable from
level 2 all the way to level 5 one
architecture
Thomas driving stack is called drive AV
the intelligent AI is called drive IX
the entire SDK is open software
developers can then take advantage of
all these capabilities to create the
future car it is an open and scalable
platform the future of AI the next major
revolution is autonomous machines and I
can't imagine a more appropriate place
than Japan to invent the future of
autonomous machines the most important
companies in the world in machinery the
world leader in manufacturing robots
fanuc the world leader in industrial
equipment Komatsu both of them I'm so
grateful and so honored to partner with
them to invent the future of autonomous
machines together
and the lastly AI in Japan the world
leaders leading companies here in Japan
Fujitsu NTT communications a ist working
together to advance AI computing here in
Japan I want to thank all of you for
coming to GDC this is really an
extraordinary time and it's a great
honor to partner with all of you to
create the future together thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>