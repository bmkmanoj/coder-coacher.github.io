<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Prof. Max Tegmark - Life 3.0: Being Human in the Age of Artificial Intelligence | Coder Coacher - Coaching Coders</title><meta content="Prof. Max Tegmark - Life 3.0: Being Human in the Age of Artificial Intelligence - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Prof. Max Tegmark - Life 3.0: Being Human in the Age of Artificial Intelligence</b></h2><h5 class="post__date">2017-10-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ImrBfVK10AY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the importance of discussing artificial
intelligence may very well be crucial to
human destiny trying to assess
everything that could go wrong is not
being alarmist on the contrary
deep thinking analysis and advanced
planning will allow us to think about
what kind of future do we want and
ultimately enable us to create a future
with AI that is positive for humans and
machines we're fortunate that these
conversations are happening more now and
that two of the press unit thought
leaders driving these conversations are
our special guests tonight first we will
hear from Erik Brynjolfsson director of
the MIT initiative on the digital
economy and author with Andrew McAfee of
two best-selling books the second in
each machine age and machine platform
crowd harnessing our digital future next
we'll hear from a max tegmark co-founder
of the future of life Institute and
author of the new of the new book just
coming out Life 3.0 being human in the
age of artificial intelligence and I
understand it's in its second week on
the New York Times bestseller list
congratulations then the two gentlemen
will have a conversation together and
finally there will be time for questions
with the audience before we conclude
with the reception and a book signing so
without further ado please join me in
giving a warm welcome to Erik
Brynjolfsson and max temple
thank you I'm so delighted to be here
it's a pleasure to be able to have a
chance to share some of the research
we've been doing and some of the work
we've been doing at the MIT initiative
on the digital economy about artificial
intelligence and how it's changing
Society I'm gonna add my thanks thank
you Jack and Susie Reno for for
supporting this and thanks to Museum of
Science for inviting me and especially
thanks to a max tegmark we were just
checked we only know each other about
three years but he's become one of my
best friends he is as I say the back
cover of his book has an absolutely
joyful mind and it's when he said let's
let's do this I I jumped at the
opportunity mainly because it's just fun
to talk to him is that you're gonna find
out a little while we're gonna have a
really fun conversation where we
interact and I'm also looking forward to
hearing all of your questions and
comments because we will open up and
everybody will will participate in it
you know we live in some very unusual
times right now as you may have read and
seen even cars are beginning to drive
themselves people are walking down the
street and they're talking to their
phones and they're they're not talking
to another person they're actually
expecting the phone to understand what
they're saying and talk back to them you
know I'm still a little bumpy they're
not really that good at it but they're
beginning to talk to us and we're in the
this I'd say about a 10-year period
where we're going from machines mostly
not understanding us to machines
understanding us pretty well and that's
kind of a unique time in human history
and we're all very lucky to be able to
participate in that and to be part of it
it opens some amazing possibilities
these could be the next the next ten
years could be the best decade in the
history of humanity or it could be one
of the worst because the power being
unleashed by artificial intelligence is
unlike anything we've seen before so let
me first set this is a stage little bit
by just defining a little bit what we're
talking about so you can think of
artificial intelligence is the set of
techniques to imitate the human mind the
classic test for it is the Turing test
many of you may know that with some
proposed by the famous sub computer
scientist Alan Turing could you speak to
a machine
not know whether or not you were
interacting with a human or a machine
machines aren't really passing that test
yet but they're getting closer and
closer especially in certain narrow
areas within that is a category called
machine learning and this is really
what's driving a lot of the excitement
recently is that good old fashioned AI
was an area where we would teach the
machines what to do we would write down
symbols and say this is how you play
checkers this is how you play chess
these are the rules and this is how you
prepare taxes and the machines would
follow those instructions now the
machine learning revolution is taking
over instead of us humans having to tell
the Machine step by step what to do
which frankly didn't work that well it
was okay but it ran into a lot of
barriers now the machines are learning
themselves how to solve problems they're
figuring it out and the way they do that
mostly there's different techniques but
the main approach is that we give them
lots of examples say this is a dog this
is a cat this is a dog this is a cat and
I won't do as many times as they do to
the machines they usually do it ten
thousand or a million times and
eventually the machine starts going oh I
think I see the pattern here and it will
start learning and the nice thing is we
have so much digital data now that we
can show them lots and lots of examples
of fraud or if successful go moves or of
faces that eventually they start
learning these patterns statistically
and a particular subcategory of that
we're really the the biggest part of the
breakthroughs especially in the past
about five to eight years is in deep
learning or deep neural networks loosely
based on the human brain and let me show
you some examples using deep learning a
particular subcategory called
reinforcement learning these machines
can learn new strategies on their own so
one example is the group of people at a
company called deep mind the Googlebot
google deepmind and what they did who's
on the cover of nature the the science
magazine they gave this machine learning
algorithm the pixels for Atari games how
many people here have ever played space
invaders anybody yeah okay how about
break out you guys know the game of
break out
the game of breakout they just gave the
Machine the raw pixels and they didn't
say this is a paddle this is a block
this is a ball the machine had to figure
that out learn it on its own they gave
it the raw pixels they gave it a
controller that they can move it left or
right and they gave it a score and said
here's the score look at the score your
job is to move around the paddle to get
as or to move around the controller they
didn't tell it was a paddle your job is
to adjust this controller and try to
make the score as high as possible and
so at first the machine wasn't all that
good it would sometimes get lucky and it
would hit the ball other times he would
completely miss it it was basically
randomly moving it around but whenever
it was successful and it got some score
went higher the machine was like oh I
got to do more of that whose
reinforcement learning getting feedback
and what to do more and more and after
about 300 games it was really pretty
good
it was almost never missing as good as a
good teenager and playing along there
pretty successfully they cite let's just
keep it let it running for a while and
the guys at google deepmind they don't
play break out a lot and they didn't
know that there was this strategy here
look at what it does it figured out how
to send the ball around behind and
they're like whoa we didn't know you
could do that so the machine had not
only learned how to play but learn how
to play better than its designers that I
imagine a newborn baby being born and in
the hospital and you handed a game and
by the end of the day it's beating all
the surgeons and doctors at the game
that's kind of how fast is learning now
that's the sort of a cool little example
you know scientific progress and by the
way this same technique worked for a
whole set of Atari games it did work on
space invaders and it worked
eventually on pac-man and other games
did work on all of them but once it had
this quick feedback loop where if you
did something the score would change
quickly it was able to learn those on
its own pretty quickly with with no
control programming now you can use
these same techniques for other things
though not just games you could think of
a data center where Google has all their
computers running as a big video game
these
all this data coming in and temperatures
and the score is try to make it as
efficient as possible let's lower the
cooling bill as much as possible and
your controller is you can adjust the
little valve so you can move them left
and right now they had a bunch of smart
PhDs working on optimizing this so they
thought they pretty much had it running
as efficiently as possible but once they
put the machine learning algorithm
against it it got dramatically better so
here you see this is before the machine
learning ragu moves on they turn machine
learning on and it got about 40% more
efficient and it was improving then they
turn it off again and went back to the
way it was before so the machine has
figured out how to run their data center
better than all these geniuses at Google
we're running it and it doesn't take
much imagination to say hey let's not
just do that for that one data center
while we do it for all the data centers
in fact why we do it for all kinds of
factories we could do it for steel
finishing lines and for makers of any
kind of an object so there's room to
apply these things to improve all sorts
of categories in fact there's three big
breakthroughs where machine learning has
made a big difference that weren't
important as recently as about 10 or 15
years ago and we write about them Andrew
McAfee and I do in our book to some
extent vision and language interact with
the physical world and problem solving
so for instance you may want to get some
snacks afterwards be careful what you're
reaching for there are some muffins here
not all of them are muffins though
sometimes we can make mistakes when
we're seeing things and faithfully at
Stanford has developed a very large
database called imagenet with 14 million
images and each of them has been
painstaking labor by humans as to what
they are and back in 2010 when they
tried to have machines see what they
were the machines were not very good
they were wrong about 30 percent of the
time today they're wrong about 2.6
percent of the time so they've gotten
dramatically better this steep curve was
when they started using these new deep
neural net machine learning algorithms
as a reference point humans are about 5%
they haven't improved a whole lot area
so we still have pretty much the same
hardware and software and so the
machines have crossed that threshold
it's important inflection point because
what that means is that now many tasks
that used to be better to have humans do
them well it's better to have a machine
do them at least more accurate to have a
machine do them and that shows up in a
number of areas for instance you can use
them to help diagnose diseases you use
that same kind of an algorithm and you
can show it examples of patients that
don't have cancer and patients that do
have cancer and the machine starts
figuring out as well or better than a
human pathologist there was a paper just
published by Sebastian throwing company
looking at skin cancer and it did better
than the humans so this is just
happening this past few months past few
years I mentioned a voice recognition
you can see the progress there eight
point five percent error rate to four
point nine percent error rate that is
just in the past year that's not like
over the past ten years that's just the
past year since July 16th Drive of 2016
still humans are about five percent
error rate too so you know it's sort of
in that ballpark right now not quite
better than humans and that is opening
up a lot of economic possibilities
interacting with the physical world so
once you can see and recognize things
versus you can recognize a pedestrian or
a bicyclist it starts becoming feasible
to give control of the car to a machine
when they first started doing these they
made errors about one per 30 frames
that's about once per second really not
what you want to have in a car now it's
once per 30 million frames so that's
years it could go without making a
mistake again better than human and so
very soon we'll see more and more these
in the road I had the privilege of
ridden and a bunch of them now and I
feel quite comfortable driving down the
road being driven down the road making a
left turn through traffic waiting and
ultimately I think it'll be much safer
there are 30,000 deaths by humans
drivers today we could drop that by 90
or 99 percent when machines probably not
100% so we'll have to face some ethical
issues when machine drivers
still make mistakes but it'll be
dramatically safer than what we have
today and they're big into work in
factories rod Brooks who used to be at
the computer science and AI lab or run
the company I lab at MIT now has a
company over in Boston called rethink
robotics Baxter works for about $4 an
hour doing simple tasks you don't have
to do any computer programming you show
Baxter what you want it to do pick this
up put it in the box
and after a couple of examples it says
oh I get what you want to do and it does
that task and of course Baxter can work
seven days a week 24 hours a day
I was just on Thursday watching another
robot a little bit like this sorting
things different kinds of soft objects
like clothing faster than humans did and
that will replace a great deal of work
in those areas and last but not least
all sorts of problem-solving medical
diagnosis already showed in the legal
area let's talk to the guys at JP Morgan
down in New York and they see a lot of
relatively routine legal work where they
said here are 36,000 360 thousand hours
worth of legal work so what does this
mean for the economy let me briefly
touch on that before I hand it over to
to max first off there's there's good
news but there's also some big
challenges it makes the pie bigger but
there's no law there's no economic
guarantee that everyone's going to
benefit it's possible for some people to
be get none of them share or even to be
made worse off than they were before and
sadly that's part of what's been
happening the past decade we I think it
could get a lot worse if we're not
careful productivity has continued to
grow and GDP is actually at a new
all-time high but the median family
income is lower now than it was 1990s
good news is actually they just had
reports up for 2016 in the last year it
there was a uptick over 3% in last year
and depending on how you do the
adjustments it may have matched the
previous high although if you normalize
it it's still lower than the the
previous high back in 1997 so we're sort
of roughly flat during that period
now median how can median be so much
than the per person and that's because
median you guys Museum of science here
is the fiftieth percentile it's not the
average it's a person right in the
middle half the people are higher and
half the people are lower so the median
can stay flat if you have a whole bunch
of wealth going to the top 1%
or the top one-tenth of 1% and that's
basically what's happened as computers
have kicked in there's been biased
technical change and you've heard about
the 1% the 1% have their own 1% the
point Oh 1% up here and the share of
income going to them is at a new record
high the only time it was close was back
right before the Great Depression if
that's any consolation
so we are having an economic challenge
of a pie getting bigger wondrous things
happening but the distribution is
becoming more and more skewed and there
are many reasons for that part of it has
to do with tax policy part of it has to
do with international trade but most
economists including me see the way the
technology is being used is the number
one driver of that now that's not
inevitable ultimately we have an
opportunity to rethink how we organize
our economy we're if the pie is getting
bigger if we're creating more wealth
that means it's theory for everyone to
get richer at the same time we can make
the rich richer the middle-class richer
the poor richer we can all be better off
at the same time that mathematically
adds up but there are some choices we're
going to have to make as a society of
what we want to do in terms of taking
advantage of some of this bounty
business as usual is not going to solve
the problem we're doing a number of
things at MIT to try to address it we're
trying to understand the drivers of this
do some research on it we've also
organized something called the inclusive
Innovation Challenge and I invite you to
another event if you don't get tired out
by this one on October 12th at Boston
City Hall plaza the governor Eric
Schmidt a whole bunch of other people
are going to be coming to talk about how
we can use technology to create shared
prosperity for the many and not just for
the few so with that let me leave it
leave you with it with the closing
thought that these technologies are
certainly wonderous
but they give us all sorts of
opportunities they can be used for good
they can be used to create vast wealth
but they don't automatically lead to a
distribution that makes everyone else
better off so it's very important I'm
glad you guys are all here because it's
very important for all of us to think
hard about what we can do to change the
kind of society we have towards a better
one and what we want to do to use these
technologies for broadly shared
prosperity so thanks very much with that
let me turn it over to max tegmark thank
you so much for inviting me here and
thank you much so much Eric for your
friendship and for your all to kind
introduction and for all for setting me
up so wonderfully here let's see if the
Technology cooperates why switch over to
this so I'm gonna continue little bit
further forward in time and talk about
what will happen if AI keeps getting
even smarter but it will be like being
human in the age of AI and what it
should be like so let's first go far
back you go and look at the big picture
so 13.8 billion years ago no I have to
start here so fun ultimately a physicist
our universe was very boring with just
you almost uniform plasma everywhere and
nobody there to even witness it or enjoy
it
gradually the laws of physics clumped
this into galaxies stars planets and so
on and about 4 billion years ago the
first life appeared here on earth that
life was pretty dumb though I call it
life 1.0 because it couldn't learn
anything in this lifetime like these
bacteria here life 2.0 is what I call us
however we can learn and if we use Eric
green gemstones metaphor of thinking of
us as a computer of sorts then learning
corresponds to uploading new software
into our minds if I want to learn
Spanish I can spend a bunch of time
studying and uploading the Spanish
module and I will have these new skills
and I guess hola Bwana
is khattala right bacteria can't do that
and it's precisely this ability to learn
to change our own software which is
enabled cultural evolution which made us
the most powerful species on this planet
life 3.0 would be if you can also design
your own hardware
we humans are kind of trying to head in
that direction or kind of it life to
point one right now because we can get
cochlear implant or it's artificial
knees artificial pacemakers but we can
but true life 3.0 certainly doesn't
exist
artificial intelligence might help us
get there though we heard from Eric the
AI is getting smarter listen and we
heard from Eric that traditionally
artificial intelligence used to work
like when a beat Garry Kasparov the
World Chess Champion a little over
twenty years ago they used to work by
people taking their own intelligence and
encoding it into a computer program
which then beat Kasparov simply because
it could think faster and remember more
than he could whereas the recent
progress as we heard from Eric has
really been driven instead by machine
learning where you just you have very
simple machines often with simulated
neural networks a little bit inspired by
human brains and you just train them
with massive amounts of data you feed in
a bunch of pixels and out comes this
CAPTCHA no it's a group of young people
playing game of Frisbee you take the
exact same thing put in this image and
it'll tell you that's the heart of
elephants walking across a dragon grass
field it's even more striking you if you
look at the playing computer games as we
saw in this nice example that the Eric
showed now once a computer can learn to
play Atari games fetched already tells
you that there's a lot of room for
growth there because you can also start
to think if your robot for example of
life itself is a game where you get
rewarded for certain things and just try
to learn and in fact the same company
google deepmind that did this came out
at all this just came out with the
following result where they train little
toy robots
to see if they could learn to walk they
just gave them points whenever they were
able to move forward but these this
software have never seen a video of
somebody walking they didn't know
anything about the concept of walking
okay they did this in simulation it was
cheaper than doing it with metal objects
that kept falling down but the idea the
same and this is what happened nobody
taught it to do this learn by itself
they tried a variety of different type
body types including some more animals
and like you see they learn to run they
learn to jump and so on
I think anything almost Kym and in life
where you have a goal can be thought of
as a bit of a game whether it's playing
the stock market or or playing a sport
so where is this all taking us I like to
think of all intellectual tasks as
forming a landscape like this where the
height is how hard it is for machines to
do and the ocean level being how good
machines are at doing it at present so
grills are chess playing human chess
playing skills have long since been
submerged by machines our ability to
multiply numbers fast even longer ago
with pocket calculators and so on and of
course the worst kind of career advice
to give to our kids is just encourage
them to do jumps right on the boundary
here which are just about to get
submerged but the sea level is rising in
this metaphorical landscape because
machines keep getting better and it's
fascinating to wonder what's going to
happen some people think machines will
never be able to do all the things we do
but a lot of world leading computer
scientists think that in fact machines
will eventually be able to do everything
we can do maybe in 30 years or so
submerging even the highest peaks here
and then what
we have very interesting choices to make
here and I feel that these are choices
we shouldn't make deliberately after
thinking a lot about them so in that
spirit I found that the bunch of
colleagues actually Mia and Lucas do you
want to stand up the two of the
co-founders of the future of life
Institute are here and Erik Brynjolfsson
is also someone we're very happy to have
on our board here the idea of our
organization is simply that help create
an the best possible future with
technology by thinking hard in advance
of how what we need to do to get things
right I'm optimistic that we can create
a wonderful future with technology as
long as you win this race between the
growing power of the technology and the
growing wisdom with which we manage the
technology but in order to win this race
we need to change strategies I feel in
the past we always stayed ahead in this
wisdom race by learning from mistakes we
invented fire screwed up a bunch of
times and then we invented the fire
extinguisher we invented the car messed
up a bunch of times
invented the seatbelt in the airbag and
all in all that was a good strategy but
as technology gets more and more
powerful eventually you reach a
threshold where the technology is so
powerful that you no longer want to
learn from mistakes you instead want to
plan ahead and get things right the
first time because there might be the
only time you have I would argue that
nuclear weapons is already in that
category we don't want to learn from
mistakes and have an accidental nuclear
war and be like oopsy you know maybe we
should have had a lot better and
superhuman intelligence is certainly in
that category also so we need to shift
from being reactive to being proactive
some people call that being on the
alarmists care monger I call it safety
engineering when NASA very
systematically thought through
everything that could possibly go wrong
with the first mission to the moon they
weren't being scare mongers precisely
what they did there is what ultimately
led to the success of the mission they
thought through all the things that
could have gone wrong and made sure they
didn't so what what is my
what we should do let me tell you four
things I think would be good first of
all I think we should try very hard to
make sure that we get an international
treaty against lethal autonomous weapons
so the biologists and chemists are very
happy that if I asked you what is your
first is not bioweapons and if I ask
about chemistry what does that make you
think of you're probably gonna think of
new materials rather than chemical
weapons why is that because those
scientists came out in force and
persuaded the politicians of the world
to make an international ban on bio
weapons and chemical weapons we
physicists have a more if the scorecard
here why when you read about Kim jong-un
and Putin and Trump with the nuclear
button and so on you're like I we
physicists feel pretty responsible for
this and the AI researchers of the world
today feel very strongly that they want
to be like the biologists and the
chemists and keep all the wonderful
opportunity of AI focused on things like
curing cancer and doing all that other
wonderful stuff that Eric mentioned
rather than just making make me
dramatically cheaper to murder people
anonymously as a good economist like
Erik Brynjolfsson can tell you if you
take something like that
like anonymous murder and you drive the
price almost a zero the laws of
economics are gonna put us lead us to
place we don't want to be so that would
be number one on my list try to keep
this focused on civilian things and I
think there's real hope for that
actually because the superpowers all
have a lot to lose there a second I
think we should as Eric said to really
try our best ensure that this growing
pie that AI can create is used to make
everybody better off and I look forward
to talking more with you right after
this about what concretely we can do and
third I think we have to invest in AI
safety research what do I mean by that
there are a lot of nerdy technical
problems that we need to solve in order
to be able to transform today's buggy
and hackable computers into robust AI
system
that we can really trust raise your hand
if your computer has ever crashed on you
oh boy that's a lot of hats how would
that feel not good frustrating maybe but
frustrating isn't the word you would use
if what crashed was the AI that was
controlling the US nuclear arsenal for
example or other key infrastructure in
the world right so it's incredibly
important that we we up our game in
terms of AI safety research making
things work and other key challenges to
just make sure that the goals that the
machines have are really aligned with
ours it doesn't have to be you know it's
a a frightening thing to be in the
presence of other entities that are
smarter than us because we've all done
it when we were all little about this
big we were all in the presence of more
intelligent entities our parents right
and that was fine because their goals
were aligned with our goals but if you
tell your future self-driving car that
take you to Logan as fast as possible
and you arrive they're covered in vomit
and chased by police helicopters and
you're like no no that's not what I
asked for and the car answers that is
exactly what you asked for
then you've begun to appreciate how hard
it is to get machines to understand our
goals when they don't have this shared
reference frame and and just because you
understand them doesn't mean they're
gonna adopt the gold we all know how
tough that can be just from trying to
get children to adopt our goals when
they full well know what we understand
what we want right and then to retain
our goals also like my kids are much
less interested in Legos now than they
were when they were little
so we program machines to be nice to us
we don't want them as they get smaller
to start think beginning is bored with
us as 38 years our Legos there are a lot
of challenges there and and just to
summarize why I think we should take
seriously the possibility that we might
get machines that are smaller than us
and why these this AI safety research is
so important let me summarize this all
in this very in this very short little
video here
we'll artificial intelligence ever
replace humans is a hotly debated
question these days some people claim
computers will eventually gain super
intelligence be able to outperform
humans on any task and destroy humanity
other people say don't worry AI will
just be another tool we can use in
control like our current computers so
we've got physicist and AI researcher
max tegmark back again to share with us
the collective takeaways from the recent
Asilomar conference on the future of AI
that he helped organize and he's going
to help separate AI myths from AI facts
hello first off max machines including
computers have long been better than us
at many tasks like arithmetic or weaving
but those are often repetitive and
mechanical operations so why shouldn't I
believe that there are some things that
are simply impossible for machines to do
as well as people say making mini
physics videos or consoling a friend
well we have traditionally thought of
intelligence as something mysterious
that can only exist in biological
organisms especially humans but from the
perspective of modern physical science
intelligence is simply a particular kind
of information processing and reacting
performed by a particular arrangement of
elementary particles moving around and
there's no law in physics that says it's
impossible to do that kind of
information processing better than
humans already do it's not a stretch to
say that earthworms process information
better than rocks and humans better than
earthworms and in many areas machines
are already better than humans this
suggests that we've likely only seen the
tip of the intelligence iceberg and they
were on track to unlock the full
intelligence that's latent in nature and
use it to help humanity flourish or
flounder so how do we keep ourselves on
the right side of the flourish or
flounder balance what if anything should
we really be concerned about with super
intelligent AI here is what has many top
AI researchers concerned not machines or
computers turning evil but something was
subtle super intelligence that simply
doesn't share our goals if a
heat-seeking missile is homing in on you
you probably wouldn't think no need to
worry it's not evil it's just following
its programming know what matters to you
is what the heat-seeking missile does
and how well it does it not what it's
feeling or whether it has feelings at
all the real worry isn't malevolence
but competence super intelligence AI is
by definition very good at attaining its
goals so the most important thing for us
to do is to ensure that its goals are
aligned with ours as an analogy humans
are more intelligent and competent than
ants and if we want to build a
hydroelectric dam where there happens to
be an anthill there may be no
malevolence involved but well too bad
for the ants cats and dogs on the other
hand have done a great job of aligning
their goals with the goals of humans I
mean even though I'm a physicist I can't
help think kittens are the cutest
particle Arrangements in our universe if
we build super intelligence we'd be
better off in the position of cats and
dogs in the man's or better yet we'll
figure out how to ensure that AI adopt
our goals rather than the other way
around and when exactly is super
intelligence going to arrive when do we
need to start panicking
first of all Henry super intelligence
doesn't have to be something negative in
fact if we get it right AI might become
the best thing ever to happen to
humanity everything I love about
civilisation is the product of
intelligence so if AI amplifies our
collective intelligence enough to solve
today's and tomorrow's greatest problems
humanity might flourish like never
before
second most AI researchers think super
intelligence is at least decades away
but the research needed to ensure that
it remains beneficial to humanity rather
than harmful might also take decades so
we need to start right away for example
we'll need to figure out how to insure
machines to learn the collective goals
of humanity adopt these goals for
themselves and retain the goals as they
get ever smarter and what about when our
goal disagree should we vote on what the
machines goal should be should we do
whatever the president wants whatever
the creator of a super intelligence
wants let the AI decide in a very real
way in the question of how to live with
super intelligence is a question of what
sort of future we want to create for
Humanity which obviously shouldn't just
be left to AI researchers as caring and
and socially skilled as we are thanks
max so how do I get involved to make
sure we don't end up living in a super
intelligence powered dictatorship well
so on that note I'm very very interested
to continue the conversation with Eric
and with the rest of you to hear what
kind of future you ultimately ultimately
all want to create with this technology
because that really is not a question
that should be left to geeks like myself
alone because it affects us all
thank you so much okay
so Max and I are gonna start the
conversation and then after I don't know
30 minutes or so we'll ask all of you to
join in but let me just pick up so III
that pen there was asking you a question
now when do you think AGI is going or
artificial general intelligence is going
to be here and you kind of dodged the
question because I know that scientists
hate to make predictions about the
future but audiences love it so I'm
gonna push you a little bit harder and I
know you know I was at with some of
these cops both these conferences and
there we did some polls of it so you can
be a little more precise about what what
are some of the people at those
conferences saying when we might have
machines that are sort of roughly as
intelligent well first maybe we should
define what AGI is I'm not sure we did
that and then and then what did what did
the other experts say well you know
where do you put yourself on that
spectrum great so first of all and what
do we mean by intelligence different
people actually quibble a lot about this
so what I mean is simply how good the
machine or the thing is that the
accomplishing its goals we have machines
today that have very narrow intelligence
that are better than all of us that with
multiplying numbers fast etc but
artificial general intelligence that's
intelligence which is as broad as ours
that can get good at any goal so we
asked a bunch of leading AI researchers
when did they buy when did they think
that machines would be able to actually
outdo us at all goals and the answer is
very interesting first of all there was
a violent disagreement yeah that's
important yeah which means we really
don't know so if somebody tells you for
sure it's gonna happen real soon they're
exaggerating because they're very very
smart
AI researcher to think it won't happen
for at least a hundred years but if
someone tells you for sure it's never
gonna happen or it for sure it's not
gonna happen in a lifetime they're
exaggerating too because we had a lot of
really top AI researchers who said they
think it's gonna happen maybe 2040 2050
including and and this group of
optimists to think that they're gonna
get there relatively soon include the
google deepmind leaders for example
whose work we showcased here so my own
feeling is i think the average was about
20:55 Butler to 120 55 was one
conference in almost 20 47 yeah it was
really precise about that two years
later I thought it was gonna come in
here sooner because the progress was so
quick so in the matter of decades I
think is a perfectly reasonable yes you
know and we put a lot of thought into
what's gonna happen in decades when we
plan for our retirement and things like
that so even if we're not sure I think
the decision I heard that we sort of
compelling was what if someone told you
an alien intelligence is going to land
on planet Earth in the year twenty fifty
five and we then that would kind of wake
us up and in some ways this is a an
alien intelligence a nonhuman
intelligence yeah except we're better
off here because if it's just some
spaceship that have arrived from the
Vega system you know we're just gonna
figure it doesn't matter what we do
because their technology is probably so
far beyond us but this is different
because we're creating this stuff
ourselves we get the opportunity if
we're careful to decide what sort of
intelligence is gonna be what sort of
goal that's gonna have and I think this
is incredible human II we we should
seize it not squander well you convinced
one really important person at that and
that was the very charismatic and very
successful Elon Musk who who came by and
he found this to be a really important
challenge he he famously spoke at MIT
and said you know we are summoning the
demon and that never goes well or it
doesn't always go well at least and tell
us the story is a really fascinating
story in the book so you have to read
the book to get the full details of it
but tell us the story about how you got
ill on - well to make a donation I won't
give away what what all he did but it
was kind of interesting yeah this
fascinating story with the yeah not too
long ago I could never have dreamt of it
would be like doing a project together
leave on must but I started to realize
that that he was thinking very seriously
about this and since we were planning to
do this Asilomar conference on the
puerto rico conference before we wanted
to bring AI researchers into this
conversation
I reached out them and asked if you'd be
interested in them in the phone call and
and it became very clear very quickly
that not only did he really care about
this but it really gets it I feel he's
much maligned in the media that loved
portray him as some sort of doomsayers
scare monger I feel nothing could be
farther from truth I mean you know him -
he's incredibly he has this incredible
optimism in the potential of humankind
that's why he's actually betting his
energy and his money on on things that a
lot of other people think are impossible
like going like spreading life beyond
our planet or or have making cars
all-electric and having solar panels
throughout throughout the world and and
so it's very natural that for someone
who really thinks a lot about the
longer-term future he's not gonna want
to dismiss the risk that might ruin
everything you know in 30 years he wants
us to take this really really seriously
and what I tried very hard to persuade
him of was that what we really needed to
do was get the AI community engaged in
this conversation and show them that
they that this wasn't about trying to
stop AI research but I talked about
winning this race between the power of
the research of the AI and the wisdom
that we didn't need the strattice low
down the power but instead help the
other runner in the race develop the
wisdom by investing in that kind of
research I talked about various kinds of
safety measures they were all completely
unfunded and and he very kindly agreed
to be the first person ever to actually
fund that kind of research and it was
amazing what happened we we after he
pled pledged these 10 million dollars we
write 5 million dollars out that's a
that's a big number
yeah I mean it's a small number compared
to what the US government spends on
research but it was for the first ever
dollar pretty much spent on this kind of
research and we so we decided to give
this out to anyone in the world who had
good ideas to support the study deadline
was short topic was novel weren't sure
what was gonna happen
we got a
we've got 300 teams applying although
although there's a little part of the
story that that's worthy so he almost
you almost didn't make the announcement
that night right I mean that was a
little touch-and-go as I recall you were
it's always at the comfort I was
watching you and him you were kept like
going over the corner and having these
like the discussions back when the cyclo
something big is brewing there and heart
palpitations right remembering but what
would that night what was the reason why
he almost didn't do it
the reason was he was trying to attempt
the first ever landing of a first stage
rocket booster on his barge
yeah other things going in any no this
has been a dream of his for so long and
his press people had said you cannot
cannot cannot distract the media from
from this you know by having another big
announcement like the day before so so
finally we came up with this this was
actually our friend Anthony Aguirre okay
found a magical diplomatic solution
which was he would make the announcement
at the conference that he was gonna do
this but nobody else would he weren't
allowed to tell the world until after
the rocket had landed and he days in
fact he swore us all the secrecy and
just to make sure that we kept her
secret he didn't tell us the number so
there was nothing really exactly is that
that number really is the is the
headline right right yeah but this
section I feel very happy
in hindsight how this helped because it
really transformed the way that our AI
friend research friends think about this
now they whenever they go to a
conference they see their colleagues
working on and I safety research also
and feel all this is cool and they feel
that this is something we can help with
rather than feeling that they're just
under attack right so you also mentioned
North Korea and some of the risks there
I know that you you mentioned not just
banning it lethal autonomous weapons but
you also have a project to reduce
nuclear proliferation this is not nearly
as distant or hypothetical it's not 2047
it's like 2017 that we're having I guess
it was it today that the North Korean
sent a missile over Japan again is there
anything so do you have a concrete thing
that that we can do about that or
anything we should be thinking about
first of all
even just bringing up is a step in the
right direction I think this is very
much the same phenomena that we're
talking about what AI here you know we
humans through science understand our
world better and better and we use that
to build technology that can amplify our
own power more and more and we have to
make sure we have the wisdom to be ready
for it but you would never walk into a
kindergarten and the skill to say hey
here's a box of hand grenades why don't
you play with this but I sometimes when
I listen to statements from Kim jong-un
and I read tweets by a certain person
done but they take this football box of
4000 nukes you know and play with them
the hindsight maybe this could have been
handled better I think how how'd you do
today or even it can be handled a lot
better if we want to have Russia in the
u.s. obviously want to have ironclad the
turns to make sure the other side
doesn't new clam how many nuclear
weapons do you need to deter Putin well
maybe a hundred maybe 500 I think if you
take out the largest 500 Russian cities
it's not that much left right I went
down the list of the largest US cities
by the time I got to 900 something I was
in goober and Massachusetts was right
next to either toll or they don't know
Russians don't have to take our Woburn
to deter us we actually but we don't
have 900 houthi nothing have mine
already has 7,000 offence to those of
you and we were yeah why does Russia
have 7,000 well because we have 7,000
why do we have 7,000 because Russia does
if Putin and Trump got together and said
okay let's start by making agreement
cutting it down to a thousand each the
turns would be completely unchanged it
will be absolutely equal it would not in
any way reduce our deterrence against
Kim jong-un either it would just be a
step in the right direction so I think
just getting a bit more awareness of the
risks that our technology poses so we
can so we can maggot right just kidding
I mean as physicists and technologists
and Elon Musk and all of you will keep
inventing more and more powerful
technologies it's like
you know with a stone or a spear you can
hurt a few people with you know a gun or
a machine gun or a grenade you can hurt
a few more a nuclear bomb can kill
millions of people but now the next wave
may be literally existential I mean one
of the things we talk about the future
lies is that there are technologies not
just AI but biological and others that
are like not giving a hangar die but
giving a little red button that says you
know we'll destroy humanity please do
not push right suppose we handed out one
of those to each person on the planet
yeah and you know how long do you think
we'd survive exactly I mean I bet there
were people during the Stone Age also
who for whatever reason thought it was a
good idea to kill a bunch of other
people during the Stone Age but how many
people can you take out with a rock in
the club in the middle night right not
so many now they were developed we're
amplifying the power of everybody we
have to really as a society get together
and make sure that this kind of stuff
especially lethal autonomous AI based
weapons right don't fall into
everybody's hands and I think that I
think that this is why we really should
but make sure we don't get into the arms
right military arms race with AI weapons
because whereas nuclear weapons are at
least fortunately very expensive to
build these things we're just gonna cost
200 bucks or something don't cost much
more than an Amazon delivery drone such
as delivering something else and if
anyone can just program in with every
cyber right yeah oh baby even physical
things if someone can just put in the
address and the photo of other
ex-girlfriend that they're upset about
and and and and know that the horrible
situation we just don't want to be in
and I think the superpowers are
beginning to realize that mass producing
this technology is mainly gonna help
terrorists and non-state actors and weak
in China and Russia in the u.s. that's
why I'm hoping they can clamp down on
their interest but I so I saw your five
minute warning there and I'd want to
make sure before we turn it over to you
in the audience that we get back to
higher note and run into these downer
topics like weapons so I would like to
ask you Eric you spoke very
optimistically about how AI has the
possibility that really greatly grow the
pie right and then you said though that
there is a
and and I heard you say before there's
shame on us if we can't make sure that
everybody gets better off as a result
I'd like to push you a little bit on
this and ask more specifically how would
you like to see this happen because I
know in this country there are a lot of
people who are absolutely against any
kind of wealth redistribution so well
it's worth thinking about so the the
shorter term in the long term and the
longer term isn't as long as your long
term so I'm thinking you know maybe you
know the next five to ten years versus
you know 20 30 years in the short run
there's so many things that only humans
can do there's no shortage of work that
only humans can do most things only
humans can do wondrous as those examples
at max night both gave so we need to
think about okay how can we add some of
you old jobs get automated how do we get
people able to do some of the new jobs
and there's three broad things you can
do there the first one that most
economists love is education and I do
too and and there's helping people learn
new skills but it's not just spending
more on it it's more a matter of
reinventing it the kinds of things and
machines are bad at our creativity
emotional intelligence and these are
things we teamwork leadership motivating
people these are things we don't teach
in schools very well if anything a lot
of schools didn't do Velma's design to
stamp creativity out of kids and adults
and so we want to reinvent how we do
school and it's gonna have to be more of
a lifelong thing where people just
continuously learn new kinds of things
you know technology can help MOOCs but
it's not mainly just throwing technology
idea there's more this this conceptual
change of less memorizing facts sitting
in rows and and learning to follow
instructions which is what machines are
very good at and more how can we play
and discover MIT we do more and more of
what we call action learning where
people are involved in projects and
figure out how to solve them so that
would be one part of it another leg is
actually more entrepreneurship you may
be surprised to learn that if you look
at entrepreneurship and innovation and
job training eight states it's actually
gone down everyone thinks it's gone up
technologies advanced there's certainly
wondrous things happening in Silicon
Valley and we talked about some
entrepreneurs but overall there's
actually been less new business
formation less new jobs created unless
new comfort
started and that makes it difficult to
invent the new jobs and tasks that are
there to replace the old one it's always
a losing strategy to try to freeze the
old economy in place the successful
strategy has always been that as
technology automates all things like it
did with you know agriculture and many
other things behind we didn't just say
oh let's see if we can hang on to those
jobs we and by we I mean other people
entrepreneurs invented lots of new goods
and services and that's the genius of
capitalism Joseph Schumpeter called a
creative destruction hmm and we got to
do more to encourage that and make it
easier for people to invent those new
jobs there's been more and more
regulations and barriers here in Boston
there was a law passed that a special
tax on uber that they took the money to
give it to taxi drivers who try to like
slow down that transition not just in
Toronto and they just banned uber
altogether you know there's just small
examples of of people feeling
uncomfortable with change right and then
thirdly I would you know the thing you
mentioned is a redistribution we have a
tax system right now that has actually
shifted more money towards richer people
over the past twenty thirty years even
though that chart I showed you most of
the wealth most of the income in the
past 20 years has gone to that top one
percent so both the technology and the
tax system are conspiring to exacerbate
inequality doesn't have to be that way
that's a completely a social choice back
in the 50s and 60s when we had pretty
good growth marginal tax rates went as
high as 90 percent I wouldn't recommend
that but certainly there's a its Bailey
really a values decision of how we want
to balance things and in other countries
like Sweden where you were born they've
been very successful in in Norway in
particular in investing in health in
education and infrastructure in
childcare and people having long
vacations so it's not necessarily giving
people money but it's it's sort of
making life a little bit more pleasant a
little less hard edge and that's those
are those are three things we can do to
soften the blow and let me just say in
the long run we will eventually I think
I share your optimism that machine's
ultimately will be able to do just about
everything that humans can do and do all
the work that we do
a lot of people say oh my god the
machines are gonna take all of the jobs
and and my reaction that you mentioned
it is is you know shame on us
if we turn that into a bad thing we're
talking about a world with vast wealth
and no need to work and people say
that's a bad thing
that should be a great thing that we are
just able to spend our time you know
having discussions at the Museum of
Science and and playing and and you know
doing sports and doing all sorts of
other things the problem is the income
distribution and that's a social choice
that's been trying to do with the
technology just to push it a little more
yeah on this so that I agree with all of
the things you've said they seem like
great things to do and I also agree that
if we can have a life long vacation and
vigil at in Athens did you'd be great I
mean some some of course we have to
think about trading in society where
people also feel meaning and purpose but
I know a lot of people who have never
worked a day in their life and feel
plenty of meaning meaning and purpose hi
they're all children and teenagers Yeah
right you know and so there's it's I
agree with you it's certainly doable but
will we be able to actually do it I
wanted to ask you
them do you think though that we will
actually be able to do this and now the
latest tax reform that's being discussed
in this country it seems like it's again
just going in the opposite direction
right well I think well it's one of the
reasons that I'm happy we're having this
discussion is that it's it's not a
matter of us making predictions it's and
you said this in your talk too it's a
matter of us making choices because this
is this is totally up to us to decide
and the way it works in a democracy more
or less is that there's no dictator or
King or anything decide we the people
decide and I've talked to the folks in
Congress and even people more senior
than that and they basically say look
you know I like some of your ideas but
unless the citizens unless the voters
are clamoring for it it's we can't go
out in front of them we have to listen
to what they're saying so it starts with
changing the conversation and deciding
you know having a deep consideration
what values do we have what do we want
to do I've no doubt about it
ability its economic feasibility its
political feasibility is you know that's
that's a choice that's up to us
ultimately oh is there
should we take yeah all right well let's
that's that's a good note oh yeah very
interesting to hear all your questions
and comes in my understanding there's a
couple of microphones here maybe we can
bring the lights up and we'd be
delighted to hear what question there's
one over there I see and one over here
just glad to hear what kind of questions
and comments you all have yeah and since
we have a lot of hands I think try to
keep the questions relatively brief and
make sure that they in fact are
questions sorry first question right
here over here on this side good evening
I'm Anton spawns I have a question about
the economic consequences of no
artificial intelligence basically
machines take over our jobs right so
right now you know the economic
consequences of that that you know a lot
of people will be out of a job hundreds
and thousands taxi drivers millions of
you know truck drivers and so on and so
on
right you say it's a political choice
but nobody except maybe us here and some
other spots are talking about it but on
television you don't hear that or in the
public media you don't hear those
difficult choices you hear some
rumblings about basic income to solve it
maybe some ownership in in the data that
we give up what are your ideas of
forwarding that that whole thing in
society that people actually don't start
talking about that yeah well this is a
huge issue and I think part of the
political dysfunction and anger we have
in the economy not all of it but part of
it I think is driven by this economic
trends you know median income as I
mentioned is basically stagnant so half
the people have gotten worse off even as
the economy is growing so I don't blame
people for being angry I mean you'd be
surprised if they weren't angry there
because they see that they're not things
aren't getting better for them and so we
absolutely have to rest it and I'm quite
convinced that over the next decade the
the underlying forces are gonna get
stronger and stronger so hundreds of
thousands millions tens of millions of
people are going to lose their jobs I
have no doubt about it
the question is whether they'll be tens
of millions of new jobs that come in
place and that is not automatic so far
actually we've
you know okay job at doing of creating
those new jobs they're not as good jobs
and part of that depends on you know
just to be clear unemployment is
basically higher now than it used to be
unemployment is not super high that
issue really is more around wages than
unemployment so wages are stagnating
even though the total number of people
working isn't suffering as much can we
create new and better jobs and as I said
I think there's lots of work to be done
in in child care in health care and
elder care and creative work in teaching
in science and arts and the PI is
getting better we can afford to spend
more on that if we want to the money is
also there so this is these are some
social choices the other thing is we can
enlist the private sector more I
mentioned the inclusive Innovation
Challenge and there's a 300 company over
300 companies and organizations that
entered and we're going to announce the
winners of some companies they're doing
some very creative things to create jobs
but the government can help support that
we just get a little bit nerdy here
about it there's something called the
Earned Income Tax Credit ro Khanna out
in Silicon Valley has proposed to Riley
expand it it's basically a little bit
like the basic income but it's tied to
work so that if you if you work more
have low income jobs they'll supplement
it and it basically takes an $8 our job
and turns into a 12 or a $15 an hour job
not by having a minimum wage which has
the employer pay all of it but having
all of us contribute to it and that way
the employer has no disincentive to hire
the person the employer hires them just
like they did before the person gets
more money and it gets to Max's question
about meaning a lot of people do feel
like they want to be part of the society
in a contributing way and over time I
think people feel more comfortable
playing like our kids do but right now I
think if you just write people checks a
lot of people don't feel satisfied about
that I've talked to some of my
sociologists friends and they and they
feel like having a way to contribute to
society as part of it too but I there's
a lot of enhancers let me just stop
there there's a lot more we could do but
a whiskey some other people have a
chance next question do your left
thank you both sorry can you hear me
yeah thank you both for being here
so in recent years many people have
taken to the streets in an attempt to
solve this problem by asking people to
solve it and every nonviolent revolution
has been stymied because the people with
their fingers on the buttons also have
buttons that they can push to stop that
I see most technological advances in
recent years as preventing that what do
you to see as the most seamless least
violent way to overthrow the
hierarchical self-reinforcing nature of
the collection of power amongst only a
few individuals can we use artificial
intelligence and the technologies you're
talking about for that and how would you
apply them in this case I think that's a
very interesting question that all
technology is a double-edged sword
obviously even fire and these marks not
answer that's right we use them to chop
down little trees meetings and certainly
one can use these modern technologies
also for positive social change I feel
that what's happening actually is that
the the anger that's being felt by more
and more people who see their lives
getting materially worse even though
even though the pie is growing is very
very real and a couple that was with
major cuts also in availability of
higher education so you have a lot of
angry people who have not had the
opportunity to learn the full details of
what's actually happening that's a dream
come true for any demagogues and
populist s'right and I think what we've
been seeing here in a number of recent
elections it is that people is very
hungry for change and they're just gonna
vote for whoever promises the most
change Barack Obama's slogan was change
and in a sense Donald Trump's slogan was
also changed because a lot of people
didn't feel the guard enough change from
the warm I think was another the Trump
and Sanders both promised a lot of
change brexit was the option that was
the biggest change and ultimately I
think you'll be really really helpful if
people can think of clever ways of Bill
a social movement that can actually tap
into this is this anger people show
people solutions that will actually
worked
Eric's book Eric's new book machine
platform and crowd that talks precisely
about sort of drivers that businesses
have very successfully used to use
modern technology to be disruptive and I
would love to see some of these same
ideas to be used to transform my society
into something a function add to that
very briefly I mean there's a ton of
tools available for centralizing power
but at least as many for for
decentralization power to giving power
to the crowd that was at least a third
of our last book my the newest book was
is about whether it's social media or
lots of other tools for tapping into the
millions or billions of brains we all
use Wikipedia and other things I just
want to push back on one part of what
you said I'm not sure that the answer is
to overthrow what we have right now
maybe it's because I'm older but I think
we've actually have some institutions
that have been incredibly valuable for
creating power to the people and there
are countries that have used them more
effectively and we just talked about
some of the Scandinavian countries that
do that and if we could restore some of
those institutions that might be helpful
but if we don't I think if we fail to
live up to the promise of the what the
institutions were originally designed
for a hope for then I think we will have
them overthrown I don't think United
States is immune to that and I think the
kind of of revolution that we've seen in
many other countries other times in the
United States 200 years ago could happen
here and so the people who right now are
in power should be very aware of that
that if they don't think about ways of
creating shared prosperity then people
will come after them with the pitchforks
like like this guy's going to okay we
have our next question right up here in
the front I think we can address some of
the fears
the artificial intelligence like turning
against us by looking at the movie
organs mm-hmm the only way to win is not
to play and if we look at just very
simple game theory I mean we know that
the secret is almost always cooperate
and not compete and any intelligent
computer is gonna learn that right yeah
right so that's a very good question you
raised there how do you make people
cooperate rather than fight I think that
one of the most powerful ways to make
people cooperate is to help have them
all think about the positive shared
vision that they have but now why do
people agree to give up a lot of freedom
to get married for example because they
have if they think about all the cool
things that marriage will enable right
and it's the same for all collaboration
it's because all parties realize that
hey you know if I put this little petty
thing aside and collaborate I can do
this great stuff now what are we
actually doing as a society when we
envision the future kind of exactly the
opposite Oh
if you go to the movies and look at the
visions of the future they're almost all
dystopia it's the Terminator or you name
it right and my wife Mae likes to point
out that that's exactly the opposite of
what we actually have to do you know I
Eric and I often get students coming
into our offices at MIT and asked me for
career advice right I always ask them
wait where do you want to be in the
future and if she says oh I in 20 years
I'm gonna have maybe I'll have cancer or
maybe I'll have been stabbed you know
that's a terrible way I wonder have I
sparkling and excited and this is where
I want to be and then you can think
about challenges and how to avoid them
we as humankind need to do that too in
fact that's the key reason why I wrote
my book I wanted to really encourage
people to think about what sort of
future you're excited about the crate
with all this technology and I'm I'm
hoping that this can really foster the
kind of collaboration that you're
talking about but people say yeah if we
actually work together we can get there
that that just seems like the perfect
place to end actually working at the
idea of cooperation and how can we work
together to envision a better or at
least a really positive future so I'm
gonna take the priority here of saying
that we are going to now invite you to
join us to continue this conversation at
a reception and a book signing will have
desserts it's in the museum's cafeteria
so you'll have to exit the theater and
then turn right and then follow the
signs and then ultimately down to the
bottom floor Eric and Max will be there
to be talked to and hopefully we can all
we can all we can all talk to one
another because there are some really
amazing comments and concerns and hopes
that were raised here so thank you
gentlemen so much this has been very
eye-opening and amazing
thank you so much thank you sorry</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>