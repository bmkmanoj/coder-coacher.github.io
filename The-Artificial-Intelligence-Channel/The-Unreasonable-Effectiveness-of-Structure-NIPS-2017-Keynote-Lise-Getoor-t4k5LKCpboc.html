<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Unreasonable Effectiveness of Structure - NIPS 2017 Keynote - Lise Getoor | Coder Coacher - Coaching Coders</title><meta content="The Unreasonable Effectiveness of Structure - NIPS 2017 Keynote - Lise Getoor - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Unreasonable Effectiveness of Structure - NIPS 2017 Keynote - Lise Getoor</b></h2><h5 class="post__date">2017-12-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/t4k5LKCpboc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so thank you very much and it's a
big pleasure and honor to be here I'm in
this talk I'm going to be talking about
structure and I'm gonna be talking about
structure both in the inputs to our
machine learning algorithms and also in
the output of our machine learning
algorithms so what do I mean by
structure and the inputs I simply mean
that you know all this crazy data that
were being inundated with oftentimes has
a lot of structure so it's multimodal
there's different kinds of entities
there's it's multi relational there's
all kinds of different links between
things there's other kinds of structures
spatio-temporal
and so on and I think there's a real
opportunity to have machine learning
algorithms that can exploit the
structure that's in the input on the
other hand there's also oftentimes
structure and the output so think of the
classic kind of structured prediction
kinds of problems in natural language
processing and computer vision and
computational biology and I'm gonna be
talking about some others later in the
talk in computational social science
knowledge graph extraction and so on but
there's all kinds of predictions that
one's making where there's dependencies
between the predictions and I really
like this quote by Dan Roth because all
interesting decisions are structured so
there's all kinds of crazy dependencies
between things but I think a lot of our
machine learning algorithms take this
nicely structured data and we
essentially kind of flatten it and put
it into this kind of matrix form and
that's convenient for our algorithms and
so on but I think there's a bunch of
different issues with this and you know
the fundamental issue is oftentimes
you're making and actually incorrect in
to independence assumption
but then further in the context of the
structure and the outputs you're not
able to do the collective reasoning
about reasoning about the predictions
you make for different entries in this
matrix and you're also oftentimes when
you do this flattening you're doing all
this kind of crazy feature engineering
where you're kind of constructing
features and those are the attributes
that go in your table and oftentimes you
lose that when you later try and
reproduce your methods and so on so
there's a real need to have ways that
you can kind of declaratively talk about
how you transform the structure into
features and so in this talk I hope to
provide you with some patterns some
tools and some templates for dealing
with these kinds of structure in both
inputs and outputs and as I go through
these I really hope that you'll keep in
mind for the kinds of problems that
you're looking at is their structure if
there is structure are you exploiting it
and if you're not could you so the
topics that I'm gonna go over our first
off some really really really basic
patterns for doing structured kinds of
problems and these are naively simple
but we found over and over again that
you if you encode these little simple
patterns you can increase performance
usually a couple percentage points but
often times five or ten percentage
points so these are good tools for you
to have then I'm are patterns for you to
have then I'm gonna go into tools and
for the tools here I'm actually gonna
get into a little bit of technical
detail about some work that we've been
doing some actual some cool equivalences
that we've found across different areas
and how these can make doing these
structured kinds of
problems tractable so this is cool and
then at the end I'm going to be talking
about some bigger templates that build
on these patterns to do kind of
interesting problems in computational
social science knowledge discovery and
also touching on responsible data
science and machine learning so for the
patterns so how am I going to capture
the structure I'm going to use logical
rules these have advantages they give
you an easy way of talking about
entities and links between entities they
tend to be interpretable people like
looking at rules and bear with me if
you're always saying like logical rules
even Brendon yesterday said logical
rules were terrible I'm going to show
you how to actually get them to work in
the second part of the talk but the
patterns that I'm going to go over for
structured prediction problems are
really these kind of basic graphi
problems where I'm trying to either
predict labels for nodes in a graph I'm
trying to predict links between things
and I'm also trying to figure out when
two things are the same and let me just
dive into the first one collective
classification which is simply inferring
the labels of nodes in a graph and the
little pattern for this expressing this
as logical rules is super simple it just
says okay I'm going to use some local
information that I have about the node
I'm going to make a prediction for the
label based on that but then I'm also
going to use this structure so if I have
another node that's linked to it that
has a label I'm gonna use that to infer
the label for the node and how can you
tell that this is a collective or
structured problem if you look the thing
that I'm trying to predict the label
occurs on both sides of the rule so
there's going to be a dependency between
the different ways that I predict the
labels and you know let me ground this
and our really simple
toy problem this is a problem where I
have a social network I'm trying to
infer some label in this case political
label but you can think of any kind of
binary classification problem on a
network and usually in these problems
what happens is you have some labels
given and then you have some set that
are unknown that you're trying to
predict and you want to do this in kind
of a joint way so how do we express this
as rules we're gonna have some local
rules and these local rules can be
things like okay if they donate to a
particular party then they're gonna vote
for that party or if they use a
political slogan that's associated with
some party they're gonna vote for a
party but more interestingly we have
these kind of structured rules where we
say okay if your friend votes for a
party you're gonna vote for a party if
your spouse votes or for a party you're
gonna vote for the party and so on so
super simple but it's surprising you add
these kinds of rules to a flat
classifier and oftentimes you get
significant improvement in performance
the next pattern that I want to talk
about is something with predicting links
or edges in a graph and for this again
we have a really simple logical pattern
that we can encode which is that if I
have a link between x and y and there's
some other variable Z that's similar to
Y then I should have a link between X
and Z so how do I so first off you can
see again that is collective because I
had the thing that I'm trying to infer
which is a link on both sides of the
rule a simple example of this grounded
in a kind of recommender system inspired
setting where I have users I have items
I have whether or not a user liked an
item and then I can have a rule that
says basically it
a user likes an item there's another
item that's similar to it the user will
like that second item conversely I can
also say well if the user likes an item
there's another user that's like that
user then that user will like an item
and I hope you get a sense here where
there's this dependency that's going to
happen between the links that you infer
by the fact that you and for one link
it's going to give you information about
other links and the third pattern that I
want to describe is entity resolution so
entity resolution is the problem of
figuring out when two nodes refer to the
same underlying entity and the pattern
for this again we use some local
information in terms of how similar
things are how similar their names are
how similar their structure is but then
the interesting thing is there's kind of
two different settings in terms of the
collective rules that you can have one
is a kind of transitivity where i'm
saying well if x and y are the same and
y and z are the same then x and z are
the same the that works in some domains
but in other domains you actually have a
kind of matching problem and so you see
that there's this dependence on both
sides of the rule where it's slightly
different where you say well if x and y
match and y&amp;amp;z are different then X and Z
can't match so this is a little bit more
matching kind of problems as I can only
match to one thing and again in some
domains this is appropriate structure to
have so these are super simple patterns
they buy you a lot but I actually really
like the case where you put all of them
together and you have these kind of
crazy loopy kinds of graphs and I'm
going to be talking about those and
talking about how you get those to work
later in the talk but
i frame this all as logical rules and
logical rules have advantages but they
also have major disadvantages so the
disadvantages is dealing with them as
intractable as soon as you have like one
inconsistency everything falls apart and
then on top of it you know I talked a
lot about similarities and you know
encoding that as a binary predicate 0 1
doesn't work very well and so it's
really nice to be able to have the
ability to represent these so I'm going
to talk about some tools for actually
really getting these patterns to work
and the tools come from the statistical
relational learning community there was
a tutorial on Monday on statistical
relational AI there was also a tutorial
on probabilistic programming so it's
coming from this world building on this
there's been a lot of different
languages proposed and we're going to be
adding one to the mix called PSL what
does PS I'll stand for PS l stands for
probabilistic logic programming and it's
a declarative language for expressing
these collective inference kinds of
problems
the key reference is this recent jam LR
paper that goes into way more detail
that I'm going to be able to go into
here this URL has a code it's open
source downloadable there's tutorials
datasets and so on but the basic idea is
that we're going to take these logical
rules and assign weights to them and
this is just like a bunch of other
languages most notably Markov logic
Network coming out of Pedro Dominguez
group we're going to use this to define
a distribution over the unknown
variables but then the place where PSL
differs is we're going to make the
random variables continuous valued and
I'm going to explain three
in semantics for why we end up doing
that
and then the cool thing is we're able to
make doing logical inference tractable
and this work allows us to take these
disadvantages and turn them into
advantages so now we have a tractable
way of doing things we can deal with
inconsistencies and on top of it as
you'll see we can represent similarities
so the foundations for this are very
much some nice work by my former PhD
student Stephen Bach who happens to be
on the academic market he also is one of
the co-organizers of Saturday's workshop
on learning from limited data but
fundamental to his results are kind of
mapping the logical rules to concave
functions and turning this into a
concave maximization problem and I'm
gonna unpack this for you but for right
now try and kind of imprint this formula
on your brain we're gonna see it a
couple more times in the next few
minutes and the nice thing is we have
semantics from three different worlds
one is coming from the theoretical
computer science community and
randomized algorithms one of them is
coming from the machine learning and
statistics world around graphical models
and then the third is coming from the AI
community around soft logic so let me
start with the first one and randomized
algorithm so in this setting we have our
weighted rule so we have these
non-negative weights and we've turned
the expression of the rules into clausal
form and we've introduced an index that
goes over the positive literals and the
negative literals and now we did max
that as a classic problem where you
attempt to find the assignment to the
random variables that Mac
Mises the weights of the satisfied rules
awesome except for this is np-hard
so there's very nice work from the
randomized algorithms community where
they convert this combinatorial
optimization to a continuous
optimization by introducing random
variables which denote rounding
probabilities and these rounding
probabilities are the probability that
you round up to one or down to zero and
then there's this nice result from 1994
where they expressed the expectation for
this optimization and then they
introduced a linear bound on this
optimization and the cool thing is they
also were able to show an approximation
guarantee that the continuous solution
to the linear program if you did a
simple technique for turning it into a
discrete solution gives you a 3/4
optimal solution so awesome and if you
paid attention and memorize that formula
from a couple slides ago this has
exactly the form that I showed earlier
so cool now we go to a different
community the graphical models community
and in the graphical models community we
can represent our problem as a factor
graph where I have random variables and
now the rules are essentially the
potential functions and this represents
a Markov random field the distribution
for this is kind of the standard way of
expressing this distribution and the
factor graph and then to do map
inference it's simply to find the
assignment to the random variables in
max
Mises the probability so we have this
form the only problem is of course this
is empty heart too so we're going to
turn to approximation techniques to
solve it and we're going to use very
variational inference where we introduce
muse that are the marginals for the
variables we can then express a solution
if we can find a globally consistent
assignment for these marginals the only
problem is you can express it as a
linear program but there's an
exponential number of constraints so
we'll use techniques from the graphical
models community particularly local
consistency relaxations to convert this
to a simpler problem and there's been a
ton of work in this space these are some
of the kind of key original papers in
here but the basic idea is you have this
complex poly tope I'm going to relax the
constraints so we're going to do exactly
the same thing here and we're gonna do
it by introducing these pseudo marginals
local pseudo marginals will express our
optimization as before and then what
Steve was able to show together with
some former postdoc Burt Wong is by
making use of the KKT conditions we can
optimize out the Thetas we can project
this into a simpler form for the
objective and if you look at this it
turns out to be exactly the same form we
saw before and they actually did a bunch
of work comparing to other kind of LCR
methods dual decomp and so on and in
some particularly loopy problems showed
a lot of benefit from doing this so
these are two approaches where I get the
same
convex problem the third approach comes
from soft logic in soft logic what we do
is we have random variables that denote
degree of truth or similarity which i
said was going to be useful there's a
bunch of work on different ways of
expressing these kind of boolean
expressions in these logics the one that
we're going to use it ends up being
quite convenient is something called
Lukesh Eve it's logic which defines
these operators as follows
and with a little bit of algebraic
manipulation we get out max at objective
where we can solve this exactly in this
case using this convex optimization and
one way to interpret this is basically
this term here is you know we have these
clauses I'm adding up the truth values
and either the clause is satisfied so
it's 1 or there's some sort of you know
amount of satisfaction and essentially
I'm trying to minimize the amount of
dissatisfaction in the rules and so
again this ends up giving me the same
form so the really cool thing about this
is three very very different
interpretations you get out the same
convex optimization and it gives you a
way of scale ibly dealing with logic
probability and similarity so I think
this appalled I think it's actually kind
of the tip of the iceberg I think
there's lots more to do here but going
beyond this we introduced a notion of
hinge loss Markov random fields just add
some bells and whistles to language now
we allow arbitrary linear potentials we
also allow hard constraints we allow
squared hinges and the general form
looks kind of similar but it's still
convex
a PSL program looks something like this
so this is a program from the collective
classification that I described earlier
and PSL essentially takes one of these
programs take some input data and
defines a convex optimization but now we
can make it even faster
this kind of MRF actually has a lot of
fine grain structure and so by looking
at this fine grain structure we can
actually improve our optimization
techniques even more and we used
optimization technique 80mm in order to
do this but basically the idea is you
solve these little subproblems
independently you combine the results
and it's guaranteed to converge for
convex problems the only trick in doing
this for PSL is how do you take the
potentials and solve them quickly and it
turns out the potentials have this nice
form where you can decompose it further
and it turns out if you go this far and
decomposing the problem you actually get
these really simplified algorithms and
programs optimization programs and so if
we compare this to an off-the-shelf
optimizer like CB X PI a kind of
industrial-strength optimizer like
mosaic versus RPS l80 on them you know
we're just blowing it out of the water
this graph is at a scale that you can't
really even interpret it for example a
problem that has a hundred and fifty
thousand potentials it takes like three
hours using CVX pi it takes three
minutes using mosaic and it takes like
seconds with 80mm our implementation and
with PSL we can do something
as 800 million potentials in less than a
minute so that's great it's fast but it
can be fast and not be very accurate so
how well does it do here's some sample
results across this is a activity
recognition problem
computer vision kind of problem and this
is the example of many of our results
where you start off with just a really
dumb simple approach and in a little bit
of structure and you get significant
improvements in performance comparing
two discrete MRF we can solve them as
well
but we can do it way faster across a
collective classification and link
prediction tasks and for something where
you're really reasoning about
similarities so this is for a drug
target interaction prediction accountant
bio kind of problem we're able to do
something that beats state of the art
but I think the most interesting thing
about this work is that it gives a way
of extending it so if you have more
information it's easy to go from here so
to summarize PSO it's fast we can make
it extra fast using smart optimization
techniques I haven't talked about it
here but we do have methods for learning
the weights and also methods for dealing
with latent variables that changes the
problem and as I said before it's open
source and you can get all the
information here I want to turn now to
these templates so now I hope I've
convinced you that we have a way of
solving these problems but let's go back
to our patterns and develop kind of
bigger kinds of
structured problems and I'm gonna do
this across three different areas so the
first one is computational social
science I think this is a really
interesting area where there's a lot of
opportunities for structure prediction
kinds of approaches and the first
setting that I want to go over is some
work by my senior PhD student Tanya
Streeter where we were looking at stance
classification and online debates and
here we have a topic climate change
related to the first invited talk we
have these people that are posting on it
and we can use information in the text
to figure out you know are they pro or
anti the topic but we can also use
information about the dialogue in the
discourse so people are agreeing with
each other they're disagreeing with each
other and the cool thing is we can
encode this as a PSL model in a really
simple way this builds on our collective
classification example from the
beginning where we have local
classifiers that try and predict first
off the stance of a post and second off
for an exchange isn't an agreement or a
disagreement kind of exchange and then
we can do some reasoning where we say
okay if someone post something and it's
pro and someone disagrees with that then
that person's post is anti if someone
post something in their Pro and they
agree then that post is pro and
similarly we can do this kind of
reasoning with the agreement and
disagreement links and we get out
something where we compared to a simple
just text based classifier and we get a
significant bump up in accuracy just by
adding in these
kind of really simple kinds of potential
functions the next computational social
science problem that I want to go over
as one around predicting links so
predicting trust links in particular and
the thing that I like about this work is
we're able to actually model two
different theories that are coming from
the social science world about how Trust
links form and one of these is
structural balance where this is the
idea that well a friend of a friend is a
friend and an enemy of an enemy is a
friend and so on and they have all these
different balances for the pluses and
minuses the trust and distrust that are
encoded in this theory so we can
represent this in an easy way as a PSL
program but then the second model that
comes from the literature is something
called social status and this is when
you're in kind of a more hierarchical
setting where you kind of look up to the
people above you on the hierarchy and
you distrust the people below you in the
hierarchy so in this model you have if a
trust b and b trust C then C doesn't
trust a and again you have some
collection of different valence 'as for
these triangles but the cool thing is
it's really easy to encode this as a PSL
model and this is work that burt wang
former postdoc led where we compared to
existing approaches in the literature
and both of the PSL approaches did
significantly better but then the cool
thing that we did next which i think
happens in a lot of computational social
science kinds of problems is we could
add in a latent variable and this latent
variable has a totally reasonable
semantics and we're going to say how
trusting or how trustworthy
is an individual and we can you know
encode this then we add this to our
model and this totally blows away all
the other models so the simple thing of
introducing latent variables in a smart
way and then kind of making use of the
structural constraints and then
evaluated on structure I think is a
common pattern so we've done a lot of
other things in computational social
science I just want to call out briefly
some nice work by already Ramesh on
modeling engagement in MOOCs some work
by P cooky on hybrid recommender systems
and explanations and then finally some
work by Sabina Tompkins that she's going
to be presenting at a nips workshop on
Saturday on cyber bullying and so I'm
excited about this face I'm really happy
to talk to folks afterwards if you are
interested in trying to model things in
this space but let me turn to a really
different kind of setting but again
where I think structure and making use
of these patterns really pays off and
this is a knowledge discovery or
knowledge graph construction and this
has worked those very much driven by my
former PhD student J pooja Roth who also
happens to be on the academic job market
and he is also one of the co-organizers
of the h ABC workshop that's on Friday
and so if you want to know more about
this topic I'm just gonna go briefly
into it but definitely go to this
workshop to find out more but the basic
idea is that we have these techniques
these information extractors it can
extract out facts from the web and from
other online sources and these facts can
be facts about entities they can be
facts about relationships but extractors
are usually really noisy and so how do
you reason about them collectively to
figure out which are the facts that you
want to actually add into your knowledge
base and the cool thing is that we can
actually use exactly the patterns that
we gave at the very beginning this kind
of collective classification this link
prediction this entity resolution all
are super important in constructing the
knowledge graph but then on top of it we
can use ontological constraints and
ontological constraints are things like
subsumption relationships mutual
exclusion relationships are super useful
but the classic things for dealing with
ontological constraints are intractable
and so we're going to use probabilistic
soft logic to kind of make this
inference but make it tractable and then
on top of it we can make use of
extractor confidences and throw that
into the model as well so we can use PSL
to make this tractable and the PSL
program looks something like this and
this is very much building on some work
that Daniel loud at all had done using
ml ends for doing this but the program
is quite simple in terms of capturing
ontological constraints capturing entity
resolution constraints capturing other
kinds of things about the extractor
confidences and he evaluated this on
three real-world knowledge graph pretty
large-sized some of these were knowledge
graph constructions and the last one was
free brace is actually a linking problem
so you're trying to match across these
databases but to summarize the results
he was able to show that kind of across
these three different settings using
each of the aspects of structure
prediction then I talked about we can
improve performance
and that's great but we can do it fast
so we can do this in a way that takes a
few minutes to do it even over these
really large knowledge graphs then going
to a different kind of setting where
there's been a lot of work on embeddings
these have been shown to work really
well and particularly well when you have
a lot of data but we compared applying
them in a setting where you have more
noisy data more sparse data and found
that our TSL methods really helped even
baseline methods we're doing better than
that
embedding methods and I think this is
really just a hint at how do we combine
these kind of settings where you have
embedding methods that work well versus
structure methods when you don't have as
much data and so on and I think this is
a interesting area for further work so
the last thing that I want to touch on
is actually a quite different
interpretation of structure and this
goes into the area of responsible
machine learning and kind of connecting
to there was yesterday's talk on bias
there were tutorials on fairness but
it's the perils of ignoring structure
and the perils of ignoring structure
actually in your domain and the easiest
case to start with is privacy so a lot
of the work in privacy says oh you know
in order to be safe just you know make
sure you hide all your attributes and
then you'll be fine oh if you're linked
to people that happen to be
exhibitionist that you know tell
everything then you're not going to be
very private you can they can leak a lot
of information there is actually some
nice work by my former PhD student Alain
Saliba who looked at this setting and we
all kind of get the sense that you'll
leak information from the people that
you're linked to but what she showed is
that actually that group said you're a
membership of leak a lot more
information and oftentimes that's
something that you don't even have
control over hiding so this notion of
how does this structure impact the
information that's leaked about you and
who controls access to that information
I think is really interesting and
thinking about it from a structured
product perspective is important the
other area is around fairness and now
this is a topic that's receiving a lot
of attention now which is great but I
think there's something that's missing
in it which is understanding the
structure and the structure is often
something that's outside the data so the
structure can be either something that
is in the organization or in the social
economic structure and being able to be
cognizant of this when you're doing your
modeling and having a way of expressing
it is important and my current ph are
postdoc ganoush Furnari has some initial
work where we've been in able to encode
these fairness constraints as something
in PSL where that you can then make sure
you obey those constraints and then do
the optimization for learning in that
setting in the final place where I think
there's a real opportunity to make use
of structure and really understand
things is in this notion of algorithmic
discrimination and the fundamental
structural pattern there is that there's
some feedback loop and the feedback loop
is something like the rich get richer
and the poor get poorer and so on so
having a way of encoding that I think is
important and
understanding the structure can end up
being the key to kind of mitigating some
of the negative effects in these kinds
of settings so in closing let me do the
most important part of the talk which is
acknowledgments I have an awesome group
of students I have a terrific collection
of collaborators and I'm lucky enough to
have wonderful sponsors and a lot of
great companies that I've worked with I
personally think that's one of the best
things about being in this area you know
all the cool people that you get to work
with as far as the unreasonable
effectiveness of structure now I kind of
come at it I hope I've given you the
perspective that there are ways of
exploiting structure that can be
tractable but really I think what we
want to do as AI and machine learning
folks is kind of complete the loop and
really kind of being able to build on
our approach as a discover structure
exploit structure find new structure and
so on and I think there's a real
opportunity in this space and I hope
that I've kind of given you some ideas
so ideas for different ways in which you
can exploit structure different ways in
which you can use it effectively like I
said in the last slide I think kind of
there's this opportunity for combining
unstructured and structured but there's
also these opportunities in combining
logical and probabilistic or as you saw
combinatorial optimization and
continuous optimization and then finally
you know from an AI perspective there is
this opportunity to be both data-driven
and knowledge driven but in doing that
in kind of a coherent way that ends up
being also tractable and I think there's
tons of cool applications across all
kinds of areas and this is a real space
for opportunities so thank you
thanks for a great talk we have some
time for questions if you would like to
ask questions please line up near the
microphones and please speak into the
microphones there's a question there
thank you for a great talk a question
how do you handle situations when there
is a structure but you don't know
exactly what kind for example you're
predicting sales of various products and
there is cannibalization effect but you
don't know to what degree how strong and
between which entities so I'm sorry I
couldn't hear
I heard the gist of your question but
not the particular sure so how do you
handle situations when there is a
structure but you don't know the exact
nature of the structure for example you
have a deep learning model that predicts
sales of products and there's
cannibalization effect you introduce new
product that effects another but you
don't know how much so how do you handle
that so I think there are approaches
where you can encode something about so
either it's completely unstructured and
you need to kind of map this kind of
unstructured thing you discovered into
some form of semantics and I think
that's an interesting area but not one
that I know how to do or have really
looked at I do think that there's an
opportunity though in kind of
structuring the model of kind of making
use of something that you know about the
domain something that you know about the
entities and so on and I didn't quite
catch the part about the particular
thing that you were worried about in
terms of the evaluation of it
let's say that you sell three products
and you think you're introducing a new
one and there is similarity between
products but you don't exactly sure how
to measure it and you're concerned that
introducing new product and your other
product sales goes down as a result and
you're trying to figure out J predict
individually for each product or
decorate some sort of a rule that this
affect that but you don't know how much
and what effects what I yeah so the
assignment problem so we in this
studying I think that you could kind of
look at different models that are making
either introducing some more structure
into the similarity corresponding to
product classes and so on and compare
performance but exactly how you would do
that and make sure that it was
comparable across the models is
non-trivial thank you
that's a question here hello okay thanks
professor for a great talk I have a
question concerning this a probabilistic
softer logic which seems to be a remnant
of fuzzy logic so my first question is
about would you please elaborate what's
the difference what's the difference
from the fuzzy logic I say so this is
interesting and the term soft is coming
from fuzzy logic so we are using a
particular interpretation for the rules
that comes from soft logic but then the
place where there's a huge difference
between what we're doing and what fuzzy
logic traditionally does for doing
inference is we take this interpretation
and then we put it into a probabilistic
model so we put it into a graphical
model and so there's a piece that we're
using
that is the same which is Luca Shiva's
logic but then the way that we actually
do inference is different is okay asking
one more question just one more
so what's in the connection about this
PSA softer logic to deep learning do you
see any kind of opportunity to explore
on the connection cool yeah so in terms
of the connection I think there is kind
of a superficial answer to this which I
still think is promising and interesting
which is you can combine the two in
reasonable ways there's a deeper
connection if you really look at the
kind of form that we're optimizing and
try and kind of push that in and make
analogies between deep learning and this
is something that actually I've talked
with Misha so so I think there's
opportunities there as well for actually
a deeper technical connection between
the two and it's not surprising that
there there would be yeah my question
there hey thanks for the talk I had a
question so let's say you have like a
set of rules and you're about to add an
extra rule so they're like kind of three
cases this rule like doesn't give you
any new information it doesn't change
any assignment of your labels or
anything
this rule is like helpful if you know it
improve your prediction in some cases
and this is like third type of rule
which is maybe it make your whole
optimization problem super hard or maybe
select wrong or anything so is there any
way we could you know get who I know
define which rules are helpful or reject
some rules yes so definitely one thing
that I didn't talk about is simply the
weight learning where you can figure out
you know which rules and what weights
should they have but a bigger thing is
what model selection or
actually structure learning is what it's
often called where you actually learn
the structure of the rules and for that
there are some existing techniques that
I think you could just directly pour it
over to PSL but I think there's
opportunities for doing things that are
even more interesting where you actually
have kind of a meta PSL program that
learns the structure of the PSL model
and that's something that we're actually
working on in the context of causal
models so that it's an important problem
we have a question here and I'm afraid
in the interest of time that'll be the
last question that we can take why thank
you for a great talk I just wanted to
ask a clarifying question you said that
the potential functions that decompose
but you didn't say much about the
complexity of the rules is there a
specific family of rules we have to
stick to in order for the potential
functions to decompose how complex rules
can we incorporate yeah sorry I probably
went over that too fast so the form for
the potential functions is very specific
it's this kind of hinge loss kind of
thing so there are convex and they have
these they're linear in that sense and
so a lot of what I was doing at the
beginning was all around how do you take
a potential function that's expressed as
a logical rule and then convert it to
this hinge loss but yeah there's a
restriction that you're going to have
these and that's the place where you get
the tractability from if it's products
or any other form I cannot use this
technique so the general technique works
when you have these convex things and
then we've done some things that are
specific to the particular form so you'd
have to kind of look I hope that easy so
as you do but yeah it's very much a
choice not surprisingly
to get it to be that tractable thank you
let's tank the speaker once again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>