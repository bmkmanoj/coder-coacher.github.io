<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Blake Richards - Deep learning in The Brain | Coder Coacher - Coaching Coders</title><meta content="Blake Richards - Deep learning in The Brain - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Blake Richards - Deep learning in The Brain</b></h2><h5 class="post__date">2017-09-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dZwB5Mj-PPM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so yeah says Yahshua said we're gonna
have a bit of a change of pace here this
morning because we're gonna start I know
we've done a little bit of it I saw
Rich's talk but we're gonna start to
focus a little bit more this morning on
the actual brain as opposed to just
artificial brains though of course the
the focus will be on trying to
understand what unites both the
artificial intelligence that we are all
interested in here and the natural
intelligence that sits in our skulls
so obviously the recent success of deep
learning and artificial intelligence
means that for most people if you
mentioned deep learning they're gonna
think about AI it's natural when you
read news article after news article
about how it's changing the world of
artificial intelligence but one of the
things that I I think many people often
don't really know people who aren't
involved in the area is that one of the
goals of some components of deep
learning research was always to
understand how our own brains work the
researchers who really helped to
resuscitate neural networks research in
the 1980s the parallel distributed
processing group wanted to understand
human intelligence and wanted to
understand how the brain works so in
this session and so did the ones in the
early 2000 that's right so it wasn't
just them yeah if you look at in fact
let's let's be clear here if you look at
the people who really push deep learning
forward in the 2000s like Joshua and and
Jeff and and Jana and stuff they are
interested in how the brain works so
deep learning is not just about AI it's
also about your brain and I'm gonna talk
to you today a little bit about how
current research is looking into how
deep learning could be implemented in
the real brain now let me just motivate
this a little bit more one of the other
interesting things that's come out in
neuroscience over the last couple of
years is
that deep learning models actually are a
better fit to neocortical
representations that we record either in
a functional magnetic resonance imaging
system or using Tet Rhodes and monkeys
then any of the existing models
developed by neuroscientists to explain
the brain and that's I think a very
interesting fact so what you're looking
at here is on this plot the x-axis is
the categorization accuracy of different
visual processing models on I forget
which dataset it might have been see far
10 or something like that
and on the y-axis you have a measurement
of the resemblance between the
representations in that computational
model in that neural network and the
representations that were actually
recorded either in human inferior
temporal cortex on the top or in monkey
inferior temporal cortex on the bottom
and one of the first things that of
course should jump out at you is that
there is a correlation between how well
the models do on categorizing different
images and how similar their
representations are to what we actually
measure in the brain of primates but the
second thing I'll point out is that so
each dot here represents a different
model a different computational model be
it a neural network or some other model
and the colored dots represent different
layers of a deep convolutional neural
network so here at the top you see layer
seven of a deep convolutional neural
network it's of course doing better at
categorization of the images than any of
the other models that we all know that's
why you're all here but also
interestingly it is more similar to the
representations observed in inferior
temporal cortex of humans brains and
that's pretty remarkable so
the little numbers are each a different
model that a neuroscientist has proposed
to explain how visual processing works
in the brain and that is their results
on categorizing seif are 10 and their
similarity to human cortex oh I'm sorry
I didn't cite that paper my apologies I
will send Graham updated slides with
that citation all the other citations
are in the talk you'll excuse me I was
working on a DARPA grant this week the
the this was by Nicholas Critias Cortez
lab and out of Cambridge but I will I
will be sure to update the slides so you
can look this paper up as well my
apologies
ah so anyway the underlying message is
that it looks like oh we have more
questions yeah that's correct
mmm-hmm category yes that no that that's
not actually trivially the case so for
example one of the interesting things
that came out of this paper it's a good
point though sorry yes so let me try to
paraphrase what you said given that
we're looking so so you know in for your
temporal cortex is a region of the brain
that's particularly concerned with the
categories of different objects that
you're looking at and so what was
pointed out is that if you have a model
that is principally concerned with
categorization and you look at the upper
layers where all the categorization is
going on inevitably it's going to be a
better match to a region of the brain
that is doing categorization is that
roughly correct right sure yes however
here's what's interesting so one of the
things that this paper showed was all
right so so one of the differences
between one what human brains seem to be
doing and what a lot of the other models
seem to be doing is that there are
interestingly enough very large
distances between the representations
for animate and inanimate objects in the
human brain and that doesn't pop out of
the existing neuroscience models it only
comes out of these deep learning models
once they've been trained to categorize
that but that's not necessarily always
going to be the case per se like you
could imagine a system which is
perfectly good at doing categorization
but doesn't have larger distances
between inanimate and animate objects
than it does different categories of
animate objects for example
now what I will say though where I think
you're very right is look the reason
that these deep neural networks are
ultimately coming to resemble this part
of the brain is in part because we're
training them on a categorization task
but what's interesting is if you train
deep neural networks on other things as
well or even on categorization tasks
there's even still better matches in
lower parts of the visual hierarchy that
are principally responding to category
what I the other thing I'll add to this
though is I think that the reason it
comes out is simply because the correct
answer to doing these categorization
tasks is in fact to have the distances
between the different categories that
the human brain does because that is the
result of cost function optimization
well we'll come back to that though but
anyway yes thank you that's a very good
point so ah anyway what I was trying to
do there ultimately is just motivate the
idea that our brains are doing something
like deep learning and let's just be
clear on what we actually mean by that
so of course the key to deep learning is
the ability to improve learning by
adding hidden layers if you if you look
at ultimately what distinguishes the
modern approaches and neural networks to
other approaches and machine and tout
and your machine learning or machine
vision etc it is the addition of all
these layers to the model so if you're
gonna use a model that has many hidden
layers to it the issue that you're going
to be presented with is what's known as
the credit assignment problem so the
credit assignment problem is is this
which you're probably familiar with if I
am a neuron and a hidden layer and I
need to update my weights in order to
optimize on some cost function I need to
know how much credit and or blame I
should get for the current results that
the networks getting on the cost
function for the current behavior of the
network
so we need some way of assigning to each
neuron in each synapse in the hidden
layer its contribution to the output of
the network now the obvious way to do
this of course is back propagation so
that propagation has been invented
multiple times by different groups and
the reason is that it is kind of like if
you're if you're addressing this
question of how am I going to do credit
assignment and the hidden layers it's
it's kind of a nice clear obvious way of
doing it so of course you all know but
we're just going to review here very
quickly that the principle behind back
propagation is that we're taking the
partial derivative of our cost function
with respect to the synaptic weights in
the hidden layers so if we have a neural
network here with input X hidden layer
activities H output Y target T we can
define the error as being the difference
between the output of the network and
the target our loss function is then
just the squared error and if we take
the partial derivative of this loss
function with respect to the weights and
the hidden layers we get this expression
just using the chain rule so this
equation then for a one layer hidden one
hidden layer neural network and I'm
gonna stick to this just for sake of
ease in this talk but it everything I
say should ultimately apply to more
layers if you if you have this equation
this is is your weight update for the
synapses in the hidden layer
now let's unpick this a bit so here's
the equation we need to do we need all
this information to update our synapses
in the hidden layer of the neural
network and so let's just start to pick
it apart let's look at what what the
brain would actually have to calculate
in order to do back propagation right
like if we're saying the brain is doing
something like deep learning and most of
our deep learning systems use back
propagation does our brain do something
like back propagation and so let's see
what the brain would have to calculate
to do that well of course the first
thing is you need the error term so you
need the difference between the output
generated by a forward pass through the
network and some target that has been
assigned to the network you're going to
need to multiply that by the transpose
of the downstream weights so you've got
a set of synaptic weights from the
hidden layer to the output layer and
that's got to be there in your equation
multiplied by your error term
additionally you need the derivative of
the hidden unit activation function and
ultimately all of this both the error
and the derivative of that hidden unit
activity depends on you having an
initial forward pass through the network
and then theoretically a backward pass
where you're calculating this so we've
got these four elements that we need for
this equation to work you also need of
course the input but we're assuming that
that's trivially available to the brain
so we need these four things we need our
error term we need the transpose of the
downstream weights we need the
derivative of the activation function
and we need separate forward and
backward passes all right well the thing
is that all of these are problematic for
the brain and it is in fact why
neuroscientists for many years largely
dismissed the idea that the brain does
anything like back prop because if
you're an intelligent biologist and you
understand what these terms are and you
understand how you could calculate them
you take a strong look at it you're like
well this is just bonkers the brain
can't do this so let's run through each
one so at least in the neocortex so the
brain can calculate error terms that's
that's not actually a biggest unit of
itself but the specific error term that
the difference between a forward pass
and some target that you've received
there's no evidence for anything like
that in the neocortex and of course the
neocortex is the region of the brain
that we're interested in here sorry I
didn't say that earlier we're interested
in it not only because it has good
matches to deep learning models as I
showed you with that previous result but
also because to the to the best of what
neuroscientists concede the neocortex is
the closest thing to a kind of
general-purpose learning machine akin to
the artificial neural networks we learn
we use an AI now some other parts of the
brain can definitely learn but they are
often crafted towards more specific
purposes your neocortex is really this
incredible just general purpose
homogeneous learning machine so there's
no clear implementation of those kind of
error terms in the neocortex and that's
problematic the second one and one
that's been arguably more traditionally
like a total non-starter for many
neuroscientists is this issue of the
transpose of the downstream weights if
you are a neuron early in visual
processing stream so let's say you have
a neuron in your primary visual cortex
the idea that it would know the synaptic
connections all throughout the rest of
your visual processing string is just
crazy we know of no physiological
mechanism by which that could be the
case now alternatively you could have a
situation where you've got feedback
weights that are perfectly symmetric and
we'll talk about that in a moment but
that in and of itself is also
problematic so experiments show if you
take any two neurons and you look at
whether they're connected to each other
there is not only no guarantee that the
synaptic weights between them will be
similar there's no guarantee that they
will both be connected reciprocally to
each other so it's a totally non trivial
matter to have backwards projections
that are symmetric with your forward
projections and this was something that
Francis Crick pointed out in an article
back in the 1980s when people first got
excited about back propagation in kind
of cognitive science and ever since that
point most neuroscientists have
dismissed the idea of anything like this
occurring on the brain now the other
thing you need is the derivative of the
activation functional so that's fine
when you've got a sigmoid activation
function applied to a linear term but in
real neurons this is actually difficult
so real neurons don't actually
communicate analog signals to each other
they communicate with something known as
spikes
we'll talk about a little bit more in a
couple of slides and spikes are all or
none events they can be thought of as
effectively yes or no and the problem is
that when you've got an all-or-none
event it's not clear how you take the
derivative of that so that's another
problem for this yeah oh yeah we're
gonna cover one of those papers yeah
it's not actually a problem I'm going
through the logic of why neuroscientists
haven't bought back prop in the brain in
fact the rest of this talk is gonna be
me knocking down each of these points so
the other issue is that there's no
evidence for separate forward and
backwards passes right like when we look
at the activity in your brain it's not
the case that like light hits your
retina and then there's a sweep of
electrical activity forward for your
visual processing stream and then after
that a sweep backwards of electrical
activity from I don't know your
prefrontal cortex or something like that
your entire brain is always active it's
always chattering amongst itself and the
idea of separate forwards and backwards
passes at face value seems problematic
okay but as I was saying over the last
couple of years we've seen a lot of
progress in addressing all four of these
issues and I'm gonna try to bring you up
to date on that and just maybe convince
you that it is in fact possible that our
brains do something like back
propagation okay so let's start with
that first one the error term so the
brain as I said can definitely calculate
error terms your motor system is full of
error terms and they're really important
for helping to correct motor control
that you're doing online but as I said
you know there's no evidence for
something like the sort of error term
that we want for back propagation for
many of the things that you've Anil
cortex lines so let's say for example
when you're learning to speak right
there's no evidence that you try to
speak as a kid and then somehow a
target is formed in your brain based
upon what your parents are saying what
you did and what your parents say gets
subtracted from each other and then that
subtraction somehow gets propagated
through your brain there's no evidence
for anything like that
now but it is the case that you do have
your parents talking around you and
giving you an example of how to speak so
even though you don't have this explicit
comparison between what you did and what
you should do you probably do have
something that's kind of pushing you
towards the right answer some of the
time and so ideally what we'd like is
we'd like a network which which has
these sort of just like nudging signals
so that the the network just
occasionally gets pushed by
environmental feedback towards something
that is more like the right answer than
what you had done previously and that's
that's theoretically possible given the
stimulus we received in the environment
so this is something that Joshua and his
postdoc is Benjamin a postdoc PhD
student and his PhD student
Benjamin who've been working on and they
released this year a paper on a system
they call equilibrium propagation and
yahshua feel free to correct me if I get
any of this wrong I know
so what they what they do in this system
excuse me mm-hmm what they do in this
system is rather than having a forward
pass and then explicit calculation of an
error between that forward pass and some
target that you have they've got two
different phases for their network so
here's an image of the basic idea for a
network that's going to do something
like back prop though this algorithm
works with many different network
architectures not just this stacked
architecture and I'll just mention a
change of variables here so we're still
referring to our input as X our output
is Y and our hidden layers is H but now
you here is going to refer to the entire
set of units activities ah and D is our
target now the idea is that what you
have is you have a phase where there is
no kind of nudging from the external
environment so this would be like your
parent who's speaking correctly in front
of you
right and so sometimes you don't have
your parent there and there is no
external nudging signal but sometimes
you do and they use this term here beta
to indicate the difference between those
situations so they call when beta is
equal to zero that's the free phase and
that's when there is no nudging on the
system from the environment when beta is
greater than zero the system is being
pushed towards the right answer by the
environment and they call this the
weakly clamped phase the to get a full
clamping like is done in actual
artificial neural networks you would
have beta equal to infinity and then the
system is just kind of like a standard
neural network in that during that
clamped phase it is getting the correct
answer forced on it but as long as beta
is non infinite what we've got is weak
clamping and so the system is just kind
of getting nudged towards the right
answer and so what they what they show
I'm not going to run through all the
derivations and stuff I
you to look it up in this paper here so
they develop energy terms for this
network so that they can know what the
networks going to settle to both with
the nudging term and without the nudging
term and then by taking the derivative
of their energy terms they can get out
this synaptic weight update so this
synaptic weight update basically says if
you've got any two neurons that are Co
active together during the point in time
in which the nudging factor was present
you want to increase the weight between
those two neurons and if you have any
two neurons that were Co active during
the point when the when it was in free
phase you want to decrease the weight
between those two neurons and this
difference is then going to give you
your weight update and in fact what what
Benjamin and Yahshua show is that this
can implement stochastic gradient
descent on the standard loss function
just the error between D and Y ah now
this is reminiscent for those of you who
do know this kind of stuff of things
like contrastive divergence or Boltzmann
machine training in that you are kind of
looking at yeah any loss that's
differentiable okay right right as where
the loss is defined by how your tart
what your target is right yeah okay
right cool so what what's what's very
interesting about this then is so like I
said it's got a flavor kind of like
contrast versions kind of like Boltzmann
machines etc but critically they're not
really just clamping the correct answer
on the system there is no point in time
at which the system is forced to have
the correct answer instead it's just
getting nudged towards the correct
answer which is something probably more
like what your brain actually
and is less problematic than the error
term that is typically passed around in
backpropagation I think now the other
thing that's very interesting about this
is it predicts a classic set of
experiments known as spike
timing-dependent plasticity so let me
unpack this a little bit for you so here
you've got an illustration of two
neurons these are the yellow dots
that's what neurons look like and they
are connected by a synapse so we've got
a presynaptic neuron J and a
postsynaptic neuron I and we can look at
the time at which these two neurons are
active excuse me I'm gonna do that we
can look at the time at which these two
neurons are active so here we've got a
little plot neuron J is active at this
point in time and neuron I is active at
this point in time and when I say active
I mean firing a spike and what
researchers have shown not just in the
neocortex but in a remarkable number of
brain regions is that if you look at the
difference in time so if you take two
neurons that are connected and you
repeatedly get them to spike with some
temporal difference between them so
let's say we always get the red neuron
to spike just before the green neuron
then you're going to get a particular
change in the synapse and the change in
the synapse is going to be dependent
upon that difference in time between the
presynaptic and postsynaptic spikes so
that's what's actually plotted here on
the x-axis on the x-axis is the
difference in time between the
presynaptic spike and the postsynaptic
spike where so it's TJ minus TI so if TJ
is greater than TI we're in the negative
phase sorry if it's less than TI we're
in the negative phase here and if TJ is
greater than TI we're in the positive
phase here so in other words this half
of the plot is where T the J neuron
spiked before the INR on and this half
of the plot is where the INR on spike
before the J neuron
and these dots are actual experimental
recordings of so on the y-axis we're
plotting the change in the synaptic
connection between them and you see this
very clear relationship between the
temporal difference between those spikes
and how much the synapse between those
two neurons change a neuroscientists got
very excited about this result
when it was when it first was discovered
and especially when it continued to be
discovered a number of brain regions
because it's it's it's the closest thing
they had kind of ever gotten to a clear
learning rule for how synapses are
updated in response to patterns of
activity and you can show that it has
some interesting properties it seems to
be for example training neuron j to
predict the activity of neuron i it has
a kind of causal flavor to it but what's
interesting is so yahshua and benjamin
showed that in fact you can get stdp out
of a set like out of a learning
algorithm that has this relationship
where the the ton change over time of
your weights is a function of your
postsynaptic activation times the
temporal derivative of your presynaptic
activation that was the original one
right and then you can modify this to
instead be the derivative of the full
activation function right and what they
also show is that this relationship does
in fact hold for their equilibrium
propagation algorithm and so in other
words their algorithm though it's
ultimately designed to be doing gradient
descent on these cost functions spits
out stdp
if you were if you were in a if you if
we imagine that that there we had a
neural network learning by this
algorithm and then you were an
experimentalist testing for the learning
algorithm in it and you ran the stdp
experiments you would get the same
results that real neuroscientists got in
the brain
that's a very interesting finding and
and very exciting in many ways but yep
sure
cracked sure okay so the way you do
these experiments is you perform what's
called a patch clamp recording on both
these neurons so a patch clamp recording
is where you go with a tiny little glass
pipette and you literally suction on to
the neuron and then you burst a hole in
its membrane so that you can record it's
intracellular electrical activity and so
what they do is in these experiments is
they'll patch two neurons and then they
can determine whether they're
synaptically coupled by injecting
current into the neurons and seeing if
it induces a response in the other
neuron that is to say if they inject
current say into neuron J and they
caused it to spike do they see a post
synaptic response in neuron I with their
patch clamp recording and so what they
do is they will then if they find two
neurons that are synaptically coupled
they will inject current into neuron J
and inject current into neuron I at
slightly different times to create this
pattern of a spike in neuron J and in
spike in neuron I at different times and
they do that many many times over now
the way that they measure the synaptic
strength is they measure that post
synaptic response to neuron j spiking so
when you cause neuron J to spike at
first you're going to get some response
in there on AI you can measure that and
then after you do this protocol you can
do that again and you can see how that
post synaptic response changed yep
right so well I I I was having trouble
with your last bit there but the first
question was I if I take it correctly
was to what extent do these networks
suffer from the same capacity issues
that hopfield network suffer from is
that roughly right okay I don't know the
answer to that do you want to address
that right yeah because they're
ultimately although you're right the
flavour is similar in terms of the use
of an energy function and stuff like
that okay any other questions yeah sorry
yeah that's a good question thank you so
okay the idea is that all right if at if
you if you consider the what's happening
to the voltages in the neurons at the
point in time in which you're running
these stdp experiments right presumably
as when neuron I is oh excuse me now in
fact now that I'm looking at this
equation
i inj or reversed that's right excuse me
so I enjoy reversed so you know you'll
have to excuse me let's well I don't
yeah let's make that oh I shouldn't
actually be doing this because I'm on
camera yeah but so let's let's let's
reverse it so if it's I you J and the
sorry you I yes it should be like this
right because it's the temporal
derivative of the postsynaptic neuron
that we're interested in yes so the the
way that this works is let's imagine
that neuron J our presynaptic neuron is
active right here and at that same time
neuron I our postsynaptic neuron has an
increasing voltage so the temporal
derivative of its voltage is positive
that is probably a moment just before
neuron I is going to spike so if you if
you're doing this protocol the
derivative of neurons a neuron I've ole
tidge at the time of of the input from
neuron J is positive and so this
relationship not this one
another error for my slides to correct
excuse me is going to give you
potentiation and that's what you see
right here in contrast if you have the
postsynaptic neuron spike before the
presynaptic neuron then the derivative
of the postsynaptic neurons voltage is
going to be going down at the time that
the presynaptic inputs arrive and so
that's going to give you a negative term
and you're going to decrease the weights
okay
so we can do back prop without explicit
error terms and we can just kind of have
a system where the neural network is
nudged towards the right answer by the
external environment and interestingly
it seems to match experimental data on
spike timing-dependent plasticity so
that's cool
item number one down all right now
transpose of the weights so that
previous model that I showed you is
still depending upon symmetric weights
in the network and the idea that the
neurons somehow have access to the
transpose of the downstream weights
which is problematic and as I said that
is in fact one of the the biggest issues
as far as neuroscientists are concerned
so let's let's draw out what it would
actually have to look like so here we've
got a neural network some hypothetical
neural network that exists in our brain
with input hidden unit output and the
colors here represent the synapses on
two neurons in the output layer and in
order to calculate my weight updates in
my hidden layer theoretically what I
need is I need a pathway that's gonna
send the error term back and do so with
synapses that exactly mirror the
synapses here and this as I said is what
most neuroscientists consider to be
bonkers because that's a very difficult
setup and certainly it's nothing you
should assume exists in the brain and
experimental data suggests that it most
definitely does not exist in the brain
there are feedback connections it's just
that there's the evidence to suggest
that they are not perfectly symmetric
that's correct yes that's right so it
could be that they're connected
indirectly via a couple of different
neurons but then it makes the question
of having symmetric synapses even harder
so it's a very difficult problem now
let's just simplify this illustration a
little bit so the idea is that here
we've got synapses w-not here we've got
synapses w1 and then we've got feedback
projections from the output layer to the
hidden layer that are somehow just the
transpose of w1 that's the original idea
of back propagation and like I said it
leads many neuroscientists to dismiss it
now the thing is though so Tim Lily crap
whose researcher at google deepmind now
he and i we we took geoff hinton neural
networks course his undergrads together
long ago and we both drank his kool-aid
and we we were convinced that the brain
did backprop and at the time that was a
very controversial idea it certainly
wasn't in vogue and but he and I he and
I were were sure did something like that
so we had had many discussions about
okay well even if you're not guaranteed
symmetric weights how could you maybe
learn how to have symmetric weights so
could you design a learning algorithm
where you could actually train the
feedback connections so that they will
eventually give you the symmetric
weights that allow you to do back
propagation and Tim decided that he was
gonna try to he was gonna jump into it I
was a young father doing a postdoc at
the time and uh whatever you go ahead
he's he's gonna jump into this he's
gonna train a learning algorithm to
learn these backwards weights now he had
an algorithm that he was interested in
and to test his algorithm he wanted to
develop a control case now the obvious
control case was to use a condition
where rather than sending the error back
through the weights that he's trying to
train
he sends the error back through some
random matrix B which he leaves fixed so
he doesn't train the backwards weights
he just sends the error back
random matrix and updates using this
random matrix B in place of the
transpose of the feed-forward matrix and
so theoretically that should be crop and
that's gonna be his control case to
compare his learning algorithm to what
should be doing well but weirdly enough
the control condition learned quite well
aha it worked better than his I he he
came back he called me on the phone that
week he came right back to his
simulations and he saw it and he ran it
a couple more times and he called me it
was like I have this really really
really weird result I don't know what's
going on my control condition is
learning better than life than the
learning algorithm I was trying to
design I think it must be a bug but I'm
gonna run it again and again and again
and he did it again and again and again
it always came back the control
condition learned better than his
learning algorithm learned quite well
and so in fact so what he called this
situation where you're just pumping back
through a random matrix he called this
feedback alignment and you'll explain
why in a second here I'm showing you a
plot of the test error that he gets out
on M NIST in a one hidden layer neural
network so just a fully connected neural
network one hidden layer
well the shallow network is is no hidden
layer so that's as expected this is why
we're all at a deep learning summer
school because the shallow network sucks
ah but then here's backprop and just
running vanilla backprop on amnesty and
a fully connected network you'll get
down to like 2.4 percent and here's his
algorithm using the random matrix and
it's actually doing a little bit better
than back propagation in this network
which is weird what's going on so it
turns out that the reason this was
working is that the forward weights
actually align themselves with those
random backwards weights so here's what
I'm plotting here this is so you can
look at the weight updates that are
prescribed by this feedback alignment
rhythm and the weight updates that are
prescribed by backpropagation for the
hidden layer and both of these are just
vectors that we can measure the angle
between right so feedback alignment this
using the random matrix is going to push
the weights in a particular direction in
the weight space back propagation is
going to push it in another direction in
the weight space and if you have any two
vectors in a very high dimensional space
just random vectors in a high
dimensional space they're gonna be
orthogonal to each other so if these two
algorithms were doing something quite
different they should be these two the
angle between these two things should be
90 degrees and indeed that's what
happens when you first start running the
algorithm it's maybe hard to see here
but the first point so we're plotting
across training examples the angle
between what back propagation is
prescribing and what his feedback
alignment algorithm with the random
matrix was prescribing and it starts off
orthogonal and then it rapidly drops
down so the system is actually coming to
prescribe weight updates now like this
this is just below 45 degrees here but
in a high dimensional environment that's
actually pretty much in the right
direction it's it's getting pushed ya
know and it's going down right yes so in
other words what the network is doing is
it's actually learning over the first
few training examples to basically
approximate back propagation and the way
it's doing that is what what Tim shows
in the paper which you can read here is
that this weight matrix is coming to be
in fact the pseudo inverse of the random
backwards projection and so that's why
the system actually learns quite well
because it's actually approximating
something second-order because it's not
just the transpose it's coming to
approximate the pseudo inverse so that
was surprising and it means that we can
do back prop without the transpose of
the weights yeah
some good news which is the train okay
right right yes
and so so let me just say something to
that effect I think that so with this
algorithm what Tim's result illustrates
is that you don't need to have symmetric
weights to get things up and running but
that is not to say that the feedback
weights are not learning and learning in
a way to help make credit assignment on
a cost function better so I think our
you know there's we do know that the
backwards projections in our brains are
plastic and they are probably learning
unlike in this case but nonetheless what
this tells us and that's what you
actually is if you have an auto encoder
it will learn to give you the right sort
of weights for back prop so if our
brains say are stocked auto-encoders
then we could effectively be doing back
prop through that system but the point
is and this is what's really in our
scientist even if it doesn't get it
perfect so even if it doesn't have
ideally symmetric weights the system is
still going to learn quite well in fact
and it means that we are no longer faced
by the strict requirement that we have
symmetric feedback weights to do back
propagation in the brain so this is yeah
so I left that point out but that's true
the extent to which this generalizes to
ever deeper networks is questionable and
so I think to get to networks with many
hidden layers you probably need some
kind of training on the feedback system
to have it work yeah
when you're out the reason why the back
propagated error signal which is whether
the transpose should be a product or ah
yes I mean so the extent to which the
output from running it through the
pseudo-inverse versus running it through
the transpose the extent to which
they're aligned is obviously going to
depend upon the extent to which the
transpose and the pseudo inverse or
similar matrices to each other similar
linear transformations and I mean here I
don't want to expect I don't want to
comment too much because I haven't
actually analyzed this but they're
they're gonna be roughly an agreement
for many matrices right many random
matrices that's that's a good question I
you know I'm gonna have to say that I
don't have a good intuition for why that
cannot be the case I don't know if you
do yeah yeah I mean that's certainly the
true most of the time but but why do we
never see it pop above 90 degrees
yep it's a good question I I'm gonna
think about that more okay so sorry just
to oh yeah another question oh yes yes
yes well okay that second statements not
true
there is a way to determine which
weights are the backwards and the
forwards weights in fact but I take your
larger point and we'll talk about that
in a second but I take your larger point
that the backwards weights in the real
brain are undoubtedly not frozen like I
said in fact we know experimentally that
they are changing ah
but again the the reason that this is
satisfying is not because I think the
brain is learning with frozen backwards
weights it's a demonstration that the
explicit symmetry that was assumed to be
required to do stochastic gradient
descent in a multi-layer neural network
is not in fact required for that and and
that means that the brain doesn't have
to meet the stringent symmetry
requirements that led many
neuroscientists to dismiss the idea of
backprop in the brain yep
yep well no okay so let's clarify it w0
doesn't align with the random matrix w1
does now in fact what w0 ends up doing
is producing a set of weights that
separate the representations for the
different inputs in a manner that
respects the seperation that the error
term imposes on them so if you look at
the representations it's a good question
if you look at the representations in a
network that's trained with feedback
alignment what it does is in the hidden
layers it it separates the different
categories on two different manifolds in
fact so if you run T Snee on the
representations in the hidden layer you
will find that your categories are in
fact pulled apart from each other and
lie on clean different manifolds much
more so than in the input
sure yeah it learns exactly the same
type of features that something like
back propagation does which as you've
seen from a number of talks and papers
and stuff often look like many of the
features that we see in the brain edge
detection etc so on a single neuron
level it matches intuitions and on them
on the vector level it also matches
intuitions surprisingly
well so the the key is that the
representations that are getting learned
here are going to separate out the
different categories because you're
still your error term is going to give
you information on how the different
categories should be separated and even
when you run that through a random
matrix you've still got that information
available to you so in order to respect
the information that the feedback is
sending this hidden layer will develop a
set of representations that separate out
the categories and now the goal of this
weight matrix is basically just to
figure out what the transformation is
from those representations to the output
space which is in fact to do the inverse
of B that's why it learns to align
itself that's right yeah yeah so this is
what we were just talking about is it
the pseudo inverse and the transpose are
not going to be identical to each other
but they're gonna provide at least
empirically we see they that given a
large number of different random
matrices that you select for B they
actually provide the same direction of
push on the hidden layer but we can
imagine matrices like if we design B to
give us a big difference between the
pseudo inverse and this and the
transpose then maybe we could push back
prop and feedback alignment away from
each other yeah
yep yes well okay so that's a good
question these are one of the many
unsolved issues so dealing with the all
of the many different delays that exist
in the brain and figuring out how you do
credit assignment appropriately given
all of those different delays is is not
a trivial thing to work out but I think
the the important thing and this is what
I always say to neuroscientists is the
the point is not that these models solve
all the problems for us they're not
telling us exactly how the brain is
doing it they are here to illustrate
that what we thought was a problem is
not in fact a problem now the the delays
is still a problem but there will be
other ways to deal with that now I think
I'm gonna for the next section I think
I'm gonna because I'm running out of
time here and I want to have time for
questions with all due respect to Syria
I'm gonna skip the stuff on Syria's
spike prop because I think he said he
was gonna talk a little bit about it
so what I'll just say is issue three
that I was going to talk about is how do
you deal with the fact that we have
these all-or-none action potentials and
we want to take the derivative of the
activation function with these discrete
events which seems problematic and I'll
just note that so
Surya Ganguly is lab in particular with
Frederick zenkei they've designed the
system which you can read about here
that does effectively back propagation
on very precise spike trains by just
defining a different loss function that
is the difference between the spike
trains can volved with the
temporal convolution kernel and then
replacing this nasty term with a nice
auxilary function that they can take the
derivative of and I'll say I'm not going
to go through the math because I want to
move on to the next topic but here you
can see that what they can do with with
that system is they can actually say to
the neurons okay we want you to spike at
this moment this moment this moment this
moment so here you're looking at the
spikes in the input layer to the neural
network oh actually here I'll move to
this one here we've got hidden units so
here's the spikes in the input layer
here are the hidden unit voltages and
here is the output and initially we tell
the network you should spike here here
here here it doesn't do it but over the
course of training you can get it to
give you exactly this pattern of spikes
so it is in fact possible to do training
with a hidden layer with spikes but I'll
let Syria tell you a little bit more
about that so what I'd like to move to
so I'll just say item three yes we can
do backprop with precise spike trains
and it's it's actually quite an elegant
solution I think so I want to get to the
fourth issue which is slightly near and
dear to my heart and will maybe be more
novel for for some of you so as I
mentioned the the the fourth issue is
this issue of doing forwards and
backwards passes to do back prop in a
neural network the idea is that you need
to do an initial forward pass through
the network calculator error back
propagate that error and that forward
pass needs to be kind of clean as it
were it shouldn't be incorporating
feedback at the moment of the forward
pass it should be just communicating
whatever the feed-forward weights are
calculating on the input but our own
brains don't seem to exhibit this sort
of forward pass backward pass nonsense
they're just kind of chattering away and
there's all these feedback connections
so presumably
for your neurons and say primary visual
cortex they will always be receiving
feedback from higher-order regions
anyway and then you're left with the
question of well how can you actually do
some of these calculations given that
they all assume that you had a forward
pass initially to figure out how the
networks transforming your input well
what's interesting is that in the
neocortex and this comes back to your
question about you know I can't know
what's a feedback synapse and what's not
what's interesting is that the brain
actually does treat feedback synapses
differently from bottom-up synapses so
in your neocortex which again is the
region of the brain that we're
interested in here the majority of the
cells are a particular type of cell
known as a pyramidal neuron which is
illustrated on the left here they're
called pyramidal neurons because the
cell body which is here is shaped a bit
like a pyramid but really the entire
thing resembles a big tree more
accurately so what's interesting about
this structure is basically so they
these these pyramidal neurons will have
their cell body deeper in your neocortex
and they have a whole host of dendritic
branches that come out around the cell
body that are known as the basal
dendrites and they're kind of like the
roots of a tree and then they send up
one unique dendrite called the apical
shaft which goes up up up oops sorry
this is this is the frustrating thing
about not using a pointer here I don't
have top you can move your slides it
goes up up up towards the top surface of
the brain and then it's so that's kind
of like the trunk of your tree and then
as it approaches the surface of the
brain it branches again just like the
branches of a big tree and those those
upper branches are known as the apical
dendrites now the reason I'm telling you
about this structure is what's
interesting is that anatomical work has
shown that generally speaking you know
nothing is a hard and fast rule in
violet
but generally speaking the apical
dendrites are receiving top-down
feedback from higher order regions of
the brain whereas the basal dendrites
are receiving bottom-up sensory
information coming in from your eyes
your skin your nose etc so the neurons
in the neocortex actually spatially
segregate the bottom up and the top-down
connections to the neurons and this
segregation of the inputs is
particularly weird when you first look
at it because of how far the apical
dendrites are from the cell body
so like when I first saw this structure
I just kind of because because I had
originally been trained in in AI and
then I went into neuroscience and when I
first saw this structure I just kind of
registered it in my brain as well that's
weird
but it got weirder when I learned about
the work of Matthew Larkin so Matthew
Larkin did throughout the late
throughout the 2000s these heroic
experiments where he would record from
different parts of the apical dendrites
in these pyramidal neurons so this is an
illustration of some of the experiments
that he ran he's got a an electrode that
he's recording the voltage in the
dendrite from at this point in the
apical dendrite just at the start of the
apical shaft and then he's got another
electrode illustrated in red here up at
one of the higher branches in these
apical dendrites and then he puffs
sucrose on to this upper branch which
causes electrical activity in the branch
now what you're looking at here these
are the traces of the membrane potential
of the voltage that was recorded by
those two different electrodes during
this experiment so we can see the
response to the sucrose on the red trace
all these little like bumps up this is
it zoomed in all these little bumps
excuse me are excitatory post-synaptic
potentials they are the dendrite
responding to that sucrose but notice
that on the blue electrode not a lots
happening that is because the distance
along that cable so you can think of
these dendrites as being like electrical
cables they have actually a fairly high
resistance along them and it is not
trivial for current to travel down those
cables and in fact what what Matthews
results shows is that by the time the
current gets down to that apical trunk
it's basically gone or at least it's
severely attenuated so this is actually
a plot of four different distances along
the dendrite how much was the initial
input to the dendrite attenuated and
what you can see is that by the time you
get like a 400 micrometer distance which
if you look at here's the scale bar so
you can see this entire thing is like a
millimeter long at a 400 micrometer
distance you've basically got a 40 40
percent 210 sorry 40 times attenuation
of your epsp now that's really weird
because like I said the top-down signals
are coming into these apical dendrites
so the neuron so one of the other things
for those of you who aren't by all who
don't have a biology background that I
should mention is the activity of the
neuron the spikes are ultimately driven
by the axon hillock which is just off
the cell body here so that means that
the site on the neuron where the
activity is being generated the activity
that's going to be transmitted to the
rest of the network is so far from the
dendrites where the top-down feedback
arrives that the top-down feedback would
in fact not be altering the activity of
the neuron in most circumstances which
is very seems a very strange thing to do
why would you have top-down feedback
that's not driving the cell well
interestingly what Matthew then showed
another set of experiments is that the
top-down feedback can drive the cell but
only in these discrete moments driven by
nonlinear events called Plateau
potentials so this is a similar
experimental set up he's got a red
electrode and the higher apical
dendrites here a blue electrode on the
shaft and then he's got a third
electrode on the cell body and we've got
four different recordings showing the
voltage recorded on those different
electrodes where it's color-coded for
the specific electrodes now so what you
can see here in B is that when he
provides a stimulation to the red
electrode you get a response on the red
electrode and almost nothing on the blue
electrode and nothing at all on the
black electrode because it's not
propagating you can ignore C for a
second that's there for the neuroscience
audience for a specific reason but
what's interesting is D and E here so
what he showed is that if you get
sufficient activation of the apical
trunk here either because you're
injecting current at the cell body at
the same time or you just inject enough
current into the red guy you get this
huge nonlinear event in the apical
dendrites it's kind of like a spike in
fact except it lasts longer and for
those of you who care about this kind of
stuff it's actually driven by
voltage-gated calcium channels rather
than sodium channels but here on the red
and blue traces we see this big
nonlinear event and these are called
Plateau potentials because they last for
this long period of time and what's
interesting is these Plateau potentials
can then drive bursts of spikes at the
cell body at the axon hillock and that
means that it is possible for the
top-down feedback to drive activity here
but only when there is sufficient
top-down activity to activate this
nonlinear function and what that means
effectively is that most of the time the
cell is going to be in
forward mode it will be receiving inputs
to its basal dendrites which it can then
it was excuse me which it can then
communicate to other neurons but
occasionally it will respond to feedback
when the feedback successfully triggers
one of these nonlinear actions ya know
so axons do not suffer from this
attenuation issue because they are in
fact designed by evolution not to so
they are rich with non-linear
voltage-gated channels that help to
regenerate the currents as they travel
through the axon that's right and that's
what that's what happens with these
non-linear events here as well now so my
lab got interested in this because we
said well if that's the case if you've
got this situation where most of the
time the neurons are effectively in a
feed-forward mode and then sometimes
they receive this nonlinear signal from
the top-down system maybe you could
basically do backprop without having
explicit forward passes and backwards
passes just instead by incorporating
this segregation that exists in the
actual dendrites so we built this kind
of simplified model of pyramidal neurons
my student jordan who's here and
together with tim lilly crop where we
had neurons that are now no longer the
point neurons that we use usually in
artificial neural networks but instead
are neurons with three compartments a
basal dendrite compartment that's
receiving feed-forward inputs an apical
dendrite compartment that's receiving
feedback inputs and a cell body that's
responsible for generating spikes and
what we did is based on Matthew Larkins
data we had it that the cell body is
largely responding to the inputs to the
basal dendrites most of the time which
you can see here so this is the voltage
in the cell body is the voltage in the
basal dendrites and here's the voltage
in the apical dendrite and most of the
time the cell body is ignoring what's
happening in the apical dendrite but
occasionally the apical dendrite can
trigger
nonlinear Plateau potential which we
then just take as the average of the
voltage over the past 30 seconds 30
sorry 30 milliseconds for the apical
dendrite and that can then get
communicated to the rest of the cell and
so what we do is kind of similar to
equilibrium propagation but nowhere is
elegant we have a forward phase where
there is no feedback from the
environment and the network just runs
and we present it with an image and
activity propagates through the network
and then a plateau potential occurs one
of these nonlinear events where the
feedback is actually transmitted to the
rest of the neurons then we engage in a
phase where we have some external
pressure that's nudging the system
towards the correct answer and excuse me
and we allow activity to propagate
through the network both upwards and
backwards
except of course again the backwards
flow is effectively cut off because of
the segregation of the apical dendrite
and then we generated another plateau
potential and what we do is we update
our weights using the difference between
these two plateau potentials which is
effectively a way of doing feedback
alignment in fact because we use random
weights for our backwards weights here
and by taking the difference between
these two plateau potentials then we are
we have a system which is going to learn
to do back propagation in fact so you
can see that here so we just tested the
the basic result first that kind of like
with feedback alignment we wanted to see
that if we added hidden layers to this
network we got improved performance so
this is classification on them inist
obviously these actual numbers suck so I
call it deep learning light but it's
because we're running a biophysical
simulation with voltages and stuff and
getting those numbers doing the
parameter search to get those numbers
down is tricky we've got some initial
some some more
showing that those can get better but
the the important point is that as we
add hidden layers to the network it does
seem to get better though as Yahshua
mentioned for a fee as with feedback
alignment we find that there are
diminishing returns you can't just
create ever deeper networks but the more
important principle here is that we're
doing this without explicit forward and
backwards passes then now the entire
system is just allowed to kind of
chatter at itself in whatever direction
the way that we're implementing an
effective forward pass is by using that
segregation of the apical dendrite which
is something that we actually see in the
real nail cortex so this is just a
demonstration that we're getting that
same basic feedback alignment effect so
this is the angle between what our
algorithm asks for and what
backpropagation asks for over training
epochs if we send back the actual
voltages through the backward
connections we get really good agreement
between them if we use the spikes we get
better than orthogonal but not perfect
but nonetheless in a very high
dimensional space that's that's still
roughly the same direction and so if you
look at the receptive fields that are
generated by our learning rule that's
just using these Plateau potentials to
learn and what back propagation learns
so these are receptive fields in the
hidden layer of the network you see very
similar features pop out so it seems to
be learning something very similar but
again done without an explicit forward
and backwards pass now one of the issues
with our model though is that we're
we're using these rather artificial
Plateau potentials and it's not clear
that that's actually something that
would be used by the neurons what we
should really be incorporating is these
bursts of action potentials that Matthew
Larkin recorded because that's what's
going to ultimately drive activity
throughout all the dendrites in the cell
and what's really going to be the key to
communicating it to other neurons in the
system as well for doing properly deep
learning so what I wanted to show you in
the very last bit before I just take
some questions is
there are some exciting results out from
Richard nods lab at the University of
Ottawa unfortunately this is unpublished
it'll be up on archive at some point
soon so I just recommend looking up now
and Sprecher if you're interested in
this and in a month or so so what they
did is they ran some biophysical
simulations of pyramidal neurons so
these are these are simulations of
pyramidal neurons with a soma and that
long apical dendrite I was telling you
about and they fit their biophysical
simulations to actual experimental data
and then they looked at what the cells
activity is communicating whether it's
communicating top-down signals to the
apical dendrite or whether it's
commuting bottom-up signals to the
dendrites around the Selma what they do
in particular though which is very
interesting is they they basically just
look at the number of events so here you
can see a spike and here you can see a
burst and they treat both bursts and
spikes as just an event and then they
look at both the rate of events and the
probability that a burst
sorry that an event is a burst and
what's interesting is that if you look
at so here they're providing a
decreasing current to the dendrite to
the apical dendrite and an increase in
current to the soma
and what you see is that the event rate
is a function so that is the the rate at
which both bursts and spikes occur is a
function of the input the bottom-up
input to the soma
whereas the probability that an event is
a burst is a function of the top-down
input to the dendrites and if you do
this same thing so you provide two
different currents over time we see the
same result pop out here so if you just
count the rate of spiking in these
neurons you don't see much of anything
but if you look
get the event rate you see the bottom up
input to the soma and if you look at the
burst probability you see the top down
input to the dendritic inputs sorry to
the apical dendrites and that's very
exciting because what that means is that
pyramidal neurons are effectively
multiplexing their top-down and
bottom-up signals
constantly so the neurons in your brain
have two different signals one that
communicates the bottom-up information
that's coming from your sensory systems
and another signal that communicates the
top-down information that's coming from
the higher order regions of your
neocortex and theoretically these two
different signals could then be used to
do something like back propagation
without having to have separate forward
and backwards passes because the entire
system is actually keeping those two
streams of information separately as it
travels through the network so what's
also interesting about this is we see
that there are subtypes of neurons in
the neocortex that have synapses that
respond to bursts quite differently so
some neurons have what are called
short-term depressing synapses which
means that they don't actually respond
to bursts differently than spikes
because when the first action potential
occurs the synapse is depress rapidly
and so they don't respond to the
subsequent spikes and there are other
synapses called short-term facilitating
synapses which don't really respond much
to the first spike but respond very well
if you get multiple spikes in a row via
bursts and so what's interesting about
that is we see that there are different
types of neurons in the neocortex and I
don't have to time to go through the
different types I'll just tell you that
there are two different types of neurons
and neocortex that have short term
depressing synapses and short term
facilitating synapses and that means
that theoretically we've got two
different pools of neurons one that is
explicitly listening to the bottom-up
signals and one that is explicitly
listening to the top-down signals and
again that would allow the system to
engage in a back propagation like
calculation without separate forward and
backwards passes which I think is a very
exciting result and potentially the key
to understanding how some of this
unfolds
so to summarize item number four doesn't
seem to be an issue either because your
brain actually seems to be designed
specifically to do simultaneous forward
and backwards passes and to carry that
information with different signals so
it's in fact very plausible that you
could do learning without these separate
passes so to end off here I began this
talk by identifying the kind of issues
with this equation and the things that
made neuroscientists very skeptical for
a long time that we could do deep
learning in the brain but over the last
two years we've kind of seen how you can
systematically just pull apart each one
of these and it turns out that they're
not me none of them are a big issue now
there are other issues that are going to
arise whether it be the delay time
constants or you know questions of how
you do recurrence and I'll get to that
in one second but at the end of the day
I think they're all going to be
surmountable of course the the final
remaining one which I just mentioned the
elephant in the room for us is is
backprop through time backprop through
time is really really critical for
training recurrent neural networks but
doing backprop through time in a
biologically realistic way is pretty
difficult so of course the way backprop
through time works right is if we have a
recurrently connected set of neurons we
unroll the neurons through time such
that we treat early time points as being
like the initial layers of a neural
network and later time points as being
the higher layers and then you just run
backprop through it as if you had a
standard stock neural network that's
great for training a neural network but
if you're gonna try to do this in a
biologically realistic fashion you have
to somehow have a record across time of
the activity patterns and the inputs at
each time point and you have to have
those all time-stamped and matched up
with each other
and we just have no way of seeing how
the brain can do that right now I have
some some ideas about how this might
work but I'll leave that for another
time and maybe for you guys to resolve
in your work if you work in this area so
what I will say is this though to finish
off there's a very good reason that deep
learning has taken over AI and that is
that it works and the reasons that it
works apply equally to our own brains
that is to say that if you're going to
try to optimize a huge number of
parameters so you're working in a very
high dimensional space and you're trying
to optimize some cost function doing
gradient descent or the stochastic
gradient descent is a really good way of
solving that problem and it seems very
likely I would argue because we don't
really know of another good way to do
that right like I said to my knowledge
no one's ever demonstrated an equally
powerful mechanism for learning in these
high dimensional spaces it seems
entirely likely that our brains did
through the course of the you know
evolution settle upon a similar solution
something like stochastic gradient
descent and I think that until
neuroscientists are able to articulate
an alternative way of learning these
high dimensional spaces we have to take
very seriously the idea that our brains
are doing something like backprop ah and
that's particularly true because as we
saw the old objections don't hold water
anymore and I suspect that the
additional objections that are going to
be raised will not hold water for very
long either
ah and so the last very last thing I'll
leave you with is the following kind of
wacky thought and this is an absurd bit
of on my part but whatever it's
fun ah let's say for a second that our
brains are doing gradient descent and
let's say that we were able as
neuroscientists to identify where those
signals are if they're the top-down
signals into the apical dendrite that
are guiding the like telling the neurons
about the gradient or something like
theoretically if we could get a
sufficiently good neural prosthesis such
that we could actually tap into these
signals that are communicating the
gradient to the neurons you could have a
system where you have an external cost
function in some neural network and you
backprop through that system and into
the brain right that's very scary yes
and so then you could have a truly
seamless AI brain interface where you
actually update your brain in order to
maximize the cost functions of your
external prosthesis which that doesn't
saying I think it should yes exactly you
want to be able to send back the signals
to the neurons that tell them what the
gradient is of that external cost
function and that will guide them in
their synaptic weight updates yes that's
right we're doing it through a very slow
Channel that's right so the other thing
is though you're sort of doing it
insofar as there you still have to
construct the cost function internally
for yourself right like you have that
cost function by virtue of your internal
goals with your phone but if you had a
system where you could literally take
any cost function and propagate that
back through the brain it wouldn't have
to be the things that you're explicitly
interested in yes okay well yeah we got
a DARPA
I'm not really don't hey anyway that's
that I'm sorry we only have a couple of
minutes for questions but thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>