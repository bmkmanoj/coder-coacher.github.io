<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Demystifying Artificial Intelligence - Oren Etzioni | Coder Coacher - Coaching Coders</title><meta content="Demystifying Artificial Intelligence - Oren Etzioni - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Demystifying Artificial Intelligence - Oren Etzioni</b></h2><h5 class="post__date">2018-02-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8Lc2j7DmEyc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">should probably turn this off somehow
not sure if I'm doing the right thing
here here we go
you know one of the famous lines about
AI is how we're gonna solve AI if we
can't even figure out a V so I am your
host dinner entertainment
I'll talk quickly and cover a variety of
topics and then open it up for
discussion but I want to make one point
very clear before I start especially as
I see folks like Steve cross who let me
at DARPA and the head of NSF and so on
no you can't have the money back but
with that let's let's get started on
this journey so as all of you know I
think we've all heard folks like Elon
Musk warned that they I were summoning
the demon but at the same time we really
need to separate science the science of
AI from from science fiction we have AI
scientists like the famous roboticist
rod Brooks who says if you're worried
about the Terminator just just keep the
door closed and now in fact those are
really up on your AI Boston Dynamics the
company that was recently purchased by
Softbank from Google actually figure
this out they they've recently released
a video where the robot finally figures
out how to open the door but there's
still so many challenges like you know
going up the steps and and so on so I
think we still have a long way to go
with with AI so what I want to do today
is make sure that we're all talking
about the same thing and highlight some
of the same issues and I don't know if
you can read this cartoon but it says
you're not being replaced by a robot a
big concern for a lot of people you're
being replaced by someone who
understands robots so after today's talk
you
be a replacement proof because you'll
understand okay so what is AI what what
do we mean by the term in theory what we
talk about is AI doing what humans do
sometimes referred to as artificial
general intelligence or AGI and that
notion has given rise to a lot of
Hollywood scripts and you often hear
when AI is used as a noun like v AI is
gonna take over the world they're
referring to this kind of AI now in
practice AI is very different as
illustrated by these pictures ai is
often very narrow tasks like playing NGO
or speech recognition there were once
thought to exclusively be the province
of humans right and now we find again
and again that machines can do it just
as well or or maybe even better so so
let's look at the probably the most
prominent case study and that's alphago
the program that beat Lisa Dahl the
human world champion and a myth here a
lot of people felt like this is really
now showing us the path towards full
artificial general intelligence and what
I want to remind you of is that board
games both literally and figuratively
are black and whites they have discrete
moves they have these finite boards
there's a very clear win or lose
evaluation function and the amount of
data you can have is essentially
infinite whether you get positions from
previous games or whether the program
plays against itself automatically
millions of times
so in those sorts of situations AI the
kind of practical AI shines and we see a
lot of other of the major successes
whether it's chess or speech recognition
not speech understanding mind you but
just the ability to recognize the
phonemes of our speech the way that
Alexa or Siri does we see facial
recognition
we see some primitive machine
translation although if you saw Doug
Hofstede's article in the Atlantic
recently you know just how primitive the
machine translation is we've seen
successes in jeopardy and robotics the
point I want to make to you is that all
these successes actually uh that look
very disparate right speech and robotics
and so on all come from the same pattern
and it's very simple and this by the way
is as technical as my talk gets tonight
I removed all of the equations and
people have had some wine and some
dinner so we're gonna keep it very light
so but here's the equation of AI we take
a set of categories let's say B versus P
or in this case cats and dogs we take an
enormous amount of labeled data examples
that are labeled by their category is it
a cat or a dog what have you and then we
feed those to an algorithm an AI
algorithm some software and that
produces the models that do the work for
us
and the important thing to understand is
all of these all three of these
components are created via manual labor
via people hard hard at work so the the
point that I want to remind you of if
you take nothing else away from this
talk is that what's called machine
learning is still 99% human work very
very much not a magical process
Nate silver whose work many of you know
in a somewhat different context he said
figuring out how to optimize something
how to do this kind of machine learning
that's a computer science problem but
figuring out what to optimize what to
learn is not so let's remember that
point and remember that what we've
created and all of these success stories
are very very narrow systems I call them
sometimes AI savants right they're
incredibly good and one thing and they
do a terrible job even shifting from
go-to chess
from playing go to crossing the street
or something like that
the second really important point when
we think about these narrow systems is
to understand the distinction between
intelligence in the one hand and
autonomy on the other hand those are two
very different things and because people
are both intelligent and autonomous it's
very easy for us to conflate these
things so I have here a two-by-two table
to illustrate these points you know you
can take the professor out of the
university but you can't take the two by
two tables out of the professor so here
on the y-axis is where we have a degree
of autonomy high and low here on the
x-axis we have intelligence low and high
and to illustrate that these are
different let's look at some of the
cells so we when we have high autonomy
and low intelligence that's a bunch of
teenagers drinking on a Saturday night
okay
and in contrast alphago is a system as I
was saying that has very high
intelligence but very low autonomy it
can't even play another game of Go
unless somebody pushes a button right so
these are very very different things and
this is really an excuse to show my dad
is his grandson but but but the point of
this slide is that our kids humans are
just so much more autonomous than any AI
system let me just make give one more
example we talk about self-driving cars
right
that sounds very autonomous sounds scary
people love to talk about the trolley
problem right which way will the car go
if it has to make a life-and-death
decision but to remember that a
self-driving car really isn't all that
different than anti-lock brakes right
it's a device that helps us get our job
done but it's not like a self-driving
car chooses where to go it's not like a
hundred of them are gonna get a drive
down Northwest they see and try to take
over the White House right
nothing could be further further from
the truth
nevertheless people ask me given all the
uncertainty about what a I can and
cannot do and some of the other issues
that I'll talk about having to do with
fairness with jobs and so on some people
ask me well why don't we declare a
moratorium on AI okay what's the rush
why don't we just slow down and study it
carefully in a body like like this one
before we continue with AI and I want to
suggest you two reasons why two kinds of
reasons why we really cannot afford to
do that the first one is that AI is
global so we have China declaring that
they want to be the world leader in a
I'm by 2030 we have Putin saying that I
he wants that the leader in artificial
intelligence will in some sense own the
world so if we slow down right we'll be
overtaken by by other countries who
already are racing and beating us in in
certain arenas that's that's reason
number one but reason number two is that
AI has tremendous potential benefits
I'll give two quick examples the first
obvious one is is self-driving cars we
have on the order of 30 to 40 thousand
deaths on our highways each year on the
order of a million injuries every year
and a lot of those the studies say that
80 to 90 percent of those could be
prevented with with this kind of of
technology so that's one one huge aspect
and Paul Allen founded the Allen
Institute Frey with a mission of AI for
the common good so to explore these
kinds of applications and to do the kind
of basic research that will allow us to
unleash the benefits of of AI we don't
work on self-driving cars but something
that we do work on is building better
scientific search engines today we have
Google Scholar and PubMed and a few
others
they're quite comprehensive but they're
really not terribly intelligent at the
same time the number of scientific
publications is growing exponentially
there's a Moore's law of scientific
publications and we don't have any
Renaissance men and women anymore
right we need some way to cut through
the clutter we need the help of
technology to for scientists and medical
researchers and ultimately doctors to do
their job and that's a project that
we're working on we have an engine
called semantic scholar it's available
24/7 at Symantec Scholar org and it's
starting to scratch the surface here to
use AI to help you find what you're
looking for and really in this sense AI
is less artificial intelligence and more
augmented intelligence right the idea of
this engine is to work
shoulder-to-shoulder if you will with
scientists to help do their job and
maybe even one day to go from machine
reading to being able to suggest
hypotheses and experiments to to actual
live scientists so because of these
types of considerations my colleague
Eric Horvitz who's at Microsoft Research
and former president of triple-a likes
to say it's not AI that we ought to be
worried about it's the absence of AI
technologies that's already killing
people right on our roads and also in
hospitals where the third leading cause
of death is medical error and AI systems
working alongside doctors and nurses
could help prevent a lot of those errors
so there's just a tremendous potential
here now shifting to the to the worries
that people have about AI
there certainly are concerns and these
go way back right so this is a picture
of Isaac Asimov who asked in the 40s and
50s can we use AI can we prevent AI from
from causing harm and he suggested his
famous three laws and the
the problem with his laws they were they
were brilliant but there were ambiguous
right there wasn't clear how to
operationalize them and so what I've
done in in a recent piece in the New
York Times is trying to suggest a more
pragmatic framework for thinking about
AI saying things like well if we build
AI systems we really should have an off
switch okay let's be sure that we can
turn the AI system off or at least
unplug it from the electricity just in
case another really important point is I
think when we think about AI and
regulation we ought to be thinking about
regulation regulating the applications
of AI AI in cars AI in ties as opposed
to the field itself right the field of
AI research is amorphous where does
computer science and software leave off
and where does they I begin that's
actually a very difficult to to
determine so rather than try to regulate
the science let's look at particular
applications of particular regulatory
bodies and think about what what we
ought to be doing there and so a few
ideas that I suggested one is that we
should realize that people are
ultimately responsible when AI systems
are in use so the notion of you know my
AI did it is not an appropriate excuse
right if my you know car runs over your
dog and I say you know I'm terribly
sorry it was a self-driving car that's
not right either you're at fault as the
driver the manufacturers at fault if the
technology is faulty but AI is a set of
tools and we need to make sure that the
responsibility rests with the people
using these tools another really
important point is that we need to have
full disclosure about AI so there's all
this talk right about the bots you know
during the election and even now and yet
we don't have AI systems labeled right
have intel inside when it's made by
Intel but we don't have intelligence
inside when it's an automated system and
people really need to know for the
obvious reasons and remember about
people a lot more knave than yourself
who can easily be confused am I talking
to a person or am i talking to an AI
system I think that's an important
distinction
the third principle that I talked about
is one of privacy privacy is obviously a
major concern in many issues AI
exacerbates that think about AI Barbie
we have these dolls that have chips in
them and they interact with our kids
quite extensively it's very easy for
them to elicit it with information from
our children and then upload that to the
cloud and if any of you think that's
unrealistic the picture there is of the
Roomba right the robot the your house
and it was reported in the New York
Times that the executives of Roomba were
seriously considering selling maps of
your house automatically created by the
Roomba as it's navigating around to
third parties right who could use it to
figure out it if you need new carpets or
what have you so AI creates enormous
opportunities for privacy violations and
we need to think about that very
carefully the last point I want to make
and this wasn't in the New York Times
article due to lack of space but I think
it's a extremely important point is to
think about the potential of AI systems
for increasing bias in society remember
that all these systems are based on
training data right and training data by
definition comes from the past the
models that are created are then used to
make future predictions so what these
systems are all doing is using the past
right to generate models that predict
the future in the process of that if our
past was racist was sexist was
inappropriate in other ways the models
will not only potentially carry that
over into the few
but they actually for technical reasons
they can exacerbate that if you know
there was a 20% bias in the data again
some group once the the modeling
exercise and finished it could be 40 or
60% so and we do have technical ways to
to prevent that so whenever we think
about the training data I tried to
formulate the principle today I should
not amplify the bias in its data it
should not make the problem even worse
so one of the trickiest issues is is the
one about jobs and I'm actually almost
done here I'm kind of doing a survey of
the different different topics and then
we'll open it up and I like to point out
that one of the reasons that I'm not a
big fan of the warnings about super
intelligence and AI taking over the
world is because I think it's a
distraction from the real issues one's
about bias or certainly one's about jobs
right we have a long term trend of
automation and software and robots
taking over jobs and Amazon opened their
fully automated store in Seattle
recently retail jobs are at stake
obviously transportation jobs are at
stake particularly for for truck drivers
and so on so what are we going to do
about a eyes impact on jobs
some people like Marc Andreessen or Hal
Varian who's the chief economist at
Google say don't worry about it new jobs
will emerge as pardon me as they have in
in the past I'm not sure that's
completely satisfactory because right
there can be a lot of anguish and
displacement while that process takes
place and some people argue that this
job loss is accelerating we don't
necessarily know in Silicon Valley the
notion of a universal basic income right
giving some money to everyone is is
quite popular my problem with that
notion is that we're struggling to have
universal health care
in this country right so how are we
gonna have a universal basic income
that's a challenge I also have
colleagues like my colleague daniella
ruse at MIT who says what we need is
technical training and and I do think
that all of us and certainly our kids
and grandkids need more exposure and
understanding of programming and of AI
and there's wonderful bodies like that
but again it's not realistic that we're
gonna take coal miners and turn them to
data miners right but by and large it's
not realistic the people who did not
finish high school and we have plenty of
those in this country are going to
become crack programmers so so we have a
real a real problem here and the the the
suggestion that I made which again is
far from a panacea or comprehensive
solution but I do want to say that we
ought to think about caregiving as an
option for displaced workers and by
caregiving I mean the whole range from
companions to elder care even a food
delivery my teenager was working this
summer delivering food to people for
whom that might have been their only
human contact or one of their only
points of contact during the week what
if we allowed people like that to spend
an extra 15 minutes and have a cup of
coffee with with that elderly person
what if we supported that that might be
more palatable because it's a job it's a
service rather than just universal basic
income and the thing that's really
important is to realize that this is a
uniquely human job right again some of
my colleagues are very excited about
having robots take care of the elderly
and again in in Japan the demographics
are such that there might not be a
choice but wouldn't you rather have a
human you know be in touch with whoever
has those those needs I think we do I
think humans are uniquely qualified and
that's something we ought to think more
about and actually it's quite common in
other countries I grew up in Israel and
there it's very often the case did you
see an older person and
have a human companion you know gasp and
it's a it's a win it's a win-win so so
this is where I want to end on these
kinds of questions we understand what AI
is hopefully a little bit better now we
have these questions should we be
engaged in here should we slow it down
should we speed it up and the point I
want to leave you with is that AI is a
tool it's a technology it's not some
mysterious magical entity and so
ultimately the choice about how we use
AI would roll it has an Isis in our
society is ours thank you very much
thanks very much for a very nice talk so
so what are going to science and
engineering what what what excites you
most about challenges and AI and what
what kinds of science and engineering
problems are your folks at the Institute
working on we're looking at a lot of
work on natural language processing so
again if you think about language which
we use all the time to to communicate
with each other but also hopefully with
AI systems that's the opposite of what
happens in a board game right it's not
cut and dried
it's full of nuance it actually requires
common sense often to understand even a
simple sentence and so we're doing a lot
of work a lot of basic research to
understand language and of course NSF
funds a lot of research by others along
those lines and we feel that if
computers could understand language it
would open up a lot of these
possibilities like better scientific
search engine and and many others as
well
thanks very much agree great talk thank
you for your time I'm Tim persons I'm
with the Government Accountability
Office or Gao we are about to push out a
study actually on this strategically for
the Congress in just a few weeks but one
of the things that I think is so
profound about this is the change from
what I could think of as a deterministic
computing into probabilistic and the
idea of how will we be able to even get
over that sort of context of what that
means about training would we get in a
car where you would say well some high
probability we can get you from point A
to point B you know that kind of thing
and I'm particularly concerned about as
we evaluate the regulatory space how a
regulator I think as you rightly said is
gonna focus on or ought to focus on the
application versus just the general
technology itself whether you're SEC or
whether you're the nitsa the National
Highway Transportation Safety
Administration or whatever so I think
that's such a profound thing I was
wondering whether you're seeing the same
thing or do you think I'm over stating
that or I'm overly worried and you know
don't be don't be so worried about it
thank you so it is a very rich rich
topic let me make to two points one is
it's entirely possible to have a
stochastic or probabilistic system but
still have a deterministic outcome right
remember what underlines Newtonian
mechanics in the chair that you're
sitting on is is quantum mechanics right
so I wouldn't extrapolate from the kind
of programming we talked about to to the
notion that we can't draw very specific
and reliable conclusions I do think that
there are things to be worried about we
ought to think a lot about how we
regulate cars and in fact there's a
patchwork of regulations emerging from
municipalities and states and that's
really problematic this is a great time
for the federal government to step in
and figure out nationwide regulations
but the other point that I really think
is important to mention when we worry
about the technology is you know the old
joke you know
was the old joke you know how's your
spouse to make the non-sexist version
how's your spice compared to what so so
the point is when we evaluate the
technology we can't evaluate it relative
to the ideal transportation vehicle we
need to evaluate it relative to human
drivers who are texting and driving
drinking and driving and killing us
every day so I'm very confident that in
a small number of years we will have
driving technology that's safer and and
that's that's what I'm really excited
about leah chalupa from George
Washington University
so you mentioned the competitors China
and Russia and in recent weeks they've
been a number of articles in The Times
Wall Street Journal the post about the
tremendous amount of investment China's
making an AI bringing people back from
the States as they're learning areas
what's your assessment in terms of the
basic science not the application with
the basic science of AI China and let's
say Russia compared to us today that's a
great question and we actually have a
statistic from the various AI
conferences so people are fascinated
with it by this and the top basically I
the dissemination of results in AI is
via conferences like Tripoli I and nips
and so on and the number of papers being
submitted and accepted by Chinese
authors is rising rapidly and I think
that it's still the case that we're in
the lead but I think that could easily
change and I think a lot of it actually
has to do with immigration right so
where we've been successful and if you
look at my Institute where I'm very
proud of the people we have it's the
United Nations right we have Vietnamese
Egyptians Israelis you know Koreans
Indians we even have a few you know
Americans you know you know sprinkled
here and there but the point is that
that's the the situation we have
actually several super sharp Iranian
scholars and they've had all kinds of
problems a lot of these people not just
the arena ones so if we screw up to use
the technical term
immigration system then we're toast the
John's over from Raytheon fascinating
talk I think it made a great point in
the beginning talk about AI savants I
like that term right so I think I would
like to hear your thoughts on on
scientists and engineers talking about
what AI is not you actually did but I
think as a community that's really
important so when Elon Musk's talks
about AI all the negatives right so your
point about AI savants that AI isn't
actually all these global things how we
as a science community engineering
community shoot not just chasing money
from funding agencies and things like
that talk about what it isn't and what
the limitations are what are your
thoughts on that IIIi think you're
you're you're absolutely right and
that's why I tried to distinguish
between the two different kinds of AI I
send them use the metaphor that remember
in the old days we had these stereos
right and you would you know adjust all
the knobs and dials to get the sound
just right
well machine learning deep learning
right this fancy stuff is a lot like
automating the adjustment of these knobs
but it's not the case that you
automatically adjust the knobs on the
stereo and the snare will suddenly turn
into a Death Star it's just it's it's
unrealistic and so we do need more
people making those points thank you i
kt stubb in the university of
massachusetts my questions around
artificial intelligence as maybe a lift
or an augmentation for folks who maybe
may not have the skills to fulfill
certain jobs but is there an opportunity
to look at AI as a way to on-the-job
train or to increase productivity of
someone who may not have the skills to
do the job otherwise and I just love
your thoughts on how we might use it as
a Augmented learning tool for a
Productivity I think there is that
opportunity and that's a fantastic way
to think I think we do have a lot of
challenges right communicating with with
programs that's one of the reasons you
know I hope we can make progress on
natural language processing at the same
time well I you know very much
sympathize with what you're saying and
that's what we're looking for I also
don't want to you know paint it as too
rosy a picture right the reality is that
right often the AI systems will rapidly
take away the jobs and if we look at
Amazon for example right at the Amazon
warehouses the number of people in those
warehouses has been dropping sharply and
some of the last tasks there's that that
the human hand is a remarkable tool so
picking items and counting items are
some of the last things left but these
things are going to go away so the
reality is that as much as we want to
use the AI in the way you describe and
we will it's also the case that is going
to take away jobs Jack when strand
Agilent Technologies you're working on
AI and the service of the human
condition
we have huge challenges in healthcare if
you take a 10 year horizon what area do
you think is the greatest has the
greatest opportunity for AI to
revolutionize healthcare Wow
you know you probably know the answer to
that better than me but let me just
suggest a few places where I see a huge
opportunity once I mentioned in terms of
of research so Symantec Scholar already
covers all of biomedicine and I think we
can help those scientists be a lot
better at their jobs it's also the case
that when I talk to my friends who are
doctors they often complain about the
amount of time they spend in dictations
the amount of time they spend in
compliance right and a lot of those
things can be automated right people are
working on Siri for the doctor's office
so the doctor doesn't have to keep
typing maybe he or she could even look
at you while you're
well while you're talking let Siri take
care of that gentleman here from Google
brain is working on using AI on top of
electronic health records right there's
so much information there that that
we're not able to mine but really the to
me personally one of the biggest things
is I'm terrified of going to hospitals
right they're opaque you know bad things
happen to people then again that's
documented that's not my my paranoia the
statistic I gave is from I forget the
name of the journal but from a medical
journal write about the third leading
cause of death well AI systems looking
over the shoulder of a doctor and making
suggestions or sounding alerts we're in
a mistake I made this is not pie in the
sky okay this is something that that we
could do today and do it with increasing
efficacy and I wish we would before my
next hospital visit Robbie's Monterey
with Lockheed Martin going back to your
charge of the autonomy and intelligence
and thinking about our governments like
a regulatory framework to develop trust
in a system like that so I see there's
really sort of two schools of thought
there's the experimental versus the
theoretical the theoretical folks are
trying to come up with with frameworks
formal you know formal verification you
know metrics and an approaches and then
the experimental crowd is like let's
just operate the system for you know an
millions of miles or hours what-have-you
from your perspective how do you see
these two camps you know sort of will
they emerge at some point is one camp
winning versus the other what are your
perspectives on that approach to
basically verifying and validating trust
in a system like that yeah I do have a
very strong point of view about that
unlike all my other points of view which
were but I I did my PhD at Carnegie
Mellon
we're Newland Simon talked about
computer science as an empirical inquiry
some very much an experimental computer
scientists I don't believe that we're
going to be able to prove theorems about
these systems the analogy I would give
you is what's more complicated the
system that flies an aircraft the system
that operates a human or Windows right
does a very very complex systems how
many theorems have been proven about
Windows in the last decades into zero
right these systems are too complex to
model and mathematically and I do think
that the people who attempt to create
very mathematical models of AI are going
to be always relegated to a very very
theoretical realm we can adopt
engineering practices to very carefully
test systems and simulate them and you
know retest them and look for various
edge cases to improve their safety and
we can build redundancy there are many
methods that we use as engineers to help
with safety but I think that the
experimentalist and the empiricists are
the ones that really are you know are
showing us the right way here I Janet
Nelson University of Idaho I appreciate
your quadrant analysis - I'd like to
push a little bit more on your views of
the distinction and AI between being an
execution mechanism for distinguished
tasks even if they're very complex
decisions and very critical decisions
versus AI as a generator of new
knowledge so I think that we would love
to see AI is a generator of new of new
knowledge I think we've seen relatively
little of that what we do see though
which again is is exciting if used
properly is we see narrower arenas you
mentioned in medicine there often
situations in in radiology
in dermatology right where we have a lot
of background a lot of historical
diagnostic decisions and we can train up
a model based on those and then do a
better job at making those diagnostic
decisions then then doctors do who who
get tired who get distracted who make
mistakes and of course when you put the
systems together a human and machine
doing their diagnosis it gets even
better I don't know if you would call
that new knowledge percent yeah it's
it's on the border but that's what I see
in the in the next let's say five to ten
years is more and more of these systems
that that help us say make these
diagnostic decisions much much better
hi Kelly Sullivan Pacific Northwest
National Laboratory did a little bit of
a follow-up on that as a quantum chemist
so I'm very much in the the fundamental
generation of new knowledge field or at
least I was when I was not management it
happens to the best of us but I'm
wondering because as an active research
scientist one of the skills that I had
was making the nonlinear connection
between data and analysis and and making
that leap to an assumption about the
something about the physical world that
that that data was telling me and then
my colleagues would say what and and
then I would have to explain how I felt
that that connected thing meant reality
was the way I thought it was described a
I I think can do that I think it can get
there and take this this deep learning
thing and say here's this massive amount
of data that you've generated and here's
the leap but what it doesn't have is the
human who can explain how the leap was
made and convinced the other humans why
the leap is real and so how are you
gonna get to the human scientist the
really fundamental this is why that Adam
did that thing person not the diagnostic
person that's way down the field for me
but I'm talking about the really
fundamental scientist how are you gonna
help them
believe the AI analysis is correct when
it's a nonlinear leap from where they've
come from
does that make sense it does it does
make sense and you're absolutely right
so I didn't have a chance to get into it
but one of the biggest weaknesses of
these systems needs deep learning
systems in particular is explaining how
they made their their decision right so
it's a statistical model and it'll make
a prediction and let's talk about it in
the context of diagnosis right
I imagine the situation sometime in the
future where I go and have you know a
series of tests run and they say you
know professor it's you know we need to
remove your kidney and I'm like wait a
minute you know I'm at attitude it says
sorry the statistics show it's got to go
we're willing you in we're wheeling you
into surgery right now and and that's
obviously a terrifying thought and so a
lot of people are working on more
explainable more transparent AI systems
but one of my colleagues Pedro Dominguez
at the University of Washington makes an
interesting counterpoint he says what
would you rather have a doctor who's 80%
right but can hold your hand and explain
to you what's going on or a doctor who's
right 95% of the time but perhaps is
less articulate now a little bit of a
false dichotomy but still something to
think about ok so the scary thing about
these inter articulated systems is that
they are better in making those
diagnoses then then the doctors know you
know in the case of science right those
are right it's gonna be a long time
before the AI systems can make these
amazing leaps that scientists make but
we will face soon a situation where do
we go with the statistical model where
do we go with what the the human doctor
says when they agree life is great right
they're both saying the same thing and
the doctor can explain why and never
mind if their explanations actually may
be inaccurate it's reassuring but what
when they disagree who are you gonna
listen to
hi Wayne Johnson from McGuire associates
but I'm gonna be speaking from my
Hewlett Packard background about nine
months ago I met a colleague who came to
Boston and we were talking about China
where I helped set up some operations
there and he said did you know that I
think was Foxconn put 50 thousand robots
and one of their manufacturing places
which I said of course not I'd never
heard of it I checked the New York Times
and sure enough what do you conclude mmm
to me that's an amazing number and I
thought we were they were there because
they were low-cost and now they put 50
thousand robots doing something what do
you what are your comments about what I
just said does that make sense where is
that going why is China doing that so
manufacturing is becoming increasingly
automated in China as well and I did
hear about that story I don't know the
particulars but I I think it's again a
huge huge challenge and and
manufacturing is going to be
increasingly increasingly automated the
one advantage that people have is when
you need to change the production line
very quickly right people have an easier
time adapting but even there that's
changing very rapidly so you're speaking
the truth good or not is you know
remains to be seen yeah I am mammoths
quiet from NIH thank you for the nice
talk there were some questions about the
proof of whether something is really
done in AI or not and when I give
lectures to my students here and there
and I always ask the question what is an
AI question what's an AI problem and
what is an AI heart and people sometimes
came with the answer that you know it's
a humanely done doable things then
this world AI problem but we have to
distinguish between AI techniques and AI
problem I say so I would like to ask
your opinion what do you think about
this when I say an AI heart problem is a
problem of which solution best solution
is not available in a tractable amount
of time tractable in a reasonable amount
of time with other tools and methods
like if you can find the best solution
which we call it global maximum in a
reasonable amount of time with an
mathematical method then it's a
mathematical problem but it's only AI
problem but if you are you know settle
down with the solution that is good
enough not the global maximum but
somewhere somewhere good and sufficient
then it's an AI problem what do you
think well let me let me make kind of
points on both side of that again very
rich question did you did you raise on
the one hand you know when we talk about
deep learning or neural networks right
to use the older term it kind of
connotes you know the brain and humans
and so on but if you look under the hood
and those systems they're doing matrix
multiplication right there they're
taking derivatives in an N dimensional
vector space so I do think that a lot of
what goes by the name of AI is is
statistics is very very mathematical it
doesn't feel intelligent in any way
shape or form so that's that's just a
fact on the other hand right if you look
under the hood
here right as you well know from an age
it doesn't look very human intelligent
either right there isn't a homunculus a
little person kind of figuring things
out red we have you know ion potentials
and you know hormone diffusion and
electrical impulses and and all that
stuff so
you know what what is AI in a more
philosophical level is is is hard to say
III do want to add though one more
perspective on this which is I think I'm
more or less quoting verbatim Pablo
Picasso who said computers are useless
the only answer questions right we need
to ask questions
I'm Brian right from George Washington
University so putting your professor hat
on so how do we prepare students for
this AI future and are there things we
can be doing I guess you know
academically to not only prepare them
for the use of these AI tools but also
to meet the demand that may be coming
out of you know that AI industry right
so III think that the the first step is
really in elementary school and I think
it's really upsetting to me
the limited degree of sophistication
most children at the age of 8 certainly
by the age of 10 can program and there's
incredibly wonderful you know games and
things that make it fun and it's really
disappointing to me how slowly we've
adopted that in our elementary school
curricula and it has to do with the fact
that a lot of the teachers I was a big
advocate in my son's school which was
you know a private school and had all
these resources as a big advocate for in
there what they called their tech class
instead of learning features of
PowerPoint that they actually learned to
program until I realized that the
teacher didn't know how to program and
what I was really advocating was firing
her which I didn't feel good about and
you know again maybe we could have
reached something if she'd done some
additional training but the bottom line
is she didn't know how to program and
she was going to teach the kids how to
program and and I had to
to give up so we really need to start at
elementary school and move through that
when I was in college there was a basic
programming requirement this is in the
80s a lot of schools have taken that out
so you can graduate from college without
being able to write a really simple
program you know with a loop and so on
that's very very problematic so I think
people need to know that it's not
because they're all going to be about
become programmers because then it
demystifies things and you know what the
Machine can and cannot do so that's one
huge thing but the second thing the
place where the computers are at least
good at and they're going to be least
good at it for the long time for the
longest time is around teamwork
collaboration empathy a lot of these you
know human skills so I would also
emphasize classes where they encourage
and build those abilities more for
example as a computer scientist we had a
big emphasis at the University of
Washington on group software projects
because writing software is no longer a
solitary thing where you sit in your
cubicle or your garage or whatever and
you know write the software it's very
much of a group effort and it's not just
a group effort with programmers working
together they're working with designers
with ethnographers other things like
that so I think there's huge
opportunities to double down on on what
we're uniquely good at I every sin I'm
at Toffler associates I don't want to
anthropomorphize here too much but I
wonder if there is equivalent the
analogy to mental health for artificial
intelligence something that's along the
lines of healthy cognitive functioning
so I don't know if there is such a thing
and if there is I'd like you to tell me
that there is and if there is is your
Institute studying it that one I can
give a short answer to so we'll have
time for one more quick
not yet great start to our program we
have</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>