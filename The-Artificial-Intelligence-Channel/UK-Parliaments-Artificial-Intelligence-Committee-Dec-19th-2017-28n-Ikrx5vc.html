<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>UK Parliament's Artificial Intelligence Committee - Dec 19th, 2017 | Coder Coacher - Coaching Coders</title><meta content="UK Parliament's Artificial Intelligence Committee - Dec 19th, 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>UK Parliament's Artificial Intelligence Committee - Dec 19th, 2017</b></h2><h5 class="post__date">2018-01-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/28n-Ikrx5vc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well a very warm welcome to you this
afternoon and we have before us we have
professor David Edgerton hands rousing
professor of the history of Science and
Technology and professor of modern
British history King's College London
professor Peter Magowan whose vice
principal public engagement and student
Enterprise Queen Mary University of
London and professor Sir David Spiegel
helps a president of the Royal
statistical society Winton professor of
the public understanding of risk a
University of Cambridge and chair Winton
Centre for risk and evidence
communication and this is the twenty
second formal evidence session for the
inquiry the session is intended to help
the committee discuss the public
narratives around artificial
intelligence and I in view of the
presence of Professor Peter Magowan
should declare an interest as chair of
the Council of Queen Mary University
I've got a little rubric that I need to
go through before I ask you to introduce
yourselves the session is open to the
public a webcast of the session goes out
live as is and is subsequently
accessible via the parliamentary website
a verbatim transcript will be taken of
your evidence and this will be put on
the parliamentary website a few days
after this evidence session you'll be
sent a copy of the transcript to check
it the accuracy and we'd be grateful if
you could advise us of any Corrections
as quickly as possible if after this
session you wish to clarify or amplify
any points made during your evidence or
have any additional points to make
you're very welcome to submit
supplementary written evidence to us and
perhaps you'd like to introduce
yourselves for the record and then we'll
begin with questions my name's David
Spiegel Holter I'm president of the
Royal statistical Society which means
I'm a statistician but I've got my
current job is worked in the public
engagement with statistics and risk and
I've also got a history of
methodological work
Bayesian methods for artificial
intelligence I used to do thank you so
I'm professor Peter Magowan
as Laura Jones said I'm vice principal
for public engagement and student
Enterprise at Queen Mary University of
London my research areas in artificial
intelligence and robotics particularly
social robotics are I'm the
institutional lead for Queen Mary's
award of the gold watermark from the
national coordinating Center for Public
Engagement and I was awarded the baton
medal for public engagement by the iut
Institute of Engineering and Technology
I'm Deb nationalizing professor of
history science technology in the Center
for the history of science technology
medicine at King's College London in the
Department of of history I'm a historian
of modern Britain and also of Technology
and science also focusing on Britain but
also more globally and the author of a
book called the shock of the old a
global history of Technology in the 20th
century thank you very much Dean now it
may be that you will only want to answer
certain questions so if by telepathic
communication between the three of you
you might just decide with nods as to
who would like to lead on a particular
answer we'd be very happy with that
because some of them may be right within
your province such as big others may be
just slightly outside so it really will
play this by ear if if you're happy with
that as we go through but there is no
expectation that your answer every every
single question I'm going to start with
a very very general one but quite
topical in many ways what in your view
of a present dominant narratives
concerning AI at the moment are these
broadly accurate and are they helpful or
harmful and I think what we've got in
mind is that artificial intelligence is
often characterized in fairly utopian or
dystopian ways so you know we've got the
contrast there
and how do we get beyond that into a
slightly more realistic perspective on
the possible opportunities and and the
risks of AI it's not yes this may well
be one that each of you does want to
answer yes well you're better informed
on this question than I am but my
general impression is that something
called the fourth Industrial Revolution
has framed many accounts of AI Dai seems
to be the central novelty in these
stories of the fourth Industrial
Revolution the it seems to be a fairly
recent perhaps popularized at the World
Economic Forum at Davos two or three
years ago in fact it is the term that
that that has it has a history Harry
Elmer Barnes an American historical
sociologist who talked about a
technological perception of history was
describing a fourth Industrial
Revolution which was about to happen in
1948 and this this fourth Industrial
Revolution would arise through atomic
energy and supersonic transport and the
1960s he changed his mind he said the
fourth Industrial Revolution in fact
started in 1935 and that the world was
going through a fifth Industrial
Revolution and if one looks around 1960
there are any number of fourth
industrial revolutions going going on
and indeed some people think that that
AI represents a Second Industrial
Revolution or the most important change
since the first Industrial Revolution by
implication the Second Industrial
Revolution so it's is we have this very
very particular sense of AI as as a
world transforming innovation and I
think that's that's a very unhelpful way
of thinking of any particular
technical advance so well I saw this was
wrong the questions before supposed I
went to do some some research on this
and the most up-to-date paper I could
find was by Fast and Horowitz we should
published uh this year in 2017 what they
did was they looked at a longitudinal
study of the reporting of artificial
intelligence in newspapers and used
sentiment analysis and and crowd
sourcing to have those particular
stories labeled as either positive or
negative and what they discovered was
that up until about 2009 there have been
a fairly Louisville coverage of
artificial intelligence and pop there
was there was as much positive as it was
negative after 2009 there was a massive
increase both in the coverage of
artificial intelligence but in
particular around the more negative
aspect so ovae I started to overtake in
there with that around fears of loss of
control to artificial intelligences the
ethics around that and that included
things like employability and the
general negative impact on the the
market the employment market there were
very positive aspects around its use in
healthcare and those were the analysis
that were done the caveats on this was
that the data was taken from the New
York Times so therefore there may be a
cultural bias in there because it was a
us-based paper and of course the issue
of whether or not being a known tabloid
to the you would get a different kind of
set of analysis and there but certainly
that I I think that for me reflects what
my personal views are on this are which
are that there are there are some very
positive stories about artificial
intelligence that the recent discovery
of the planetary system for example but
those are very much being overweight at
the moment with the the negative stories
associated with that and very often
those negative stories are somewhat
sensational and not surprising because
there
newspaper and therefore we picked up on
there and very often not actually based
around the credible technicalities of
what's available to us at the moment
and very large pinch of kind of thought
the future geisha yeah I think that's
what I'd like to add the the fact that I
don't believe people do have not being
given a good impression an accurate
impression of what's actually going on I
think part of problem is this word
artificial intelligence which I deeply
suspicious all said thirty years agos to
work in this area and people are deeply
suspicious of it then and then and the
massive claims are being made by what
would then called expert systems that
would discover mines and would do all
this government it was all utter puffs
there was so much power this is an area
which is be full of puffs of a decade
after decade and I'm low that public I
mean now there is plus some fantastic
work going on in machine learning in
algorithms self-driving cars were you
know all this technology that is quite
extraordinary whether any of it could be
really considered as intelligent I think
it's another matter okay if you can play
chess it can do that kind of stuff but I
ask you believe the AI should be
reserved for thinking generalized
artificial intelligence that something
really does share intelligence and when
that is displayed to me I will be truly
impressed but until that happens I will
be equally impressed by the amazing
technological developments in terms of
machine learning algorithms pattern
recognition voice recognition speech
processing automatic translation these
are extraordinary feats that have been
done I would entirely agree with that I
think one of the issues around
artificial intelligence that that terms
David rightly points out is it's bandied
around fairly fairly liberally
I mean all that artificial intelligence
does in in the terms of what we have
today is actually to find patterns in
data that's all that it does and we are
constantly finding patterns and data
ourselves when we're reading something
for example we're segmenting the letters
from the page we're looking for those
sorts of patterns and that's all that
artificial intelligence does now
depending on the data that we put into
it and what we do with the results
coming out of
then there are a whole lot of
interesting things you can do with it
but ultimately it is simply about
finding these kinds of patterns and so
you all confirm that there is an issue
here I mean whether or not it is a
dramatic change in technology I mean all
of you're almost suggesting the distance
but nevertheless there is oh if you're
like a narrative issue here how you how
do you suggest that we get over that I
mean for instance are the creative arts
is is is science fiction a way of
getting through this I mean other are
the ways that that that we can overcome
this which aren't necessarily kind of
purely linear in a way that's just a way
which is to to look back to the past to
understand how unoriginal these
arguments are and I think that will
prevent a certain amount of unnecessary
repetition if I may I'm that may I say
that sounds quite an intellectual
approach to the problem I mean not that
I'm decrying that but I'm not I think
it's not necessarily the case that an
intellectual approach is going to crack
this problem is it well I think it could
also be a very practical approach some
reads a few lines that perhaps the
method will become we've become clear
this is from some some time ago the
essence of modern automation is that it
replaces the hitherto unique human
functions of memory and of judgment
computers have reached the point where
the command facilities of memory and of
judgment far beyond the capacity of any
human being or group of human beings who
have ever lived in America technological
change is beginning to move now even
more rapidly in the white-collar
professions and in engineering because
it's so much easier to program
operations of costings of wait sheets
than it is to program an engineering job
we can now set a program controlled
machine tool line so that without the
intervention of any human agency it can
produce a new set of machine tools in
its own image and when machine tools
have acquired as they now have the
Faculty of unassisted reproduction you
have reached a point of no return
where if man is to is not going to
assert control over machines the
machines are going to as
their control over man Harold Wilson
1963 the white heat of the scientific
revolution the Scientific Revolution
being affected me the second so we just
keep we keep shelling people we've been
here before Julia yes unless unless
there's evidence to the contrary one
should assume that most of this rhetoric
is just reheated nonsense from a hundred
years ago any other approaches I'd be
delighted to pick up on the science
fiction side of things so science
fiction is a double-sided sword in this
particular stage I'm sitting here in
front of you because I was inspired by
robots on the television Star Trek
Doctor Who all of those and very many of
my colleagues are in actually doing
artificial intelligence research have
been pulled in through that kind of
excitement that comes from having that
media representation of AI however we
also go to the movies and go oh no not
another set of robots trying to take
over the world kind of story and why is
that there well it's interesting to look
at the kind of broader cultural issues
around that field of Japan so for
example Japan has a very positive view
towards robotics a number of different
reasons for that one of them is the fact
that predominantly in Japan there's the
Shinto religion and the Shinto religion
allows objects non-human objects to have
a soul winners in the judeo-christian
the type of view of the world the only
thing that can ever saw was a human
being and therefore anything that
doesn't and pretends to be a human being
is evil so if you go back and for
example where robots come from would be
that with the Golem legend the golem of
the who looked after the Jews in Prague
which was a large clay man which was
brought to life by putting special
incantations and words entered into into
its mouth and in the Japanese culture
robots are actually the heroes they are
the ones who are saving the world who
are
making the world a better place in
Western culture they tend to be the
kinds of things that go up against Tom
Cruise and in the end lose which is good
because there is a moral structure there
but there is there is an intrinsic evil
in there and of course both of those are
neither true or false the technology is
morally neutral it depends on what we
wish to do with it that makes it good or
bad it does show the power of culture
there is the absolute power of culture
professor
media representations I think are
incredibly important of any scientific
technology and I think that the people
working in this area the practitioners
need to take more responsibility for the
media representation of their subject I
think if there's puff stories they need
to be called out I think there needs to
be more engagement with journalists with
people telling a story sue thee the
stories of the told are greatly busted
but accurate and because you know the
will come on to historical analogues but
a lot of you know when we think about GM
or vaccines or something like that the
only way to get good stories into the
media is for active engagements of the
sciences with the media to take it very
seriously the way in which their work is
pretty presented so I think well that
needs is that people working this area
there need to be a certain number of
what Michael ambassadors spokesman
performers people who get out there who
will engage with the media either to
present themselves or to work with
Germans to get accurate stories in there
and so that this this to be taken really
seriously just as an example over here
you know we've been trying to improve
the image of statisticians I don't think
we've seen as dangerous just dull and so
we really working hard so we've got a
whole program of training young RSS
ambassadors to get that one's just be
made head of statistics of the BBC I was
on radio 5 live this morning spouting
out about statistic of the year and this
sort of stuff so you know we are
actively trying to change the way in
which our profession and our work is
portrayed in the Met I'm really into
academics seeing themselves as
performers as well yeah I'm a performing
statistician yeah well I'm sure you're
all role models
but to be honest I think that is a
particular issue because we are bought
into this absolutely the question is how
do you motivate and reward those others
to actually do it because there are a
lot of people researching this in the
universities up and down this country
and many of them are unaware of what the
concerns are the wider society has
because they never bothered to speak to
them we need to think about how we
incentivize that possibly through the
knowledge transfer excellence Network
kind of things that are coming up to
make sure that people are going out
there talking deflating the puffs and
telling people the exciting stories
about the technology and the advantages
of it as well as becoming better
researchers because they become aware of
what the context is in the country
around them and what their sensitivities
are and that is something that breaking
down that wall is that a proactive
approach based correct I'm just going to
bring in Baroness Brenda and then I've
got Lord Gideon's wrong for this
committee which is where we get the
balance right in terms of the utter
puffs thesis versus the embrace the
change now and I'm getting that right
because we have a responsibility as
parliamentarians to to make sure that a
future generation is ready to embrace a
change and to ensure that they have
sufficient skills to do that
where do you think the balance lies for
us as a committee or should life for us
as a committee in that
that the Parliament or government has
the responsibility to ensure that the
people embrace changes that are that a
dictator from above I think I think a
governments and Apollo has a
responsibility to give people choices
that over which they can exercise the
collective collective judgment we
shouldn't assume that that the stories
that we tell about AI will actually
reflect what come what will come come to
pass so I disagree quite quite strongly
with it with a view that in essence we
have to educate the public about a
future that we already know is going to
going to exist
do you like disagreement on R and X well
I'll continue to disagree in the Ferger
I don't think that the problem is really
puff generated by the by the media I
think there's a problem of elite
understanding here and the nation of the
fourth Industrial Revolution is a is a
perfect illustration of that now why do
people who are supposed experts in this
area talk in this in this in this
extremely crude a historical on
analytical evidence free way not just
about AI but whole number of other other
novelties so it's far far too easy to
blame the media for this for this this
this this kind of way of thinking yeah
we get the balances of committee where
should we get the balance I think there
are there are there are many sorts of
people that that are expert in the way
the economy is developing the way
society is is developing I think one
dangers one one identifies a particular
technical advance as a driver of of wide
social change the authorities on that
become the experts in that in that in
that technique and I think that that in
itself is an unhelpful approach with
apologies to my god no I actually
completely agree with you I I think in
part I was saying there was very much
the aspect that as researchers we do
speak in technology and elitism and we
do that to protect ourselves that
very much most jargons are created in
that way but also we aren't aware of the
the wider things that the social
sciences of the arts can contribute and
one of the things that I've done all the
way through my life is to ensure that I
produce that mix and it's not about
going out there and prostitue lysing to
people and telling them you must learn
about this it's about saying isn't this
interesting and explaining it to them in
such a way that they can pick up on that
so it's not it's not about forcing
people to change their mind or to agree
because that would never work what we
need to do is we need to be open about
it
we need to be aware of the let people be
aware of all the things that that
technology is capable of doing which is
already making their life a far far
better and happier life than it was
before but which vanishes unseen
underneath it's like mathematics and
statistics they're all there but nobody
sees them thank you and Lord Lord Gideon
so I'm going to come up fully accept the
force of most of what was said and let
me just say that I think the shock of
the oldest trick book and deserves
enormous esteem which is hell but around
the issue you know everybody struggled
with definition what a is but from what
you're saying you wouldn't define an
autonomous vehicle as displaying any
form of intelligent behavior because you
know only a few years ago that I was
thought to be completely impossible and
an autonomous vehicle has to respond to
all sorts of previously unknown
circumstances otherwise it's not
autonomous here you wouldn't you
wouldn't include that under the category
of AI oh you would
i I think the one would have to prove
under the category of AI in the way the
AI is generally understood I would I
would say it was a reactive an
autonomous there's a really nice analogy
in some sonic of that von tiehl Bratton
Berg created these idea of Battenberg
vehicles and these were just very simple
ideas or something it's detected like
and something in the motor so you
connect together some of your text light
in something as a motor by a kind of
positive connector in between it and you
switch that on and that will move
towards the light you then change the
connection and that will move away from
the light whereas you and to promote
flies that you look at that you say oh
that little robot likes like that little
robot gets frightened by life and you
can actually take these very simple
reactions and you can build them
together into much more complicated
machines each of the individual
component parts of which is a simple
reactive circuit and yet it exhibits
very complex behavior so at some stage
you would say well that's doing
something intelligent because that's
what I would expect you know a human to
think about doing at the time well I
don't want to take the committee's time
but I mean an autonomous vehicle has to
respond to many new situations it's
never encountered before therefore it
has to learn surely otherwise we would
never trust them on the road see there's
something quite significant going on
there writing
and yeah and they can they can have
accidents as we've seen in part of the
reason for that is that they are trained
on very large datasets of the sorts of
things that happen but those situations
where the actual pattern of stimuli of
actual pattern of the information was
coming into which is not something they
have specifically seen they wouldn't
have general intelligence but it would
still be a machine which has
but could never trust it on the roads if
it isn't in some sense amazingly complex
but didn't say we anyway I don't like a
human being driving I think we shouldn't
draw the line circumstances question if
they help in chemical I think we'll
continue to speculate on that one by
count reading we've already started on
historical comparisons I think quite
well so I wonder if I could and whether
or not they're useful in understanding
what's what's happening today but I
wonder if I can broaden it to try and
bring in other technologies what
happened in other revolutions as it were
I mean I'm very aware that sometimes
technologies come along and the public
says fine that's great
reproductive technologies mobile phones
other times
shale gas biotechnology come along and
the public says whoa we don't like that
and I've you know feigning contact with
scientists before this freight train of
controversy has hit them and they've not
seen it coming as it were which is this
and how do we know which this is sorry
we're off piste question german oh no
absolutely logical the precise part of
the observation that we have any number
of techniques that we use in the present
and we've used in the in the in the past
those that become the subject of
controversy are a very tiny minority I
think as we need to start secondly we
invent many many more techniques than we
can ever use which means that we must in
fact reject most of most of the
techniques that that that are on offer
now one problem we have here is that the
loss of the standard discussion suggests
that it's a bad thing to to reject new
techniques but but we have to do it all
the time we can't have a hundred
different kinds of
or 400 kinds of methods of of skinning
cats we have to reject and and
scientists themselves have played a very
important role in in rejecting notice
choosing and not not proceeding with
with the take up of the majority of
things so I think the public has a
perfect right indeed a duty to do to
reject most things that that are that
are on offer so we have a very
complicated world stuffed full of
changing changing techniques where we
necessarily will necessarily have to
exercise choice so I would frame the
question in quite a different way I
think the thing that distinguishes the
one examples you gave is that people
will warm to a technology if they feel
personal benefit from it and that's been
shown in many cases where people did
surveys what their technology they were
scared of in the 1970s microwave ovens
were up there with nuclear power
stations but people got to like
microwave ovens you know there's still
nobody understands how they work but you
know they because they're very useful
mobile phones you know there's the
mobile phone masses that causing cancer
is it giving you you know brain cancer
by using a mobile phone well it's not
actually big issue because people like
their mobile phones they don't want to
get rid of them all the time people will
warm to technology leave it's called the
effect heuristic in psychology that once
you decide something is nice you just
you discount any possible criticisms of
it that's very popular but you can just
see the opposite happening with things
like fracking fracking where people
don't feel a personal benefit from this
and therefore they object to it they
feel that someone else is getting the
benefit a companies doing it you can see
that for the current example with
non-argument Monsanto about where the
glyphosate is carcinogenic or not the
farmers who see a great benefit from
using roundup or whatever you know being
very Pro glyphosate they're either the
campaigners who don't see who don't feel
that there is a benefit to to them of
using this a very anti so the crucial
thing I think within that within this
areas where the people feel that the
technology is being useful to them there
of course it already is being massively
useful to them you know every time
they're using you know the I've no
Google Maps this thing to do they're
driving in front that using that that
every time they're taking a picture and
it's identifying the face is nice and
it's focusing it's people are already
using this technology all the time so my
feeling is that that that this is not a
technology that will have the same sort
of intrinsic fear associated with it as
some of the other technologies where
people don't feel they're getting any
benefit it need not be one could you
just repeat the at the very beginning
you said this is an example of a tour by
count ready
oh very aware the effect here this
effect here is thank you very much
engineer it's right it's reason why
people like nuclear power you know it
spend on your association is it is it
warm and fluffy yours are not and if you
live in extra a nuclear power station
people are very Pro nuclear power from
all these various techniques of most of
which get rejected but where does the
that whole range of choices that the
public makes or doesn't make into play
with the development marketing branding
advertising of something which might be
the wrong choice but succeeds because it
winds its way into the hearts of the
public by commercial interest I think
it's rather concerning that we talk
about a technology it's in relation to
the the final final consumer technical
choices are being being made by all
sorts of agents who were not the final
the final consumer so it's positing
above a certain kind of consumer whose
inherently distrustful of a certain
kinds of techniques that doesn't seem to
capture the problem
at all not lots of different bodies are
are are taking decisions some some
openly some some some some course
controversy most most most day if your
question is directed to does the does
the the market system competition
between private enterprises and
particular research agendas of
governments produce optimal a technical
development I think the answer is almost
certainly no no it no it doesn't but the
the the the employee question there we
might we make generate better and better
choices and generates perhaps more
optimal teams is a really important one
that we absolutely need to ask and we
don't we cannot ask it if we assume that
techniques and novel techniques come out
of the ether and we merely have to to
apply them so again we need to shift the
discussion it seems to me to ask what
kinds of things would we like as a
society and how how can we ensure that
they come about and and there might be a
very free-market answer there might be a
more statist answer but that's where
there is room for serious discussion it
seems thank you George syndrome you have
no way answered my question because I
really wanted to touch more than public
trust you've spoken about meat or
representations or cost even media
misrepresentations with many of the AI
community that we've spoken to have felt
that the media focus more on the threats
rather than the opportunities and to
that end my two questions are how can
debates and discussion around AI be
conducted in a way that will engender
public trust and do know of useful
examples from other countries which
could be instructive
well I surely want to we want to
generate knowledge and understanding
rather than trust my first my first not
eating trustworthiness trustworthiness
will be yes trustworthiness in in in in
the agents involved in the discussions
yes absolutely but but not trust in in
an abstracting land like like hey I yes
I'm gonna channel one of your fellow
peers or any of it exactly why I thought
I thought so and I just spiked on about
this all the time I mean we shouldn't be
trying to be trusted you know she said
it was like totally take on you've got
to demonstrate trustworthiness and that
means you know having a degree of
transparency but not just it's called
fishbowl transparency we just could
Blair and tell everybody everything that
it has to be and she says either way
everything's the information you're
using it's going to be accessible people
to be able to get it they got to
understand it to some extent and they
got to be able to critique it if they
want with us Lee comes on to this idea
of explanation as well which we could
get onto very happy to talk about but so
I think again you're you know the people
that you say you're AI people have been
saying that the media is giving
misrepresentations but again I'm not
actually blaming the media when I was
talking about media reps also blaming
the media I was blaming these AI think
why aren't they working with the media
why aren't bad ensuring the right sort
of stories that are appearing no it's
difficult you can't control the medium
you can really work with it and to I
think it's completely wrong to blame the
media before the representations of the
de killing no but if I could just go on
it many would argue that artificial
intelligence is not necessarily
artificial noise of intelligent it is a
form of smart check checked into
technology and we we noticed in the
recent Eurobarometer survey that 74
percent of those surveyed in the UK
would make more use
digital technologies if there was more
widespread tools to improve reputation
and trust that's really what we're
trying to get it yeah I think the idea
of trust is important
I've been latest applause Mary Paul put
scientists I think third behind doctors
and nurses in terms of truck trust in
the in this country extraordinarily high
so we're starting from a sign basis in
this country in particular I think in
terms of trust but we said that the if I
could get on to this idea of explanation
nothing is important because that's to
do with an aura Neil's big point is that
if people want to be a need to go to
check what's going on they need to get
it quickly the need to better assess why
a decision has been made now we could
talk a lot about whether the GPR
whatever is going to and it's what
extent that is going to make it a legal
necessity to explain why a decision has
been made but even if it doesn't it feel
it feels the idea of interpretability
and explanation of whatever you want to
call it AI or algorithms is incredibly
important and it's taken very seriously
within the AI community the latest AI
conference nips whatever is full up with
you know how can you make deep mind
interpretive or you know incredibly
difficult for some of these blackbox
algorithms compared with the sort of
simpler statistical sort of things I
grew up with it's still produce where
you can actually see the weights being
given to each item of evidence well is
you're using deep learning there's no
way you can work it out people are
desperately trying to work out ways to
produce an explanation for why things
are happening and in fact you know the
quite strong debate going on about
perhaps in terms of predictive accuracy
it might be willing you know better to
give up a little bit of that in order to
have something better explained to
people with I mean there are ways I
think of making big engendering you know
making an algorithm even if it is a
black box more trustworthy and that's to
allow people to do what is actually
changing what was the crucial thing that
tipped the balance between me getting a
loan or not or whatever I mean I don't
know if anyone else does this all the
time went
my online insurance stuff always changed
my address a few times to work out you
know what is it that's driving the
premium has been quoting to me I just
lie and find out well what you doing
well I can do that now checking up some
good tips exactly yeah because it's a
black box algorithm probably not a very
sophisticated one that's producing the
premium probably pretty crude but I can
sort of reverse engineer it by playing
with it now that should be an option
open to everybody for whom a decision is
being made and using some sort of memory
I think one of the other things that I
would just add to that what David was
saying was our own benchmarking that if
you have kind of data sets that you sort
of knew what human experts would think
was the right answer to it then if your
your decision-making system your AI
system is going completely off that then
there's something slightly worrying in
there so it's not just about looking at
the the inside of the black box which is
incredibly important because it's part
of the reason that these deep learning
systems aren't used in safety critical
systems because you can constantly prove
time and time and time again if it'll
work which comes back to the point about
smart cars if you have an exception to
it it's it's like with something called
the frame problem a AI tends to work
within a newest set of parameters and if
you go outside that there's a problem
but human beings have that as well if
you put in a new situation you have to
kind of make mistakes to learn from so
it's both understanding what's in the
black box but also what is that black
box doing and a set of what would be
considered sensible benchmarks for
insanity thank you
and Lord Holmes
should the public be informed when
they're using a product which features a
substantive AI elements if so how would
some form of kite mark or notification
be a good idea I think there's something
in this to be honest one of the the
issues that I've also been involved in
through my career is it's around the the
underpinning importance of mathematics
and the fact that this is quite
difficult to to get young people to
study mathematics all those things have
improved a bit a whole range of
interventions and a whole set of reasons
why or why that hasn't happening but one
of the things that I constantly spend my
time doing is reminding people with the
fact that our mathematics and statistics
on who pays so much of what they want
and actually wear underpants so much of
what they want to be able to do have
their mp3 player works or or so one is
because they're built into simple
artificial intelligence systems so I
think raising that awareness of the fact
that it's there to say with it in you
know the ingredients and in foods that
we that we eat and all of the things
have to be labeled on the back you know
may contain traces of AI yeah I mean the
problem with that is that you have to
define what a I was and to say over this
has got 80% AI or 30 percent yet really
it's not like the food labeling which is
a very good example I think of a traffic
light system whatever mean it's
extremely good example of public
communication which people's mail and
may not want to use and is I think would
be very dangerous so I would put in
place of a kite mark they again the
ability for people to to critique or to
check what's being done to them and in
particular why am i you know one of the
think big things of course is
recommender systems facebook says it's
sending news feeds to you why in
facebook now you can at least ask why am
I seeing this you don't get a very good
explanation but it's not you know it is
a start of being able to see asked
extra questions right you know what
algorithm is being applied to me at the
moment I think the so I think the one
thing that one could expect are making
this up now to go along is that you are
told to what extent the decision being
made is automated in some sense like
that I don't quite know but you know
just like you know being told that you
are being targeted with this
advertisement that this is not something
that's going out to everybody you have
been specifically had this aimed at you
you should be able to know that a little
bit like they always tell you this cause
being recorded for training the purposes
you know there's a requirement to do
that actually human is not in the loop
yeah to me to decision ahead maybe yes
that's kind of interesting piece of
communication that will be thank you and
long kidiots and the implications of AI
for personal data and privacy be
communicated to the public and you might
like I don't know whether you could
comment on implications for children in
particular because there are actually
the first truly digital natives we've
never known in another world and you can
see their colleague or the devices can't
be separated from the devices they've
become in a way part the machine they're
they're piling up data without knowing
what they're doing so how can society
address this issue it's an incredibly
complicated problem two things that I
would I would put into that one of them
is around that the data protection
legislation I think that could go much
further to look at what is really the
the big issue which is recombinant data
where a piece of data is being taken
over here and a piece did from there and
over here and combined together and in
certain instances you would say you
would you would give over a particular
data that you wouldn't give over if you
were going on to a different website sim
you know you tell your friends something
your parents some necessarily but if you
were able to join those two data sets
because you knew your name
then you know a lot more about that
information you have been willing to
reveal and either of those interactions
so I do think that looking at how
recombinant data is used is something
that is worth looking out the second
thing that I think I think has has
actually been quite successful in its in
its way of of actually showing this was
born my favorites and I use it in my
lectures a lot but back in 2010 please
Rob a me.com I don't fear any of you
come across this so it was a website
that went live for about 48 24 hours 48
hours and what it did was it had a
little bit of intelligent decision
making stuff built into it that looked
at people's posts on various social
media and was able to pick up things
like the geo-tagging that you have in
photographs that you label as I'm having
a retirement holiday and then other
things on other other facing Here I am
outside my house and the Geo tag for
that tells you where the house is
but you know that the time stamp says
that that person's over in Spain on
holiday and as do you tag particularly
over there you can combine them together
and you know if that house is empty and
that came that came out actually an
incredibly simple set of rules that we
needed to combine that together
scratching the definition of artificial
intelligence but it made real impact
because people suddenly realized though
that was what could happen if your
personal data was there and you were
wreaking all this information right left
and center so it may be some more of
those short short short short sharp
shots might be interesting especially
one of the things that broke ties me not
the rest of the committee I think is
implications to face recognition mm-hmm
could you maybe build that into your ah
so face recognition
absolutely what I was thinking of the
next yeah the technology for that is
improving tremendously it is still very
brittle
the moment you wear a hat the shadow
passes over your face a lot of these
things is actually very difficult to do
you can recognize his face recognizing
it's your face is is is also quite quite
different the Americans have been using
it to scan for for criminals in crowds
at football games as people are going in
and coming out once you've got that data
that can look at a video feed and
passively a passive video feed and
actually begin to extract data from it
which is robust opens a whole series of
other ways of being able to build
artificial intelligence and freshness
even after and then I've got baronage
program just like I mean the particular
thing about this technology is people
don't know what's big that they're
giving doctor away and that things are
being done with it and it seems to me
that it will be impossible to tell
everybody at every situation when they
are providing data and you can but so I
think this is where we'll come onto
later about data governance mechanisms
it's more than rather than each person
having to be have viewing of being
personally responsible for everything
that's being extracted from them it's a
scenario where some regulation and
government and governance is appropriate
which is not I don't think this is a
anymore an object for personal
responsibility at the same time I do
when we think about children in
particular and I going to introduce this
term data literacy which I would come
back to you later on it's big enormous
Leonie this is a there's new skills and
you guys a particularly connected with
social media that are absolutely
essential for for modern citizens and
they're starting to be taught in schools
and you know there's it's a fake
ultimate fake news detection at school
by school kids II think so that there's
a lot of interest in this lot of
programs being developed a lot of you
know curriculum being developed for this
seems to be enormous ly important that
they're these are there are some basic
skills now that we'll have to which need
to be part of every futures
very feminine questions first one is any
thoughts about whether data could ever
be a commodity for a younger generation
but you know whether there's any
potential for that and secondly is the
mum of a twelve-year-old just that the
whole thought or concept that on a
smartphone and all twelve year olds have
smartphones however much you try and ban
in it that they they don't care about
giving away all this data they just and
even though they are highly educated
about how to use a smartphone they
really really don't care and there is a
generational divide and we've picked
that up from other witnesses as well so
you know if I say put that on Instagram
that we're on holiday there's absolutely
zero understanding of that from my
twelve-year-old so you help us with this
generational divide how can you overcome
that because that is it's new isn't it
because there's a jet whole generation
who who have smartphones and just don't
care about how much of their information
is out there maybe it'll have to be like
our generation was taught not to talk to
strangers there has to be a basic change
in education that people have wormed
from very very tutorials to up too late
I think one of the things that some of
the work that I've been involved in has
been taking artificial intelligence and
discussions around it into primary
schools and actually the very simplified
versions that we have there where you
can actually build a build a neuro
neural network with bits of string and
toilet wounds young kids understand that
it could play a very rudimentary game of
snap and they're excited and interested
by it and then you're educating them
about what what's going on around data
and how theatres and canoes and so on
and I think if that's there it starts
off in primary and carries through then
by the time hopefully we get to 12 they
are much more savvy about by
we need an early intervention and embed
discussions around artificial
intelligence into the curriculum because
it's across the curriculum you say it
can be it can really enhance the the
learning that young people are doing and
building that into across the curriculum
supporting teachers so they feel more
capable of being able to discuss these
sorts of things I think is important in
the same way that you know maths physics
chemistry biology and history geography
are important but these days computer
science and particularly artificial
intelligence data science has become a a
science for the to commoditize their
personal data so by that you meaning an
individual says I'll tell you this if
you pay me I own all this personal data
yes and you can have it but you have to
pay there are companies that are already
doing that where they will pay you to be
able to access your film role so they
can find out about you and start to
characterize you so that we can it may
not necessarily be money but they will
they will let you download an app that
does wonderful things but at the same
time the payment that will take there is
no such thing as free on the web you
give you data and that's really what
you're paying now thank you
and but we must move on to Baroness
Banquo
voilá is very much on the discussion
we're having which is fascinating and so
what do people need to know in order to
make informed choices about their own
lives in terms of jobs preparing
children for the future where we touched
on that but it's an exhausting as a
subject given the uncertain impact of AI
in the coming decades
what is interesting that the survey by
YouGov showed that people really aren't
very concerned they don't worry about
their jobs not
this 2% were not worried at all should
they be worried should we help them to
be worried so that they can help find a
solution I'd like to know what you
professor teacher when you give
presentations at school oh I'm very much
that it comes back to this data literacy
that you have a deep skepticism there
everything you see in the media is the
first thing and teaching people the
tools to deconstruct arguments that
claim to be based on evidence the
numbers show in this stuff so actually
you know there are a set of principles
you can go through to try to decide
whether something you're hearing how
reliable it is so it is again coming
back turn or anneals point that is
trustworthiness you need to be able to
innovate and I don't like the thing of
educating people you just need to
empower people to check on someone's
trustworthiness so a lot of people need
to know a lot of adults need to know
exactly those things too don't they yes
yes I hate to think it's too late if you
teach them in school so by the time
entitles hopefully they'll be
remembering there should be people been
worrying about jobs and the changing or
the changing landscape of them in
general I think I think it's the one
thing that we could be certain about
this uncertainty in the future in the
jobs market and not just necessarily
because of artificial intelligence
technology but because of the whole
range of other of other things I think
the one thing that I say when when
talking to do young people where I go to
schools is about flexibility is those
transferable skills those abilities to
reason to be entrepreneurial and so on
in there so if you look at some of the
the work that's coming out of there some
think tanks I my favorite piece of data
that was presented the previous session
on AI was the one that gave the
percentage of jobs to be lost in
constituencies depending on which member
of parliament it was suddenly got people
very interested doing that but that was
you know potentially up to 30 40 % my
feeling is that it probably will not be
as bad as that because there will be new
jobs that will be opened they will be
requiring you to be flexible to be able
to move into them to retrain and that's
why I think of the importance of
education but then I would say that
wouldn't I as a University University
professor but I also think that the the
threat of artificial intelligence is
likely to go in a direction that is not
quite the way we imagined it I think
that what we'll see in the future are
potentially large areas of beneficial
blending bringing together what AI does
well about human intelligence does to
work together in there I mean very very
brief example our professional
intelligence system that I've been
working on which can actually analyze
where people look in images for example
rather than having to pay lots of people
to sit with AI trainers and things on
when I tried to commercialize that I was
told that it wouldn't go anywhere
because if you undermined it and you
said to all these designers that were
out there I've got something that can
replace you it will get no attraction so
what you do is it's now becomes part of
their computer-aided design so they do
all the clever stop it tells you this
and it becomes a human in the loop
and I think that that's likely to be the
direction that things will go yes
professor edge - and then I'm going to
bring in Lord platinum and then by
Calgary Glee I think we we would do the
service to the to the public if we told
them that AI was going to be the major
determinant of the deployability or
their of their children who did
effectively that with with IT would
people who did that with space rockets
and with with airplanes before them each
and individual new technique will will
have a small effect in relation
to the total to the total economy it is
it is to misunderstand the nature of our
society to assume that one particular
technique will have a transformative
effect which is out of proportion to all
the other all the other tech Matic cars
they've put all taxi drivers and all
lorry drivers out of work if we have
them but that is that is that is an
argument that people make I could see
lots of arguments but not having
automated cars I can see lots of
arguments for buses and trains and and
for walking and for cycling so that
that's my point away that we if we start
with the assumption that we will have
nothing but driverless cars we will do a
disservice to the public's understanding
of what the future is is likely likely
likely to make you know another part
just it doesn't sit but this is Rick
this is about political economy brexit
is going to have probably a much larger
effect than AI on the employment
possibilities our children will will
will will have do we go do we do we go
and warn them about about about this in
school the price of oil whatever
whatever it might be MIT may be more
important or other preview I'm less far
less concerned about the impact the
product ization of AI then I am with the
notion of product ization of people and
this is where I see the this very
troubles me greatly and it touches on
the next question I'm sure some getting
ahead or Steven but tell you why they
come from
do you think it makes me at all unique
years I spent the first dozen years my
dive in advertising and by the time I
left I had no illusions whatsoever that
if you offer advantages to people in
advertising to find out more about their
customers they'll take them and it's the
misuse of data that troubles me very
greatly about people being a fourth
I like watching soccer there for a girl
of sky upset it's quite specific but the
fact that by lot by watching soccer
there data on all of my family's habits
are being collected centrally
and then could be turned around and used
in a variety of ways leads me to the
whole issue of the misuse of data I just
jotted down here it's an example why is
it that I trust which but I have a
mistrust of TripAdvisor
I think it's because not just I was
growing up with MIT which I know that
which is controlled by the National
Consumer Council and I know the
TripAdvisor does its best to manipulate
me and push me a bit by the number of
sites it has to make decisions how do
you suggest and it's about government I
think and I think professor usually you
touched on this how do what's the role
of government in ensuring that we're not
just aware but we actually protected
against the misuse of data which has
been collected without our knowledge
and this comes in the whole area of data
governance and organisations which is in
a state of flux really I think at the
moment in this country and and else
elsewhere about the role of regulation
in data as I said I don't think is up to
every individual to have to protect
themselves against this because it's
going to it needs a higher regulatory
framework and I there's the various
bodies at the moment you know ICO
information Commission because I think
you know could be doing very well but
could be strengthened even further
there's it really comes in there's no
field convention for data ethics has
just been set up which is with the help
of the raw statistical society and
there's also a Council for data science
ethics that's being and being proposed
so there's there's various bodies and
all and I'm not going to say exactly
what's the right balance or how they
should be done except there is this
massive need to to grasp this and to
develop appropriate governance and
regulation but it's going to use
to be debated that's just a silly
example from my own background so I
started in advertising 1957 the big book
that year was van spec arts hidden
persuaders the preface will remember
very well indeed and the issue that
cropped up was the the whole business of
subliminal messaging and the IBA moved
within a year to be very clear about
what you couldn't couldn't do on
television in terms of speed of images I
mean it was done now whether they
overacted undirected is something
probably gone but the government moved
like lightning it was real do we have
the same mechanism do we have the same
will still to use our agencies to move
against the misuse whatever it's
happening Edmund has happened for ages
in setting insurance premiums you know
the very strong regulation that the only
genetic condition you are allowed to ask
about is Huntington's the farsighted my
understanding you can't ask ethnicity
you can no longer ask gender for car
insurance you know there's also some
rules have been put in there and where
the where the companies would love to
have more data because they can get you
know they could do it find a
stratification for the premiums but they
does not allow it but I think the point
is an important one because within
they're actually collecting that data
can allow them to do services that
actually would be very positive to you
it's a question of whether or not what's
being done to you is something you enjoy
having done to you or something that you
don't you don't and I think that makes
it very difficult to to do subliminal
messaging I think was an interesting
example that you chose the efficacy of
it is again something that can be very
strongly argued but it was moved on very
rapidly because it was a very contained
solid kind of little block of of things
and that wasn't said sperm analogous
means people will work like zombies and
just buy this so if that's clear you can
ban that because that's what that does
recombinant data data fusion from
from sources isn't of is an of itself
not necessarily an evil thing but it can
be used for evil things that I think
that makes it very difficult as
professors vehicle holder says that
whole thing around data governance is
important and it may be that you can't
block particular things at particular
points and say you're not allowed to to
do this but then you you open the whole
broader situation with regards to
transporter transfers because there are
cases of data havens where things that
can't be done under our data protection
it can be transferred to a lot of places
done over there process the member
terryback again
sorry that's sorry before I bring in
bike out Ridley professor Edgerton did
you want to just on this point about
will that could were like I think
there's a general phenomena that lack of
lack of will to control private
corporations private interests in in the
public interest and we've seen of course
in the case of in the case of television
I think they a decrease in quality of
television programming of the last
twenty or thirty as consequent on you
believe there's a public interest
element to this being exited which is
certainly what I believe not being
exercised yes we could rip we we know
how to establish mechanisms to ensure
that the public gets quality information
we have decided not to use those those
those powers for all sorts of reasons
that are very familiar but we return to
a situation where we do thank you very
much thanks I can't really come back to
the point that Professor Edgerton was
making a few minutes ago about the risk
that we get carried away and prepare
children for a future which might never
happen if you like um can you give us a
specific example maybe going back to
that era Wilson speech you you read from
of where we got a bit overexcited about
a technology and built something into
the curriculum or into the way we re
skilled people that turned out to be a
bit of a bust I mean did we train far
too many nuclear engineers
did we miss the integrated circuit yes
and could be argued that perhaps too
many science energies in general were
were trained given the number of jobs
that were before them I know in science
and engineering that there was a
desperate shortage in fact the fact that
so many go to the cities of jesters that
rather hope that rather an oversupply I
mean certainly in the realm of public
policy all sorts of assumptions drove a
particular technical development into
what turned out to be dead ends at least
for the United Kingdom if not for the
world as a whole massive over investment
in British atomic energy for example
over investment in supersonic transport
I think it can be better off with a
Concorde never come along at the
advanced gas-cooled reactor never could
never never never come along so I think
these these enthusiasms for very
particular techniques have their
negative side one shouldn't assume that
it's all about exciting people about and
getting into into science they lead to
certain public policies which can
actually reduce national perhaps human
welfare more more January so it it is
not a cost-free exercise to hype one
technique over over over another thank
you Bishop thank you and the
government's recently have proposed
announced the Center for data ethics and
innovation which will aim to lead in
that area can we ask you what would be a
good ethical framework for the
development and deployment of AI not
only to build public trust which we've
covered quite well but also for afro
assuring society I can just observe in
what you've said so far you've been very
strong on teaching people deconstructive
and critical skills and building a
strong hermeneutic of suspicion into
particularly children but you haven't
been particularly strong about
appreciative inquiry about identified
what is good and makes for a flourishing
society so we had not only avoid the
dangers that build good qualities into
our common life I thought I was
addressing that that point you did yeah
yeah I think it's a crucial crucial
wonder that we need to get back and into
into a position so I think we were there
at least partially in the years after
1945 where we believe we can take a
collective view as to how to improve
society and act on it collectively now
there are very good reasons why why many
people began to reject that that sort of
sort of approach recognize that but but
I I think there was value in it I think
we ought to empower ourselves as a
collectivity to think through the kind
of society that we want and the kind of
machines that we want the kind of
techniques that we want to deploy it and
decide indeed who should have control
over those those techniques I think want
us to really take a utilitarian approach
to this because there are many positive
things there are many negative things
and it requires a decision to be taken
on on what will be allowed and what
should not necessarily be allowed and
then the the kind of gray area between
those and those really can only come
through discussions by having in the
same way that as as a scientist if I
wish to do a particular experiment I
need to go through an ethics committee
and that ethics committee has to lay
members as well as expert members on
there and I think putting in place
structures like that they give some kind
of confidence on on the data what what
people feel this would give us a a
slight idea of what's likely to be the
the red buttons that we shouldn't be
pressed
and then look at the center is central
and innovation and I think you're right
we have slightly emphasized the the
critical part they the appraisal part
which is I think where a lot of the
ethical debate comes in the other side
of what I would call data literacy is
the innovation side which is the
enormous excitement the enormous you
know benefits for this and you know
again I think you're new in primary
schools you know kids should be doing
this stuff II think you'll networks are
the toilet rolls it's so exciting to DX
they come up with new ideas things they
could do anything the data that are not
just passive recipients of stuff on
their phone they're actively going out
and innovating and constructing and that
and it's never too early I think to
introduce that thing and I think you
know that will happen you know that
should just happen anyway so I think I
quite like this ethics and innovation
because they're two sides of the same
coin but you know one is to do with the
production the others I think to do with
the innocence the control or the
criticism and you need both talking
about things ethically can be a way of
not talking about them economically and
politically and I think that will be a
serious serious mistake thank you thank
you Swinton
how should we be thinking about the
International narratives around a I
there's been much discussion about an
arms race the merging between nations is
this a useful way of thinking about air
yes no I think when we're thinking about
technical advances we switch between a
very kind of global vision as to this
new technique is affecting all of
humankind to a very nationalistic vision
without without warning and I think we
need to we need to be very very very
careful about that for example there's a
lot of lots of talk around AI which
focuses effectively on what the United
Kingdom can get out of AI economically
in competition with other with other
other countries that are also developing
AI but sometimes those those discussions
about what the United Kingdom can get
out of it oh they've actually the same
discussion as what is happening in the
world as a whole the reality is there is
an element of competition and the United
Kingdom might indeed be able to use AI
without being an innovator in that with
that area without indeed exploiting
British innovation in that in that area
so there are many separate discussions
to be had about about the relation of
the nation-state
to to AI and they shouldn't I think be
completed as they as they often are for
example the moment it seems that the
government is looking to two to diverge
from EU regulation precisely in these
areas I assume in the hope of getting
getting at an economic advantage I think
would be some read very hard questions
to be asked what what actual advantage
the United Kingdom has these are the
other parts of the world in in in AI
which
probably worth that serious examination
that I looked at one point to the kick
that the case of Biosciences and I found
there that the claim that the United
Kingdom had a really unique strengths in
Biosciences that had to be exploited and
to not really be a very strongly
supported by the evidence the reality is
that there are five or six rich
countries that are on a reasonably same
level when it comes to Biosciences and I
guess a I don't know that particular
case so one must be where the stories
that we're increasingly told about these
very particular British British
strengths waiting to be exploited yeah I
agree I think that the whole issue is
it's not simply about artificial
intelligence but Materials Research
Biosciences are all series of things
which could be considered an arms race
with with with with other countries and
AI is just one of many of a mix of
technologies that potentially can if
they make his way into the marketplace
can change the way that the we buy and
consume products and I think that's just
important to see it there there's
nothing special about me I don't think I
can say much by this except you know we
just got to be aware of the enormous
dominance of Facebook Apple Google and
Amazon in this area and he's just can't
ignore it then we have that has to be
taken into account in any thinking about
about our roles of the in terms of
national identity thank you Lord
colleague thank you talked about certain
national areas of strength from possibly
son which so exaggerated and so much
maybe not fully appreciated interested
to know what you thought the strengths
that the UK has particular strengths the
UK has in AI
the other house we've got very strong
machine learning communities yeah
that somebody selling picking up the
first week of alters point about
Facebook and and Twitter and so on they
are setting up a headquarter in here in
the UK because they are able to then
absorb elements from the UK university
system so deepmind actually a colleague
of mine who replaced me when I moved to
become become vice-principal got
kidnapped in a very large bank with a
very large paycheck by deep minded we
never saw them again so that that threat
or opportunity a combination of both
great I'm not gonna come down one side
of the other I think it is it is a
threat I think to the UK from the point
of view of the fact that it's very
difficult to recruit lecturers in those
particular areas because they are all
being picked up by these these large
companies if they're worth their salt
which means it's difficult for us as a
university sector to keep developing
these things but it's also an advantage
in that we now have links with these
larger companies and that's useful for
one point of view you know exploiting
their their knowledge base plus spread
and things
they tend to do them very quietly as a
real business I'll be in danger of
becoming a vessel state in the digital
yeah they're where we've heard that
phrase I think I think I think there is
there is a possibility because these are
just such large multinational
organizations I think the one thing that
that continues to impress me is the fact
that there are still a lot of very
creative young academics coming into the
system who are coming up with fantastic
new ways of doing things and the point
is at the end of that do you are you
able to keep them on and sometimes they
will be because the academic lifestyle
is is different from working for one of
these large companies we have less
hammocks we don't pay them as much but
there is a certain level of freedom
within it and also you know what people
do enjoy teaching the next generation of
young minds so I think there are ways of
keeping people within the university
sector and in the AI side of things but
actually universities these days are
more interested I think than they have
been in the past in in a kind of cool
working with these larger companies as
part of the government's industrial
strategy and so on that that's going to
be incentivized seasoning as we separate
from the European Union that's going to
make the UK I promise not to say
anything about breaks it monarchy this
is such a contentious issue however if I
must I think that what somewhat concerns
me is there's a lot of discussions about
breaks that the pros and the cons of it
and in those discussions very little
very occasionally you get to snippet
about mother and science and it's all
about Trade and Industry that's
incredibly important but
we as the UK were very well represented
within things like horizon 2020 the
project that I did on social robotics
was a seven year project with people
from across Europe that needed to be
there because we were looking at
cultural differences as well and they're
very there are cultural differences on
the acceptability of robots in AI in in
in different countries I think
potentially we might lose some of that
particularly the freedom of movement of
of academics although they hopefully
will have as the government was
mentioned there were visas that allow
them to come in whether they will want
to do that is a question I think time
will tell right thank you very much and
final question from Baroness Grenda
every witness this question at the end
of every session and we want one
specific from each of you that you think
we should make as a recommendation in
our affair and given that it's our final
time that we do this most likely we're
sure they're going to be an absolute
cracker from each one of you it's a new
pressure so a single recommendation
about what we should recommend the
public is not the problem
elite understanding of technical change
in his impact is thank you coming up
from that is it's the same thing that
the public is not the problem we have
ten thousand last research assessment
this is research excellence framework
over ten thousand three and four star
researchers in this country if we can
take those people who are researching
artificial intelligence and motivate and
reward those people to actually go out
and not just disseminate but co-create
with people to put it into the
curriculum in schools to to work hard on
there I think that is something that
would make a significant change and to
give one specific example when people
apply to the Research Council's then you
overarching research council in the
application form six words to change the
country the six boards are must contain
significant evaluated public engagement
okay what I said before I think you
should be empowering a new generation
with data literacy and that includes
both the ability to innovate and ability
to critique fantastic thank you very
much very succinct thank you very much
indeed
and you see we didn't want to let you go
because we've had such an interesting
session thank you very much I've learned
two new phrases fishbowl transparency
and recombinant data thank you very much
indeed it's all every little bit helps
the proceeding has ended</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>