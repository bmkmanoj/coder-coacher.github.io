<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Build Safe &amp; Friendly AI - Prof. Stuart Russell &amp;  Sebastian Thrun | Coder Coacher - Coaching Coders</title><meta content="How to Build Safe &amp; Friendly AI - Prof. Stuart Russell &amp;  Sebastian Thrun - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Build Safe &amp; Friendly AI - Prof. Stuart Russell &amp;  Sebastian Thrun</b></h2><h5 class="post__date">2018-01-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6Qrct8tWNhE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">from WBUR Boston and NPR I'm ray Suarez
and this is on point
fellow humans we are at an inflection
point AI artificial intelligence started
off at a crawl years ago today it's
galloping ahead computers have been
voraciously gobbling up our online data
and have already learned a heck of a lot
now they're almost ready for take off
and some of the biggest voices in the
field say we have to figure out how to
keep something more powerful than us
within our power this our on point the
call for a set of rules for our
computers you can join us on air or
online do you really believe computers
are getting not only faster but smarter
than us do you welcome that do you want
to see a code of ethics and technology
that will keep humans safe join us
anytime at OnPoint radio org or on
Twitter and Facebook at OnPoint radio
joining me from Paris France is Stuart
Russell one of the pioneers in
artificial intelligence founder of the
Center for human compatible artificial
intelligence at UC Berkeley
he wrote the standard textbook co-wrote
the standard textbook in his field two
years ago he wrote an open letter
calling for ethical AI that's been
signed by over 8,000 people including
many of the top names at Google Facebook
Microsoft last year he commissioned a
video called slaughter bots in the
run-up to a UN conference on arms
control for autonomous weapons you can
find a link to Russell's open letter the
slaughter bots video and more on our
website OnPoint Radio org Stuart Russell
I'm almost hesitating to say I'm
delighted to talk to you but let me say
welcome to OnPoint hi ray thank you you
know I talked to techno utopians
techno dystopian as I hear all kinds of
plausible scenarios for our near future
from robots that can become intuitive
companions to housebound elderly people
learn their habits and their
personalities and I say Oh Bravo
and then here the in the next moment
practically about a future where robots
without us even realizing it control the
aspects of life that that shape our
daily existence what is it that I should
be worried about so I think the first
thing to do is is not to think about it
as forecasting the weather we're not
saying okay tomorrow it's gonna rain or
tomorrow it's going to be you know 75
and sunny we should think about it as
trying to steer a course it's as if
we're you know the captain of a ship and
we want to make sure that we know where
the icebergs are and that we don't crash
into them so what you're worried about I
think depends on the time scale that
you're looking at right now there are
things to worry about today there are AI
systems generating fake news generating
fake videos being used to persuade
people to change their behavior whether
it's their commercial behavior buying or
political behavior who they vote for
there's even automated blackmail so
there are programs that read your email
and follow your texts and follow your
movements on your iPhone and figuring
out if you were doing something you
shouldn't be doing and then they start
blackmailing you so those are things
that are happening now another thing
that's happening now is you mentioned
the slaughter bots video is about
autonomous weapons and I just came from
that meeting that you mentioned the
United Nations meeting in Geneva where
the Russian ambassador said you know we
don't need to worry about these things
you know there are decades away in the
future and Kalashnikov which is a major
Russian arms corporation is actually
selling autonomous weapons we just heard
this week about a mass drone attack on a
Russian base in Syria by 13 drones
that were launched by an unknown party
so we don't even know where they came
from so these things are moving very
very quickly but before your listeners
start to worry that these these killer
robots are the ones that we have to
worry about taking
the world these are two very very
different things the the killer robots
can be dangerous without any ability to
take over the world just like you know a
gorilla
armed with a machine gun could be very
dangerous even though you're not worried
about that gorilla with the machine gun
taking over the world so the danger with
autonomous weapons is that people use
them effectively in very very large
numbers to create a weapon of mass
destruction
they can do things an individual warrior
can't do and I think that's that's an
aspect of this that shapes not only
weapons but a lot of the conversation
about the future of AI much of what we
think of as the future ability of our
machines is shaped by conditioned by
science fiction in the 1968 film 2001 a
Space Odyssey the supercomputer how
refuses to listen to orders from
astronaut dr. Dave Bowman Dave wants to
disconnect how take control of the
spaceship but Hal is programmed to let
nothing get in the way of his mission
open the pod bay doors help I'm sorry
Dave I'm afraid I can't do that and I
think what made what made the Hal 9000
so creepy is that he was perfectly calm
and rational sounding when refusing to
do what Keir Dullea was asking him to do
which yeah I mean that seems like part
of the possibility of a future sentient
machine yeah so there's another episode
in the same movie a little earlier on
which actually sets the scene where Dave
is playing chess against hell and you
know Dave losers and how treats Dave
like a little child here Dave your your
game is really improving and it's there
to show that how can out think Dave no
matter what Dave tries but fortunately
in order to have a plot for the movie
eventually Dave does outwit how land
to switch hell off if how had really
been a super intelligent machine then
how would have outwitted Dave and they
wouldn't there wouldn't have been much
of a movie all the humans would be dead
this week I came across an example that
cut a little closer to the bone since
I've made my living as a reporter for
the last 40 years The Economist magazine
trained an AI program on how to write a
news article and in its science and
technology section it gave the program
all the information that a journalist
would need to produce an article it came
out what you could tell there was
something wrong with it but at the same
time it was pretty good for a machine
pretty close though the story didn't
always make sense WBUR producer and
performer a Maurice Everson dug deep to
find the soul of the machine and here
she is reading part of that story
written by an intelligent machine the
result is a shape of an alternative to
electric cars but the most famous
problem is that the control system is
then powered by a computer that is
composed of a second part of the
spectrum the first solution is far from
cheap but if it is a bit like a solid
sheet of contact with the spectrum it
can be read as the sound waves are
available this is way way beyond what a
computer was able to do even a couple of
years ago this is moving very quickly
I'm not so sure because I would be very
convinced by that that story so I'll
tell you another little story so this
morning I had some ibuprofen on the
counter it's an Advil if you like and it
got knocked off on the floor and my dog
being a puppy immediately netted before
I could pick it up so then I'm like okay
how do we make the dog throw up so I go
on go online and and it turns out that
if you ask questions about how to you
know how to cure your pets
there are lots and lots of AI systems
that are answering those questions so
you know you find this a conversation on
just answers calm
it says oh hi you know my dog just
swallowed ibuprofen you know what should
I do and the AI system answers well how
much does ibuprofen weigh and how old is
he thinks ibuprofen is the name with a
dog so so I think that we can make demos
that are very impressive and there are
real advances going on so particularly
the ability to recognize objects in
images and to do speech recognition you
know I would say it's doubled or tripled
in quality in the last few years and in
some in some senses is actually superior
to human abilities particularly
apparently in recognizing different
breeds of dog so so progress is very
rapid but we are a long way from having
something like hell which in many ways
is superhuman
across the whole spectrum of knowledge
and reasoning and planning ability to
have a conversation ability to read lips
which is part of the plot in the movie
so I think very few people are saying
super intelligent AI is right around the
corner and you know we have to put the
brakes on it you know we have to stop
doing this what what the debate is about
is first of all when is it going to
happen is it going to happen and how
long it's going to take and if it's
going to come what are the risks that we
need to start thinking about now and and
the hell you know the 2001 movie is
actually a pretty good description of
what the problem is so how has a mission
the mission has been given to him which
is in fact completely mysterious in the
movie but it's something to do with you
know getting to Jupiter and then finding
this the second obelisk and getting in
touch with the alien species that put it
there and nothing once once a machine
has been given an objective it's not
going to be convinced by someone
speaking that it should adopt a
different objective
unless the objective already included
you know but if they've says do this do
this then you have to listen to Dave and
not complete the mission finding the
obelisk so this is the issue and there's
a very nice quote from Norbert Wiener
who was a very famous mathematician in
the 20th century and in 1960 he said we
have to be absolutely sure that the
purpose we put into the machine is the
purpose which we really desire and so
this is the core of the problem we might
call us the King Midas problem because
King Midas said you know I want
everything I touch to turn to gold and
he got exactly what he specified or he
got his purpose and then he died in
misery and starvation because his food
and his drink turned to gold I'm talking
with one of the top voices in the field
of artificial intelligence who says we
desperately need to give our computers
an ironclad set of rules that will make
sure they work to our benefit what rules
what Ten Commandments would you give the
world's computers I'm ray Suarez this is
on point
how much would you pay to avoid morning
traffic why our plane tickets to Boise
so expensive and what can a tuna cannery
in the middle of the Pacific tell us
about taxes I'm part of Garcia co-host
of the indicator a new podcast from
Planet Money we're in every episode we
take on a new unexpected idea to help
you make sense of the day's news get it
on NPR 1 or wherever you get your
podcasts this is on point I'm ray Suarez
we're hearing the debate within the
world of AI about whether we need to
build fail-safes into our computers now
while they're on the brink of becoming
more powerful than we are you can join
the conversation do you believe we can
control our computers do you think we
can design them so they remain in our
service advance us and not leave us
behind later on in the program we'll
hear from Sebastian Thrun another big
voice in the field but a techno optimist
right now we'll continue with my guest
Stuart Russell a man expert enough to
have earned the right to worry Stuart
Russell one of the pioneers in
artificial intelligence founder of the
Center for human compatible artificial
intelligence at Berkeley let's take a
listen to what some of our listeners
have been writing on our website and on
social media and Steph says just a
rhetorical question when it comes to
making complex decisions we don't fully
understand the factors that influenced
our reasoning we make up explanations to
account for our decisions but those
explanations are not always accurate are
we trying to hold a eye to a higher
standard than we apply to our own
decision-making Gerry writes on Facebook
the US must have excellent product
liability laws our product liability
laws are weak in the technology sector
and have been for quite some time
we must elect politicians who are
skilled in writing good and ethical laws
until those laws are in place and
enforced we should exercise prudence
when using technology and minimize our
risks Stuart Russell is there a
market-based solution to the problems
you're worried about in the future
well I think the market does actually
play a role I was just thinking about
the you know weather Chernobyl could
have been prevented by product liability
so the you know total cost of Chernobyl
was getting on for a trillion dollars so
I think you know a liability insurance
policy probably wouldn't have helped
that much but the way the market helps
is that we have to solve this problem in
miniature long before we reach super
intelligent machines so let's take a
very simple example if you want to have
an intelligent personal assistant that
you know helps you organize your travel
you know books you into the right hotel
puts you on the right flight you know
make sure that you know how to get from
the airport to the hotel and so on so
how does that system know whether you're
you know me who you know isn't gonna
spend more than 200 bucks a night on a
hotel or president Trump who you know
would probably stay in the presidential
suite for twenty five thousand dollars a
night humans are different and a piece
of software is going to have to learn
the Preferences of the person that
they're working for otherwise people are
not going to buy it you know if
President Trump's not going to use it if
it puts him in a $200 or night room and
I'm not going to use it if it puts me in
a $25,000 a night room so so commercial
forces mean that we have to solve the
problem of how a I systems learn about
the preferences of individual people and
then learn to you know help you know
help people achieve their objectives and
also trade-off between the objectives of
the person they're working for and and
other people so I made up a little
anecdote when I was trying to explain
this at a meeting one day so you come
home from work and your personal your
personal assistant reminds you that you
have a very important dinner at 7:30 and
you say what what dinners that and it
says oh it's your you know your 20th
anniversary you have to go to dinner
with your wife and you say oh no I
totally forgot you know I've already
booked booked dinner with you know with
the CEO and and the system says
I did warn you but you overrode my
recommendation okay well what am I gonna
do now and the system says well I just
arranged for the CEOs plane to be
delayed until tomorrow morning and and
he sends his apologies and he's gonna
have lunch with you tomorrow instead so
you know problem solved you get to meet
with the CEO the CEO thinks it's his
fault and not yours and you still get to
have dinner with the wife now you
wouldn't want an AI system behave that
way because you know it's not respecting
the Preferences of you know the CEO on
everyone else on the plane and the
airline and so on it's just trying to
solve your problem so so these kinds of
events mean that you know a system that
is not built with the ability to learn
preferences and to respect preferences
of others correctly is going to be a
huge liability and so as AI systems
start to be able to impact the real
world you absolutely have got to figure
out how to make them what we call
provably beneficial meaning that I can
mathematically prove that they won't
make that kind of a mess Stuart Russell
joins us from Paris our next stop this
hour is Fort Lauderdale Florida Isabelle
is calling welcome to the program hi
thank you for taking my call I intrigued
by this conversation I am an academic
and we just submitted a few weeks ago
for the Academy of management conference
which is a very large conference with
over 10,000 participants and it was
about the social and ethical
implications of artificial intelligence
the reason that we with a group of
colleagues presented this is because we
see the conversation is absent in our
classrooms we educators don't discuss
what are the impact on different
stakeholders what is their other social
or ethical implications of inventing
everything we can and the accident is or
the focuses everything that we can
innovate is cool but there
there's an inner landscape about values
about thinking in the long term or the
broader scope that is just not addressed
and so that is the reason we we
presented that paper and I was just
intrigued about this conversation boy
Isabel right you are that idea that
almost determinism that if we can think
of it then it must be okay
drives a lot of the innovation that's
going on what's your reaction Stuart
Russell I have to say I completely agree
with Isabel and probably for that reason
I'm rewriting my textbook so that these
issues are you know front and center
right there in chapter 1 and chapter 2
but I think in general the computer
science community has been very slow
just to take itself seriously I think
particularly in AI we've spent so long
just trying to get anything to work that
we haven't worried too much about the
you know ethical and social impacts in
the way that for example the biologists
are worried about it because you know
biologists have have been very much
under the public eye for thousands of
years because you know doctors are
cutting holes at you they better they
don't know what they're doing
whereas in AI people have been playing
chess and and making robots downs up and
down you know there's not been the
opportunity for a big impact on human
life but that's changing very quickly
and I think computer science absolutely
has to catch up and I recommend that
everyone read a story by e/m Forster you
know who usually wrote novels of
Victorian and Edwardian manners but he
wrote a short story called the machine
stops in 1909 and in that story
human beings sort of live within a
machine that takes care of all of their
needs you know everyone has their own
little cell and the honeycomb so to
speak and look it provides them with
food and drink and entertainment
communication they have internet they
have iPads they have videoconferencing
they spend a lot of time listening to
lectures on massive open online courses
and the human race becomes completely
dependent on the machine to the point
where they actually no longer even
understand how it works
which is a recipe for disaster as it
turns out so and this is a slippery
slope the people who live in that
machine think that they have the best
possible world that the old civilization
where people were outside where people
met each other in person where people
did things other than read and think and
talk you know that that old world was
horrific and and the new world is the
best one and so it shows how our our
culture our our own values are actually
quite plastic and fragile and can be
molded by the environment that we're in
and we go down this slippery slope and
wall-e you know is another the movie
wall-e is another example where the
people who live on the spaceship and
wall-e
you know which has to leave the earth
because the earth has been turned into a
you know an ecological disaster so the
human race is now on these giant
spaceships and they're all looked after
by these machines and they all become
obese in sort of stupid they sit there
with their faces glued to screens all
day long and this sort of in feeble mint
is something we have to be very
concerned about so in some sense we now
you know after millennia we now have the
power to do anything we want with the
world or we soon will and we don't know
how to use that power well Stuart I'm
about to give you a little bit more well
better informed push back then genial me
let's introduce Sebastian Thrun he's
also a big voice in artificial
intelligence he's been called the
godfather of Google's self-driving car
he was a VP there he's a founding
director of Stanford University's
artificial intelligence lab chairman and
co-founder of the online university
Udacity and he joins us from where else
palo alto sebastian welcome to one point
hey Reagan how you do it
so would your would your advice be don't
worry so much Sebastian I would say that
technology
has a history of good users and bad
users I mean technology that can be
abused includes the kitchen knife and
includes nuclear weapons and AI will be
no exception but we've seen an amazing
number of great new innovations using AI
that empower people do the things you've
never been able to do before and viola I
understand kind of the fearful
perspective that's being laid out here
that's partially fueled obviously by the
movie industry I think there's a great
benefit to build for example south
driving cars that enabled blind people
to use Motor Vehicles safely that we
should not be dismissed but can we build
in guideposts around a field that that
so far is not hemmed in by folkways
practices standards that are of long
duration before we we think of AI LCI
Magana of the world let's dose of
realism to this and let's ask what is AI
really doing there's been amazingly
great examples of AI systems playing
games like the game of go at a human
level skill finding skin cancer better
than the best human dermatologist or
flying airplanes and what all these
systems do is something very very very
simple they observe a repetitive task
something like a pilot in an air cockpit
or a driver in a car and after watching
long enough they can repeat what the
person does and they do it very well so
for example I spent better part of my
career building self-driving cars first
at Stanford and then at Google and we've
gotten to the point where these cars
basically are safer than human drivers
give you a statistics we kill in traffic
more than 1 million people humans do
every every year around the world and
the Google self-driving car has driven
more than 2 million miles and has only
had one small fender bender in its
entire accident history or something
that people can't do and this machine
just
replicates good driving behavior it has
absolutely none of the skills that has
been laid out on this on this video show
it can't enslave people it can to
redirect claims it can't issued drone
strikes can you fly a plane they can
only repeat this one very simple thing
which is how to turn the steering wheel
Stuart Russell is there a yeah but
answer to Sebastian well so you have
several yeah but so so the first one is
yes of course there are benefits to AI
if there were no benefits people
wouldn't even be doing AI and and I
wouldn't be talking to you about this
because there would be no progress and
there'll be nothing to worry about
so it's sort of like saying well
electricity is is useful for lots of
things look you know you can you can
shave you can boil water you can do this
you can do that electricity is fantastic
therefore we don't need to worry about
nuclear power stations exploding well
it's exactly the opposite if the nuclear
power station explodes which was what
happened with Chernobyl then we stopped
getting the benefits in fact the new
nuclear power station construction was
cut by ninety percent after Chernobyl so
we have lost a lot of the benefits
almost all the benefits of nuclear power
had been lost because people did not pay
enough attention to the risks and so to
say electricity is good for you has
really nothing to do with it
and of course if it wasn't good for you
we wouldn't be building nuclear power
stations but I totally agree with
Sebastian that the the focus is not on
the way AI systems behave now we are not
building general-purpose AI systems that
can do anything but I do want to point
out something so we used to say about
six months ago or even a month ago that
you know alphago is amazing you know
pretty much from scratch it learned not
not by imitating humans actually but by
playing itself to to exceed all human
players at the game of Go which has been
played for for hundreds of thousands of
years but we always said well you know
alphago is brilliant but you know
alphago can't play chess I can't play
checkers
you know it's a very very narrow system
so don't think that it's going to take
over the world well so turned out that
the people who build alphago decided to
see if it could play chess and in two
hours
alphago learn to play chess better than
any human being as well as go as well as
Chinese chess will show thee so so I
think things are moving very very
rapidly and it is very dangerous to say
when a I can't do X and y&amp;amp;z and probably
never will those predictions have always
turned out to be false in the past
Sebastian look I completely agree as we
build new technologies invent new
technologies there will be accidents and
last I checked they are still more than
fun that nuclear power plants in
operations in the world and last I
checked despite the horrible tragic
excellent and human failure in Chernobyl
we all still benefiting from electricity
I want to point out this radio
conversation would not be possible
without electricity and I have yet to
meet people who say because the
Chernobyl we should stop using
electricity we need to see things in
balance we need to understand that every
technology has dangers and risks risk of
accidents risk of abuse but also
positive aspects and empowering things
and Stanford we recently looked into
Diagnostics medical diagnostics there's
about 10,000 Dermatology's in in the
United States they're very hard to get
by they make roughly 450,000 dollars a
year as a well-paid job and we ask the
question can we learn from those
demythologize to find deadly diseases
like skin cancer melanoma using camera
images so that we can take that same
skill into places where workers the
mythologists don't operate like Middle
East or or Africa other places and after
training in neural network and
artificial intelligence systems with
about 130,000 images we were able to
replicate the the skill of the best
Stanford board-certified dermatologists
and we already have no examples we have
clinicians have used the system in the
field and spotted melanomas
that they themselves didn't see and
intend to biopsy and found that they
themselves made a mr.
and our system were they able to spot it
and when Bastion I have to take a break
there right there we're exploring the
way forward for artificial intelligence
which really does mean the way forward
for the human race I'm ray Suarez this
is on point
up first it may be just the podcast you
didn't know you were looking for it's
the Morning News podcast from NPR you
can put it on during breakfast or while
you're commuting and you'll be caught up
for the day in just about 10 minutes
that's it
find up first on the NPR one app or
wherever you listen to podcasts this is
on point I'm ray Suarez we're hearing
the debate between two scientists in the
world of artificial intelligence and
it's not a theoretical debate anymore
about what our computers will do when
they become as they will smarter than we
are my guests are Sebastian Thrun
founding director of Stanford
University's artificial intelligence lab
and Stuart Russell founder of the Center
for human compatible artificial
intelligence at UC Berkeley Joshua's
been patiently waiting in Newport News
Virginia Joshua welcome thank you so I'm
a cyber security specialist at the
Newport News ship and I have plenty of
friends in cyber security and ethical
hackers and we talk all the time about
different vulnerabilities and threats
that new systems come through and when
it comes to the development of AI or
robots as we'll call them we actually
referenced a sci-fi movie that came out
rather recently called iRobot featuring
Will Smith the robots had a core set of
three protocols and actually to keep
order and maintain safety and the first
protocol is you shall not hurt any human
bring harm to any human second protocol
you shall obey every human's command as
long as it does not just lick the first
protocol finally the third command is
that you can protect your own systems as
long as it does not interfere with the
second or first protocol and yes in the
movie there's a cash drop event but if
that's all about sci-fi the core of the
value is that we looked in the systems
and let if you actually put that in
place all this fear can be undermined by
a simple solution on top of the idea
that there are there is of course the
everlasting effect of user errors is
that when it comes to it humans do cause
the issues and if anyone wants to hurt
something they can but if you're talking
about
systems by themselves causing mayhem you
follow the three rules of robotics that
simply won't happen Stuart Russell did
Isaac Asimov give us a good template to
begin your hoped-for code of ethics yeah
so as most laws are quite interesting he
actually designed them not to prevent
robots from from taking over the world
but actually to create interesting plots
for his stories but they are actually
quite interesting to to think about so
the the big question comes around what
do we mean by harm so it actually goes
on to say or by inaction allow a human
to come to harm and the the clear
weakness in the laws is that it doesn't
consider uncertainty so if I if I am a
household robot and my owner is about to
get in the car and drive to work
then I should prevent him from getting
in the car because there's a chance
while he's driving to work that he would
get hurt in a car crash and therefore I
shouldn't allow him to do that and you
take this to an extreme you know I
shouldn't allow him to go in the Sun
because a photon might strike his skin
and initiate a cancer which might
eventually kill him so I have to sort of
run around with a Sun Shade over him at
all times and so on so forth so the the
problem you get with that type of law is
the same sort of problem you get with
with the King Midas request to have
everything turn to gold that when you
take it literally you get these really
really catastrophic ly bad outcomes and
what I've actually been thinking about
is is how do we avoid this sort of
fundamental problem right so if you make
machines that are more intelligent than
us and intelligence is is what gives you
power over the world so we're saying we
want to make machines that are more
powerful than us but we want them to
have no power whatsoever you know that's
a good trick if you can do it and so I'm
trying to figure out how to do that
trick and the trick seems to be that
while so the first law actually needs to
be changed a bit that the machines job
is to help human beings realize their
preferences and the second law is
actually that the machines do not know
what those preferences are and this this
kind of humility is crucial because if
the Machine ever believes that it knows
exactly what the objective is then
nothing you can do will divert it from
the course of action that it has chosen
flying right in the face of Isaac
Asimov's three rules of robotics is the
video slaughter BOTS my guest Stuart
Russell commissioned the 2017 video to
illustrate the problem of weapons that
do not need human instructions to
complete their missions in this scene
someone the technologist is presenting
his new product a tiny killer drone that
reads social media to find and kill
whoever fits the description of enemy
that a human being gave it he throws the
drone out into the audience and the
drone flies back to the stage and fires
an explosive charge into the head of a
enemy mannequin just like any mobile
device these days it has cameras and
sensors and just like your phones and
social media apps it does facial
recognition inside here is three grams
of shaped explosive this is how it works
did you see that that little bag is
enough to penetrate the skull and
destroy the contents bizarrely members
of the audience applaud and you could
hear them whistling in the background
but that slaughter bot punched a hole in
a mannequins brain you can see the
complete slaughter BOTS video at our
website on point org Sebastian Thrun I'm
sure you've seen this video what do you
make of it it it's a great vocal section
honestly that technology shown there
doesn't exist but yes weapon systems do
exist and we as a country have for a
long time used drone technology to do
precision strikes in places like
Afghanistan and Iraq and those are
guided by people it's very important to
understand that for these technologies
are being recognized or cybersecurity
attacks and similar things there's
usually people behind this as bad actors
from North Korea and at state actors bad
terrorists but individuals that
corporations and what we got to do is
hold these entities accountable when
something like very like this happen
that is not to say that all technology
is evil this any technology in the eye
being no exception can certainly be
abused but if we look at the current
situation for example of cybersecurity
and I really like the first comments I
think the the real threat in the
cybersecurity world actually people its
actors what it benefits for their own
benefits abuse technology today and
ignored it has become very complex and
as a result there's many ways you can
abuse technology again you can see the
slaughter bots video at our website on
point radio org Columbia Missouri Ray
welcome to the program are you okay I
think there are two major issues here
that once you have a technology and you
unleashed that technology it has a life
of its own and you talk about bad actors
the world is full of bad actors so maybe
some thought ought to be maybe to look
at should this technology be released
and technologies that smarter than human
no no
we don't need that the next problem that
we have and this is a major one and this
is the cause of all of our other
problems overpopulation too many humans
now if you have technologies that does a
job that's dangerous to human okay but
if you have technology that replaces a
human because it's cheaper not okay we
are in knee-deep in humans and nobody
ever ever talks about our population
problem well ray just a few moments ago
we heard sebastian through and talking
about detection machines that can find
melanoma on someone's skin with a
greater accuracy than a trained
clinician isn't that a good use of our
machines and our machines being better
at something than we are well I don't
think so because you're replacing
somebody that makes a half a million
dollars a year and think we're all that
money those you got a machine you know
where does that money go
we need people doing those types of
things we need better education let's
spend our money on get it in public
education and get people that are
they're smarter than a machine
now I take your point but there are no
half-million dollar a year
dermatologists in northern Syria or
western Iraq right now and there are
probably people who need a good skin
exam to find out if they are in the
early stages of skin cancer ray from
Columbia Missouri thanks a lot for your
call Saco Maine is next
Ethan welcome to the program
my question is well first of all scary
stuff and I'm actually you know I'm
scared I think this needs to be looked
at like put up in top of the list
first reason I think is it's you guys
are talking about the benign you know
intelligence in the future but are
making them benign but right now I'm
seeing it invading lives like
specifically I'm on tinder and I've
noticed that
I get you know I get sort of bought type
things cat Fisher's ever you want to
call them and then they if you respond
to something it looks like that then the
next bio you get person you get is can
be ask you the question you know put
forth with the other person so it's like
it there it's learning and so it's it's
here and it's now I think it's it's
disturbing I guess the new normal that
the second thing I want to say is is a
on an international level this could be
very disturbing if wires get crossed
between world leaders and you your
career panel guy was talking about the
it's a lot of times malicious and
there's people behind it so could you
know it's very concerning that we get on
top of this and don't let it get out of
hand with Ethan making an interesting
point on on tinder it might be annoying
irritating even a little creepy to know
that it is a non-human intelligence
that's taking advantage of things that
it's learning from you and and messing
up your experience on a on a dating site
but there are if you project that out
Stuart Russell far more malign
applications for that same human-like
ability to converse with somebody and
probably useful ones as well that's true
I mean I as a sort of hobby I've been
arguing that we should avoid completely
humanoid AI systems at all costs meaning
ones that are physically
indistinguishable from humans the way
they are in West world and and humans
the the television series and others
because itself you know it's a form of
lying you know through our subconscious
we cannot help but interpret the human
form as a human being and to the extent
that systems pretend to be human
they are lying to us and and I don't
really like the idea that there are BOTS
on these chat sites I think every bot
should be declaring itself to be a bot
rather than pretending to be a human but
let me come back to to the two issues
that quickly raised both of which are
extremely important one is the question
of employment and I'm afraid that this
is nothing to do with AI this is
economics if we develop human-level AI
you know the value of that is comparable
to the GDP of the entire planet if not
many multiples of that so the economic
momentum the high in creating AI and
using AI to fulfill all the economic
functions is really going to be
irresistible and the question is what a
human is going to do now if you look at
the last 200 years we've had a lot of
economic growth but we've done it
largely by using humans as robots most
people in most jobs are being used as
robots and they do their best to have a
good time despite that and now we're
worried that that's going away it will
be incredibly disruptive but we have to
look forward I think to a future where
humans don't have to be robots anymore
and we need to reorganize our education
system and the way we think about our
economy so that the things that humans
will be doing which is mostly working to
improve each other's lives directly are
actually remunerated that people are
skilled and trained in doing that that
their credential eyes their professional
well that that perfectly teased up
Sebastian because he's been trying to
develop driverless cars and one of the
largest single occupations for men in
the United States is driver so we're
going to have to deal with the the
downstream effects of of your advances
Sebastian when I also started a company
called Udacity very taut now almost 10
million people tech skills and people
that come to us and learn with
University find jobs in places like
Silicon Valley I think the way in these
things is the way forward honestly if
you could relieve people of the
necessity to drive trucks and they could
drive trucks from the living room and
have the same income I think the world
would be a better place if in the last
hundreds of years we invented technology
like a running water what a soilless
penicillin
electricity thinks that we've come to
rely on I challenge anybody who
questions the principle of progress who
go back mentally to the time four
hundred years ago when all of us were
farmers and asked the question is that
the life you wish to live today that's
that I get well back back when most
people on the planet were farmers they
were also living to about 40 years old
as well and I'm correct we probably
don't want to go back to that world
either correctly I think it's also worth
saying about 70% of employed people in
Africa work in farming today and ask
yourself the question is that the life
you want to live because by making
baitin by making us superhumans by
giving us superhuman power when we prowl
feels good superhuman voice in the user
cell phone we've basically empowered
ourselves to be free from very simple
repetitive work and there is progress
that I personally cherish I love my job
well I'm gonna have to stop it there
only because now not because we've
settled anything but because the tyranny
of the clock is making us come this come
to a close Sebastian Thrun is founding
director of Stanford University's
artificial intelligence lab he joined us
from Palo Alto Sebastian thanks for your
time Stuart Russell is founder of the
center for human compatible artificial
intelligence that UC Berkeley he joined
me from Paris
Stuart good to talk to you thank you a
good night and you can continue the
conversation and get the on point
podcast at our website OnPoint Radio org
and follow us on Twitter and find us on
Facebook at OnPoint radio coming up
tomorrow</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>