<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Max &amp; Meia Tegmark - What We Should Want: Physics and Psychology Perspectives | Coder Coacher - Coaching Coders</title><meta content="Max &amp; Meia Tegmark - What We Should Want: Physics and Psychology Perspectives - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Max &amp; Meia Tegmark - What We Should Want: Physics and Psychology Perspectives</b></h2><h5 class="post__date">2017-09-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yWq78lXzG_A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">great well for our next talk we have a
double act
mayor kita tegmark works in psychology
at Boston University and max tegmark
works in physics and cosmology
at MIT they both have extremely broad
interests but one of the subjects around
which their interests converge is this
topic of the future of artificial
intelligence they've both been central
and the future of life Institute which
has just been founded over the last
couple of years and has already become a
really major force in the field today
they're going to talk about what we
should want physics and psychology
perspectives please welcome man max it's
a pleasure in an honor for as opposed to
be here and we were encouraged by David
those of us who work in fields other
than AI to step forward and see what we
can bring to the table to help with all
these fascinating questions that are
being discussed here so we're gonna
bring perspectives from physics and
title here I will just ask you how do
you feel about this so back to physics
what can physics do for you you know we
can give you tools that can help
understand some of the interesting
questions that we're discussing here
like what are the ultimate limits on
computation on intelligence the ultimate
limits on the future of life the options
we have for ultimate goals that we just
heard about from Stewart and from
Eliezer here for psychology we can offer
you tools for understanding human
well-being
for debugging your minds and your
thinking and hopefully for for designing
or at least inspiring psycho morphic AI
systems and I use the word psycho
morphic here as a parallel to
neuromorphic I mean actually
constructing psychological features and
artificial systems not just projecting
them onto
systems now often when I hear my AI
friends discuss what we should want what
sort of future we want and on the
timescale of centuries or millennia they
get scoffed on my other app by other
people that's science fiction talk about
distant horizons like a hundred years or
a thousand years as a cosmologists I
find this just hilarious no because for
us talking about a billion years into
the future isn't science fiction it's
science it's the mainstream we do all
the time we have a very good idea what
happened in the last 13.8 billion years
and I can tell you with great confidence
a lot about what's gonna happen in the
next billion that sort of frames this I
can tell you as a physicist for example
that if we don't improve our technology
where we the question isn't if we're
gonna go extinct question is just are we
gonna get taken out first by a
supervolcano or an asteroid impact or
are we gonna get taken out by the Sun
eventually evaporating all our oceans in
a billion years so see if you take a
physics perspective you really learn to
love technology and the good news is
that with technology if you I can tell
you about in the Q&amp;amp;A how we can solve
all of these problems and really help
life flourish for billions of years
if we don't wipe ourselves out first so
physics has a very optimist optimistic
message to bring to this conference
which is first of all the technology can
very much be our friend and we also have
this vastly greater potential for the
future of life than we thought we had we
don't just have hundreds of years left
to go but billions and not just here on
earth but also throughout the cosmos
we have over one we have hundreds of
billions of solar systems in our galaxy
hundreds of billions of other galaxies
amazing things we can do create
resources and opportunities and physics
can also give a great deal of optimism
about the future of intelligence because
I know as a physicist that this brain is
simply a quark blob arranged in such a
way that the processes and information
and certain sophisticated ways and there
is absolutely nothing in the laws of
physics that you saying you can't make
quark blobs that are much smarter than
this quark blob and if you in case
you're worried that Moore's law is about
to fizzle out because you read that in a
British tabloid or whatever
physics has good news here too that we
have actually this nice work by Seth
Lloyd showing what the ultimate limits
from physics are on a computation and we
are thirty three orders of magnitude
away from that so we can do a lot better
than we can do yet to another source of
optimism is don't feel insignificant all
right we've during the first 13.8
billion years of life viewed life is
just a minor perturbation on an
otherwise lifeless cosmos right but if
you look at this planet it's clear that
life is having a more and more dramatic
impact of what Manhattan looks like
right even though in the cosmic scale so
far we're still just a perturbation what
physics tells us is that if intelligence
keeps developing it's it's very likely
that our entire cosmos will also
transform where life goes from just
being a little minor perturbation to
really a dominating driving force a lot
of great opportunities here the bad news
is that physics cannot tell us which of
these opportunities we should actually
want what's actually gonna make us happy
and make us feel well-being in the
future so for that we instead need to
turn back to psychology our
psychologists we're much cooler we have
a very clear answer to what you should
want
unlike physicists and what you should
want you should want happiness and you
should want well-being if you don't
desire wellbeing for yourself or for
your fellow human beings see me after
the talk for a diagnosis so I was very
fortunate to be here at another for
another conference on the future of AI
organized by Jung McCune and one of my
thinker heroes who's right here Daniel
Kahneman asked a very important question
namely will AI make you happy and I was
very surprised to see how difficult it
was for people to engage with this
question so if we turn to psychology and
try to understand a little bit about
what well-being is for human for humans
is supposed to be we have different
psychological theories this is one of
them this is one of the more popular one
once and if we look at this theory for
example human well-being has three
components you should leave a lead a
pleasant
I for life of enjoyment you should lead
a good life life of engagement and a
meaningful life feeling affiliation to
your fellow human beings you feel
meaning and purpose and also
accomplishments now it's easy to
speculate how AI can impact all of these
in the future but we can do better
actually we can not just speculate but
actually test some of some hypotheses
that we have in psychology so for
example if we look at the good life at
the life of engagement and take it as a
key study for how AI might impact it one
worry that is talked about a lot is how
automation might might impact the good
life that the life of engagement where
you you feel you know your own self
efficiency in the world so what does
psychology have to say about this let's
see what psychology has to say about the
possible perturbation of the job market
so job loss psychology says that
unemployment can produce negative
long-term effects on well-being even
reemployment can produce negative
effects on well-being and that not even
considering the fact that you need to
switch to a different field to a
different kind of job even retirement
has mixed effects on well-being both
positive and negative but I you know you
can argue well does this really say
anything about AI arm or more about the
way we have our societies constructed so
let's look a little bit about what
matters so if we try to ask
psychologists what do they what do they
find about what really matters what
drives this well-being we see that
financial satisfaction is one of the
strongest predictors of life evaluation
respects being a strongest predictor of
positive feeling so if we could in a way
make sure that the financial needs of
people are being satisfied for example
by having some basic income and that
they can be engaged in some activities
that gain them the respect of other
people's then maybe we can we can
actually reap the benefits of having AI
that will probably make our jobs much
more interesting and will eliminate all
the drudgery and in tasks that can be
easily automated we can go even more
in-depth there are lots of other groups
to study we can
study part-time workers maybe we should
just simply work less we can study
homemakers maybe we should just focus on
our relationships raising our kids
instead of work we can focus on people
who retire early and so on and try to
get useful insights on how how how we
should design a society that's very
welcoming of AI and uses it for good we
can also study different constructs
psychological constructs such as self
efficiency drudgery play and so on to
gain all these important information for
how to make AI most beneficial for us
various ways in which AI can make us
more happy or less happy and create a
better future or worst future and
there's a fascinating spectrum of
opinions about what will actually happen
if we get AI much better particularly to
the human level it's a particular honor
for me to show this plot which i partly
plagiarize from wait but why not calm
since we have the Creator wait but why
not come here in the audience and this
is not the only access to where there is
a fascinating disagreement paestum ends
versus optimism there is also a very
interesting disagreement about the
timeline of things will we get human
level III
within a century or so or is that very
very unlikely both of these I think most
of them are serious researchers and
thinkers I know fall into these three
categories in the upper right here and I
respect all three of these viewpoints
any of them might be right this is a
very very legitimate topic that we
should discuss more and that we should
also discuss a lot more of course all
the fascinating technical challenges
that come with any of those three views
such as what we heard about from Stuart
Russell and eleazar this morning for
example so to really be able to focus on
these legitimate questions it's very
important that we don't get distracted
by illegitimate questions silly myths
and confusions such as what Stuart
Russell brought up this this morning
since he didn't have time to talk about
oh let me see if I can just put them my
top seven ones or so on together on this
one page here first there's this this
myth
that we know for sure the timeline
where's if you actually go ask the
expert this is a poll we did at the
puerto rico meeting last year the
conclusion is obvious we simply don't
know when we're gonna get human level
either a lot of very smart researchers
are think it's never gonna happen or
take hundreds of years there's a lot of
really smart ones who think maybe we'll
get there in decades so the conclusion
is obvious just start preparing now in
case this happens so we can make the
best of it
another very persistent myth is that the
only people who worry about these things
are Luddites well I have news for you
Stuart Russell and all the other AI
experts in this room who do worry about
these things are not alone is another
but persistent myth has to do with what
it is that the Warriors worried about
it's simply not the case that what's do
what Russell and others are really
worried about is that AI is gonna turn
evil or turn conscious the concern is
simply not malice the competence if we
have if I'm for example in charge of
this awesome green energy project which
is gonna create a hydroelectric plant
power plant then it's gonna be great and
there's a little ant hill in the middle
you know I actually like ants I go out
of my way on the sidewalk outside here
if I see one to not step on it but in
this case you know tough luck for the
ants it's not that I'm an evil anteater
it's just that my goals weren't quite
aligned well the ants and I'm gonna turn
on the water and we just want to make
sure we don't place humanity in the
position of those ants that's what the
concern is another persistent myth is
the thing we should worry about is
robots and the truth of course is that
the concern is not robots it's simply
the intelligence if you have some very
superior intelligence it doesn't need a
robot to have a lot of impact it just
needs an internet connection
yet another myth is that somehow
machines can't control humans well the
reason we can control time tigers isn't
because we have sharper claws or
stronger muscles it's just because we're
smarter than them
yet another myth is that machines cannot
have gold now what I mean by gold the
thing we're concerned about isn't some
sort of touchy-feely definition of
Gold's we're just concerned about
exhibiting goal-oriented behavior and
that machine's can absolutely do you
know if you're chased by a heat-seeking
missile you're probably not gonna say to
yourself I'm not worried about this
because that missile doesn't have goals
and just elaborate on this a little bit
more Stewart Russell brought up this
very important point of and so did
Eliezer about emergent goals pretty much
whatever go will you actually have
initially which could be as silly as
just maximizing your score in this
little computer game I made up here we
were trying to save a sheep and bring
them in from the bad bad wolf and get it
into the air safe area here will give
you certain other sub goals first of all
you realize pretty quickly would be that
you don't want to go through here and
blow up because if you're a dead robot
you know I didn't get any more points
and say no more sheep so you get
self-preservation instinct pretty much
whatever your goal is against evil
mohandro is the first person to have
brought this up you also get a goal of
improving your world model because if
you find when you start learning more
about your world you realize there's a
shortcut here just great you also tend
to get an emergent all getting more
resources like why not get this little
potion here that lets you run twice as
fast why not pick up this gun here so
you can shoot the wolf and save all the
sheep you know so the bottom line is
pretty much whatever goal you start with
if it's really ambitious it will give
you the sub goal of keeping those goals
enhancing your capabilities get better
hardware software and preserve yourself
get curious lots of other things okay
which may if we haven't thought this
through carefully clash with a human
goals and give give Gil goal
misalignment finally people who worried
about this
all worried because they're persuaded
that super juice is just it's gonna
happen next week and what we should all
do right now is panic when of course the
fact is all people are saying is well if
there's a non-negligent negligible
chance it might happen in this century
hey now will be pretty good
to start planning ahead and and
preparing okay now these are a bunch of
myths that we've identified and kind of
understood but it's important to ask not
just about them but why did we make
these logical mistakes what bugs in our
thinking led to these myths because if
we can understand that that can help us
also understand other bugs in our
thinking we haven't yet identify it in
the context of a future AI so with that
let's turn over to our debugger
psychology so psychology doesn't just
offer us ways of testing hypotheses
about our own well-being but that we can
you know try to apply both in the near
term future for example as I give the
example of job markets but also in the
longer term future when we deal with
this unease of being outsmarted by other
entities but it can also give us some
tools for for debugging our own thinking
and max likes to say this a lot that in
order to create a good future we need to
win the race between the growing power
of technology and the wisdom with which
we manage it so I feel that psychology
has something to say about wisdom and
this agrees with the old Greek advice
know thyself mainly be aware of your own
cognitive biases and Daniel Kahneman has
done amazing research trying to map out
all these cognitive biases if we go back
to the belief commonly commonly held
beliefs about AI that max has explored
for example this idea that it might be
inevitable or impossible here is a
cognitive bias for you to consider maybe
you are just having a confirmation bias
you are searching interpreting favoring
and remembering information in a way
that already confirms your your own
pre-existing belief another commonly
held belief especially in the general
public is that robots are the main
concern maybe people should worry a
little bit about the availability bias
and namely that you're overestimated the
overestimating the likelihood of events
happening maybe because of all those
Hollywood blockbusters that you've seen
or simply
because of the cognitive strength that
you know it takes to under to really
imagine a disembodied intelligence so
coming back here to the question of what
we should want and ultimate goals and so
on yet another thing that physics brings
to the table is a little word of caution
that more work is needed here
we heard particularly eliezer talk here
about how things get harder when you
start thinking really long term about
open-ended goal is because most a eye
problems are not like that
traditionally it's like okay goal win
this chess game goal drive the
self-driving car that from A to B safely
yeah we know how to handle that but a
lot of famous papers and even Nick
Bostrom's book talks about the idea of
final goals so much more long-term the
ultimate goal of the mission of the
super intelligence AI might have and
here as a physicist big warning flags go
off you know what do we mean by the
final goal for our universe do we mean
that we have a function that specifies
exactly the best way to arrange all our
particles that's the goal okay suppose
we managed to accomplish that now what
you know time doesn't end at least that
last time I was doing physics research
there's no indication of that so since
there's things are gonna keep happening
the whole question of final goals really
deserves a lot more research to make
sure we're not just chasing after a
mirage here and moreover we know a few
things about the ultimate fate of our
cosmos we think entropy keeps increasing
and it seemed like ultimately whatever
we do will be some kind of cosmic heat
death which will be kind of a bummer so
I think the real key message here from
physics is really it's not the
destination it's the journey so going
back to the journey and to see what
psychology has to say about this journey
and how to make it happy we've heard
yesterday a very beautifully articulated
vision for the future of human and I an
AI collaboration that was expressed by
Jessica Rossi so I think that you know
if we envisioned and if we work towards
a future where AI systems will be our
companions our collaborators maybe maybe
even our descendants then something that
we will probably want is to put in them
cognitions and behaviors that we are
most proud of and the good news from
psychology is that so for example one
one very good one very good cognitive
and behavioral mechanism is altruism
right we might want to have that in our
companion robots in our collaborator AI
systems so the good news from psychology
is that ultras exist and even extreme
ultra exist and not just as an idea in
our heads but actually in actual real
people and this is an existence proof
that there is it is possible to have
intelligent entities that are even more
altruistic than most people and we'll
hear from the next speaker how you know
super intelligent might be even
construed as super ethical and the even
better news is that psychology is now
making a lot of progress trying to
understand really the cognitive
mechanisms behind extreme altruism and I
won't go into details now in the
interest of time but I'd be happy to get
questions about this this amazing paper
that came out two years ago so to wrap
this things up
I hope that Max and I have convinced you
that there are some very useful tools
both from physics and from psychology in
terms of considering what we want and I
hope we all use them what we meet with
the proverbial genie so that you know we
ask for the right things and don't have
to put them back in the bottle
hi my question is how can we prevent
religion mingling too much into AI so in
the future we don't have AI who probably
hates people who masturbate or it's
people who are example yeah this is a
very interesting question which i think
is part of the broader question about
when we say we want to make sure that
the future AI is aligned with our values
whose values we're talking about my
values
Isis's values some do random dude in the
Middle Ages as values you know so I
think the real message here is first of
all of course this is a very important
open question and second this shows that
to really make the best of AI it's not
enough to just have technical research
among AI scientists right we ought we
really need to get psychologists
sociologists philosophers and also and
really the whole human community looking
into these questions because this is an
answer that everybody has to come
together and really pursue a college II
for example in and when we define
psychopathology we really define it it
boils down not to values it actually
boils down to how well you are able to
cooperate and in a human society so I
think that one thing that we might want
to make sure that the AI systems that we
create have is is this ability to really
cooperate well with us now you know
human beings have not been so good at
cooperating with other species so
actually we don't know what what is
going to happen but that's one goal and
one vision that means we should and just
very briefly one other very interesting
point which Francesca Tosi mentioned
yesterday is that in the short term
even belong before we figured out what
we ultimately want it makes a lot of
sense to put in at least some
kindergarten ethics that we can all
agree on into the systems we build like
airplanes should never under any
circumstances if they have any kind of
AI in them fly into a building or a
flying into a mountain like when under
guess Lubitz the Germanwings probably
told it to do that right already putting
in some basic minimal ethics into the
machines it's gonna be a big step up
from where we are now we shouldn't let
perfect be the enemy of the good
insofar as some undesirable behaviors
might actually be beneficial towards
goals for example in rationality
sometimes people talk about how maybe
you're procrastinating because the thing
that you're going to do shouldn't
actually be done maybe you should be
focusing at something else and that's
why you end up procrastinating because
you should be doing the thing or in or
just vaguely if some undesirable
behaviors are equilibria in really
subtle ways do you think that in terms
of like embedding psychological
mechanisms in AI do you think that it
can be problematic to only embed
beneficial obviously beneficial
behaviors and psychological mechanisms
that is a very good question personally
I feel a little bit more pessimistic
honestly about our ability to really
create psycho morphic AI systems and the
reason for that is that I feel you know
evolution has at a very very long time
to try all sorts of solutions and I feel
that you know in the spirit of what
Stephen Wolfram was talking about
yesterday we might actually stumble upon
solutions for behaviors you know that
don't go through the same routes of our
own cognitions and feelings so I think
you know it's a it they will be inspired
by our psychology and then that that's
in that way you know they will they will
have both some of our that we would want
for them to have some of our beneficial
you know behaviors but in terms of you
know the cognitions and the
justifications of those behaviors in the
grander you know scheme of the AI psyche
so to talk
it's it's hard to imagine what that
architecture would be like I mean we
don't know yet so much about our own
psychology that I think there are huge
technical issues even in just specifying
how is it that we behave in the way that
we behave or have the cognitions that we
we have but it's it's an interesting
question like are we able to create will
we be able to create sort of the ideal
you know behavioral and cognitive entity
or not Thanks
and one of the slides you had a rocket
and you said that rocket has a goal
which I mean it all boils down to
definitions but what kind of what was
the definite what would be like a
definition of the goal of the rocket and
the real question is what's the
difference between the Rockets goal and
a human goal versus an AI go I guess I
have to bring word consciousness up like
your conscious goal versus just a
physical and material you know find the
lowest energy state sort of goal so how
do you think that comes about like this
conscious goal versus these excellent
questions so let me answer that when if
we care about how the machines feel and
if we're being cruel to them and whether
there's mind crime like Nick Bostrom
said and so and then we care a lot about
consciousness and and all the subjective
issues but if we keep from if we care
about us what's gonna happen to us it
simply doesn't matter at all whether the
machine has a subjective experience in
the spirit of David Chalmers is a hard
problem it just matters what it does
okay so if we look at the behavior of
machines then we can make a very clear
definition of what we mean by it having
goals we can ask is the behavior of the
machine best explained cause through
causality that this caused this process
or is it more economical explained
Keeley logically so saying this
heat-seeking missile is simply acting as
if it's trying to hit my airplane and we
have a lot of examples where machines I
at most economically describe like the
ladder and whenever that happens I think
it's reasonable to say they're showing
goal-oriented behavior that's what I
mean by having goals and if the machine
has its goal in that sense you know to
do something that we don't want it to do
it's a problem so I think the message is
very clear in the sense that matters
that we it could cause us to have
concern yes machines can have calls he's
trying to encourage you to be a hardcore
behaviorist basically but I and your
David Chalmers can testify to this I
think the question of conscious is
actually fascinating and I'm spending a
lot of my research so actually that
might ease we're studying it but that
does not change the fact that completely
aside from that machines can exhibit
goal-oriented behavior and we want to
make sure it's that behaviors where you
want okay well we're basically going to
power on through there's not a there's
not a coffee break but well Wendell sets
up feel free to take a minute or so to
stretch in place mini break we figure
people start leaving this place we'll
never get them back in</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>