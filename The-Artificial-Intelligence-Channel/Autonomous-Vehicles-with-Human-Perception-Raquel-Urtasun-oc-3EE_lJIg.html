<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Autonomous Vehicles with Human Perception - Raquel Urtasun | Coder Coacher - Coaching Coders</title><meta content="Autonomous Vehicles with Human Perception - Raquel Urtasun - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Autonomous Vehicles with Human Perception - Raquel Urtasun</b></h2><h5 class="post__date">2017-10-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oc-3EE_lJIg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks for this amazing introduction now
I have to keep two that I'm not sure I
will be able to do that great so it's my
pleasure here to be TV today and I
wanted to years I guess introduce Who I
am just in case you guys don't know so I
have three jobs which keeps me quite
busy I am still an academic one day a
week I am in the University of Toronto
and the vector Institute which i
co-founded a whole bunch of the people
that you see in the picture including
Geoff Hinton and the latest greatest
news I guess as of May 1st I'm also
heading a new lab of uber etg in Toronto
so cell driving cars are in Canada now
and that's really really exciting so
today I'm gonna talk about what led to
the uber acquisition but not what
happens after May first okay so bear in
mind that so I guess perhaps you have
already seen in a little discussion
about why we need a cell driving cars
but what is very important for me is
actually that I mean we need to lower
the risk of accidents but we need to
provide mobility for you know many
people that right now cannot you know go
to the place they want to go and we need
to think of the future of public
transportation or right Sharon right and
in particular we need to share resources
and this is really the picture of our
cars and that's shouldn't me like that
right 95 percent of the time the car is
park right so we are yes you know
utilizing our planet without you know
real reason so if we look at typically
what is done in a driving car companies
see the stock is typically based on
things that came out of the DARPA
challenge and the systems are pretty
good at localization but planning
obstacle avoidance and there is two
things that they do which actually made
them not super scalable the first thing
is to use the leader right or the prices
are dropping it's still quite expensive
right to buy you know listen later and
the other thing which is the beast in
the closet is actually mapping right so
yes some of the u.s. estimate it was
gonna take two billion dollars right so
that you know we can scale to you you
say all over markets were yeah so what
I've been working on for the past seven
years in
how to make solutions that are scalable
meaning that chip sensors and try to
drive without maps or without the litter
prior knowledge as possible now if we
want to do something of this form we
need to think about many different
things at once the first thing that as
an academic was difficult was actually
data and so we created many years ago I
guess they still the only benchmark for
self-driving and computer vision which
is kitty and to my despair it's still
the only benchmark which I don't
understand the other thing that is
important is learning right so we can
just handcraft everything because you
know we need to be robust to scenarios
that we have never seen before
we need holistic models that reason
about many things at the end of the day
we have fixed computation for many
things many tasks and we need to think
of Hardware at the same time all right
so so if we want to get rid of the later
get rid of the maps what are the things
that we need to do so everything I'm
gonna show you today is mostly deep
learning ok so I don't need to say that
but this is typically what you can do
and with deep learning and basically you
have robust good and fast stereo
reconstruction this can run real time
and after 40 meters can basically almost
replace the later other things that you
need to do is you need to do perception
so you spend the past you're gonna have
obsessed with instant segmentation is
what you're seeing here in the image so
the idea is you have a single image you
are interested in labeling every pixel
but not just with the category of Sircar
broad but also you want to estimate this
is one car this is another car etc and
this is a particularly difficult problem
for deep learning because the loss
function is agnostic to permutation so
we build some interesting technology
lately based on the what the shell
transpose actually scales really well
it's independent of the number of
objects so you can run real time for
anything and this is strong
generalization is trained in a set of
cities and tested in a in another set of
cities you see the prediction in the
middle and the ground truth on the right
okay so even with gravity scenes can
actually do pretty well now if you wanna
do so driving yes level in pixels is no
they're right so you need to really
esteem in what's happening in everything
everywhere in the scene this is our
latest greatest results this is joint
detection and tracking so this is
actually quite technically very
interesting you can bug propagate
through solvers and here you see the
results of what we have as well and in
general what you want to do is estimate
everything that is in the scene so here
are some results that we had like even a
couple of years ago with yes having a
single camera mounted on top of the car
the car is driving in intersections he
has never seen before and it's able to
estimate the local map of the
intersection so speeding them up on the
fly is estimating where the your car is
so it's doing localization as well as
estimating with every car is in the
scene and a traffic situation that you
see on the bottom left even though it
doesn't see traffic scene also things
like that so the cars are color-coded in
by their intention so basically here we
are estimated where everybody is going
what is it gonna be going in the next
couple of seconds and this is as I said
single camera news and Argosy that you
know we have been trained on other
things that you need to do is actually
localization
so localization is an interesting
program because typically the way it's
done is that saywe models it is that you
go around and then you collect how the
world looks like and that's really
expensive meaning that what it means is
that basically you need to know the
appearance of the world at every point
in time right so here what we look at is
yes values in OpenStreetMaps which is
this cartographic mobile environment and
the weak in the emotion of the vehicle
we can estimate really quickly where the
vehicle is in the you know in the global
coordinate system okay so you seek here
so you have a property distribution over
the graph of the road you know the
bigger it starts driving you have a few
miles of the distribution and very
quickly right we know exactly where this
vehicle is right so this is a Manhattan
like scenario so there is - most of the
distribution but again soon we're gonna
do something where there is only a
single location and this for the whole
city of culture which is 2,000
kilometers of road it takes 35 seconds
of driving to actually localize with
precision of two meters
which is the precision of the maps that
we use these maps are same they're
available for free online for 60% of the
world so you can just download you don't
need to capture anything it's free now
in terms of mapping right so why why do
car companies or you know cetera Inc our
players use maps you can think of a map
assistance as a sensor which basically
tells you the static part of the scene
right so it gives you robustness and it
allows you to only look at the dynamic
objects so the problem of the way that
mapping is done is that you have say one
of these cars right with this expensive
sensors and basically you drive around
the world you capture data and then
there is some labeling process where you
basically say okay what are the roads
where are the and the lanes where are
the possible places where you can park
etc okay
so that makes you know you have very
small coverage because it's at the
vehicle level and it's very expensive
right and as an academic I look at can
we actually do this by you know spending
zero dollars okay and so it turns out
that you can use aerial images or
satellite images satellites pass around
the earth twice a day so you have this
up-to-date view of the world and we
create methods that can automatically
extract the HD maps of the form that you
see on the top where you have lanes
parking spoiled sidewalks etc yes
automatically and it takes only three
seconds in a single computer to get
Twista made it's per kilometer of road
okay so basically with a very small
cluster of say ten computers you can run
the whole world okay have you know
up-to-date estimates and one of the
things that you know long time ago I
created Kitty right that that was I
guess five years ago or something like
that and one thing that bugged me about
mapping is that it's only the players
the companies that are actually working
on this so I created Toronto City and
this is about to go online soon where
basically we have for the Greater
Toronto Area all possible views of the
city so the GTA the Greater Toronto Area
is 20% of the population of Canada it's
huge okay and we have all these
different views opener
later cameras from aerial use drones etc
now as an academic I cannot label I
cannot pay labels to route to label all
this right yes for the aerial images is
gonna cross between you know twenty to
thirty million dollars to label that
okay so what I did is I went to the
government and I got all this
information from maps that the goal
would have captured there are 3d maps of
of the city every single building etc
and then basically we develop algorithms
that can align all the sources of
information including the all the
different sources of imagery as well as
the maps and can create automatically
grant truth and here you see the quality
of the grant through this really really
good ok so so it's a consequence now we
have you know grant through it for the
whole Greater Toronto Area and we're
gonna put online the benchmark very soon
so these are the tasks that you can
participate between instant segmentation
with semantic segmentation doing all the
stuff other things that we have built
since then is us a bill you know
deployment techniques to actually be
able to extract this Maps automatically
and this way you are seeing here for I
guess maybe you started somehow yeah you
can see from aerial images and one other
thing that was interesting is from
panoramas you can actually get
automatically centimeter accurate maps
that was actually quite interesting
alright so yes to conclude I've shown
you a couple of things that my group has
is building in the last seven years on
how to make a photo were selling cars at
scale with sensing perception
localization and mapping and the next
week big match mark and there is so many
things to do and you know I hope to you
know start a new episode of my life I
guess at uber and building really thinks
at the scale and whoever is interested
in joining you know please come and talk
to me thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>