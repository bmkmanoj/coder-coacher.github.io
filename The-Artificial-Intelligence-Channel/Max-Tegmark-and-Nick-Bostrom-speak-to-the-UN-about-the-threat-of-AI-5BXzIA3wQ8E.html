<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Max Tegmark and Nick Bostrom speak to the UN about the threat of AI | Coder Coacher - Coaching Coders</title><meta content="Max Tegmark and Nick Bostrom speak to the UN about the threat of AI - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/The-Artificial-Intelligence-Channel/">The Artificial Intelligence Channel</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Max Tegmark and Nick Bostrom speak to the UN about the threat of AI</b></h2><h5 class="post__date">2017-08-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5BXzIA3wQ8E" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Doce very briefly another remark with
what our colleague from Benin mentioned
indeed you are you may be just starting
now but some 25 years ago my country was
that they at the same stage when we were
just starting everything from the
scratch and that applied not only just
to CBRN but to many other many other
issues and one of the ideas why
Philippines Morocco and Georgia
conceived that thought to have a group
of friends is also to enhance that sort
of an exchange of thoughts and even
bilateral contacts and exchange of
expertise which we on bilateral level
have done as a matter of fact with with
many countries so that could be another
avenue for us together with European
Union of course and uniquely to to work
on now let me let me give you a very
interesting segment where we have
private sector and hopefully you will
enlighten us whether we should be more
cautious and afraid of what is coming or
we should feel more secure Iraq Lee
please I'm excited to moderate this
session when we are moving to this next
session which will deal with the
technological advancements and the
evolving nature of the CBRN security now
I will make some introductory remarks
and then I will introduce my speakers we
are actually making a history right now
it's the first time in the history of
the United Nations General Assembly that
the issue of artificial intelligence
will be addressed even in an informal
setting during this side event but
that's that's extremely important to
break that eyes and to bring these
issues on more on a mainstream level
today we have some very interesting
speakers here and they are representing
all different segments of stakeholders
we have world leading thinkers we have
representatives of academia we have
international organizations and plus a
private sector as well and we are
particularly pleased to have Sigma
security solutions with US private
sector we believe that involve
of them it's extremely crucial in
shaping the future of international
security
now as the director of uniquely has
rightly pointed out CBN threat is
absolutely far from being static and
it's changing and therefore it's of
paramount importance to keep up with all
the challenges that arises in the
implementation of the international
mechanisms dealing with disappearance
security you will all agree with me that
with the recent explosions in
technological capabilities comes out of
the greatest opportunities for
enhancement that global community has
experienced but at the same time in
parallel is the increased increased
threat there arises which arises from
such a rapid advancements now in the
realm of CBRN security it is by no means
disassociated from technology you will
all agree that traditional threats to
the sibilance security take on and
completely new dimension with artificial
intelligence and autonomous systems
augmenting basing criminal capabilities
right so with therefore it uniquely
started to look at the current
technological capabilities and how
artificial intelligence and robotics
might be used by terrorist organizations
or non-state actors as delivery systems
for chemical biological radiological or
nuclear materials in fact we already
have started working with number of
international organizations to explore
some potentials we started to work with
OPCW on these issues we started to work
with unity with the Organization for
Security and Cooperation in Europe and
other international organizations on
running information courses on security
implications of artificial intelligence
and autonomous robotics these are aimed
at bringing together key stakeholders
and state-level decision-makers in
addition and this is also very important
we are acknowledging the critical role
played by medium in the disseminating
information therefore we are building on
our existing uniquely master class
program that exists in other areas of
our work to run training courses for
journalists and other professionals
facilitating contact with academics and
practitioners
and in fact at the beginning of next
year we will be holding such a master
class in The Hague in the Netherlands
together with Klingon the Institute of
International Relations and this master
class will be purely dealing with the
issues of security implications of
artificial intelligence and autonomous
robotics and I'm very much hoping of
cooperating with some of you from here
so our panel today represents a
miniature version of our uniquely
approach which has taken aim at
contributing to ensuring response
responsible technological development
what we as the UN entity strive to
create is a multi-stakeholder a
stakeholder platform for cooperation and
that's sort of a version of stakeholders
what we have today representing here of
course the security implications of
artificial intelligence and machine
autonomy goes far beyond the CBRN
environment and extends further through
almost every facet of our of
civilization so now I'm going to stop
here and with this short introduction I
will start introducing our speakers who
will shed light on what's happening
what's happening now what is going to
happen in the future and what are all
the implications first I'm introducing
and we're absolutely it's our pleasure
and we are honored to have you max here
max tegmark who is a who's a physics
professor at Massachusetts Institute of
Technology and the scientific director
of fundamental questions Institute he's
also a president of the future of life
Institute and which recently launched a
7 million research program for keeping
artificial intelligence beneficial now
with more than 200 technical papers mr.
tegmark has featured in dozens of
science science documentaries his work
with the sdss collaboration on galaxy
clustering shared the first prize in
science magazines breakthrough of the
year 2003 marks please tell us how
current technological developments are
alter the balance of society security
and beyond
so thank you so much dear lackeys thank
you so much Georgia I'm so honored to be
invited to this and I'm delighted that
you're organizing this I also want to
thank you Anna Cree European Union and
everybody else who's made this possible
we just heard about what our
organization the future life Institute
is perhaps best known for so far this
seven million dollar research program
that we've just launched but before
delving into details about that let me
take you step back and say a few words
about technology in general our
organization consists of a lot of
thinkers who love technology but who as
Cindy Smith very very eloquently put it
here earlier feel that technology is
something that both can empower and do
fantastic good in the world and at the
same time gives us new power to screw up
an even grander ways than before so we
feel we want to do everything we can now
to make sure the technology gets used
for good if we look at not very powerful
technological inventions like fire for
instance we use the strategy of learning
from mistakes we spewed up a bunch of
times and then we vented the fire
extinguisher but with more powerful
technologies nuclear weapons and Petach
biology artificial intelligence etcetera
we don't want to learn from mistakes we
want to get things right the first time
because that might be the only time that
we have right and the way I think about
this is to create a great future for
Humanity we want to win this race this
race between the growing power of
Technology and the growing wisdom with
which we manage the technology by
investing more in this wisdom we're
gonna hear more in this session from
Pierre and Daniel and Nick about nuclear
and bio and an AI but let me start by
talking just a little bit about nuclear
weapons because even though I want to
end up with talking about AI I feel that
while we celebrate our successes here in
the National Action Plans and in CBM
it's a very important at the same time
highlight our failure so far to learn
from them when we take on new more
powerful technologies so we don't repeat
past mistakes and I think that nuclear
weapons is a great case study of enact
inadequate risk management why do I say
inadequate since we still haven't had a
global nuclear war well let me just ask
you this question which one of these two
people is more famous and let me ask you
a follow-up question which one of these
two people should we thank for us all
being alive here today because he
single-handedly stopped the Soviet
nuclear attack during the Cuban Missile
Crisis I'll give you just one hint he
wasn't Canadian so that already says
something about how little attention we
as a species pay sometimes really
important issues and moreover I would
say the lesson that we should draw from
this is that that you know relying on
luck there's a really poor long-term
strategy the issue with let's see the
arkhipov with just one out of a
hair-raising the long string of near
misses with global thermonuclear war and
although we've mostly focused so far
about nuclear threats from terrorism and
crime we must remember that there have
been also a lot of close calls or we
almost had an all-out nuclear war
between superpowers and even if the
chances as low as 2% per year that that
happens by mistake you know the
probability that we're gonna screw up
and within centuries is virtually a
hundred percent so you would love you
need to do better than just hope for
luck in the long term if you play
Russian roulette long enough we all know
how it ends the second lesson I think we
can learn from from the nuclear case
study here is that it's really important
to understand risks in advance before
you fully build out the technology and I
feel that we epically failed with
nuclear weapons here I feel personally
guilty about this because I'm a physics
professor I feel this was our fault
partly as physicists so let's look at
the quickly of the fact when nuclear
weapons were first built them the
decision makers in scientists generally
thought that the worst the main risk was
would literally get blown up by it and
people had these risk assessments that
if things went really really bad maybe
we would kill 300 million people or
something like that now we know that
that's hopelessly naive and that this is
not even getting blown up by it isn't
even the number one largest risk to
worry about
for example oops this is a photo from
downtown Las Vegas in the 60s you see
the mushroom shaped cloud in the
background that's how close it was to
downtown because people had totally
underestimated the dangers of
radioactive fallout and acknowledging
that now the US government has paid out
more than two billion dollars in damages
to settle these down winter cases and
there have been more people who were
killed by fallout from these peacetime
nuclear tests than who died in Hiroshima
Nagasaki combined but that's also not
the number one risk even though it was a
big oopsie in the 60s it was realized
that if you set up one single hydrogen
bomb 400 kilometers up above Earth's
surface you can create an electric
magnetic pulse your pens of thousands of
volts across pretty much the whole
confident potentially this permanently
this disabling electronics cars
cellphones the power grid which can lead
not only to catastrophic infrastructure
meltdown but also if you have a long
power failure together with all these
thousands of nuclear devastated cities
then there are additional oopsies people
haven't thought about for example if you
if you actually have a long-lasting
power failure in a nuclear power plant
you know what happened in Fukushima well
if you don't keep the pumps on that
circulate the cool water that covers
these spent fuel rods and pools like
this one it boils off within a matter of
weeks then the Chaconne ium cladding on
the fuel rods catches fire and then you
get the super chernobyl and you you
could get that basically all of these
fuel pools there are 300 of them here's
I only draw draw drew little wind plumes
around f5 of them but you can imagine if
you do that around all of them it's just
further adding to the misery I'm
highlighting this at the metal level
just because these are things that
people hadn't thought about
for decades and decades while the
technology while we built tens of
thousands of these weapons and yes and
we still haven't talked about even the
worst risk that's been discovered so far
right now if if we were to actually use
a large fraction of the 16,000 nuclear
weapons that currently exist many of
which are on hair-trigger alert so we
could have if you think of the largest
couple of thousand cities on earth you
could have them all destroyed within an
hour right now if we were to do that
then a nice-looking planet here would
before too long look maybe potentially
like this as at the switch from the fire
storms rose high up in the atmosphere in
a shout at earth and and this was not
realized how serious this would be until
the 80s about four four decades after
Hiroshima Nagasaki and although this had
a very powerful influence this research
and push to help persuade Gorbachev and
Reagan to negotiate the largest nuclear
cuts ever done it turned out that
unfortunately these calculations were
rather inaccurate they were made on a
supercomputer which was less powerful
than this phone and it turned out that
they were too optimistic but more modern
calculations done by some of the world's
leading climate modelers on real today's
supercomputers show that this might last
not two years but more like ten years
and for the following summer you can see
here the temperature drops
this makes global climate change seem
like peanuts in comparison you see in
the American breadbasket Ohio for
example the temperatures are dropping by
20 degrees or so that Celsius it's a 40
Fahrenheit my American friends and if
you're looking and saw in Russia or
China you get drops I'm like 30 35
Celsius what does that mean in plain
English well we don't have to be
agriculture experts to realize that if
this turns into this when you're gonna
harvest it's not so awesome for food
supply and what doesn't have to make
fancy calculations to realize that
rather than maybe having a few hundred
million people killed and as in some of
the worst-case scenarios that people had
in the 60s it's very plausible that the
vast majority of all people on earth
would starve
death and then succumb to pandemics and
other things that would follow no not
great and the thing to take away from
all of this I think is simply that this
is an example of where we built the
technology first and realize the bunch
what the main risks were way way later
and as we get more and more powerful
pack we want to learn from this mistake
and really understand the threats first
so that we can avoid them in the first
place so in that optimistic spirit let's
take a closer look here at the
artificial intelligence this is a
technology which has wonderful potential
of course to do great things and we've
also seen how it's been making a lot of
progress maybe earlier the early
progress in AI appendant it'd be
involved like when Garry Kasparov lost
that IBM is the blue for example good
old-fashioned AI were some human
programmers taught the machine to do
something that it could then do way
faster than Kasparov and beat him
similar sort of old-fashioned approaches
that are very successful now our
self-driving cars and to some extent
went when the Jeopardy beat blue but
this place show was won by IBM's deep
blue however most of the most recent
breakthroughs that have happened and
there's been a real real amazing series
of breakthroughs just in the last five
years were things that people thought
would take decades to accomplish have
not happened all of a sudden most of
that stuff has involved a completely
different approach where the Machine
actually learns like a child it's it can
take vast amounts of data and using
using deep learning another techniques
that Nick Bostrom will tell you about
can actually learn to do all sorts of
things that the programmer has no idea
even how it did it just like your
children learn to speak your language
and you don't even know exactly how they
did it so look at this picture for
example this is something that was
science fiction five years ago has done
last year at Google you just send them
the pixels of this image and the
computer says that's a group of young
people playing a game of Frisbee you
said in this picture and the computer
says oh that's the herd of elephants
walking it across the dry grass field
and we don't really know exactly how the
computer did it because it just learned
you know from massive amounts of data
we'll hear more again from Nick about a
little bit of under the hood of what's
involved in this stuff
but I just want to talk about quickly
two issues that this raises so first of
all there is the there's a so there are
two completely separate issues we should
not complete there are near-term issues
with technology that almost exists right
now and then there are longer-term
things about if machines get smaller
than us one day what might happen then
Nick will tell you planning about the
latter but in the very near term let's
talk about RTI weapons a little bit so
our organization recently launched an an
open letter on autonomous weapons where
which was signed by over 20,000 people
and and about 3,000 of the world's
leading robotics and AI researchers this
open letter it was very much inspired by
the Chemical Weapons Convention that we
heard about from the Dead Sea Ghana Cova
and the biological weapons convention
that we heard about from David face why
did these people these researchers sign
this well people who go into biology
generally want to make the world better
they don't go into it because they want
to make bio weapons people who go into
chemistry they want to make the world
better not to create chem weapons and
it's the same of course with these AI
researchers they want to use AI the cure
diseases to help alleviate poverty and
do great things not to figure out new
ways of mass murdering people or
destabilizing the world and they feel
concerned that their technology that
they're building is being bastardized
for really destabilizing uses what are
some of these things that these people
worry about well we for example today
when when drones are used to kill people
it's always a human who makes a decision
who's removed controlling the drone from
somewhere right
but within years we will have the
technology that we can completely
eliminate the human from this just have
the drone fly around for a few hours
find somebody use its own and I software
just like that elephant recognizing
things saying oh this is the person who
looks like it's our enemy and then have
it have it killed with no
human-in-the-loop a big risk with these
things is that if once
any superpower goes ahead and mass
produces this thing of course all other
superpowers are gonna want to do so - it
will have it arms race our hands but
this arms race these researchers feel
will be very very different from the
nuclear arms race because whereas it's
very expensive to build nuclear weapons
and very hard to get hold of the
materials these weapons will be
incredibly cheap you don't need any
heart to obtain materials a quadcopter
costs few hundred bucks on amazon.com
today the software cost nothing once
it's developed and you can have the
potential that someone with an axe to
grind for you know under a thousand
dollars yeah let me back up
if superpowers build this if you get the
arms race going before long North Korea
is gonna decide the bill lid and and so
on and so forth and before long some
country in the need of cash is gonna
sell this on the black market and then
and then all sorts of non-governmental
organizations with an extra but I will
have them it and these are perfect
weapons for for example assassination
you can program in the fifth what your
nemesis looks like have a thing fly for
two hours identify the person to kill
him and then self-destruction no one
knows who did it
straight for ethnic cleansing you can
program these things to look for a
certain ethnic group only and kill them
that they're very very cheap you can
imagine on swarms of little bumblebee
sized things with which just the
recognizable face will find the eyeball
which is the source softest part of the
skull fires a little bullet there which
is very cheap and you don't need a lot
of power kills people if you have
thousands of those you know it it would
completely transform warfare in a way
that's very hard for foreign nations to
defend against other than by creating a
police state and for this reason there's
a very quite broad consensus among the
researchers in this field that this is
an arms race you just shouldn't start
that's the best way to stop it and I
want to just conclude by pointing
forward a little bit towards Oh Nick
Bostrom who's gonna follow me here
looking at super intelligence sometime
in the future maybe in 40 years maybe in
hundreds of years maybe never we'll see
there's certainly the possibility that
we might make machine
that can be with everything that we
humans can do and then what well we our
organization organized the first ever
conference of AI researchers to talk not
about how to make things smarter but
they talk about this issue in particular
how we can win this race and have wisdom
keep pace with the technology it was in
Puerto Rico in January of this year and
it was actually really productive there
was a very strong consensus that emerged
that this is something we need to think
about the goal of artificial
intelligence should be redefined from
having the goal of just creating pure
undirected intelligence was creating
beneficial intelligence and there was a
very look we brainstormed up a very
detailed action plan a list of research
projects that should be done that would
tackle embarrassing unanswered questions
that we need to answer and we need to it
might take decades to answer them so we
should start researching now you know
not the night before a bunch of guys on
red bow you know switch are on their
thing and what was very exciting about
this was that Elon Musk was present at
the conference and he said look I hear
you guys you want to do this research
well let me give you ten million reasons
to do it and with his donation we were
able to launch a worldwide competition
for research ideas we were overwhelmed
by getting three hundred teams from
around the world putting in wonderful
proposals and it's very painful for the
experts who have to review this to pick
out winners but 37 teams have now been
selected and I've started to work on
this and it is I think you'll be very
very exciting to keep following how this
develops we view this as just a little
bit of seed funding for the wisdom and I
would encourage all of you with
resources of governments and big
organizations to remember that if we
want to win the race between the power
of Technology and the wisdom with which
you manage it we have to mindful of the
fact that almost all the investments
right now just go into making the
technology more powerful there's almost
no investment on the wisdom side so if
you're involved with any organization
and get help a little bit ramped up this
sort of research you would do humanity a
wonderful service thank you
a MUX
thank you very much for this absolutely
inspiring in wonderful presentation we
are now at uniquely trying to invest in
the wisdom side certainly and want to
have you join us in this endeavor as
well intellectually as well as in any
other means and your presentation
certainly proves how important it is to
bring these issues to the discussions
that the United Nations at the General
Assembly and that at the level of
decision makers to have the awareness
raised there and to see what we can do
together to put all the stakeholders and
all the particles together now yeah max
you made a comment about about the
drones and how easy it is to get them
recently there was an incident at the
Japanese Prime Minister's house when
somebody flown a drone with a
radioactive material on top of it and
that got there obviously this was
remotely controlled drone but but at the
same time what happens when machines get
smarter and this is something I'm going
to address it to Nick Bostrom and I will
introduce him he is a professor at the
Faculty of philosophy at the Oxford
University he's the founder of the found
founding director of the future of
humanity Institute the author of The New
York Times bestseller super intelligence
the book and he was named one of the
foreign policy Magazine's top 100 global
thinkers Nick please tell us what
happens when machines get smart get
smarter very much for the invitation and
everybody who is contributing to making
this meeting happen so just while we're
getting the PowerPoint slide up I I can
say something in general about so I want
to sort of expand on some of the things
that max were saying in his talk and and
this grandiosity named a research center
that that around the future of humanity
Institute we see ourselves as in the
business of of trying to put a little
acceleration on into the wisdom side of
this race between wisdom and
technological capable
so to start without I want to introduce
a concept that that we find is useful
for organizing our thinking when you're
really zooming out and looking at the
human condition from a high altitude and
look at the really big picture this
concept of what I call an existential
risk there's never been an existential
catastrophe in all of human history and
there will only ever have been either
zero or one so an existential risk is
one that imperils the survival of Earth
originating intelligent life but I could
permanently destroy our future so all
the things that have gone wrong in human
history all the wars and earthquakes and
plagues from from this strange
perspective or sort of like me ripples
on the great pond of humanity when you
thought up the total amount of suffering
and happiness at the end of time these
might not really register where as an
existential risk would be important in
that context so we define it as a risk
that threatens the premature extinction
of Earth originating Telenet life or the
permanent and drastic destruction of its
potential for desirable future
development so this focuses our
attention we have this very wide mandate
the future of knowledge is today that
could be anything pretty much but when
you put on the lenses of focusing on
existential risk like almost all the
concerns that preoccupy the world's
population fall away because they just
aren't possible existential risks in
there and a very small number of
concerns remain which we can divide
broadly into two categories so risks
arising from nature and risks arising in
some way from human activity one early
finding of this field of existential
risk studies is that all the really big
existential risks certainly if we're
talking about the timescale of a hundred
years or 200 years are in this
anthropogenic category you can see this
quite easily if you just reflect on the
fact that the human species has been
around for a long time we have survived
earthquakes and fire storms and plagues
and asteroid impacts for a hundred
thousand years so it's just not very
likely that any of those things will do
a sin within the next century
whereas we will in this century
introduce entirely new phenomena new
factors into the world so if they're
going to be existential risks in the
century they're most likely to come from
these new
things that we will do and and and most
of the possible ones here have to do
with anticipated future technologies and
another way to look at this is is to
consider this metaphor of a giant urn
full of balls and and you can sort of
see human history as the process of
reaching into this urn and extracting
one ball after another these faults
represent ideas technological
discoveries the products of human
creativity and throughout our tenure
here on this planet we have extracted a
great number of these balls and most of
them have been good some of them have
been mixed blessings none has been such
that it has spelled our a disaster we
might wonder what would it be like if
there were one of these black balls in
the urn is there some possible discovery
some technology that could be invented
such that it invariably spells the doom
of the civilization that discovers it it
could run a kind of counterfactual
thought experiment and think back 100
years ago eight years ago before nuclear
weapons had been invented and you can
ask yourself what would have happened if
it had turn out that instead of
requiring highly enriched uranium or
plutonium like a really difficult
processes to unleash the power of the
atom what if it had been some simple way
something like baking sand in your
microwave oven or something like that
right so so now we know that you can't
have a nuclear weapon by breaking sound
in your microwave oven but before we did
the relevant physics how could we have
known how it would turn out like it
could have turned out like that and in
that scenario that might well have been
the end of human civilization at that
point because if anybody just by doing
some simple thing that they can do in
the kitchen could wheel the destructive
power to kill me Lister and it might
just be impossible to have cities and
concentrate in population and so forth
but nuclear energy turned out not to be
a black ball but maybe a gray ball
instead so it looks like our strategy
currently is to continue to pull balls
out of this urn and just hope that there
isn't a black ball in there because if
there is we will eventually pull it out
and then that will be the end of it we
have a lot more ability to invent things
than on invent things
so so this is a general reason also for
thinking that the biggest existential
risks over the course of a century might
be from possible future discoveries that
we might make and I've put up a partial
list here of some of the perhaps more
likely candidates for areas where
existential risks might emerge there are
several things to notice about this
there's also all of these technologies
here have great potential for beneficial
uses which and paradoxically is one of
the factors that makes them go higher up
on this list because it increases the
likelihood that we will actually develop
them if there was some technology whose
only used was to cause destruction of
humanity then maybe we would have a
greater likelihood of steering clear of
that but if it's something that has wide
beneficial impacts for Health and
Environment the economy
chances are we will eventually develop
these another thing to notice about this
this is that at the bottom there I've
I've put in some unknowns so if you
think again back a hundred years ago and
consider what the answer would have been
if it at that time would have asked what
are the biggest existential risks over
the next couple of centuries then none
of the ones that we might now be tempted
to put near the top of this list would
have been mentioned I mean certainly not
machine is heaviness I didn't have
computers synthetic biology wasn't the
concept nanotechnology was not a concept
that might have worked some about
totalitarian tendencies but for the most
part what now seems to be the biggest
risks are ones that have only in recent
decades popped up on the radar and there
might yet be others that we haven't yet
conceived of which is one reason why we
think there is potentially a high value
in doing this kind of research just in
case we can find something else that we
might be able to do something about so
now let me transition to speak more
specifically about possible concerns
from the future of artificial
intelligence at the very most basic
level the the the point is this that
intelligence is an extremely powerful
thing it what makes the difference
between the human species and and our in
many respects very similar
relatives the great apes that that share
most of our ability and only in very
recent evolutionary time has departed
somewhat and and these small differences
in our brains have resulted in all these
vast differences in in our ability now
to shape the future of the planet sir
it's our small increases in intelligence
that have enabled us to develop this
modern technology and so forth and it
therefore seems plausible just just even
at first sight that if there ever were a
time when machines became as much
cleverer than we are as we are than
other animals then that those machines
could be a very powerful shaper of the
future maybe they would be able to shape
the future according to their
preferences and then that this is
therefore it seems to be a topic that is
worth transferring out of the domain of
Hollywood movies and science-fiction and
kind of entertainment and into the arena
where academic researchers can begin to
think about it as a topic where the goal
is not to have fun and be entertaining
but where the goal is to develop like
increasingly accurate beliefs and
proposals so max was already mentioning
some of the advancements that have been
made some milestones that have you
crossed if we look under the hood behind
these applications then we see a great
number of developments in algorithmic
techniques that have occurred and pretty
much all of these really only since you
know in the living memory of a lot of
people alive today I mean the computer
is still quite young and so if we think
about how far we have come in these past
70 years it makes one realize that
within the lifetime of us or our
children that could might common perhaps
all the way in addition to these
advances in algorithmic design and
architecture there have always been
developments in in hardware and if you
look at particular domains such as
computing you find that roughly half of
the improvements in performance have
been due to computers getting faster and
half due to better algorithms and and
that as a rule of thumb seems to be true
across the board that both hardware and
software contribute
roughly equally in recent years I think
maybe the reason two or three for years
to have been a new sense of excitement
in the world of artificial intelligence
a sense of having compound on stock that
the field was kind of stagnating a
little bit before but now particularly
with developments in its known as deep
learning and some other techniques there
is a sense of renewed progress a lot of
exciting frontiers to explore also
reflected in industry activity with some
some high-profile acquisitions and a
kind of war for talent among some of the
large software companies of the world we
find an artificial intelligence already
in wide application throughout the
economy I'm going to read off the whole
list but a lot of the inventions that
were originated in artificial
intelligence research laboratories we no
longer tend to think of as artificial
intelligence once they actually work
then just become software and this is
sometimes frustrates AI researchers that
kind of get credit for all the things
that that have been accomplished but but
but AI techniques are and why to produce
already and that that list will continue
to grow longer if we look for example at
a game may I ask one particular area
where it's easy to compare human and
machine performance we find that machine
you tell us already in in many games
perform as well as or better than human
beings I think that the next big game
were where computers will exceed us will
probably be the game goal which is kind
of the Asian equivalent to chess a big
organ great complexity some challenges
that that remain today is better methods
for transfer learning this is the kind
of technology we would need to be able
to use insights that you learn from
solving one problem and then apply them
in a very different area and this is
still something of a challenge that AI
researchers are working on concept
learning more flexible reasoning with
learned concepts as opposed to just sort
of
symbolic tokens that don't mean anything
long-range hierarchical planning reading
and more complex system architectures
like tea you might get a slightly
different taste depending in which AI
researcher you ask but but these are
certainly some of the major outstanding
challenges that stand between where we
are now and replicating the full
functionality of the human mind learning
ability and planning ability that makes
the human mind so powerful so reflecting
on these developments I think as max
said that it's very important to make a
clear and emphatic distinction between
the near-term and long-term
both of these contexts have serious
legitimate challenges and opportunities
to think about but they're quite
different so in the near term we have
issues such as autonomous weapons next
mentioned we have of course non
autonomous applications of these you
could have in many situations perhaps
the human making the final decision by
pressing a button but with a lot of AI
assists image processing etc you have in
a very different direction people are
thinking about the impact of automation
on the labor market and whether the
problems with chronic unemployment that
one is beginning to see in some
countries have something to do with with
that or whether it in fact has to do
with completely other things like
offshoring of labor or the economic
cycle but as machines become more
capable this is likely to become a
bigger issue surveillance and data
mining of course cybersecurity
self-driving cars have issues for
regulators like exactly what will the
legal frameworks be for allowing these
on the road and and a bunch of other
things and and these issues are quite
different from the issues that arise if
we ask the question what happens if AI
actually succeeds in its original
mission which has all along B not just
to create domain-specific applications
little tools here and there but actually
to do all the things that the human mind
can do and that's obviously farther off
but also the implications are much more
profound so
we did it survey of some of the the
world's leading experts a couple of
years ago on one of the questions we
asked was by what year do you think that
there is a 50% probability that human
level machine intelligence will be
achieved which we define for the
purposes of this era as the ability to
perform most jobs at least as well as a
normal adult so so real genuine human
level machine intolerance and as you can
see the median answer to that question
was 2040 or 2050 depending on precisely
which group of experts we asked and that
estimate should be taken with a large
amount of salt in that it's based purely
on the subjective impressions of people
expert in the field but there is really
no science that enables us to predict
with accuracy how long these kinds of
developments will take it could happen
much sooner or it could take a lot
longer so I think instead of a
particular year think of a probability
distribution so smeared out over a wide
range of possible arrival dates there is
a a different question also about timing
but which must be distinguished from the
first so so far I asked about this kind
of first era there on the horizontal
axis time until take ups like how how
long between now and human level machine
intelligence there is a second question
if we ever do reach that level how long
between that point and until we have
something that is radically super
intelligent and you might be quite
pessimistic or optimistic depending on
how you look at it but you might think
that it will take a long time before the
field of artificial intelligence will
actually reach human level maybe you
think that these opinions about the
practitioners are biased maybe they want
to believe that their field is really
important and it will succeed maybe you
think it will take a hundred years
rather than 50 years or more
you might nevertheless still think that
if we ever do reach that level that the
transition to super intelligence will
then happen quickly and in fact that is
my view that it would be harder to get
from here to human level than to get
from human level to 2 radical super
intelligence
one way to think about it is this and
intuitively we'll have this notion of
smart and dumb that maybe looks somewhat
like this we think at one and we have
like the village idiot completely
hopeless mongrels everything and at the
other end you have sort of your favorite
scientific guru what Einstein or Ed
Witten or something and these kind of
define the extremes of human cognitive
performance with regard to how difficult
it will be for artificial intelligence
to achieve a particular level of
performance however I think that the
picture will look more like this that we
start at the left of this diagram with
zero capability when we invent computers
let's say zero artificial intelligence
and then slowly over time the AI train
moves along this track and after many
many decades of really hard work by a
lot of researchers perhaps eventually we
reach mouse level artificial
intelligence something that maybe can
navigate a cluttered environment that
not as well as the mouse can and then
after a lot more work I mean where we
reach chimp level and after a lot more
work beyond that which we don't really
tell yet level but I don't think that at
that point the train will slow down I
think it's whoosh past human will
station the brain of the village idiot
and the brain of Albert Einstein are
almost exactly identical same size same
number of neurons more or less the same
biology there's no particular reason to
think that it will be got harder to
match one than then to match gathers so
to wrap up so what I have argued and I
recently wrote a book on this is that we
then will confront this control problem
which is the problem of assuming it
could solve the intelligence problem
like how could actually make machines
and teller like how could it then ensure
that these very intelligent machines
will be safe and beneficial to humanity
and I argue that this raises unique
challenges technical technical
challenges and foundational challenges
that there are possible scenarios in
which super intelligent systems become
very powerful and for the reasons I
alluded earlier like intelligence is a
general-purpose thing if you have
nothing telling us it can invent all the
other technologies you don't already
have and and also as I described in the
book there are these superficially
plausible
of solving the control problem ideas
that immediately spring to people's mind
that on closer examination turn out to
fail and so there is this open currently
unsolved problem of how to develop
better control mechanisms that is more
difficult because it will need to be
solved before we actually have these
fully intelligent systems by that time
we already have a solution so so I'm
very glad that people like Elon Musk are
stepping into the breech here where
there has been a complete funding vacuum
until recently and and that some
activity is beginning to happen and and
I recommend that that we sort of
accelerate this work of establishing a
field of inquiry to do foundational and
technical work on the control problem
and in recognize that as such as we
stinked legitimate academic endeavor
that some small number of the world's
best brains should be working on it just
as so many other things are being
started by academics that we should try
to attract top mathematics and computer
science talent into this new field that
we should build strong research
collaborations between the AI safety
community and the AI development
community of in industry in academia
because ultimately the path to success
is that whatever ideas for safety are
developed also get implemented and both
of these need to learn from one another
rather than take up antagonized
positions that in long range scenarios
and planning we should consider super
intelligence as a possibly important
factor in shaping humanity's long-term
future this does not commit one to
thinking that this is just around the
corner that we should hold our breath
and be like super excited about every
single announcement in the media but but
if you're really thinking long term
about humanity's future decades out then
I think this is a legitimate thing to
take into account and finally that it is
important to integrate into this
research community and into society's
thinking about the long-term future of
artificial intelligence that this is a
unique technology that should be
developed only thought for the common
good of all of humanity it's too big to
just be thought of as something that
will raise the profits of one firm a
little bit or give one country a slight
edge this is really a concern for all of
us everybody in the world if this is
developed will share in the risks
whether they like it or not and it also
seems fear
that everybody should stand to gain if
things go well and have a slice in the
upside thank you very much
Nick thank you very much for this
absolutely great presentation and and
one of the recommendations what I would
also add there is to bring these ideas
to the policymakers to the international
organizations and private sector and
create some sort of a platform where
where all of these segments all of the
stakeholders could work together to
ensure that yeah what we're going to do
if AI succeeds and as your we see in
your presentation basically we are
leading or we are heading towards that
ai is going to succeed and we have to be
prepared about it so our next speaker is
Daniel fix I will ask a question to
Daniel but first I will introduce him
he's the chief of the biological weapons
convention implementation Support Unit
he's in charge of assisting biological
weapons convention States Parties in
their efforts to implementation of the
global this global treaty as well as
assisting remaining countries in
acceding to the biological weapons
convention my friend Daniel I used to
work at the had senior positions at the
organization for the prohibition of
chemical weapons we worked there
together and he has a strong interest in
science and technology technology and
how its developments are going to affect
global disarmament and non-proliferation
treaties now Daniel tell us what's going
to happen if AI succeeds and what's
going to happen with the biological
weapons convention or with biological
weapons thank you good afternoon
everybody thank you first of all to
eunuch Reed to Georgia for organizing
this event I think it's been a very
interesting discussion so far I've
certainly learnt a lot already this
afternoon I'm sure there'll be more
things to learn as we go on towards the
end of this event as well and I think it
just shows a lot about the multi-faceted
nature of this you know of this issue of
CBRN and the the science and the
technology that underpins it what I'm
going to talk about I'm not really going
to focus on the details
I'm not mice
a scientist I'm not someone who's a
technical person here I'm going to talk
more about the governance framework and
the way that we think about managing
these technologies and particularly
focusing on as Eric Lee said the
biological weapons convention and the
way in which that is used to to govern
and to manage biology basically and
first of all I want to start with
looking I mean we're meant to be here
looking at the future but I also want to
look back to the past and it's quite
quite good that both previous presenters
have also referred back to historical
you know examples and things like that
as well so I want to go kind of like it
says here Back to the Future I also I'm
just like to note that this month is the
month in the film Back to the Future
that Marty McFly when he was time
traveling in 1985 it was October 2015
the he time traveled forward I mean that
was 30 years he went from 85 to 2015 I
want to go back to another 10 years so
to 1975 two events happened in that year
1975 that were probably at the time not
connected not thought of as being
related to each other at all the first
of them was a conference in a place in
California or conference center in
California called as Ilima it brought
together scientists and basically what
they did they drew up voluntary
guidelines to ensure the safety of
recombinant DNA technology this was they
were already thinking you know this
field was there were these new
developments these new advances that
were happening which could pose risks
that could pose challenges so a group of
mainly scientists some journalists some
others were involved as well
but mainly scientists you can see some
of them there in the photos and came
together and it's widely seen you know
looking back now as a kind of a landmark
in the self-governance of science its
there are kind of you know differences
in kind of the impact of value that
people put on this particular conference
but it was as I said it was its widely
seen it it's widely referred to now
people often speak about other areas of
technological advances needing they're
kind of Raziel as Ilham are moment as I
said something else happened that year
very soon after in fact
Marvel's February then this is March
1975 you see pictures here from where I
work in Geneva this is inside the UN
building the Paladin a salon in Geneva
where the biological weapons convention
the BWC
it was negotiated a few years before
then these are pictures it was very much
a kind of a product of the Cold War you
can see USA USSR there they were the
co-chairs of the conference on
Disarmament at the time the negotiating
body in which the treaty was negotiated
another picture here from the same time
I mean the people in these pictures are
slightly smarter than the scientists you
saw but you can still kind of you know
tell it's roughly around about the same
time sometime during the seventies and
so this treaty it was the first
international agreement to effectively
ban an entire category of weapons of
mass destruction later on you had as
dieter was talking about a chemical
weapons convention but the BWC was the
first one to do this it's a short simple
but elegant treaty which it's faced
challenges over it's 40 years but it's
today represents a strong norm against
the hostile use of biology and it has a
membership of 173 states from around the
world many of which are represented by
the people in this room the convention
itself you can see that this is the
front page of the kind of the official
version with the seal on it of the
convention and a couple of quotes from
the preamble so like the opening kind of
objectives of the Convention and it's
comprehensive
they kind of comprehensively prohibits
biological warfare and you can see from
the second quote there that it refers to
this this kind of repugnance this this
abhorrence of using biology of using
disease as a weapon and this is a taboo
that you can kind of see stretching back
to ancient history you can look at
ancient documents from various cultures
around the world and you can see that in
you know across the world for centuries
the idea of using poison of using
disease as a weapon has been something
that's really almost psychologically you
know kind of bred into us as humans it's
going to be in our DNA almost that this
is something that is really quite kind
of as it says there repugnant to the
conscience of mankind
and just in terms of what the BWC
actually covers and you might not be
able to and you don't necessarily need
to read everything on there but its
scope is also comprehensive as well it
covers the use of biological agents not
just against humans but also against
animals and plants and as you can see
hopefully on the screen there this is
something from the conference that took
place on the biological weapons
convention in 2011 it applies to all
naturally or artificially created or
altered microbial and other biological
agents and toxins and the conference
that took place back then as you can see
in the second paragraph reaffirmed that
it applies to all scientific and
technological developments in the life
sciences and other relevant fields so
it's as I said its scope is
comprehensive its prohibitions are also
comprehensive as well before moving on I
just wanted to kind of flag some of
these risks and we've seen some of these
listed already you know we're talking
about things like the diseases the
outbreaks that we're familiar with just
in the recent months basically the MERS
outbreak in South Korea it was a small
outbreak but it caused a big economic
impact Ebola in West Africa obviously at
least 11,000 deaths big economic impact
again there near the afflicted country's
recent modeling by the World Bank says a
Spanish flu this is the kind of flu that
the epidemic that happened or pandemic
after the first world war could kill
more than 33 million people in 250 days
and cost almost 5 percent of global GDP
and then the World Economic Forum in its
global risks report this year two of the
risks are kind of related to what we're
talking about here one of them they
identified as rapid and massive spread
of infectious diseases
another one was weapons of mass
destruction when we're talking about
biological weapons we're kind of linking
linking those two to identified risks
together what I wanted to do now just
kind of flagging these risks I want to
turn and talk a bit like I said I'm
going to talk about the biological
weapons convention itself and the kind
of the governance framework and the way
in which the Pratt
good implementation of the BWC takes
place and you know the hope is here that
what I am saying is of relevance and of
some kind of interest perhaps to you
know how we think about managing the
risks that are posed by you know
artificial intelligence for example in
some of these other technological
developments that we're thinking about
this guy was a as you can see a former
US ambassador to the biological weapons
convention and what I wanted to put this
quote here for is it basically reminds
us that as much attention should be paid
to kind of implementing these treaties
as is paid to their negotiation we have
a lot of attention if you think you know
we need to get a new treaty in force we
need to you know we have a campaign to
get countries to join or to get them to
adopt a treaty after that people
generally forget about it and it's left
to kind of be implemented at a much
lower level with much less attention
what he's saying here is that these
treaties need to be tended they need to
be nurtured over their lifetimes and
basically that there's a lot of kind of
invisible work really that's done in the
background by officials he talks about
that some officials will have to live
with these treaties full time all the
time from our point of view the most
visible way in which this happens is the
meetings that we host in Geneva every
year we have two meetings a more
technical one generally in the
summertime you can see a picture there
from one of our recent ones and though
it's got more political one which takes
place in the winter it generally around
about December you can see the dates for
this year's meetings but these meetings
are really only a part of the story this
is what you see like I said it's the
more visible thing as much activity goes
on at the national level which is where
the work that happens in the BWC context
really closely overlaps with what we
were hearing earlier about what you
Nicola is doing what the states are
doing with the National Action Plans and
what the European Union is supporting in
that respect as well and the centers of
excellence all right I just wanted to
hear knowledge that work and say you
know how important that also is and the
work that the states are doing
themselves for implementing you know in
our terms the biological weapons
convention this slide is just a kind of
overview of what agenda items are being
discussed in what particular topics are
being discussed
in the program of work that has been
running with the biological weapons
convention since 2012 I won't go through
all of them at all but I what the one I
really wanted to focus on it's the one
in the kind of middle oval at the bottom
there says reviewing SMT reviewing
science and technology and that's really
what I wanted to be kind of focusing
most of the rest of this on you can see
and again I don't expect you all to read
and I certainly won't read through this
whole list but these are the topics
which the the member states of the PWC
back in 2011 the last time they reviewed
the whole treaty these are the signs and
technology topics that they identified
as being the ones that they would study
for the next five years so from 2012 up
until this year and you can see
hopefully from the top two they're a and
B that and we've already heard it from
the previous two presenters it's
important to look at both risks and
benefits for these things so you can see
there they talk about things having
potential for uses contrary to the PWC
but also that have potential benefits
for the convention as well so as with
these other technologies we were hearing
about there are both involved here and
then also there's elements there about
codes of conduct on things that promote
a kind of a responsible culture or a
culture of responsible science one
particular advance and I mean there are
many that are discussed in these
meetings and there are many that are
relevant to the BWC but one that's been
much in the news recently as you can see
from this front page of The Economist
from a couple of months ago it's
something called CRISPR Kass which is
it's been discussed to have meetings in
Geneva it's basically something that can
be used for editing genes basically
adding disrupting or changing the
sequence of specific genes and as you
kind of get the impression from this
picture it's something that people say
you could actually be using to kind of
basically create designer babies is
obviously what they're getting at here
to edit humanity as it says it's
obviously something that can bring great
benefits to humanity you know curing
diseases or preventing diseases being
carried through generations but as I
said with lots of these advances it
obviously brings risks with that as well
whether by accident or by intent
besides the annual meetings I referred
to that we have in Geneva these two
meetings every year and I've mentioned a
couple of times that the member states
of the BWC actually meet every five
years to kind of have a comprehensive
review of the operation of the treaty
itself last time was in 2011 the next
one is coming up next November and you
can see from this extract from the
treaty itself and at the bottom there
says that the review shall take into
account any new scientific and
technological developments relevant to
the convention so that was kind of baked
into the convention from its beginnings
that science and technology would need
to be reviewed and would be an important
part of that review every every five
years and based on the discussions as I
said each year I showed you the list of
topics earlier that have been discussed
over the last five years and the review
that will be coming up next year this is
what the last review conference the one
that took place in 2011 said should
happen in 2016 that they should also
again look at new developments so since
2011 developments have taken place since
then should be reviewed and assessed in
2016 and before finishing I've got a
couple more slides and one of the things
I wanted to kind of pull up here on the
screen it's a quote I use sometimes and
in presentations I think it really kind
of gets to the core some people think
there's a kind of silver bullet here
when we're talking about these kinds of
technologies that you can solve the
problem you know you can ban something
or you can just you know stop people
doing certain things and as Joshua
Lederberg says here he was someone who
won the Nobel Prize for medicine in 1958
he did a lot I mean a very very eminent
very you know I'm very well known very
well respected molecular biologists also
did some work in artificial intelligence
apparently as well I wasn't I wasn't
aware of this until I was reading about
him more recently you know he made this
point that there is no technical
solution to this problem it's something
that's it needs to be managed it needs
to be governed and it's not enough just
to look at the technical side you also
need to look at the ethical the human
and the moral dimensions of this problem
as well what I wanted to finish on as I
said I'm not going to get into the kind
of the technical issues but just a few
key points and the first one of
is exactly what I just said from Joshua
Lederberg is that it's you know with
lots of these technologies it's about
managing them it's about oversight
it's about governance it's not a quick
fix solution you can't you can't solve
the problem we've seen with the PWC that
it's also very important to engage and
to involve a diverse range of
stakeholders so not just governments not
just industry but scientists academics
civil society more generally the third
thing is this whole issue of you know
talking about science in in the
diplomatic context which is basically
what happens in Geneva it's really a
diplomatic setting but then you're
talking about hard you know kind of very
cutting edge science issues sometimes
that's difficult and that's not just
something that applies to the to the BWC
we look at climate change we look at
lots of these other issues that are big
global issues but explaining those two
well to the general public but also to
decision makers and to politicians is a
very difficult task and we really
haven't worked out how to what's the
best way of doing that and then the
final thing is that it's very important
to focus as we've heard on the benefits
it's very easy and we get lots of hype
and you know you talk about sci-fi and
Hollywood films and you know these kind
of doomsday scenarios about the the
risks and you know what could happen but
it's very important to focus on the
benefits you know you mentioned already
how most people go into these into these
subjects into these fields for good
reasons and you know that's that's
important and it's also important to
make sure that the benefits that come
from these advances are shared amongst
all countries rather than you know as is
sometimes the case or at least the
perception that these newer advances are
things that are only you know kept and
only available for certain countries of
the world and so those were the things
that I wanted to kind of leave you with
those are the contact details of me and
my unit what I wanted to leave the final
final word was not me but hopefully if
the video will work properly I wanted to
leave the final word with the UN
messenger of feasts who's Michael
Douglas when it comes to disarmament
Affairs and we had a short video message
which was prepared earlier this year for
us and it's very short it's about 90
seconds or so
he much more eloquent than me he says
you know he summarizes the issue and
sums up the kind of key points I'll hand
over to Michael Douglas if it works
we're all aware of the terrible
devastation and economic impact which
naturally occurring diseases can cause
naturally occurring diseases are a
threat which Humanity has been facing
for many thousands of years and in some
cases we have been fortunate to overcome
them for example the successful
eradication of smallpox imagine then the
deliberate use of disease as a weapon of
war or terror in the early 1970s the
international community therefore
negotiated a treaty to outlaw biological
weapons the biological weapons
convention came into effect in 1975 and
now has over 170 member states
this treaty outlaws biological weapons
and is a vital part of the world's
efforts against the spread of weapons of
mass destruction with this 40th
anniversary year now here I call on all
those working in the biological sciences
to promote a culture of responsible safe
and secure science on the remaining
states to join the biological weapons
convention as soon as possible and on
the current states parties to continue
to improve its implementation in this
way we can ensure that the use of
biological weapons remains as the treaty
states repugnant to the conscious of
mankind more to you rather than Michael
Douglas also I probably took to him as
well thank you Daniel very much as you
have sort of rightly pointed out with
the words of if there are no technical
solutions there are no so-called
solutions the solutions are to bring all
the stakeholders together to discuss
these issues and to to find the little
solutions which will in combination
service oh good now we're going to move
to our next speaker and and
we're going to ask a question to mr.
peer-reared who is executive director of
the sick by security solution so he
already has the solutions in the in the
title of the company that the company
was founded in 1927 with the
headquarters in Lausanne in Switzerland
and Sigma is the world leading privately
owned company providing security
identification traceability and
authentication solutions and services
worldwide Pierre please tell us what
private sector thinks about all these
technological developments how are you
going to participate in that in the
shaping the future policies or are you
going to take part in this or you think
you want to stay away I want to hear
your ideas and your opinions how private
companies private sector views these
threats and how yeah you will be
involved in this floor is your pair
thank you thank you very much directly
and first I would like to address the
chair your excellency and to of course
express my sincere thanks for inviting
us and also to director of the Unitarian
to the European Union to ask the private
sector to express its views about these
CBRN issues because today I've been
hearing and listening and learning a lot
from audio from whole views and I would
express only my gratitude to to see the
level of government that many member
states of the UN have been paying and to
the magnitude attention that you paid to
this to this Evon to this the magnitude
of this terror which is likely to happen
the the point I would like to make today
is a is in one word 15 years ago at the
moment the United Nations voted the
famous revolution against terrorism and
today the technology the technological
landscape
was totally different absolutely
different today the technology has been
evolving at the same pace a criminal
brain is sinking the criminal brain has
two major differences between of a
normal brain his hate is limitless and
his space in finding the and enriching
the objective of his hate establish Li
hai and this is totally different from a
normal brain from this village agent to
the most ants time person you've got a
brain which is isolated somewhere in the
world and the guy is just watching
States and there are population let me
just give you an idea of what while the
technology exactly 15 years ago you got
this thing which was at the left side
absolutely useless compared to a
smartphone and you've got these computer
which were the equivalent of two days a
chip that is going on your finger the
same capacity and the first word here is
miniaturization increase computing power
of accessible devices such as cell phone
if you want to address practically the
CBRN issue today you ma'am states
you need to think that you need four
pillars technically technologically
sorry the first pillar is of course that
wall no the security gates with x-ray
gates gradual gradual of the gold gates
era fide gates the second pillar is
portable chemical sensing the third
pillar is continuous monitoring and the
false pillar is tracking and tracing
tracking and tracing is something which
is not very rocket science
since the postal service's has been
invention the male age track and tracing
is existing what's what is the letter
the letter that you're going to send
from point A to point B is something
very very elementary all postal service
in the world know where is your letter
and they do deliver that but securing
tracking and tracing is something
totally different which was not existing
even fifteen years ago so I propose to
you a short travel into a holistic
approach of those four pillars the first
pillar and I told you is security gates
today and compared to the time of 15
years ago cargo inspection can be today
performed on thousand and non-invasive
way and ports and distribution center
load and presence of dangerous materials
CBRN materials can be checked x-ray RFID
radiology can help you in such a task
you know how many containers are in
circulation on the surface of the earth
at the moment we speak
it's very difficult to understand but
for a criminal brain it's very easy it's
44 million containers in circulation at
the moment to speak if a guy with a
criminal brain want to hide something
which is harmful to the mind kind is
going to do it second pillar is portable
chemical sensing the second pillar is
absolutely central for the chemical
products which can be which can become a
chemical weapon by assembling chemical
products and the continuous monitoring
of presence of explosive and dangerous
chemical substance is today possible and
technically technically I don't speak
politically the whole planet could be
monitored in real-time using what was
not existing even 15 years ago the cell
phone network third pillar the
continuous public space monitoring and
here is something that as well was not
existing 15 years ago
it's the real-time and remote detection
of chemical threat in public threat in
in public I'm sorry in public spaces
today you have the possibility to detect
in a public place like a railroad
station an airport a public place
whatever you have the possibility to
detect a very few molecular from 22:26
molecule on 1 billion molecule is
circulation in the earth you use
infrared cameras which captures and
reflectors no-neck is going to see that
featuring
but this is already existing and we had
a confrontation with dr. Smith yesterday
here it is already deployed in some in
some places public spaces I think as a
pilot so certainly it's it's it's going
to spread but it's going to change the
possible detection and let me go now to
a an industrial trend this trend is
based on what is existing what is
currently developing and what will be
existing in the near future
the tracking tracing of all those 44
million containers is something which is
a headache because you can load can
upload you can dilute you can reload a
container if you don't know what's going
on into the supply chain you're done
you're literally done therefore you've
got what we all know they're the legal
supply chain from the manufacturer at
the consumer the final purchase or
buying legitimate product but you've got
also the bad guys at the bottom the
illicit channel which is the exact
symmetry of the licit channel and you've
got some evans the first event is a
fictitious export on the in the supply
chain with fraudulent declaration up to
the purchaser unknowingly buying illicit
product if you want to stop this first
event therefore you need to create a
product identity to enable traceability
if you want to stop the two which are at
the
of this of this supply chain you need to
create product authenticate
authentication to distinguish fake from
genuine if you want to stop which is at
the middle of the supply chain you need
to create a product story by collecting
all those events and therefore you're
going to isolate the legitimate and
compliant business from the right
operators and tremana organization those
people are very marginal but because
they are they are the brain which is
shaped for terror they are totally
different like the rest of the mankind
so if I summarize you got those four
pillars and if you want to get inside
those four pillars what is this what is
existing today and what is developing
today the product identity is existing
but only on serialization and secure
level of containers what is inside the
container is in product marking solution
this is totally a new developing world
five or six years ago the Texas industry
Authentics started those pagans for oil
and gas industry today those taegons are
moving towards new liquids which are
acid but when you take the tag ins which
were a put in the oil and gas industry
you put that in a I said citric or
chloral whatever is the acid it is all
it is the key issue and when you are a
terrorist
and you mix chemical products to become
an explosive should you have put some
taggants inside between the two acids
between the fertilizer your urea and the
acids there is no stability this is a
true and basic knowledge that all of us
must know
therefore the industry is investing
massive amounts of millions of dollars
in trying to understand how to stabilize
those taegons to be traceable for the in
product marking solution this is going
to happen but with billions in
investment second pillar existing
capability we all know today the product
authenticity Kay authentication is
existing to distinguish genuine from
fake
if you go also to what is possible in
terms of graduation of the
authentication today and that was not
the case two years ago today a simple
consumer having downloaded an app on a
smartphone with a certain low level
security compared to law enforcement
officer who is going who are going to
get very higher standards of apps in
terms of security today a consumer may
see if something is fake or genuine in a
shop in a retail place protocol
authentication is the mix between
existing and developing capabilities and
if you go to the product history
therefore you are now
in the existing capabilities because you
can go using very simple technology and
very simple scanners from to see
aggregation and disaggregation inside a
container a maritime container or air
container and therefore here you are in
the in the field of developing
capabilities by create product history
and these technology is just out of the
laboratories it has not been deployed
anywhere in the world but it's now on
shelf that you exactly know when you are
a manufacturer when you're a buyer when
you're a seller where exactly is your
product and if the container is safe has
it been open where is it
by whom it has been opened has it been
reloaded by what and this is product
history and therefore you can control
most of your supply chain when you
create all those pillar you create
intelligence through monitoring
inspection control and today I would
like to express my gratitude to the
European Union for creating the Adhan
project inside the SP framework program
sorry number seven with regard of the
Adhan program and you've been bright
enough at the European Union to construe
a consortium of 70 enterprises and I'm
very happy to tell you that Sigma is
working inside this consortium with all
the rest of the 69 companies in terms of
CBRN contamination they take
in food staff and enhanced tracking and
tracing solution in food defense
scenarios thank you very much for this
fascinating presentation that we see
what's happening in the real world what
is happening in the real things and
without so and uniquely is already
involved and involved in some activities
related to that
Marco maybe you want to tell us a couple
of words about this activities please
and then we are finishing and to the
Chairman and currently excellencies and
distinguished delegates just to a minute
I think we heard a lot of fascinating
presentations on the technology side to
see and to discuss how important is
technology for security and to take max
words he will sit here how important is
the good use of technology to increase
security just to share with you that
unity has already start in some research
on this area on the good use of
technology and especially on how the
technology community and governments are
cooperating to secure the legitimate
supply chain of specific products which
are very important in terms of security
and health and safety for citizens well
on the one side we will surely inform
you of the outcomes from the research in
the next weeks we also seen that it's
extremely interesting to enhance a
dialogue between public and private
sector is exactly on this on this area
how the technological community and
governments may work together and share
ideas on which are the new trends which
are the new interesting developments
which are the new challenges not just
for the CBRN before increasing security
at large and how we can better cooperate
to increase security at large so we like
also to move in this way as luckily
creating possible platform from
exchanging of information is extremely
interesting bringing together both
private and public stakeholders I would
like to see the suburbs as a as a
cross-cutting issue the different
thematic areas that we have within
Munich we would be great to have CBRN
artificial intelligences one of the
issues we will discuss also in this in
this kind of interaction to increase
security of governments and citizens
alike thank you sure we just heard four
fascinating presentations we have a lot
of food for thinking food for thought
hand over to the chairman of the event
thank you thank you Rock Lee we are of
course off schedule but if by UN
standards for three hour exercise to be
thirty minutes late it's not not too bad
and before closing I want to ask
uniquely and European Union if you'd
like to make your final comments please
I want to thank all of you that stayed
all the way through we had a hundred and
thirty people here today and I think
that that's a real testament to how
important these issues are to have that
money attend a side event and this is an
important issue we'll all be out in the
lobby and be happy to chat out there but
I won't keep you in here because between
us and food for the opinion and just
like to thank you for attending this
very interesting session and very happy
to see that now a sense of local nation
or ownership is is growing up countries
are now looking at you yourself we are
just facilitating the work and funding
it where it is necessary it's very very
nice to see that I'm also very also very
interested in saying different
presentations and the last one in
particular where we see that the links
between our activities the more
governmental level and the civil society
the
the private sector the the Academy is
also very important and you see we have
seen another example of coordination
between different stakeholders on CBRN
and you mentioned the Eden demonstration
project which I know very well and which
is also dealing in some of your
countries I know Morocco Ukraine and
Serbia Georgia are involving this Eden
project as external partner nothing we
are progressively joining forces and
it's very nice thank you very much and
as a as a chair I also want to thank all
of you who whose who had stamina enough
to stay this long it was I believe very
interesting discussion that we had
indeed much has been achieved as we
heard from the presenters but obviously
there is no time for complacency as you
you said and I fully agree on that CB RM
risks obviously are of different
character could be natural accidental
criminal and in addition to that it can
draw sources from conflicts and
uncontrolled territories and non-state
actors as our presenters were were
telling us and also the industries are
so diverse they may emerge from
different industries or even agriculture
which we think that may not be that
dangerous but danger is there because
because of chemicals by technology not
to mention about atomic atomic energy
we've seen how national action plans are
important tools not just to streamline
the strategies but also facilitate the
capacity-building cooperation with
international organizations the regional
cooperation which is really necessary to
to curb the curb proliferation
proliferation of hazardous materials and
in general CB CBRN Centers of Excellence
have been a very good example how on a
local level from
bottom to top we can build up and last
but not the least want to congratulate
our scientist you are indeed lucky to be
born in the 20th century and not in the
Middle Ages because they had a quite a
different approach towards science then
although I'm having a second thought
whether whether that approach of burning
people was right or not but on more
serious I indeed as ill on mass that it
is biggest existential threat to
humanity but we are on this path whether
we like it or not and it is a moral
issue moral and ethical issue and with
science as well as with the policymakers
it is now upon us to stand on the side
of morality and make sure that the new
technologies are safer and are in
service of humanity now with that and
before closing I want to again thank
Pierre vo who is with this company
offered a very nice reception and for
those of you who don't know view is one
of the best shadows in in front so it's
got the best wine so please join us for
for this reception after this gathering
and again thank you all very much for
participating</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>