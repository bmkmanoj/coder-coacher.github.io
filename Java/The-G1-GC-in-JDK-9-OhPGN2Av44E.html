<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The G1 GC in JDK 9 | Coder Coacher - Coaching Coders</title><meta content="The G1 GC in JDK 9 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The G1 GC in JDK 9</b></h2><h5 class="post__date">2017-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OhPGN2Av44E" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right thanks everyone for coming
I'm Eric and today we're gonna talk a
bit about the g1 garbage collector in
JDK 9 but before we begin I would just
like to show you all this slide let it
hang out there for a few over seconds
for you to enjoy and now that's out of
the way let's look at today's agenda
we're gonna be talking about the g1
garbage collector and first of all we're
gonna start off with a quick intro into
g1 in 2017 we will then continue on
looking at five major improvements to g1
since JDK 8 and then last but not least
we will do a little bit of sneak peek
into the future and see what's coming up
for d1 but who am i I'm Eric I like to
program garbage collectors I work at
Oracle in the JVM GC team and has done
so for about six years now the past
three years I've worked on the g1
garbage collector and I was a reviewer
and open in decay where I contributed a
lot so the quick intro into g1 in 2017
first of all what is garbage collector
and what is g1 solving well garbage
collection is a way to manage memory
so in Java programmers do not need to
explicitly manage to memory ourselves
you will allocate your objects with new
and then the memory will be reclaimed by
the garbage collector once it's no
longer in use you can compare this to
see where programs programmers must
manage the memory themselves using
malloc and free how the Scourge
collection work well all your objects
will be allocated in a memory area
called the heap these objects will be
laid out in memory with respective
fields those fields can in turn contain
references to other objects but also in
google internal values as you allocate
more and more objects you will start to
fill up this memory area called heap and
once it's completely filled up well
there's no space to allocate more
obviously and so something as gonna have
to happen now if the program is gonna
continue running what it's going to
happen is that the garbage collector
will force your application and then it
will
see which objects are currently in use
by the program because if you think
about when you write that method in Java
you might allocate a bunch of objects do
some computation and then return the
result but those objects you use for a
competition you don't really need them
anymore
so the garbage doctor will find out
which objects are in use and will do so
by starting from the so-called routes so
in order to figure out which objects are
live and heap and being in used by the
programs you stopped in your application
you scan the Fred stacks for the Java
threads you find the references pointing
out objects like this and then you say
that now I've found those objects I'm
gonna consider them live but as you see
on the slide we're just a bunch more
objects and we can iterate over the
fields in each object in turn and follow
of the references and then we will find
more objects that are reachable from the
roots and if you keep doing this an
iterate on this algorithm we will
simulate or find them all once we have
found those objects we can compact them
to one end of the heap there are other
schemes available from memory management
but this is one example the objects can
be compacted to one another heap and we
will have now have a continuous free
memory area we can use for new
allocations the program can then resume
running and suddenly there's more space
for new objects to be allocated in
jae-won is one such garbage collection
algorithm and this is the first page of
the original paper which is getting a
little bit old by now so the paper was
published in 2004 on g1 garbage
collector the JDK got experimental
support for day 1 in 6 to 14 and
official support in JDK 7 u 4 in 2012
and this year a few weeks ago when JDK 9
was released q1 became the default
collector for the JDK so with this
information
be wary when you're reading old blog
posts Stack Overflow answers etc about G
1 because quite a bit has changed
between 2009 and 2017 the G 1 has
evolved a lot since it was first
introduced with experimental support
so the goal of g1 is to provide both
throughput and low latency and
throughput you can think of that as
roughly the number of transactions per
second or the total running time of a
program whereas latency that will more
correspond to the maximum time of a
transaction and the default post call
for g1 is 200 milliseconds this post
goal can be tuned you can say to g1 I'm
ok with longer pauses which probably
will result if you have a back-end
service for example in longer request
times but in turn you will get better
throughput and get more work done per
time unit whereas if you are concerned
about latency and say that I don't want
it to post not at all or very little you
can decrease this value to a much lower
value but there's always a trade-off so
here you're gonna have to sacrifice
throughput a bit but in turn you will
get shorter forces so how does do you
wanna achieve this well the goal here is
where the methyl here is to use
generational region based memory
management
that's quite a term so the heap is split
into multiple regions so the region size
will depend on the heap size for example
if you have 4 gigabyte heap then you g1
will divide it into 2048 2 megabyte
regions new objects are allocated into
so-called Eden regions and a John
collection will happen after a number of
Eden regions have been allocated during
such a young collection j-1 will find
live objects in those Eden regions and
compactly copy them into a survival
region objects will then continue to be
allocated in Eden regions and after a
while if an object survives multiple
John collections they are compactly
copied into an old region so as your
program keeps running more and more
intermediates will be used for
allocations young collections will
happens the objects will be surviving
and moving into survival regions some
ways survive for longer times filling up
more and more old regions with live
objects and sooner rather than later g1
will have to start a concurrent mark
cycle to find out in the old regions
which objects are actually in use in
which or n't so the job application is
not stopped during this time the
concurrent mark will be running
alongside your job application
traversing the heap and finding all
these live objects in the old regions
then once the concurrent marking cycle
is finished even survive an old regions
or collected in so called mixed
collections the live objects are again
compactly copied into survivor and old
radians so on the side here in this
example we are taking all of the Eden
and survival regions which must be
collected every time and also shows in
two old regions to collect the result is
time goes on G when we collect more and
more of the old regions so more and more
of the heap will become free and then
once they're no longer or an old
gradients suitable for collection for
example they might contain too many live
objects too is not worth collecting them
jibon will once again resume doing junk
collections thus g1 moves and
transitions between the following states
it starts out by doing young collections
which will copy objects into survivor
regions and promote them to old regions
after a while as the heap is getting
more and more full a concurrent mark
cycle will be started the concurrent
mark Sotka is not only running
concurrently with your application they
can also happens young collections
during the concurrent mark circles
running once the hard mark finishes g1
transitions are going to do with mixed
collections and once they are no longer
and in suitable regions to collect it
once again transition back to do enjoin
collections and so the cycle repeats
so we wrapped a bit of knowledge about
how g1 works we're going to look at five
major improvements and how they were
done that has happened since the JDK 8
so we're gonna have a look at string the
application introduced in 8020 we're
gonna see cloth unloading with
concurrent marks with shipped in a 2-14
we're gonna see the eagerly reclamation
of humongous regions introduced in 8 to
16
and then the adaptive sort of the
co-current mark cycle this is shipped in
Yeti not just recently and also about
with a lot more efficient collections
that were also shipped in Yeti canine
but let's start out with string the
application so in this example we are
allocating two strings I have one named
conf one and j1 j1 we often put your 1
and they have very similar content if
you look at the slide they actually are
identical and now you might now think a
little bit couldn't we make better use
of the memory instead of having this
duplicated character arrays on the heap
taking up valuable space could we do
this would that be okay or could it be
any problems with the java program if we
were to do this little trick it is
actually perfectly legal and valid and
fine
because in Java like string the
character array value is both private
and final so if we do this behind the
scenes that your Java program will not
notice any difference the way we do this
is that during a collection g1 adds all
new newly allocated strings to a queue
and then after the young collection is
done g1 will concurrently check if any
two strings equals if the two strings
are identical then you can make them
refer I will give one mixed and refer to
the same character array and please note
this is not the same thing as in turn
strings string in turn cares about
string objects whereas during the
application cares about the character
arrays or the value fields and
internally in the AVM they use different
tables this can save a lot of memory and
a lot of footprint on the heap depending
on your application of course if you
have a lot of maybe a lot of SQL
statements that are repeated or a very
that contains the same values this can
be a big memory saver the trade of this
that it will use slightly more CPU due
to the concurrent work going on at the
same time and it might also cost
slightly just a bit longer John
collections so if it works it worth it
or not that depends on your application
how much memory is save and your CPU
requirements you can try this out with
use students application in Yeti k8u 20
and later the next improvement we're
gonna look at this class unloading with
concurrent mark and this is a tricky
subject so objects on the heap have a
corresponding class and those classes
have in turn being loaded by a class
loader when the objects are when all
instances of a class on the heap are
dead that means that the class itself is
dead and of if all closest loaded by the
same class loader are dead that means
that we can unload these classes and
garbage collect the corresponding class
loader now the question is how do we
find out if a class is dead or not
well j1 will traverse the entire heap
and as it does so finding live objects
it will encounter live objects and can
therefore from those novel objects find
out which class they belong to or in
Orion sources of and mark the
corresponding class as live since a
clause can only be unloaded if all
classes loaded by that Clause cross
loader are dead we will mark the closed
address live and all classes loaded by
the class loader as live as d1 traverses
the heap more and finds more and more
live objects more and more classes will
be marked as live and the corresponding
class loaders after the heap has been
hit rate a few when we found all live
objects we can in turn iterate through
the class loader graph and find out
there's an openness a class though there
isn't work that's live that means that
closed or is dead
and we can unload all the classes that
class loader has loaded so in one tricky
sentence after all objects have been
visited then unload all classes loaded
by class loaders that aren't live and
there are two algorithms in g1 that
visits all live objects on the heap
you have the concurrent marking which is
it's really tricky to to find out the
live losses during current marking but
it performs pretty well and then we also
the fall back full garbage collection
here is a lot easier to find out which
which classes are live
it's slow and will cause longer pauses
so in JDK a 240 we finally shipped close
unloading after concurrent marking this
is controlled by the flag cloth
unloading with concurrent mark and it's
enabled by default since 1840 and it can
reduce the need for full full back full
DC's quite a lot in your application if
you load and unload a lot of classes and
again available in a t14 later the next
little trick or improvement or feature
be done is well be done money but one
significant is equally reclamation or
igloo reclaim of humongous regions and
this was shipped in 1860 so let's have a
look at that one when objects are larger
than half a region they are called
humongous in g1 and the region's they
are allocated in or called humongous
regions g1 doesn't copy humongous
objects around on heap because it's too
expensive they are large and half a
region so they take up a lot of memory
so thereby copying them takes a lot of
time something we do not want to do but
on the other hand these objects use a
lot of memory and if they become dead we
want to free that up pretty quickly so
we can reuse it for other objects and
allocations so what we do is that we
utilize the fact that g1 keeps track of
references between old regions as can be
seen on a slide here we have a couple of
old radius regions and one humongous
region we see that there are no incoming
references to that one humongous object
in the humongous region and there is one
outgoing references from a humongous
object but since there are no incoming
references from other objects in old
gradients that means that the only thing
that can keep this humongous object
alive is an object in a John region that
is either in a region or survival region
but remember when we do a giant
collection we will look at all the live
objects in all the John regions so
during the junk collection g1 will check
if drawer and references from a John
Young object to this humongous object if
no references are found from John
obvious we know that nothing is holding
on to this human
we can reclaim the memory and reuse it
later so day 1 can do to this feature
reclaim him along with objects during a
young collection it does not need to
wait for concurrent mark to finish to
realize that object is dead this was
introduced in 1860 and can help quell
loss if you have if you allocate a large
objects so the next feature gonna look
at is the adaptive sort of concurrent
mark and this was shipped in JDK 9 so
this concurrent mark cycle that looks
through all the live objects in all the
old regions again it can take a little
bit of time until it finishes but it's
important that it does finish because if
it doesn't finish then g1 doesn't have
the liveness information needed to
collect objects in the old region's so
co-current marking must finish before
the heap is full with old regions and
the problem is done of course when
should have distorted prior to yet ek9
you had to use the flag initiating heap
or kc % which meant that you set a value
for example 35 and concurrent marking
would be started when the heap was 35%
full now this is obviously a way to
static way to do this and many of you
experience problems with this that the
concurrent mark saga was kicked off too
early resulting a slightly worse
performance or too late resulting at we
couldn't collect old regions so in 9 we
replace this with a much more adaptive
dynamic calculation we do use for the
first collections just as an initial
value to the ergonomics engine the value
of this flag and then we sample runtime
data and see how the applications
allocation performs and how much data
you allocate and then we can use those
samples and the feedback from previous
concurrent mark cycles to determine when
to start off the next one and of course
we always had a safety margin because we
really wanted to finish in time so this
results in much less concurrent mark
failures which in turn saves you from a
lot of this fall back full GCS
this is controlled with a flag - xxg one
use adaptive I hope and this is enabled
by default in 89 and I recommend you to
keep it on so let's look a bit at the
new more efficient collections that we
have introduced in JDK 9 we did a lot of
work going into UDK 9 in fact we had
more than 250 announcements going in for
G 1 there are things all over the place
there are more parallel phase sisters
improved peel up sizing parallel freeing
we have T lab resizing concurrent mark
from rules and a bunch more updates to
the internal data structures for the
garbage collector we have more than 180
bug fixes going into G 1 G C in your
canine so what is the effect of all this
well how much did we actually improve
well the uptake has actually been great
here I have a bunch of nice logos and
code some various things and then I pipe
the slides for legal and out came this
slide so J 1 has been picked up by major
Java frameworks and applications
especially Google applications such as
some very well-known IDs and also
server-side frameworks so many major
companies have also switched or or
switching to g1 for the workloads
particularly those where they care about
the post times but also cares about the
throughput need a mix of those and
remember to always run with latest JDK
release if you are running with D 1
because the improvements are kept being
kept added so you want to ensure to get
the best performance that you are
running with the latest version so let's
look a little bit in to the future of g1
and what is it going on at the moment we
are not I live sitting by we are
continuing improving and developing even
though 9 is just released so for the
next year DK release we are looking
forward to parallel fall back full DC so
the reason that all of you have cell
problems will fall back which is the
full UC is not supposed to happen which
a one but if it does happen it has
really painful in the post so for the
next decade release we are looking
forward to parallel fold back full uses
that even though it is a failure case
you will have a much faster and speedy
recovery
this is being reviewed right now on the
mailing lists and you can see more
details in Jeff 307 on open a decay that
your nuts that kept slash 307 we have
also made significant improvements to
the core scanning so of course then it
scanning is a detail of how g1 works and
it needs to perform quite a lot of it so
this summer we revamped the code and
improved it quite a bit which resolved
in a nice boost and shorter poses but we
do not stop there we are continuing to
push even further continuously and at
the moment there are patches going on to
rebuild the remember sets concurrently
we haven't looked into those today but
remember sister our key data structure
into how g1 works and in the future we
can hopefully rebuild them concurrently
we are also doing a lot of work into the
ergonomics engine trying to improve it
and improve your economic so you don't
have to tune as much but is that g1 can
itself figure out what values to use and
what flags to set now if you will want
to stay connected and I hope you will
please join the community hotspot - TC -
use at open indicator java.net there are
a lot of experienced users on that pain
list including the GC developers and to
all you users who are on there helping
each other thank you we really
appreciate that you knew the ones who
tuned a lot and have a lot of experience
helped out the newcomers to the
community and as a questions we the GC
developers also read this mailing list
but unfortunately we don't always have
time to answers so again thank you for
your Co providing answers you can also
find us using I am on OpenJDK channel on
IRC top c.net
we can chat with us if you have any
questions we are usually around and
lastly but not least you can find me and
several others of the JDK and JVM devil
in the DevOps corner in the Oracle
developer long share in Moscone West you
can learn more about working in 2g one
at open indicator java.net and learn
more about worker and java at work on
java if you're on twitter please follow
at OpenJDK over at worker and the
hashtags java one and DevOps and with
that I would like to leave say thank you
and the jumpy of time to questions so
yeah question
no I the question is I'm gonna repeat it
for the video and they do I have any
performance numbers that I can share
with you or benchmarks result and no I
don't have anyone I can share with you
one slice today unfortunately but please
try it out and see how it performs I
think you will be hopefully satisfied
yeah question
the story come again please yeah so the
question is how big are those regions a
region can be anywhere from one megabyte
to 32 megabytes it depends on the you
can set that yourself with - x6 g1 he
produces but I would probably recommend
that you leave do you want to select
appropriate so I have the region it will
look at the heap size in total and then
decide but if you are having problems
with for example humongous allocations
and humongous objects then you might
want to bump it up a bit
yeah question again over here
yeah so the question is if an object is
bigger than reading size I said that the
readings might be as small as one
megabyte what if you allocate for
example one and a half megabyte byte
array for some R no image data or
something
well when G 1 allocates then a humongous
region and a humongous region can span
multiple regions so the object will be
consecutively laid out in multiple human
resilience in this case too if you have
a 1/2 megabyte allocation and 1 megabyte
regions but it would still be the only
object in those two regions which will
be next to each other yeah question in
the back
so the question is is this features to
eat application that was released in
8020 on by default now it is not on by
default since there is a little cost in
terms of CPU both will concurrent work
and but and also will work you in a pose
we have it off by default so you can opt
into it yeah question the front
so the question is yeah I get the
questions so if the question the
question is if an object is copied from
one region to another region how do we
make sure that no Java threads or your
program is modifying to obey at the same
time the application is stopped the JVM
can stop the java application which you
will not know this besides gee suppose
in the log but the application is
stopped - no no work for your
application is ongoing at the same time
as the object is copied yeah question
air filter so the question is for
adjunct collections are there any
options similar to concurrent marking do
you mean for example two concurrently
find the live objects engine witness
yeah so the candy one concurrently find
it like objects in journal regions no it
can't it will stop the world but this is
based on the hypothesis which is very
very often true that for Java most
objects are allocated either died young
or they live for a very long time so
even though you will fill up the evil
eden regions with quite a few objects
when we stop we only have to care about
live objects and those are usually much
much much fewer than the total number of
objects have been allocated so therefore
we don't have such a problem with to
long-john collections yep question
so the question is have you thought
about maybe using some kind of job
annotations to provide hints yeah
you mean hints for a particular class
yeah no we are not given that too much
thought and we I don't think there's
that much we can use from such hints we
are usually fine by fitting that out in
the JVM itself so no we are not thought
about it and but we might do but I don't
think there is too much we can value we
can get out from that I think there was
another question maybe in the back yeah
I do I foresee any other big
improvements coming up to give one I
actually do think that the ones who held
up here on the sides might of course
differ between you and me but these are
to me pretty big improvements and also
the ones who are looking into rebuilding
remember SATs and improved ergonomics
will also hopefully result in big
improvement so to me these are big to
you I don't know
yeah yeah don't be doing any research
that we really revolutionize GC well I
think about GC like 300 days a year so
yeah we do think a lot about it I don't
want to stand up here speculating what
goes in and what comes knocking but yeah
there's a lot of activity that we are
doing so hopefully that will result in
some nice improvements it doesn't always
do that unfortunately but a lot of the
time we can make some pretty good
instruments and we will continue to do
so yeah question
yeah so the question is how much does
the concurrent mark reduce the need for
or the time for a full UC so G 1 doesn't
useful you see in its normal operation
as you saw on the slides even prefers to
move between young collections and then
transition to young collections and
concurrent mark and then transition into
mixed collections instead so it will
collect the old radiance incrementally
over a number of mixed collections and
preferably don't have to do a full
collection at all which means in a lot
lot smaller forced times compared to
full collections so hopefully we'll
concurrent marking and the mixed
collections you can avoid felices
completely and don't have to have them
at all</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>