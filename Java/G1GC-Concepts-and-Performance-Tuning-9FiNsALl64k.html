<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>G1GC Concepts and Performance Tuning | Coder Coacher - Coaching Coders</title><meta content="G1GC Concepts and Performance Tuning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>G1GC Concepts and Performance Tuning</b></h2><h5 class="post__date">2017-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9FiNsALl64k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right welcome everyone and thank you
so much for coming I'm Eric and today
we're going to talk a bit about g1
concepts and performance tuning but
before we begin I'm gonna let this slide
hang out there for a few awkward seconds
for all of you to enjoy alright let's
have a look at today's agenda we're
gonna start off by looking at three
important properties when it comes to
garbage collection throughput latency
and footprint we're now gonna move on to
see how you can measure the JVM and the
garbage collector after that we're gonna
get into some tuning and in the end
we're gonna talk a little bit about the
community but first who am i up here I'm
Eric I like to program garbage
collectors I work at Oracle in the JVM
garbage collection team and has done so
for approximately six years and for the
past three years I've worked on the g1
garbage collector and I was a reviewer
and frequent committer to OPI decay so
let's go into our first point for today
throughput latency and footprint these
three important properties can roughly
be defined us for free put the number of
requests per second so if you have a web
server or some other back-end service
the number of requests you can handle
per second for latency you can think of
that as the maximum time for a request
and for footprint well that's usually
consider just a memory usage of a Java
process and we're gonna look about the a
little bit more on each of these
properties in detail so for throughput
we usually measure that as the total
running time of the Java process and
when it comes to garbage collection it
can differ a bit between different GCS
how much they contribute to the total
running time some collectors are going
to pause so stop the java application
and these poses are of course gonna
contribute to the total run time of the
program but there's also some more
subtle differences Jesus can do
different optimizations during a pause
and also while your program is running
so different collectors can result in
shorter or longer total running time for
the same workload and when it comes to
fruit you usually care about that when
you have more
pache kind of like workloads for example
when you compile your java source code
with java c you don't really care too
much how long the JVM is post during the
completion you just want your source
code to be compiled as quickly as
possible also you might have offline big
data jobs running or you have some
scientific computation where you're not
really interacting with the program just
tell to start and you want to get the
result back usually we measure this as
the again the total running time or the
output during a time unit for example
requests per second or something similar
the second property we're going to talk
about is latency and I will load you in
here probably concerned about this
usually this comes up when you have a
service such as a network service we
have some back-end service and you have
a often you measure the request time so
how long if a user wants to see your web
page a long time from that they load the
start low the patient will get a result
back this is very important and often
you see diagram such - - slide where on
the x-axis you at the time on the y-axis
you have the request time and DC
contributes this or is a problem when it
comes to this because if the garbage
collector decides to pause your
application that means it will
contribute to the request time and
usually when we talk about latency we
have to think a little bit more than we
quantify it what we often do is that we
sort the request types from longest to
shortest and notice I dropped label on
the x-axis this is just a sort and
number of request types now and then we
can start to quantify what it means
tell lower or higher later this now we
can say for example well 95% of my
requests finished in 50 milliseconds
were shorter and of course we can do the
same thing when it comes to the garbage
collection process we can measure the GC
pauses and note there it's not always
the case that the longest request had
the longest see suppose there are a
bunch of other things contributing to
the time of a request there could be
Network latencies they can be io going
on you might have to read something from
disk that contributes but we kind of
course do the same thing when it comes
to GC pauses as will be requests types
we can sort them from longest to
shortest and now
can start to quantify properties about
our DC post times saying for example
well 90% of my DC poses were shorter
than 10 milliseconds when it comes to
latency you often care about that we
have interactive workloads for example
if you're trying out the new yell tool
in Yeti canine any types of expression
in the HL you don't want to wait for a
long time until you get the answer back
you want to see it immediately and get
responsiveness also network services
again a some kind of web back-end you
care about the requests coming back to
the user quickly and also in graphical
applications if you are rendering things
with a framerate you don't want to frame
to take to a long time because it will
cause slugging slackness to your
application and when we measure this we
usually talk a bit about the percentile
of a time unit for example the 95th
percentile is 50 milliseconds that means
that 95% won forces were shorter 50
milliseconds and the last properly we're
gonna see a little bit about is
footprint and here we see a little bit
of an x-ray of a java process going on
and what contributes to the memory usage
of such a java process of course the
bulk of the memory usage is probably
going to be the Java heap itself which
contains lots and lots of Java objects
but there's also other things going on
such the C heap or the native heap that
the JVM can use to allocate data
structure it needs to support its
algorithms there might be anonymous
pages mapped in with M map they will of
course also be gifted code that also
takes up space for your process and some
other things going on and when it comes
to GC it also contributes to this
because different algorithms might
result in smaller or larger heaps
different DC algorithms can also consume
more or less native memory in order to
support its algorithms and also some
enough pages etc
and if you are concerned about footprint
you are probably working in a bit more
memory constrained environment for
example you might want to program to run
on a Raspberry Pi and IOT device but
it's also starting to sort of become
popular or a frequent problem again when
it comes to containers that you want to
pack a lot of JVMs or containers onto a
single machine and we usually measure
this as the memory usage of a process in
megabytes or gigabytes so the problem
here is it is usually hard optimized for
all this properties at the same time
often you have a trade-off you can
optimize for one or two of them but then
you will have to sacrifice third one a
bit sometimes there are some gold
optimizations but that is not too common
what's very important is that you define
success when it means for your program
to perform well in terms of your own
application for example if I'm serving
up a web page then I might say that well
all my users visiting a web page or at
least 99.9 percent to them should get a
web page back in 300 milliseconds or the
program should run wrong on a small
raspberry pi zero or the big day it
knows as the object finish in four hours
these are properties of your own
programs no one cares if you have a very
place in a fast JVM but your program
runs slow what's important is that your
program is fast and if that means you
have the to me a VM that might be it but
please remember it's all about how the
user perceives the application of your
performance not the JVM itself so we
looked a little bit about these three
properties and now we're going to see
how we can get some data out of the JVM
so performance problems can come from
any layer in the stack you have your own
application which might have data
structures libraries algorithms that
perform sub-optimally the JVM itself of
course that is running your application
might have problems with the JIT with
locking with synchronization with GC the
operating system the kernel you might
see problems with schedulers with
transparent huge pages locking again you
might have problem with a sealed library
in the user space of your OS that
performs suboptimal a and finally you
can also of course have problems with
the hardware itself may be an outdated
firmware that doesn't have all the
latest performance enhancements there
might be problems with virtualization
memory bandwidth etc but for this talk
we're gonna focus on the JVM and
particularly the GC but if you really
want to achieve maximum performance
you're gonna have to take your whole
system into account and look at various
other things so if we want to know more
about to give them how can we get some
data out of it well we have two main
options here we have Java flight
recorder which is enabled by their flag
- x-axis tower flight recording this
will result in a binary recording a
binary format and the you choose which
events you want to subscribe to
subscribe to and get the data that in
the recording and that recording can
later be viewed usually in Java Mission
Control you can also use text-based
logging in JDK 9 you had the new unified
logging that was introduced behind the
flag - X log the logs are in text format
and here when you choose what the kind
of data you want to measure you use tags
and levels to describe what information
you want to get out of the JVM and of
course these text files can be viewed in
an editorial of your choice and we're
going to look a bit more deeply into
those two options in turn and let's
start with Java flight recorder so with
flight recorder today in your k9 you
will write java XX unlocked commercial
features and then start flight recording
give it a filename recording dot j4 in
this example and then run your
application after application is done if
you do LS in the same
Factory you will find a recording of j4
in there and the recordings the data you
get in them or event based issues which
kind of servants you want to subscribe
to and get that data in the recording
you can select these events in a JFC
settings file and in JDK 9 you can also
create your own events that is new for
you k 9
this is a very powerful feature you can
create events in your application that
will end up in the same recording as
events from the JVM itself you can
correlate maybe you can see that you
create an event when you start to do
your reporting analysis job and you see
that when you got that when you also got
an event saying that for example the GC
took too long time or etcetera and now
we can very easily correlate between
these two events happening and see that
well this was maybe the cost and this
was the effect recordings are viewed in
Java Mission Control or JMC for short
JMC 6.0 was released alongside Oracle
JDK 9 and you can use your emission
control to start recording so you don't
have to use the command line you can use
the MC to get the recordings going you
can also in JMC configure which events
you want to get data from and in
starting in games is six you will also
get automatic analysis your recordings
so JMC as a rules engine that can did
use what has been going on based on the
events in the recording and if you want
more information see oracle calm /
Mission Control for more details about
JMC and here's a screenshot showing what
James it looks like when we look a bit
more into detail at the garbage
collection information logging the other
choice for getting data out of the JVM
so JDK 9 introduced a new flag - X log
and the unified logging framework so the
format for the options to enable logging
is in simplified form - X log is like a
tag you select which level you want
information on the tag and you tell log
in subsystem where the log should end up
on esterday out a city or arena file
perhaps for an example here on the slide
we see that I want for all messages
tagged with DC I want the info level on
those if the or messages tagged with DC
plus faces
I want the debug level on dos and for
safe
almost
just tagged with safepoint I want them
on the trace level and I want all this
in the file GZ - logo text for more
details on this command line flags and
how to specify the syntax you can see
Jack 158 on open a decade of java.net
slash slash 158 and for an example what
output looks from a log here I'm just
enabling GC and since the fourth level
is info I will now get one messages
tagged with GC on the info level and
then you also run your application and
to start out we see that for each line I
get a few decorations so the first
columns or in this case you get a
timestamp when was this log message
written you will see the level so I'm
running with the default level which is
info so all my lines have the info level
I'm also getting logs that are tagged
with GC and only GC so here I'm getting
C which tags this message hasn't of
course only GC and then the message
itself and here the JVM is telling you
that you are now running with g1 looking
into a bit more what a G suppose looks
like on this kind of logging level you
again see the timestamp the info level
the GC tag and then we come into the
actual log message and for each log
message you will get a GC ID here for
the first one is 0 they don't have to
come in consecutive order it is just an
identifier because we will see later
there might be more log lines for a
single GC and then the ID helps you to
identify which lines belong to which
garbage collection posts it tells you
what kind of post this was this was a
young post apparently and we will see
where that is the reason for the post
this was a recreation post the heap
usage before the post after the post and
the capacity how much memory could have
grown too and the thing was to your
concern about the length of the post
itself alright so we looked at how to
get data order JVM and do some
measurements now let's get in a little
bit more into tuning so tuning often
starts with a problem that you are
noticing maybe a request took too long
time when you had in your performance
lab you discover that the CPU of one
your service is hundred
and utilized or the Java process
throughout the memory you need to
understand why and what happened and
what is going on in there
so in all these cases I usually apply
the method of first I measure to see
what has been going on then I need to
understand why was this happening and
when we have the data and we have an
understanding of the problem they're
making often tune around it and so the
issue but first things first
when you start the queue and start to
measure you want to optimize something
use a minimal number of Aeon Flux to
begin with we see many examples where
people have been inheriting previous
colleagues JVM flags for years maybe in
their fifth generation there are so many
flags in there most of them might not
even apply any longer there might be
conflicting flags flags for different
kind of garbage collection in the same
command line so just start out with X MX
to begin with get a clean fresh slate
when you starting to optimize please
rely on first hand after it information
for yet ek9 and my colleague Thomas just
rewrote the entire g1 tuning guidelines
so they are freshly rewritten for 9 with
all the latest info so please have a
look at that document and much of this
presentation is of course based on this
it will help you out when you are tuning
again g1 has been around for a long time
there are much outdated information on
the web in various blogs talks etc so
please use up-to-date information when
you start attune and finally use as
recent JDK as possible this is
particularly important for g1 which has
improved a lot in more recent years a
releases alright so the problem we're
gonna look at today is too long poses
this is often what we hear from users
that they are concerned about and want
to tune and again why do we care about
this well if you have some kind of
interact application and the JVM and in
GC this case poses your application you
will have longer requests times or you
will drop frames etc so we want to
shorten these poses in for interactive
applications your first go to a flag
here is going to be
Maxie supports Millis because this is
the flag that in many cases drives D
ones or economics engines so Jiwon tries
to keep a post target and this postdoc
is 200 milliseconds by default if you
increase this post target and you give
the higher value let's say I'm fine with
500 millisecond pulses that means you
will get more fruit put out of your
application but you will also get higher
latencies because you are saying I'm
fine with 500 millisecond posters and if
you're fine with that in turn you will
get better throughput on the other hand
if you say that I want really short
pauses then you can decrease this value
to for example 100 milliseconds or 80
milliseconds that of course comes with a
cost
there again these trade-offs always show
up as you will get less Rupert but on
the other hand you will also get shorter
poses but what if setting max DC for
smelliest isn't enough you set it to the
value you want here I'm running with 200
default but still these poses seems to
be a bit too long we have one at 220 170
and then we have a really slow one at
400 the first thing I look into is what
kind of force is this because you need
to understand in order to solve this
problems we must understand what's going
on otherwise we ask on a guest us at a
bunch of JVM Flags trying randomly after
something seems to work and that won't
lead to any good so again start looking
at the kind of post here we see a few
different kinds of forces we apparently
have one Yan pose one mixed post and one
full pose and we're going to look at
them in turn and see what we can do
about these problems so to begin with we
will see a little bit more about the
joint poses and this young post
apparently run for a bit too long to
other 20 milliseconds compared to 200
and they weren't the soleus problem we
must remember the steps first we measure
and we have measured and gotten a date
out then we need to understand why is
this happening what is going on inside
the JVM when we have this knowledge we
can tune around the problem but do we
have sufficient aid in this case or do
we know enough no I don't think so we
need to know a bit mobile young
connectionist and what is going on so g1
splits the heap into multiple regions
you have Eden regions and survival
regions this
come together known as young regions
there will be free witness on the heap
with no objects inside them
River also the old regions an object
stores out by being allocated into an
Eden region then after as it a John
collection happens and it survives a
giant collection it will be copied into
a survival region and if it survives
multiple yarn collections it will
eventually end up being promoted into an
old region looking at the heap prior to
a giant collection you see that all of
our Eden regions have objects inside
them and also the survival region the
orange objects are live those are the
ones that are actually in use so g1 will
find this orange objects in the ether
and survival reaches the live ones and
it will compactly copy them into a free
region and update all the references so
that the world looks sane again when the
jvm when the job application resumes so
f is for a free region so we copy the
compactly copy the live objects into a
free region and afterwards when is
copying is done we will as a result
havin the free region turn into a
survival region and the Eden regions
turn into three regions and can be once
again used for allocations as you see we
started out with one free region and
have a compactly copied four regions
into one free region and now we have
four free regions so we have the heap is
more dense more compact so we can reuse
the memory for new allocations so
looking at this posts we now have
understanding of what is going on a bit
more and tirion collection but do we
have enough data no in this case we
don't so we need to enable more logging
and now I'm going to say - X log G store
that means I want to lag log all tags
that's including at IDC so there might
be log messages including GC but also
other tags and now I want all the lines
with GC and potentially other tags
inside them so let's see what we get
when we do easy store Wow now we got a
lot more information and here we can see
that DC ID helps us out by so we can see
which lines belongs to which garbage
collection and these all belong to GC
154 we can see we still have the John
Force
where
thing apparently 18 workers for this
evacuation so things are being run a lot
in parallel with their different faces
apparently we have the pre evacuated
collection set evacuated collection set
and post evacuate accept and then some
other time we can see the radiant
distribution prior to the collection
after collection so we had three hundred
and fourteen in the region's prior to
junk collection and as we now know to
eat in radiance we will compactly copy
the objects into three regions so there
are sierra ones afterwards they have all
become free we had thirty four survival
regions going on today going into the
collection and when we were done the
data resided in 32 survival regions and
the old radiance increased from four
hundred fifteen to four hundred forty
nine
we also got the information about the
among students i'm at a space we will
not go into that today and finally we
get the heap usage before and after the
capacity and the time for the post
itself so if we look a bit more closely
here we see that it seems like this face
evacuate collection set takes almost all
the time we see it took fifty two point
five milliseconds out of 54 we also see
that there seems to be quite an increase
in old regions and we're also using
quite a bit of survival regions so again
evacuating collection set took time
there was a proximate in ninety seventy
percent of the post man helped make seem
to survive we had to use thirty four new
algorithms and forty two new survival
regions but to really get to the bottom
this we need even more information to
finally see what happened here so we're
gonna enable debug level on all log
lines including the tide GC so let's see
what we get we're gonna get a lot of
output this is not something you wanna
run in production you will quickly fill
up to log to a lot of info but if you're
tuning and drilling down into a specific
problem this might work will help you
and so i just copy the part of the log
here there are a bunch more information
about the GC but now we will see all the
phases under sub phases listed in the
log and we will see that the face that
took a lot of time was OB copy and now
you see the face is labeled with mean
average max that's because all this is
being run in parallel and concurrent at
the same time so the average time a
worker spent you doing
it was for approximately four to nine
milliseconds and the most time worker
took was fifty minutes again so
apparently the post is spent doing OB
copy so what can we conclude well
copying objects takes time but why the G
one has two copies so many objects for
this pose well most objects are supposed
most young objects or supposed to be
dead and this is based on the hypothesis
that most objects either die young or
they live for a very long time if this
is not true free application you might
have to tune the number of John regions
that you one can use you might have set
the flag CG one new size present in g1
max new size percent perhaps you have
more information about your application
than g1 can deduce because I ergonomics
engines will try to find an optimum
value here but you might know something
that you want duster for example you
know I'm going to generate a big big
report or something and once the report
is done all the basic cannot die but if
g1 decides to pause before the report is
done
there might below a live objects around
that has to be copied also if you just
increase the number of John regions a
bit the objects will have more time to
die and it will be less live objects
Fuji want to copy moving on we will have
a little look at a mixed pose and the
good thing here is that you will now
have a better understanding of young
collections you can bring that knowledge
over into mixed collections because they
are very very similar the difference is
that a mixed collection collects both
young and old regions and as we've
already seen the young regions can be
all disappear
the young readings can be bounded with
g1 max new size percent but what about
the old regions can you bound the number
of old regions in a pose we need to
understand a bit more about mixed
collections in order to answer a
question so if you look at this heap on
the slide here we have a bunch of eden
regions with orange level between them
we have two old regions into three
regions and the old radius was a few
live orange objects what you want to do
for a mixed collection is going to
select all the young regions those are
even a survivor once they always had to
be
collecting opposed and one or more old
regions and definitely do the same thing
as in a giant collection the live
objects would be compactly copied into
three regions and then the regions in
this and then the old radians and
younghui s that were collected will
become free regions so again very
similar the code is actually almost the
same for a young and a mixed collection
so g1 selects a collection set of
regions we can bound the junk part of
the collection set with g1 max new size
% and we can bound the old part with g1
mix GC count target g1 mix this account
target is by default 8 and that means
that Jia will strive to collect all old
regions during 8 mix collections if
you're looking for lower latencies this
might be a way to low value let's say
you have 800 old regions because they
were rather large heap and you want to
achieve short poses you don't want to
copy a little data each post you want to
spread the work out during many mix
collections well if you have 800 old
regions and you have a mix GC contract
of 8 you might end up with approximately
100 old regions permits collection if
most of regions are rather full and this
can be way too many you see two way to
long process and then it's a good sign
you might have to increase mix GC count
target to a higher value you can also
tell you one that it doesn't have to do
so much which seems a bit strange but
you can soon it to do less work with the
flags for example mix GC live threshold
percent which by default is 85 and this
flags would tell g1 went to consider
collecting an old region because if a
region is mostly filled with live
objects and then we just kind of shuffle
data around on the heap we're going to
move objects there are one was old and
live from one region to another so on
the slides we haven't really gained
anything I mean the point of all these
collections is to collect multiple
regions with a few live all between them
into one single region so we can reuse
the other regions but if a region is
almost full now we won't really get much
monomer back and g1 mix dive yeah do you
want mix this is like threshold % tells
g1 the threshold who ran to consider
collecting an old region and by default
that is 85% full if you decrease this
value that means that g1 will skip
collecting if said 65 percent or 55
percent then g1 will skip collecting
those old regions but this might result
in more heap usage we're going to leave
more garbage lying around on the heap
the other flag is g1 heap waste percent
which almost as well means in name which
allows more garbage on the heap so this
is a goal for g1
it says that I'm okay with leaving by
default 5% of garbage lying around on
the heap if you are ok with more garbage
on the heap that means that even can do
less work and you can increase this
value but again a warning this will
result in more heap usage and again we
start to see this trade of you we got
shorter poses but perhaps more footprint
alright we saved the worst one for last
so here we see a full clip pose and
apparently this took way wait a long
time if a typo story of 200 we are up at
400 here so this doesn't seem too good
what is going on here if you see a full
collection that's a bad sign they are
not supposed to happen this is a failure
mode of d1 and it is clearly not running
optimally it is very important for you
to understand why a full collection
happened the good news is that it's
often pretty easy to find out where full
collection happen and work around it but
it's very important that you do it if a
full collection shows up in your log or
in your day for recording you need to
gather understanding of what was going
on because this is again a failure mode
so in the log you will see the posts
here the full post at the bottom bolded
if you just look a little bit earlier
into the previous lines you will notice
this little line in the previous john
collection to space exhausted what could
that mean well during a John collection
as we've seen g1 will try to compactly
copy all the live objects into a free
region well what is a lower of live
objects in the young regions and not
that many free regions left on the heap
well we will get a to space exhauster
that means that the war
that much space to copy the live objects
into so instead the the Eden regions and
the incoming survival regions will just
be turned into old regions we won't
almost free up any memory and as a
result we will eventually pretty soon
after run into a full collection and
here come out ask yourself what I didn't
even do a mixed collection here I mean
if we look again there were a couple of
old regions there couldn't we have
collected a few of them freed up some
memory and reuse that we must understand
a bit more about g1 to answer a question
I understand what we didn't do what we
did a junk collection and not an old
collection or mixed collection so on the
previous slides we've seen only just
vaguely hinted at well there's going to
be this orange live object but never
really told you why they are there how
did you even find out what was live and
what wasn't live so J one finds live
objects in young regions every time it
does a giant collection there are
usually a few live objects in the jungle
region so this is pretty quick and it's
done during a force however for the old
regions of which are often plenty g1
we'll concurrently find all our objects
and this can is called concurrent
marking and can take a bit of time
especially if you have a large heap and
the good news is that this will not stop
your job application this is running
concurrently at the same time as the job
application is running but the problem
is that Jamin cannot collect a region
without lightness information if doesn't
know which objects are live or dead it
can't know which space to reclaim so
mixed connections require concurrent
mark to finish and why is that a problem
let's have a look at an example so as
your application starts out you will
allocate objects into Eden regions as
you allocate more and more you're going
to start to fill up more and more
ingredients and d1 will decide up now
it's a good time to pause you have
filled up quite a few million regions
and your young collections it will find
all the young live objects during that
post it will compactly cop them into
surviving as we have seen and as you
guess here on a timeline this is a
little post where your application is
post and I will continue running
now as time goes on more and more of
these young collections will occur and
eventually objects we start to survive
more and more young collections and will
be promoted into old radiance again time
continues more and more pauses and now
the old regions are starting to fill up
as well but from g1 point of view they
are being filled up with like objects
believers can't really tell the
difference at this point about the live
in the Adobe Act in an old region now
it's a good time to start the coherent
mark because we need the concurrent mark
to finish before we run out of free
regions on the heap so here you can see
that the concurrent threads are kicked
off on the time axis and it's being run
at the same time as the vacation is
running so there's no pause in there
there might be young collections going
on concurrently really concurrent
marking that is perfectly fine and these
giant collections might promote more and
more objects into old radians so now
it's getting rather heat full-dome and
hopefully concurrent mark is about to
finish soon so we can reclaim memory
from old regions and luckily enough it
just finished so now that concurrent
mark finished jeeva finally gets the
liveness information it needs and
discovers aha there were only a few of
the Excel of in each old region and if
we go back to our problematic post that
was very long we saw at the bottom we
have the long full post it notification
failure we look a bit further up we saw
the two basic sauce hood okay they
weren't enough survival regions for a
yarn collection to co-publishing to and
if we look even further up we see that
oh there was a concurrent cycle started
and concurrent mark was kicked off but
the important thing here is what we do
not see in the log we should we do not
see at the concurrent cycle finished
concurrent mark did not have time to
finish it didn't finish in time the g1
couldn't get the lioness information it
needed to collect old regions and
therefore when they were no more free
readings available it had to fall back
to the failure mode a full collection in
Gaelic nine we introduced adaptive sort
of concurrent cycle this means that we
will driven by the data we gathered
during run time of your application how
it behaves and our policies we will the
kickoff the concurrent mark threads
hopefully in time this is driven by the
economics and
but you might say that I'm really
concerned about this I really want to
finish in time so you can if increase g1
reserve percent which is by default 10
to say that okay I know that you can
calculate fairly well when to store in
car markets but please have a buffer at
the end of three regions so that you
really do finish in time and if
something happens during a card marking
for example you get your blog post on
Hockey News and suddenly you have a too
many visitors to your website and a lot
of objects are being allocated as a
result you might need a little bit
slightly larger buffer you can also
increase the heap size to give
concurrent marking more Headroom and
more time to finish as it traverses the
heap it is very important that if you do
get a full collection as you analyze not
only why it happened but also the
outcome of that photo collection
particularly if the full collection
didn't free up any memory that means
that either the heap is too small or
rather you have a too large number of
live objects for heap without size or
you might have a memory leak in your
application filling up the heap we all
be student villi but you are some how
holding on to them looking in Java
Mission Control here we see an example
of automated analysis introduced in
James's 6.0 and we see that the full
collections get a full 100 severity
score that means that this is a serious
problem and it also says the g1 garbage
collection will use but the JVM too
diverse here old collection and we see
that there where a GC is stalled and you
need to look into this if you think that
you might have a memory leak and you're
not really sure if you see the outcome
most of the heap was full and it
shouldn't really be that's robux you can
move on to the allocation tab in JMC
which will tell you which objects has
been allocated of which type will also
give you the stack traces where was that
those objects allocated from so you can
do a drill-down analysis and understand
why did you get a full heap and where
could a memory come from so we looked at
three kinds of forces and we use the
same method in all these cases we
measured either using logging or Java
flight recorder we got a better
understanding of how it worked by yeah
you guys by watching this presentation
or you can read that Union guidelines so
you know what is going on and why could
have cost the longer pause and then we
tuned to work around it and achieve
better performance so we've seen a bit
about the free properties throughput
latency and footprint we looked how to
get data from an instrument a JVM we
seen how we can tune around and tune for
lower latencies for the ball for all of
young mixed and full forces and now we
want to talk a little bit about the
community so if you want to engage with
us the GCC developers and also many of
the performance experts and people
working will go up with collection and
orchestration tuning please sign up to
host port GC dues on Oprah indicated
java.net and also thank you to all of
you who are helping those who are more
experienced helping out newcomers and
analyzing the logs we did you see
developers ourselves you are also
reading this list but unfortunately we
might not always have time to answer you
can also join the OpenJDK RC channel on
IRC that of c.net if you want to chat
with us and while you're here at yellow
one please stop by the Oracle developer
long chain was Kanye West I'm usually
around in the DevOps corner you can
learn more on open educated java.net or
work on java and if you're on twitter
please follow at opening decay or at
worker Java and DevOps and thank you so
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>