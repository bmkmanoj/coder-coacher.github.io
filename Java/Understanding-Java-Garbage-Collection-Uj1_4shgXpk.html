<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Understanding Java Garbage Collection | Coder Coacher - Coaching Coders</title><meta content="Understanding Java Garbage Collection - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Understanding Java Garbage Collection</b></h2><h5 class="post__date">2017-10-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Uj1_4shgXpk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">see we've got about another 30 seconds
before the time but just out of interest
how many of you are how many how many of
you have this is the first Java one
they've ever been to cool how many have
been to a previous the other one okay so
um audio can you test for the back can
you guys hear me better now in the back
I'll try if I speak louder does it reach
okay I'll try and do a little louder on
the voice but if you can pick it up a
little there because that's above normal
well it's good to see so many fresh
first time in Java one people that's an
interesting mix for the audience usually
we get about a 3/4 to 1/4 ratio but this
is good subject we're gonna talk about
is right up there hopefully you're in
the right room
I'm guilt na we're talking about garbage
collection in Java and just to set the
right expectation for the for the top
there's a little bit of echo at least
for me to set the right expectations for
the talk this is not a a how to tune GC
talk this talk is focused on how GC
works how the machine works or how the
mechanisms work and the idea is that if
you can understand what garbage
collection doesn't general in the
various stages and techniques
terminologies and then you can apply
your own brain to the tuning exercises
really so rather than giving you a set
of flags given that are good for 2017
for a specific collective a specific
version of Java and a specific version
of your application I'm gonna try and
get you a feel for what garbage
collection actually behave like so you
could do the job on a regular basis so
now that's the real purpose here you
learn enough to be dangerous and then
you will get dangerous and that'll come
with pain later
um now my work in a company that makes
JVMs and garbage collectors so I'm
really really proud of that and I
promise that I will keep that part we
make the best garbage collected on earth
pretty much to the end there will be a
lot of generic useful education here
that's good for any GPM or any garbage
collector actually in the runtime so
agenda why it's the way we're going to
cover this is we'll start with
fundamentals terminology and mechanisms
will then go and classify all the
currently available production garbage
collectors in Jamie on most of them and
then we'll talk about to stop the world
problem thank you this was no
prescription and didn't talk about you
know what a world where that is salt man
doesn't have it anymore
which like I said I'll keep that in the
middle about me my name is Gil Timmy I'm
the CTO at is all systems I've been
working on garbage collection as a
problem for around 15 years now and
here's some evidence of me working
for those who don't recognize that
that's a trash compactor that's in my
kitchen the job of the trash compactor
if you think about it is to perform
minor GC compactions during the week so
you only do a full GC evacuation once a
week that works great here in cut point
at least then this isn't stopped working
there was a bug in it you can see the
fragments were falling out the building
open that actually happened I thought it
would be funny to take a picture with
the actual garbage collection book but
the most important thing about this
picture is that it was taken in lazy and
I recycle and I need new pictures I used
to look better so I've worked in various
garbage collectors including our garbage
collector called c4
and a process collector I built a lot of
things physical machines virtual
machines that help design CPU
instruction sets and operating systems
and driver ISM runtimes obviously all
the way up to nation scale enterprise
applications with tens of millions of
subscribers all that comes with that so
I've made a lot of mistakes that some of
those that I teach people about but
unfortunately not you know people
usually learn from their own mistakes
different subject that you'll find me
talking about a lot is the notion of
latency and response time how its
measured how it behaves you can find a
bunch of stuff online with me talking
about that and to do one more little
raise-your-hand survey at the beginning
I'd like you to kind of start raising it
and keeping them up as I get to a number
that you recognize or sorry raise them
drop them laughter how many of you use
Java with heaps that are half a gigabyte
or more okay let's first of the room the
rest of you are really tiny now
how many have more than the gigabyte
keep your hands up if not drop them on
about more than two gigabytes more than
four gigabytes more than 10 gigabytes
more than 20 50 hundred can't want to
talk to you afterwards now but the
reality is any of these let me show you
a magic trick I was guessing that this
is where we're gonna group this guess
has been correct in the last ten years
I've been doing talks around this for
about ten years and that hasn't majority
of this row the drop the hands it
that's an interesting observation about
the fact that we don't actually make use
of memory and growth of memory and the
fact that in the last decade we actually
got 100 times the memory for the same
price but we still get the sizes the
same that's a big observation and a huge
reason for them
okay so background why should you know
how garbage collectors work not just how
to tune them and what flags to use why
should you know a little bit about words
I like to use practical stories this
actually happened to me then call it the
story of the good little architect any
Mark Twain fancier and I define a good
architect not by the quality of the
architecture but their but their ability
to actually make people build an
architecture if you come up with the
best beautiful architecture you can
think of but nobody actually adheres to
it you're not an architect you're a
philosopher
the architects actually get people who
build their stuff or at least the
successful ones and early in our career
was spotless garbage collector we
actually ran into their success
architect and along with them and ran
into an 18-second pause and a pause this
collector which was very embarrassing
this was back in 2006 or so so we went
in to see what's going on here and when
we dug into the application to see
what's going on
we found some surprising behavior this
application had behavior that we
normally didn't see and every time we
did a garbage collection we found that
we had to execute tens of millions of
finalizes every time which at least that
the time is very abnormal no because it
was abnormal we didn't bother to make
that a concurrent operation at the time
since then we fix that so now even this
won't cause but it was curious we're
trying to figure out where this comes
from because we just don't see that
normally so we dug into the application
with the customer we found out that
every single class written in a project
that ran for about 18 months over ten
people how to find one every single
class that this team wrote had a
finalizer there was a very good
architect that playing in here
nobody got away from doing this but more
interesting was what did the finalizes
do anybody want to guess what the final
residue exactly so the nothing the the
final answers were putting nulls in all
the references to help the collector out
because you don't want to if this object
cars you don't want to keep references
to other objects right let's help the
collector out by putting those
everywhere well this is the worst
possible thing you can ask a collector
to do it doesn't help it it hurts it but
there is a world where this is exactly
the right thing to do in C++ this is how
do you write set code you have
destructors what are the equivalents you
make sure that if you die you you kill
everything you touch so rough
scanning will collect those two and
whatever else you doing and if you
actually don't adhere to this kind of
architecture you're gonna have memory
leaks and corruptions and all kinds of
other bad things happening
so you need the structures and
everything is equal suppose in Java you
never want destructors or finalizer
unless you absolutely can't get away
from doing and even then it should think
three times before so this is the wrong
thing for Java or any garbage collected
language and it's the right thing for
reference counted languages with
disrupted wine because collectors work
in certain ways and we'll get into that
hopefully become evident why this is a
such a bad practice it's like a thousand
exports more expensive for the collector
video okay so up being this a little
more in general I find that there are a
lot of myths and misunderstandings about
collection a lot of what people think
about collection garbage collection is
wrong and most of the advice you will
find an intern that is the opposite of
correct so even when you read my stuff
you should be suspected it but academic
work tends to be pretty good peer
reviewed academic papers tend to be
pretty good but general internet advice
tend to be terrible especially three
years after it was written so and Google
doesn't forget so here are some basic
things there are different than what you
might think so for example Bob
description isn't a lot better than what
people think at a few things for example
garbage collection is actually the most
efficient possible way of managing
memory it is cheaper than any other
alternative when it comes to cycles
spent for allocation and removal of
dynamic things
GC is cheaper than mono period and we
can prove that I'll get into a proof
later
I know no this is controversial that's
fine
the other one is the garbage collector
basically doesn't spend an efficient
carbon script doesn't spend enough any
actual work looking and thinking about
that object
which is why asking to finalize objects
as a terrible thing because you're
asking you to take something that costs
it nothing and actually do an operation
for object and then the last part is the
garbage collectors at least in Java and
most modern runtimes
will absolutely find all the dead
objects they don't need help they don't
need you to break cycles they don't you
don't have to worry about linked lists
that point to themselves and weird
graphs of objects if it's dead it's dead
you don't need to worry about it they do
a perfect job
a precise job of finding the dead
objects and helping it out there putting
knobs it's just getting in its way
doesn't make it more correct it makes it
more stuff but there are a lot of things
that are worse than what people might
think for example if you're garbage
collector has any form of stopped the
world operation to perform its work I
can all work out if it's rare or not it
will pause for something in the order of
a second for gigabyte of my stuff that
you have you can't get away from that
you can delay and yes there are some
collectors which will actually not do
that thing is one example there's others
in the works but phenom and me if you're
doing compaction and stop the world you
will see the spawns you cannot get away
from it I don't care what other people
tell you now you might be able to get
away for it for an hour or a day or a
week but it is there it's just Swift
over the road beyond that not all memory
leaks the severe winds and garbage
collectors we take care of a lot of
memory leaks that are common mistake
bugs that happen in other environments
but fundamental leaks are forgetting to
forget we're still there if you just
keep accumulating stuff it's going to
grow it's not a magic point the last one
here is very important to stability
garbage collection things to work in the
opposite direction of what people want
from testable systems most of our tuning
and garbage character garbage collectors
has been focused on pushing bad problems
to the future making them more and more
rare not eliminating them but pushing
them forward and that
means that when you've tuned your system
to finally pass a 20-minute stress test
you haven't actually gotten rid of any
problems you've just moved them to
minute 21 free QA this is a terrible
thing because a well-tuned GC system
often takes days or weeks to actually
test which is why are some interesting
tools that help you cause the bad GC
things to happen while you run like the
interesting names
okay let's talk terminology basic
terminology starts with classifying the
collectors and how many of you know what
a pair of garbage collector is okay
bunch of you how many of you know what a
concurrent garbage collectors now this
that is fewer than apparel there's a
reason those two words are synonymous in
English there are some languages I grew
up speaking Hebrew where there's only
one word for both of these but in
garbage collection classification
they're orthogonal they don't mean the
same thing they can create garbage
collector does its work while your
application is running the garbage
collector and your applications are
concurrent with each other we often call
you guys the mutaters you're mutating
the heap you're changing its shape a
parallel garbage collector is a
collector that uses more than one thread
intimates junk it can use more than one
thread more than one CPU to do whatever
it is doing these things have nothing to
do with each other
you could be concurrent but not pal you
could be power but nothing current you
could be neither you could be both these
are just definitions of terms
unfortunately if you read maybe 30 years
back in garbage Millington papers you'll
find these terms actually interchanged
what used to be called peril is nothing
called concurrent but this is probably
good for the last 20 25 years of
academic work at least and garbage
collectors so keep in mind that prowling
collected current are very different
things now what does this stop the world
collector will stop the world is the
opposite of concurrent rather than run
concurrently with your application it
stops the world
in advance and then you get to run later
so these are direct opposites a
monolithic collector or a part of a
collector this model I think is that
that's all the work in one chunk and one
piece of work that you cannot break into
pieces and maybe do in pieces and run in
the middle so long as an incremental
collector is a collector that can take
the work you need to do shrink it into
smaller pieces do a little bit of it
maybe stop the world do a little bit of
it then stop stopping the world but you
run then do the next journey the next
you might say interleaving its work with
the application but not concurrently it
stops you does a little you run
something it doesn't do intervening
incremental collectors are usually stop
the world incremental runners but
there's one very important technical
word in garbage collector classification
and it is used honestly in academic
terms mostly but it's been kind of abuse
from a marketing perspective that is the
simple English word mostly mostly means
exactly what you think it means but you
need to carefully carefully read any
sentence that has the word mostly in it
mostly concurrent means sometimes
thought to cram mostly parallel means
sometimes single thread and mostly
incremental means sometimes monolithic
mostly it's usually what you put in
front of a really nice thing to say I'm
not doing that or anything I mostly do
that but I was honest with you I said
mostly you'll find that in a lot of
classifications okay let's talk about a
few other terminologies precise and
conservative collection ism a precise
collector well let's start with
conservative a conservative collector is
a collector that's not quite sure where
all the pointers are it's good to go and
find junk heap but it's not quite sure
where all the pointers to everything are
no some but not all and it needs to it
as a result be conservative some things
might be pointers might not be pointers
I need to deal with that
a precise collector is a collector that
actually does know when it collects
where all the pointers are and this
difference is very fundamental because
there are some things you cannot do
unless you precise
for example the collector he has to be
precise if it's gonna move a knob to get
from one place to another if you move
one object point A to point B you have
to fix all the pointers to point to it
but what if you're not sure where they
are maybe you left one dangling or maybe
worse here's something that I think
might be a pointer but I'm not actually
sure if it's a pointer an integer maybe
it's just an integer that happens to
have the value that looks like a pointer
I'll change my integer value because an
object later both of those are deadly
mistakes to make you can't afford to do
them which is why without being precise
you will not see any moving objects the
hard work to make the collector precise
is not in the collector itself it's the
information given by the collector by
the runtime the collector just needs to
know where the pointers are but it's
things like the JIT compilers and the
runtime that needs to know at any point
in code where the collector might
collect where all the pointers are for
example at this point in the stack if I
stopped and collected I need to know all
the registers if the pointers all the
call stacks if they're pointers of that
and if I move one code line that changes
that information is carried in in
hotspot on what's called blue perhaps a
few other times as well which the
compilers of the JIT couponers to
produce and next time you need a JIT
compiler writers think that for doing
all that hard work that only it's needed
for this kind of stuff because without
it we wouldn't have foresight garbage
collection we wouldn't have compaction
we would record all the JVM s we have
today news precise collectors they all
move objects at one point or another
safe points are these interesting things
that we do in execution to allow these
for size collectors to work so we could
theoretically have any program counter
point at any point what everything would
be but that's both hard and also hurts
optimization so it is insert safe points
in the execution where we say here we
know where all the pointers are here we
know what all the pointers are safe
points are ranges of execution in the
thread where we have full description of
what the pointers are amount of stuff
between them we may not but there we do
there are all kinds of safe points and
GCC point and safe point I'm using
interchangeably here there are other
reasons for safe points as well when I
say that we bring a thread through a
safe point it means that we get it to
that range of execution that we have a
good description for and don't let it go
past that point and that sounds a lot
like stumping the thread right and
stopping this event is one way to do
that there's one key exception to it
for example J Michaels anytime you call
j9 function including blocking a socket
or a read or anything else anything you
actually enter a safe point now entering
the safe one doesn't mean you're not
running you could be inverting a matrix
in C++ for the next three hours but you
are not changing any pointer states
you're not changing where the pointers
are so you are at a signal we have a
good description for where do we need
safe place to be frequent otherwise
we'll have what I call it time to safe
white problem not gonna get into it here
but it's fundamental either you know
everybody's waiting and this one guy
hasn't come back for the last three
hours
looks like a big pause but nothing has
started working it but there is a local
safe point where we bring all the
threads to a common safe point and that
is what is known as they stop the world
pause the global safe point and stop
with what laws are the same thing
so we talked about some terms let's talk
about some behaviors here are the three
things that all precise collectors in
the practical term will do one of them
is they will identify all the live
objects that there are they will reclaim
all that
that they can prove are dead and they
will relocate objects from one place to
another every one of these things will
happen in a precise collector there's no
real point in being precise if you don't
do all three but let's look at concrete
examples and classic simple algorithms
that do these steps the first one is a
mark sweep compact collector
marking is where you find all the line
object that's step one sweeping is where
you identify all the dead stuff and
somehow the only three cycling it that's
step two and then compacted step three
one two three one two three but
separately there's a separate command
collector called the copy collector
which doesn't do this as three steps a
copy collector from the maddening takes
all the objects from one space and call
it from space say let's move all the
live stuff to a two space in one pass
and when I'm done and the other that all
the stuff is in the two space so from
space is empty
that's a single pass that does all three
of these things find the objects move
them and as a result every claim to
business so I'm going to break that on
the actual faces of the ones I just
talked about as explanation so we can
talk about them in complexity marking or
tracing it involves starting from what
we call roots roots are static variables
the threads and their stacks themselves
things that are the roots of visibility
pointers I can start from and we start
from these groups we do what we call
tracing or painting anything they can
reach that does not get them marked I
reach I mark and then they look inside
of it and keep reaching so I let the
paint and follow everything I could see
and everywhere I go I mark that I've
been there if I get to a place that
already marked that they need to go
there again so I start from the roots
and actually I can reach in now at the
end of one of these exhausts of tracing
passes that starts from the roots all
the reachable objects anything they can
reach you from my root set is going to
be marked line
and anything I can't reach from the
roots I will not be worth like there's a
very important quality here if I cannot
reach it from the root set now I will
never be able to reach it from the root
set again to be able to express a
reference to an object I need to be able
to reach it before an expressive so the
copying the reference rather it's only
reachable thing
so once I've shown that something isn't
reachable it is there it's not becoming
alive again this is why a circular
linked list doesn't have to be tagged
and broken because if I can't reach into
it it's gonna be dead doesn't have to
break things apart
so that's tracing it's exhaustive but
from the complexity point of view it's
work grows with the live set with the
men of live objects and like references
we have to move through but that with
the size of the heat if I have a twenty
gigabyte heat for a hundred feet up I
keep and only have a hundred megabyte of
live stuff I'm only marking 100 megabyte
of live stuff the size of the heap has
nothing to do with the complexity of the
market but if I double the life set it
will grow to swing here to myself
sweeping is a very simple mechanism
imagine I just did a mark and everything
that's alive is alive and if not is not
we sweep through the whole team looking
at all the objects and if they're not
live we somehow deal with them recycling
them every second later putting them in
freeness is one common way to go through
everything everything that's that put in
our fingers we'll deal with it later
this is obviously a simple pass we can
paralyze it or not but it's work is
linear to the size of the heap but after
you manage and visit every single object
regardless of events that are alive if I
double the heap size I double the work
changing the lights that has no
effective in the work like not
significant leaders okay so once we've
marked and swept
we know where all the good stuff is we
have compact this is a simple mark sweet
completo
let's start with why do we need to
compact people often argue about this
but I think the arguments are so
probably twenty years ago or more the
reason we compact is because if you
don't over time your heap will get Swiss
cheese you'll end up with halls
everywhere and even though the heap is
90% empty you have no place to put your
11 kilobyte string because the biggest
Hall is nine kilobytes there's 100
gigabytes of free memory but not whole
big enough in your 11 of your library
and that would be very embarrassing if
we threw an out of memory exception at
that point so because of that we have to
compact now the reality is in the real
world when you have variable size
objects with variable mixes of size
going over time you will threaten them
to heat it's unavoidable there's no real
argument about this in the term it's
just a question of how long can you live
before you have to do this that has a
lot of or variations but anyway we will
need to compact so what this compacting
me what compacting means moving objects
together to make bigger halls and there
are various - thanks for doing that for
example you can compact in place which
is what the marks we compact collected
in topology see does which is think of
it as we marked everything respect
everything move all the life stuff to
the left
that's compacting it to the left then
I'll have all the empty stuff on the
right it'll be configures so we
basically are gonna move stuff together
to get all the empty stuff to be big and
it basically has to then not just move
the objects but we move the objects they
have to fix all the pointers to those
objects so we get us some attract them
and pass and fix them
that's a compacted place there are
evacuation compactors that take and take
a region of memory and move all the live
stuff out of it and now the region is
empty the similar technique from marking
and fixing up the references - but it's
not the difference in behaviour the fix
the point is very important if I moved
one object that object might have a
billion things pointing to it so I have
to scan the heap for every possible
pointer to this object and fix it why we
never ever move
because that would be very inefficient
so we tend to move a lot of objects
together or most of the objects together
because then we get to do one pass to
fix everything up together complexity
wise even though this is a pretty bad in
heavy operation it's only linear to the
life so that we have to move the live
objects and only give to fix the line
references so the heap size doesn't
really change the work yet bring the
light side absolutely okay
the other type of collector I talked
about a coffee collector this one takes
objects from the front space and moves
them to through space starting from the
roots moving everything you can find
puts it in a new space and at the end we
have an empty from space it's actually
very effective very efficient it's a
single pass linear moving to the life
side and is actually a very common news
collection for some mechanisms however a
thing to keep in mind here is it needs a
to space in the to space in a simple
without thinking other things happen
around it collector needs to be as big
as the from space because we don't know
every anything is that we might have to
move everything and this is usually
monolithic you start to move everything
you can't believe anything behind so the
to space needs to have room for all my
stuff which is as big as current heat
because I don't know how much is that in
there that's the simple so looking at
some of the qualities copying requires
2x because of what I just said a mark
compact without the sweeping an
evacuating more compact my 8 2 X the
memory to do a full compaction but it
could stop in the middle because it's
doing the region at a time a mark sweep
contact with compacted place doesn't
need extra memory to compact that's a
nice bus both the coffee and mark
compact are linear only to the amount of
live stuff it's the sweet that grows
with the heat mic sweep impact
and is linear also to the heap and then
mark-sweep and sometimes compact I
didn't talk much about but that's a
common attempted to be related to the
vegan then I talked about the monolithic
part of company let's talk about
generational collection that brings some
of these things together I talked about
the efficiency in the linearity of these
algorithms for a reason generational
collection is a really cool thing that
was introduced to the 1984 based on this
observation
it's called weak generational hypothesis
and if it's most optimist objects that
young means soon after I look it's that
most of stuff out of people dying that
don't equate this with most life objects
are most life objects I think them to be
all they're the ones who survived but
dynamically out of every ten objects I
look at nine dollars that's a very
strong observation it's usually more
than that to work knowing that this is
true or believing that this is true we
can apply what we talked about in
efficiencies to make a very efficient
generational collector when we do that
as we focus on weak on what we call the
young generation the region of the
memory that was recently allocated
believing that the vast majority of this
is that the vast majority is that means
the life set is a very small percentage
of the heap size so I want to pick an
algorithm that's linear only to the live
set and not to the heap size and there
won't be an efficiency as long as they
were of similar size you know 2x here or
something but if I think that only 1% or
0.1% is alive and I apply a copy
collector to that that's a hundred times
more efficient to the sleeping
collectors if this stuff is dead how do
we keep the stuff true how do we make
sure that this assumption remains true
things do survive and if we keep them in
this thing they'll keep accumulating and
this sparseness will stop being true so
things that have been around for a while
we have to put somewhere else
we need the young generation to be done
because this assumption is true about
young stuff and that's what promotion is
stuff that has been around long enough
somewhere else so we keep being
efficient in their generation now there
are places where I've seen people tweak
the young generation too you know with
size and promotion thresholds to never
promote to try really really hard to not
promote all they're doing is making a
single generational collector where
there's no weak generational offenses
and all the efficiency is out the window
you have to get rid of that big spoon
efficiency to be there once we get rid
of them and put them somewhere else we
collect events somewhere else the old
generation when it fills up with
whatever collector would use for them
and this tends to be a order of
magnitude plus filter so today and most
workloads are most I mean the vast
majority of workloads every workload I
look at a GC long form we're looking at
a ten to one twenty to one ratio between
the work we need to do if we have a
generational collector and if we did it
for the same awkward it's a pretty
effective filter there are few other
things about it to do this magic we need
to maintain something we call me and
remember it second we need to know about
the routes into the young generation
should we can only look at the young
generation or not at all if we look at
the whole team game over so we do that
with something that lets us know about
all the pointers from the all to they
honor their various techniques for that
Clarke marking is is one of those and
I'll talk about it a little bit the
other nice thing about generational
collection is we can use something like
a copying collectively in generation but
not have 2x the memory in there because
if we can't fit there the entire from
space in the first place will just spill
it over to Belgium but the young
generation doesn't have to be twice the
size this is why if you look at hotspot
for example the Eden pits to be much
larger survivor spaces it's not that you
know it's gonna fit there it's just if
it doesn't
okay so remember it sets are these
important things that we want cover here
a little I'll say about them is this in
order to track all the points from the
old generation to the young generation
we have to intercept anything that
stores such a pointer or scan is another
way that router will be less efficient
this is why there's a write barrier in
most collectors that are generational
that the tracks all pointer rights so
that it could keep track of the set the
base assumption is this set is very
small sparse if most of the auction
point into the engine the weeks in the
original hypothesis is probably wrong to
begin with so it tends to be very good
at very efficient to work that way and
card marking which is a technique that's
used by all the JVM seems to work well
now if we put all these things together
we talked about terms and mechanisms
let's look at how they come together
into actual collectors the young
generation all the collectors all the
current production collectors are
generational there's some non generation
law sacred generational I'm very
interested in your talk later that
explains how you can have to do a
generation then that are not but in the
production systems this is absolutely
true the youngster ational the
concentration is usually a copying
collector and it's usually a monolithic
stop the world copying every word on
this slide has been defined now and
these are terms that we talking about
not just words the whole generation is
usually some form of a mark compact may
sweetly not the old generation might be
stopped the world like the concurrent
might be partially concurrent might be
increment will stop the world are all
cast with combinations this is usually
where a lot of the interesting
differences are now if we look beyond
just those classifications have stopped
the world and stopped the one would be
simple there are a few known stuff of
all techniques that have been out there
for a while for example one if I want to
mark without stopping the world
the g1 collector the CMS collector do
this one way to do this is to deal with
the simple race that happens if you do
it and plug it up the simple race that
will happen is if I'm going around
marking painting everything I can see
and you know the mutator it's picking up
an object I haven't looked at yet it
puts a reference to it behind me in a
place I visited and won't visit again
then get rid of all the references to it
I might not see the object might not
mark it alive might collect it even
though it's alive and that would be
embarrassing so we have to plug up that
incorrect marking race and there's only
one real concurrent working race that
needs to be plugged up somehow we have
to prevent that propagation from
something that haven't seen to be only
to what a visitor one of the common ways
to do this is with multi pass marquee
idea there is the you you track every
mutation of every pointer in memory
become your right to a pointer you track
that and then when you finish your
concurrent pass you say well that's
probably good but I've missed something
so let's go and everything let's look at
everything that mutated and work on that
and when you finish looking at all the
stuff that you've marked as I've touched
this maybe you're done but maybe you
need to do it again when you feel good
about it when you think the list is
small you might stop the world and
finish the work depending an algorithm
you've used you may be able to make this
converge provably or not
CMS collected for example just three
tries and we'll have some unknown amount
of working set of ten but the g1
collector uses a snapshot at the
beginning marker that can prove that
this converges but these are techniques
that example they involve tracking
mutation as you write every right to the
heat now costs you the other interesting
thing you could do is try to not compact
the entire universe at one time if you
agree that compaction Rob it and then
you try and do incremental compaction
this is fundamentally what you want this
what does that mean we track the cross
region stuff
the pointers between regions as a
different kind of remembrancer and then
we try and find regions that have only a
few other regions pointing to them or
sets of regions is a point to only a
small set of regions we compact the
target regions knowing that I only need
to fix the pointers in a small set of
regions rather than the Hongki but I
hope I could find those sets this
actually works pretty well but it could
run into degenerate behaviors where you
end up with a very empty region with a
very popular object in it so you're not
going to compact that then you'll do the
same for other regions eventually you
have to compact the tiny bit of the even
ligament so those are fundamentally
improvements but they're part of what I
call the denying the inevitable trend of
garbage collection in general we start
with some understanding that you can't
get away from compaction and then we
basically say let's go after the empty
spaces or the cheaper spaces to get
stuff from first and we apply a
generational collector that's a great
efficiency technique but also reduces
pauses for until we have to do the altar
but eventually you have to develop so
then you look at the doulton and say
well I don't want to compact that whole
thing maybe I can avoid compacting it
maybe I can keep things in free lists
for a while until I have to compact it
that's what CMS does but eventually so
you look at that compaction to say maybe
I won't have to do it on once maybe I
could do it a piece at a time and that's
what she wanted us but eventually you're
gonna have to deal with popular objects
and other pressures only need to come
out of that if we look at the natural
collectors you deal with today
there's the classification I said most
of all finder let's look at start with
perrault you see LTC is a classic barrel
collector has a peril monolithic stop
the world copying agent pretty much
everything I say it's paralleled by the
way it also has a monolithic stop the
world mark sleep compact okay it's
pretty much like top
it's efficient it's fast stop the world
for everything it does let's look at the
CMS concurrent mark-sweep collector
common collector use for hot sensitive
applications what do you guys think the
Newton to the young generation collector
of the CMS collector classified what
kind of company
it's a monolithic stopped the world
copying collector it's exactly the same
algorithm classification is the parity
see what does that have to do with CMS
well nothing CMS is named for its old
generation behavior the young generation
is a monolithic stop the world collector
it is not concurrent and it's not March
the old gen is they mostly concurrent
described so in the academic paper that
describes algorithm mostly confer not a
compacting Walton it's got this multi
pass marker that's mostly concurrent
it's got a fully concurrent sleeper
keeps things in Sweetman and free lists
and then it has this doesn't compact
part which is where the mostly comes in
because you can't get away from
compaction so that's what it does when
it has to compact it does a monolithic
stop the world mark sweet compact CMS
apart is a filter between the neutron
and the fold you see it's an effective
filter but eventually you'll have to
focus this is a big reason G one exists
as a collector because of the
realization that you can't get out of
context so let's look at G 1 what does
the new gen of G 1 plus minus G 1 is an
incremental garbage first
Lee well it's a monolithic stuff the
world copying collector you know this
Kevin it's all Jen has a mostly
concurrent marker but it's a much better
mostly than another worker it is
provably
it will provably converge so you can't
run an application it'll make it run
forever but it has a stop the world
mostly incremental convector it does not
compare concurrently it stops the world
for any compaction in the only way it
frees memory is to compare it so the
only way to reach the memory is to stop
the world but it tries to do that in
small increments well I actually have a
quote here from the objective design
objective of the collector it says we
try to avoid as much as possible having
a full TC what does it tell you right
there it has an HEC design by design
it's the site to have afford you see as
a fall out to fall back from trying to
do the right thing with incremental but
you will end up maybe don't take longer
maybe you could use them so for your
application it won't happen for a long
time but by designers a Fugees okay so I
classified the normal hot spot
collectors the ones you can use today
I'm gonna talk a little about this
monolithic stop the world's you see
problem or the stop the world in general
but there are many ways to deal with
some the world GC this is the most
common way so you know you can just go
to the other talks to talk about how did
you fit right imagine that this is not a
problem one may be will tune it so it'll
run this long without a GC with declare
success you know 40 minutes no GC game
but then you look longer and you see
that they're glitches and you look over
days and you see that there are regular
glitches another way is to use creative
language to to make yourself feel better
about the fact that you have stopped of
what you sees that will just freeze your
entire application for no good reason
except for the collector wants the
convocation
these are actual sentences for marketing
material and design goals on the web not
making any of these up this is from an
actual marketing material of a GVM I
can't name but I could say that it has
something to do with determinism in that
brilliant sentence it said I will
guarantee a worse case of 5 milli second
nineteen nine percent of the time
doesn't that sound great it's a
guarantee I'll just point out that one
percent of one hour is 36 seconds I'm
allowed to pause for 36 seconds once an
hour and I've met my guarantee or 360
milliseconds that's that's a meaningless
statement that makes you feel good but
there are others mostly as I said put
mostly in front of stuff makes people
feel them that's what it means right so
so that's what it literally means it's
telling you right there it's honest you
just want to read it the other way you
want it you don't want to hear about the
restaurant very consistent I've heard
this a lot you know it's a call that's
actually a Jekyll for a future version
of g1 to be fairly consistently below
500 milliseconds that literally means
that sometimes we would be worse than
this right well be way outside the ring
and typical positives will be in the
tens of milliseconds literally means we
will have pawns it's much bigger in
intensive milliseconds we told you so
right so these are good ways to make you
feel good about but if you actually have
to make an application live in the real
world you might want to actually measure
what's going on and get enough open
source everything and it lets you if you
the actual Higa thing behavior of your
application oh we are so it's not 15
minutes
I'll do two more minutes than a quick
sorry about this
so c4 is a collector we have it solved
this problem the problems solving you
can look up the slides online later but
fundamentally if you classify it it has
a great guaranteeing single pass marker
can't be done concurrent compactor it
classifies as compacting a concurrent
collecting option and the concurrent
compacting Yujin it's the only non
pausing new gender is right now and JVMs
or run times in general it has no
fallback to stop the world we don't have
code that knows how to do this so there
is no fool TC there is no stop the wall
there's no I couldn't do it so we will
pause it stick
design-wise it's built around the notion
of always doing the same thing and never
being in a hurry a lot of the algorithm
design is to make sure this is true
algorithm cool things you can see this
online but let's talk about what it does
to your application the fundamental
thing is we take care of things like GC
tuning so you no longer have to do this
or this instead you just do this kind of
stuff and tune the heap size down until
it breaks and then triple it and go home
right so you know tuning GC looks like
this you get behaviors for real
applications where this is Cassandra
running an irregular server that's the
one really second and you get to run
applications with just more throughput
per machine if you care about us a nice
you just get more out of a machine if
the reason you put more machines to work
as SLA isn't good if you put too much
work on it so fundamentally that's what
c4 does and it is a concurrent
concurrent dumped in an ultra collector
you can come to our booth you can come
to be able to hear does I clear that one
for the next speaker and I'm sorry for
the surprise at the time here I thought
me in another</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>