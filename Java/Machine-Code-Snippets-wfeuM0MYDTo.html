<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Code Snippets | Coder Coacher - Coaching Coders</title><meta content="Machine Code Snippets - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Code Snippets</b></h2><h5 class="post__date">2016-08-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wfeuM0MYDTo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so let's start my name is Vladimir
Ivanov good morning everybody and today
I want to talk to you about to tell you
about machine code snippets in Java the
experiments we have been conducting for
the past year I started in September
right after GBM language cymet so a
usual flight from the sponsor and
another notice from me its work in
progress nothing is finalized then
nothing is finally decides so I would
like to tell you about the experiment
the results and how we ended up there
where we are right now so on a GM LS
page there is a notice we will speak
bytecode here in this room unfortunately
there will be no bytecode in my
presentation only mention code assembly
code for x86 so let's start so I first
of all I will give some background to
get you up with the problems we are
facing and the solutions or entering
solutions we came up with to solve the
problem it's a machine code snippets to
simplify our prototyping work and the
vectors we try to bring gap of vectors
to on java for to java platform to to
assist vector api implementations so
probably some of you have used that site
it's a intrinsic guide by Intel guys so
there are tons of lots of intrinsic in
C++ compilers in order to expose
different vector instructions so till
recent times it was that they were
around hundreds of instructions and with
a week's 512 lots more intriguing things
are coming so instead of hundreds we
have thousands often too
so we started to looking at a debt and
John pretty accurate is summarized our
feelings at that moment so it was quite
hard to reason about eight weeks to try
to play with it lots of inter
instructions many difference between
different vector extensions we have a
weeks we have eight weeks to we have SSC
for different varieties of sec so we
wanted to bring up a sane a model of
vector programming to Java and we
started to vector API project again will
tell you about vector API in much more
detail and I will focus on earth on a
question how to expose all those
instructions to Java because we want to
implement as much of the implementation
to have it as much as we can in Java and
we have to access all those instructions
so till now we have two ways to solve
the problem use GV m intrinsic or switch
to native code so what is GV m intrinsic
geometric is a some hard coded
implementation in GBM for well known
methods so it's either hand written
assembly or expressed in compiler ir and
for example many methods in class I
intensify ball by JIT compilers for
example class dot is instance is an
intrinsic in Java 9 we introduced a new
annotation called hotspot intrinsic
candidate to make working with intrinsic
maintaining them much more manageable so
if you browse at the GD key code and you
see this intrinsic in such such
annotation it means that vm knows about
method and it tries to optimize it the
other solution Agni it's there from the
very beginning and if we want to expose
it exposed Dean intrinsic through Jane I
we can come up with a bunch of Jane I
method like we have a native method in
Java some helper class and have a native
implementation which actually
essentially has as the intrinsic we need
why isn't it what why is it in not that
good idea because we have thousands of
intrinsic and we have to create a method
entry point for every matter also in
vocational our head is also prohibitive
for our purposes I last year I give a a
demo on GV m language Simon show you the
native method handle prototype in
project Panama we did so we have metal
handles in Java since Java 7 they works
really good for Java methods but they
they don't know anything about native
methods why don't extend them to death
and here's a simple example how how it
works so like constructor method type
look up native entry point and exactly
it involved that's it it fitted pretty
well the implementation we have jabulani
invoke implementation we have in GD GD k
so almost all the pieces have occurred
counterparts for native methods and from
the user perspective the invocation of
native method doesn't differ from any
location of java method and with the
proper support on a compiler side native
method handle call can be turned into
direct call in the generated code
and it to save us some time on in what
during invocation which is pretty good
for a such small code we are interested
in what are the benefits and pros and
cons of to this approach so native
methods allows you to expose arbitrary
native code but it involves some
ceremony for Jane I it's much better for
method handles but still in vacation
overhead is non legally non-negligible
it's nonzero and still the actual code
is a back to the GBM in the optimizer on
the other hand GBM intrinsics provides
you with a full power to the older GBM
you can do whatever you want but it's
quite hard in terms of development and
maintenance you should hard code and
teach vm to speak all those intrinsic
which we and we have many many many
intrinsic very interested in many
instructions so well we want to avoid
that so we came up with an idea of
machine code snippets so let's come up
with a new breed of method handles which
actually let's cross native method
handles and intrinsic and come up with a
breed which doesn't suffer from all
those problems so the idea the first
iteration is let's wrap a row machine
code in a method handle and expose it to
the user as a metal candle so what's
other primarily use cases first of all
prototyping we want to minimize
implementation code allow to define new
material as simply as possible give a
decent performance comparable to gvm
intrinsics and we are interesting pretty
small snippets in size up to dozens of
instructions for it for vector epi very
interesting almost
single instruction snippets so existing
solution doesn't don't match either
first or second point so let's start
with an example consider we want to
Victor eyes move operation we have a
system Eric copy and we want to move
data from one area to another in Java we
can do that element by element it's
pretty inefficient we have a better ways
these days let's try to Victor eyes it
we have a fancy 256 bit registers on x86
CPUs these days let's try to use them so
we read 256 our value from memory and
writer right away so with a snippet it
looks that way so we have a method
handle it has a method type and it wraps
a machine code row machine code so the
first question is what are the registers
what do we address in this snippet we
have some Java values java data source
source is object upset is a row setting
this object where to start reading the
value and death is a base pointer for
the result and offset to is there set in
the destination object so what what are
the how can we pass the parameters into
the code between Java code and native
code so we have 42 to come up with some
implicit assumptions and let's use
platform ABI for that so we have a
method handle with a method type it has
a number of arguments and we assume
every argument has some predefined
location so we have a dir sire de
exercise fine so great we have a metal
handle we have
the machine code wrapped in a method
handle so is it enough not really we
have different execution mode in the GV
m so we have optimized code reduced
budget compilers and we have interpreter
and we want method a method called
snippets to work in both modes so to get
a sane we need two different versions
something I I call a lamp stand alone a
standalone version on machine code
snippet snippet a key into native method
which can be invoked from all execution
modes and for optimized code a JIT
compilers knows how to embed the
snippets into the generated code in bed
I mean gluing in the right into the
generated code calling conventions
matches native API for simplicity so for
simplicity this that's a simplifying
assumption so let's try to match native
API to make our life easier so we have
on our Linux a x86 t4 we have sex for 6
registers for integral of parameters
let's use that it also to expose machine
code snippet to the JIT compiler I
introduced a new entry point mention
cone snippet which extends in a
different tree point and these entry
point holds the actual machine code
snippet code the JIT compiler Cal can
grab it hands-on and native entry point
holds the address you see right so there
is a address field it's a row address of
the entry point so when JIT compiler I
issues a direct call for the native
method handle entry point in the
generated code it et tu reads that field
it can do the same for a measure for the
machine code snippet and extract raw
machine code from there
how how do we define our machine code
snippets first so the API looks like
that right now it's a first stab it's
not finalized in any way it just the
first version I come up with and it's
solved the problem I haven't invested
any time in polishing it yet so there
are two important pieces their method
type of the method handle which will be
produced and the actual measured code so
for our snippet it looks like the
following we have a nameless copy
256-bit the type is return type void to
a register addressing mode base pointer
plus upset and the destination base
pointer plus offset requires a week's
the instructions are available only on
ABX as part of a week's extension and
the dimension code encodes to instruct
machine instructions are we are
interested in so the standalone version
looks like the following so some
ceremony before and after like setting
up at the frame and the dimension code
we I interested in is simply embedded
and the arguments are passed in the
registers to be implicitly agreed on so
much in native calling conventions it's
pretty unwieldy to use method handles in
directly so every invoker throws an
exception throwable exception so you
have to handle it so it's a convenient
to wrap the message handles in some kind
of method to simplify to use it in a
more uniform fashion so here is an
example of unsafe wrapper for the info
for day method handle we came up with
and let's see how does jit compiler
behave so we see the following inlining
invoker check type of the matter candle
and then invoke native so extract entry
point object and I'll invoke it and when
did compiler sees the entry point is a
compile time constant it extracts all
necessary information from it and the
meshing code looks like the following so
we have almost the same version as we
have with the standalone version and
it's optimized so it's produced by jit
compiler so it embedded the machine code
in the interpreted code the same code we
asked for but we have some red register
to register moves and the reason is why
in the reason we have that because
calling conventions in GBM for java code
and native collin college is slightly
different have you how many of you heard
about java calling conventions before
well quite many i have surprised a
little bit but that in java is that it's
not specified it's a area of vm
implementation so vm implementation is
free to choose whatever calling
conversion it is interested in and for
speeding up gene I calls hotspot has a
special calling convention which shifts
the registers are one step so when you
call a native method you can put Jane I
and pointer in the first register first
parameter register without shuffling
other registers and it works pretty fine
that's why we have all those directory
moves in the code and in for standalone
version the same task is solved by
linker method so when we call
from Java code to extend the loan
version we go through a linker method
linked to native and it does shuffling
argument shopping for us so like doing
that shift and to expose that
functionality to user we have to provide
some safe rapper so here is an example
of a save rapper we do a rebalance
checks computer upset and then call
unsafe rapper that's how it's intended
to use so three levels lowest level
method handle which wraps mention code
then unsafe rapper and then safe wrapper
which can be exposed as a part of for
example public API if you're interested
in so let's switch to a more interesting
example and let's look at back
operations at VP ed added ed packet
integers it's supported starting
starting avx2 and it sums to 256 vector
registers and put the result in the
third so how could we expose such such
instruction on Java level we have to
express vectors 260 256 bit value well
do we have anything right now well not
really we have to come up with something
new a drone and Brian a couple of years
ago came up with a new term impedance
mismatch when they talked about GBM and
language evolution we have a similar
problem on hardware with hardware as
well hardware walls new instructions are
added new registers larger registers are
exposed to the
on the machine code level but GBM a type
system stays always the same so if we
want to expose the values larger than 64
bits we have to refrain to some tricks
so for the prototyping purposes we came
up with the three new classes long too
long for long gate to represent 128 and
larger well beat values they are value
based classes right now until we got
value classes they are intended to be
valued classes and treated in the
following manner they are well-known to
the GBM JIT compilers have to treat them
specially to be able to match them to
vector registers and I have implemented
support in situ to do that i'll i'll
talk about that later so they until
until value types out there we can't
consider them at the first class
citizens but once we have value types we
hope we can be able to make them as
optimized about as primitives so okay so
we have longed for right now to describe
you mmm register so what's next we have
a new signature two arguments long for
long for but our current calling
conventions don't allow us to call that
code right away so we have to somehow
put the value into from the box to
vector register so vm should provide the
implicit boxing and unboxing operations
between these newly introduced boxed to
get the layout the mesh encode expects
so here we have to unboxing appear
patience and boxing operation after the
resultant computed and what to do with
the result it's a object and we have a
machine code with we should somehow
allocate that box so the which we should
provide a reallocated box for the result
in that particular case and it's it's
placed in the first is prepended to the
arguments and past the first argument so
here we have a wee box the result into
pre-allocated box but we don't do we
don't need to ask users to do that we
can do that underneath for example
either explicitly reallocating box and
passing it into the method handle in an
unsafe rapper or well construct an
appropriate method handle which does
exactly the same job so for the user
it's exposed that the methods handle bit
the same method type as was requested
but when it's actually invoked and
before calling mesh encode the box for
the result is allocated so here is a
standalone version and it contains all
necessary boxing and unboxing operations
we need to provide the correctness in
blue there is a dimension code we asked
for and the inner Jeet compiled code we
have the same operations so we we we get
boxes values where we extract values we
we we execute the snippet code and then
we box the result in return return it
because Java code doesn't expect the
values such large should so too in order
to be able to work with it from Java
code we have to expose them as a box in
a boxed for
like as a long too long for long gate
let's look at a more complicated example
nested operations so here is the JIT
produced code snippets are in blue
boxing unboxing operations are in green
and dean stroke instructions we don't
want to see in the code I in red so
that's some artifacts of compilation we
want to get rid off so what's the
problem here we have a break we have
many snippets in the same compilation
unit in the same code but they have
exactly the same shape so they use the
same register so they can flick for the
same registers so JIT compiler has to
move the values live values around spill
them and feel in order to preserve them
across snippets because they actually
destroy that values how can we fix that
well with the current assumption we can
do that but let's change that lets user
help us with that so let user know about
register allocator decision what
compiler does so let's switch from row
machine code to so-called snippet
resides so ask user for recite of the
snippet he wants to use instead of row
machine code so on in compiler we're
interested in register masks what
registers can be used for arguments with
it with the calling conventions but
night native we have a fix it registers
we want to relax that constraint so how
to describe that register max masks
fortunately in Java 9 we have
gomti interface coming and among other
things it has registered definitions in
platform configuration files so we can
use that let's let's try so here is a
refined API so instead of asking for a
row machine code as a byte array let's
ask a user for register masks for their
arguments and the snippet generator
which is an interface which gets in it's
a functional interface which for a
number of registers so register
allocator chooses the register from
register masks feeds them into the
snippet generator and gets a specialized
machine code back so it allows to
specialize a snippet for they actually
use em use sites in the generated code
so the code should be much better
generated code should be much better so
here is a actual example so we have
method type as we have before so long
long long to longer long for arguments
and the long for result here are the
register max masks any xmm register can
be used and the here is a snippet reside
we get a register for every argument for
return type and we have in this
generator to have to produce the machine
code which complies complies with that
constraints so ok let's encode their
registers we have got from decompiler
and produce the instruction it looks
more complex more complicated but the
main problem is that we don't have
assemblers in the Java
so that's will be the proper API it
should be much simpler and growl has a
macro assembler so it should be used to
produce row machine code from Java and
the IP I will look much much better they
couldn't we look much much better okay
here is a code with the for register
allocator of a snippet and we see we
don't have any spills here and the
following snippet has a different
registers used than others so and no
registered register moves or spills here
but still there are some instructions
left so what what's what can we do with
that and the thing we haven't thought
about before is effort so when we we
agreed to obey to calling conventions so
calling conventions fix the argument
locations but also preserved registers
are also defined by the calling
conventions so implicitly there is a
number of registers which are killed
across a call which aren't preserved
across the call and it causes the JIT
compiler too conservatively move the
values out of the tread Easter's to
avoid their destruction so the on linux
x64 all xmm registers are destroyed
across calls so that's why we see
unnecessary spills let's fix that let's
make the preserved register set explicit
let's say this particular a snippet
doesn't kill any registers and what do
we get well my small and Mac cut much
cleaner
no more well there are at least three
and unnecessary instructions but two of
them spiel and feel that second and
third are caused by a allocation we have
so allocation involves a call native
call in to GBM runtime and a slow path
because if we ran out of memory we have
to try to free some and it's a call into
a native another method so in another
function so we have to obey to calling
convention there so your mom is spilled
because of that and there is one rector
egg move upper which is also attributed
to that particular allocation call
because we use our BP down we use it
here see so here is it so that's all
about machine code snippets let's look
in more details on vectors and box
eliminations so as I told you before for
every vector snippet which returns a
vector value reallocated box that's kind
of scary if we can't rely on box
elimination box unboxing elimination
because well why do we care about code
quail quality if we boxing and box
around snippets well so how does long to
look like on how it's declared so until
we have value types we have to do some
precaution ourselves some bully
boilerplate things ourselves like we
want to use factory instead of
construction so boxes offer beaded to
explicitly allocated only factory should
be used everything is intrinsic I'd or
that purpose and there is still one
thing which is marked as fixed me Phil
declarations l1 l2 what's the problem
with that so here is a key play out of
the long to box so we have a heater and
we have payload to longs 16 bytes and we
want to operate with them in a as a
single location like we with a single
instruction load 124 beats and put them
back we don't want to mess up with all
the house I was a problem with the house
well if we want to we can hold it on a
Java side because depending on the
platform we have big Indian and little
Indian architectures so how do we know
what what half correspond to what part
in value well we can't do that so what
we would really like to do is to have
box with some payload of desired size so
some kind of intimacy Phi the knowledge
of the box in the GBM and enable our the
value values large n64 beat on GV m
level not on the GBM type system but at
least on GV m level another thing is if
you noticed III think some of you
noticed that all the spills are an
unaligned loads and stores and we do the
same both in generated code and the bog
boxing unboxing we do explicitly for in
the code for loading and storing the
result of vector operations and jit
compiler do does that
same white so can we use a faster for
aligned variety well not now the hip
alignment is eight byte boundary that's
what garbage collectors guarantee us and
we can guarantee that the valley vector
value is nature aligned and for a vector
valley national alignment is its size so
for long to we need a 16-byte alignment
for long for winning two 32-bit bite
alignment and long gate we need 64 byte
alignment and without garbage collector
assistance we can do that so we have to
stick with more with unaligned allows
and stores we can fix that in generated
code because we are in full control of
our stake layout and we can align it at
the beginning of the generated method so
regarding boxing right now in the
current prototype see to treat specially
the boxing operations on vector values
so there is a special node called V box
which is produced for the snippets a
result and it puts it conditionally puts
the value produced by a snippet into
pre-allocated box but if the code
snippets unless that it goes away so the
result is used as is without any boxing
and unboxing so we have boxing only at
the beginning when we load something
from hip then operating mostly in
registers or spills and fields and then
box the final result into the hip
another thing which is interesting in
the generated code is the value it is
the spills and feels across a call to
a new instant java it involves a safe
point because if there is no memory left
we have to save point and runs garbage
collector but you see we can optimize at
that point but we don't box and then box
it we you we have a raw value how is it
correct if Wendy optimized at that point
will we still be running will GBM crash
or what so JIT compilers preserve the
correctness for that particular point
there is a matter of information
attached it which instructs the D
optimization logic to box the result
from on top of stack as you can see here
is stack 0 slowed stake 0 and it
corresponds to the actual location of
that value so during the optimization
GBM will automatically box the results
and we are fine but in generated code we
have very efficient representation so
GBM is pretty smart about tweeting
vector values right now what can be
improved well why can't we move
allocations around the code so we have
three instructions here which are
necessary to which are added by the that
call new instant java if we move with
upper there is no need in those
instructions so but c2 can do that
because it's a every allocations a
possible safe point and some point has
Stadium state attach it so we can't
freely move the allocations but with the
value types and hazing boxes they bring
us it should be solved so I'm really
eager to see a hazing box prototype and
the try it out
there is another if it's repeated boxing
it's some jit compiler artifact I don't
know frankly speaking I haven't invested
haven't explored yet why it happens
instead of instead of spilling on heap
or on the stack the value is so well
spilled on the heap let's call it that
way so we reload the value from the heap
twice it's not that bad but still it's
possibly less efficient than having the
values build on stack so let's look at
the more complex example let's try to
Victor eyes naive implementation plement
ation here is a function let's try it
let's try to vectorize it so let's read
let's try to Victor eyes cashing a byte
array so we read values in by eight
bytes expand that to integer values and
then process them and do that until we
ran out of content and then some are the
result of the final result up so it
looks on Java in Java code it looks like
like that here we have our loop body
rehash eight and we read along value
from the byte buffer but byte array and
pass it into the one the processing
function v h eight so how does the code
look like so here is a c2 ir and you can
see so in gray the rats nib snippets
nodes green our boxing unboxing
operations and we can see that all the
snippets operate on vectors raw values
no boxing unboxing involved but we have
boxing and unboxing when we start
executing executing an iteration
and we leave it when we switch to the
next iteration and well we are in a loop
and it's pretty bad right when I'm where
every loop iteration we do boxing and
unboxing what what what went wrong so
here is the problematic store vector we
haven't eliminated that the result of
the loop iteration it stores the result
into a egg local but it can't eliminate
the box why the problem is limitations
of skip analysis in situ so initially we
have diff the first value of the
accumulator it's 0 and then we update it
on every iteration and on IR level we
have a fine owed for that value n c2
can't eliminate that case it doesn't the
current implementation doesn't cover it
so it causes also the other loads so we
have an allocation in the in the loop in
the loop body so we have to spill values
around and here we have a bunch of
constants used so in the algorithm we
have a number of pre computed vectors
which i use it for multiplication to get
the necessary result and here we see
that those loads are coming from our
constants so we load a constant value
put it in a register use it and then
destroy it and then on the next
iteration we load it again so that's
another inefficiency in the generated
code so it's not that bad considering we
have to spew around the allocation box
allocation for that further for the for
the result of the integration but anyway
let's I I haven't
fix it the the following bug so probably
if it did the problematic boxing goes
away there are other unboxing operations
will will go away as well so here's a
bunch of observations about the Skip
analysis in situ so the problem with
finals vectors aren't hoisted out of the
loop with those constants repeat that
unboxing and the box allocation
placement so so that's almost it the
current status of the prototype is it's
almost issue complete I focused on C to
support on linux solaris in max x64 the
prototype has been used for a while for
by young grapes for experiments with
vector api and thanks to paul and young
for the feedback and for the bug report
that was really helpful and without you
without your help it will want to be
dead so what's the remaining work so
there are some missing features left so
it would be nice to have temporary
registers in the snippets also some
instructions are require an alignment
and right now there is no way for a
snippet to know where it's in it will be
placed but we here I showed you register
allocator aware snippets it can be
extended to a location-aware snippets as
well the compiler knows where it will
embed the snippet and kate pass that
information into the snippet recite the
generator and improve our Diagnostics so
more errors are helpful more diagnostic
errors are helpful when you inject
unsafe in currently unsafe code into the
GBM so if it crash it causes a crash
it's better to see it right away
and not try to diagnose it so probably
it's a good time to start prototyping on
other platforms try to how it looks like
on spark and arm 64 support is in other
JIT compilers like growl and c c1 is
also a good way to eat interesting
experiment because right now or there is
only see to support so probably some of
the seat watch assumptions can sneak
into the api api is a problem as well so
a better way to declare snippets is also
necessary and the escape analysis should
be enhanced not necessarily for a
arbitrary java objects but for vector
boxes like prototyping kaizen boxes
support the boxes which don't have
identity don't preserved how much time
they have ok a couple of more slides so
example multiple return values we have a
cpuid what do they mean by what what why
do we need multiple return values so
cpuid returns to results to values into
registers and we have to box the result
ourselves to pass it to the user so long
to is a good candidate it's exactly
enough barely enough space for for ins
and the in generated code it looks like
the following so if we want to extract
one value we have to put all the values
into the box all for produced values
into result values into the box and then
extract the value we are interested in
there is no boxing involved here because
we construct in the register but still
we can't eliminate that
come biking the result into the register
so if we expose on an IR level that the
snippet produces multiple values instead
of one we can say that ok there is here
here is the result you're interesting
and jeet can use it right away without
all that a boxing so that's it here are
the links please if you are interested
in that please try project Panama we
have an extensive number of samples to
work with thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>