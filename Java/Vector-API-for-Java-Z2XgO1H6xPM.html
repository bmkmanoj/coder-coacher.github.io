<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Vector API for Java | Coder Coacher - Coaching Coders</title><meta content="Vector API for Java - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Vector API for Java</b></h2><h5 class="post__date">2016-08-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Z2XgO1H6xPM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm a engraves i'm from intel and this
talk is a bit of a dovetail on what
vladimir just presented so vladimir did
a lot of work with code snippets and we
at intel are working on an api that's
going to be more user facing developer
facing in java called the vector api
it's pretty exciting work there's
there's it's a lot of interesting stuff
to play with i kind of feel like you
know a 16 year old driver that just got
behind the wheel of a car and then crash
it into a mailbox or something cuz
that's what happens with with these
kinds of projects but it's very
enjoyable and the work is very rewarding
so i excited to describe it to you today
so not to be outdone by the legal
disclaimers seen previously i have a
couple slides of disclaimers i'm not
making you any promises this work is
very much prototype your trademarks are
your own etc and so forth if you'd like
to go back and read these i'm sure
they'll be somewhere on the internet and
then as a more concise disclaimer the
code in this presentation is like you've
heard before prototypical subject to
change
it lives in project panama and i'm also
told to say that it is licensed under
the GPL v2 exception you all know this
but here it is so if you're interested
in the code you can get it from the
panama repository it's online waiting
for you to check it out so just a quick
overview of this talk we're gonna go
through a quick introduction give a
brief re for a into code snippets as
i've been using them then discuss the
vector api and its design and some of
the challenges and opportunities therein
and then i'll do a quick wrap up so this
is primarily right now collaboration
between oracle and intel the vector api
is though we're open to anybody who
wants to participate so you probably
recognize some of the names hear that
familiar suspects some very nice and
very intelligent people along with
myself working on the vector api project
so we're always looking for more people
to add to this
so briefly terminology since the word
vector is highly overloaded here API is
overloaded code snippet etc code
snippets is what Vladimir is working on
in coding instructions in Java hosted in
Java executed in the JVM runtime and
then being bound therein with method
handles for invocation the vector API is
a layer over that of an ear over that
that provides some additional safety
type checks and regularity to the
underlying layers since the ultimate
goal of this API is to be cross-platform
it needs to be sufficiently removed from
a particular architecture but still
straddle that line where it doesn't
impose an additional performance penalty
in so doing so it's implemented on top
of code snippets and the challenge of
our work so far has been to make sure it
doesn't come at a significant cost so
there's a number of explorations that
we're sort of engaged in right now to
investigate what's usable and what is
feasible so our motivation many popular
applications benefit from data parallel
computation everybody probably has one
they can name off the top of my head
we see a lot of libraries for machine
learning dependent upon data parallelism
or they would benefit from data
parallelism currently in the JVM
architectural support for data parallel
architecture extensions is opaque so
this kind of parallelism occurs in the
form of super word optimizations loop
unrolling and that's subject to a bit of
brittleness right you have to write your
code in a way that optimization passes
can come in recognize them and optimize
them which these these optimization
passes enjoy a lot of success in the
wild but there are algorithms that are
particularly resistant to optim
Zain passes making hay with him
especially when a developer a human can
write them from the get-go and in a
vectorized form and see the results
almost instantly so we're looking at it
to expose pure Java solutions in this
area to avoid J&amp;amp;I interfacing a lot of
solutions now that would link to
something like lip gloss deal with a J&amp;amp;I
overhead it's not the same as say in
lining these instructions into your
program per se so developers are left
with this choice where you have to make
sure that the data that you are
operating over in a parallel fashion is
sufficiently large that the overhead of
the J&amp;amp;I is not overcoming your calls out
and then secondly we want to make sure
that these solutions minimize cruft and
boilerplate in the generated code so we
want to make sure it's good quality so
like I was just saying we want to expose
those things portability and performance
we want both trade-offs are ultimately
necessary in some cases but we'll cross
those bridges when we get to them and
scalability as Vladimir Vladimir and I
actually have a very similar slide I I
dumped it when I saw him do it but you
all saw the Intel intrinsics
website where you type in you know the
name of an instruction and then there's
you know so many different different
operations and instructions for you to
choose from and that's just one AVX or
let's say B X's for x86 but that's just
one vectorization extension so we're
dealing with sort of a combinational
explosion as architectural extensions
grow and then multiply that by the
number of different architectures we
want to support we need we need a we
need an approach that will scale for
implementers that we can keep our minds
wrapped around it and not have to
hopefully cut down on the implementation
complexity vector vectorization is a
very rich and powerful
tool that comes in architectures and it
is it is deep so when you're dealing
with vector instructions it's it's easy
to to to get lost in some of the details
and when you try to abstract over those
details you can end up making some of
your programming models very fun
idiomatic and very confusing and strange
to use likewise you can over normalize
these things and end up looking like C
making it very own Java so the goal also
is to have idiomatic api's for
developers to use and understand for
vectorization so code snippets so we're
treating code snippets like I said as a
substrate for our implementation brief
review code snippets are a portable API
for expressing primitives in our case
they're more flexible to prototype and
to experiment with than implementing
hotspot intrinsics which usually
involves a number of different pieces of
work going forward with things like
we're all on the horizon encoding these
things in Java have certain benefits as
far as technical debt is concerned we
don't need to necessarily carry that
forward if we do a lot more work in hot
spot and then growl comes down the line
a few years later we don't have to do
this all over again so having it in Java
is a very nice thing and then Isis can
use the same API so everybody gets gets
a crack at it it's in prototype base as
we've heard but we've observed some
decent some pretty good performance
characteristics though we're not quite
to the point of benchmarking everything
you'll have to wait until Java one for
that but we we have observed good code
quality and good performance on small
examples but we need some bigger
examples to really definitively say
describe the nature of our performance
so method handling vacations combined
with code snippets is a really good
approach for inlining code quality etc
so just from my angle implementing a
primitive like we said we bind to method
handles
the method handle light method handles
library has additional Combinator's we
can use since whereas before in regular
Java you just write plain old Java
arithmetic expressions etc you can't
invoking things in tandem with you know
each other or method handles that have
data dependencies you can also use
method handle Combinator's for those and
that's really handy and then like we
said we use method type to describe the
types vectors represented by the long
objects in the best case the wrappers
can be alighted the values can be
register eyes but escape analysis and
box illusion is still work in progress
but it's looking very promising at this
time so vladimir mentioned that there
isn't an assembler in java but we're
working on it for x86 we've got some of
the pieces coming together it's more of
a macro style encoding system right now
but it's it's it's it's looking good so
far and you can check it out on panama
so implementing a machine instruction in
this case this is the add PS so instead
of integers we're looking at floats we
have our type we have our feature
checking predicate so in this case the
add PS requires a bx so check to cpuid
flag is av x present if it's not bomb
out with an exception if it is keep
going
register masks so in this case v ID PS
is a three operand thing it needs a
result registered to store in and then
two operating registers it's
non-destructive e flavored operation we
get these by a JVM CI and then down here
is some macro rised x86 encoding that I
probably will avoid going into that
aside from saying its vex encoding there
are a number of methods to help support
that if you're really interested in that
kind of thing you can check it out on
the code base but we will probably
encapsulate this a little bit more but
this is what it looks like right now and
so we ended up omitting the bytes of the
vex encoded instruction that supports
the add PS this case similar to
Vladimir's we have two checked
invocation
so with the addition of a peer job of
equivalent function for sanity checking
it's just good practice then we wrap V
at PS in sort of a checked invocation
point if something fails an exception we
raise an error otherwise we just
continue we use this as the public
access or point for this method handle
but it looks just like your
run-of-the-mill method so a small
example using this kind of thing is
we're interesting we're interested in
adding a race and this is just in what
you're looking at right here is just an
iteration over some arrays a left and
right array with the destination array
to sink the results into for brevity's
sake we are for lack of complexity sake
we assume that the the arrays are mod
eight in length because we're not we're
not going to do a whole lot of cleanup
right now this is just for short
demonstrations sake we and then we
iterate over the arrays adding the left
and right results and then storing them
in res which we do in the next slide so
add a race just to isolate this code for
the next slide you'll see why but we
have a method handle for loading from
from a float array loading along for so
256-bit register gets loaded from that
we add the two together and in this case
we are a Sisk opera or we are assist
construction set so you know if you got
it use it so patchable Beck utility I'd
PS is doing a sunk load right out of
memory to save us some time and some and
some instructions on the back end and
then so we do that operation stored in
our our and then we dump it back out to
the float array so that's our scaled low
and our scaled store and our addition to
generate the code we provide lots of
flags in this case we disabled enrolling
in superward as a comparison to baseline
operation
just to see that we're getting some
gains for tiny examples like just array
addition super word the super word
optimization will wake up and make total
hay out of that and even if you generate
the best code your code will probably be
about as good as super words for this
tiny example so you won't see any gains
unless you turn super word off so we
turn it off just to make sure we're
actually seeing some real gains over a
simple scalar operation so let's see how
hopefully that's a little readable okay
so the code it generates and this just
trust me on this I had to crop it just
right so it would fit on the slide but
this is the entire this is the entire
body of add arrays dumped out so
snippets are pointed to with minimal
anything else and then you see at the
bottom we we do some cleanup and then we
return
so snippets used in this particular way
I know in some in the previous talk we
we observe boxing issues but snippets
used in this programming style where you
render along for from an array use it in
an intermediate fashion like so where
it's where you have a dependent chain of
operations and then sync it back out to
an array results in minimal spilling you
see how it slowed the loads occur the
first two operations the very top you
have V moved equ and then you have V add
PS with one operand coming from memory
and then there's a fee move DQ back to
memory where we write it back out so
there's no saving going on because these
are value ish classes and they don't
need to live anywhere we're not uttering
their names anywhere outside of this
body so c2 is able to discharge any
spills it's it's a pretty nice trick so
this will be probably one of the only
remarks I I make on performance
disabling super weird and loop unrolling
we see about a 40% reduction in clock
cycles spent in that kernel so we're
counting on clock cycles in this case
wall clock time there's still some
overhead occurring from other
is in the in the library and we're in
the process of chasing them down but on
a fine grain level on a per level where
we're particularly interested the loop
kernel itself is quick so we're working
on bigger and more intensive workloads
to sort of stress this but so far it
looks pretty good for a prototype so
moving onto the vector API it's like I
was saying
eisah extensions to support
vectorization are very expressive you'll
have the same operation supporting
numerous different kinds of operands you
know X in my mm z mm in the case of the
latest avx-512 is coming down the pipe
so this creates sort of a headache for
people wishing to abstract over this
there's sort of an in cross improv
problem that occurs if you want to
parameterize by types etc sizes so it's
a challenge just to wrap it up but we
need it anyway if we want to have a
platform-independent
abstraction for the vector a vector is a
ssin so it needs to capture it needs to
capture all this in the spirit of Java
itself so platform independence once
again I keep saying this along with
meaningful static checking we can we can
live in the land of method handles all
day but we have a type system so we
might as well use it statically where we
can where it makes sense and where it
doesn't make sense we can always defer
to runtime but if we the more static
checking the better as long as it
doesn't come as a significant cognitive
load to users so in an immunity youth
familiar patterns so the vector API as
it is right now was proposed by John you
can check out the initial draft proposal
on the Panama project listserv
but the base type is this notion of
vector
unrelated to longed-for that's
parameterised by an element type and a
shape type while while these these type
the element type isn't particularly
constrained we're looking at the
broadest support in float integer and
double types in the case of x86 the AVX
extension resides mainly around those
data types there are operators for
longer and shorter things but the most
complete set of operations live in those
size types so that's where we're
spending most of our time and so the
draft implementations of the vector api
are checked into project Panama sort of
a loose outline of the structure as it
is right now one of the things we're
particularly interested in is rendering
rendering vectors from arrays and
vectors from boxed primitive array types
render you know if we're parameterizing
by generics then that in in our fields
that we were to render from would be
parameterized as well it sort of
behooves box types box arrays and so we
get pathological results if we if we
stick with box two rays and primitive
arrays of box two primitives so what we
do is we do the special agent
specialization routine running a similar
play that we've seen in streams within
stream and double stream so here we do
float vector which is a subclass of
vector itself we hide some additional
factory methods here for rendering in
and out of primitive arrays because
that's where we really want to spend
most of our time and then hidden behind
the scenes are the specialized float
vectors which support the specific code
snippets for sized operations in 128 256
and other sizes to come later so the
basic functionality vector vector
operations you you see some of the
familiar guys just adds moles and
arithmetic operations on vectors yeah
vector a yeah vector B add them together
you return a result which is a new
vector and it's immutable that's that's
the thing
right now the long vector objects and
the instruction set architectures that
we work in are immutable ish as well so
you know if you're using a
non-destructive vector operation than at
the it's it's uh it helps to stay
immutable and it's something that's nice
you know immutability is is a new you
know a newer feature not a feature but a
new trend that's that's being championed
everywhere so we're starting from
immutability and seeing how far this
takes us so some more advanced
operations on vectors you have scalar
vector interfacing so getting elements
in and out of vectors putting elements
back into vectors which it's not a set
it's a put so slight nuance there but
put would mean we generate a new vector
and then we have horizontal reductions
on vectors which are a little trickier
these vladimir mentioned that some code
snippets would be more than just one
instruction and horizontal reductions
usually end up being more than one
especially where floating-point is
concerned and you have a canonical
horizontal evaluation for floating
points so we've we've we've had some
light discussions as to how about the
floating-point fidelity of the vector
api and i think we're going to stay
faithful to strict FP style evaluations
so we have to write it in a particular
way there are some horizontal operations
for for addition and other other similar
things in the ice ax but they don't
evaluate in the in the way that you
might expect they they reduce kind of
like this instead of like this so you
reduce and then you reduce again kind of
in a tree like local fashion so that's
it's good for integers less less for
vector floats but it's a work in
progress
and then loading and storing two arrays
these are the box forms but they're
there for reference and then sort of the
fully realized expressiveness of the API
and where I think some of the
particularly interesting stuff resides
so you have maps maps takes a unary
operator up and Maps it over a vector
sort of tweaking every element in the in
the vector and then you have a masked
version of that map and we have a
similar map or say you could also call
it maybe a zip or some kind of a reduce
you have two vectors you have a binary
operator you reduce them down to one
vector likewise masked version of that
the the masks and some of these other
types like shape are also specified in
the in the in the repository as well but
in this case you can kind of expect
their behavior you can kind of predict
their behavior mask just directing in a
bit wise fashion how to execute lane
wise so these are particularly
interesting and I want to I want to
stick on this but I have one one little
note before I go there so the previous
kernel we specified with code snippets
looks pretty similar in size and shape
with the vector API we just mask over it
with some factory methods we have some
extra additional type safety but I'll
say right now that given the way that
Long's need to be boxed that we're still
working out this problem the vector API
in it's sort of wrapped form sees a lot
of artifacting of the long objects on
the back end in the code generation
process so we we are working on it but
we're also investigating alternatives
that I shouldn't say alternatives but
other approaches to
compliment the vector API specifically
approaches to deal with some of this
fully realized expressiveness that we
are really interested in in being able
to apply to vectors so higher-order
components right this is something it's
just something we really want we got
lambdas in Java now we got we should be
using them right but this comes with
some interesting challenges so in
essence this is like they'll write the
loop customization problem the
programmer specifies a loop body and the
loop body is specified lane wise so if
you have an element of float element
type in float you want the user just
wants to say look I have this I have
this lambda it works on floats here's
some arithmetic do whatever it is you
got to do to make this vectorized it
turns out that's like not the easiest
thing to do because if you have you know
if you have if you if you're given a
lambda on at runtime and it's lane wise
how do you know what's in it I mean
anything can be in a lambda a whole
Turing tarpit can be in a lambda so how
do you vectorize that in a way that the
user can easily say well I wrote this
code and I expected to be vectorized
with these characteristics cuz we're in
we're in this we're in this area of perf
right so people want to be able to write
code that has pretty predictable
characteristics so what do we what do we
do here should we should we should we
focus on introspection of lambdas just
for this API and I would argue probably
not because that would be asking for
expression trees in Java and that would
be opening up a whole can of worms just
to make this one feature here work so I
think there are other ways forward where
we can enjoy a lot of this without so
much pain basically by saying we need
better control of what the user is able
to say in a loop body we can do this
with factories for constructing the
operations that we want to vectorize but
they need to be composable enough that
people are willing to use them so if
if if we give the user just a library of
bodies to map and say well this is the
ad body this is the mole body good luck
I mean they just execute one execute the
other you don't want to be that fixed
but you also you want to have enough
composability where they can say all
right I have all of these little
components how can I wire them together
to form a new loop body that I need for
my computation and still see the games
that I want to see so instead of just
regular higher-order full-blown firing
on all cylinders lambdas what we can do
is we can stay in that realm but focus
on Colonel construction in these bodies
we can provide components that people
can use we can make them composable okay
sounds good constraining - what's
vectorizable great some interesting
interesting constraints that help us in
this in this area are that most
vectorized vector operations are either
unary or binary operations so if you
have an ad you have two arguments if you
have a naught you have one argument and
there are a few that take more there are
a few that have kind of immediate fields
that you need to do a little bit of
dispatch on but overall you're
constrained into this little slightly
ragged but arity - and smaller type
operations so you can start from there
and we can continue using method handles
to illustrate this this whole thing so
just to just as a brief sketch of what
I'm talking about
say you have your method type and then
we instantiate some code snippets and
what our goal is to represent what's at
the top we can start with method handles
and then we can start combining them
together with combinators and then we
can do some fan-out
yeah that's a little bit of fan-out and
we've basically constructed what's at
the top so we can do it with method
handles the combinators are there we can
start from a high level lambda ish
representation and encoded in method
handles so there has to be some kind of
transformation that exists to get us
from a higher level representation to
this method handles representation
because really it's just combinators all
the way down with code snippets at the
leaves
let's just open these up a little bit so
we want wrappers over this as well that
have some static checks and some
shielding from the brutality of the
underlying architecture one method is
proposed by John it's up in in Panama
it's you can read it I it's it was an
interesting I think I think both methods
here actually share quite a bit you can
read about it more there I'm gonna prob
I'm gonna skate around it a little bit
um in this presentation because I
focused a little bit myself on a
slightly different approach but it is
mapping vector operations and relating
them to the operations that are
arithmetically arithmetic aliy available
in java and in the in the bytecode so
it's a very tight fitting correspondence
to Java bytecode and operations that we
supply to be composed in lambda bodies
or higher-order loop bodies so another
approach this is one I've been playing
with is to use a lightweight syntax tree
so not one like c-sharp syntax trees but
just a little syntax tree that we can
construct and then maybe apply some
transformations to to get us back down
to method handles so it's it's still
very much in the work yes but the one of
some of the benefits still remain like
they were in the in the lambda version
which is we can think about it lane wise
and once we think about things lane wise
we have this benefit of where the use
the the runtime system can actually
select which vector operations are are
which wide vector operations are
available in the particular operations
that the user specifies so the user
doesn't have to constrain themselves to
avx2
or AV x1 or some other
with you know with constrained extension
so some quick quick thoughts so
rightmost vector operations are
expressions expressions are basically
trees method handles can be combined
together in a tree-like fashion using
some of the usual suspects so you can
you can make things in a graph like
fashion and compose them together that's
really great
so permute arguments collect arguments
filter arguments filter return and we're
seeing we're seeing even more being
added into method handles and you know
I'm very glad I came to JB MLS or else I
wouldn't have heard about all the new
stuff that's coming in nine that is
totally relevant to this work so method
handles have added benefits here we've
observed some good code so you know why
not and coding this way we've already
seen can help Allied boxing so this is
sort of sort of the idea so if you
construct an expression tree it's just a
tree you have a visitor the visitor
traverses the tree the visitor then
produces a bound up method handle
composed of all the corresponding method
handles that relate to this expression
tree so that's cool but wait there's
more right boom so if you just have a
different visitor for any kind of method
handles you wish so if you have the
method handles on the back end present
you can query which visitors you have
available you can dispatch that visitor
a diversity tree build your computation
and then execute the best computation
that you have available on your system
so you can sort of divorce yourself from
worrying about what's on the right and
stay in the nice world on the left so
just as a to illustrate this a little
bit so baby's first little Edsel that it
domain-specific language for this we
have an expression interface we have add
mul knots sort of building up a tree
here and then we have a trace expression
for debugging and I'll elaborate more on
why this is necessary in a second we
have ways to introduce constants so in
the case where you have constant values
you want to load from add to start from
you do have to actually utter a long
form make and so you pack those with
your constants Lane wise that's fine you
only this only ever correspond to the
utterance of one make so you have one
long four on the heap one long two on
the heap that's cool and then you have
your actual evaluator which is a kind of
reductive visitor in the sense that you
it traverses the tree and collapses it
all down to one value in this case being
a bound up method handle so one thing to
note is Trace what that is is it's like
a tap on the expression tree when when
when you compose method handles and you
want to see the values flowing through
this computation trace will you know if
you have an expression tree trace will
break the connection between two
dependencies and route along for out
where it realizes it I say long for all
the time it could be any kind of long
but I'm sort of fixed with lot four in
my head it routes a long out a long
object out realizes it in the high-level
Java sense as an object that you
consider does some inspection with it
hands it off to a consumer the consumer
prints it out or something or does some
kind of debugging routine and then
passes the value back on through to the
rest of the expression tree as though it
wasn't there so it's kind of an on-site
effecting aside from your i/o inspection
routines so what this looks like is is
you have a binary operation a classic
binary operation parameterize by this
expression type which is itself
parameterize by the type of the constant
leaf nodes so you have an expression
left right but instead of being a body
that you execute directly you're now
using sort of a functional symbolic
trick so there's kind of a plumbing
inversion that happens in this where
once you have composed your expression
the an evaluator first plumbs this with
symbol nodes with constant values to
know whether or not they correspond to
the left or right value so these fall
through your expression tree which are
symbolic and Ellinor and you get a you
get a syntax tree out and then it can
traverse the tree so some advantages of
doing this with lambdas because you
could just do this with a constructor
but if you have lambdas that are
predefined you can actually compose the
lambdas in the classic ways you see in
the Java Java util function since so you
have your anthems and your compose and
all that so you can compose these
together and compose expressions in a
lambda sense so you retain that sense of
composition but it's still very symbolic
so and I leave out the code for this but
when we once we have these these you
know when I still have an expert there
but that's expression float method
handle binary reduction takes one of our
operators that we've defined in this
fashion and then also takes source
source operands so an array left and
right which are our sources and then a
syncing array in the style we saw in add
arrays before but in a more generalized
sense so we we do a binary reduction
left-right test we give it our our
lambda body and we can execute it what
this does is this this binary reduction
does a selection of who's my who's my
evaluator for the system I'm residing on
and in the draft implementation it just
assumes the presence of a be x2 and and
goes along its way
plums it generates method handles and
then invokes the method handles in a
fully applied sense so what I'm
interested what I was particularly
interested in this experiment was to see
how specialized we could get the code
like how shrunk down specialized you
know no no additional call invoke
overhead etc and so forth so to do that
you know then you you invoke it once
just to say you invoke it and then you
do it like 25,000 times just to make
sure that like everything's fully in
line so we can get the next slide and
brag about it so this is the generated
code from what started as an abstract
syntax tree hosted in Java we have the
array based addresses here we have our
loads and there's a lot of text here
because there's a lot of this is
debugging so you have a little bit of
cross at the top but it's it's not much
you move down so the snippets are
outlined in snippets
so when you an ice thing about code
snippets Vladimir's done is when you
print the generated assembly the
snippets are wrapped so you can find
where they're what's actually a snippet
and what's being generated by code gin
so snippets are encased in these little
snippet locations the the word the names
for them are are listed as well so we
have our two loads and then after our
two loads comes our vectorized ad and
our vectorized mol and we store it and
then another thing about the binary
reduction I forgot to mention was that
it uses looping method handles so I was
you know where's Michael at he's over
there there you are method handle loops
you have a customer right here so those
are great those are great so before that
I was I had to have these little you
know dangling static methods that I
would have to bind to myself but now I
can use the API that's great and I don't
have all these mystery methods that
never get invoked directly they just
method handle bound but with loops
that's what we're that's where we're
gonna go with this the method handle
loops so essentially this is a counted
loop except that it steps it steps eight
instead of one so at the bottom you see
just the loop bookkeeping so we compare
two I think hex 200,000 is the length of
the array just for test two sake and
then if we're if we're there yet if
we're there we fall out if we are not we
jump back to see 83 b-26 70 which is
right where the first load occurs 83
b-26 70 so the code that falls out of
this is like very nice there's the loop
there's the vectorized operations and it
feels really good so if in expression
trees are so great and why don't we just
use them all the time well so there's
some issues with the expression trees
that make them probably not the
one-size-fits-all answer and the one
that comes to mind for me the most is
control flow
if your reasoning about Lane wised
operations and you want to begin
branching based on one but that one
lives in a vector with another one that
doesn't want to branch you now have this
kind of oh gosh what do I do
so you you you have to seed some you
have to you have to make a choice so the
vector API as stated earlier gives you
more high-level branching possibilities
that's not to say though that we could
get some control flow mimicked in masked
vector operations so if you have ternary
style sort of total arithmetic branching
so if in sort of the functional sense
where it's if this or this both return
expressions that's a possibility you
could probably do that with some masking
or some very limited well understood
control flow choices but as far as
masking operations are concerned those
are those are a little bit harder to
come by in the eye so for like a total
set of operations at this point so TBD
on that working on it so essentially
you're kind of presented with this
choice where you can have fine grained
control with coarse grained aid or you
can of course grained data with fine
grained control so control being control
flow you can make your choice I would I
would I would hazard to guess that the
expression trees high-level kind of loop
body construction approach can get a lot
of people a lot of mileage without
having to delve into specific vector
specific vector level reasoning about
them in that way so I think there's
something for everybody in both of them
and the expression tree approach will
may end up living in the higher order
components of the vector API but like I
said it's all a prototype I know it's
all TBD so wrap up so some challenges to
idiomatic design here
the boxed elements and I mean not the
long objects but generics are behoove
box fields so how can we reduce our
complexity of our API knowing the value
types are coming well we're kind of
stuck until value types come but that's
that's okay we can do a lot of hands
specialization - to get rid of our
boxing immutability in this case is
facilitated by new which is fine so long
as escape analysis can work on it so if
we can ramp up a scape analysis and our
coding style so we can avoid unnecessary
allocations fine but if something messes
up as I've seen in some tests if you
have tight loops and you're allocating
long fours long fours just go right
under the garbage like it's they just
get tossed right into garbage you have
to be really careful how you do it and I
think some of this behavior will play up
through the vector api itself if users
of that API aren't careful enough so it
has to be understood how to code in this
API to avoid these things and it kind of
gets me into this place where I'm a
little less comfortable where you say
vector operations return immutable
objects but no objects really get
returned it's just kind of this value
thing it's intermediate if you use it
the right way so you risk falling into
this like operations and semantics
Twilight Zone where like the semantics
of the API are highly dependent on
compiler optimizations working correctly
and it's not comfortable but if Valhalla
is coming it may we can just kind of you
know continue on a little uncomfortable
and and then you know we'll make it out
of the spaces
lastly idiomatic is a moving target in
Java I mean I've demoed some of this
syntax stuff before and people kind of
go huh and so I am I am loathe to impose
too much Lisp like syntax s expressions
on people just to use vectorization
however though I think the cogent kind
of speaks for itself that methods in
this vein have value so how can we take
this value and make it palatable to the
developers who want to vectorize their
their data their data processing like I
said before value types are coming
they're not quite here yet we can play
like they're coming soon so yeah yep so
anyway
so continuing work we're enhancing the
baseline vector API kind of finding that
minimum viable API doing some more
exploration on higher-order
functionality because I think that's a
really rich and very powerful component
to the API and we're digging into what
the trade-offs are so what I showed you
right in this last set of slides or less
set of images of code generation was an
incredibly specialized data specific
operation specific set of koujun so how
can we back off of that and still get
the code quality that we want and be
flexible what are the trade-offs what do
we got to do so we will be reporting
back at JavaOne with some hopefully
better data and on perf and just code
itself and i'm looking forward to that
so if you're interested Panama project
you know what you love it it's up there
discussions are on Panama dev vector API
code is in that directory there and the
prototype implementation as we said
before probably it'd be nice to have a
BX - so check your proc info if you
don't you can probably still do quite a
bit - so so just be warned it's it's
still a bit rough around the edges but
if if you if if you want to try it it's
there to play with so that's it for me
so thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>