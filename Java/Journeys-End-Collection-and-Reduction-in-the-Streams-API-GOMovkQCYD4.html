<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Journey’s End: Collection and Reduction in the Streams API | Coder Coacher - Coaching Coders</title><meta content="Journey’s End: Collection and Reduction in the Streams API - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Journey’s End: Collection and Reduction in the Streams API</b></h2><h5 class="post__date">2017-10-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GOMovkQCYD4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning thank you for your patience
thanks for coming to this talk today as
well so I'm going to talk today about
collection and reduction in the stream
in the stream API this is a talk about
basically about Java 8 so the idea of it
is if you've been using the stream API
or if you haven't been using the stream
API but you aren't
but either way you aren't really very
confident about the quite large subset
of that API which has to do with
collectors then this talk is meant to be
for you so I'm not going to spend a lot
of time on streams as a whole I'm not
going to I'm going to assume mostly that
we know we know roughly what's going on
there and we're going to focus
particularly on this one particular
operation it turns out that it's quite a
large API and it's actually worth
delving into because you can do a lot
with it and I hoped to show that during
this during this talk so so just just
who I am if you've heard of me then it's
because I've written these books on a
couple of books on Java and if you
haven't and that's not entirely
surprising I like to say the Java 5 book
is the best book in print the best book
at all are devoted to generics I'm
concerned that without any fear of
contradiction that joke has lasted 10
years it's obviously the only one I
couldn't say it couldn't be so certain
otherwise and then I wrote a book on
Java and the but in this book which is
really about streams although it's got
lambdas in the title it's really much
more about streams in about lambdas is
what this talk is based on so and and
then I'm a champion and I'm the Java one
rock star and stuff like that um so the
agenda for today is I'm going to talk
about why we want collectors and what
that's about that actually takes up
quite a lot of the top because I think
because I think having some background
on what's going on is quite useful then
I'm going to talk about the predefined
collectors that are provided by the by
the the framework and then we'll
probably take a break if I haven't used
up all of my time with fiddling around
with cables and we'll take a five-minute
break and then we'll do some worked
examples and and the idea that this is
that you're going to you're going to
write the code for me if I can manage to
get IntelliJ up without touching the
cable then well
a bit of live coding in the second half
and actually see some use of these
collectors and then finally there's a
there's a very short section maybe 10 or
15 minutes just to round off the talk
about how you how and why you would
write your own collector so the example
domain for the talk is made as simple as
possible we just have a value object a
person with three fields a city which I
presume to be an enum but we never
actually never actually see it defined
and and a string field and and an int
field so the idea that is to have a
couple of reference fields and and the
primitive field cause that because that
works differently and that gives us some
different problems and the kind of code
that we'll be seeing is really as simple
as it could reasonably be we're going to
be creating a new person and we're going
to we're going to be making a list of
person objects and then we're going to
be seeing the different things that can
happen if you use that as a source of a
stream and essentially what we're going
to be doing is operations on that and on
the streams that are produced that way
and then we'll then we're going to
collect them and we'll see what the
collective is about so just to take it
for a little while just to take a kind
of higher level view what's going on
what's going on in the stream well the
life of a stream element is is it begins
at a at a splitter rate that's how it's
born so the idea of a splitter ater is
it's it's a kind of cute name for
something that can both iterate and
split and so it iterates if it's
processing the stream sequentially
because it feeds the elements of the
stream in feeds the elements from its
source into the stream one by one so
that's iteration as we know it and and
it can also do under certain
circumstances it will it will also split
the the its source imagine say an array
or a ray list then you can see that the
that you could process that more
efficiently if you had parallel hardware
by first breaking it down into into into
sections each of them being suitable for
until you have as many sections
essentially as you have cause to execute
on so in this case I'm imagining that
we've got a
an ArrayList or an array and it's split
in two it's been split twice into 4 into
4 pieces because it's executing on 4
core hardware all this is done
automatically for you by the by the by
the stream API if you want it to happen
all you need to do if you want to if you
want to get the difference between a
sequential stream with in which case the
splitter ATAR is just iterating you just
say I want to stream and if you want to
and if you want a parallel stream as
we're going to see here because each one
of these yellow things is a pipeline and
in and essentially the different threads
attached to each of the different cause
it's executing the the code for the for
the stream pipeline on each one of the
data sets each one of those subsets and
and if you want that to happen you'd say
I want a parallel stream instead of
saying I want to stream and it's really
as easy as that whether you'll actually
make any real gains from doing that it's
a different matter
because for to get a significant
improvement in performance by going
parallel as we say requires that
requires a number of conditions that may
not that aren't met in many common cases
but it's so the idea of the building
parallelism in was was that it should be
explicit but unobtrusive that was a
slogan of the stream of the stream
designers and and they and they
succeeded it is it is parallel it is
explicit it is unobtrusive it's very
easy to use and probably too easy to use
because many people have been quite
disappointed not being not having fully
understood the situation in which you'll
get benefits they sometimes have been
disappointed so what happens is then the
elements come down these the elements
come down these different pipelines and
then they're collected by it by a
terminal operation so these so the three
that so the three stages of the life
style lifetime of a stream element are
the the splitter ATAR where where
they're born the intermediate operations
where they're transformed and they're
finally collected by a terminal
operation and we're going to and we're
going to be concentrating on the
collector I should say probably that
although I've kind of although in that
little introduction I've not been very
positive about parallel execution the
idea of parallel execution was still
very
to the stream API designers because what
they wanted was to make sure that the
code that you wrote the code that you
write for streams should be equally
executable either in parallel or
sequentially you may get very different
performance depending on depending on
your particular hardware setup and other
things but the but functionally it
should work in exactly the same way so
this is a very important design
motivation and sometimes you think there
are things missing from the stream API
why why can't I do this
and the answer is because you couldn't
do it in parallel and if you can't do it
in parallel then you can't do it you
can't do it at all in the stream API so
I call in the book that in the book on
lambdas I call this parallel ready code
so you even if your code isn't going to
be executed in parallel it should be
ready to be executed in parallel and
they see that as the way forward for for
collections processing in Java okay so
the so now I'm going to focus on the
terminal operations a bit there's three
kinds of these and I'm only going to go
through two of them very briefly because
I'm not interested in I'm really
interested in the third one very much
the search operations are things that
all match and any match and find any and
find first C's these these terminal
operations are the things that actually
pull the data down the stream down down
the stream in it so you could set a
stream up by saying I want I want I want
a stream but until you actually say
until you actually provide a terminal
operation start the execution of that
nothing moves so here what we're saying
is we want to we want to get back a
boolean corresponding to whether or not
all of all of the adults all sorry all
of the person objects in that in the in
that people list have have an age field
of greater than 21 and if they do then
that'll be true and if not that'll be
false find any and fine first working
something like the same way they
returned an optional because they're
looking for something that meets a
condition and it might not be there and
it might be there these things that
these these are called short-circuit
operations and they're quite important
from the point of view of processing
infinite streams because of all of these
search operations will stop when they've
when they're when they're satisfied so
for example in the case of the example
the example code there
if the
could you could have you could have a
really long list of people person
objects and you could be processing them
sequentially and if the first one is not
an adult the first one has an age of
lesson two of less than 21 then
processing will stop so it doesn't need
to process the whole stream in order to
in order to evaluate the condition so
these short circuit operations are very
useful without them you actually
couldn't do anything useful with
infinite streams the second kind of
terminal operation our side affecting
operations everyone loves these because
they look like you know what you're used
to
so if you see you've got but so you've
got for each and every one says alright
okay I really can do it eration here so
one of the points I'm going to be making
in this talk is you really can't do it
eration any longer you see for each you
think hey I can do it eration so so for
example for reached here takes a
consumer that's something that just
takes the value and doesn't and and does
something with it but doesn't return
anything and we've got here that we're
going to print out each of the person
objects each of the personal objects in
the stream so the first question is
could we maybe use these use these
terminal operations these side affecting
operations
they're called side affecting operations
because they do something to over to a
value that's outside of the stream could
we maybe do that by calculating it's the
total of the ages of the of the person
objects in that list will that work
sequential or parallel will it work
well okay listen that's that's that's
interesting so the answer was sequential
II it will work in parallel it won't
work naturally that's slightly off
actually this won't compile the beacon
because because some is some is not
final that's the kind of that's that's a
sort of trivial answer because then
you'll say you'll fold your arms and
you'll say ha why did they put this
stupid restriction on some has to be
final or actually as we now say
effectively final so why did that why
did they do that well the reason why
they did that was because of what I said
a moment ago which is that it should
work properly in parallel and you're
kind of right that it won't work in
parallel it won't work in parallel
because not because I mean supposing we
we did some trick to get around the
effectively final thing we could make
some into a field or we could use the 1
element array trick or something like
that but even if you could write this
you wouldn't want to
and the reason you wouldn't want to is
because some if you imagine it executing
in parallel this variable sum will be
hot it's gonna have to be accessed by
every single thread right so every
single thread will have to will have to
get hold of it and and the reason why
you're saying it won't work I guess is
because it's not guarded here you would
have to synchronize on it and that would
be a tremendous overhead that would just
be really that would completely remove
the point of having parallel processing
in the first place if you had if you
have to synchronize on every access to
some so we really should not calculate
ages anything like this it's not just
not just this particular example but
anything which which uses an accumulator
effectively we're going to have to get
we're going to have to stop doing that
and the and the argument of the stream
designer this was that not only we
shouldn't feel we shouldn't feel bad
about this we should be pleased because
we're going to find a better way of
coding so they have a quite an
evangelistic attitude in the in the
design of the stream API there's a push
towards functional programming and and
you'll see I hope that it actually gets
results so so
so we're gonna use reduction this test
now I get on to the kind of terminal
operation I'm really interested in which
is reduction so what's the difference
between between reduction and and used
and why do we want it I suppose is it is
the question here so here I've got the
the kind of code that you would imagine
writing if you wanted to calculate the
total of the values in an array and here
I've got here I've got an execution
graph of it just very very roughly you
can see that what's going to happen is
that the way that this the execution of
that statement in blue there is going to
involve repeated additions to the same
variable so first of all we get the
value 0 we add 1 to it then we got it
value 2 now that we have that to the to
the value we've accumulated and so on
and that and that of course is going to
be is going to give this this huge
problem that I mentioned that that we're
going to be that without synchronization
it will be wrong and with
synchronization it will be slow and it's
just really an elegant anyway so if
you'll want to avoid an accumulator we
can use it we can use so-called reduce
operation the one I'm going to look at
here is that there's two overloads of of
reduce four-inch streams one of them
which takes a binary operator on int and
one of them which takes which which
takes a base value and a binary
operation on it we'll see the difference
between them but the one I'm going to
look at is the first one now so avoiding
an accumulator you you would right you
could write something like this so here
what we're doing is we are we're taking
the the values and we're putting them
into a stream this is instead of using a
list here I'm just using an array and
we're going to and we're going to reduce
them over the over this summation
operation what's that mean the a it
means that we're going to say that that
operation is going to take two in and
it's going to return the sum of them so
the execution graph will look like that
will look like the thing on the right
now and you can see that if obviously if
you scaled it up because this is
trivially small but if you had a if you
had a much larger array you can see that
you would get you would you would get a
big gain in terms of they focus on a
single on a single variable so what's
the condition needed for this to work
well the answer is that
although that's one possible execution
graph for this for that code it's not
the only possible one so whether how the
splitter ATAR works to divide the to
divide up the the array structure is
something that you can't really know in
advance so you shouldn't have to know
the detail rather you should define an
operation that is going to work whether
it gets split and the condition for that
to happen is that the it for example we
might get we might get this rather this
different this different execution graph
that's also possible and it's certainly
possible quite clearly if you if you
were working with the with a sequential
stream so the condition for it to for
the condition that's required for this
for reduced to work is that the binary
operator must be associative associative
means that that a plus B plus C has got
to be the same as a a plus B plus C in
other words it doesn't matter how we
group things the order is still
important we're not talking about about
things that operations that are
reversible or commutative but we are
talking about we're talking about that
the way that we group operands to the
operation that we supply to reduce has
got to be has got not not to matter so
you can see that if we scale this up now
we get it we get a better picture
supposing we wanted to add together a
lot of different things then you can see
that here you've got suppose you
wouldn't we're imagining that this has
two threads this is executing on two
threads and and they can proceed
independently until at the end they're
going to have to they're going to have
to be the results are going to have to
be joined together now you might think
well this is a huge overhead and a lot
of waste of time for just for doing
addition and you'd be quite right so
Regis so there's no way that reduction
it's actually going to win over over
using an accumulator in terms of
efficiency for simply for addition but
if you if you have intermediate
operations which which are more than
just addition remember that remember
that what we've got here essentially is
that it's a pipeline I mean I've just
simplified it down to this very simple
to this very simple case but if you had
a pipeline which was computationally
heavy and this is the important thing
computationally expensive then in that
case distributing that out over
different
cause and allowing them to proceed in
their processing could get your big gain
so you'd serve for example if you're
doing cryptography calculations or if
you're writing a chess program or some
other thing that's going to require a
lot of heavy computation then making the
maximum use of your parallel cores and
nearly all machines now do have parallel
course or server machines certainly do
that's going to be that's going to give
you a that's going to give you a big
game and that's the that's the kind of
the underlying architectural motivation
towards towards towards this kind of
thing okay so so that's how a reduction
works arm primitives that's a very
simple case and reduction works on the
immutable values to reference values as
well so and it's defined in the API so
I've shown I showed you reduced defined
on in streams and now I'm going to show
you reduced defined on streams and you
know we've got these four different
kinds of streams the primitive ones in
double and long and then we've got
reference streams so they did define
reduction on reference streams and you
can see that it can sort of work so
there are not very many immutable value
table reference types in the platform
API but one of them is big decimal you
can't you can't actually alter one of
those and and so for example if you want
to add up a list of big decimal then or
an array of big decimal then you can
reduce then you can reduce them in that
kind of way but what about so that's
immutable values but what about
collections collections are not
immutable well how can we can we reduce
can we can we use reduction with
collections the API gives you to
understand that because after all
they've defined the reduce operation on
reference on reference values so it
looks like it ought to work and in fact
the truth is that they didn't that they
there was a lot of time pressure on the
definition of the of the stream
framework and this was something which
if they'd have had more time to consider
might well not that might well not have
slipped through not because it isn't you
not because it's completely useless as I
showed you in the bigdecimal example you
can use it but because it's
very misleading and a lot of people have
fallen down down and out down a trap in
this case well there is one way in which
you could make reduction to collections
work and that way is kind of pretty
horrible you could take each element of
your stream and you could and in the
client code you could create a new empty
collection and then you could submit
that and then you could submit those
collections to the to the just for a
reduction and the reduction operation
would be a doll that a dormer just
merges two collections together it's
it's possible to do that and I will show
you an example at the very end of of
doing it but it's not something you
would ever want to do in practice it's
really it's really it's really pretty
grim
it's it's extremely and if it's going to
be extremely inefficient because you're
gonna have to create lots and lots of
extra objects and you're gonna have to
use a door which is typically all the
time which is typically much more
inefficient than the add operation on
collections and basically it's horrible
so we can do better so over an identity
alright so I just wanted to say that's
right before I go on to talk about about
collection so I just want to look at the
over at the other overload I've talked
about the about the reduction method
that takes a single operator well what
about the one which takes a base value
and handin operator so that's going to
be important for what we took for what
we talk about next and we've got those
both for both primitive streams as well
as in the top and for reference streams
as in as in the lower example there and
you can see an example here where in the
code I'm calculating the sum there of
over an array of bigdecimal
and the way that I'm doing it is by
reducing over big decimal zero as the as
the base value and then and then each
and then each successive operation will
be will will be add and now that works
and it that works in a particularly
useful way because it means you don't
have to return an optional you know that
even if the stream
empty we had an optional in the past in
the previous example from the from the
other overload you can see optional int
and optional of T on the slide but for
this one you don't need to have an
optional because even if the stream is
empty you know that you know there's
going to be at least one value one value
is going to come back because you
because you've got big decimal zero to
start off with so that so this works so
this works for immutable objects fine
and and this is what it looks like
reduction over an identity looks like
this now so we've got a we've got our to
the two halves of the potentially much
more than two but the two halves of the
array here and we and each thread is
what it's going to do operating on the
separate core it's going to start off in
the case of it in the case of our big
decimal here it's going to start off
with the zero and then it's going to add
the values sequentially when it's
finished doing that bit when it's do it
when it's finished doing that and when
all the threats have finished doing that
they can merge the results together will
this work with collections
well reduction over an identity doesn't
work with collections at all why not
no not immutable but I only but I was
the one who said that this should only
work with them you too if you try to do
reduction over collections you'll not
get a compile error or anything you'll
not get an you'll not get an execution
error that we know it won't throw an
exception or anything like that but
you'll just get the wrong answer
well supposing it supposing I provide
supposing and providers so the question
so the question is is it
non-deterministic because I don't have a
starting value but suppose I provided an
empty collection same ways I provided a
big decimal zero there and then to
collection for the starting point does
ordering matter ordering ordering will
influence the result yes absolutely but
it's not actually that it's not the key
so depending on what on what order the
the threads execute you will get
different results in a quite an
unpredictable way I touched the cable oh
no I touch the cable we're done but at
least at least I've got a discussion
point anyway to go on with all I did
this it's just a merest brush so the
problem is with the this is a real
example of multi processing can I do
this so the the the reason why it won't
work is because the Assumption behind
reduction is that the is that the base
the base value is if you that the
assumptions the base value is immutable
I just read really carefully
it's a game isn't it
the the assumptions of the base that the
base value is immutable so that point
about immutability is really important
so basically each thread is going to try
to use the same the same base value for
it's going to try to use the same base
value for for its computation so what
will happen is if you say I'm gonna if
you offer it if you offer it a a an
empty collection if you say the empty
collection is to be the start of this
reduction then every thread will take
that same collection as I start of the
reduction and it'll be empty to start
off with but when the second thread
comes along it won't be empty any longer
but the second thread won't know that so
the threads will get quite confused and
I'll get they'll make concurrent access
to that collection so it won't work it
won't work it doesn't matter well it
probably will work let me think of it
let me think from home will it work on
us on a single thread it doesn't yeah
it probably it probably will work on a
single thread if you're lucky but if the
but absolutely the way that the the way
that the API is specified is it says
absolutely you not guaranteed to have it
work you're not guarantees so at some
point in the future when somebody says
ah this program looks like it might run
better on parallel hardware your program
will break I mean your program is
absolutely not thread safe and it will
take very little change in how it in how
its even and how its deployed possibly
in the future and deploy lots of
different hardware and it might break so
you so it so it's not it's not it's not
the road to go down we've got to do
better than that and so the answer to
this is the answer this is collectors
and the idea here is that instead of
supplying an identity a base value we
supply a function so the function is
executed by each thread and it produces
a new fresh empty collection on each
occasion so so it's a in this case it's
a lambda of the I'm imagining it so that
for this particular collectable code
whatever it is it's a lambda which takes
no arguments it's a supplier when they
in the language of the stream API it's
the lambda function API it says it's a
supplier which takes no arguments and
returns something in this case an empty
and empty collection and if you eat
thread calls that when it when it starts
work then each one is obviously going to
get its own separate new fresh thread in
the new fresh collection so there isn't
reduce overload that looks like this but
it uses an identity and not a supplier
it's very similar but it's just a
warning to you that if you ever if you
ever are trying to do reduction over
over over stream don't and you're trying
to reduce onto mutable values the
reduction doesn't work and that's really
the reason why the API should maybe have
a warning in it or something like that
but hey we don't do that with Java guys
and we don't put warnings in the API
documentation but we really but we
really should in this case so that's so
this is the answer now we've got these
things now we we've seen the components
of a collector here we've got the
supplier in blue we've got an
accumulator which which so-called which
adds
elements to to a container and then
we've got we've got the the end when we
when we the each thread is calculated
all the values it's going to calculate
the results have to be joined together
in something called a combiner so that
and that is what that is what what we're
looking at is define a collector you
need to provide all these three things a
supplier an accumulator and the combiner
and that makes it sound like it's gonna
be really hard and already you're sort
of thinking this is too much for me but
don't think that because I'm kind of
broke I've sort of broken the rule
really here and it was a rule that that
Brian gets was very emphatic when I was
writing the book he said don't tell
people about this stuff he said because
he was very concerned that it would look
hard and he said I want them to
understand it's really very easy we
don't actually have to define collectors
of our own very often at all there's a
vast array of a vast number of of
collector sort of given to us by factory
methods in the collectors class and
those are what I'm going to spend most
of today talking about because they're
really useful and they save you from
having to do this work nearly all the
time and I will talk at the end about
writing your own collector but it's not
something you have to do you have to do
very often okay so so that's the the
basic motivation behind the behind
what's going on with collectors and now
I'm going to talk about a bit about
using the predefined collectors that
this is really kind of the heart of the
talk in a way apart from the practical
work that we're going to do this is this
is the heart of the the information so
the collectors API is provides these
factory methods in the collectors class
they produce standalone collectors and
I'm going to that not all the collectors
are standalone some of them are only for
use as downstream collectors and I'll
explain that in a little while but in
the first place let's look at these
things that are standalone collectors
because they're easier to understand
they are and though I'm going to say
they fall into three categories
once the ones that will collect into
framework supplied containers ones that
all collect into custom collections
where you where you supply the
collection yourself and think that
something I'm that I call classification
maps which are the ones that are
actually most versatile and useful
so the predefined collectors are kind of
straightforward they come from factory
methods as well from factory methods in
the collectors class these factory
methods I'm not going to be writing
collectors dr. lists and collectors dr.
set because it would make the slides
unreadable but anytime you see you see
methods like this this is this is what
they are they come from the they come
from that class and they and the the and
sorry the the top line the top line of
these are these things which will which
the frameworks provides the supplier in
the case of two lists it it was it will
currently it will collect into a into an
ArrayList not guarantee that is always
will no part of the specification but
that's what it does and a hash set and a
hash map again not not not define
joining is slightly different
what joining does is it can helpfully
concatenate strings so it does things
like it concatenate strings with putting
interspersing commas between them if you
want or some other separator rather than
you're having to do this clumsy thing
that we always used to have to do of
iterating over them then taking the last
separator off so it does that and then
will allow you to specify a prefix and
the suffix and so forth so joining falls
into this category it's this way I
talked about containers rather than
collections because the idea of a
collector is collecting into something
that will hold the result really rather
than rather than always a collection it
often is in the the to map and to
collection are will allow you to specify
your own kind of maps but you want a a
tree map or a linked hash map say or
something like that or supposing you
want your collecting to a deck or some
other some other things that that
implements the array deck some other
things that implements the java.util
collection so the user would probably so
you would provide it the supplier in
that case and then last of all these
things that produce classification maps
and will be looking a lot at those so
I'm going to illustrate how these things
work with with animations which are kind
of start off looking a bit a bit over
simple and you'll think I'm insulting
your intelligence but they do get a bit
harder here's an example of what would
happen if you wanted to collect the all
the elements of the person stream
into into a into a set so the the code
the code is at the bottom collectors
doctor set and and the my idea of the
animation is the thing on the left is a
is it's going to be a stream and the
person objects will come along it and
and then and what will be emitted at the
right-hand side is whatever we're trying
to get so in this case it's pretty
simple the the collector creates so it
creates a hash set object and internally
and that and it puts each of the
elements that come down the stream into
into that into that hash set object and
then when the stream is exhausted at the
end when the automatically it perceives
that the stream is exhausted and then
and then the set then the set is emitted
so that's pretty straightforward
mmm the and I won't insult your
intelligence by showing you the same
thing about to list because it's kind of
obvious but maybe to map is slightly
more interesting because to map takes
take two functions it a function which
is going to provide the keys for the for
the entries of the map and a function
that's going to provide the values so in
this case we want a map from city for
for all of the for all of the persons in
for all the person objects and people we
want a map that's going to that's that's
going to for each city give the
correspondent given the name of a person
of the person who lives there so the way
that works is like this again again it's
it's kind of this kind of simple bill
comes in bill lives in where's bill live
he lives in London so London becomes the
the the key for that for that entry and
and Bill's name is surprisingly bill and
so that becomes the value for that for
that entry and now here comes a me and
Amy lives in Athens and and her name is
also Amy so in this way we're building
we build a map up and and in due course
these stream is exhausted and that map
comes out we get a map from city to
string because because the key mapper
producer took a person and gave a city
and the value mapping took a person and
and give a string so that's that seems
pretty that seems pretty straightforward
but what happens though I mean you can
probably see any meat a snake coming up
straight away and what happens if two
people live in the same city pun you
will get it you will indeed get it
collisions here's John and now John has
moved to Athens what's going to happen
there well you can't have two to map
entries with this with the same key
obviously so it by default what you'll
get is an illegal state exception you
might not be bothered about that because
after all you might actually have a data
set where you actually knew that
everybody was going to be in it that all
the keys were going to be distinct but
it but there's another overload which
allows for the possibility that this
situation might arise and you might want
to handle it so this one takes has the
key mapped on the value map as before
but now it also wants a merge function
and the merge function takes two two
values and two values in the value
domain and does something with them and
gives you back a value in the value
domain so in this case I very simply and
what I've done is I've taken the two two
strings and I've concatenated them
together just to be just just for the
simplicity of the example and now you
can see that if that code is executed
and and and it turns out that Amy and
John live in the same place then here
comes here comes John now we've got the
same collision and in this case what
happens is since we've got the since the
lambda at the bottom which takes the two
string values and joins them together
that's what's going to be put in to the
to the value of that entry in the case
of that collision so that's what's going
to appear so I should say the reason the
reason why I go through all of that is
when when you first of all see the
signatures like at the top there and
they get the I mean that's getting a bit
complicated and they get a lot more
complicated and if you're not used to
this ap I know when I first met it IV
some no there's a lot of angle brackets
there really is and and there's a
naturally in there in the real API
there's quite a lot of question marks
which I've taped which I've edited out
of the slides for simplicity so it's
quite off-putting and
and I think it's quite a good idea to
just you know to maybe to get over to
you that what's going on behind the
scenes is actually really a lot more
simple so that's just right so that's
the framework that's the one that does
the framework supplied containers and
that's them they're custom collections
is pretty is pretty straightforward
there's there's a to map method here
which is going to which is going to
allow you to to collect talk to a custom
map I've taken the example here of a
tree map you notice that the because of
they're all the difficulties that we now
encounter with overloading overloading
produces more method overloading
producing more and more difficulties as
time goes by and the language is
extended so it gave a lot of problems
with lambdas and method references and
so now they it's a fashion in API is to
not define to not define two methods
with the same number of arguments so
that so that for example here although
you probably you may well not want to
merge function you're still going to
have to supply motor function if you
want to supply a map supplier because it
because the if we left out the merge
function just allowed you to supply them
at the map function only we'd have to
met two overloads each with four
arguments and then method overloading
starts to become very difficult so we're
playing an easy way now so you have to
supply an emerge function but of course
if you don't really want one if you
don't really want to one then you can
just go back to the default which is to
throw an illegal state exception so what
about this map Factory well I haven't
got an animation for this but the idea
is that basically it works in exactly
the same way as I as the as a previous
map example shirt did but in this case
you are telling the the the collector
what to put as the container that it's
collecting into so you see you you give
it what it'll do it it was call the
supplier that you provide in this case
we supplied the the the supplier we gave
was that was a parameterless constructor
of tree map and so it will call that get
a tree map and it will and it will use
that as the box that it's going to
there's going to collect into
it does indeed sorry because so the
question is at the end does it have to
combine the multiple multiple tree maps
that it's created yes absolutely so it
has no map merge at the end and it has
to do that in a thread safe way because
tree map of course is not it's not so
it's safe so that one of the big bonuses
of the of the stream API is that it
allows you to use parallel streams and
do parallel processing collecting into
collection containers that are not
themselves thread safe and it manages
the thread safety for you but obviously
there's a cost and I mean the cost is
really quite high for example emerging
tree Maps that's a really quite an
expensive operation but but it's safe
it'll do that safely that's defined so
so there's two characters the two
methods for collecting two custom
containers one of them is the one of
them is for custom maps because of
course maps don't implement the Java
util collection interface but everything
else does or queues and sets and this
all implement the the the collection
interface and so the so the method for
that provides you with that will allow
you to to collect to a collection looks
like this that's the signature but the
but the the parametric type see is as
defined as being it has to be it has to
be a subtype of collection and and and
what that returns is a collector which
will take I should have I should have
said something about the the arguments
to the the type arguments to the
collector the the first one is the type
that's being collected the last one is
the type that is being collected too so
so I mean typically for us it would have
been like a person and list of person
and the one in the middle is an
intermediate type which is used
internally within the within the
collector it's there's a there's an
extra stage that I haven't told you
about that happens at the point in which
the values are emitted so it's called a
finisher and once all the values have
been collected together something
sometimes has to be done
to them in order to in order for them to
be emitted
the simplest example that would
immediately come to your mind is if you
had a if you're using a stringbuilder
internally to build a string up but
you're actually what you wanted to
return was a string so the finish are
there well that would would do that
would do that job usually you don't have
to worry about that about that middle
type parameter because unless you're
writing your own collectors it's not
usually very important so the reason I
laid out the that's the method
definition of to collection is because
if you see that in the in the API
documentation if anybody still looks at
API documentation of course I'm an
old-fashioned person then it looks
pretty menacing but actually it all fits
it does all fit together here's the
example of of using two collections
supposing we wanted to collect not to a
tree map but to a tree set while tree
set is just to kind of set and so it
implements the the the collection job
util collection interface and here what
we're doing is we're making it as we're
going to get and a set of sorted named a
set of names but we want it to be sorted
we wanted to be created sorted if you
put things into a tree set then they'll
be sorted on their natural order in the
usual in the case of strings that's
their alphabetic order in the usual way
of things so so this code will give you
back a set of a set of a set of the
names of the person objects and in
people sorted by alphabetically so
that's the first two types frameworks
supplied containers and custom and
custom collections and the third type is
classification Maps so these these are
all created by by grouping by also by
grouping by concurrent and and
partitioning by both there's that's not
very important grouping by is really
that really the one that matters we've
got three kinds we've got simple ones
that with downstream or the downstream
and a map Factory let's have a look at
these
so here's grouping by with a with a
classifier the idea this is it'll make a
classification mapping it's sort of like
to map except that the values that are
placed in the map are our lists of
elements our lists that
I should say the big the big l1 list
corresponding to each classification key
so for example if you use person get
city as the as the as the classifier
then you would get a map from city to a
list of person and that would associate
each person that would associate each
city with the put the people that lived
in that city and the code the code for
doing that would look like what you see
at the bottom there
people got stream clicked collectors
grouping by and that means that what
we're going to do is we're going to
apply that that function that method
person get city I'm going to apply that
to each person object as it comes
through and then we're going to and
we're going to use the result as a key
and we're going to take the we're going
to take the person object and add it to
a list of list of persons that
correspond to that so here's a bit of
his how that's going to work in a in an
animation so we bill and John live in
London and Amy lives in Athens now
they're moving about these people so
bill so bill comes in bill lives in
London and so he gets put into he gets
put into a list of person objects
associated with London and Amy comes in
and Amy goes to a is added to a list of
persons that they're associated with
Athens and John comes in and kind of
obviously joanna is going to be added to
the list the bill is in and now the
stream is exhausted and that and we've
got and we get out the map from city to
listen to the list of person so that
seems pretty straightforward and
possibly quite useful we'll see ways in
which it's quite useful but it but quite
limited so like what if you didn't want
to put them into a list every time
suppose you want to do something more
with them one of the things that I've
said about the that I haven't said about
the great virtues of the Collector's API
is that it's very composable so you can
we're going to see how you can fit
different collectors together and build
up quite a complicated quite a complex
and elaborate processing pipeline just
by fitting them together so we'll see
how that works this is this is this is
the start of it supposing you wanted to
suppose you wanted to
make something other than a list maybe
you wanted to make it maybe you wanted
to make a set instead well there is this
idea of a downstream collector so a
downstream collector is one which takes
the values that have been that been
emitted from from a collector and it
within the same collector a does some
further work on them so you get an age
of clip of collection work so so if you
sort of the overload of grouping by
which takes a classifier and the
downstream collector uses the classifier
function to make a classification
mapping into a container which is
defined by a downstream collectors and
another stage goes on so it's so so the
values placed in the map are containers
of the elements and one container
corresponds to each classification key
so if we wanted to get a set of person
rather than a list of person we would we
would use the we would use a downstream
collector to set remember to set is a
factory method of the collectors class
which which creates a collector for you
so it's so there's like as a collector
embedded inside of this collector here's
that here's the diagram did you see the
downstream collector is actually
embedded inside of this this outer
collector and his in his how it's going
to work bill comes in and he goes and
and he and he gets clattered he gets put
into not not that not a list as before
which was automatic which was the
automatic default but into whatever were
into whatever container has been defined
by the downstream collector and and and
in this case it's to set so you can see
these are like little little versions of
the to set collector that I started off
with and then and and then so on with
the rest of them the name Ian and and
John so actually you might say well like
how does this relate to the to the to
the default one which which just clips
to a list the answer is that it's
exactly the same the the default one is
exactly it's just the same as this
except instead of having a to set
collector embedded but then it it's got
a two list collector embedded within it
so it works in just the same way it's
just they obviously thought it was
convenient for you to have a default but
you didn't have to think about where it
was
go so that's how you that's how that
works mmm and so last of all on these
elastic on on this section there's a
there's a collector which applies a
function before the values are processed
and you might think why would I want to
do that I mean that doesn't sound like a
very sensible thing to do because after
all one of the one of the most common
operations intermediate operations of
streams is a map operation right
so if which applies a function to each
value so if okay the so if I could apply
a function to each value as it's coming
down the stream why would I want to
collector which is going to do exactly
the same thing so maybe maybe maybe you
can think about why why we would want
that given the the what I just talked
about with the downstream collectors
absolutely you might need a map in a
downstream collector because what you
might want to do is after the first
collections taking place you might then
want to do some processing on the on the
elements that come out before you
collect them again and we'll see
examples of this is that's really quite
a common thing you want to do so
supposing you want for example to you're
interested in a certain piece of
information from a remote from our value
but you also want to have the whole
value as well for later processing so
what you would do is you would do the
classification on that on that initial
piece you passed through your value and
then you would extract whatever else you
need for later on so that's it so it's
actually pretty useful I mean if I make
it look like a like a if I put it in
this kind of way it looks pretty stupid
because you could get the same effect as
this just by putting a map operation on
the stream so what but I did it this way
for the animation because the animation
is really complicated if if I do
anything else and then I'll show you
I'll show you more realistic example so
here so here that this is a mapping
operator and it has the the downstream
collector is to set by the look of it so
the the mapping is person get city and
the downstream operator is set so what
we're going to get here is a is a set of
of the city
that people live in and obviously you
could do the same thing there just by
just mapping person to city in the
stream but but in the next example that
I'll show you then you couldn't you
couldn't get the same thing so that's
that's the animation example but oh
something went wrong there I'd it that's
alright that's that's it that's more
sense of that's a more sensible example
so so here what we've got is probably
not very sensible we've got where we're
going to group people by the city and
then we're going to map the the names of
the people that that we're gonna sorry
we're going to map that the person those
person objects to the to their names and
then we're going to collect them in the
downstream collector which will be
joining so what we'll get then out of
that is concatenation of the names of
all the people that live in each city so
London will have John and Bill on
whatever it was and can cut it can
catenate it together and there's a
significant number of these convenience
of these of these various collectors
which correspond to other to operations
on the on both on the intermediate
operations like mapping which
corresponds to the map intermediate
operation and a lot of and a lot of
factory collectors which correspond to
terminal operations that you want that
you want to incorporate into collectors
later on so for example you could vary
an in-stream you can count the number of
elements on it well for a for as a if
you want to downstream collector that
can do the same thing it's created by
the counting factory method of the
collectors class and same for Max and
min which which will give you max by and
and min by and these are these these
methods do exactly the same thing but
you can put them into you can use them
to create collectors that you can use
you can use for downstream collectors so
some average summary statistics summary
statistics gives you the sum the count
the minimum and maximum and the average
so that's so that's a kind of useful
object and again you can get that both
ways and even and even the reductions
can be done
okay so so last thing I want to talk
about before before the break because
we're just coming up to the hour is the
concurrent collection so concurrent
thread safety I've said thread safety is
guaranteed by the framework even for non
thread safe components so I mean this
this is this is a big plus because quite
a lot of the time you if you're writing
your code so it's gonna be parallel
ready then you don't know in principle
you don't know whether it's going to be
from now on you don't know whether your
code is going to be executed
sequentially or in parallel so since
it's probably going to be executed
sequentially for some time to come it
doesn't make much sense to start right
start writing two concurrent collections
but you have a bigger over which have a
big overhead just because they're
thread-safe so you would want to use non
safe non throw safe collections you're
going to carry on using hash set and
hash map and all that kind of thing so
it's a big plus that the content that
the framework says I don't care whether
you're whether when that change you have
takes place
would you sequential and parallel
execution you don't and you're not gonna
have to worry about it I'll look after
it so I will look after thread safety
whether it's sequential or whether it's
parallel this and this is actually
really kind of a big bonus and in years
to come as the technology for
parallelizing code becomes better you'll
really be grateful for this because you
because increasingly you're just going
to get this benefits of parallel
execution for free or not exactly for
free but really really cheaply all you
have to do is change stream to parallel
stream and everything will still work
perfectly and so that's that's quite a
big plus but in some cases you actually
know that you're the in you're going to
have to use a thread safe container
already right from the start so you to
so maybe you're collecting into a you're
collecting into a concurrent map which
is already being used by by other by
other threads and so it needs to manage
its own thread safety so in that case
you're
the the the framework will still work
fine if you use grouping by for example
or to map it will still work fine but it
will impose the overhead of thread-safe
execution on to your on to your
collection and your collections already
thread-safe so now you're going to be
paying for the thread safety twice over
which seems like a kind of poor deal and
so the so grouping by into map all have
these all have these extra overloads
that allow for that allow for
concurrency every overload of to map and
grouping by has a dual two concurrent
map and grouping by concurrent and and
in that way the you you don't have to
pay twice if you already know that your
collection is going to be thread safe
then you can then you can take it then
you can take advantage of that okay
right so we've reached 930 fantastic
timing even considering that the
problems with the the cable so I'm so I
know it's quite a long time it's a two
hours is quite a long time to sit
through somebody and chattering at you
so I think a five minute comfort breaks
quite a good idea before we stop though
are there any questions on the first
half yes
right so the question is well how can
you know where you are in the collection
supposing you suppose you've you want to
do something to every third element of
the stream if you start thinking about
so there are kind of there are ways in
which you can do this and but mostly
they involve actually attaching the
attaching an index value to the value
before it starts down the stream and if
you and if you think that sounds crude
and you can't understand why the stream
API doesn't offer that think about
trying to do this with a with the
collection that's being executed and
it's being processed in parallel
supposing supposing I've got a million
element array and I want to chop it up
into pieces I and I and now you tell me
how you want to know where in the total
array each element occurs you want to
have some way of doing that so there's a
huge overhead in in providing that you'd
have to provide the starting value
actually I'm going to do something quite
like that in the in the in the example
in the example at the end but you'll see
that there's an overhead involved and
since it's not the thing that people
most commonly want to do and because
it's difficult to do with parallel
processing they don't provide it out of
the box yes
sorry
well you could you could run them
through a filter that's probably that's
that's the that's the generic solution
that the stream a sorry the question was
how do you validate them and the answer
is a generic solution that that the
stream API offers is the filter is the
filter operation there really isn't
anything else that it would allow you to
yeah that's it I think yeah yeah I mean
I think I select the answer to your
question yeah
so so the question is what if you want
to do things would essentially want to
do things twice for the stream elements
and that's that's quite a II basically
that was a design aim of this of the
stream designers so you can't do most of
those things there are extensions to the
stream libraries and I'll see if I can
find some references before the end
where people have actually added new
libraries that that I don't that onto
this that help you to do that but it's
not part of it it's not part of the
basic stream API okay last one and then
we'll break
this one
I'm I'm using a downstream I'm using a
downstream collector I'm using a
downstream collector here in exactly the
same way as I used to list for the for
the first example this sorry Oh have I
all right so it's so yeah there's a typo
yeah yeah sorry thank you for putting
out right five-minute break
please come back or if you don't go you
don't want to come back just hit the
green button on my hands
Jesus
sorry I'll put them on slide no I
know I've never done that one
he might be Stewart Marx thank you thank
you well students very good too well
sorry I just say Stewart is very good
and then mine too
yeah yeah look out for his talks
definitely
so you don't get the program of the
identity over the production over the
nope
is that better
that's right the thing with a tree hello
but that's working yeah yeah yeah yeah
yeah no I think it's okay right cool
okay so yeah so you're gonna do the work
owls oh let's let's let's have an
example so first example I'm going to
choose is we're going to classify people
by age because that's right that's
really simple people by age but after
this it's up to you so how would we
classify them by age why we're going to
want to map from integer to person oh
yes integer to person people by age
people by age equals and I'll give you a
clue people dot stream that's because
they're all going to start this way okay
Wow
come on yeah yeah that's a good idea
thank you I'm not very good at this
stuff so I I often actually is it's kind
not it's a bit of a cop-out really to
get you to do the work because like like
you'll then gonna tell me where I go
wrong
I hope thank you it clicked not so that
maybe maybe dr. dot collect grouping by
sorry person double can't go on get it
age right okay see if that works
Oh might be an idea to do something with
it with the output that's out people by
age okay so we've got a map there from
33 to a list containing Bill and Eric
and 21 to Amy and 42 to John looks about
right yeah with the data at the top cool
okay right so we need to choose
something a bit harder maybe a bit
harder all right I'll give you one more
names by age so that's gonna be a map
well you should tell me really
integer 2 list of string
name's by age stream
so if we were to downstream collected
them we've got grouping by right so it
was up what's going to be the
classification its person like it yeah
age again isn't it sorry mapping okay
because what good because you want to do
some more processing
all right thank you
nothing
okay right sorry but it's not just a
missing paranthesis it's all it's
complaining about something so mapping
wants to take all right yeah no there's
no default there's no default for
mapping we're gonna have to say to lists
that's better so why is there no default
well because it they didn't think there
was gonna be a single common case and
for that right so so we've got the names
out so that that's that that's it looks
actually it looks remarkably like the
like the first one but in the first case
sorry I should have said the first one
we kind of cheated the two string method
of person prints the name of the person
in inverted commas so that's what you
were getting that's what you got the
first line the second line you actually
got their real name
maybe I should maybe I should maybe I
should have made the two string method a
bit more look a bit more obvious yeah
yep so that's this is an example of why
you want Matt of why you want downstream
collectors like napping that are no use
in their own because you because what
you've done is what you want here is we
want to get we want a map from from the
name sorry one want a map from the age
to the from one from one property of a
person to another property and you don't
actually work but you need to keep the
person object as a whole past the first
past the first classification so that
you can use it later on to extract the
second one in the right place I probably
explain that really badly
okay let's any ideas okay I have two
right so let's go let's have something a
bit harder because this is a population
by age that's not too hard still
population by age so that's going to be
a map from
I mean I I mean sorry okay so that's not
very clear what by population by age I
mean let's click let's get a map from
the each age to the number of people
that have that age pun well you might
think that it's long yeah that's right
because well we'll see I mean I mean if
I could leave it there and then we'd get
a really puzzling compile error but
because it was actually the stream the
the compilation errors from streams and
not that not always that easy they're
not that easy to construct so actually
getting the type right helps but it's
going to be long because what we're
going to need to do because we we don't
know how many of them that might be okay
population by age and you'll see you'll
see that you'll see the how we get that
value because people don't stream all
right
grouping by now plant
sorry I had a mutter person age okay
and we and you want you want to just
count them is that it's that all there
is yeah this looks like that's all there
is how do I count them there's a
counting collector isn't her or a clay
we talked about accounting collector but
actually it's a factory method called
counting which which produces which
produces a collector that doesn't have a
name okay population by age okay let's
just check that that's working okay so
we've got 33 we've got two people
twenty-one we've got one person
forty-two we've got one person
so I touched it sorry okay sorry carry
on
certainly you could so what you could do
is you could provide you you could
actually do more than just average I
mean you definitely could do that but
you could you could get in use in
summary statistics which would give you
which will give you that and a lot of
other information as well
summary statistics gives you it gives
you and really I need a remote control
some statistics gives you the count the
sum the average minimum and minimum and
maximum as well but if you just wanted
to get the let's see let's see what
would happen if we just wanted to get
the the the average does that be quite
good wouldn't it so so well at the
moment at the moment let's let's define
that problem average age by city okay
average age by city average age by city
right okay so that's gonna be a map from
city to double I guess average age by
City
oh right no not necessarily I mean the
the reason the reason that we had long
the reason that we had long in the in
the last example was because counting
the counting collector that's that's
going to return long because it doesn't
know how big the I mean why should they
write it for anything less than that
when they when they don't know what they
when they don't when they don't know
what the values are gonna have our but
if we know I mean like in this case for
example in oh the average age isn't
going to be this there's no point in
having a big decimal for that might be
on right so so so in this case it's it's
it's we can we can just weakens we can
settle for a double and we could
probably settle for something less if we
if we if we cared absolutely you could
use it yeah I mean I mean it's a
reference type we can have streams of
whatever reference type rely yeah
absolutely
okay so what are we gonna do and we're
we're gonna click we're gonna after all
this is a talk about collectives why
would we do anything else routine but
whooping boy well it looks like I mean I
kind of first cut at this what do you
think yeah a person get City I mean that
looks like that's going to work doesn't
it or something it's gonna be the start
rather of what we want to do so right so
now what we want to do is we want to get
the total age of all the people we're
gonna get the total age of all the
people in the in city and then and then
the count of them maybe that in summary
statistics thing that might be might be
a good idea write in it sorry
well there is an average function on
that I think is an average function on
on its dream I don't know
actually that would does a really good
question let's let's just see averaging
int it's it's averaging in the name of
the collector or it's averaging in the
name of the yeah I think I think I think
average is the is actually the name of
the function on let me just let me just
cease and say since it since I says I
can't remember and and it would be
worthwhile knowing when to int stream i
okay so I don't a ver äj-- so it's
average right okay so we need to we need
to get the what we need to do is to get
the the ages into a stream and then to
average that stream right that's what we
need to do now how M do that
right averaging let's try the averaging
averaging int to int function so it
sounds good doesn't it takes a takes a
takes of T and it's a map and it takes a
mapper I like that okay so what would be
what would we expect to put in there
then person person dot your age person
kind of get age yeah okay right so is
exactly that give us our answer it seems
to be saying that it does this is what
this is why I like to do this stuff
interactively because somebody generally
knows a better answer than I do
this let's have a look
Londyn 33 tulsa 42 and athens 27 london
40 london 33 well okay athens 27 tulsa
42 looks good
sorry
sorry I didn't catch that could you say
it again well because because we have no
way of saying I mean like it's like in
this case we're averaging that we're
averaging the age for each city I mean
in general I mean for a real-life
problem you're I mean for a real-life
problem and you're doing some data
processing you're gonna expect to have
more than one person per city but but
the how much work your idea is that
we're doing too much work because
sometimes they'll be cities with only
one person or no people in them but if
there's no people in them then then
there won't be then there won't be any
extra work if there's if there's one
person yes there would be some there
would be some work yeah but you know
it's programming so that happens cool
okay that's it that's a good problem any
others are we doing for turn now we
still got a bit we still got a bit of
time another ten minutes or so
okay let's have something I'll provide
one then how about this cities cities
with more than one with more than one
inhabitant
slightly different
sorry
I would need to put I'm certainly gonna
need to have a filter in there
what was my tech what's the type I'm
headed for here cities with more than
one inhabitant the Elissa a set of
cities were some of a set up city
or column popular cities though they're
not actually they don't you have to be
very populist for this today more than
one inhabitant okay so we're going to
need to we can't do it we can't put a
filter on straight away because we don't
have the information that we need now
first of all we're gonna have to do a
collection aren't we we're gonna have to
we're gonna have to a collective
grouping by so what are we going that
we're going to group by right City so
then we're going to do the counting so
now what do we have we've got so what
was so what we've got at this point is a
map from person to the which actually
what's really quite useful list is to
actually write out where you are at this
point so we've got a map from city too
long right so for each city I've got
I've got the the city reach city I've
got I've got the other map which maps
each city to the number of inhabitants
in there sorry
I have to you have to do I have to do
another stream but what am I going to
stream now this is something I haven't
told you about this is something you
have to do quite often for these
problems I'm gonna have to break this
map down I can't stream a map directly
I'm gonna have to get the empty set of
it you know so now that's and now what
I've got is a set of entries each one of
them associating a city with along so
now I could do the filter thing what you
want sorry okay so so I've gone so I've
got an entry and and and and I want to
check whether the value okay that is
probably it'll probably get this right
when when when it'll when we've got the
we got all written if it doesn't I can
go back and I can I can give an explicit
type to the what do I got wrong sorry oh
yeah thank you oh look all the Reds come
away that's fantastic right so so now we
now we've got a set of the entries we've
got we've got a stream of the entries
and we've knocked out all the ones we
don't want so all so I think all we need
to do now is just recover the names of
the cities is that right okay so we want
to oh I shouldn't have done that
how are we gonna get those out collect I
mean what's gonna be the collector here
alright so I do I do want I do want to
sit but well at the moment what I've got
there's still the entries right I
haven't I haven't actually broken the I
haven't actually broken the city out of
there I'm going to need to I'm going to
need to put a map in anti so I'm going
to need to map from to map my entry get
which of them what do I want
is it it is key right okay
and now I want to collect that to assert
how about that
see if that works
okay so only athens has more than one
person that this is after the apocalypse
right yeah okay so that worked right
okay we got time for one more yeah we've
got time for one more yeah
if it's in map on the stream and mapping
as this it's a it's a factory method in
the collectors class so the difference
between those is that map is an
intermediate operation which is applied
to every value as it comes down the
stream changes each values it comes down
the stream if you want to do that once
you're actually if you want to collector
that is going to do that before it does
its collection in other words if it's
going to take an incoming stream and
apply an operation to it you need to you
need to have a different kind of
collector so you are rather you need to
modify the collector you need to take
your downstream collector and you say I
want something done before that and
mapping takes the downstream collector
and there's something that you want done
before that and it puts them together to
make a new collector okay one more then
this they're getting a bit harder and by
the way there's a we've got a hands-on
lab tomorrow which which will stretch
you really a bit further than a bit
further than this it's quite this really
quite interesting but it's a it's a
hands-on lab for streams and Landers and
it's really well it's really well graded
it's Stewart Stewart marks from Oracle
has made that made that lab cooperated
with him a bit but he's done the huge
amount of work on it so I strongly
recommend that to you if it's not full
up already right so most popular age
responses from is actually quite
interesting
yeah there's even more difficult to get
the I mean we probably don't have time
to get them that you would just want you
would just want an inter an integer I
mean we're really kind of we're really
taking a punt here on on what we're
going to get out
in fact we'll see that that isn't right
either but we'll let's see why
sorry well the murder is like if you've
got ten people that are 33 years old and
12 people that are 42 years old 42 is
the most popular age you want a grouping
by
right so now we've got and in the way
that I in the way that I like to write
it we've got a map from I've got a map
from age in integer well in digital
persons so far but but obviously that's
we're going to need to change that sorry
it's it's it's yeah you're absolutely
right it's to a list of person yeah
thank you
so so we're it right so what I think
counting sounds counting sounds good
because that's going to enable us to
find the maximum the maximum isn't it so
so where's the counting it where's the
counting gonna go here we could put in
we could put in now straight away you
don't think so so so we would then get a
map from integer to integer too long and
that would be and that's actually going
to have the information that we need in
there isn't it
because because yeah that's right
because it's actually going to have the
count it's going to have the age and
it's going to have the count for each
one so I like that so I think if I just
say counting now right then I think that
then I think that we probably oh that
was not what I meant to do
so what we need to do now now we've got
now we've got a map which has got as now
it's er I should change that now to from
being from being list of person to being
long and now what we've got to do is
we've got to analyze the entries in that
map to sort of invert it really because
well max value I think you know I think
there's a there's a some kind of there's
a max by function on I think on on
streams is that right
maybe I know but it's got to be if we
had a stream you've got a max by and you
provide a comparator and it's going to
order the elements according to the
columns and then you could just get the
the that would give you the one you want
it but we need to have a stream of these
these of these entries so I need to I
need to I need to put in entry set again
all right okay dot entry set dot stream
now that now why isn't it doesn't like
that max list it's not called max by
it's called max max by is the name of
the function of the method that the
factory method that produces home
a collector the desert so the comparator
we want here is now there is some clever
stuff in java 8 and they gave us what we
could do is we could obviously we could
define a lamb that we said given an
entry the the one that the one o the
return the result of comparing the
values which is what which is what we're
probably interested in here isn't it
yeah but
there is a method in map entry
so it's map entry dot comparing by value
fantastic that's the one we want isn't
it
because we want to compare the to
compare the council's and it's gone
again no no it's no no it's got to the
point where I can't even touch the
machine that's going to make it
difficult okay so I think that's it
is that right I am gonna get an optional
in yeah I was waiting for that to come
up as a compiler so yeah so I need to I
need actually to get the I need to get
the the I do need to map I do need to
map it don't I okay so I want to so but
what I've got now is what I've got now
is an is the entry isn't it so I so I
want to do a get value isn't it isn't it
shouldn't we get value you know it's not
it's not it's not offering me ah because
the reason why it's not offering me yet
it's not offering me that because it
knows that it knows it's gonna return an
optional I mean I knew it was going to
return an optional I didn't want to to
just spoil your fun
the reason it's going to return an
optional is because what I'm doing is
I'm trying to get the largest value out
of a stream with the max method but of
course we don't know we can't tell them
advance that it's going to be anything
in that stream right so so if so the
result of that the the consequence is
then what we're going to get what we're
going to get back is an optional int fun
so second
if I have to introduce a maximum this
particular this code isn't gonna isn't
is going to just choose one of them
absolutely there is a more complicated
version of this code which we don't have
to which we aren't gonna have time to do
but that it is in the book which which
actually allows you to to get to get
back and the full map I'll choose this
or choose a set of the most the most
popular ones right so what do I need to
do to this to this optional to get to
pull the D so where would I wear when I
map there where would I map the empty to
the to the key I'm gonna have to do that
after after the max I don't think so
actually I think I probably wouldn't I
make my life easier if I wouldn't I tell
you what would make my life actually
easier would be would be in fact instead
of that I mean I could do that but what
would actually make my life easier would
be to map this to the get to get to get
the value how do I need to only don't
need the key right okay it's I'm
comparing by value but now I need the
key don't I map I'm so so I'm going to
say map entry
you get key right right
okay so I want to say or else or else or
else - one right
oops and and now that and now this is
not gonna be right because actually I'm
surprised I know right
I thought I could have done worse I
could also have defined this as an
optional int which is which is what I
was invited to right let's see if that
works that didn't well and possibly
printing it out would be a good idea
thank you
it's a popular age let's see what
happens
cool I'm the most popular age is in fact
30 to 33 in our data all right so we've
got two people with 33 what do you think
doable guys at the front think it's
doable you guys at the back I know it's
a big room isn't it it takes a bit
it takes a bit of getting your head
around it right but but it is but you
can see that it is doable I've made it
look a bit easier than then you'll find
it because you will get a lot of stupid
compilation errors they're not stupid
it's just right really difficult to sort
out and you have to do some you have to
do some reasonably smart things to like
I mean extract variable for example
really helps a lot
sometimes the compilation errors are
quite misleading so you have to you have
to kind of think your way through it a
bit but you can see that you'll get it
we're getting quite a lot of quite a lot
of power the quite complex functions out
of doing at putting together pretty
simple things now that idea of the you
know the UNIX tool philosophy of putting
simple things together to make bigger
ones works pretty well here and it's a
lot of a lot of how it works is the
composition of the of the different
collectors and to some extent as well
the composition of the the composition
of the intermediate operations into the
streams okay I'm going to go back to the
slides now just do just to round things
off because they're pretty much out of
time
oh we were sure about me
time right still just I mean not mirror
so I'm just going to I'm just going to
show you very briefly some stuff about
writing your own collector and then
we're done yeah okay so question why
would you want to write your own
collector well the answer is often you
don't I mean I think you've seen now
there's just a huge number of plexes in
that I mean the real problem is actually
understanding that fantastic variety of
things there are in the collectors class
rather than rather than going off and
writing your own you really need to get
your head around what's on offer before
you start reinventing the wheel but
sometimes you might want to for example
if you wanted to accumulate to a
container that doesn't implement
collection the library doesn't offer you
much support for that or in the case
that we're going to look at now
supposing you wanted to share state
between the values being collected and
that's that's that's that's what we're
gonna look at now as an example that the
that isn't offered by the library ones
either
so the problem right the problem I can't
remember whether I don't think I
described it like this in the book but
never mind anyway this is Oprah's
problem openers problem is that these
are the ten books that she chose the
best ten books of the last decade and
now her problem is that she that I chose
this illustration because I was looking
for a set of books and I thought oh
right she might have some problems here
finding a book out of her collection so
I think we should we should give her a
hand with this and and the idea is of
how we're going to solve Oprah's problem
is we're going to provide her a map from
the from the name of the book from the
book to its starting point on the shelf
right so so and we'll do that by
calculating the cumulative thickness of
all the of all the books that precede it
because that's you know the starting
point of the shelf it's obviously
Eckhart Tolle a new earth and that's
that's that's at the left hand end of
the shelf and then 336 pages further on
she's going to find the Poisonwood Bible
now 336 pages of course she's not going
to know the measurement of that but
we'll give her a conversion well
we'll convert that into inches or
millimeters or something so that she can
then fight so that she can find it and
so in this way she'll have a have a
really easy way of finding all the books
on her shelf of last best ten in the
last ten years you don't think there's
anything strange about this at all do
you
I got a specific request remote probe
for this with this code so what she
needs is a is a map from from the from
the book to its cumulative to the
cumulative page count that precedes it
on the shelf so since new earth is at
the far left-hand side that the
cumulative page count before that is
zero but it's got 336 pages in it and so
the cumulative page count before the
Poisonwood Bible is 336 so that the
we're going to what we're going to do is
we're going to construct all the way I
thought about this when I was when I was
building this up in there for the book
was that we're looking for a data
structure that's going to hold this
information there's a kind of really
obvious way of doing this of course
using an accumulator but we know that
the accumulators are out you can't use
accumulators with the with the stream
API we've got to find a way of doing it
that it's going to that's going to be
parallel ready so so so the idea is to
find a data structure which which we can
see as provides a partial solution to
the problem and then we see how we can
join together smaller bits of this data
structure to make larger ones until
eventually we have the whole thing
that's gonna be that's going to be the
idea here's the here's the data
structure that we're looking at the the
big square brackets surround a
sequential data structure which I made
in which I used for which I used an
array deck in the book but actually I
think an ArrayList would be fine and
there's be a slight performance
improvement with an array and the idea
is that we you know we know we're going
to need the accumulator the combiner for
the and for the for the collector and we
of course gonna need a supplier the
supplier is obvious it's a new ArrayList
or a new array deck whenever we're going
to use but the the accumulator is pretty
straightforward - it takes a book a new
earth and then what it does is it
it puts the title in there it puts the
it puts in the the number of pages and
it puts in the cumulative displacement
but it doesn't know that yet because
that's what we're trying to find out so
that's going to be a zero to start off
with and then the then the way that the
accumulator will work is that a single
thread accumulating the the first few of
these books will take a new earth first
of all it'll make a data structure to
contain it and then it'll put it in in
this array deck ArrayList and then it's
going to then the accumulator will take
another one The Poisonwood Bible and it
will wrap that in the data structure and
it will and and and now it can actually
say what the cumulative page count is
and the right-hand cell where it can say
what that is because it because it's
obviously just the the cumulative page
count from the previous one plus they
plus the page count from the previous
one so it adds those two together and
that's how the accumulator works and now
if we want to think how we're going to
get the whole the whole the whole thing
and so imagine this is this is a
stand-in for the for the sequential data
structure which contains all of the
books you can see that this this can be
made up from two partial ones suppose we
would have two partial data structures
like this that have been constructed in
the way that I showed you on the
previous slide the one on the left is
the was was built using an accumulator
and one on the right was built using the
accumulation now we've got to combine
them together and the combination is
pretty straightforward what we do is we
do the the combiners just takes the
cumulative page count of the rightmost
element of the left-hand half plus the
page count of the rightmost element of
the left-hand half so you can see that
those two red arrows and that makes 976
that's the cumulative page count of the
whole of the left-hand side and then it
just adds that to every element of the
to every page count of the of the
right-hand side in turn so combining
these two data structures doesn't
doesn't involve you and having to have
an accumulator at all we've had no
accumulator in building up this
cumulative page count which is which is
what we wanted and so that now what we
would do is we would take this and we
would we would run it through a stream
and we would we would project we would
use a map function a map operation
to project out the the name of the book
and the and the and the page of the
cumulative page count and then we would
make a map out of that so that's kind of
that's the principle of it the full
codes in the book I wanted to I wanted
to I mean I think this is it's it's a
useful example because it shows how
something which just looks like it's got
to be an accumulator actually turns out
not to have to be an accumulator we have
just got our minds so welded into the
iteration and accumulators that we don't
see other ways of doing things even if
they're actually pretty pretty
straightforward so just to finish off I
mean I did actually think about how you
could do this using reduction but I
guess I could skip over this pretty
easily the the the way that you could
get the same thing using reductions to
take each one of the the the idea that I
talked about earlier on if you were used
to reduction there's a functional
programming you so hey I don't need this
collectors stuff I'm just gonna do it
there I'm gonna do it the tried and
tested way you'd have to take each one
of these you'd have to take each one of
these elements you'd have to make a new
you have to make a new data structure
out of it you'd have to put that in a
sequential you have to put that in the
sequential thing just like when you're
starting in the accumulator off and then
you're going to have to run reduction
over all over over all of those it's
going to be really expensive and clumsy
and quite a lot of it will have to be
done in client code so it's really it's
it's really not great the Collector's
was an innovation it's actually
something different from from what's
been done before it's the first time I
think that reductions been used in a
really big way in a language that
depends on mutation java is not a
functional language functional languages
by and large using immutable data
structures and java is not a functional
language and it's not going to be one so
so adapting this side the idea of a
reduction this functional idea adapting
that into immutable containers was
actually really quiet it was quite a big
breakthrough I think so it's it's pretty
clever stuff okay so that's that's the
that's the sales pitch they know it's
now just for something else my machine
is on so I'm going to talk I just talk
very briefly as a wrap-up while I'm
waiting for it to wake up about you know
not responding cool I mean I'll just
talk very briefly about performance so
the performance of collectors is
generally depends a lot on on the
accumulator the accumulator is going to
be if you if you imagine us to kind of
10,000 element array then then then the
accumulator is going to be used an awful
lot more than the combined that the
combined that will be used relatively
relatively little and so just I'm just
finding up and just finding my place
again so so the the the performs of the
accumulator is pretty critical and that
actually really is going to be is going
to depend on the performance of the
accumulator for the particular
collection so generally speaking will be
using add the add method of different
collections for it so so that's we're
not really looking at anything very
different from from what we have with
with iterative code we're looking at
improvements because a lot of the time
the the compiler can do better with with
stream code because a the the the it
uses a technique which is something like
loop jamming in in in more ordinary in
conventional conventional code
commercial iterative code what it does
is it you can actually see and it
combines loops together and it gets
better it gets better optimizations out
of that the problem the biggest problem
I found in looking at performance of
large of collectors on large data
structures I mean the the kind of
simplest thing is that simplest thing to
say is that map maps are more difficult
and particularly because they need to be
resized so resizing Maps is expensive
and map merging which has to be done for
the combat for the combiner is a very
expensive operation so resizing so
initially sizing your maps if you've got
if you're going to be putting a lot of
data into a map getting the initial
sized ride is actually worth a lot
so that that's a that's again a useful
tip okay conclusion collectors
generalization of reduction they
actually are like reduction only better
they allow a functional style while
you're continuing to work in a language
which actually it's not going to be a
functional language the they're really
well designed to be composed together so
you can actually do pretty fancy things
by simply by just changing them together
I really kind of fell in love with them
as you can see when I was you know when
I really understood them properly and I
think and I think I think they're really
great they take a bit of getting used to
but then anything it's worthwhile does
okay so that's that's my pitch for today
I hope you enjoyed it thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>