<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>JVMLS 2015 - Multi-Language Runtime | Coder Coacher - Coaching Coders</title><meta content="JVMLS 2015 - Multi-Language Runtime - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>JVMLS 2015 - Multi-Language Runtime</b></h2><h5 class="post__date">2015-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kOnyJurioyw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright so we've seen a lot of great
talks at the JVM languages summit
talking about jb ms and and hearing
about what people are doing with
different languages on that JVM this
talk is going to look at multiple
languages and JVMs from a slightly
different perspective that i still hope
you'll find interesting and i will try
to end up a little bit early since we
went long in the in the last session and
hopefully that'll give you some time to
for questions and i look forward to
hearing which think about it this is my
first time at the JDM languages summit
so i thought i'd tell you a little bit
about me I I work at the IBM Toronto lab
on JIT compilers I've been doing that
for about 13 years I'm the current
architect for the Testarossa JIT
compilers in the IBM JDK and I'm leading
a current I secret project which is the
topic that i will be talking to you
about today but first our lawyers assure
me that there is a gripping legal tale
in this slide and the next slide and i
highly encourage you to go back to the
slides and read through it in case it
has any impact whatsoever on how you
interpret what i say so so first of all
i'm going to give you the story behind
this talk so i'm going to start off
purposefully telling you about a problem
that IBM has been facing for a while now
and and just talk about the secret path
solution that we have been working on to
address that challenge now I know you
all traveled here from all parts of the
globe to hear about IBM's problems but
bear with me some of those problems
aren't just hours I think there are
actually problems that people in this
room are going to experience as well and
so the talk is going to end with an open
proposal and a request for feedback on
the work that we've been doing and just
want to hear about what you think about
what we've been doing so our
stakeholders mostly talk to us about
Java so I'm from the JVM team so people
normally just talk to me about Java so
we hear lots of things about java java
java java what should we do with java
what should we what's not working in
java what what should we be doing
differently but a while ago it wasn't
all about Java
started talking about some of the other
languages and you know it would be nice
if we could ignore those people but
there are customers there people who are
going to be using our products and so we
started to listen and now we've found
that it's actually lots of different
languages we still have a lot of people
who are interested in Java but there are
other Java sorry other languages that
are now showing up from JavaScript to
Python to Ruby to you name it lots of
different dynamic languages and yes even
COBOL we do keep hearing about things
that are happening in COBOL and there
are advancements going on in COBOL but I
won't talk about that very much today
because I know it's not really a dear
topic for this room there are a number
of reasons behind this I think I mean
the number of open communities
investment that people have made in
making those languages much more
powerful and capable and useful for
solving problems that people are really
wrestling with coupled with the ease of
deploying applications for many
different runtimes in the cloud and
platform-as-a-service infrastructures
and and finally just the trend towards
microservice architectures where we're
no longer building these massive
monolithic applications in Java we're
breaking those things down into much
smaller services that can be actually
written in whatever language is the best
tool for the job and so so this is
actually a great thing this is not a
problem but from ibm's perspective we
have our own JVM implementation we find
maintaining even one language is a
pretty costly affair right you have to
keep up with advances in hardware
platforms making sure that you're
exploiting all the new instructions all
the new capabilities that keep coming we
have to keep up with competitors thanks
although I think that's actually a very
good thing about the job ecosystem right
having lots of competitors working on
the JVM implementation has actually been
very good for the job ecosystem and it's
driven us to do a lot of performance
improvements that might not otherwise
have happened quite as rapidly you know
we have to do lots of hours of testing
writing new tests fixing all the
problems that customers find as well as
even the ones that we find ourselves
before we inflict them on the rest of
the world and then all this sort of
activities that go on around the
development team writing documentation
managing project the project and
releases and engaging with stakeholders
and oh yeah this thing called innovation
actually pushes forward the state of the
art in in the run time that we've got so
let me just look at the top of that top
one there now we've heard a couple of
times today that x86 is the only
important platform may be armed but
throwing the mic around sorry about that
so we've heard that x86 is the only
important platform here you're going to
fix this I just as two sleeper hit yes
okay well good funny I'll have to say it
again we've heard today that x86 is the
most important platform it's not
actually the point I'm trying to make
but I'm making it very well IBM on the
other hand has customers that run across
a number of different platforms so we
have our own power architecture we have
our mainframe architectures and and
these are actually very important we
have very big customers running on all
of these different platforms and you
know we have different operating system
variants on all of these three major
hardware platforms which add another
multiplicative factor and I haven't even
taken you to account 32 and 64 bit
compressed reps and all those other
variations little-endian vs big endian
all of those variations makes it
extremely painful to to implement and
maintain even one language runtime so as
soon as there's one hardware advance on
one of these platforms we really have to
surface that in the runtime and if you
start adding more language runtime so if
we were to take the same approach that
we took with Java and implement a
parallel implementation of all these
language runtimes we would have to do
all that work over again we have to pick
up all that work and repeat it in
another run time so 42 that looks bad
but maybe we could pull it off three
starts looking really worse and and once
you start getting too many languages
it's very clear that this is not going
to scale at hall and so for IBM
clearly the approach that we're using
for Java is not going to be the thing
that we're going to be able to use to
address the needs of our customers going
forward and new customers and the thing
that really makes this challenging is
all the existing language runtimes are
completely different implementations
they have just-in-time compilers some of
them some of them don't they have GC
technology they have threading models
they have mechanisms to cooperate among
different threads but they're all
implemented completely differently
they're completely different
implementations so even if we were to
work in these different runtimes and try
to surface the support for our hardware
platforms in all these different
runtimes it's still a lot of work
because no matter what you do but you
know in in the java space we'd have to
pick up and apply that leverage in the
in different runtimes and we wouldn't be
able to share very much of that
knowledge implementation costs efforts
own so it's looking very costly to for
us to support multiple language runtimes
in the way that we've traditionally done
this now that's not an unfamiliar
problem to everyone in this room right
we're here to talk about JVMs and
languages running on top of the day bm's
because that's a great way to leverage
all of the investment that's happened in
the JVM and that provides great
interoperability with Java which is you
know we get to leverage that large
ecosystem of both programmers developers
and code as well as all of the JVM
implementation details under the covers
so we get great jits we get great GC
performance there's a little bit of an
impedance mismatch between the
implementing what the what the JVM is
implementing in terms of the JVM
specification and the thing that the
other language runtimes want to to
implement on top of but that's a problem
that obviously has been recognized and
we're working towards we've seen lots of
talks talking about how the details of
the JVM specification can be massaged to
help other language runtimes operate
better and this has been a very there's
a very successful community of JVM
implications lots of looking on a
Wikipedia page there's 56 different
languages that run on top of the JVM and
that's great
but IBM had a little bit of a concern
with leveraging the JVM in this
particular way because in a sense it
divides the language community by
imposing trade-offs all right there's
trade-offs in the runtime that are
imposed by using the JVM and then
there's also just well okay there's
there's trade-offs implied by using the
jbm to run these different languages for
some languages the division in the
community doesn't really matter because
the language was created on the JVM it
runs on the JVM there's a single
community on the JVM so that's not a big
issue but many of these existing
languages like Ruby and Python have a
vibrant non JVM based community and if
you're forced to choose between two
different runtime implementations to run
your code that can make some quite stark
trade-off choices right you may want
high performance but you may not be able
to run with all the extension modules
that make that community vibrant and
great and I know there are some talks
later in this maybe even later today
that are going to go into detail on some
of that ish those issues with accessing
extension modules via of the JVM which
has traditionally been a pretty bad
problem so and even bridging this divide
would mean really migrating an entire
community either one way or the other
and so IBM we have some experience with
being another JVM implementation and
seeing some of these migration and
compatibility issues java as a language
was really almost designed from the
start to be to have multiple
implementations it has a really
well-defined JVM specification it has a
really well-defined language
specification and these are great they
do help with implementing multiple
implementations but they don't cure all
the problems right there are always
compatibility issues sometimes bug for
bug issues which can be particularly
frustrating and behavioral issues
because the specifications aren't you
know fully complete there are areas of
the specification that our
implementation to find or that they
aren't you know they don't they aren't
actually specified and so you end up
getting the it doesn't work that way on
the other one kind of statements and
these migration issues
as we've heard earlier or really kind of
turned customers off they really don't
like to migrate either from one run time
to another or or even to later versions
of run time so we decided to experiment
with a slightly different approach so I
don't want to characterize this as a
competitive approach it's really i think
a it works together with the approach
that's being taken to use run languages
on top of the JVM but we wanted to
experiment the different approach that
would allow existing runtime communities
to leverage the strengths of the
technology within the JVM and so the
secret path from the title of my talk is
really to unlock the vm within the JVM
so i think from the last talk that cliff
gave you can see that there's a lot of
technology and a lot of stuff that's
been built inside the JVM that doesn't
necessarily need to have a java flavor
to it we may have implemented it inside
a JVM for the purpose of executing Java
but those technologies don't need to be
written in that way in fact we could
refactor them in order to distill out
the Java specificity of that of those
components and have a language agnostic
core set of components for things like
JIT compilers and GC technology and then
it might be possible to lift those
language agnostic components out of the
JVM and integrate them into other
language runtimes to straight try to
migrate some of the capabilities that
we've spent so long building in the JVM
and investing so many people and ours
and and money building that we can bring
those capabilities to other languages
for a much lower cost and so what we
would get if we were to do that would be
a toolkit of language agnostic
components that could be used to build
language runtimes and augment existing
language runtimes and so you could pull
out that VM and you could integrate it
into say the Ruby MRI runtime and use it
to bring jit compilation GC technology
other tooling capabilities or you could
do the same thing with C Python and
leverage these components these ways
really what we're doing is we're
establishing a different API into the
components that we've built rather than
using the JVM
specification which despite all of the
efforts that we're going through is
still a jvm specification it's a
specification for a machine that runs
java even though it's getting a lot
better at running other languages as
well so the secret experiments that
we've been performing with our
production JVM we are we've we've been
working on refactoring the components
within the j9 JVM which is the IBM JDK
to create this language agnostic tool
kit designed for being integrated into
other language runtimes so things like
memory allocators thread the libraries
platform port library then hook
frameworks tracing engines garbage
collectors JIT compilers a lot of the
code that implements the things that you
just saw in cliff clicks presentation
that are present in the IBM JDK are now
being refactored so that we can actually
pull those out and apply them in other
language runtimes we then performed a
bunch of experiments to try to integrate
some of those components into other
language runtimes and Ruby MRI NC Python
are the two that we chose as basic proof
points to see how well does this
experiment work now this is a lot of
work so it's been a long effort the
refactoring job is a tremendous activity
to to apply to a code base and so we
knew that if we started this and did it
in a side branch it would just never
merge back into the real code base and
so rather than doing that our product
development team has actually dedicated
some resource over the last couple of
years to doing this aggressive
refactoring inner code base while we're
developing the new releases for IBM JDK
8 which we released earlier this year
and IBM JT canine as that development is
proceeding it's going alongside with all
of this refactoring and that's an
important proof point for the fact that
it's not just that you can take this
these components out and put them
somewhere else it's that you can take
these components out treat them as a
toolkit augment the toolkit and
reintroduce them periodically into those
other language runtimes it's a model of
consumption rather than just you know
here's a starting point go wherever you
want to go from there we want to be able
to build something that you could
actually continue to innovate in and
push innovations into multiple different
runtimes
so so in performing these experiments we
took a bunch of different components
from a runtime and integrated these core
runtime infrastructure so utilities a
threading library the port library vm
structures all of these things along
with a tool agent we incorporated those
into Ruby MRI and into the C Python
runtime and then that enabled us to
start doing some of the more exotic
components like a trace engine the
garbage collection technology and the
just-in-time compiler and there are
other things that we have tried that I'm
not going to talk about today but I'd be
happy to discuss with after the talk
okay and so there are several proof
points that we decided to to implement
so method profiling is something that's
not always easy another language
runtimes to get a very good view of
where the time is being spent in the
runtime because these runtimes are
written in C and if you use standard
profiling tools to try and find out
where time is being spent you find out
that various byte codes and byte code
helpers and various guts of the runtime
are being used but that doesn't help you
connect back to the language that your
program is written in the functions and
methods and blocks that your code is
written in to find out what are the pain
points that you need to worry about we
also ported our entire garbage protect
well not the entire our garbage
collection framework into both of these
runtimes to provide some interesting
capabilities on top of that we also got
some for most GC output which is
something that's not always available it
helps you understand what your garbage
collector is doing as well as some of
the visualization tools and the insight
tools that we have around using the
garbage collection technology and
finally just-in-time compiler we
incorporated some simple just-in-time
compilers into these languages which
don't exist right now and so I want to
report on how our successful we were so
method profiling so just as a background
err iBM has a tool called health center
which can automatically connect to if
you ask it to connect to a JVM and it
will with a very light weight overhead
it will tell you where
methods are consuming time within the
JVM so you can see here there's a
histogram on the top pane showing just
where the most time being spent in these
in this little application that this is
demonstrating and then the lower pane is
actually showing call stack so you can
actually break down if something took a
lot of time where was it being called
from most of the time and the way that
this gets implemented is actually by a
trace point which feeds call stacks
periodically to the health center tool
and so we took that same trace point in
incorporated it into the Ruby runtime
leveraging all of the infrastructure
that we had already poured it into the
runtime to handle the trace points and
to connect to the health center agent
and for free we got Ruby methesse row
files so there's this the top pain again
shows time being spent in Ruby code and
the lower pane shows the call stack from
the from the the Ruby stack
representation within MRI of where that
where those calls were being far from so
this is a this is a good example of just
picking something up from j9 plugging it
down into the Ruby MRI and bang you've
got an extra capability that you didn't
have before directly from the runtime
the second experiment we did was with
taking our scalable garbage collection
framework and incorporating it into C
Python and MRI so it's a our GC is type
accurate it's a it's actually a very
scalable high-performance multi-threaded
parallel concurrent you name it all the
buzzwords that Cliff mentioned in his
talk for how you know what you need to
do in order to have a high-performance
GC we have that and so we've done this
refactoring job to distill the java out
and take the garbage collection
framework and introduce it into the Ruby
MRI runtime and for free just because re
it's a it is a type app framework of
course because it's used in Java but in
this case we're using it in a
conservative sense because the Ruby MRI
garbage collector is conservative and
the reason for that is primarily so that
extension modules can continue to
operate
the way that they operate because
they're not tightly aware of what the
garbage collector is doing so it's not
careful enough and doesn't maintain type
accuracy so and and since and since not
breaking extensions is an important goal
for us we decided to just step down and
do and do conservative GC so another
advantage that we got of introducing
this collector technology was Ruby MRI
the heap is actually a set of slots that
are constant size and most of the memory
is actually being hung off of the the
heap in native memory and what that
means is it's really hard to control
what the size of the Ruby heap is
because what most of the data is
actually somewhere else and it's not in
a in a managed environment we were able
to make some changes into the MRI now
this wasn't as low touch as some of the
other changes that we've made but we
were able to actually instrument to find
all those allocation points and move
that data from native allocation on to
the heap and and with variable sized
objects and now the GC you can manage
all that size so you can say if you want
a four gig heap you can get a four gig
heap if you want a hundred megabyte keep
you can have a hundred megabyte heap and
that actually does more or less reflect
the memory usage of the of the ruby
program so one of the interesting
capabilities that we got out of that was
just a verbose GC output which I'm don't
believe Ruby MRI has you can just say
dash for both GC and bam you get xml
output that's shown here sorry it's a
little bit small a probably can't read
it but it's just basically giving a lot
of information in detail about what the
garbage collector activities are well
what GC phase is happening how many
objects is it finding how much memory is
it collecting how much memory is left on
the heap at the end of the cycle how
long did the cycle take and so on so
similar to the method profiling view
that health center can provide method
can also provide a GC visualization so
it can actually take the data that i
just showed in text and xml form on the
previous slide using trace points it
actually gets the same data to the
health center tool and so it can provide
a visualization of what's going on
during GC pauses when they're happening
how long they take how much data is
being collected again the same type of
data and it can visualize that for you
so we actually didn't have to do
anything here because the GC technology
that we picked up out of j 9 already has
the trace points in it we put it down
inside of Ruby MRI did some stuff around
the edges to make it work inside the
Ruby runtime and and we got that the
same tool for zero changes could provide
a visualization of the GC activity
that's going on the other oh and we
could also do that for C Python sorry I
didn't have a graph of that for the
method profiling stuff before but we can
also do this for C Python same basic
premises it is we just picked it up put
it down it just raised points got
generated the asian communicated it to
the tool and the tool can visualize the
data that's coming out another tool that
we have is a it's called garbage
collector memory and memory visualizer
it's a tool that can provide more deep
insights of both the activities the GC
it can provide tuning recommendations
options settings that might help tune
that the performance of the garbage
collector and it's based on the verbose
GCO put that that we just saw so because
we get the verbose DC output this tool
actually operates just as well for Ruby
MRI as it does for Java and it can
indeed provide recommendations on
options that you can tune with your GC
so that it can improve its performance
just-in-time compilers okay so Ruby MRI
on CPI thon neither of them have JIT
compilers there are other Ruby
implementations like JRuby and Rubinius
and other C Python implementations like
pi PI that have JIT compilers but the
reference implementations which are
written in C do not have chik compilers
there are lots of reasons why tech
compilers are tough to to build for
these languages there are people in this
room who are much more able to explain
the challenges of trying to compile
languages like Ruby and Python than me
so I will defer that that basically it
comes down to the very dynamic
capabilities and mechanisms that these
languages have also there's undirected
sorry unmanaged direct access to vm data
structures because it's c you can write
extensions and see they can reach back
and
for things and twiddle things and change
things all unbeknownst to anybody and so
that makes it a real challenge for the
JIT compiler to actually optimize
anything because it has to be
maintaining the state that anybody can
reach in and look at and see and if you
do you'll break something which kind of
goes against the compatibility concerns
that we had finally there's some design
choices in the runtimes themselves that
make it difficult to write yet compilers
for so one of the examples here is the
Ruby MRI uses set jump and long jump for
exceptional things like iterating and
calling blocks and this is actually
quite a challenge quite an interesting
use of such jump and long jump that
makes it rather difficult to incorporate
native compiled code into the same
environment so our efforts to date here
have really focused on trying to get to
the point where we have compiled native
instructions we want to avoid making big
changes to the runtime so that it's not
too difficult to adopt if this becomes
of interest to these communities it
wouldn't be too hard to adopt these
these compilers into those runtimes we
want to provide consistent behavior
between compiled code and interpreted
codes so we don't have those
compatibility and migration issues that
we were talking about we don't want to
place any restrictions on the use of
native code and extension modules for
either Python or Ruby and so the last
point I guess is just that you know this
this isn't a super mature effort at this
point we haven't done any benchmark
tuning we haven't done any benchmark
specials we're really not very
exploiting very much profile information
about what types are flowing through the
program at this point we're really just
trying to do a proof point and
experimental and just demonstrate that
it's possible to pick up the compiler
from j9 and put it down inside one of
these other runtimes or both of these
other runtimes and get compiled code
performance for relatively easy effort
remember that a recurring theme here is
that we want to maintain compatibility
we want the community to be able to stay
together while they're picking up all
the code that we're picking up and so
actually the proof here is that we can
run rails and that's true for all of the
stuff that we've that I've talked about
today for the method profiling support
the GC technology and adjust in time
compile
support we can run rails and that's a
pretty strong statement because rails is
not an easy thing to to get working all
right just a little bit of background on
the the just-in-time compiler component
that is inside j9 so it's called
Testarossa it was originally built as a
Java just-in-time compiler it has a
fairly standard flow where you build the
intermediate language from the byte
codes that flows through a sequence of
optimizations which improve the quality
of the intermediate language that then
flows down through a code generator
which can generate code for either power
or x86 or mainframes and you know
there's there are a lot of queries that
the compiler has to make while it's
compiling code there are compile-time
connectors to talk to the j9 JVM we
built compile-time connectors for Ruby
MRI and for C Python so that you could
ask questions and so the JIT could ask
questions and also it has a large
profiling framework that it uses in the
Java environment we're not currently
using that within the Ruby or C Python
environments and then finally there's a
run time aspect of this which is sort of
support for the code a bunch of runtime
helpers it manages the code code caches
and the metadata that's associated with
the code so that things like stacks
stack frames can be walked and so on the
compiler was built as a java
just-in-time compiler however over the
recent years it's actually been expanded
to target eight different languages
including cobol and an esoteric language
that only exists in IBM none of you will
have heard of it but our economy
probably depends upon it fairly
substantially all right so results so
this is a bench 9k performance a subset
of the bench 9k benchmarks it's not a
particularly awesome set of benchmarks
to use to measure just a time compilat
performance there are lots of compilers
that do a lot better than this I'm not
going to say that we have fantastic
stunning numbers here but I think if you
put them in the context of the
requirements the constraints that we're
operating inside and trying to maintain
compatibility and ease of adoption
within the runtime these are actually
pretty good results so on x86 which I
know is the platform everyone here is
claim claims to care about you know we
have three benchmarks that are above two
times performance and a number of ones
that are everything's above one some of
them not very much above one like I said
we haven't done any benchmark tuning
here at all this is just basically the
results that we get form from a
straightforward application of our
technology into this runtime there's
lots of low-hanging fruit here that we
know of that would make this a lot
better optimizing things like method
domestic dispatch for jetted calls and
so on that would that would make a huge
difference here but we just haven't done
that because it's now because Testarossa
is a retarget abul compiler framework
it's already built to compile on x86 and
power N and our mainframes these e
systems we automatically get results for
power now these are not as great results
as we saw on x86 and obviously will be
very motivated to go and look into why
those differences are there because in
principle we should be getting
relatively similar performance on power
as we would get on any other platform
because we haven't done any target
specific stuff right now we've basically
just gone to the process of converting
the bytecode into RI oh excuse me
running a small set of optimizations on
that IL and then just letting it flow
through the code generator and so you
know so for free and once we had done
that we got x86 we have power and we
also have it running on our main frames
so all of these are on linux format for
example and you know again similarly
similar kind of performance profile for
our mainframe systems and that was
basically for free we didn't have to do
anything special to get that final proof
point here is is it the fact that we
actually use this code base to release
our IBM JDK 8 so this released at the
beginning of the year you could argue
that if we if we were doing this work
and it slowed down our ability to
deliver other code what are their
releases that would not really be a very
successful thing right we want to be
able to use this technology in many
different places without interfering
with anybody's really schedules and so
I'm happy to say that our JDK 8 release
was as good as any release that we've
done in fact there's a number of new
capabilities that we added
there it coincided with the new release
of the z 13 mainframes and we did some
pretty amazing stuff to exploit all the
new features that were available than
that in that in those machines as well
as a number of similar kinds of things
in the Power Architecture so we're doing
a lot of work across platforms we do
have a big team working on this but we
manage to do all of this aggressive
refactoring and take that code and reuse
it inside of other runtimes at the same
time so I think that's actually a pretty
impressive thing we also managed to
release some cobalt compilers at the
same time but so we think our results
are pretty promising but it's all secret
so like who cares right well you know i
am here talking about it we realized
obviously very early on that these are
not just problems that ibm's facing IBM
is very large and it has all of these
concerns altogether but that doesn't
mean that these concerns aren't also
true for everybody else who's using
different language runtimes so I think
most of the people in this room can
probably read through this list of of
challenges that IBM faces right we own
our own platforms we own our own
operating systems we're building cloud
and pass infrastructures we own lots of
different tools that have to access a
lots of different runtimes we have large
data centers that benefit from
optimizing and and and improving the
resource usage for efficiency and we
have lots of developers and customers
who are working with multiple runtimes
probably everybody in this room can pick
at least one line on that list and
replace IBM with your name or your
company and and that statement would be
hopefully at least partially true and so
that means that that everybody in this
room could benefit from the type of work
that's happening here so we think this
is a really a common set of problems
across our industry and we would all
benefit from having these language
agnostic components that we could use in
a number of different ways and even iBM
has figured out that these languages
really exist in the open and so that
means if we really want to have the
broadest possible access to the
components that we're talking about we
have to create an open community around
these language agnostic components and
so that's what IBM is going to do our
vision here is to create a community of
contribution
around this toolkit of components that
can be used to build VMs for any
language the fundamental tool kit is
language agnostic and that means that
it's a good place for all of us to work
together individuals communities
corporations to safely collaborate on
building new and better vm
infrastructure right you don't have to
just use the infrastructure that's in
one run time we can pull it all together
and we can work on it together we can
work on the pieces that are common and
we can innovate ourselves on the pieces
that differentiate for our own interests
that will enable everyone to focus more
on innovating instead of just building
the same old wheels that we've been
building in different language run times
over and over again so it will also have
the benefit that it will provide a more
robust core technology for all these
languages runtimes because we're testing
it from a number of different scenarios
we'll fix bugs once not five times in
five different runtimes and it's a it
would be a great place to collect best
practices share learning and you know do
things like this conference to try and
share what's going on in this area and
it also would mean a lower barrier of
entry for new languages right so if
there's this core set of coop that this
cool core toolkit of components
available if you want to create a new
language runtime is relatively easy to
pick up something that's language
agnostic and specialized it for your new
language idea and so we can test new
ideas and get much more effective
results and test them more reliably so
I'm almost done but I have a few parting
thoughts so almost no one starts a new
project saying first I'm going to write
the firmware from scratch there are
people who do that but they're usually
writing firmwares
no one says i'm going to write the file
system from scratch no one says i'm
going to write the display drivers
unless you work for a video company we'd
like to make these statements just as
unlikely i don't want to have to write a
cross-platform port library from scratch
every time that i want to work on a new
language runtime I don't want to write a
new garbage collector from scratch every
time I want to run it write a new
language runtime and I don't want to
write a new chick compiler from scratch
either now there have been some projects
in the open that are being that are
being very successfully used on some of
these fronts but we think a community
built around trying to trying to solve
all of these problems together is really
a very effective approach and so I'm
keen to hear your feedback we think are
encouraged our results are encouraging
what do you think on the idea yeah the
idea the proposal thank you I like it
two thumbs up awesome thank you so some
of the challenges that we're currently
experiencing here so we would like to
create an open project open source
project around these language agnostic
components that come from the j9 JVM
technology our codes not quite ready to
open up there are some low level
components some of the earlier
components on the diagram that I showed
of they don't do this then this then
this then this some of those are ready
but some of the larger components aren't
yet ready sort of for example or
compiler right now we still have to
disentangle many of the other language
support that you know like cool that
you're not interested in from the from
the parts that we would that we would do
think would be reusable in a language in
a project like this we're currently
fighting a little bit of a battle to to
rebalance the work that we're doing to
refactor these components to make them
open source ready with trying to make
our proof points more compelling right
so try to push up those performance bars
too so that everyone goes wow that's
amazing that's great and then finally
you know we want to engage with
communities and partners and we need to
figure out the right ways to do that and
so I guess I'm here to say
what do you think and and do you have
any advice for us there any feedback or
you know would you like to get involved
and a couple of you can talk to me now
or you can send the email or you can
send our CTO janjua bitch email and we
would love to have a conversation with
you questions you had your hand up
earlier IBM well ok so i wouldn't say
we've gone through all the hurdles there
but what we're what we're working
towards right now is we're looking at an
eclipse foundation project which would
mean it would be under the Eclipse
license which means a very friendly
license for any type of use right as I
said in an earlier slide we want these
to be broadly accessible to as many
people as possible that doesn't mean
putting restrictions on how you can use
it yep I can understand that I'd love to
see it go away too no we did not sorry
we did not do that we have not done that
work but we have some ideas for how we
might try leveraging some of the
expertise that we have building in a g9
JVM so you know the issue of cooperative
suspend came up earlier in the context
of hot spot so IBM's JVM is a fully
cooperative suspend model and it does
have rather efficient primitives for
figuring out how to lock and how to keep
everybody in the right frame of mind and
so taking a parallel technique to that
not necessarily taking the code that
we're using in j 9 which is actually
very complicated code to understand and
track you know it's it's you know
whenever you're trying to do something
very aggressive and multi-threaded and
high-performance you end up with
complicated nitty-gritty code but but
the basic approach I think we could try
to migrate that it's just not an effort
that we've started yet
yeah it does work we've so we did have
some issues incorporating the GC into C
Python and you might have noticed that
the GC results that I presented were
from Ruby we've had more success with
integrating the GC into MRI then with C
Python we do have some lingering issues
so I can't claim for sure that we've
solved that problem but but we have done
the work to integrate the GC in to see
python and and you know and it does work
we done we didn't change reference
counting although we did do a few
experiments on the side to try what
would happen if we took away the
reference counting aspect and just
relied on a mark sweep approach for C
Python with the obvious consequence that
you lose timely finalization and so you
know that's a migration issues because
there are lots of extensions that
actually rely on timely finalization and
so you know we kind of backed off from
that as not really an interesting
experiment to do by ourselves in secret
as a proof point yeah yeah I'd really
like to do that control thanks to what
extent do you think the design choices
of MRI are going to limit how far you
are exactly the issues that have kept
koee the others yep kept trying to go
down yeah we're at least not right well
so there are a number of them it's not
it's not us it would not be a small
effort and so in in our view we thought
it would be better to make the
compatible see what we could do by
staying compatible see where we can get
to hopefully that's a compelling
argument to at least get involved and
start you know so
working with the community I think there
are a number of things that we've
learned you know along the same lines as
cliffs talk things that we've learned
from building j9 over the past 20 years
that that could be brought to a run-time
like Ruby that we could try to we can
try to help you know Ainge some of those
fundamental problems but as it is I
don't know like I say we can still make
improve it does have to it does have to
be fixed it will definitely limit the
viability that the effectiveness of a
jit compiler like we'll never see
numbers like like JRuby shows for these
types of benchmarks I don't think maybe
it's possible you know like I say
there's still lots of low-hanging fruit
that we could push on I guess I'm just
I'm dubious that within the constraints
of the existing system that we could
actually make that happen without making
large-scale changes in some very
complicated parts of the of the the
runtime for example exception handling
which is always an extremely tricky part
of any runtime design in MRI it's not
pretty either they're doing do have C
extension support and it's incredibly
expensive they're in directing handles
but as a result they have better GC
better jit is that approach that you
were interested in looking at yes
because we because depending on how many
successes are in the system and overhead
can be getting overwhelmed sure vista
yep that's true and there's they're
seeing yep so I mean so you know the
weight Java gets around this is by the
definition of the jni and the in
directions that you perform in order to
get access to anything that's actually
from within the management that managed
to run time so you know providing that
same facility in another language like
Ruby you know along the lines of maybe
what Rubinius has done is one way to get
there and then the the fact that it
makes performance slower I'm not sure
that's like that would be a compelling
reason not to just do that but if you
had other things that could make up for
that performance like the advantage that
you'll get by doing that is is the more
read them from the jit compiler to
optimize things right right so you get
on you it's it's going to cliff
mentioned this earlier right it's it's
you you have to get off the path that
you're on get on to a new path and then
that gives you the longer runway to get
to you know higher degrees of success
right yes so that I mean that's that's
an issue that so it wouldn't necessarily
interoperate at the Java level but we
could at some point dr interruption at a
lower level so the api there the the
specification of these lower level
components is at a language agnostic
level if you can surface the same API
through different things and you have
the same connective tissue going on
between the different runtimes the
opportunity for interoperability is
there it's it won't be as seamless as
trying to work with java objects and
pass them around but but i think the
interoperability issue our capability as
possible nope nope it's the GC is
language agnostic it does not part of
part of incorporating the GC technology
into a language runtime is the language
runtime specifies what the object model
is and then the GC works within that it
queries the language to say how do I
find out what this thing is you know
here's a pointer that you told me is
live you know tell me what other
pointers it points at right other blocks
of memory that it points out and then
I'll walk those ones too yes although
it's although it's not it's not pleasant
but I mean basically we introduced me no
pre or post fork kind of collection
points to make it work right and then
you know we can bring threads up in the
fork process or born on
are changing of the two languages change
your cold start hmm that's a good
question we haven't measured that so it
would it would it would have an impact
so that so that the JIT being introduced
does the current that we've
incorporated is is synchronous so you
block to compile code the the underlying
technology that we have in j9 is
multi-threaded asynchronous we must
haven't taken that code and brought it
across into these runtimes so in
principle we could get that same startup
performance startup performance is
something that j9 is well known for
doing very well at rightful I have
things like shared classes and ahead of
time dynamic ahead of time compiled code
so you know bringing those capabilities
over into these other language runtime
should help with those types of issues
as well any other questions one more
good no one rises to the challenge okay
all right thanks everyone</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>