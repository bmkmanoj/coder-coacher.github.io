<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Eclipse OMR | Coder Coacher - Coaching Coders</title><meta content="Eclipse OMR - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Eclipse OMR</b></h2><h5 class="post__date">2016-08-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/w5rcBiOHrB0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone my name is Mark
stood Lea I am a senior software
developer at the IBM runtime
technologies team and I'm also the
technical lead for a project called
Eclipse Omar I'm going to talk about
today when I was here last year I came
to talk about a set of secret
experiments that IBM had been performing
to look at migrating some of the core
technology from our j9 java virtual
machine into other language runtimes
like Ruby and Python and you know core
capabilities like method profiling
scalable garbage collection and
high-performance just-in-time compilers
and we thought those experiments were
successful and so at the end of the talk
I indicated our intention to create an
open source project and community around
those components so that they could be
leveraged by all kinds of different
language runtimes and so I'm back this
year to give you a little bit of an
update on where we got to we obviously
created that project it is the Eclipse
Omar project at the Eclipse Foundation
and and I'm also going to do a bit of a
technical deep dive into some of the
just-in-time compiler technology that
we've been building alongside this
project there we go
lawyers like to say things and write
things more things all right so just to
quickly tell you everything that I'm
going to tell you today so you can walk
away if you're not interested in any of
this I'm gonna give a very brief update
on the Eclipse OMR project I'm gonna try
to keep that brief so that I can focus
on this the latter two sections of the
talk I'm gonna introduce a library
called Omar JIT Builder which is a
native code generation toolkit that you
can use even though the Oh Marge it is
not yet open sourced it's coming in the
fall of this year but you can still play
with with JIT builder it's available in
a docker image there's a link in the
presentation that you can use and I'm
gonna show some experiments because I
know that you guys are you know from the
Java community you're primarily
interested about what you can do with
Java so I'm gonna show some experiments
that I did to pull the JIT builder
library which is a C++ library into Java
so that you can actually use it as
alongside a JVM so you can do things
like call native code directly from Java
I'm
use a matrix-multiply example which I
know is a very simplistic not very
relevant example but it was quick to get
up and running so it worked easily it's
not that much slower than pure drive I
know that's kind of a weird result to
report but I'll explain why that's not
such a bad result and then JIT builder
also has some support for vectorization
so I'm gonna show how you can vectorize
that matrix multiply very simply but by
adding a few words here and there
predictably the word vector and it
improves matrix multiply performance by
40% just by doing that so it's a pretty
it's a pretty good story we think okay
so let me just recap the motivation for
why the Eclipse of our project was
created in the first place
so the observation the core observation
here is that there are lots of lots of
different language runtimes out in the
world and they're all doing largely
similar kinds of things obviously they
they're they're implementing particular
languages which have particular
requirements but the core capabilities
are core technologies at the center of
many of these runtimes it's very similar
but they've been implemented completely
differently because they've been built
by different people who are trying to
achieve different things and what that
means is that if you invest a lot of
work in improving one runtime you get
almost no carryover into other language
runtimes and that's a big problem for
IBM we've spent decades improving our
IBM j9 JVM and it's had little there no
carryover into other language runtimes
and so the prospect of picking up that
work and doing it in a number of other
different language runtimes
isn't very attractive to us but and it's
and it's becoming an important problem
as workloads are moving into the cloud
cloud plug for platforms obviously
depend a lot on language runtimes all
the services and applications that
people run in the cloud yes they run on
top of containers but they also run in
language runtimes and all of those
adjectives that people like to throw
around with cloud platforms around
resiliency you know elasticity
scalability all of those kinds of things
security they all depend on the
underlying support that's being provided
by the language runtime that's running
the actual workloads that are in the
system and so if you have different
runtime technologies it becomes very
expensive and slow and you have to get a
lot of moving parts working in the
in the same direction in order to
advance the actual cloud platform and
provide those capabilities to a
consistent level for all the
applications that are running in that
platform so the Eclipse Omar mission is
to build an open reusable language
runtime foundation for cloud platforms
that's a very grandiose sounding mission
but if you don't shoot for the skies you
don't go very far so we're doing that to
try to accelerate advancement and and
innovation within cloud platforms we
want to do it in full cooperation with
existing language communities we're not
trying to build a new set of languages
that will then be the ones that people
use in a cloud we want to work with
existing communities and we want to
engage with a diverse community of
people who are interested in language
runtimes people like yourselves in this
room from professional developers who
are building enterprise class mature
language runtimes
to people who are working in academia to
people who are just students and
hobbyists you know the next language
runtime could come from any one of these
people groups of people and so we're
interested in engaging with all of them
Eclipse omar has a few key goals which
differentiate it from other projects
which are trying to do sort of similar
things the first is that Omar has no
language semantics of its own it's
supposed to be a neutral technology base
and that means that it's in order to do
that it's a it's it's used for building
language runtimes it's a toolkit for
building language runtimes but it's not
a language runtime itself and that
distinguishes it from the JVM approach
to this which is where you build
languages on top of the JVM obviously
the JVM is a language runtime it has
like its own language semantics those
are evolving but at the core at JVM is a
java virtual machine all Mars not a
runtime it doesn't have any language
semantics and that means that all mark
components can be independently pulled
out of the project and integrated into
any language runtime without affecting
the semantics of that runtime and we
think that's a pretty powerful story and
it's a it means that Omar is really just
a tool kit of parts that you can grab
whatever you want and integrate it into
your language runtime as I mentioned the
project was created in March of 2016
we're on github we've got about four
hundred thousand lines of code there
already
and we have a developerworks open site
that has some articles and some
information more information about the
the project we have a website at the
Eclipse org which is extremely
minimalist right now but we're about to
replace that with a much better site the
code is available under a dual license
so you can license under either the
eclipse public license or the apache
license that's a very flows are very
flexible licensing arrangements you can
use it for whatever you want for
commercial terms or for just playing
around and contributors are very welcome
so right now the project consists
entirely of IBM errs but we don't want
that to be the case
we welcome anyone to come and join us
and work on this technology as well as
to you know be nurtured and become
become committers we're looking for
committers as well just to give you a
flavor of the things that are already in
the project so I'm not gonna go through
this list exhaustively but we have you
know a platform abstraction layer
threading models the GC is kind of the
main big component that's there we have
some support for diagnostic stuff an
interesting aspect is if you have no
semantics language semantics and you
aren't a runtime how do you test it so
we had to create a language independent
test framework which is essentially in
as an example runtime which allows you
to run tests against each of the
components and that's all based on
Google test 1.7 so lots of code there
now the just-in-time compiler is coming
this fall and so the rest of this talk
I'm actually going to talk about this
JIT builder library that that I've been
working on kind of on the side and so
the goal of JIT builder was really based
on observation that it's it's not all
that easy to write a JIT there's a lot
of things a lot of moving parts a lot of
little details that have to kind of
align properly you have to know a lot of
stuff no matter what technology you're
using to to make it work and so I wanted
to see if how easy I could make that
process you know with the goal that
maybe you can't get the utmost
performance by using JIT builder but it
would make it easier to bootstrap the
process of getting a JIT compiler in
place so it's really a prototype
interface at this point so you know
prototype alert it's designed to
simplify that process as I mentioned
it's a toolkit that can be used to
generate any kind of native code
have to do a JIT compiler but it's
really designed for building a chick
compiler Oh Marge it is not open source
so it's not an eclipse om R which means
JIT builder is not in Eclipse Omar but
it is available as a docker image you
can download and play with I've been
starting a blog series to describe how
to use this stuff and there's a link to
the to the first article in that series
and it'll be more articles coming to
give more details and explain some of
the things that I'll also be talking
about in this talk so the the high level
API to jet builder is actually a very
simple thing initialize JIT gets the JIT
up and initialized and ready it
initializes all the data structures that
the JIT requires it gets it loaded in
memory among other things it allocates a
code cache and that code cache is where
your compiled methods are going to go so
that that code cache has actually
managed by the JIT itself when you're
finally done at the end of things you
can shut it down and that will free the
code cache so you don't want to do that
if you still want to call your methods
because they'll go away at that point
but but other than that those are that's
the very simple API you used to get a
JIT and shut down the JIT and then
there's this part called compiling and
you need you need to create a thing
called a method builder and that's how
you describe to the JIT what it is that
you want to compile so what is that
thing
so a method builder object basically
corresponds to a C function that you
want to be able to call that can take
some number of parameters and it can
return optionally a return value if you
want and there's two parts to the class
that you write you write a constructor
which is gonna describe what the types
are of your return value and what your
parameters are and then you're gonna
write a build il method which is gonna
describe the methods code and I'll
explain more about how you do that and
show an example in the next slide
actually the method the route though the
core method build our class that's
provided by JIT builder provides a bunch
of services that allow you to inject
code and so when you write a method
builder it looks something like this
this is actually the example more or
less that I used in that first blog
article that I referenced earlier in the
talk so let's just go through these
piece-by-piece so define
name gives you gives it a name that's a
pretty obvious one define parameter lets
you define parameters by name so here
there's a parameter called value which
has an int 3 2 bit integer type if you
had multiple parameters you could call
define parameter multiple times in the
order matters it's defining the the call
parameter or and then finally you can
tell what the return type is in 32
32-bit integers so this is an increment
function that's going to take an integer
and a 32-bit integer and return a 32-bit
integer there's this type dictionary
thing up here that gets passed in that
you have to pass to the underlying
method builder it's for recording and
looking up types and defining new types
so that's exactly where int32 came from
it's actually something that was that
originally came from it's defined by the
core type dictionary type and then and
then the next step is to write your
build il which indicates the operations
that are going to be compiled into your
method so in this particular example
it's going to load the value parameter
it's going to create a constant 32-bit
integer 1 it's going to add those two
things together and then it's going to
return it so the the underlying Omar JIT
technology is is a tree based expression
intermediate language and so when I
write build il I tend to write it in
trees like shown on this on this slide
but just as validly you could write it
in say an LLVM IL like form or you could
say you know t1 equals load value t2
equals constant 32 of 1t 3 equals ad t1
of t2 and then return t3 raised equally
valid it's a little bit find it a little
bit more verbose but but it works just
as well it's kind of whatever whatever
works for you the last thing I wanted to
point it on those on this slide is just
that the the point that the the
parameter name is is defined as a string
and you can use the string later on by
the the load and it will just map into a
stack slot corresponding to the to where
the parameter comes in ok some
observations here so operations are
mostly type list right you said I said
add on the previous slide not add 32-bit
integers those types are derived from
the operands and so the leaves of the
expression tree are the things that
actually determine what operations are
being performed there are exceptions
in the current form so there are
services called load at and store at
that are used for storing through
pointers loading through pointers and
storing three pointers index at computes
the address of an element of an array
those ones at this point you have to
provide type two but in future I'll
probably remove that that requirement
types for parameters and locals can be
defined in the constructor or the first
time that you store to a variable the
first time it's referenced the type of
the operand that you store into it will
determine what the type of that local
slot is for from for all future uses so
if you need a different type you need to
define a different thing if you want to
do control flow you need to use a
different type of concept called an isle
builder so a method builder is actually
a special case of i/o builder i'll
builders correspond to a particular code
path a method builder is a code path
that takes parameters and returns a
value but an isle builder can be any
kind of control flow path and so in this
example I'm going to create an
if-then-else construct so I'm gonna I'm
gonna create a builder for then for the
den side of the PID if and a builder for
the else side of the if if and then a
service provided on I'll build are
called if-then-else
can connect together those two builders
into an if-then-else structure using a
condition like less than or a is less
than B it will execute the code that's
in the then path otherwise it will
execute the code that's in the else path
and then you have to inject code
operations into each of these paths
independently so this code shows
injecting code operations into the then
path and it's going to store obviously
the value 1 into T you can do the same
thing on the else path this is going to
store 0 into T and then any path any
code that you inject not into a specific
builder is going to follow the the
if-then-else merge point of the if so
this code that returns T is going to
either return 0 or 1 depending on
whether T was set to 0 or 1 in the ven
path or the else path in fact you could
inject those code to operations in the
else path 2 if you wanted to and just
have the else path return you can really
do anything you want here it's a matter
of which builder you and Jack
the operations which build our object
you inject those operations into you can
do other kinds of control flow for loops
while loops do loops this is very see
like kind of structures but you can do
variants that count up and down you can
do breaks and continues all the sort of
usual types of things you can do an
unbalanced if you can do switch
statements etc I mentioned the type
dictionary before it's a way of managing
type so you get a set of primitive types
that are based on the underlying
primitive types of the OL margit
compiler which is showing it's java
heritage here in the set of primitives
that are actually available right 8 16
32 64 bit integers floating point
doubles there's actually an address type
as well which you shouldn't use directly
there are a pointer or array types that
are defined by default as well so the
pointer versions of all of those
primitives and then you can also define
structures so if you have a struct with
a number of fields you can define that
and there's an example on the slide here
which shows how you would define a
structure called element and then add
three fields the next field which is a
pointer to element the key field which
is a 32-bit integer and the value field
which is a double and then the code at
the very bottom shows how you would use
the load indirect service to be able to
access the keith's element off of a
pointer called PTR and there's a there's
an equivalent store indirect which
stores a value into the into some field
off of pointer another facility that's
available through JIT builder is a thing
I call bytecode builders and these came
up while someone was actually trying to
write a JIT compiler using JIT builder
and it's it struck me that if you if you
have already code that is essentially
iterating through byte code handle or
byte codes and trying to implement
handlers as part of the interpreter we
could leverage that same structure when
we're trying to build a JIT compiler so
here you create a byte code builder
object you start by writing a handler
for each of the different byte codes
that you've got in your interpreter each
one has a set of operations that
implement that byte code and then you so
you write the handler using the Builder
services to inject those code operations
in do some builder object then you
create a byte code builder object for
you
one of the bike codes in your method so
you go through all the bike code indices
and you create a new object and then
similarly to how the interpreter uses a
switch statement and walks through the
bike codes in order to execute the code
in this case you just iterate over the
bike codes and you call the appropriate
handler for that bike code object that
corresponds to that byte code index and
this has some nice features because the
bytecode index is is associated with all
of the code operations that get injected
into that particular byte code builder
object that particular code path and so
the JIT knows exactly which byte code
index these operations are associated
with which provides some nice debug
ability options going forward finally
all those that just gives you a forest
of little pieces of snippets of code
that are handling all of the different
byte codes that are in the method D then
you need to indicate how those things
are all connected together and so
usually as you're iterating through a
byte code you know exactly how control
flows out of that byte code is it fall
through to the next byte code or not
does it jump away to another byte code
or not and so there's a couple of
services add fall through builder and
add successor builder which let you
communicate that information at JIT
builder finally the first byte code
builder is the thing that needs to
execute when you enter the method and so
your method builder has to do this call
to append method builder here so that so
that code will begin executing at the
the zeroeth bytecode builder and then
once you've done all that the JIT
builder can basically piece everything
together and put it all into into a nice
method for you sorry and I there's a
little bit more explanation about this
and a talk I did a couple of weeks ago
at developerworks open which goes
through a little bit more detail than
more pictures and diagrams showing how
this process actually works and we've
done it once so we did some work with
the salm plus plus which is the simple
object machine for those who you're not
familiar with it it's a it's a research
and teaching vehicle for virtual machine
technology there's a number of different
implementations in a number of different
languages we chose the C++ version of
that and added a JIT so a guy who works
on the Omar team Charlie Gracey he
actually built a gyp in about a week for
the his first JIT for Psalm plus plus
and it's got about
nineteen bytecodes something like that
and he's showing a 3 to 4x improvement
on most benchmarks at this point so for
a week of work for somebody who'd never
written a JIT before in their entire
life that's uh pretty impressive and and
good result this slide shows the current
state of all the things that you can get
actually there's some things missing
from it right now because I've added a
couple of things in the last week but
I'm not gonna go through these in detail
but basically this is a this is a set of
operations it's a point in time
statement about what JIT builder can do
it's not a complete set but it's a
pretty good set to get started with all
right so I can hear it all in your minds
you're thinking wow I have to write C++
code I'm a Jap a guy I'd really rather
write Java code so what if you could use
JIT builder from Java right you have
this lovely j'ni interface we have all
these things that have been built on top
of the JVM and to augment the
specifications so that we can actually
interface better with native code
couldn't we leverage that to interface
with ship builder so yes I've proved
that basically the rest of the talk
shows the results that I've managed to
put together in the last kind of two
weeks worth of work alongside all of my
work so this is really a prototype ee
but it does hang together and it does
work so the concept here is that
alongside the JVM you have a
just-in-time compiler that's operating
and able to generate native code that
can then interface back with the code
that's in the JVM
so you have you have an execution
environment inside the JVM you have a
Java JIT that's inside the JVM and it's
generating but sorry native code from
java bytecodes
you have a Java heap that has Java
objects and then in the unmanaged native
environment I'm gonna dynamically load
legit builder library natively and it
create its native code cache here and
then interface back and forth why a j'ni
and at the same time the method builder
objects that I talked about you creating
and bytecode builder objects and I'll
builder objects we're gonna cross link
Java objects over here so that you can
write code over here that interfaces
with objects in the Java heap and then
those are cross-linked back into the
native code sequence so you don't
actually interact directly with the
native code you write code over
here which interacts with these objects
and then via J&amp;amp;I you can interact with
the native code that you're getting
that's being compiled and so the process
to actually use JIT builder from Java is
very similar to how I described for in
the native case so this is just the
package location so you need to be able
to find all that JIT build their code
you need to load the dynamic library
that corresponds to the Java jet builder
code base and then call initialize JIT
to initialize it and that should work if
it doesn't work then something is very
clearly wrong you may be ran out of
native memory say you have to create a
type dictionary just like you had to
create in the in the native side you
have to create a method builder object
write a method builder a class that
defines what thing you want to compile
and then you have to create an object
that corresponds to the method that you
want which is the method M here when you
want to compile it you just call the
compile function on on mat moult here on
your method builder object and that will
give you back a method handle which you
can then invoke as many times as you
want passing parameters directly from
Java so this is all Java code that I'm
showing here on this slide there's no
native code that's happening here and
then finally when you're done you can
shut down the JIT and same caveat your
native code will disappear when you do
that because the native code cache will
be freed so the example that I'm gonna
show here is matrix multiply I know
that's a pretty weak example but it's it
was a simple one to get up and running
as I said I started working on this two
weeks ago so I didn't have a lot of time
to put together a lot of stuff so here's
the constructor for the matte mult
method which defines the name is matt
mult it has three parameters C equals a
times B and the the matrices are going
to assume to be square at with n as the
parameter I could probably get that from
an array if I wanted to but I decided to
do a comparable native versus C
implementation of this and it's not
going to return anything so in return
type is no type now there's a little bit
of a difference here I didn't talk about
array parameters on the native side
because it didn't actually matter on the
native side if the parameter was an
array or not but when you're working
with Java you have to make sure that
you're doing the right things via J&amp;amp;I
when you're working with the
that's inside an array because you don't
want GC to go and move your object when
you're Dorking around with the elements
inside the array and so there's a bit of
a ballet that happens at the beginning
of the method and at each return point
that does the calls to to get the array
elements via the J&amp;amp;I functions so that
you can access the raw element data and
then on return to release that to
communicate to the GC that it's okay for
for this object to be pinned or or not
to be unpinned I guess okay the
innermost two loops so this is the JIT
builder code for the N by n matrix
hopefully you can all read it so so this
is the J loop this is the K loop here so
we're doing a for loop over an iteration
variable J this is going to be the
Builder object that we're gonna store
the code operations in the J loop it's
going to iterate from 0 to n by 1 inside
there I can access J as the index
variable of this of this loop I'm gonna
start off my dot product here by storing
into some a constant double 0 point 0
then I create my K loop which is going
to iterate over K from 0 to n by 1 and K
loop is the builder object in which I'm
gonna store the body of the K loop
inside there I can access the the
iteration variable K very easily load 2d
is a function that I wrote I'll show it
to you on the next slide which just
basically you know does the index array
calculation I embedded I'm using a and B
as single dimensional arrays so it just
computes you know I times n plus K as
the index into those arrays and produces
those values same thing for B of KJ and
then this is just doing the dot product
right so we multiply those two values
together add them and then store it back
into the sum variable and then finally
in the J loop when we're finished
creating the dot product we have to
store that sum back into C of IJ that's
it in a nutshell
oops sorry wrong way all right so load
2d and store 2d is actually very similar
so it uses the load at and index at
functions that I talked about earlier so
you can see here there's an element
address
a service that's used by both load 2d
and store 2d as I said it's just taking
AI times and adding J and adding it to a
so there's no object header here it's
just its indexing directly into the raw
element data for a some array a and then
in order to do a load at you are sort of
in order to load the element that's at
that address you just do the load at and
if you need a store you do a store at
all right so how well does it work this
is the comparable Java version just for
reference here I've tried to do the fair
thing and implement the exact same loop
that I used for JIT builder this is the
loop that I wrote in Java that does what
the JIT builder code does and so I did a
couple of experiments which you already
know the results of but go through it in
more detail now so the first experiment
I'm so I'm just multiplying some big
double matrices I chose big matrices so
that they would take a significant
amount of time it would give the time
for the JIT to warm up to see what code
it was doing as well as time to
transition to the optimized code so that
we don't have any sort of warm-up
effects from from JIT code so there's
plenty of opportunities to transition
optimized code it's about six Meg's of
traffic so it does actually fit into the
on-chip caches on the on the machine
that I used it's a big massive 32 core
machine on which I used one so it's a
little bit of overkill but anyway it
worked it was a very quiet one of our
performance machines and then I know
you're all expecting because I'm from
IBM you were expecting me to evaluate
this using the IBM j9 JVM instead I
decided to use open JDK just for fun so
so I measured open JDK 8 running the
pure Java implementation and then I used
open JDK 8 using the Java JIT builder
implementation of the matrix multiply
and these are the results I got so so I
did 20 runs of the matrix multiply it's
probably a little bit of overkill
because obviously it kind of levels out
pretty quickly but nonetheless you can
see on the the blue line is open JDK the
orange line is open JDK with jibt job
the Java jet builder implementation and
matrix multiply so it's a little bit
faster open JDK with the pure Java
version and that's
that's okay because the difference is
only about 9% and I'll explain on the
next slide why that's not why I don't
think that's such a big deal one other
important thing that I wanted to point
out here is just that even in this
example there's a ramp up cost for using
the Java JIT compiler it does take time
for it to transition to the most
optimized code that it can generate and
so it's only on the second run that
you've got the the best performance that
open JDK could do although I have to
admit even on the first run at beat Java
JIT builder so it's it's doing it's
doing a very good job but it's not
getting to the best code that it can get
whereas Java jet build there is a lot
more stable and it can get code right
away and the the the reason it can do
that is because there are no heuristics
around there are no embedded heuristics
around when code gets compiled with Java
it builder you say MDOT compile and it
compiles it on the spot for you right
then and there okay so open GD kate's 9%
faster why is that not a bad thing well
comes down to a point in time statement
about the refactoring work that's going
on in order to enable us to open source
the OL margit so for reasons that I
don't really hope I don't have to get
into JIT builders in a state right now
where the or the ol mark it I guess is
in a state right now where it can't
identify induction variables and loops
so for those of you who aren't familiar
with the term induction variable they're
basically expressions that change as a
linear combination of the index
variables in loops
they're pretty important for doing loop
optimizations many loop optimizations
depend on being able to identify index
expert in duction variables within loops
in order to do anything and so that is
the case in the OL market and that means
loop optimizations are basically
disabled in the jet builder code I'm
assuming I think it's a pretty
reasonable assumption that the open JDK
8 JIT compiler is doing loop
optimizations on the code that I've
generated matrix multiply it's three
nested loops I think it's also a pretty
reasonable expectation that loop
optimizations make a difference in this
in this benchmark and I did actually
verify that the index expressions that I
expected to see in the inner loop inner
loop of the JIT builder matrix multiply
are there what I haven't done is
verified to that that the openjdk Java
JIT managed to do
striding through the loop so it's just
doing a pointer bump inside instead of
having to do the multiplies in the ads
to compute the array index expressions
okay
so nine percent slower okay great so
let's try the vector support that's
there in in jibt builder I didn't talk
about this yet so let me just give you a
quick description of what's there so the
OL marge it has primitive types
available for doing vector operations on
any of its primitive types so they can
do 8 32 8 16 32 64 bit ants floats and
doubles can be represented as vector
types and then because shipbuilder
operates without with type less
operations it's really only the loads
and stores that need to get affected
when you want to work with vector data
instead of working with scalar data and
so load changes to vector load store
changes to vector store you know it's
pretty predictable renaming style There
is obviously manual work this is not
Auto vectorization this is providing
facilities for people to be able to
write to vector code and expose that
through through the through the through
the the digit builder interface so you
know I had to change the loop bump on
the on the J loop to bump by 1 instead
of 2 because I'm working on doubles and
the hardware that I'm running on can do
two doubles at a time I should have
written a residue loop but I didn't
because I knew n was a multiple of two
and so it would never execute so again
this is kind of a prototype alert here
you know some of the data types don't
work on some of our platforms this is
really in in a state of being developed
but it is what's good enough to actually
run this code so let me show you the
inner two loops again so I showed you
the scalar code before the red bubbles
show the code that I had to change in
order to make this vector loop so I had
to change the trip count on the J loop
remember that J loop is the one that's
going down the column on the rightmost
array so it's very easy to vectorize
that that access pattern so I had to
change stored a vector store I had to
change load two vector load there are
another couple of changes inside the
load 2d in store 2d but it's the same
type of thing I had to add vector to the
load at and to the store at so it's
actually a very simple change
I had to make to the code and so I think
that was that's pretty easy it's not
much to it and the result that I got is
is a pretty good result it's not as good
as I had hoped for and I still have to
dig into why the results not as good as
I'd hoped for but but it basically did
improve the performance with chip
builder by 39 percent over the original
numbers and that gets you substantially
better than actually the pure Java
implementation because you're actually
being able to leverage the instructions
that are that are there and the hardware
that pure Java doesn't let you or
doesn't let you from the implementation
that I gave leverage those instructions
you know I know there's gonna be more
talks maybe later today and tomorrow
they're gonna talk about new facilities
the new new ways of accessing these
types of hardware facilities so it's
it's really a point in time comparison
you know I'm not comparing against any
of that those types of facilities okay
the just before I wrap up here I wanted
to talk a little bit more about sort of
the strategy that I have around this
chip builder technology so it's really
about creating an incremental story
around investing in in building JIT
compilers so similar to I think it was
John yesterday who was talking about the
the layered approach to to accessing the
power of the JVM I want to build an
incremental investment story for
building JIT compilers and JIT builders
really kind of the first the
introductory layer to that I want to
make it as easy as possible for someone
to start writing a JIT compiler and get
up and running so the bytecode builders
is one step towards that it's designed
to get you up and going quickly the
lower implementation layers on which the
il builder and method builder and
bytecode builder classes are built
provide a much more granular control
over what intermediate language is
actually being generated and fed into
the Omar JIT compiler and so if you use
those layers you can actually do a lot
cooler stuff but it's at the cost of
having to learn all the details of the
Omar jet intermediate language which I
mean it's not impossible to do that
obviously it's not as super complicated
in your immediate language but it does
have its subtleties and there are lots
of details to get right just like all
compiler intermediate languages so the
experiments I showed here really show
you how you could surface this tech
within the Java ecosystem because I know
everyone's interested in Java here but
these bindings you can create these for
just about any language there's no real
reason why you couldn't surface JIT
build their technology in Ruby or in
Python or in JavaScript or other places
it was you know if I add up the work
that I spent creating the Java bindings
to the point that they are at right now
it took me about two days of work
they're not complete obviously but the
remaining work is really mechanical you
know that two days of work included some
help from a few other people so dan
Heidegger I know some of you know him he
helped me with the code to proof up the
anonymous class that has the native
method inside it so that you could call
it by a method handle there are some
folks on the JIT team that helped a lot
with getting the vector encoding the
whole set up so that we could generate
the vector instructions that we needed
to vectorize matrix multiply on x86 and
so on but but largely speaking it's not
a lot of work to get that up and running
and working and it would work
consistently from language to language
of language all right so let me just
wrap up so the Eclipse Oumar project we
created it in March we have a mission to
try and create an open reusable language
foundation runtime foundation we're
trying to build an open community
everyone is welcome to come and share
and discuss ideas to share technology to
work with best practices we have 400,000
lines of code in the project right now
that give you access to mature
enterprise-grade runtime technology and
there's more coming the whole marriage
it will be coming this fall the JIT
build our code is available now you can
play with it it's available in a docker
image I have not yet made the Java JIT
builder code available but I'll be doing
that hopefully at the conference and
make the docker image available and
though anybody who wants to follow me on
my Twitter link which I'll show on the
next page I'll I'll be posting once I've
got that up and running and will point
people at it it lets you write your own
JIT compiler it's part of an incremental
strategy to let you invest incrementally
to to bring just-in-time compiler native
performance to your runtime and you know
I show Java bindings but it could really
be used for anything and I guess I'll
wrap up by saying everyone's welcome to
join us and I hope you will
I'll just leave that up</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>