<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Project Sulong: an LLVM bitcode interpreter on the Graal VM with Matthias Grimmer  @grimmer_m | Coder Coacher - Coaching Coders</title><meta content="Project Sulong: an LLVM bitcode interpreter on the Graal VM with Matthias Grimmer  @grimmer_m - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Project Sulong: an LLVM bitcode interpreter on the Graal VM with Matthias Grimmer  @grimmer_m</b></h2><h5 class="post__date">2017-08-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yyDD_KRdQQU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody my name is matheus Grima
and today I would like to talk about
projects along an LLVM bit code
interpreter on the ground and before we
start with this talk I would like Orakei
wants you to know that the following
presentation gives insight into a line
of research without further commitment
the world is polyglot there are many
great programming languages out there
and programmers use the tools and
programming languages that suit the
needs most however when we try to
combine and compose different
programming languages we will
immediately see that all these program
is programming languages live in this
thing's world the implementation of each
programming language is different which
makes it hard to combine programming
languages it requires us to write
boilerplate code and when running our
applications we win we will experience
performance bottlenecks caused by these
language boundaries our group at Oracle
labs invented de Grasse VM and degrade
VM results these issues because it
allows you to easily compose different
programming languages provides a rich
set of tools that you can use with each
and every of these programming languages
and it seems to be a perfect role
however appearances are deceiving all of
this programming language in one way or
another like to talk to native code Java
likes use Chennai Peru with Roc
extensions in noches there are native
modules Python also uses the extension
and so on and so forth and our native
code again lives in a separate world a
world their code is statically compiled
a world there are that there are no
dynamic checks whenever we access memory
where there are pointers where there can
be buffalo overflows and so on and so
forth also the fact that we have
precompiled binaries again introduces
about a boundary between the VMS like
the JVM and precompiled native code
in today's talk we will talk about zulan
and Seulong the project Toulon makes C
C++ and all of your native languages are
first class citizen in gray VM and
before we start with details about too
long let's take a closer look at what
the gray VM actually is McGraw VM
consists of many different languages and
we used to truffle framework to
implement those languages to travel
framing is an API that allows you to
implement your favorite programming
language for example using an AST
interpreter truffle itself uses the
growl compiled as a dynamic compiler to
compile those programming languages at
runtime to machine code and those two
things then can run on top of hotspot or
on top of substrate via let's have a
closer look or a brief look at the idea
behind crustle the idea is very simple
you parse a programming language to a
tree and a SC for example then you start
interpreting this esc during
interpretation you collect profiling
feedback and specialize your tree for
example you specialized the JavaScript
plus operation for example on numbers
only this plus only adds up numbers once
the tree is executed frequently enough
and it gets hot we partially evaluate
this tree and compile it to machine code
partial evaluation means that we assume
the trees stable in line all the nodes
into a single code block optimize it and
then get optimized machine code we
hereby heavily rely on optimistic
assumptions about our profiling and
about our program being behaving
constantly and of course this optimizer
these assumptions can go wrong
we have to dsm eyes provide a machine
code transferred back to interpreter
Reese Peschel eyes and then the cycle
starts over again so that was a very
quick introduction to truffle I guess
most of you guys know about truffle all
already
so let's directly take a look at Sula so
as already said soo long is an LLVM bit
code interpreter that means you compile
your C C++ Fortran code using your own
LLVM bit LLVM front and then compile it
to LLVM bit code once you have this bit
code file you can run it on top of gravy
amusing so long so for example if we
would compile a c snippet like this to
LLVM bit code we would use clang and
then we would get this bit code file for
our c snippet and can directly run it on
through long a location your native a
your native applications will do a
location and so long allocate those
guest language allocations on the native
heap so whenever your LLVM bit code does
some allocation like native code we
allocated on the native abusing the
unsafe api and given that we are running
LLVM bit code we are using the same
alignment for the data as for example
binaries would do that are combined
using GCC or LLVM and that also allows
us to exchange our allocations with
pre-compiled native code so what this
means is that too long cannot only run
your LLVM bit code on top of radium but
it can also access precompiled binary so
main application running on top of so
long and your able to somehow link to
precompiled binaries as you are used to
when compiling and running your native
code using normal native compilers and
this is done using Crawford's native
interface which is part of profile and
allows you to easily access precompiled
binaries
so here is our LLVM bit code example
again and this example consists of three
basic blocks the first basic block on
top is just a branch to the second one
the second one contains the function
call the addition the comparison and
another branch and the last one is
return statement on the very right you
can see the proper notes we build in so
long for this LLVM bit code on the very
right you see all the notes we build for
the individual statement in the middle
we have the three basic blocks
so this rebasing blocks just group
together our statements and on the very
left we have the basic block dispatch
node and each basic block is implemented
easily all we need to do is we need to
read we need to iterate over all
children of all statements and execute
them and during partial evaluation we
need to inline all children and in that
case it's pretty easy we unroll this
loop and then can actually execute an in
line of the statements it gets trickier
when we take a look at the basic block
dispatch node because this node actually
is responsible also for expressing the
control flow of our application so basic
block zero has a direct successor name a
basic block one basic block one is the
loop body it can jump back to itself two
basic block one and it can jump two
basic block to loop exit and basic block
two then does not have any successor
it's the return of the function in that
case partial evaluation is not as
straightforward as before because given
this loop we cannot just inline all
basic blocks because there is also the
control flow we need to Express so the
question is how can we partially
evaluate this loop
we have to first of all we have to
extend our partial evaluation algorithm
a bit but we need to also help the
compiler a bit in order to allow him to
unroll this loop and what we do is we
add some additional information to every
basic block what we do is we add an
array of an array to each basic block
that stores all possible successors of
this basic block and this array is a
partial evaluation constant that means
when the compiler partially evaluates
this very this very basic block it can
see what successors can follow this
basic block and now we under on the left
you can see the source code and the
source code are of our basic block
dispatch implementation got a bit longer
and we added but a bit what looks a bit
like an indirection namely we take a
look so we execute the basic block get
back and index into these successes
array and then we read the successor out
of the successes array given the index
next and get back the index of the next
basic block that really seems like an
indirection but we will see that this
allows the compiler to easily unroll the
loop so the compiler now starts peeling
the loop the first iteration can be
peeled easily because with the loop so
the the index was initialized with 0 so
we can easily peel out the first
iteration and that's easy so far and now
we benefit from our partially ever
partial evaluation constant successes
array next is the variable next is a
runtime value the compiler doesn't know
anything about it but it uses it as an
index into our successors array and the
successes array itself is a partial
evaluation constant so in this
we know that index can only be one which
allows us to pin the next iteration out
of the loop and we do the same again
successors is again a partial evaluation
constant and in this case the compiler
sees whoops there are two possible
successors so it needs to insert a
control flow split so here is the splits
in pseudocode and then the compiler also
recognizes that the the one branch where
index is one has already been expanded
before and when he sees that he just
entered the back edge and doesn't
further expand this branch in the else
branch we continue as before we peel the
second iteration out of the loop and
afterwards in third the loop itself
again last iteration the compiler sees
that the loop will now terminate index
is minus one and the loop unrolling has
terminated and we successfully removed
this loop and we were able to partially
evaluate and in this node and we were
able to inline all basic blocks into our
basic block dispatch node and after that
we have machine could block for our
native C C++ function and we can
optimize it and it will result in good
performance and Rabia so that was a very
brief introduction to how Seulong works
it's other than that it's very similar
to other truffle languages and I would
like to present a small demo of so long
now and what I'm going to show you now
you can try it yourself please go to the
oracle technic work download degrade vm
and the example i'm running should run
on your machine too
okay so we are not going to write a
simple C application because I guess all
of us have written a C application
before and we did run it so what we want
to do now is we want to combine C with
other languages and therefore
demonstrate the strength of de graal VM
so I start my C application I define a
struct for a point I will add a function
to allocate an initializer point and a
function to free a point and these
functions we want to use them from our
JavaScript application in a second and I
will also add to getta functions to get
the x and y properties of our struct and
yes all these functions will be used
from our JavaScript application so let's
write the JavaScript application the
first thing we do is we load the bit
code file into a polyglot we will start
the up we will start the Grove am using
this javascript file so the first thing
we do is we load the C part of our small
application then we import all the
functions which is defined in C code so
that we can use them from JavaScript and
here we just were just using the C
functions we just defined from within
JavaScript so let's run that first thing
is we need to do is we need to compile
the C code and then we can run it
it's no big surprise
we the program works as expected and
what we are doing is we are accessing
our C functions from within JavaScript
so let's make this a bit more
interesting we add another function an
error reduce function this is a C
function that takes a double pointer
which points to an array it takes the
size of the array and it takes an OP
function that we use to reduce the array
to single value and now let's use this
very function also from within
JavaScript so whether it is I imported
this error reduce function as before I
define a JavaScript plus function and
now I'm calling our C function from
JavaScript I as arguments I pass the
JavaScript array the length and the
JavaScript function and what will now
happen is that we will bind a JavaScript
array to this double star array and a
JavaScript function to the C function
pointer variable here and at this line C
will call back into JavaScript and use
the JavaScript add two to perform the
add of our array values let's compile
again and run in run this and ask before
we get the results that we expected and
what we just did is we had on an
application where we'd tightly a couple
JavaScript and C and all of that was
running in top of char on top of the
gravy
you might wonder why you see here or why
use JavaScript why you see from
JavaScript at all of course the answer
might be performance
and to demonstrate a bit what we can do
given that we can tightly combine
JavaScript and C I would like to extend
this point example a little bit further
and what I did is I am now allocating an
array of points and I mean C so I create
an array of points and not of point star
I'm filling up the values and then I'd
like to shift all elements in our point
array by a certain data just an example
and as I might see I am using the array
indexing rather than accessing the
properties directly and then there is a
small harness just to - yeah measure the
performance and what I what I would like
to do now is I'm compiling it again and
I've compiled this C file now using LLVM
all three all optimizations enabled and
let's run this to get this to get the
native execution time now let's go
better so time was a bit more than 10
milliseconds and now let's go back into
JavaScript and compared it to JavaScript
performance so what we are doing now is
we are again allocating an array of
points this time it's javascript points
and we are running the same micro
benchmark as before and shifting all
these javascript points parcels and
delta given that we are on top of growl
VM we can also use the C functions which
is defined so here I'm allocating my C
array and I can use the C array from
JavaScript and so I've write the shift
function also in JavaScript and as this
is a C array I can use the same nice
array indexing as before from within
JavaScript and shift to see
from JavaScript so it's an area of value
types and now let's run it on rail VM
so the first first part is the
JavaScript application and takes about
50 milliseconds and when we do the same
thing but with the C array you can see
that performance improves quite a bit
and we get close to the pure native
performance that was not using growl at
all or the growl growl VM at all and in
this case our JavaScript plus C
application has close to native
performance
okay what else can we do with too long
on gravia let's talk a bit about Ruby
Ruby has to see extension API it's an
awesome API that allows you to write
parts of your Ruby application or
modules in C code and one would assume
that there is a very clean API between
the Ruby engine and the C extension
itself it makes it easy for other Ruby
implementations to support this API well
sadly that's not the case the API is
rather nasty and it reveals a lot of MRI
internals to the C extension and
depending on how well behaved the C
programmer was it is easy to run or it
is very hard to to provide an API that
can run all the extensions out there and
that leaves us with the Rada
unsatisfying status quo there C
extensions are only well supported when
running on MRI and now I would like to
show you how we implemented the C
extension API on top of graal VM so what
you see here is a very small T extension
on the very left you have the Ruby code
the Ruby code instantiates the C
extension C array and then it called
eros ohm passes the Ruby array to the C
code and on the very left you have the
for loop that simply adds up all values
in our C array and we are using
different C extension functions like for
example this Ruby array entry function
that allows you to get certain elements
out of Ruby array and these C extension
functions are all defined in a header
file in this Ruby header file and this
Ruby had a file it contains all six
central functions that we need to
support on Broadway
and what we did is we took we
implemented our own Ruby header file
where we just listed all the all
function definitions and then we
introduced a ruby dot C file that
contains all the implementations of this
Ruby dot of this Ruby header file and so
we are implementing the C extension API
in pure C so for example in order to
access the the nth element of a Ruby
array we are just using truffle API
prophets interrupt API in order to
access the Ruby array down here you can
see truffle read index which is nothing
else than accessing a foreign array from
C there are also functions that are not
so easy to implement on seaside for
example the fixed num to integer
function and what we do is we implement
this function in Ruby and then just call
the implementation of fixed to int from
C so we are calling the Ruby function
from C that implements this the
extension function and now we have a
system where we implemented an existing
API across two languages in pure guest
language code so there was no need to
tweak so long nor ever the need to tweak
trottle Ruby we could implement the
entire API in guest language code and
all we need to do is the ship Ruby dot C
and Ruby dot RB together with Raleigh M
which allows you to run existing C
extensions on valium
another benefit we're on top of garage
VM so we're also on top of truffle and
all these applications are just a bunch
of truffle note and we can apply
inlining and the differences between
languages are gone once we have profile
notes for them so we can inline across
across language boundaries so you see it
so you see extension can inline your
Ruby code and your Ruby code unless the
C extension there is no compilation
boundary between those two languages
anymore we did some performance
measurements and the baseline here is
MRI running image manipulation libraries
and the baseline is running pure Ruby
code and from this pixel manipulation
libraries there also exists a cig
central version and that's what you see
in the upper bar the MRI the C extension
that the same benchmark but implemented
in with the extensions running on MRI
and we took the same six inch benchmarks
and run it on our system and what we
could see is that it's been about three
times faster than MRI and the reason why
it's so much fast is simple it's
cross-language inlining there are a lot
of codes between Ruby code and C code
for example for each and every area
access object access and so on and so
forth and the fact that our compiler now
can see through those areas allows us to
get very good performance okay another
demonstration now I would like to show
you that our C extension implementation
is something real and not just a toy and
I couldn't think of a better example
than running OpenSSL C extension on the
growl um which is a rather big and nasty
Ruby module implemented using C
extensions and we want to use the open
URI module from Ruby
of Murie module allows us to get the
HTML code from a webpage let's just use
github and this this module directly
depends on open SSL and open SSL well
it's as the extension more less
okay so what we are about to do is first
we want to look first we want to load
the OpenSSL the extension and we do that
by require open SSL so that now loads
open SSL and let's check whether it's
available by doing put oh I'm very sorry
yes so what I did is I loaded the
OpenSSL C extension here and now let's
check if it's available put and we can
see that OpenSSL is now available so now
let's load up Murray and finally let's
do put open HTTP github.com to read
okay I hope the internet connection
works but yes we should now see the
content of the github page so my point
here is that you can use the gray VM and
Ruby plus extensions for real-world code
and run real-world extensions on top of
chromium yeah
let's go back to slides and we don't
want to stop here so we want to also
implement other native interfaces for
example they CC classes interface of R
or Python the same way we did for for
Ruby and benefit from having native
languages on top of Albion okay now
let's put some cream on the top let's
make our exit let's make the execution
of native code on top of Brad vm memory
safe and this is done in a research
cooperation with shakey you link at the
beginning I told you when ever so long
does an allocation if this allocation is
done on the native e for example for
this group we would just allocate 16
bytes on the native heap and in
yesterday John Rose said that the checks
at run times are one super power of the
Java VM and now we want to use this
super power also for native applications
running on top of the garage VM and what
we do is we want to use Java allocations
in order to represent CC plus data
structures and that gives us spatial
spatial memory safety because we are not
directly accessing data on the native
heap but we are using Java objects to
represent those objects and you're not
using raw pointer values but we
implement pointer values
using Java references plus a certain
dosage we will see that in a second
and given this abstraction that we are
using to implement an even lower level
concept allows us to make native
languages running on to long memory safe
and we will get temporal signals for
free because there is a mighty garbage
collect in the background which ensures
that we do not access for example access
memory after it has been freed so this
example our structure we are using a map
like Java object to implement structs
and for every member in a struct we add
a lot to our map and the identifier of
these slots is just the byte offset that
native pointer arithmetic would add to
the base pointer and we implement
pointers using set pointer objects and a
fat pointer object is nothing else than
a reference to the java map and an
offset and this offset we can then use
to implement pointer arithmetic and it
doesn't matter whether an access to our
structures like indicated here s arrow b
or some weird pointer arithmetic as long
as the offset is then zero or a and with
offset 0 we access the first first entry
in our map and if offset is a we use
AIDS as an identify into this map and
can access the second property and for
example right value for point two to
destruct and this is work in progress
this is research but once it's once we
have this that means whenever you access
native code from Java or access native
code from from your C extensions you're
not throwing away all the safety
guarantees but also C code or native
code will run safely and we can still
guarantee memory safeness
and that all already brings me to the
end of my presentation so what we did
was so long so long brings native
languages to the gray VM and makes them
a first-class citizen integral VM
Seulong allows you to efficiently
combine different high level languages
with native languages Seulong can
implement existing native interfaces
like the C extension interface and the
cream on the top is that in the future
we will also be able to guarantee memory
safety when running native applications
on grow beyond and with that I'm happy
to take questions yes
so I just wondering do you know how much
overhead um to use the safety memory
model I cannot get answer that
so the memory safeness is very early
early work I'd like to point to two
different papers that are already out
there talking about memory safety and so
long but I do not have an evaluation
using big benchmarks here and sorry I
have to point you to two to the
scientific papers
so I have two questions do you support
like advanced features of see like set
jump long jump and like can I copy the
Java stack and then get like a
reinforced e okay set some long jumps is
not yet supported other than that so
long is still single threaded so you
cannot fork but you can use ruling from
different threads that's possible but
Turing itself cannot fork that's the
current limitations of solonius and the
second question would be how do this
interact with garbage collection like if
you even see where you have like malloc
and free and then in Java how do you get
like you have the garbage collector skin
or the garbage collector communicate
with mental memory okay yes that is a
very good point when when when running
when running C code on top of a JVM of
course the different memory models clash
and it works it works it works pretty
well the fact that in too long we can
store all the local variables in Java
data structures so in proper we call it
a frame it contains all the local
variables and we can store like manage
manage values in there as as yeah that's
no problem however there is some
limitations for example it is not
possible to store for example a
reference to a chava script array into a
C struct that's just not possible and in
such cases we say whoops that's not
possible and you have to to resort to
some work around our workarounds are for
example some some maps that map point to
reference and so for example what we do
is we we get for a reference we get an a
long value that somehow maps to the
reference that we can then store into a
struct but that's all my work arounds
but given that there will be a memory
safe version of Subang that we not use
the native memory anymore but only use
Java data structures than we have also
resolved this this limitation but
currently yes given natives given strong
any tentative allocations that that's
the limitation but for example they now
as the extension work it almost never
occurs
hi this is really great work but I have
a question on the calling convention
like clang and other LVM front ends they
generate code that sometimes rely on
some like very subtle platform dependent
calling conventions for example if you
return a struct in C and if you compile
that down to LV Mir then on different
architectures you might get different
like weird stuff like sometimes a struct
may get unpacked or sometimes it it gets
allocated in the parent frame in the
caller frame and then a pointer is
passed down so how does Seulong handle
that and so that's the first question
the second is how does suelen work with
the standard runtime libraries of these
native languages and especially with the
calling convention in mind ok Assad is
the second one
sir one can access see the native
library by on prophets native interface
so that's pretty simple native calls
that we have to do and regarding your
first question
so lnv Mir is very nice here because
either it uses built-ins that we just
implementing Java or the so long only
has to implement all the all the LLVM IR
bit codes and these these differences
you mentioned for example when returning
a struct are not visible to to so long
so so long just interpret or execute llm
IR and and those those differences do
not matter for us I see so you're
expecting that the LVM are generated
from a front end is going to be
compatible with whatever runtime library
okay thanks
hey super fun work similar to the set
jump long jump question you had a ruby
code snippet that threw an exception
what are the semantics for exception
throwing from say managed from Ruby into
C does it or yeah yeah I've so that all
boils down to two traffice interrupt API
so when there are exceptions across
languages it's a matter of how we want
to show them to the user i I wish I
could have showed you a stack trace
across Ruby and C I'd like to invite you
to check out the next version of grad VM
and throw an exception in C or in Ruby
and then take a look at the stack trace
and what you will see is you will really
see the guest language stack trace where
you have a C frame a Ruby frame a C
frame Ruby frame so yeah cool and just a
quick follow-up have you thought about
what the right thing to do is with say
for instance if I'm we're executing see
and we segfault
could you imagine wanting to like wrap
that in a native exception of popping it
back or do you think it's better to just
crashes like it normally would current
name you just crash could be possible
yes to wrap that but currently we just
yeah SEC fourth yeah thanks
thanks really interesting work it looks
like one of the goals is memory safety
and I'm sure you know LLVM has you know
memory safety features in the form of it
sanitizers address sanitizer memory
sanitizer and I was wondering if you
could I'm sorry little horse I was
wondering if you could address the
advantages or disadvantages of doing
something like this for memory safety
versus just compiling your data so with
LLVM with the sanitizers turned on yes
yeah yeah the sanitizer is by far not
catch-all issues and given that we
performed checks at run time allows us
to catch the the arrow or the problem
right before it occurs and the question
you just raised is a very good fit to
one of our recent papers where we dive
into details and compare like address
sanitizer so the safe version of Seulong
and so on and so forth and find out the
advantages of each other and measure
performance differences and if you like
I can I can show you the paper right
after after this talk and then we I'm
not yet published it's only submitted
but yeah then let's let's continue this
afterwards yes there is plenty of work
there okay then thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>