<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Jump-start Your Microservices Development with Java EE | Coder Coacher - Coaching Coders</title><meta content="Jump-start Your Microservices Development with Java EE - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Jump-start Your Microservices Development with Java EE</b></h2><h5 class="post__date">2017-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1HdtILoL6O4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I think the flow people are slowed
down so we'll get started
so welcome this is jump and start your
micro service development with Java EE
I'm Kate Stanley mrs. Graham charters we
both work for IBM and we're hopefully
gonna give you some information today
about why we think Java is a good fit
for micro services so this is the
content that we're going to talk to you
about today we'll have a little bit of
an introduction to microservices just a
quick show of hands who here already
thinks they know what a micro services
okay so we'll give a bit of introduction
then hope for you level set where we are
and then we're going to talk about Java
EE evolution some stuff about docker and
micro services some packaging
considerations that you might want to
think about while you're creating
applications and then also how you can
use the open API specification and a
conclusion we're going to show a couple
of demos as well we'll try and keep the
talk quite general about Java EE but
because we both work for IBM we're going
to kind of demo the things that we know
and we're used to and hope that the demo
gods smile on us today so let's get
started
so what are micro services they're used
to compose a complex application using
small independent autonomous replaceable
processes that communicate via language
agnostic api's so rather than deploying
one big application you deploy it in
lots of small pieces and they come with
some advantages and then some sort of
complexities and difficulties at the
same time so whenever I'm giving a
microsomes talk I always kind of say go
have a look read don't just choose micro
services because you think it's going to
solve all your problems because it does
have some added complexity so some of
the advantages are that you can scale
your applications in individual pieces
you can deploy new versions of the micro
services very quickly but then it comes
from some with some disadvantages of
having
flexitarian how those services interact
and how they call each other the other
thing that's worth mentioning around
microservices is twelve faxes so twelve
factors is a methodology for building
software as a service applications it
was created by the developers at Heroku
and although I wouldn't say that you
have to follow all of these factors if
you want to build a successful micro
service it definitely is a good starting
point to get you thinking and having
your head in the right space so I've
listed them all there I'm not going to
go into detail today on all of them but
you can go to twelve factor net and read
about the different factors but if you
keep these in mind while you're building
micro services then you'll find that
your applications are better suited for
the cloud and better suited for the kind
of environments that you want micro
services for so what should we look for
in a micro service environment so this
is not just the twelve factors but a
little bit beyond as well so obviously
some micro service technologies you
might want to look at how are you going
to secure your application one of the
other considerations with micro services
is because of the communication aspect
you need to consider fault tolerance and
what are you going to do if one of your
services goes down another thing might
be looking at how you're going to do
load balancing or how you're going to
find the services in the first place so
there's some different technologies that
you're going to need to look out for
when you're trying to decide what you
might need from a micro service
environment the next two there come
straight from the twelve factors that's
fast start up and clean shutdown an
individual micro service should be
something that you can just throw away
and once you throw one away you should
be able to start it up again very
quickly so you'll hear people saying
that micro services should be stateless
you don't want to have to do some sort
of process where you store some data
that was in caching and having to kind
of think about that before the
application goes down if the application
goes down you should be able to just
start up a new one and carry on the
movement towards micro services has kind
of come alongside cloud native
applications and a movement
to the cloud so a small footprint is
useful here because you're paying for
the amount of space that you're using
often and that's where again with micro
services the scaling comes in because
you just want to scale up exactly what
you need and not have to pay for a lot
of space and things that you aren't
actually using externalising config is
something you want to do for
microservices it again comes from the
twelve factors basically means rather
than having your particular application
have all the detail config for that
particular environment you want to be
able to inject that config so that may
be through environment variables for
example and that way you can redeploy
your application in many different
environments and you've just changed the
config that gets injected into the
application you don't tightly cup all
the application with its config the aim
with micro services is to be able to
iterate faster and get more out of your
application and with this comes a need
to be able to make changes and push them
up and a need for developers to be able
to actually run what's in development to
be the same as what's in production
you'll find if your developers doing
something completely different from
what's in production then when you try
to deploy it to production you're going
to have a problem and that slows down
the amount of time between the developer
making the first code change and it
getting out to production and since one
of the reasons to move to mic receiver
sees is to speed up that cycle then
having development and production parity
is very important and then the last one
is containerization we're going to talk
a bit about the advantages of
containerization but it's something you
might want to consider if you're moving
to mic reservist --is
so it's quite clear I think I've heard
many people say that because there's a
perception that Java is too slow too
bloated and I think it's worth looking
back through the kind of history of Java
reeds don't understand how we got to
that perception but then also then I'll
follow on by looking at what some
vendors in the industry are doing to to
kind of move away from this this view
that Java is is a large bloated slow
environment so if we look back back in
1998 when first Java EE came out it was
a small number of specifications and a
small number of technologies and over
the years we've added more and more
specifications to get to the point where
we where we are today with Java EE 8 and
it was quite clear in the kind of 2009
timeframe that there was a need for
something smaller and so we started
creating profiles so for example the web
profile and then Evol platform for all
the technologies but I think what we've
seen is that you can create a profile so
web profile when I talk to customers and
we have we have in our DM offerings that
align with those profiles they say well
that's okay I like web profile but I
just want this capability or actually I
don't want all of web profile I just
want servlet or servlet and c-d-i and
things like that so customers are
wanting to kind of pick and choose the
capabilities that they use so profiles
help a little bit and I think actually
the main way in which profiles help is
they give you an understanding of what a
vendor provides so if a vendor says they
support web profile then that's great
you know that if you're going to that
vendor they've got all those
capabilities as a part of that
specification you don't necessarily have
to use them all there are some
environments that provide a number of
different profiles that go beyond the
kind of web profile and full platform
environments so they'll provide cut-down
examples I guess the most common example
is Tomcat which is just the kind of
basic web container capab
but then what's been happening over the
past few years and we did this in
Webster with Liberty five years ago is
some environments are actually giving
the you the ability to pick and choose
exactly which of the capabilities you
start you want to use so rather than
thinking of Java EE as a platform when
you have to take the whole thing and
it's potentially bloated and potentially
slow and so on you can start thinking
about Java EE as a set of capabilities a
set of API is and choose which API API
is you want to use to solve your
particular business problem
so with Open Liberty and Webster Liberty
we have this concept of features so as
you can see my pointer won't light it up
on the right-hand side this is just an
example of a server configuration that's
going to use jax-rs 2.1 and open api 3.0
so you might be in this example doing a
rest service and wanting to expose that
api out in the form of some document
that can then be used by some consumer
and then we let you you minify that
server down so it only consists of those
two those capabilities or any
capabilities of those capabilities
depend on so you get a nice constrained
package that just fits the fits the
purpose in wildfire wealth ice warm has
the it has this fractions concept works
slightly differently so it's based off a
maven dependency declaration so you
declare which of the wilds what wildfly
swarm fraction you tell I work for IBM
because I can't say wild fly swarm you
pick and choose your wild fly swarm
fractions based on dependencies and you
made an pom and then the build will
output an executable or runnable jar
that you can then run that includes
those capabilities so that's the kind of
e aspect and the way we've seen not
necessarily as a set of specifications
evolved but how vendors are providing
the KDE capabilities that makes it more
appropriate and more suitable to do
micro services well then beyond that
there was a kind of feeling that II was
not evolving as fast as we needed to in
order to address the requirements for
micro services and so a group of vendors
got together and formed micro probe
iÃ¶ and then sometime later that then
moved to eclipse so there's now the
Eclipse micro profile project and the
purpose of Eclipse micro profile is
really to evolve and incubate and an
experiment with a specifications for in
in the micro services space so the first
one
so micro profile 1 0 was was pretty
basic it just referenced three of the e
specification so it said you're going to
want to use jax-rs you're going to want
to use CDI for injection and you're
going to want to use JSONP to work with
Jason and then it created its study
creating its own own specifications the
first one was config which again relates
to what Kate's saying about 12 factor so
the config spec lets you externalize
configuration outside your application
so you can have this deployable unit you
build at the start and as you move
through your pipeline and tested in the
different environments you don't have to
rebuild that thing you just change the
configuration as it moves through the
pipeline fault-tolerance I won't go
through all of them but I'll pick out
some of my favorites so fault tolerance
when you start thinking about assembling
applications in terms of a set of
collaborating services or micro services
then you need to start dealing with
issues like the fact that there's a
network involved and the fact that
probably another team is responsible for
deploying something you that you depend
on that thing might go away
they might upgrade it might fall down on
it flat on its face or whatever so fault
tolerance does is define some API some
nice annotations that you define the
policies that you want to use in order
to deal with the potential and
availability or unreliability of
services that you depend on so it
standardizes I think it's like five
patterns you've got things like bulkhead
and circuit breaker that's a little
thank you and also the ability to define
a fallback service for example so if you
retry a service five times and you still
don't get a decent answer from it you
can go and then call a fallback alright
so what I'm going to do is just demo
God's permitting and do a quick
demo of the the kind of right sizing of
a server environment so I'm going to use
open Liberty open limit is an
open-source app server that we this
isn't my laptop so I'm gonna be pretty
slow can you all see that no come to the
front okay I'll talk through it so so we
what I've done is I've gone to open
Liberty dot IO and I've downloaded a zip
package of the server the zip packages
76 76 megabytes that includes full java
re' seven capabilities and micro profile
1.2 capabilities which is latest level
of micro profile and the install is just
an unzip onto disk so third time lucky
so we've just got this directory here
that's where the where the servers and
that and first thing this is the server
runtime but it's not actually a server
instance or any server configuration so
the first thing I'm going to do and I
need to find the backslash is create a
server ok so I've created a default
server and I can I can run that server
so I've got the backslash and so as we
well I don't think I mentioned there's a
lot of the vendors are focused very put
a lot of effort into having quick
startup of service so for example
website Liberty starts in in a few
seconds a lot of the other other app
servers do do so as well so that's the
browser I want isn't it
how you even got the URL ready for me
thank you oh we can see it's open
Liberty running I've got no apps
deployed that's just a kind of default
landing page and so that's running
running a few capabilities so what I'm
going to do is just go into the server
directory
and this is where the server
configuration lives and got to remember
editors we got we've got Visual Studio
code so if I just edit the server.xml
this is just the default server
configuration now is that going to pop
up in that one
you've got your fee on running how many
yeah okay so you can see the default
server configuration that we have in
this particular distribution is it's
going to put JSP in but let's say I just
want to do the servlets and we'll put
the version of 3.1 version of servlet
and I can save that and you can see on
the server side where it's running it
said okay I no longer need JSP 2.3 or
expression language 3 0 so now I've got
a server that's just running servlet it
just picked all that up but then I've
done my development I built myself an
application and I now want to package
that thing up into a distribution so I'm
gonna package the server up and I'm
gonna make it an executable or a
runnable jar so I need to specify and
I'm assuming that's a comma
okay so as I said at the start of the
demo at least the download package is 76
megabytes
I'm now going to package the server up
and we can see we now got a about 15 and
a half Meg server distribution that just
can just run servers and I can run that
thing now so
and I think just about every vendor
supports runnable jars nowadays but I've
got it later on we'll discuss whether
and runnable jars are the right thing or
not okay and if I go back to the browser
just refresh that page and yeah you can
see the server's running so that's just
an example and I'll kill that off now so
it doesn't cause us any problems Yeah
right back to the slides
well not nothing I've got focus on the
slides do I need to do not probably do
it from the beginning that went yeah
yeah so probably to do shift FM function
alien keyboard sorry okay
so we've seen the kind of alternative
approach to using java re' capabilities
now I want to move on on to docker as a
concept so who here is using docker okay
course you probably know more about it
than I do
who here is doing micro services but not
with docker okay I'd be interested to
know what you're using but maybe not
just now so we see a strong correlation
between micro services and docker and
containers so containers as a concept
are built on kind of two capabilities
one is this notion of isolation so that
you can or namespaces
so that you can avoid flashes of names
of certain things in an environment so
Linux has this concept of namespaces so
that you can avoid conflicts on file
system on processes on users and on
network and so on so that kind of helps
you avoid conflicting on those things
and then it has the concept of control
groups or see groups which let you then
partition up the resources of the system
so assigning a certain amount of CPU or
a certain amount of memory to a
particular container so the the control
groups helps avoid the concept of nosy
neighbor and if you've heard of that
before but know it knows it knows the
noisy neighbor so the name space thing
is the nosy neighbor because you can't
see your neighbors stuff the control
groups is the is noisy neighbor where
essentially if you've got a badly
behaved micro service or something
running on the same host
because you can constrain the resources
it can use it can't then to up the whole
system so in the java re' world I think
for many years customers have deployed
multiple applications to the same
application server instance it's over
the years it's become a much less common
pattern because of this noise in a noisy
neighbor problem because what would
happen is they deploy multiple
applications one application would maybe
have some bad behavior or require more
resources and you'd end up starving the
other applications of resources and
causing yourself problems and so let's
look at some of the qualities of docker
so what docker provides so docker has
this concept of a docker file the docker
file describes what your what when you
build an image what what you want that
image to consist of so in this
particular example we have already a
WebSphere Liberty image that's defined
and we want to add a wall file to it and
so that will then build another layer a
layer another layer on top that includes
that that war that you can then get an
image for and then you can then deploy
that as a container so docker gives you
this kind of consistent way of defining
that packaging it's also a way that's
independent of Java and the concept of
micro services is a kind of polyglot
concept you're not going to just
necessarily in your organization with
deploying Java you might be deploying
many other types of things so this gives
you a nice way of describing all of
those things in a consistent way
including things like the externals of
the things you're deploying such as what
ports do I need to make available that
kind of thing I've talked about the the
layers what are the nice things about
layers is as you reuse them and build
things on top those those layers can be
cached by the environment so that means
you've got less disk usage because it
just caches it and you end so there's
kind of one definition of it that you
then build upon unless i/o because
you're not moving because they're cached
each time you build a new image on top
you're not moving those things around
you've got a consistent API so docker
defines things like how you can do
logging and metrics and volumes and so
on and those things are consistent
across the different types of things
that you do you choose to put inside
your docker container and the final
thing is immutability so you can and
this again relates to 12 factor you can
make the thing immutable by essentially
putting effort into everything in it and
and not referring to things outside
which means that the contents are not
going to behave differently as you move
it through your pipeline because they're
not relying on things in the external
environment things outside the docker
container okay so we're going to see
another demo now and what I'm going to
do is create a project with the IBM
cloud developer tools CLI which is a
mouthful of a name but basically within
IBM we have several different ways for
you to generate a starter project so we
have a CLI you can go in through the IBM
cloud and there's also a websphere
liberty source specific page and they
all generate a similar application but
it just gives you a different entry
point so I'm going to generate something
then I'll show building and running with
maven and docker and then how you can
actually use the mayor and doctorate
environment to keep deploying your
application and Reis without restarting
the container because if you have to
restart your container every time you
want to see an update then that kind of
slows down your development time so it's
just a nice way to do development so I'm
gonna be running this in a VM because
I'm running Windows and I just find
docker behaves a little bit better if
I'm running Linux so that's why the demo
earlier was running a bit slow because
I've got this VM running in the
background so to create a project I
would run VX dev create so VX dev is the
CLI tool that I've installed and it
asking me here if I want to log in to
bluemix if I logged in to bluemix which
is our IBM cloud then i could get it to
provision actual services in the cloud
for me so things like Cloudant or any of
our Watson services but for now I'm
going to continue without log
and it just won't do any of that
provisioning pieces so then goes and
retrieves what starters so I can pick my
starting point and here I'm going to
choose that I want a micro service and
then I have some options of languages so
you can see at the top we have I don't
if that's big enough hopefully you guys
can see that
and but the four options are Java mica
profile Java EE node Python and then a
Java spring so I'm going to choose micro
profile Java EE because that's a topic
of this talk is and then I would name my
project and create it I can set that off
going because of the Wi-Fi may or may
not generate happily so I'm matching a
switch across to one that I created
earlier while that creates in the
background so I can have a look at the
code that I generated earlier and so
here it is so when you generate an
application you get a whole bunch of
content you get a pom file to build it
you get a docker file to run it docker
you also get some helm shots if you want
to run using helm and some bluemix
specific files if you want to create
tool chains and pipelines that deploy to
bluemix so you get a whole set of stuff
ready for you to go so to get started I
want might want to build my application
with envy uninstall so it's set up to
run Liberty in this case that's our Java
EE micro profile vendor of choice and it
will build the application then start up
the Liberty server and actually run
integration tests against the service
you can see there it's hitting a health
endpoint to make sure that the apps
running properly and then it finishes
building so then I need to build my
docker container so I've got a docker
file which is just here which we can
have a look at so you can see it's based
on a WebSphere Liberty image so
WebSphere Liberty has loads of images in
your hub that you can check out and then
we're just copying
the content from the server over into
the container so if I build that and tag
it with J one demo starts building up my
container and as Graham said it's using
caching so you can see there it's used
cached versions of the application
server so it's quite quick for it to
build cool so that's done so now I can
run my container so I could just run it
with a docker run and then it would
start up and I could access my
application and that would all be fine
but in this instance I'm gonna make some
changes to my applications so instead
what I'm going to do is run it with the
docker volume so I did a docker run I
need to specify port so I'm going to
specify 90-80 as the port and then I'll
specify volume that I want to mount I
think my volume is at J one demo and I
know I've got my server is in my target
directory so it's in target Oh Liberty
wlp okay actually prints the and WP user
servers and it's just called default
server that's the default server name
that it gets given and then I'm going to
map it into the config directory so the
config directory is set up for this
docker container so that you can if you
put your config there then the docker
image for Lib C will just pick up your
config and then I've specified the name
of my container
so that will start up the Liberty server
and you can see the logs coming out
there and it should pick up the
server.xml content that I have in the
target directory so if I show you my
target directory quickly in here you can
see that when I did the env and install
it put a Liberty here so I have a whole
local version of Liberty that installed
for me and then inside the user servers
default server directory then I've got
my config here which you'll see is
pretty similar to what Graham was
showing earlier and if you choose micro
services then you get the micro profile
1o feature which is the Liberty market
profile feature so my application is now
running and I should be able to access
it so if I go to this URL then this
should tell me whether my application is
running I get back a health endpoint at
the moment this is just Jason that's
returning but they aim would be that
once the micro profile health like
specification is available then we'll
switch to using that I've also got an
example endpoint so if I go to v1
example then it says some data has been
printed out so then if I go back I can
actually update my application so the
example is running here and it just says
some data so I can update this to say
hello from one and then I can save that
now you can actually set up Liberty
within vs code to automatically update
but for this demo because I wanted to
keep it a little bit vendor agnostic I'm
just going to show running maven and
some of the other vendors have options
where you can actually run maven tasks
that will then do this update for you
and we'll kind of run in the background
so you can see my app from earlier did
get created if I see one CD into this
one I'm gonna do an MDM package just
reproduce the package that I've just
changed so that's going to again compile
all of my classes and then copy it
across and we should see the server on
the left hand side view there it's
picked up some updates so it found that
there wasn't a functional update to the
server config but it's noticed that
there's been an update to the web
application and it's dated it there so
if I go back and do a refresh then you
can see my new message so when you're
then pushing this through the pipeline
you might want to not use a volume and
stick with your docker file that is your
one immutable object that you pass
through the pipeline but for developing
locally it's nice to be able to not have
to shut down your docker containers
no I didn't rebuild the docker image now
so so all I've done here is I've mounted
a volume into the docker container so
rather than it using the copy the copy
of my config that got copied in by the
docker file it's actually using the
location that I mounted so when I did
the MDM package it would have been
updated in there and actually if I'd
have used their built-in support in that
we have in vs code for liberty or we
have tools in Eclipse as well then I
could have actually set up so that I
could just change the class save it and
it would have automatically updated for
me yes so it's my container is picking
up when I did the MV and install I got
an updated application in this folder
down here in my drop ins folder and
that's what it's picking up so I mounted
this whole directory the soda pop
default server directory here that's
what I'm out it so that's what happened
when I did
and package your copied in there and
then the update happened well so I think
that's all I wanted to demo from that
point of view I'm gonna stop the docker
container because that will slow things
down
and that leads onto the next so so this
is the demo that I just did will if we
haven't like answered your question at
the end then ask it again but hopefully
this should answer people think you're a
plantain we're just going to ask that
just to the right time
okay so packaging so when you're
considering the packaging for your micro
services there are a number of
characteristics that you might want to
kind of ask yourselves what do I want to
achieve from my packaging do I want it
to be externally configurable because I
want to kind of follow the twelve factor
practices do I want it to be immutable
again relating to twelve factors so I
can be confident that the thing that I
built at the start and run my unit tests
against is the same thing that I'm going
to test maybe in my staging environment
maintainable we all want maintainability
don't we and the choices that you make
in terms of packaging may may be it may
affect the main factor maintainability
of your your micro-service consistent so
do you want consistency may be across
microservices so you deploy many many
micro services consistency can help in
terms of people wanting to move move
teams and work on different micro
services and so on maximizing reuse and
sharing again the approach you take can
help maximize reuse and sharing do you
want separation between what you build
as a team or as a squad in terms of the
application code and what you're reusing
which might be a vendor's java
environment or it might be some open
source frameworks that you're adding
into the environment having that kind of
separation can be important and then one
of the kind of quite often the elephant
in the room is the organizational fit I
work with a lot of big customers who
have separate dev teams separate op
teams and hands up if that's that's the
environment you work in yeah yeah so the
opportunist and a PI server that's what
they've done for years they own that
they're responsible for that and that's
great and the dev team of historically
thrown a war file over the wall with
some configuration or whatever and said
do that for me and now the dev team is
going I'm doing micro-services I'm going
to give you an Apple jar and they go
what do I do with that so that's an
important consideration because
organizational change is quite quite
often a lot harder than technological
change okay so we talked about
yup servers and how the ability to
customize your runtime environments
we've talked we've seen examples of
runnable jars and we talked about
containers so what's the best choice
what's the best fit and it can kind of
depend so if you're using docker and
particularly if you're a polyglot
environment we're deploying multiple
things then then you're going to want to
use docker as your packing Packaging
mechanism and the thing is once you're
doing docker then you probably want to
benefit from all the docker capabilities
so what we talked about in terms of the
layers and the images and the the
caching and so on so think about
structuring them I can see it think
about structuring your environment in
terms of the kind of based operating
system putting Java down putting your
server down and then there might be
frameworks and libraries that are they
reusing open in open source or maybe
you're a developed in-house and you
might want to put those in as a in as a
layer because putting them in there
makes them explicit you know which of
your docker containers are then using
those things and if you've got a
security vulnerability or you need to
upgrade something you think you can see
quite easily what your dependencies are
and where you need to maybe do a
redeploy or rebuild and redeploy of a
particular micro service and then
finally add your application thing in so
as you go down that stack hopefully the
things very less often the things at the
top of the things are going to change
the most which is your application code
and if you're doing runnable jars then
and you get I think less flexibility and
also it doesn't work particularly work
very well for a polyglot environment
however if even if you're using docker
as I mentioned about the organizational
aspect of it you might not be the person
that creates the docker image that might
be our ops team in which case war again
is probably the best thing for you as a
development team to create as a package
and then you give it to the ops team and
then there you go and do the docker
things things with that rather than
giving them an executable jar which
they've then got to go and look inside
and try and find your war file and pull
it out and go and put it inside the
docker container okay so the last thing
we want to talk about here to say is the
open API specification so those of you
who aren't aware it's a simple standard
API description format version 2 was
released back in October 2014 and back
then it was the from swagger and then
now version 3 is the open API
specification so the swagger kind of
specification was well
swag was donated as part of the open API
specification and there are some
different implementations so I've
mentioned swagger there and often people
use swagger and open API as
interchangeable words and you can find a
lot of vendors actually support this as
part of their application server say for
example with Liberty we have a feature
that's that provides it and again with
wild fly swarm they have a fraction that
provides it why is this useful for micro
services well for micro services
communication between the services is
really a key aspect that you need to get
right because you're suddenly in a
distributed system you need to have good
communication between those different
parts and along with micro services
often comes an organizational change
where you have different teams that own
the different micro services from sort
of writing the code all the way up to
deploying and support and that means
that you need a well documented API
between the different micro services so
the open API specification comes in very
well here and it can be used in testing
specifically to make sure that both the
producer and consumer of a particular
API is keeping too
the specification that you have chosen
and there are a set of different tools
that you can use one such tool is
something called pact where you can
define tests that can be run by the
people producing the API to make sure
that they haven't regressed anything or
changed anything that would break their
consumers another thing to think about
it's micro-services driven by desire for
short life cycles so rather than having
one big application that started being
written a long time ago and you just
keep adding pieces on the edge you're
likely to be writing new applications
much more frequently and with that it's
useful to be able to have some
auto-generated code so I already
demonstrated today how we generate an
application but actually being able to
generate based off a API dess
specification is very useful and that's
where open API documentation can be used
it's also polyglot and a multi-vendor
environment so you can use open API even
if you're micro services made up of
services that are all in different
languages so for myself when I've been
working with my colleagues who have
microsomes that need to interact with
mine even if there's a written in say
JavaScript or Python or whatever we can
all have this one view of how they
should interact so I mentioned code
generation there's a lot of open source
tools available if you go look on maven
for example there's a whole set that you
can use and some of the vendors actually
supply like built-in support for you to
generate code based on specifications or
generate the actual document to show the
specification of your API based on the
code so you can go both ways so in the
IBM cloud we have an option for you to
generate an application given the
document and we also provide this from
the Liberty app accelerator which I
mentioned earlier so you can see the
swagger button there in the corner and
the wildfly swarm project generator
which is sort of their equivalent to the
app accelerator also provides this
option and so here's a quick sort of
diagram in case you're not aware of what
it might look like if you were going to
use this technology so you can have your
actual endpoint specified in similar way
that you would with just Chuck's or s
and then you can add extra sort of user
information as well with swagger and the
nice thing is it produced s-- it
produces this UI so I've used this a lot
when doing development because you can
it's a nice way to visualize the API and
get a real understanding for what the
team want out of the API and how you
might interact with it and so for
example with Liberty if you use their
API discovery feature then you'll get
this you are as part of that so in
conclusion we think you should consider
the individual capabilities of Java EE
it isn't something that you have to take
as one big lump you can choose the
different pieces that you want and make
it the right fit for you you should
choose your runtime to fit the
particular capabilities that you require
and different vendors provide different
options for how you can do this with
docker as the packaging model jar files
maybe isn't something that is useful and
actually you can just stick with a wor
phone but again it depends exactly what
you're doing but having talked or
something's in your environment will
definitely be useful for micro services
and then of course the Mike profile
community adds programming model
essentials and removes boilerplate that
you would otherwise have had to read to
write so it provides annotations and
things to get your micro service written
more quickly and sort of the code more
clean finally we've got the swagger or
open API specification which you can
make use of as part of Java EE the
different vendors support it and then it
can be used even if you're we've got a
polyglot environment so we've got a few
resources here if you want to go read
more about micro services and there's a
red book which I actually co-wrote with
some colleagues of mine and that kind of
gives a general overview for Java but
it's got some Java EE specifics in it as
well whereas dev dotnet is the WebSphere
Liberty developer site so all the
developers myself and Gro included that
work on Liberty have written articles up
there and documents about micro services
and then you can also go to micro
service builder which is the sort of
Liberty and IBM cloud private version of
the bxf tools that I showed you and then
of course we've got links to open
Liberty
which we've recently announced and Reiko
profile ire and if you want some reading
then we've got some resources for you to
check out as well so I think that's
about all we have time for thank you
very much for coming and we welcome any
questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>