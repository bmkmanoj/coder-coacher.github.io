<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Parallel Streams, CompletableFuture, and All That: Concurrency in Java 8 | Coder Coacher - Coaching Coders</title><meta content="Parallel Streams, CompletableFuture, and All That: Concurrency in Java 8 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Parallel Streams, CompletableFuture, and All That: Concurrency in Java 8</b></h2><h5 class="post__date">2017-10-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/x5akmCWgGY0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay let me at least let me get started
anyway and if they have to make
adjustments they'll make adjustments the
title of this is parallel streams
completable futures and all that the
idea is to look at the concurrence
mechanisms and parallel mechanisms
inside of Java
now I specifically was referring to Java
eight of course everything carries over
right to Java nine they've added a few
methods to the API in Java nine but
basically it's the same exact stuff so
anything I'm going to talk about now is
applicable to both a 10-9 in fact I have
run this code the code I'm going to show
you is works under both Java eight and
Java nine and I'll give you the
information for that now my name is Ken
cousin by the way it's cousin like the
relative even though it doesn't look
like it we think it's a Ellis Island job
or something my company's cousin IT I
call it cousin I T my wife refers to it
as cousin it like the Adams family it
was her idea
what can you do any rate there's my
email address website blog and Twitter
handle feel free to contact me whenever
my delete key works as well as anybody's
right any rate a few years ago I wrote a
book called making job a groovy that's a
Java groovy integration book published
through Manning last year I wrote a book
called Gradle recipes for Android just
to undercut sales entirely if you were
to go to Gradle dot org and register you
can get that book for free if you want
so shows my negotiating capabilities I
negotiated a royalty on a book that I
knew they were going to give away so you
don't want me negotiating your next
contract this is the book that I have
out now
modern Java recipes and everything I'm
going to talk to you about pretty much
is in this book we are actually having a
book signing at O'Reilly in the
exhibitor I think they're one one floor
down over by the wall tomorrow at
afternoon at two o'clock if you're
interested now the reason I bring it up
is partly because my editor be really
annoyed if I didn't but also because
these are the URLs for the github
repositories for the code I'm going to
show you the entire book repository is
under github calm
my last name and then the name is Java
underscore 8 underscore recipes now I
have several small examples I'm going to
show you out of there
but then I needed a larger example to
show how the completable future stuff is
put together I threw in a parallel
stream as well that one is under a
separate repo called CF box scores I'm
going to download box score data from
Major League Baseball online so I'm I'm
probably asking a lot out of our Wi-Fi
but hey you know if you don't you don't
try you know let's see what happens
right if it was easy anybody can do it
so at any rate I have two github repos
involved and you're welcome to take
anything you like out of there for the
book I also have a repo called Java
underscore 9 underscore recipes for the
handful of Java 9 ones as well but I'm
not using that for this talk if you have
a safari account I have a whole bunch of
video courses at Safari Books online I
also teach training classes there and of
course all the books are available there
as well but that's more self marketing
than I could stomach so let's move on
now yeah let's get this out of the way
because anytime you talk about
concurrency and parallelism somebody
gets annoyed and they get very precise
about it I'm defining it this way this
is how I understand it currency is
something you design for you're talking
about having multiple things that can
run at the same time that can go
concurrently as they say but that
doesn't mean they are running
concurrently it just means we try to
design them with that in mind
whereas parallelism is when we actually
are running two things at the same time
so in principle you have to have
multiple cores to do parallelism
although I would argue if you do
multiple threads it's effectively
parallel as well but that's the gray
area that's where a lot of debates will
happen I'm going to try to use those
words with that in mind those are the
definitions you tend to see online so I
thought I'd bring them here so alright
there's the definitions now I want to
bring up something that you may be aware
of a rich Hickey the creator of the
closure programming language closure
with a.j basically Lisp on the JVM gave
a keynote presentation several years ago
at the conference called strange loops
some of you may know it and st. Louis
it's called simple made easy now it's a
fascinating keynote but it's you
from my point of view for one reason the
concept was as some things are
inherently simple meaning conceptually
simple and even simple and execution you
know exactly what to do step by step
whereas the concept of easy is that hey
it's a method call in a library and
there could be a ton of complexity under
the hood but it was easy to do with the
parallel streams in Java eight they have
made it very easy to experiment with
parallelism but that doesn't mean that
getting excellent performance out of
concurrent parallel applications is
simple see it's it can be very complex
and I'll talk about what the general
generally accepted requirements are for
this to be beneficial for this to work
out but I don't want to pretend that
even though they've added a lot of
classes to make it easy to experiment
it's still not a simple phenomenon going
to parallel stuff here I want to combine
that notion by the way that's one of my
favorite demonstrations or illustrations
of the word easy is that I remember
there was a script presented for Star
Trek The Next Generation having an
anniversary this year and they the
writer had written out this elaborate
set of instructions for Captain Picard
to tell him how to go into orbit around
a planet and he crossed it all out and
when standard orbit ensign and that was
it so that's easy without necessarily
being simple and that's the kind of idea
I'm looking for now I also want to
mention a comment from Brian gets I'm
sure you're familiar with Brian gets if
he's in this room please don't tell me
I'll be far too intimidated to complete
this talk ok Brian gets is the author of
Java concurrency in practice he also has
was one of the chief architects for java
at son and now oracle you know one of
the real Giants in the in the industry
when he talks about concurrency actually
when he talks about anything I listen I
don't generally understand but I do
listen he has said many times that
parallelism is strictly an optimization
this is coming most recently out of one
of a series of articles he wrote on Java
streams at developerworks the IBM site
developerworks
put in a link there to our article four
out of a series of five that's the one
where he talks about parallel streams
you're welcome to all of this of course
the presentations been uploaded but if
you need it before that just contact me
I'll be happy to send it to you any rate
so the idea with all the parallelism and
concurrency mechanisms in Java is to get
your code working sequentially first
work with a sequential stream and then
once that's working then you can
experiment with parallelism and have
some confidence that you can draw some
conclusions and get some benefits out of
it all right
that's all the waivers let's go on these
are all the factory methods if you will
the mechanisms that we use in Java to
create streams there's the stream method
that's a default method that's been
added to collection there is the of
method the factory method that's used in
many classes in Java eight to produce an
object
there's the iterate method that takes a
seed and then a unary operator and
provides successive values by applying
the unary operator over and over again
to the existing values and then there's
the generate method that takes a
supplier it just invokes the supplier
over and over again
retrieving results as we go all of those
by default produce sequential streams so
whenever you if you don't let's put it
this way if you don't specifically say
parallel it's sequential that's the idea
now there are a couple ways to make a
parallel stream one is that collection
also has a parallel stream method so
that we have that option as well and
oftentimes what I'll do is I'll create
an app with a stream in it and then just
change it to parallel stream to see if
that improves anything or what I have to
tweak in order to get benefit out of
that there's also a method called
parallel in-stream now technically
that's in base stream the parent
interface for stream there's also a
method called sequential as well and the
Java Doc's are very vague about it but
the idea is that parallel will return a
parallel stream or the existing stream
if it's already parallel and sequential
will do the same for sequential ones
these are both intermediate operations
on stream meaning they produce a new
stream from what we're dealing with
and then it we don't get any values
until we put a terminal expression on
there as we do with stream processing
normally if you want to find out if a
stream is sequential or parallel then
there's a method called is parallel that
returns a boolean nice and simple easy
to find out whether you're dealing with
a sequential one or a parallel one but
in general unless it says parallel it's
sequential now one of the things that is
not obvious from the API which is very
important to know is that you can't do
part of a pipeline sequentially and then
part in parallel now we'll talk about
which things you want to do sequentially
which things you want to do parallel in
a minute but the point is is that you
cannot just simply change from
sequential to parallel and back and have
that change in the middle of a pipeline
now if you know how stream processing
works this is not a surprise but just as
a quick illustration I have a class in
my repo called sequential two parallel
tests and if I go to IntelliJ here and I
went to the yes this is the one I want
and I'm clearly gonna have to make the
font bigger but let me open this first
so here is sequential two parallel tests
and let me mom improve the font size
because we changed everything here so
it'll only take me a moment let me make
it I don't know 35 or 36 how about that
is that readable you see that in the
back and great it didn't do it but
hopefully it will
alright I'll just do that and then I'll
fix it later ok so the idea here is they
just have a series of test cases just to
illustrate the mechanism so here I say
if I use the of method on a stream I'm
asserting that when I call dot is
parallel that will be false
same thing on iterate is parallel as
false generate with math colon colon
random there's my supplier specifically
a double supplier that also is not
parallel here if I created a list of
elements and then call the stream method
again that's not parallel but of course
obviously if I call parallel first it
will be so I change that to true and
then down here if I call parallel stream
of course it's true so that's all well
and good that's not surprising where
things get interesting is if you try to
do parallel and then sequential
consecutively or even if you put values
in between like here I'm saying let's go
to parallel because all I want to do is
double the elements and that's an
independent associative operation that
would be fine for parallel I can even
look at the values as they go by and
then I want to do sorting and sorting I
want to do sequentially because that's a
stateful operation and it already has
its own parallel type of mechanism
concurrent mechanism built into it I
mean it's not a true parallel sort but
it's just an existing sort so this is a
sort of thing you're tempted to do well
it turns out that parallel and
sequential are basically setting or
unsetting a flag and since nothing
happens till I hit the terminal
expression here the collect what you
would find is that once I hit the
terminal expression it will say well we
started parallel we switch to sequential
the entire stream will be treated as a
sequential stream ok so you can't turn
it on for part and then turn it off
you'd basically have to do it as two
separate streams there's no easy way
around that okay so also if you're going
to return a stream and then call
something you know try to put them in
separate methods again since nothing
happens until you get the terminal
expression that's not going to help
either you might as well do the parallel
part return a collection with of doubles
if you will and then do the sequential
part with the sort and that's about the
closest you can come to that so I can
just
for the sake of argument I can execute
this entire class and you see all the
tests pass and therefore all those
asserts about sequential and parallel
are true and not a big surprise so again
that's something you need to be aware of
however if you're not aware of that that
can bite you okay now when is parallel
worth doing here are the basic
requirements first of all I mentioned
the operations have to be independent
and associative they do not have to be
commutative because it's not going to
try to switch the order a times B versus
B times a it's not going to do that what
parallelism is all about or concurrency
is all about is grouping so instead of
processing a hundred elements
sequentially we're going to divide them
into groups of twenty-five and process
them in individual groups so it's all
about the associative nature of the
operation not the commutative nature so
as long as the operation doesn't mind
how you group them that's a candidate
for parallelism also we want it to be
stateless if we can I'm saying that by
saying independent so that the each
element doesn't depend on surrounding
elements or any other element like that
doubling operation is clearly
independent and clearly associative so
that's a minimum requirement to even
bother with parallel if you're doing
something stateful or that has
additional dependencies it's not going
to get you any benefit here now another
requirement is this thing you will see
expressed on various websites as n times
Q greater than 10,000 where n is
basically the number of data elements
and Q is the amount of time spent
processing each element now the problem
with that measurement n times Q greater
than 10,000 is they never put a unit on
Q so I don't I mean how do you measure
so let's just say it this way the
product of n times Q must be above some
threshold you are introducing overhead
by going to parallel you are basically
by default as we're going to see
introducing a fork joint pool splitting
up the work and individual sections and
then joining them back together again
once they're done and that introduces
overhead and so therefore you either
need enough data to make that overhead
worth it
or there needs to be enough time per
element that that overhead
worth it and things like multiplying or
adding numbers together believe it or
not is rarely worth it the basic Java
processor is incredibly fast at
processing primitives and I'll come back
to that as an illustration I mean if I'm
simply adding up numbers I've done many
test cases with say 10 million numbers
and that's nowhere near enough to make
it worth it to go to parallel sequential
is so fast on that it's hardly worth
going parallel and I'll give you some
better guidance about that as we go now
another requirement that people don't
talk about that often is that the data
also needs to be easy to partition
remember that when we go to parallel
streams in Java
we are using this fork/join pool under
the hood we are simply dividing up the
work into equal sized sections and doing
the processing on each section and then
merging them well if the if the machine
can't figure out where the begin and
where the end is then it's not so easy
to divide them up so if you're doing say
an int stream with a range well that's
easy it knows where the start is it
knows where the end is range or range
closed but if you do a stream dot
iterate with a limit that's asking too
much it doesn't necessarily know how now
of course from a mechanical point of
view if you're dealing with an array as
the source of your data great nice
consecutive memory locations that's a
dream scenario for this whereas if
you're dealing with a linked list well
good luck ok so the idea is that the
datum should come from a situation that
is easy to partition if and if you have
that then it's worth it you can expect
to get a significant gain out of
parallel parallelization now in order to
show a demo I'm going to show a simple
demo that is going to just run a main
method and illustrate this but of course
all demonstrations like that should be
viewed with some suspicion because
you've got this hot start of the JVM you
don't know what else is going on in the
system etc there is a project that comes
from the open JDK project called the
Java micro benchmark harness many of you
may have heard of it it is a it is a
Java project that is based on
annotations and it allows you
to run a method as many times as you
specify it does a series of warm-up
iterations it'll create a forked JVM
just to execute you can do all kinds of
optimizations in that and this is an
excellent way of I don't say monitor
measuring basically the performance of
individual methods on that so I put in a
link to the the jmh project the project
is not real well documented but they do
have lots of samples and that's helpful
now I'm running it two different ways
one is that Gradle I'd use a Gradle
build tool for everything I do
Gradle has a nice jmh plug-in and that
works fine that's what I have in the
repository if you were to take a look at
the codebase alternatively IntelliJ IDEA
also has a jmh plug-in that lets you
just run as and run as a method and it
will do the benchmarking right there so
I do recommend this is a nice tool to
give you data that you can actually have
some faith in you know that might
actually be something you could
reproduce now to show this again I want
to mention when you do parallel streams
you are by default delegating to a fork
join pool now fork join pool was a class
added in Java 1.7 it is an executor
service so if you're used to using
executor service or executor snoo cached
pool or fixed size pool or whatever this
is just another one but this is the one
they use by default it does the now the
common pool which is a method inside
fork/join pool a static method call
common pool returns the common pool for
the JVM now this has mixed reputation
because people go well if other things
are going on in the system I'm using the
same pool and that's bad yeah you could
argue it but it is a highly optimized
pool that also does what they call
work-stealing meaning that if if extra
jobs have been submitted and one thread
happens to be idle it'll go and grab the
work okay so it really does have
excellent performance I would say try it
and if it doesn't give you the
performance you want then most of the
methods in completable future that I'm
going to show allow you to specify
an executor service or more properly a
cool also if you want to and I have an
illustration of that as well now when
you make a fork joint pool technically
the default pool size of that is equal
to this calculation runtime get runtime
dot available processors actually I
think I meant a plus one there rather
than a minus one and I'll fix that
but here's the thing I on my laptop here
which I suppose these days I should call
a private cloud server right yeah it's
just a laptop any rate this laptop is
about four years old I'm waiting for the
for them I still want them to release a
better Mac I'm really hoping you know
but at any rate I have a course on this
machine so when I create this common
pool and get the pool size this
calculation of runtime dot get runtime
dot available processors returns seven
but then you add one because the pool
size may be seven but main is still
operating as well so I just think of it
as the work being distributed among all
eight cores and that's really how it
does work in practice now I'll show you
in a bit how you could change the number
of threads if you want okay but first
I'd like to demonstrate this so I have a
class called parallel demo let me go
back here and I'll open that one up so
what I'm doing here is I have this
method that's going to double a number
this is a function obviously and the
reason I put it in a separate method is
so I could manually introduce asleep
inside it and I'm also going to do what
I normally do whenever I'm trying to do
anything with parallelization which is I
like to put in a print of the current
threads name so that I know which thread
is operating to make sure I am using up
all the threads and things are working
now the main method here started off
with a very small array list that has
six elements and what I'm going to do
let me skip this down here I'm going to
make actually I'll make this in stream
right here and I'll start off with it
sequentially let me turn off the
parallel part and I'll just map it to
double it so that's going to double each
number but it's going to
introduce the the sleep as well now if I
cut this down to only six elements right
now then I have enough cores for each
core to get an element okay so my n is
very small but I've got enough
processors to handle them all
individually that's why I had to
introduce a delay otherwise I wouldn't
see any change at all from going to
parallel so I'm going to double them all
and then sum them I actually don't care
about the Sun but I need a terminal
operation in order to make the stream
actually work and here I'm going to use
instant dot now in between in other
words I'm just going to print out the
amount of time this took okay so now if
I do this sequentially I've got six
numbers I introduced a hundred
millisecond delay well by golly that
ought to take about six seconds and if I
look at the output here it was a little
over 600 milliseconds I introduced a
hundred millisecond delay on each so it
took a little over 600 milliseconds
which is what I expect and then if I
turn in turn the parallel back on and
run it again you see first of all in the
pools here there are the workers 1
through 5 plus main see so I still count
that and main will be reused and this
took just over a hundred milliseconds
now this is the dream scenario for
parallelization ok if you're if you live
a good life and everything works out
this is what you'll get you know that's
not going to happen very often but it
can be very beneficial this is the one
you show your manager you know in order
to get them to let you go ahead and work
on this you know so now but the thing is
is I just did what I said not to do
right I rent something in a main method
just to demonstrate this was working
well with that in mind I also have this
doubling demo in a jmh package and here
you can see this is using annotations
that come from jmh I'm looking for the
average times I want the time unit to be
milliseconds everything is scoped to a
single thread each calculation I'm doing
to fork JVMs I tried to set the memory
to be as big as I could afford so that
memory was not an issue in this
calculation and then there's my same
double it but this
time I put in the two methods here one
with sequential one with parallel and I
added the benchmark annotation on top of
them now I could run it but it would
take a while to run now because it would
do 20 warm-up iterations and then 20
actual iterations which it would average
and it would do this twice for each of
them so I would have all of those runs
and with my delays that would take a
while so instead what I've done is I've
copied the results and just put them
here so here is the sequential one and
what you could see is the average over
the 40 was just over 600 milliseconds
per operation and with parallel it was
just over a hundred milliseconds per
operation and those values I believe
okay so it's a very nice tool and it
does give you confidence in in the
calculations that you're doing so that's
really all you need to know to get
started with the parallel stream stuff
and I wanted to give you that background
now one other thing that people always
ask is how do you change the number of
threads okay there is and this is listed
in the Java Docs themselves if you go
into the Java Doc's for fork/join pool
there is a setting called Believe It or
Not Java dot util dot concurrent dot
fork/join pool command dot parallelism
that mouthful and you can set that in
your on the command line with a dash
capital D flag or you can just do system
dot set property and pick another number
and I've actually done a calculation
like that as well this one called common
pool size just to show you what I mean
so here this one I just tried making a
range from one to three million and some
of them in parallel and then I could
print out the pool size and then I could
say oh I could make a manual one
whatever size I want and then I could
use the regular old submit method which
is going to return on a fork joint task
which means eventually I'll have to call
get and that throws all these exceptions
we'll get to that in a minute but this
is the base without changing the
defaults all I would have to do is
change the system dot get property and
set this value and I could run it in
parallel as well now if you change the
size
of the pool too much bigger than the
number of processors on your disk you're
not likely to see a whole lot of
improvement okay again the common pool
is choosing processors based or the
thread pool based on the number of
processors you have that's a pretty good
guess you know but you do have the
mechanism should you wish to do it
it is available and certainly worth
experimenting with if you like okay so
enough with that one
now what was added in Java 8 was was
completed but that's based on future the
future interface was added in Java 1.5
ok this has been in there since the
addition of the Java dot util dot
concurrent package and the thing about
the future interface is that when you
return a future using the submit method
takes a callable on an executor service
then the method returns immediately and
then you could go about doing other
calculations the problem with future
well one issue with future is that in
order to get the value out of the future
you have to call get and get as a
blocking call so eventually you got a
call get and hope that you're done or
that you're ready to wait for it to be
finished now that's ok but that's the
fact of life where life becomes
difficult is that if I want to have
multiple futures if I want to say first
do this then do that then do the other
now I got a problem because now I'm in
what they call call back hell or I've
got some other way where I have to wait
for everything to beacon finished and
now I feel like I'm back to blocking
again this is where completable future
comes in completable future makes it
very easy to coordinate multiple tasks
so that it waits for one to be finished
before the next execute and so on so one
way people have tried in the past to
coordinate regular old futures is that
the future has a method called is done
and you could do this thing called busy
waiting put in a while loop that just
keeps asking are you done are you done
are we there yet are we there yet are we
there yet and it's exactly that annoying
ok and the problem is is that that can
generate literally billions of calls you
know especially given how fast
processors are right now
so while this works and I have a demo of
it I don't necessarily recommend it okay
this is really a pain and this again is
partly why the the completable future
was created and I'm going to jump to
that now so completable future is a
class that's all about coordination it
implements two interfaces future and
completion stage and that means there's
a lot of methods involved and I want to
show you the basic idea the first thing
is though is how do you complete a
completable future if I don't want to
call get which or which I could if I
just want to complete it there are three
built-in ways there's complete which
takes a value completed future or even
complete exceptionally now before I go
to the code here let me give you an idea
how they're used together so here's the
idea say I have some cash a map of
integer to product I use the concurrent
hash map here so a cache of integer to
product and now I have a method called
get local which is going to take the ID
here and pull out the value from the
cache but I also have this legacy code
that came from somewhere else that has a
get remote method takes an ID I'm
introducing my simulation of a network
delay if you will or the legacy delay
then I also have the situation where it
could throw an exception if something
went wrong I needed it to be predictable
so I could you liked my choice of ID
there yes no I'm not going to make any
jokes moving on so I wanted something
predictable so I could write a test case
for it so I picked an ID and down here
I'm ultimately going to return the value
now this is being done sequentially
actually let's see how these are used so
if I have the get local and the get
remote and these are private methods
then the public method is called get
product with an ID now in normal Java
code that was not concurrent you'd write
get I get product with an ID you'd
return a product in this case I want to
return a completable future of the
product so this will return immediately
so you try the local one and when you
call get on a map and there's it's not
in there you get back a null so I'll say
look if it's not null if it worked
then I use completed future and say yep
there's my product
the futures done we're ready to go if it
fails if it's not in the cache basically
now I have to use my legacy system so
I'll make a completable future here I'll
call get remote returns a product
eventually put it in the cache and this
time I call complete on the already
instantiated completable future and
return that finally if something goes
horribly wrong in all of this I catch an
exception make a completable future and
call complete exceptionally which wraps
the exception itself so that I can check
the exception that comes out and I could
check its source and find out what
happened with it and all of that works
as well so that's why you have all three
different methods this is a nice
illustration of that working given our
time restrictions I'm going to just say
that take my word for it that this works
and I'm gonna go on to another example
okay now what about running
asynchronously because all of that was
synchronous except for the fact that the
product the method returned right away
okay well completable future implements
both future that's why you have a get
method and the others join etc it also
implements completion stage which has
about 38 methods in it I went and and
counted which means completable future
as over 50 and it looks pretty
overwhelming fortunately there are
patterns we could follow the patterns
look like this the methods that have the
word apply in them like apply apply well
we'll see it apply take as an argument a
function because the mnemonic is
remember if you looked at the function
interface inside as an apply method okay
so this connects a function apply two
function methods that have the word
accept on them take a consumer again
inside the consumer interface your
single abstract method is accept so it's
trying to make it easier to remember
that the run methods take a runnable
that's easy the supply methods take a
supplier so when you see these method
names you can just identify from those
categories right away which of these
they fit in
now there's methods like then and this
is how you wind up chaining them
together so see there's the apply so
apply takes a function I'm going to take
each element and I'm going to square it
say this example by the way is right out
of the Java Docs I didn't even run this
this is right out of the Java Docs and
then except takes a consumer at which
point I'm going to print it see I just
use a method reference but so be it and
then run and this takes a runnable which
is for who knows why printing a carriage
return okay but that's the idea by using
these then methods then each method will
wait for the future to be done before
going to the next one automatically now
they can run asynchronously but it's
sort of like joining on threads one is
waiting for the completion of the
previous before it moves on each way and
by chaining together methods like this
you can accomplish much more complex
tasks so you saw then there's also some
patterns in the method names like either
which says either this one or that one
whichever finishes first there's both
waiting for both there's combined which
says wait for this one and then provide
a by function that's going to take the
result of the first one and a
completable future and put them together
so it's going to wind up allowing you to
combine results and again I'll show you
an example so the other pattern that
comes is that in many of the methods
they end with the word async and then
there's overloads that don't the ones
that don't operate in the same thread as
the caller so back here
none of these say async on them this is
delegating to a thread in the pork joint
pool but all three of these methods are
running in the same thread altogether
whereas if I used then except a sink or
then run async then it would take the
job and resubmit it to the fork joint
pool to go for the next one this can be
very useful but again it introduces
overhead so it's something you kind of
have to experiment with it may not
necessarily help depending on all those
other factors we talked about but the
key is to know which one is which that
the ones with async do operate in a
separate thread potentially because it's
resubmitting to the pool and the ones
without it don't so let's look at some
of this stuff again complete all finally
there's one other category of methods in
there these are overloads
all the pretty much all the methods to
submit jobs take an extra argument of
type executor and that would say if I
don't want to use the common fork/join
pool then I provide my own executor from
the executor service okay so if you want
to just use the common fork/join pool
you use the overload without that
otherwise you use it with it and I have
a whole set of test cases here on
completable future tests for example
that will show for example here you
could see I've made a fix thread pool
and I did supply a sink see that's going
to take a supplier but it's going to
submit separately to the pool and I
provided the third argument with or the
second argument with the pool itself but
then apply then apply then except that's
all going to run in the same thread as
the one I used in the pool that's the
sort of idea of what you can do all
right now if I go back to that get
product one the one that I showed before
I had everything in the remote lookup
happening sequentially legacy system it
would be easy enough to replace that
part with supply async so I turn this
into a supplier where I call get remote
put and everything that's all done as
part of a completable future operating
asynchronously and when that's done then
the rest will happen so that's a very
simple change that could be made to
hopefully improve the performance of
this system in general okay now we still
have a get method we still have a join
method it's interesting this some of the
decisions made at the beginning of Java
that we're still paying for one of which
is checked exceptions right we still
have to deal with those and if you write
a lot of streaming code you deal with
that all the time
well the get method declares that it can
throw both execution exception and
interrupted exception and those require
those are checked exceptions they
require a try-catch block or throws
clause or something there's also a join
method that does the same exact thing
and the only thing it throws is a
completion exception which is unchecked
so if you want to put in the try catch
block you can put in get and if you
don't you put in join and it's basically
the same thing now of course if you
don't catch the exception down you go
you know
fine but if you want to manage it you
call get otherwise you call join but
just like in future those methods block
to wait until things are done on the
other hand this is another one that
people don't tend to see very often you
can wait for the pool to become quote
quiescent there's a word for you
there is a method on fork/join pool so
here I'm getting the common pool called
a wait quiescence and it takes a time
unit and our time an integer and then a
time unit to say how long to wait for
the pool to settle down and be no longer
busy and what you can do is that if see
here's the concept I should say it this
way when you say supply async or any of
those methods you have started the
process you don't have to then you don't
have to do a start meth or anything like
that it's automatically running but the
common fork/join pool is composed of
demon threads so that if nothing is
running they all get terminated see if
nothing else is operating it just shuts
down so if you have a main method that
just calls it then it the main method
completes then you get no results
because all the demon threads were
terminated you can either call get at
which point it will block and wait for
the thing to finish or you could simply
change the timeout on the common pool
doing away quiescence and make it long
enough that it will not finish before
your calculation finishes and either one
of these work the actual concept is that
in a real system where you're submitting
jobs all the time the pool doesn't go
quiescent you don't have that problem
but this is one of those ones that until
you see it you may not even recognize
it's there and it's very useful in those
simple cases where the pool would have
gone away and you wonder you're looking
at somebody's code you're caught why
didn't they call get why didn't they
call what happened here how did it
complete it completed anyway just
because they waited ok one other thing I
want to point out before I show you the
bigger example there are many methods in
that completable future class one of
them is called all of it takes a var arg
list of completable futures of any kind
it's a static method the problem with
this method
is it returns completable future up type
void now that would be fine if I don't
care about the results out of any of
these guys if I do care about the
results the question is how do I get
them the simplest thing to do is to make
this completable future var Arg list
make it a separate collection and then
transform it into an array so that you
can call this and then call join on the
all of so now you know they're all done
then you can do stream processing to
extract the results and it looks
basically like this so here is all of
demo here so down let's look here this
here's what I want to call is get value
I wanted to return an integer but I wrap
it in a completable future but again if
I'm going to do something with a sleep
in it which is how I'm going to make
this take some time that throws an
exception it's really awkward embedding
exception handling code in a pipeline so
I made it in a separate method here to
sleep for a random period about 100
milliseconds or left less return 42 I
don't actually care about the value and
then here I'm going to call this a
number of times and here's my demo is
that I'm going to generate calling that
get value a stream of 10 completable
futures and convert them to an array so
this is normal stream processing code
using some methods you may not use very
often like generate or to array which is
really convenient
there's my array constructor reference
you know kind of neat that'll create an
array so now I've got an array of
completable futures I can use that in
all of because an array matches the VAR
arg argument and call join and now
they're done and I can turn them back
into a stream and map them using the
join method not to wait until they're
finish but to get the values out of them
so by calling map with the join now I've
turned my transform my stream of
completable futures into a stream of
whatever the values are coming out of
the completable futures themselves and
then I could print them one by one so in
this case I'll just you get a bunch of
42s and I do you know so this is a nice
little mechanism that can be used to
extract values out of the collection
like that now I have a
bigger example I'm mostly just going to
have to show it to you but this is the
the idea here is that Major League
Baseball provides their box scores
online for free I think their own tools
actually use these and these box scores
are updated continuously now you don't
need to know anything about baseball to
understand this you just need to know
there are two teams and they keep
playing until there's a winner and these
the the statistics are compiled in
something called a box score that's all
we need in this particular case oh and
that you don't know if a game's gonna be
played until it's actually played
because it might get rained out okay
that's enough now
here for example is that webpage that I
was mentioning MLB here and if I drill
down into the current year so here's
2017 and then there's organized by month
I'll pick May 5th it's my son's birthday
you know and these are the games played
that day you could see them with a year
month day and then away team and home
team and the one or two would mean first
or second gave a double-header any rate
these are the games were actually played
and if you look inside one of these
you'll see there is a a file look he
right here called box score Jason and
this is the one that has all the
information in it the who's playing what
the scores are what the results are
everything so this is a system that's
been around for a long time might what I
wanted to do in my application was
access that site for a range of dates
and then figure out the game links for
each of those dates now to do that to do
the networking I'm going to use okay
HTTP nice very popular networking client
download the JSON box scores for each
game and I'm using the the parser for
HTTP the I forget the name of it right
now but it's a very common HTTP par so
you'll see when I see the code I'm going
to transform each JSON object into Java
objects using JSON use Google's JSON so
I wrote out the classes to map that and
then see that this is all stuff that I'd
like to happen in one thread except I'd
like to have it concurrently for all the
games or as many of the games like
could over the range once I have the
data however I have several things I'd
like to do essentially simultaneously I
would like to save the results to files
that's an IO one that's going to be
slower than everything else I'd like to
just determine the score of each game
I'd like to figure out which game had
the highest total score and I'd like to
write them to the console with all the
games scores with the max game in the
max score and all of this is in that
other repo selling you about so here's
the basic idea
this is in that separate repository let
me make this bigger and I have this get
games here and the idea is in my method
print games I make a completable future
with a supply async to get the game
links so I wrote my own supplier and
this is something you don't see all the
time is you actually make a class that
implements at the supplier interface I
don't want to do soluz a lambda for this
I'm going to put in some state there's
the base location
there's my local date and the number of
days I'm going to do three days by the
way Jabba 9 makes this easier because
you can actually use local dates in a
range now whereas you couldn't in Java 8
here is my actually this is the
calculation well let me start down here
again get is going to iterate over the
dates for that many days and for each
date get the links on that page and then
if I get an empty list I'll put in an
empty stream otherwise I'll put in a
list of streams and that's why I'm using
flat map and that will give me overall a
list of our stream of game lengths so I
collect them into a list and this is all
using LJ soup that's why I couldn't
think of so this is all using J soup and
ok HTTP to go find those links and then
process them ok that's step one then the
next thing is I want to retrieve the box
scores so sorry that was here
so supply async and then apply this box
score Retriever and this guy is going to
again implement function and use
Google's jisan with the client so this
down here it's probably easier to see it
here in parallel because why not I'll
map each of those
links to the link to get the actual box
score now here's where the the
interesting part happens or one
interesting part 900 ml over but I'll
finish it pretty quickly the idea now is
that I could get a rainout and if what
if that happens there's no box score and
there's no way to know that so I'm going
to filter them by optional dot is
present in this game pattern to result
mechanism I'm returning an optional if
there's a rainout C so if there's a
rainout then if the box where is not
found I'll return an empty otherwise I
do have nullable and I get them back and
then call get and then turn them into
the list here and the others are simpler
the others here I want to save the
result list which is simply a method up
here to for each one save the results
will file and I'm writing out how to use
jisan to do that and then the there's
exceptionally if something goes wrong
and here's the one to get the max score
and get the future and all that stuff
and it's all in here I join them all and
then print them out and if I execute
this here let me run this execution here
and you'll see that they will all if our
Wi-Fi holds up pop out here and I pick
the game with a rainout so that one
doesn't exist and the rest of them do
and there you go there's there's
everything being calculated so again
this is all in the code in the
repository so to summarize going
parallel is easy using completable
futures is easy getting benefit out of
it is where the where your time will
actually be spent
parallel streams delegate to the common
fork/join pool but you could change the
size of that pool completable future
lets you coordinate multiple ones and
there are many many methods available to
do the coordination i'll hang out if you
have any questions but otherwise thank
you very much for coming
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>