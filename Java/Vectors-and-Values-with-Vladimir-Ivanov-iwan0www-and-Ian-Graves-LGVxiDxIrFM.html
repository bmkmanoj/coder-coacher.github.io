<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Vectors and Values with Vladimir Ivanov @iwan0www and Ian Graves | Coder Coacher - Coaching Coders</title><meta content="Vectors and Values with Vladimir Ivanov @iwan0www and Ian Graves - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Java/">Java</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Vectors and Values with Vladimir Ivanov @iwan0www and Ian Graves</b></h2><h5 class="post__date">2017-08-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LGVxiDxIrFM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everybody I think we are
ready to start yon gray from winter and
I'm Lady Mary burrows and we would like
to give an update on vector epi project
which has been working on we have been
working on it as part of Project Panama
so since we we have a joint talk as a
bonus to this slide you cover one more
though and let's let's start soon okay
yeah so the vector API is a you know
it's motivated by we want to vectorize
things we want to do things in a single
instruction multiple data so given a
loop body like this we want to get it to
fully leverage Cindy registers and in
that case we wanted to look something
like like this where we can represent
packed ad pack operations in an
idiomatic Java way so our goals just up
front before we dive into this we want a
maximally expressive API so something
you can do pretty much everything with
is the is the ultimate goal with
coverage of all the operations that one
can reasonably expect on on a particular
architecture as far as performance is
concerned a predictable performance good
code quality and is competitive with
auto vectorization so if you're doing it
yourself and we give you the tools to do
it yourself we want you to be able to at
least match Auto vectorization but
that's that that that's a reasonable bar
to to shoot for we want you to be able
you know as a goal we want you to get
well above what you can get with Auto
vectorization cuz if you're doing it
yourself you're putting the effort in
you know you should see some results and
then we want some ways to make the code
portable so fall back for you know
narrower vector support on different
architectures or wider supports so ways
to write code that can transition across
different vector sizes and without
without you having to express a kernel
multiple different way
so this was last year
John had proposed the Strom and vector
API an immutable vector type with
functions like you see here two
parameters element and size we call it
the shape size essentially a bit width
and we've worked on we had a prototype
implementation I think of inspectors
based around these machine code snippets
which Vladimir's going to jump into here
in a little bit and raw vector types
called super Long's so fast forward a
little bit we we have a we had a draft
API implemented off of the the original
spec and the goal is to get code written
here to our our desired code shape we we
we have a so the vector API operations
are specified in an interface but live
in I want to say singleton at zero
vector instance primarily this is
because it's difficult to parameterize
at least in generic form the shape and
the element size when it comes to
rendering and marshalling vectors to and
from data sources so what you do is you
query the system for a vector instance
of a particular shape and size and if
such a thing is supported on your native
architecture then it gives you the zero
vector for that for that and for that
for that a element type and shape and
then from there you can instantiate
other vectors etc and then you also have
a zero value which is usually pretty
useful for a lot of different operation
so what we still are sort of holding off
on or working on is that in the current
shape we don't have full pipe
specialization we're still talking about
parameters in their box form so we have
to kind of dance around the boxing issue
a little bit under the hood you know
vector parameterize by integer or floats
will be behaving in a performant way if
you stay inside vector code
you're writing a bunch of code with the
vector objects chained together there's
not really boxing occurring it's just a
parameterised in you know inputs and
outputs of scalar types and data types
that is concerned with the integer
parameter if you're projecting scalar
values to and from there's some auto
boxing effects that's not a deal breaker
I'll in a couple of slides we've
actually refactored this in a way that
this really is no longer too much of an
issue and see here basically what we're
getting at is full value types you know
we've seen a lot of talks so far about
minimal value types but to fully realize
the vector API full value types with
enhanced generics and jetpacks and
flying cars are still you know something
that would help us fully realize the
vector API
another important coding component is
being size agnostic with your code so
you can ask for a particular vector
instance of an element type and it width
and if you don't have that available on
your local architecture then you're kind
of posed so if you're if you're
expressing your kernels you want to be
that you want them to be you want to
loosen the type constraints on code
wherever you can so given some vector of
a particular element you don't really
care about its size but you can query
the length of the vector if you're
starting through arrays or byte buffers
or whatnot so we want to be able to
express code in in this way so given
this vector loop we can we can have a
vector loop that looks something like
this when it's vectorized so if you see
here - we have a yeah not so much
um so so around the loop kernel with
vector at integer s we've loosened the
constraints up and the zero vector has
threaded through this this method so
essentially this prevents you from
having to write a kernel for integers
128 bits integers of 256 bit senators of
512 bits etc you start by just saying
give me the vector spec that will fill
the hole in my vector kernel so a really
important use case for something like
this is the line you know align lining
your loot colonel
so a really common thing to do is to
work your way up to alignment to your
vector your main vector loop and then do
a fixed up loop at the end so you have a
pre loop a main loop and a post loop and
so being size agnostic lets you write
things like this once or even back to
these out so you don't have to write
three loops if you have a more
higher-order issue approach so being
size agnostic prevents blow-up in your
in your code from having to support as
lots of different vectors so where we're
at now at the API structure is we have a
top-level vector parameterised by shape
and element type and then we have
subclasses abstract classes implementing
their affixing the the element type like
int vector and float vector and then
underneath that there are concrete
vectors where the operation basically
reside so this fixes this fix is the
issue of scalar gets input in our in our
vector operations and lets us lets us
talk about things in terms of primitives
and not box primitives and like put a
lot of pressure on on auto boxing so in
project Panama this is essentially what
it looks like now we have a vector
interface at the top level and then we
start to specialize part way with with
an inspector here with a shape that is
still yet to be determined and then when
we get down we drill down to the very
bottom we start getting vector classes
that are specific to elements and shapes
and then within those we have particular
bindings to in this case in this example
it's something akin to code snippets but
we would be specifying either into C to
side or an intrinsic occation side where
what operation corresponds to this
specific vector of this specific type
inside so we get semantics and size and
all that down at the bottom layer and so
initially we did we implemented a lot of
this bra vectors and the super long
types and you know this is this is the
original work from last year and we're
now starting to transition into
something like we just showed you here
which is more specialized and I think
this is where I hand off the baton to
Vladimir to go more in depth to this
thanks yen so row vectors are used to
hold vector values they are raised no
information about the size of elements
and types and we encapsulate them inside
typed vectors so right now in Panama we
have a typed vector and row vector
separation to simplify the
implementation when we started playing
with it
we placed a bunch of challenges and the
most important one was optimizing a way
back to boxes since all the classes we
create they are inherently identical we
need to do a significant amount of work
to eliminate them and it doesn't work in
all cases so other 2n mentioned that
primitive utilization and victor rising
higher order operations but for now I
want to focus on optimizing array vector
boxes because that's the crucial step in
order to get a predictable vectorization
of your code so we are leaving not ideal
world right now and there is a mismatch
between GBM and hardware v vm is random
so we don't have any primitive types
larger than 64 bit so we can't natively
describe value like values larger than
that so we can rely on we can try to
rely on escape analysis and JIT
compilers and sometimes it works so for
example in this particular case I use a
bit simplified API so it has typed
vectors are explicitly available
used so I won't use that vector
interface directly so the point here is
to demonstrate what kind of challenges
see tooth or other decompiler faces when
trying to get rid of vector boxes and
colorizing vector values so in this case
we have a vector local in the basic
block in the loop body and then see to
that
it's job fine no boxing so all the
vectors are in registers so the code the
machine code is quite nice when it
becomes a bit more complicated like
reduction of our array it becomes much
harder for t2 to keep up and it fails to
eliminate the boxes so there is a you
could think that there are two stages
escaping non escaping but there are more
states like there is non escaping and
scholar risible so even if the object is
non escaping it doesn't necessarily the
JIT compiler does necessarily can't a
scholar rises so in this particular case
C 2 detects that the value is not the
object is non escaping but it can't
prove it can still arise it because C 2
implementation is the control flow
insensitive and it just gives up when it
is merges of objects in the IR so you
can think that okay let's use a
different compiler which had of Spain's
here escape analysis why what was the
problem
the problem is more offer that the
escape analysis is not the right right -
to get reliable box elimination so for
example if some JIT compiler eristic
inlining carry six dozen in decide to
inline a call we have to box a value
into a box to pass it inside Akali
inside
or receiver value so do compiler
compiles do local another analyzes and
the escape analysis should be global to
get a good result
users can help do compiler by for
example writing of vectors into heap and
it defeats it keep analysis as well
identity sensitive operations also are
possible and it's hard to educate users
to avoid it especially if you use some
helper code like libraries and such code
can be solvent down because that so if
you users can experience problems even
if they don't write that code directly
but use some libraries to work with for
example you have some collection and you
or well yeah and it tries to computed
insensitive our code identification code
for example so yeah if yep analytics
into is brittle due to numerous
limitations in the implementation and it
in the approach in a call but well we
have been I we have been working on
value types like for three years and
well they're perfect sync for vectors
let's wait for value types and get rid
of any problems with boxing
unfortunately full-blown value types are
not there yet but hey we have minimal
value types and we are this earth talk
we where we will cover some of the
aspects minimal value types here we will
try to to describe the experience of
working with value types building
something on top of it so I won't cover
what are minimal types what are the
minimal types so it's a first version
that's it it deliberately kept minimal
to get something done quickly
and if we want to get a value type we
have to create a value capable class and
at run time we get a we can VM derive a
value type for us so at runtime there
are two classes on bytecode level there
are objects and values so there are L
type and Q types and Q types are
represented as derived value class so
the keys in the name is minimum so what
kind of limitations does it impose on us
[Laughter]
here we go sorry about that so what kind
of limitation does is impose on us so no
sub classing so the hierarchy we have
the separation between type and raw type
doesn't work anymore so we have to
flatten it so we have we have to come up
with the type vector and which
implements an interface so embedding
value types into another value type type
doesn't work as well so we can
encapsulate a deep raw bits of a value
in a value class and keep keep it
flattened so we have to do it ourselves
so we end up with the following stay in
the following state where we have typed
vectors which VM should be able to map
to vector register before that we worked
with a row type so single type / size
their shape another thing is that there
is no way to directly invoke a method on
our value so it has to be boxed first
and if we want to invoke a method on a
vector and avoid the boxing even in
intermediate box shortly we have to
avoid invoking methods as instance
methods on values on vectors so it
forces us to provide a method handle
based shape of vector API so all vector
iterations are exposed at method handles
because MVC supports only vector value
type operations operations on value
types on method method handles wrapping
value types in the objects doesn't work
so we so how does it look like so let's
look at memory layout so we have a
multiple choices and in Panama we we are
speak with the second one we just put a
payload as a long field and that's it
but there are more cases we can put each
field for every element in the vector or
just a reserved space and that's it not
don't expose any field
what kind of protocols different
approaches have so what if we don't have
any fields on value type so we have to
provide special factories and extractors
to get a user's hand on the actual
content of the vector because Vivi's
field and get field won't work because
there are no field declared so we have
to cover that are for for for ourselves
so what if we try to piggyback on what
minimal value types provide and just
declare the fields as elements element
as field so well it should work right so
if you want to access element just use
get field and name the corresponding
field or to construct to compose a
vector just use the release field and we
get as a result a vector with updated
element well it looks like it see
pretty well until we realized that in
order to avoid any boxing we have to
intensify those operations because we
have vectors in registers and if we try
to access anything by offset we have to
spill the value into memory update and
then load well that doesn't look that
attractive so we want to use special
instructions provided by the instruction
set architecture is sake and we have too
intrusive it means that we have to
intensify implementation of those
bytecode moreover what about Indian Asst
so how to order the field so depending
on the architecture the fields can be in
a different order well more problem to
be still so what about letting the
arrays so unlike other use cases for
minimal value types flattened vector
arrays aren't that important so the
benefits are that we get arrays
accessors for free by n VT but the
downside is that you just have to create
their own arrays and this comparing two
primitive arrays which are unique
vicious in the Java volt right now they
used everywhere we it's much better we
don't have any benefit in layout are
respected so in memory everything data
is flattened so whatever we use from
memory layer it doesn't matter much so
from usability perspective it's much
better to work with primitive arrays
than with explicit flattened vector
arrays but as a downside we have to
provide special accesses for to be able
to extract a vector from a primitive
array and write it back another benefit
of current implementation of MVT is
calling we can easily get vector :
conversion by slightly extending what is
done for our value types so right now
see two supports special calling
conventions where values passed as
fields in registers we can extend that
for our vectors and pass vectors in
registers so avoiding any boxing when
passing vectors inside some helper
function cally or getting it back which
should significantly reduce the need in
boxing so let's look at the example so a
simple one victor is dead we have a loop
over over an array and the loading
vectors from two arrays summing and
rewriting the result in the third array
so let's focus on the loop body and see
how it goes so the first question how to
get access to the actual operation so
operations on vectors are encapsulated
in metal handles and that there is there
is a need to do CPU dispatching some way
to detect what's available on the
current mesh and we are running on so we
can implement that using factories so
for example query at run time what was
the maximum size of the vector available
and after we get one getting a most
optimal implementation of the operation
on the vector shape we need so here we
want a vertical vector I'd add on two
vectors of well maximum size so okay we
have all the operations needed as method
handles to implement that so what kind
of options do we have
let's try to invoke them right we need
to load to load some and then store will
it work not really we have value capable
classes on mentioned on the bytecode
level at the call side but the method
candle is typed as a derived value type
so there is a mismatch there there will
be an exception thrown at runtime trying
to execute a different work exactly
okay let's try to do generic in work
well it works but from compiler
perspective not that well because
inlining does it work there is a when
you when you do an invoke generic right
now there is a cache on a method handle
which tries to catch the result of the
latest s type adaptation and reuse it
and the JIT can't see through that and
just issues a visual call well it's it's
not what we need right we want a really
backed vectorized code
okay let's adapt metal handle beforehand
and invoke and we get boxing on every
invocation both when we pass something
into metal handle and getting the result
back so the metal handle we invoke is
the well it assets it expects value
types it works on value types the
problem is that the tooling support is
not there and that's a deliberate
decision with minimal value types so all
the usages use side call sides will work
on our objects on all types so we have a
load a sort and invoke visual is on L
type so what kind of alternatives do we
have either generate you type bytecode
or compose message handles how does it
work how does it look like okay let's
see what what can we achieve with byte
code generation Marisa did an excellent
job with a new Python library which I'll
use here so it supports the cue types
that's the first library which the
both queue types I hope Remy will come
up with the cute MVC support in Assam
and it will be possible to write you
typed bytecode using assets as well but
unfortunately we are not there yet and
the bytecode library which Mauricio a
road is the only way to issue bicycles
cue typed byte codes right now there was
a workshop on byte code generation
yesterday so that's that's about that
but the library Marisa told you so we
need to reduce so there is no way that
there is no support on byte code level
for the operations we need so we have to
reuse meta channel so we take a method
handle we got from the our Factory
here I embed it as a constant to pull
patch we have that support and then load
arguments and invoke and I have here few
types so no boxing and the method handle
I use is also Q type so it it it it has
derived value types in the signature
first load second load the same okay
some again of q type bytecode and the q
types in the signatures and store it
back everything happens on Q types no
boxing needed great so what about matter
handles how can we express the same
functionality using metal handle okay
it's a bit more complex unless you're
afraid of byte codes so we have methods
handles
primitive operations we need to compose
them okay collect arguments want collect
arguments twice collect arguments again
it looks similar to what we need right
two loads
at the store but there are too many
operations to our many arguments we need
only four right three arrays and the
index
okay we need to permit arguments to
avoid some duplication and here we here
we are right we have a method handle
which implements what we need okay how
it's how it relates to queue type
bytecode we have metal handles which are
on derived value types but hey we need
queue types with JIT compiler speak byte
codes right so we're at you types they
on lambda falls so lambda forms were
extended with the Q type so on lambda
from level the the that metal handle
looks like that so the matter kind of
are stored on Matt okay endo methods
handle instance and the byte code
operates on on them so on bytecode level
we see q types again but the since
lambda forms are raised
instead of concrete value type we see
underscore underscore value so that's
what Fredrik mention when talking about
JIT compiler support that particular
code shape causes problems to treat
compilers or additional support is
needed on compiler side to be able to to
find out what are we can creat value
types there but C 2 works fine with that
so it's able to eliminate buffering in
this particular case and get decent code
generated and how to use loop loop body
we created well here we can iterate over
the array and invoke the
the loop body on every index with the
stride of a vector length we can do that
here because the type of methods handle
doesn't have any Q types so it's it's
expressed in terms of primitives for
objects all the belyeu types are hidden
inside so here you see all the vectors
or all the value types are inside now
nothing returned or no value types are
passed in so we can safely invoke the
method handle and get the decent code so
we saw two approaches byte code
generation and method handle well do
like that when I hear the Vincent on
Monday coined a new term and I liked it
so much because it expressed it was so
close to what I can be feeling working
with the method handles in MVC so it's
too painful even for that simple example
we just load two vectors do a single
operation and store them we have to do
multiple steps to get desired result but
we think we have a better story for
working with vectors and here is again
again alright pass it off yeah so you
know the introduction of MVT and value
types gave us a really good story to map
stuff from the code snippet level to
something we can use to generate
reasonable you know reasonably efficient
pretty nice tight code but the path
there is like like you said somewhat
fraught
you can do it it just takes some doing
and one might imagine that everybody who
engages in this is going to end up with
a giant harness that they they end up
writing to make their lives easier I
mean I you know we didn't have any
examples with method handle based
looping or anything in this slide in
these slides just because it would take
more than two or three but we did have
you know we do have some solutions
running it generates great code so at
the very least we're to this point now
we we're up to method handles we can use
method handles with queue type value
types are minimal value types and code
snippets
so it's a very least we have this
functioning mid-range step sort of in
line with how MVT is on a path towards
full value types we now have a partial
pathway to vectorization so one thing
that that that that occurred to us is
that really there's no better way to
talk about expressions than to just talk
about expressions so the original spec
for the vector api had a number of
higher-order components and those were
primarily intended for you to talk about
vectors in lane one lane wise fashion so
you know traditional a plus b times c
type situation you know it's natural and
it seems like it should just be listable
to the vector space so we've been doing
some work on that with higher-order
vectors these are you know some of the
examples and and you can you know we
talked about this last year but will
just reiterate it again you know if you
see the the this is a really natural
thing to want to do to vectors is to
lift a unary operator or a binary
operator over the element type to the
vector but in in this even in this
abstraction you've got a couple of
issues the the parameterised type is
boxed and you're going to be expressing
things in terms of scalar types so how
do you convert your scalar types to two
vector types you're basically walking
back to auto vectorization again so what
do we do
what what what does one do so
given given some lambdas like what are
some of the options so one of them is
cracking cracking serializable lambdas
getting the byte codes walking the byte
codes abstract applying abstract
interpretation to the byte codes and
reproducing an expression tree and
there's your expression again basically
what we want to get to the expression
how do we get to the expression
higher-order functions deliver us the
expression in some packed form how do we
get it back out again
so byte codes one way but you can still
introduce the programmer can still
introduce you know a Turing machine into
lambda and what are you supposed to do
with that we want we want more predict
we want a more predictable path to
performance so regular lambdas are a bit
too expressive so they're not the
greatest mapping so what about what
about reinterpret double higher-order
functions how about you know what if we
were to take something like a an
expression like so and just you know
consider it like it's a tree or how you
know given subtree we can take that tree
we can reverse the tree with some kind
of vector ops collection you know maps
to operations to method handles of a
particular with scalar forms or vector
forms and we can produce scalar kernels
and vector kernels that are isomorphic
to the same same expression so with that
you can then populate your pre and post
loops kernels and and your your vector
loops as well that's cool so how does
one do that one way that we have been
experimenting with it is to get to the
expression tree by cheating which is to
just say hey programmer make the
expression tree yourself don't write
like a traditional scalar expression but
use a little library construct the tree
and we'll traverse the tree that you
construct so using a builder the
developer can construct a tree and then
the libraries can traverse it this is
this is a really common thing in
functional programming you come up with
an ADT or something something interprets
your ADT and then produces does then
dispatch is based on that you know Scala
enclosure
m/l hassle that's just like second
nature to those language but in Java
it's not it's not exactly the most
natural thing necessarily to to impose
on programmers let's see this is yes so
this is an example of a little mock-up
we did and threw it up in its in Panama
the Panama repo right now links at the
end or on the slides when you get them
but we were we hide our expression trees
inside of inside of a lambda and then
bind parameters
explicitly and then hand this off to an
OPS builder which then populates the
expression tree with leaf nodes and then
visits all the nodes and reconstructs
method handle based equivalent so this
is the way you can you can walk an
expression tree with your pile of method
handles and reconstitute a kernel that
way without without having to do it by
hand oh and I should say that in
Vladimir's examples I think one of the
fun for tchen abut one of the first
things you want to do when you write
kernels is to write expressions and when
you do method handle Combinator's on
expressions that are in operations deep
that's when you end up with these
massive fan out and then you have to do
permutes and sometimes you have to
shuffle indices around so just just just
focusing on expressions and a nice way
to kind of encapsulate that prevent a
lot of the pain gramming that's
associated with wrangling permute and so
just building on top of that we can we
can say okay well say you have a
reduction like a left fold or a reduce
so we can use a builder that's pre
specified to that you give an expression
tree of that shape with an accumulator
and a node and then it can do reductions
based on some expression you build that
way this boils down to this this this
decomposes into a recomposes into method
handles with loop dominators which I
believe the loop is JDK nine isn't yes
so cool and this is another one with
masking operations
ternary style mask operations and you
know these examples all I'll pull out
you know fall out pretty well with the
expression tree approach you know it's
something that we're still working on
and can be improved upon we're you know
seeking feedback for these types of
things so expression trees are basically
a front end right now they live on top
of method handles with code snippets but
we could you know reorient them to face
the vector API through a method handles
interfacing or just look at byte code
spinning as well but in the end the
ultimate goal is something that looks
more like this where we're not concerned
as much about size we can talk about
parameters in lowercase form we can we
can act as you know we can look at our
data sources and array as sort of more
of a view style and then we can just
throw in our our our lambdas to
manipulate those so our project status
okay I think there's one detail I didn't
stick in these slides which was
yesterday and this is something that
came up yesterday when John was talking
at the workshop John mentioned what he
called liftable lambdas and I just
wanted to dovetail on that that what
this is with expression trees is
essentially a I want to say kind of a
workaround that does lifting a kind of
lifting on its own but this could be
superseded by a a you know
infrastructure for generalized listings
from lambdas or higher-order functions
in Java so if you could you know
symbolize the lambda body in a
particular way and then reinterpret that
and that was a that was the thing that
was available to everybody to write
their own custom listings then the
expression tree approach and the
reinterpretation of lambdas could live
on top of that work as just a use case
of generalized listings in Java liftable
lambdas so here in this example we cover
lambda so that's the most natural way to
write expression trees and type safe
manner so but we are not there yet
and
we don't have correctable lambdas which
are required to reliably victor eyes
predictably ripped our eyes such code
shapes so that's a something for a
future work mm-hmm yeah
a rising tide lifts all boats in the
vector api is definitely writing on the
MBT wave and ultimately the value types
wave will improve the experience for
users of the vector api so minimal will
you type based vector api is a first
step in the right direction and once
there are more support in different
areas we can piggyback on that work to
provide more fluent vector api more
natural for Java programmers but
unfortunately we are not there yet but
Mia we are moving in that direction
alright so now back to project status
yeah MVT based factory support in the
JVM we've talked about we have you know
we're very prone to going down rabbit
holes when we discover interesting
things so we one thing we've been
working on Intel is enhanced intrinsic
ation for the vector api since it's so
specified so well defined the number of
classes the concrete instances are fixed
it's essentially a closed world we work
we've been experimenting rough on when
we co-workers at Intel has been
experimenting with specializing and
intrinsic I based on the type hierarchy
of the vector API and he's gotten some
pretty good results I think that I think
it sounds little lately yeah just last
last hid bit vector ap the the latest
vector API specification we had a we we
had a big post a couple weeks ago and
then Paul Santos you know the master of
api's got in there and cleaned up my
mess it wasn't a mess but you know it
needed cleaning and he he knows how to
do it better than I do so he it's in a
really get in pretty good shape and it's
it's it's also susceptible to targeting
or enhancing terms of occation so the
implication patches that I think are
inbound to Panama
that demonstrate that work on the the
spec API as it exists now and then the
expression language is in there and it's
all in Panama yes I got ahead of myself
I do that every time so it's just we've
been experimenting with all this stuff
in situ playing with c2 IR and so we
have that workload from a similar
workload to before you thread in a spec
vector you fill in a templated whole
base style in your programming we're
doing math it's sort of this is sort of
a contrived example but the generated
code is on the right and you can see it
makes proper use of blends and adds and
and it's loads and stores and it's
pretty tight code and it leverages a lot
of the existing c2 architecture so this
particular example demonstrate that
intrinsic based approach is on par with
machine code snippets which I use can
phantom are so we don't need to bring
machine code snippets along with vector
API we can attend all them and since
right now we we try to meet great to
Valhalla project to to build something
on top of minimal value types we chose
the duration from Panama to Valhalla and
note the other direction so this it's
much easier to port intrinsic based
approach and this particular case
demonstrate that the approach itself is
on par with machine code snippets we
have we can achieve the same result with
the simpler solution all right so these
are the contributors that's us and some
other people and then the material so
references and then once again safe
harbor statement so yeah we are done
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>