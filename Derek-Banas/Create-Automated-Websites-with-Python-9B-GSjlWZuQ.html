<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Create Automated Websites with Python | Coder Coacher - Coaching Coders</title><meta content="Create Automated Websites with Python - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Derek-Banas/">Derek Banas</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Create Automated Websites with Python</b></h2><h5 class="post__date">2010-09-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9B-GSjlWZuQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello internet and welcome to the
tutorial in which I prove that I do
these videos to answer your questions
instead of driving tons of traffic these
three guys the bottom of the screen are
responsible for this tutorial and I hope
they like it I'm going to show you here
how to scrub websites for good articles
that you can use on an automated website
and whenever I am creating automated
websites I in essence do what you're
going to see here today and then take
the articles and the titles and the
descriptions and so forth
and send them to the WordPress postie
plug-in that shoots them up onto the
page and so that you know this works you
can see here what I did was I jumped
over to the Huffington Post and I chose
The Huffington Post because I posted a
poll on my website and I went to their
comedy page I grabbed the title I
grabbed a link to the original article I
grabbed the article itself for at least
800 characters of it if that existed and
I grabbed the description which you can
see right here which is a summary now
how I'm able to do this was I went to
their RSS page as you can see right here
and then I clicked to view source and I
figured out that their titles were
surrounded by tags with the name title
the link to the original article started
this text that you see right here and
the description summary is here so what
I'm able to do is go in grab the title
grab the descriptions throw that in but
then also grab the original article and
take as much content from it as I want
and I'm going to show you how that all
parades and then on top of that once I
was able to figure out how the RSS feed
was structured if I want to go in here
and look for the tag that surrounds all
the content what I do is I just select
the beginning of it and then I hit view
page source and I do a find in which I
look for that and you can see here here
is the article and every single article
starts with this tag class equals entry
body text all of this stuff is very
important and knowing how I did this
you're going to be able to do this with
any website that has an RSS feed so I'm
going to get into the code you're going
to have to go out and get a library it's
called HTTP Lib to Google actually put
it out and you can get it quite easily
by just typing in a
HTTP Li B - like I did up here and it's
going to take you to the website that
has it which is by the way
code.google.com/speed for HDTV Li B -
and if you don't know how to install
modules inside of Python I'm going to
show you right now all you would do is
type Python 3 if you're using Python 3
followed by whenever you download the
actual library the module that I'm
paying reference to there is going to be
a file called setup py that is
downloaded and you just simply go into
your terminal and type this right here
and hit enter and automatically loads
the said library into your modules
inside Python and that will allow you to
use this module then of course you're
going to import those two libraries and
if you haven't seen my Python tutorials
or my regular expressions tutorials you
are totally confused and you probably
already left but huge definitely should
watch those before continuing either way
going to create a main function down
here I'm going to create a variable
called URL to get and then I'm going to
put in there the RSS feed location for
said website this right here is going to
actually go out to the website this line
of code here and it's going to download
all of the content that exists at this
location then this line of code right
here is going to assign all of the
content from said page to this variable
called content then I'm going to convert
content into a string and send it to the
function that I called grab site tags
jump up here you can see here this is
the attribute it's accepting that
gigantic string and here I am creating
the regular expression like I have
already talked about previous tutorials
in which I'm going to look for the tags
title put a bracket around what I want
to get this opening bracket this closing
bracket I'm going to say I want all the
characters between 5 to 90 characters
and lengths that are surrounded by these
title tags
I'm also stating here with this or tag
that I also want between 5 to 300
characters that exists between the
summary tags that's going to be the
description and last but not least here
I'm going to grab the link to the
original article you
the code that you see here on the screen
and all of this information is available
at new think tank code column all this
code and I'm going to end this whole
entire guy with the ignore case
attribute so it's not going to pay
particular attention to any case changes
then I'm going to run the find all
function by passing it the regular
expression for what I'm looking for and
page to search which is going to be the
content from said website I'm then going
to cycle through everything that hit for
this regular expression and I'm going to
print to the screen both the title the
description and the link to the original
article I'm then going to pass the
original link to the original article
and it's stored in the second index as
you can see here if we go down here
number the indexes start at zero so
titles in zero summaries in one and two
is the location in the original article
so I want to send the location of the
original article to this function called
get the article and what this is going
to do is it's going to jump over to that
page and it's going to grab the original
article for me and print that to screen
as well I put this if statement in here
to make sure that the string that is
sent actually contains information and
then I'm going to call the HTTP method
and it is going to get all the
information from this new URL that is
sent and it's going to assign it to a
new variable that also is called content
I'm going to convert all of that content
into a string and then reassign it back
to the variable called content and here
I'm going to create a new regular
expression to search for and in this for
instance this is going to be whatever
information that will define your page
that you are looking for so remember
from the beginning of the tutorial I
said we're going to be looking for all
of the text that lies between div class
entry body text and then peculiarities
of the huffington post as they normally
have between one to forty garbage
characters then followed by a paragraph
tag and then I'm stating here that I
want to grab between 1 to 800 characters
that is going to pay reference to the
article itself so instead of having that
really short description on my automated
web site I'm going to have an 800
character we'll all
long article there and again I'm Nora in
case then I call the find all function
once again I supply it with this regular
expression I just created and I also
supply it with a string that contains
all the texts from the website that I am
searching for I convert all that article
that I just pulled down into a string
and here I'm checking to make sure that
the article is at least a hundred
characters long because I found with
often post anything less than hundred
characters it's garbage you're going to
find out with most websites and then
here this is going to be specific to the
Huffington Post or whatever website
you're going to be pulling information
from I chose to use the replace method
to replace common garbage characters
that are found inside of the post so for
example they often in their articles
they have these extra backslash
characters and quotes and so forth so
that's what I'm doing here with the
replace method I'm actually going in
there and cleaning up the article and
eliminating this newline character and a
whole bunch of other garbage things and
yes you can stack the replace method
because I did it right here and then I
come down else and if the article is not
100 characters in length I call the pass
method which just says to skip
everything else that we're doing here
and then I call the return statement
that returns me back up to the grabb
site tags function to continue
processing the additional articles and
titles and descriptions and so forth and
so on and then once I do that I have my
title link to the original article the
entire article up to 800 characters in
length as you can see right there and
the description and then normally what I
do on the automated websites is I give
them this title and I of course put this
link back to the original article at the
end of this article that I pull and I
put the descriptions in there sometimes
and sometimes I don't and on top of that
I don't have it displayed and I did want
to make this excruciatingly ly confusing
I also often perform search functions on
the titles to make sure the titles
contain information that applies to the
automated website that I use so and then
all this information again gets sent to
the post ich plug-in and it gets
displayed on the websites without me
having to do anything occasionally these
break the regular expressions stop
working if
you do a whole bunch of these guys but
it really doesn't happen that often
that's just whenever they change the
format like it often posts stop using
title in their RSS feed well that would
cause a lot of these things to break and
of course there's many different ways
that you can handle those errors that
I've covered in previous tutorials so I
hope you've enjoyed this rather
complicated tutorial on how to scrub
websites for good articles to use on
automated websites if you have any
questions leave them in the comment
section below
till next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>