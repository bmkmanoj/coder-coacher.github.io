<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Python 2.7 Tutorial Pt 13 Website Scraping | Coder Coacher - Coaching Coders</title><meta content="Python 2.7 Tutorial Pt 13 Website Scraping - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Derek-Banas/">Derek Banas</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Python 2.7 Tutorial Pt 13 Website Scraping</b></h2><h5 class="post__date">2010-11-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Ap_DlSrT-iE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Oh Internet and welcome to part 13 of my
programming with python 2.5 through 2.7
tutorial today I'm going to cover how to
scrape websites and if you didn't see
any of the previous tutorials definitely
check those out otherwise you will be
confused what I mean by scraping a
website is I'm gonna jump into an RSS
feed I'm gonna grab the title the link
to the original article and then I'm
gonna jump to the original article and
pull out all of the content from it
automatically and you can see it's quite
easily done you can see there's the
program that you will have at the end of
this tutorial and hopefully understand
and it's pulling all that information
right from a website which I'm using The
Huffington Post and there's the code but
I'm gonna explain it to you now first
off whenever you're gonna do sweb site
scraping you of course need to know some
information about the website you want
to scrape from so for example if I want
to be able to come in here and grab this
text from here I'm gonna need to figure
out what tags surround this text that I
want to get so I'm just gonna hit ctrl C
on the beginning of this I'm gonna do
view page source control F paste and I'm
gonna look for the location of the
article and after experimenting and
looking around here I finally figure out
that the Huffington Post for example now
this isn't gonna be a true of every
website you can see how easily this has
done The Huffington Post surrounds all
of their articles with this div and this
specific class defined okay so I want to
write that down that's a critical piece
of information and if I'm gonna be
scraping from the RSS feed which is the
easiest way to do it I'm gonna need some
information in regards to where is this
link and where these titles and where is
all this information so I'm just gonna
go you again page source and I'll see
you by looking in here that they
surround all the titles with the title
tag right here so I want to write that
down that's important and the links to
the original article lies in this link
tag that's right here on screen so just
to make sure you can see title and link
so if I want to get the title and I want
to get the link to the original story
this is where I am going to get that
information and that's pretty much all
you need to know to be able to scrape
information from a website I'm gonna
jump in here there's some modules I'm
going to need
to get how you were able to pull
information from a website is by using
this module called URL open and I'm
going to specifically just get URL Lib
I'm gonna use a new module that you're
actually gonna have to go out there and
download called beautifulsoup
and it makes life very easy in regards
to website scraping extra important here
and then I'm going to import my regular
expressions module and if you haven't
seen my regular expressions tutorial
I'll provide a link to it on the screen
I'm not gonna go through that again with
Python 2.7 because I think I did it
about as good as I can do with Python 3
and everything is identical so there's
no point in me doing it again well first
I'm gonna define the web page that I
want to pull information from and I'm
gonna use the Huffington Post's RSS feed
so let's jump over here and get it right
there copy jump back down here into my
code and paste it and like I said you
can do this with any feed the only thing
that's gonna change is the tags you're
gonna believe you can be looking for and
then append read on to the end of this
and that's all you need to do and that's
gonna pull all the information from this
page and stick it in my variable name
web page then what I'm gonna do is
define the regular expression for title
and all I'm gonna do here is type the
title in and then these rounded off
brackets followed by a dot star and then
title again and real quickly if you
don't know what a regular expression is
what I'm doing here is I'm surrounding
the information I want being the dot
represents any character and star
meaning more than one of whatever
precedes it so what I'm saying here is I
want to get all the characters as many
as they are with the star function here
and that lie between the tags title and
the closing title tag but I do not want
to get the title or the closing title
tag if I wanted to get those I put and
bracket around it this way but I don't
want to do that I want to leave the
title tag there because I have no
purpose for it so that's the regular
expression for grabbing the title and
I'm actually show you how to do this in
two different ways
and here I'm gonna find the regular
expression for grabbing the link back to
the original article we'll use single
quotes here and from looking at that
information
I was able to figure out that the link
starts off with link and then Arielle
and then any characters any number of
characters followed by H reference is
equal to and then this is what I want to
be able to get which is the reference
back to the original article and then it
has a closing tag at the end okay
and if you don't understand this because
you had don't understand regular
expressions so check out that tutorial
because it's really cool all right you
know I'll here I'm gonna store all the
titles and links I found in two
different lists equal to or II find all
find all functions gonna do just that
for me and what I do is I pass to it the
regular expression that I want to search
for and where I want to search for it
which is in the web page I'm just gonna
copy this because I only have to change
one word that's gonna be link and Link
and link here okay so what these guys
are gonna do is it's gonna search for
these patterns inside of the webpage and
save them to the list I'm gonna jump
down here and I'm just gonna define a
list iterator and using the range
function I'm gonna define that I want to
grab both the title and the link
starting at the second title and link in
the RSS feed and through the 16th so I'm
gonna grab the first 16 articles while
ignoring the first one which is always a
junk one in this for instance in your
case you might this might be one if you
want to grab every single article and
now what I'm gonna do is I'm gonna print
out all this information to the screen
and in this instance I don't have a main
file so I'll need uh and now I can run
this and you can see how it's gonna jump
out there and get all that information
for me just that easily and I could
probably also come in here try a new
line and you can see it jumped out there
to the huffington post and it grabbed
all my titles right there and it also
grabbed the link to the original article
so it's pretty useful however we can do
better let's come in here now and let's
go grab the entire article this is the
problem that most people have this is
the thing that everybody wants to do and
can't figure out how to do I'm gonna
show you article page because we do have
the link to the original article I'm
going to jump out to the original
article and get it
this this line right here is gonna grab
all the content from the original
article and now I just need to scrub it
now what I'm gonna do here is room I
remember that the article always starts
with div class equals entry body text we
covered that in the beginning of this
tutorial so I'm going to search for the
index the beginning location of that
exact thing so let me jump over here
come down here again copy view page
source you can see right here div class
entry body text I'm just gonna come in
here and copy that jump back over into
Eclipse and paste it right there yeah so
that's what I'm gonna be looking for
it's gonna return the index location for
the web page then what I'm gonna do is
create a new variable called article and
all this codes on my website freely
available do whatever you want get rich
off of it don't care if you can't and
here I'm gonna say that I want to copy
the first 1,000 characters that lie
after this div so I'm is this is gonna
kick back the original index for me and
then I'm gonna say I want to copy
everything up thousand characters in and
assign it to article and now what I'm
gonna do is pass all this information to
the beautifulsoup module and then you're
gonna see some neat things here and how
I pass all that over just like that and
the information that I want it to take a
look at now I'm gonna tell beautifulsoup
to locate all of the P tags and store
them in a list so paragraph list is
equal to soup dot find all and then you
could put in all the bold tags all the
any tags anything you put in here
beautiful soup is going to find it's
gonna search for a tag with that name
and it's gonna store it in the list so
this would be title this could be
anything you want it to be then what I'm
gonna do is iterate through this and
print all the paragraphs out to the
screen with a new line in there and you
can say it's doing it it's going in
there and not only actually cut this off
in the middle for the new line there and
you can see it's jumping out to the
huffington post and it's grabbing the
title the link to the original article
which is awesome and
it's jumping to this page where the
original article lies and it's copying
all the paragraph tags it's copying
everything from that webpage and posting
it right here on the screen there's no
reason you couldn't post this anywhere
else or dump it into a wordpress
database or do anything you could
possibly want with it and there's all
kinds of crazy things going on here but
let me show you how cool beautiful soup
can really be beautiful soup without I
can throw away a lot of this stuff and I
can grab the titles and links with
beautiful soup in all kinds of other
different ways so let's just jump in
here and I can delete all this and let's
create soup 2 is equal to soup webpage
in print to find Oh what this will do is
print out the screen all the titles as
you can see but it prints it out in a
great big giant huge list so I'm gonna
get rid of that and I'm gonna show you
how quickly you can do what took all
that code before title soup is equal to
soup to find all and in this
circumstance I'm gonna tell it to find
all the information that lies between
title tags and here I'm gonna tell it to
find all of the links that lie between
link tags and then real simply I'm gonna
iterate through them all and throw a new
one in there oops
gonna come in here hit title title soup
now I thought you could see it jumped
over there with that little tiny bit of
code and it grabbed all my titles and it
grabbed all my links and you could of
course scrub out anything you didn't
want here with all the different string
tools available to you with Python so I
hope you enjoyed this tutorial this is a
real quick and easy way to scrub
websites for information take
information from our cest feeds and do
pretty much anything else you want to do
online with information any questions or
comments leave them below until next
time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>