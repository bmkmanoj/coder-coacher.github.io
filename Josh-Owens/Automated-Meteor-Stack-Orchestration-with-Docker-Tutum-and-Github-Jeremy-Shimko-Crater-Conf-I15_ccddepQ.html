<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Automated Meteor Stack Orchestration with Docker, Tutum, and Github - Jeremy Shimko - Crater Conf | Coder Coacher - Coaching Coders</title><meta content="Automated Meteor Stack Orchestration with Docker, Tutum, and Github - Jeremy Shimko - Crater Conf - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Josh-Owens/">Josh Owens</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Automated Meteor Stack Orchestration with Docker, Tutum, and Github - Jeremy Shimko - Crater Conf</b></h2><h5 class="post__date">2016-04-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/I15_ccddepQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is a video of a talk from crater
remote cough given to a live audience in
February 2016 this video was made
possible by sponsors like modulus IO ok
grow calm and space dojo calm if you
would like to find out more information
about upcoming conferences be sure to go
to cough crater dot IO and put your
email in the form that pops up in the
lower left corner enjoy the video
alright so welcome to our second crater
comp makeup session today we are going
to hear a talk from Jeremy Simcoe he
he's been working with reaction commerce
actually and they've built a platform
using meteor and darker and well I'll
let him explain it all but welcome
Jeremy awesome to have you thank you
very much for having me
first off I just want to thank you and
everybody who came back today for for
the for the accommodating the schedule
change and being able to come back for
the makeup session that's awesome so so
thank you yeah so so there's a there's a
pretty wide range of topic to cover here
but I'm gonna try and boil it down to
like the you know the minimum amount to
kind of get get people started this is
this is of course assuming a meteor
audience and that that want to get
started with with docker and and want to
kind of get an idea of what what step
one is so first a little bit about
myself I am a longtime freelancer full
stack node JavaScript dork with a
kind of long time focus on DevOps i but
before doing doing mostly meteor node
stuff like I am now I was I was
freelancing more more generalist and
also an audio and video engineer and the
way that all kind of tied together was
mm-hmm I worked for a production company
or a variety of production companies
doing doing a lot of live webcasting
actually kind of ironically like my
conference webcasting it's a little bit
different format than this actually the
in-person kind of conference type of
thing but but but that was kind of the
core of my job description was was going
and doing the live production stuff but
also doing all of the web infrastructure
for distributing the live video
streaming kind of probably similar to
probably the most recognizable name that
does stuff like that now is is live
stream comm they they kind of specialize
in that live event space but for the
last the last three or four years I've
been exclusively just just web developer
and and most of that has been almost
entirely meteor as well and now as a
fairly recently I am full-time at angle
works and those would be folks that are
responsible for reaction commerce and my
most of my role over there is building
launch dock which is the platform as a
service that is being used to to launch
duck arised versions of reaction
commerce apps for customers so you know
customer signs up and launches in app
instance and and it essentially launches
a docker eyes version of reaction for
them on our infrastructure so not all
that is
- - galaxy of course just a little bit
more customized for our use case so the
kind of the overview of what I hope to
go through today and touch on a little
bit of each of these items is just a
high level of what what docker is and
and why a meteor developer might
actually care what docker cloud is a
little sidebar here as tunnel about two
weeks before my talk I'm sorry two days
before my talk was supposed to be last
week totem announced that they are
discontinuing the platform in favor of
docker cloud which is for those that
don't know docker bought totem a few
months back and and they are rebranding
the totem platform as docker clouds so
handful of things changed under the hood
but for the most part it's the same app
and yeah yeah so so kind of a kind of a
curveball at the last minute but for the
most part to be fair it's it's really
it's mostly logo changes and and a
couple of terminology changes but the
underlying functionality is also um and
excuse me a really common question I get
for all of this stuff is you know so
it's like like everything else in this
space there's an overwhelming amount of
things to to learn about it with docker
or even wider than add devops in general
it's you know they're they're whole
different job descriptions all by
themselves so you could easily focus
100% of your time on that and never
learn everything the same way you can
with javascript so so one of the most
common questions I get about this stuff
is is it actually going to be worth my
time to learn the basics of this to use
this and and is it even feasible to you
know to accomplish much
with a small amount of information
because a lot of times that's that's not
the case
just just skimming the surface and
getting the basics it doesn't really get
you too far but in the case of docker
and meteor you actually can surprisingly
get by with with just just the basics
and and and that's kind of where docker
cloud comes in is it kind of allows you
to not have to understand a lot of the
infrastructure side of things
and they take care of all of the
orchestration deploying docker
containers across lots of servers and
and yeah they take a lot of a lot of the
hard parts out you know the DevOps II
parts out of it and and give you a nice
interface to click around him to do that
yourself
so yes the next the next most most
common question is like where do I even
start with this stuff
there's there's so many bits to learn
like what's the important stuff to eat
and even begin so that's kind of the
main idea of this talk in the first
place this is it's just the basics and
and you know just get to working working
deployed app and then anything else
after that is kind of optional and you
can expand on it as a team so so
obviously the biggest question is what
is docker and probably the most common
comparison
I hear - - docker is is two VMs
so most most people know - most
developers know what a virtual machine
is you know thin think VirtualBox or
something like that or a vagrant which
can be using VirtualBox under the hood
but essentially they're just images of
an entire operating system and you can
reliably have a snapshot of an operating
system in a moment in time and and
transport that around mm-hmm and it will
reliably do the same thing a matter
where
because it's it's the whole operating
system with everything in it
the difference with docker
well so the problem with that is it's
the entire operating system so it's huge
you know it's it's it's in the you know
probably tens of gigabytes so it's not
it's not very transportable it's not
it's not a convenient unit to move
around and there's a lot of redundant
stuff happening so you know for example
having you have three different media
wraps and they're all on the same
operating system you don't need to have
three full snapshots of that entire
operating system because the only thing
that's different between those three
apps are the apps themselves so you know
kind of enter docker that's that's
that's what that aims to be is here's a
snapshot of just the app mm-hmm the app
and its dependencies and then you have a
server that runs the docker runtime the
docker engine mm-hmm and and that
becomes that becomes the base you know
using the VM analogy that becomes like
the base VM and everything else runs on
top of that so all of those things that
are common shared across all of those
apps can share that common base without
having to be transported with with that
advantage and probably one of the best
spots to to kind of getting I I was
going to make a diagram for this but it
seemed like such a unnecessary thing to
do because one already exists
right on Dockers website you know right
at the top of their their home page
there there's a what is what is docker
and this is this is pretty close to the
top of that page and this is um this is
essentially illustrating the point I was
just making you know on the left you can
you can see the the guest OS blocks
those are those are the entire operating
system you know so that's using Ubuntu
as an example those are three full
snapshots of the entire operating system
and and they're identical and so so so
it's it's pretty inefficient and on the
right you see the the darker version of
the same thing where there could be only
the common base ends at docker so all
you need is server running docker and
any docker container will run on it so
another kind of great analogy that's
that's fairly similar to that that I
just heard somebody say the other day
mmm was it's like it's like shipping
containers and of course that's that's
where the docker name comes from this
from boat shipping containers but the
point there the the analogy is that
shipping containers are all a
standardized size and a great
opportunity for a picture of ship with
shipping containers sorry about that but
so they're all a standardized size and a
boat that carries shipping containers
does not care what's in those shipping
containers it it could be it could be
clothing it could be food it could be
whatever shipping containers have their
own refrigeration sometimes in the case
of food they have their own climate
control that's how you know bananas come
from across the world in a shipping
container and that that has kept it a
very specific humidity and temperature
and anything outside of that shipping
container you know the boat doesn't care
what's in there and then another
shipping container may have absolutely
no climate control necessity but both of
those shipping containers are the exact
same size and they stack in the exact
same way and they would sit on any any
boat meant for those of you though
that's where that has docker so that's
that's kind of the idea there so so you
know the big obvious game there is is of
course if it works on one server you can
expect that it'll work identically on on
the other server or they're very oh it's
a very short list of exceptions
so so yes that's that's kind of docker
in it on that shelf so the next next
most common question is you know how do
i how do I tie this in to meteor and and
it's actually a surprisingly it's a
surprisingly short list of steps to just
to just do the basics to get a meteor
app inside a docker container and my
couple of my favorite base images for me
here are these guys I I just kind of
recently started using Tupperware from
from Chris Wessels and a meteor D of
course is it's from is from arunoda and
it has has been around and popular for
quite some time these are these are both
pretty pretty battle-tested base
containers so you know what does it mean
to be a base container so if you think
about what the dependencies are of a
meteor app we obviously have node at a
specific version obviously it's on a
higher level than that it's it's on a
Linux machine and and then then you
might have a whole bunch of optional
dependencies you know phantom dance and
whatever you know this there's tons of
other things that maybe app specific
that you might put in there but that'd
be at the very least both of these will
get pretty much any meteor app up and
running with that with a single line
doctor file in the move of your project
so the other half of every meteor app
every single maybe your app is of course
Mongo and and there's two there's two
ways you can go with that so you can you
can go the route that the galaxy does
and you use another provider for for
Mongo and that-that-that-that of course
what's up the responsibility across a
couple
places and and obviously you're here
Mongo you're Mongo instance should be
different in a different place than your
app is anyway for performance reasons so
it kind of doesn't matter where it is
whether or not you put it in a container
on another one your servers or you use
Mongo as a service like like composer or
mongolab for the purposes of this talk
and the demo I'm gonna do shortly we are
gonna do a darker eyes version of that
and I'm gonna tell you the couple of
caveats you have to think of there so
there are a couple of couple of images I
like for for that of course there is the
official officially sanctioned Mongo
docker image and then there is the one
that I built which has the the purpose
main purpose of it is to to run a
replica set to run three containers in
three Mongo containers ideally across
three separate servers but not required
and and and run them as a replica set
excuse me so so kind of the caveat to to
Mongo in the container is that your data
is in a container so so there are a
handful of you know that starts to
starts to work its way up you know
slightly more advanced docker usage but
but but kind of high level you don't you
don't want to leave the data inside the
container you want your you want your
containers to be immutable you you want
to be able to lose and and start more
containers or you know swap them out if
one fails you you you never want
anything to stay inside a container that
you care about so short answer is that's
why hosting hosting elsewhere with a
Mongo as a service can be significantly
easier especially if you're new to
to doctor and managing persistent data
in doctor but there are other options so
you you know for example you can do data
containers which are just containers
that are linked to a you know in this
case a Mongo image and all that
container does is take the data you know
it's it's linked to the Mongo container
and the data from the Mongo container
goes in there and then you can swap out
your Mongo container and it'll you know
link back to that that storage container
when it when a new one comes back up and
that's one way to persist your data the
other is to to persist it on the host
itself so when you run a you know a
Mongo container on a server you can you
can persist that data in a directory on
that house that's probably a slightly
simpler easier to manage scenario how
about because that starts to work its
way into slightly more advanced we're
just going to keep it like in the
container kind of disposable Mongo for
the sake of it so the sake of the demo
of course my phone's so so what is dr.
cloud and so docker cloud up until last
week was was totem and chatham you know
to understand what dr. cloud is a little
bit of history behind that is this is
this company totem that was bought by
docker a few months ago is a is a
platform that you could use to
orchestrate docker containers across you
know any amount of service so you can
use it to to launch your own server to
launch your servers you can use it to
deploy your docker containers to the
servers you can have container repos
they're you know storing your container
repos they're just like with docker hub
which sorry to step back a second you
know
docker hub is basically github for
docker containers it's it's versioned
containers and and functions basically
how you would expect it to if you are
familiar with with github so so totem
has their own private container repo and
they also they also will do all of the
orchestration and server setup for you
and you can use it with any major cloud
hosting provider you know AWS
digitalocean
and add your or any of those or you know
custom or no I'm not sure what the term
they use for it is but basically if you
had your own server running in your own
in your own data center you could you
could also use that that as well but
that the cloud integrations are
obviously a bit more feature-rich
because they're they're talking directly
to the platform so so yeah so totem
takes a lot of the the pain out of
managing you know container repos and
and server orchestration and container
orchestration across the servers all
these things you can do with the
standard docker toolbox which is
actually what it's called but if you
want to slightly more managed
point-and-click
version of that and you don't want to be
in the CLI for all of that totem is is
kind of aiming to be that so as I said
doctor bought them a few months ago and
and it was unclear until last week when
they made this surprise announcement
that they're what they were going to do
it sounded like they were continuing on
but it wasn't clear if it was going to
be the same product but the short ish
story there is it is the same product it
just as a new logo and
and a kind of humorously not quite
finished website so which actually you
won't find a link to on their on their
website they you know so they released
they released this to to current totem
users last week and and you know said
you know your account transfers over but
but they're not they're not they're not
really pushing it too hard on the main
site so you might not find it if you go
looking for it but know that it is
cloud.com
so easy enough URL to another so yeah
yeah so so that's it for you know that
static slides I am now gonna just walk
through walk through your doing the very
basics of setting setting an app up with
docker and and docker cloud and getting
it deployed and getting getting an
automated redeployment when you push to
your repo and get up so let me just
switch desktops here so you can actually
see my see my correct desktop okay so
what what we have here is mmm this is
the meteor to do that
the me or create weeks example to news
yeah you can ignore my M alias there for
meteor so that this this folder is the
the output of that so because I already
have some can things in there I won't go
ahead I won't do it again but
so take a look and see what we have in
here so so nothing nothing done to the
app at all
the only things added are these couple
of files here and I'll start from from
the most basic so so the first the the
first here is the docker file itself
which is not surprisingly a requirement
of any any app to be doc arised you put
this in the root of the root of the
project and you pick your base container
here so in this particular case I'm
using the the first one from from Chris
Wessels here the Tupperware one I happen
to mm-hmm I happen to like this one
because it's it's it's configurable you
can put find this to be a little more
approachable for for people that are
better new to doctor you can put a JSON
file in the root of your in the routier
project and it will read that as kind of
somewhat somewhat uncommon in docker
well usually most of the configuration
ends up in the docker stuff but I think
for people who are comfortable with Java
Script and and and you know some dot
file configs in the root of their app
which there are now about 50 of them in
every app should be comfortable with
something like this so so this is pretty
straightforward there's there's there's
not much that that needs too much
explaining there but but you know so
other other optional things you might
want to have inside your doctor
container when it builds the app for you
you know like phantom Jass and image
magic you know so pretty straightforward
with that so you put that in the root of
your project in this particular case
leave so these are all the defaults so I
don't have I didn't put this file in
there because they don't need any of
these things and I'm fine with these
defaults so so just know that these are
the defaults that that will happen it
won't install any unnecessary things
that this particular app doesn't doesn't
need
but anyway you can you can certainly
recommend hitting hitting up this repo
and taking a look here and kind of
reading through it's pretty
straightforward to use it so to use it
and in this app it's it's all I've done
two things so so this is the the base
image pretty pretty obviously from this
base image if I wanted to do anything
else inside my docker container before
it is finished building I would finish
writing that out in here you know so if
I any linux command I could run you know
in here and and and it would run that it
would run that inside the container so
there I'm gonna own the entire thing so
wouldn't do that but um but yeah so so
that's that's the the base image setup
and this in this particular case for an
app that is pretty bare bones like the
to do that that is literally all you
need so the only other thing that's from
Tupperware readme that it points out
which is technically optional but it is
a best practice is to use a doctor
ignore file mmm and the doctor ignore
file works like you would think it would
if you're familiar with git ignore files
so all that means so you can think of
the build that happens inside a
container as as a production build so so
the things you don't need in production
are here are the local build things that
happen when you are working in
development and just to be a little more
thorough here again i just elias meteor
2m so if you see that so so we'll start
this up and and of course make sure that
this is this is actually running
see the end and ok to news app up and
running as as it was originally started
so so we're good there so we'll go back
to the repo so so the things that we
don't need in the production build are
the node modules that get built here and
build files for the packages and then of
course the local database and all of the
other files for the local development
build so so it it isn't necessarily
going to break anything if this stuff
isn't there but you're you're you're
having to copy these files over to the
doctor machine so you're just saving
yourself from pushing an unnecessary
amount of files that aren't going to be
used and so that's practice there and
you won't have to touch this folder to
me or this file too many more times
once you've set it up the first time
so I guess probably a good next step
would be a quick brief intro to docker
compose when you pull up the tool box
here so the doctor toolboxes is really
where you're gonna you're gonna get
started with installing everything so
pretty straightforward Mac and Windows
install it's it's less complicated on
Linux because doctor isn't but docker
only runs on Linux so essentially what
this stuff does is set you up with a
virtual machine that has doctors on it
and and then all of the docker tools
like doctor itself doctor composed
docker machine for managing servers with
docker on them and then kite Matic is is
the the UI for the VM that it installs
so this is just kind of a UI over a
docker virtual machine so let's see here
these are all popular popular popular
containers and you could click them and
it will download that container and it
will launch it on
on the VM and actually should be quick
payoff here for sake of demo since that
finishes downloading you should be able
to click on that and you will have nginx
boxing nothing but of course of course
well done so let's get back but couldn't
it happen if it was in the demo what it
just worked so so back to the docker
toolbox here one of the things in the
docker toolbox is docker compose and and
what docker compose does is it allows
you to use the Gambel file and define a
collection of containers docker
containers that are that together kind
of form form a unit stack if you will
and you know in the case of a media app
of course you have a Mongo separate
Mongo instance and in this example here
we have a Mongo container so so all this
does is essentially launch a when you
use docker compose to launch this it'll
use under the hood it's using docker to
launch your Chibueze container and also
a Mongo container and then and then link
them together so so this link is kind of
literally a network network link so it
changes the host file inside of the
inside of the the to news app container
and you can just put that you know the
name you defined in the link in the URL
of the Mongo Mongo URL and this is
actually pointing at will resolve to
this container so you know if this were
that instead at would result for that
container once you do that so so that's
so that's so that's what that is
so it's all a kind of a closed Network
thing within within the same docker host
so because a meteor app won't run
without being
connected to a great abates I included
this msconfig in here as a starting
point to to show you what how launching
a container looks so so go back into the
base of this before you can actually
launch a doctor container you have to
build it so in this case this is this is
all you need to do if you've put a base
image in there that satisfies everything
that your your app needs which in this
case we have you do the daughter build
and then you tag it with the convention
is is your docker account name with the
app name and then and then a tag so this
might also be you know yeah something
something like that you might even like
a tag it by versions as well but in this
case we're just going to do this and
then the got at the end just meetings in
you know the doctor file is in this
directory or build from this correct so
easily the most common command you're
gonna use with doctors so what this does
when I start this is it reads that base
image and and you can see it's it's
didn't see a Tupperware JSON so it's
using the defaults as I mentioned before
so it's downloading so the base image
what it already has in it is it's a
linux box that already has note
installed and all the dependencies that
meteor needs you know specifically node
o 10.40 one and of course it's good yeah
so the base image already has all of the
all of the dependencies that that the
app needs and then the only thing it
needs at that point is meteor itself and
the app code so it downloads meteor and
then
stalls media copies your app code over
and then it does a meteor build the same
way it would if you were to bun meteor
built in this in this same directory so
one more time I just deleted deleted all
my cash there so it'll it'll have to you
don't have to download that stuff again
I am running in case this totally hos is
making it seems like that might be
happening here I already have this stuff
built and push that was really kind of
just doing this to uh for demo purposes
here but if we look over here and my
docker hub account lots of people like
to record screencasts of their demos and
then and then talk over them now is one
of those times that kind of wish I did
that it's uh looks like the doctor the
default docker VM that's it's hanging on
there so not a huge deal if I can't
actually demonstrate this for you but um
so once once the okay there we go
we do it on this other one okay oh that
one watch okay so now it's downloading
the base image sorry about that it's
downloading the base image which again
as the the Linux OS you know the base
which actually while we're doing that
let's look and see what's in that base
image if you look inside the docker file
the Tupperware repo here and see that it
comes the base image is from Debbie and
Jesse which is literally dude the distro
and the version release and then there's
a couple of environment variables set
here I assume most people that are
familiar with meteor are also familiar
with environment variables and they are
the standard way of passing in
configuration to docq containers so
these could all have been on separate
lines or all on one line like you did
here pretty straightforward they're copy
the copy command is literally copying
over the scripts that are go back here
into the includes directory these are
all the scripts that that set up the set
up the operating system setup node all
of those all of those steps so you know
again huge huge advantage of doing this
is you have your entire operating system
and it's set up completely in version
control and it consistently consistently
runs the same way so so not a whole lot
else to see here so so bootstrap script
sets up the whole OS and and everything
else and then
once you once you use this base image to
start your app this is the swoop it does
- no startup novoed and pointed at your
app let's go back and see if that build
is done so we can see here it pulled
down found the whole base image that we
were just looking at it then copied our
app into that container and now it's
running the build script which is
essentially is downloading a year and
then it's installing meteor and then and
then we're building the app which is
literally just the meteor build command
with a couple of arguments so now it's
going to install NPM dependencies and
anything else it's in there pretty
minimal for this app because it's just
the twos example so the last thing you
want to see is successfully built and
then a container ID so now if I I did
configuration here so I can use now I
can use docker compose to to start up
that app this is the same it's the same
name I named that when I built it so
it'll know to use that and then this is
the standard Mongo the official Mongo
image that comes out and this is a
command it'll run when it starts mom go
up on that service so starting up the
app oh so I'm sorry so because we have
this link here and it's linked to Mongo
that also at the same time has a
function of declaring a dependency so
when that link is there docker compose
knows the app needs to have this running
before this starts so so Mongo will
download and and start up and be ready
for connections before the app comes up
so let's see what that looks like so
that's simple as it's doing docker
compose oh and d4 attached meaning to
not stay in my terminal search session
we'll go ahead and do that and it'll
pull down all the layers of the official
Mongo container
so kind of again on docker fundamentals
here you know the kind of the basics of
docker is is that it's it's all dr.
containers are all broken down into
layers and when you change something
about a layer only that layer needs to
be needs to be transported so kind of
kind of like the operating system
analogy from earlier but it even goes
down to a more granular level of every
single line on a docker file every
little command you put in a docker file
creates a new layer so now I went and
changed one of those lines it'll only
rebuild that one line and it would use
the cache of all the other layers before
it so so yes and incredibly efficient
for for moving parts around and now if I
run multiple copies of Mongo or my app
for instance from from this from the
same server they will all use the same
base image it won't download a whole
other copy of it a hundred times over if
I if I ran a hundred instances it would
be using from the same files but they
would be entirely isolated okay so as we
can see there that that works so let's
do the ever hand the docker compose logs
and that will spit out the logs of of
our two container so happened to spit
out the two dus logs first but it's
starting your application that is the
expected only log output of that
particular base container so that means
the app is running there's no errors in
there and then this is a fortress all of
mongos startup logs
outputting here and and there are no
errors in there as well so we've got out
of there and I happen to know actually
hated because Dockers default VM was
bailing on me because I was choosing to
use it in a demo I created my own I
created a new a new VM
with docker machines real quickly and
all that local level Oh three I believe
so I can get the IP of that machine like
that and there we are so so same app now
inside a container and connect it to a
Mongo container you know so this is a
full production build you know it's it's
the output of media bill and connected
to to a separate Mongo container so you
can take a look at what we have running
here to docker PS for docker you know to
show processes doctor processes that are
running and you can see the two
processes are the processes that are
running on this server are the two back
we just built and the Mongo container
now there are tons of commands you could
you could do to to inspect any one of
these things so it's just an example or
inspect and then the container ID or the
name and you can see all kinds of stuff
about this container you know it's it's
the environment variables that are
passed into it
the exposed ports that you can you can
get into it you know all ports are
closed by default so you have to have to
specify what ports are open which is
remember from our doctor compose here I
have said I want docker I'm sorry port
80 on the host to be able to be wired up
to port 80 on the container excuse me so
when something hits when something gets
port 80 on the host like I just did in
the browser it will route that traffic
so obviously you can only have one thing
on a given server with port 80 exposed
publicly so if you wanted to have
multiple instances of this container on
the server your next step would be to
have a load balancer container in front
that that would that would route based
on domain name or something like that in
an effort to not get even more dense
than it already has
I won't i won't go go into that so wow
really killin it on time here sorry
alright so so we now have that running
locally it's at one more time we can see
that coal tar containers are running
locally so alright how does this
translate to somewhere on the public
internet that somebody else can say so
you're gonna go to dr. cloud I'm not
going to walk through too much in the
setup here in the interest of saving
some time but this is the this is a
default dashboard here and I'm gonna go
ahead and terminate the example I had
them earlier oh I'm sorry
so so first things first let's make this
publicly available for the automated
build hey that's up up on our up on our
repo here yes to commence okay so by the
way is this everything we've done here
is gonna be available and my my github
account here at this link so we'll go
back to right okay so I'm sorry so I
built the container I did the docker
build commands the
the only thing you would do after that
synonymous to to get cushion bolas is
docker pushing poll and and I'm now
going to push this up to my account on
on docker hub so that I can actually
pull this from anywhere the same way you
would pull your app source from anywhere
because what's going to be happening is
it's going to be pulling from from the
app servers that it gets deployed on so
so I built this container I've tested it
and made sure it works fine locally and
I push this out to dr. hub and now I
know I can pull this to any dogger
server anywhere of any kind and docker
server that's running docker and this
container should run in the exact same
way so you should expect to have the
same results no matter what because
everything is encapsulated inside that
container and and the server itself
doesn't care what's actually in it it'll
just expose the ports you said to
exposed and point traffic at it and
everything else that happens inside the
container is completely black box to the
soap so while that's pushing pushing to
docker hub is notoriously a little on
the slow side but be fair that was
several hundred megabytes there and I'm
also streaming video screencast so I
guess it's not that bad but it is it is
sometimes if you have if you have a
large app it can be a little a little
bit painful sometimes so let's go back
to Susan's docker cloud again and so so
first things first I've already done
this but for the sake of explanation you
would go into your your account settings
you're going to need to add a cloud
provider so that you can have some
servers pretty straightforward there so
you would add credentials and fill out a
handful of things pretty
self-explanatory digitalocean because
it's about as easy as it gets to use I
went with that one for this demo but you
hit link
count and it'll bring you to to a
digitalocean authentication that
redirects you back to this page and
that's it you don't even have the
copy/paste API key is it does it does it
that way so so dead simple to use them
once you have those credentials in there
you can now go to nodes and do launched
a new node cluster began I already do
this so we won't wait for it but so you
could name it something so I might name
it to do this example so I remember
what's on this server deploy tags are
optional but that's how you might you
know for example if you had two servers
one for the Mongo containers and one for
the app containers you might you know
you might put a deploy tag on their app
or deploy tag of Mongo and then in your
configuration you would put those deploy
tags in there and if that's how it would
decide what server to put the containers
on we don't have any tags in our config
right now so we'll leave at empty but
the provider digitalocean
pick a region and then pick the size
these are all the same sizes that you'd
normally see when you firing up a server
on digital ocean so please pick that one
because it's big enough you could you
could launch up to 10 at a time in a
cluster if you wanted to and it would
treat them all kind of like one logical
unit and it would just if you were
deploying things to anything on the
traduz example cluster it would you know
docker cloud would just make the
decision for you on where to place
things just kind of automatically takes
care of more conspiration for you so
then he would hit launch and it would it
would do the oceans API and start
watching servers once that's done you
get this which is is it's just one
server so I look inside here I can see
the containers I just I just killed but
so we have a server ready for launching
these airs so I feel like I'm rushing
here but god I got a little long-winded
here I want to make sure I get all this
in here so so kind of the way docker
cloud works and the late
worked is is is is using what they call
staff files and snack files are
basically almost identical to the docker
compose file that we saw before with
with the only difference being there are
some additional syntax that you can use
you know for for example auto redeploy
is one and will make use of that shortly
when they automate the deployment from
from get up so so this is a stack file
this is this is obviously a little more
complicated than the original doctor
composed I showed you before but but
this is all basically the same the
exception of now has a blog URL and it
has Mongo URL this is actually as much
as this doesn't look like it can
possibly be a valid Mongo URL it
actually is this Mongo one Mongo two are
the host names for these down here you
can see there they're linked to those so
as Mongo one there and with the
configuration for the Mongo primary and
then Mongo 2 and 3 this is the second
Mambo 2 is the secondary and the third
is Yarber there there's no data on it it
actually just it just handles replica
set handles elections when a failure
happens between a what a failure happens
in a replica set if one fails the
arbiter is the one that says this one is
the new primary lots to read on Mongo
replica set probably no better place to
go than the official Mongo Doc's lots of
lots of long-winded explanations on that
so I won't go too far into that but what
this is is my my launch doc replica set
image that I mentioned earlier and if
you go to if you go to this repo which I
will get with Josh and figure out a way
to you give actual clickable links to
everybody here
like this repo has a long description of
how to build and push and use the
replica set Mongo image is that um that
I'm using care but there there is one
already published on docker hub that you
can use the only caveat being they all
have the same key file in them for
communicating with each other and that
is not yet they're not in this case
they're not exposed to the public so
it's not a big deal but if you do end up
using this short version is build your
own copy of it follow the follow the
directions for generating your own key
files
it's how the three the three Mongo
instances communicate with each other
you can kind of think of them as like
SSH keys for for internal communication
between the three servers so so again if
you if you end up using this yourself
just go through through the directions
from from top to bottom and build your
own version of it but the sake of demo
we're gonna use the one that's already
published on docker hub so go back to
the create a stack thing so so basically
all we have to do is paste in that
configuration and and technically that
original docker compose I had this this
would work if I paste that in there
that'll launch on that server as is and
actually for the sake of demonstration
let's just do that so we'll go ahead and
just paste that right in there okay and
then we're just gonna well actually yeah
we'll create and deploy so it knows it
has a dependency on that Mongo container
so see it'll start it'll start firing
that up that should come up pretty quick
because I've already done this before so
that the container should be cached on
the machine and once that Mongo
container finishes booting it will then
start launching the - duze container
which it is going to have to download
again because I just pushed another
another version of it
but while we're waiting they're open in
a new tab here that look at looking at
the Mongo container itself and you can
you can click on the logs here and you
can look at the server-side logs and you
see the same thing that we saw when we
did that when we did that locally
earlier so you can do you know all right
so it's already done so we'll go into
the tube you here look at the logs there
we set out same one line log from
earlier so so if we're looking for work
back out here so this is the stacks page
it shows you all the containers that are
in your stack and we'll go to the app
container will look at endpoints and
this is what you would point your domain
name at to to get to your app here um
so bad and open that and there we are
it's deployed it was the exact same
container image that we just did locally
so so that so that all worked and again
if I wanted to run you know 20 of these
across 20 other servers I would
basically just put a load balancer in
front of them and everything else would
be done the same way so if this wasn't
exposing port 80 I could actually run a
bunch of those on the same server right
now or you know if I had a server
cluster running and I had 10 servers
running I could hit that up to 10 hit
apply and it would launch this container
across all 10 servers and then of course
I would hopefully have a load balancer
in front of that so traffic gets routed
accordingly but but it's it's that
simple to deploy across 10 servers and
we haven't touched a single server
configuration at this point so the last
little bit I know I feel like I'm
rushing here sorry guys so the last
little bit to kind of complete the
workflow is attaching it to attaching
that particular container to a registry
I'm sorry to your to your github repo so
you go to the registries tab and since
that of course that repo that I pushed
to before so I've already set this all
up before but see here
um all right so this is already large
joke edit I can get the same dialogue so
yes so when you when you start a new a
new repo had I not already done this
already you would get this dialog note
that it is currently in beta not that
that ever scared off any meteor
developers so this is github org in this
case my my account in this case the
repository name same one we pushed to
before Auto test I encourage you to
click the link there and read about what
all that is but that is what it sounds
like it will optionally when it builds
your container for you it will run tests
for you if you want to obviously we
didn't but you didn't write any test for
this app so there isn't anything to run
but the last part is the tag mappings
and this is the tag that I put on the
docker container itself when I built it
locally this is of course my my github
brett branch and then and then auto
build is checked now if i also wanted to
have you know perhaps a staging tag i
might do something like this
if I actually had a dev branch and
that's funny it'll actually let me do
that
and any time I push anything to the
master branch it will build a new docker
container with the tag latest with you
know all of these all this info and
it'll push it to docker hub which which
we had over here you can see my my tags
here my latest tag pushed eleven minutes
ago so and that's it so I can hit save
and build then it would build again but
but I've already done that so we'll do
save and that's that so now anytime I go
back out here and they'll change the
readme in the interest of saving time
okay and go back over here and I don't
know if it'll happen that fast but yeah
it will then master so it detected
you know the hook came from github and
if we go in here it doesn't show it in
the UI here but if you look in the
timeline you can see that it's actually
it's cloning it from github and and it's
going to start up it's actually going to
build it on one of my servers which
right now is I only have one running so
it'll it'll set up the whole build
process on there everything essentially
everything I just did locally the the
local build and then docker push and
push it up to the repo to the docker hub
repo and then if I have that brings me
back to that on this stack file
configuration if I have auto redeploy
true when a new version of the container
hits docker hub it will auto redeploy
this app so that's optional and and
potentially dangerous maybe not if it's
a staging server though but but if I
guess if you have tons of tests running
then there's nothing dangerous about
that right so the last little bit is is
- so you can see the no replica set
version worked I'm gonna go ahead and
terminate that so I can free up 480 on
that server and and then we'll go to
create stack and the same thing with a
replica set and again this is all in all
in that repo and you can just copy and
paste this whole thing it's the
configuration again it's configuration
for the Mongo replica set and then
basically be almost the exact same
config
the app itself go ahead and copy that
paste in here I'm gonna just create
stack tell you why in a second let me go
ahead and create stack which means not
start everything and because sometimes
the app can come up before Mongo is
ready we're gonna manually start start
this stuff so we'll start the first you
know the the secondary and the arbiter
and make sure they're up and running
which should only take a few seconds you
know hit the primary that should only
take a few more seconds than the other
two the only reason that one takes a
little bit longer is because it actually
has to configure users and replicas set
configuration that's all kind of
happening right now
and then I usually give it you know
maybe 10 seconds or so before before I
start the app in this particular case
like that I know it won't have to
download it again so I'll go ahead and
start there while we're waiting for that
we'll go look at the Mongo primary here
and uh and you can see in the logs that
are flying by here I'll back up a little
bit to the beginning where it first came
up and and now the environment variables
I passed in in my stack file
configuration are what was used to
configure the replica set this is all up
with a set configuration stuff going by
here so it's communicating with the
other to the other two containers up
here and go look at the stack again and
the two views app appears to be up let's
go look at its logs just to make sure
yep and go back to the stack I'm sorry
go back to the the app container get its
endpoint which is again what you would
point your domain name at and there we
go it's a it's a meteor app pointed at a
three container Mongo replica set again
with the caveats that the data is
actually but the databases it's inside
the container so it's not what you would
want to do you'd want to
actually have that exposed and staying
on the host or getting you know sitting
in a data container but the the
essentials of that whole setup is the
same no matter what it's more or less
just to demonstrate how you would get it
up and running but persisting data is
it's kind of a whole other talk by
itself so oh so alright so in recap
there any time so now you actually don't
need to manage you don't need to manage
docker manually locally anymore so you
would you would develop your app like
you normally would
you would know commit get push and and
once it hits github the rest of the
stuff that's it it's done so docker
cloud will then clone your repo it'll
build a new docker container it'll push
it the docker hub and then it'll deploy
it from that image from that from the
new version on docker hub out to your
server so so at this point deploying is
as simple as as git push and yeah yeah
so sorry went a little long there but I
was I was worried I wasn't gonna have I
was gonna have too much time left over
but I feel like I could talk for another
hour on any one of these topics on the
side here but um so yeah I guess why
don't we we maybe open it up to a couple
of questions that there's there's still
time for that yeah yeah well we can
record for up to 90 minutes so haha all
right is that a my stop okay you got yep
alright so the first question I actually
had is like what's the pricing on dr.
cloud you and I had a private
conversation but I think it would be
interesting to kind of discuss yeah so
it it's uh it's they do it they obscure
the specific price a little bit if first
of all you get they obscure the website
a little bit here I have to walk out to
get to their their marketing log out to
get to the marketing website but if you
scroll down cloudy calm if you scroll
down there is their pricing situation
here so your first server nodes in this
particular case your your your first
server is free so what I have running
right now is entirely free from the dark
cloud perspective obviously I am paying
for for digitalocean right now for that
server which I think the one I fired up
is like twenty bucks a month and I'm
also running everything on one feel like
right now I'm running three Mongo
containers in an app container on on one
server that's not not going to be
amazing performance but if I wanted to
fire up to do that exact same setup
across four servers the way it should be
the config would be with the exception
of one line per per item would be
identical so so the config items for
Mongo one two and three and app would
get a deploy tag so it's literally one
line in that yamo file that just says
tags and then it's an array of tags so
so I might do app so the app one and
then Mongo one Mongo to Mongo three and
then I would tag my servers with those
same exact tags and then when I use that
llamo file to launch the staff it would
put the containers on the servers that
match those tags and if it doesn't match
any it fail so keeps you from shooting
yourself in the foot but um but that's
how you would do a slightly more
complicated set up but kind of getting
off from the actual question being asked
here so two cents per server per hour so
what is that
time's day times a months so $14.40 a
month first surfer managed by by docker
cloud so not terrible but you know so
using my for server setup example there
that i just said you paying for three of
them obviously so so it would be you
know about 45 bucks
and that's not counting the server cost
so so for those of us that were using
totem for free for the last eight or
nine months it's a little bit of a
downgrade before I have I could have 20
servers up and it didn't cost me
anything but but obviously that was that
was you know a beta period perk so you
know not not terrible pricing and for
what it saves you from doing you know
like I said you you could you could do
that entire setup using docker tools use
docker swarm to to manage a cluster of
servers and you know just do the entire
nest from CLI but you know I think for
most people it's worth $14 per server
per month to not have to be that guy
unless you want to be but but I think
the majority of people it just doesn't
doesn't make business sense it is not a
trivial amount of things that you need
to understand to manage all that
yourself the other side of that is is
what comes with docker cloud is is is
you know there's a whole overlay network
so things can be across cloud providers
and it's on its own private encrypted
network and that's huge so you could run
you know your mom go instances in
different different regions and it
operates the same way like for those
that are familiar with AWS and their you
know their virtual private networks and
you you could essentially do that except
across cloud providers you can do it
within you know a bunch of digital
digital ocean servers or you could do
some digital ocean servers and some AWS
servers and
and have them all be on a private
overlay network so so there's definitely
some non-trivial stuff going on there
that that that would not be easy to pull
off yourself so so not it's pretty
justifiable price if that's some that's
something you need to do yes yes note
down there diversify your cloud indeed
that that's kind of one of the
attractive points of you know docker and
before it totem was was it wasn't
locking you into a specific cloud
provider you can obviously you could use
your own account and and you could use
multiple accounts so you know maybe you
have your staging environment somewhere
where it's cheaper or whatever yeah so
now so now what are the other options
dr. cloud so docker also has there it's
called Universal control platform and it
is a very new and it is a stealth hosted
essentially a self-hosted version of the
same thing
I got an early invite to it I I still
haven't gotten around to trying it but
I've watched a handful of videos and
read through some Doc's and it seems
like it's a bit early days and it's kind
of targeted at people who work in an
enterprise situation where like this
stuff will not cross our firewall and
and we have to have it inside so so it's
anyway that's that's that's one of the
first that come to mind but it's there's
so many I haven't even heard of yeah
every once in a while I'll stumble on
another one it's like they're there no
shortage of people in the business of
doing you know doctor orchestration and
service you know code ship just just
started just just started really pushing
hard on on there I forget the name of
theirs but yeah this is a there's a
whole bunch of them some of them are
specific to certain parts of the world
there's a couple of European companies
that only deal with data centers in
Europe and but for the ones that allow
you to use any class
and your own account it's it's a fairly
short list I think but but there are
there are a ton of them for sure and of
course that was just gonna say this
there's this Rancher - and and that's
actually kind of been most of my my
focus and in the last month or so and
those are familiar rancher is is
essentially an open-source version of
what you just saw with with dr. cloud
it's it's self hosted so so comes with
its own sense of responsibility in that
department - you know so it's so it's
pretty an open source but but you kind
of on your own we're with dr. cloud
somebody else is working out how that
whole platform works but but it does it
does work well I've used it quite a bit
and I'm in the process of building more
tooling around it for for launch doc and
yeah that's probably one of the one of
the next biggest ones biggest ones out
there but kind of falls into its own
category because it's because it's self
hosted and requires a little bit a
little bit more DevOps background - to
just support it so of Aldus asked how
long does the app with docker and is it
possible to make it with zero downtime
without using a load balancer without a
load balancer no yeah no you essentially
are you would have multiple versions
obviously at least and basically down
put a new version of it placed load
balancer switched to there now you take
one and and that's how you you know zero
downtime saying that's one of the ways
you do it but one of the things that
comes with dr. cloud and totem and
rancher is is a really highly
customized tightly integrated version of
AJ proxy
specifically for that use so the whole
docker cloud and cuttom dashboard
everything is kept up-to-date real time
with with WebSockets there and their
entire state of everything in your
account is accessible via WebSockets so
they're customized version of H a proxy
also has a WebSocket connection to the
API for your account and when you add a
new stack for a given app I'm sorry will
do add a new instance for a given app or
remove an instance a tree proxy gets
updated real time so adding in some
containers and scaling up and down the
configuration gets updated instantly so
yes the short answer you can't do it
without a load balancer but implementing
a load balancer on any of the of the
platform's I mentioned is pretty
straightforward it's kind of a
first-class feature that they've made
really easy it's also how you would use
ran out of time on SSL setup or
description of SSL setup but that's also
where you would terminate SSL is in you
know you basically paste paste a PEM
file in an environment variable box and
and click Submit and and that's that
it'll serve up SSL certs based on based
on the hostname being requested so you
can have any amount of them so we could
have a load balancer with 10 different
apps behind it each with their own SSL
cert and they each just get passed in to
environment variables it's it's it's a
lot more approachable than getting into
the server and doing it yourself the way
if you've ever set up as ISO manually
before it's way easier than that it's
really just copying and pasting that
into a into a form field and
submit and that is not really the case
when you manually set up agent proxy and
ten apps all with different domain names
and you manually editing config files at
that point all right last question so
thank you Jeff cuz I answered everything
yes sorry to spread the content so thin
there I thought I just it was I wanted
to kind of get the whole end and saying
but it's it's you know the more the more
details you add to it the more
explanation it requires so it was trying
to fit it all in there so you can know
once once you get through that whole
setup process and again you can use that
repo as a starting point of seeing the
base configs and you should be able to
take those same docker configs and put
them in your own app and it should work
exactly the same way assuming you don't
have any kind of special dependencies
you know specific to your app but even
then adding them in there is is it's
fairly trivial and then and then after
that you don't even have to build the
containers yourself anymore you can just
push to push to github and it just
happens for you and then optionally
deploys too so nice it gets a lot easier
after that initial hump
well thank you Jeremy sure thank you
glad that we were able to fit it in and
thanks again for everybody who took the
time to come back out check it out yeah
yeah all right thanks guys this video
has been a space dojo production you can
click the learn more button to find out
more about us at space dojo com or you
can click the subscribe button to get
notified about new videos we put out
each week thanks for watching
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>