<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Clojure Data Science - Edmund Jackson | Coder Coacher - Coaching Coders</title><meta content="Clojure Data Science - Edmund Jackson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Clojure Data Science - Edmund Jackson</b></h2><h5 class="post__date">2013-02-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/RVmY2lQ4DHE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">oh okay way to make me feel welcome
that's awesome
okay so I'm
Jackson I'm an independent consultant I
do statistical stuff and data analysis
I'm here to talk about doing that in in
closure so they design sanctorum so
let's start by defining our terms
what is data science or what is a data
scientist and a wag on Twitter once said
that data scientist is an analyst who
happens to live in California and I
think there's a lot of mileage to be had
in that one actually but there there is
something new and there's something very
old as well let's start with the old
because this is closure like like our
roots when you think back to what did
they designed to be in fact it's that
realm of endeavor that requires
simultaneously advanced computational
and statistical methods so you have to
do both of these things together at the
same time and I think that's sort of the
defining thing and if you define it that
way I you think that you know Alan
Turing he started the whole of computer
science for this very purpose I mean he
was trying to decode German codes in
real time you know under conditions of
bomb falling duress and that was what
what inspired him it wasn't long Katz
you know it might be hard to believe you
see the internet these days but that was
the start of it and you know this
tradition has continued things like
atom-smashing at the LHC or Radio
Astronomy protein crystallography all
these are scientific endeavors that
require both very advanced maths and
very advanced computers working together
to solve a problem so it's been around
since the beginning so what's the
excitement what's a new thing all those
examples I've given you have required
billion dollar government research
budgets and armies of PhD zealots to
solve them and what's new now is that
that's no longer the case the advent of
things like computing platforms which
give people very powerful computers to
do large-scale calculations open-source
platforms like our which give you the
tools that you perform statistics in the
hands of every man and large amounts of
data of accruing in private companies as
well as being opened up from the public
sector to do statistics over all of this
is democratizing this activity and
that's the excitement it's kind of like
the early days of Linux where you know
the stuff came out and people could just
hack on it
you know you know the the original UNIX
high priests had a bit of a giggle up
their sleeves but they were wrong right
and it's the same here like the stuff is
coming out it's in his early days and I
think it's gonna revolutionize stuff so
let's let's talk about analysis yeah
right so what are the how do you summon
forth knowledge or understanding from
within data what are the tools this is
the sigils of doing that and like the
first spell would be Excel and yeah I'm
not kind I'm not really joking about
that it's like a an interactive
functional reactive programming language
with a an embedded math DSL and
graphical capabilities you know what's
not to like you know it's the most
widely deployed analytical platform on
the planet the trouble is it's a sort of
possessed by this demon Paperclip who
will like turn your floating-point
numbers into dates and like not tell you
right they've got a completely opaque
computational model I mean you know the
spreadsheet now takes ten minutes to run
why there's no way to find that out
right so more serious tools or things
like MATLAB which grew out of linear
algebra that's very good that's doing
that sweating fast it's very big in the
engineering community Mathematica which
is symbolic manipulation so symbolic
integration differentiation that kind of
thing are which grew out of stats and
then sort of them more specialist tools
like SAS and Stata
but they're not really programmatic so
that's like sort of one group of tools
that are used to do analysis and the
other stuff is like C++ all of the the
heavy lifting is often done in C++ and
the you know the heart of darkness
itself Fortran which underlies most of
the rest of them in fact very frequently
if you go deep enough down the stack you
find Fortran there okay so these things
solve one part of our problem so they
have like a mathematical abstraction so
they give you an interactive environment
and you know like that talk we saw
yesterday about the the neural networks
that's absolutely critical for doing any
sort of mathematical exploration you
have to be able to poke your data
prodded it throw some curves up change
it you know play with it and see what's
going on you can't do the Gilad as a
cynic run on any visualization as part
of that then the actual tools that they
provide you
things like linear algebra statistics
machine learning and optimization all of
those are available libraries in these
sorts of platforms but that's not enough
for data science data science is more
than maths its data right so you have to
be part of an environment or a context
like either you have a large amount of
data and you have to get it or you're
within a business process so you need
more than mathematics you need to be
part of reality plugged in and that's
the second requirement which is platform
okay firstly you need speed I mean that
that goes without saying but then it's
data data data right the analysis like
previous things like your mathematical
platforms it tends to be a case of
someone will give you the spots of data
and you go in the corner and you analyze
it then you come back and you tell them
the answer and that's not really
applicable for data science because the
data is coming in and you got to embed
yourself in a business process or keep
up with it and so you have to deal with
things like XML and what you going to do
with XML in MATLAB you know put it into
a matrix it's just better off you need
zippers right you need proper data
structures to perform the analysis in
its native native way it's speak on its
proper level you need the ability to get
at the data so proper access to things
like databases queues REST API is all
that kind of stuff this is not really
available to something like Mathematica
you just just it's not there in addition
because you're part of a larger context
you're not hiding in the corner with
your box of data you need to have
end-to-end quality control so things
like tests integration deployment
monitoring so data science requires both
right you need the mathematical stuff
and you need the platform stuff and
that's sort of not really available in
your traditional things I mean they kind
of segregate out like that and the
reason is our demon friend complexity
right so if you're working in C++ and
you're having to worry about buffer
overruns you can't be worrying about the
condition number of your matrix at the
same time you just you know very few
people have the mental capacity to do
that they exist but they're kind of rare
so on the other hand if you're working
in Mathematica and it's given you the
tools to perform an American to grab I
mean a symbolic integration it probably
doesn't give you handles to make that
thing fast or to get to the grips to get
to the nitty-gritty
because
getting it away from you so compromises
have been made and it sort of it
separates out it according to that curve
the more platform power you get the less
analytical power you get and vice versa
so you have this situation you have two
layers you wanna get to the top
analytical stuff gets you halfway up so
you can analyze your data and get an
answer but now you can't scale it out
now the hand you've got your C++ if you
have your answer you can scale it up and
do useful things but how do you get it
right and you know this is what's me for
a long time trying to solve that problem
now this is a crying need so obviously
there is an existing answer and then
answers is Python the Python community
has really stepped into this they've got
a really nice virtual machine which
gives you good access to databases and
it also has strong libraries like numpy
and sci-fi that gives you good
analytical capabilities so they're
really like forging ahead and they're
getting a good following in this
particular domain for that reason
because they sort of in that sweet spot
but you know the serpent is never to be
trusted and the reason yeah I like
Python really the reason is this I mean
what's the difference between this and
this I mean you know Kevin will be into
that I mean it's all about typography
right written like that that's later and
I'm talking about maths there I'm
talking about programming and this is
like it's subtle and it's indicative of
a fundamental rift in in the ideology
and something like an ideology well in a
programming language sorry in
mathematics this makes sense if you only
if X is an infinite value it does make
sense if excellent that that's true in
an imperative language that makes sense
whenever X is a number and in perl
whenever X is anything right so the
point is like putting aside like
differences between equality and
assignment I know these are different
things there's a fundamental
disagreement between the model the
domain you're trying to think about it
is mathematics and its mode of
expression in a language and that's a
difficulty when you work in an
imperative language you're doing this
you're building the machine to solve the
problem rather than solving the problem
itself on its own terms so you're saying
you're trying to decide how is this
machine going to work and the lever
turns three and a half degrees and it
shoots the toast up to the two can and
I'm not sure what happens next but the
point is you
what you program is the machine is a
description of a process and the
nitty-gritty thereof rather than being
in the domain of your problem which is
the mathematics itself so it's like
logic programming you want to be in the
domain of the logic describe their
logical operators rather than the search
itself so that's problem number one
problem number two is that you know it's
got mutable data so I want to spend long
wait this is like old old hat here but
it's like you have this data but people
can change it so you worried they're
gonna squish it so you can't hand it
around so you lock it up into something
and you hand that around but now people
can't get to the data so you have to
give them some way to gather data which
you just locked away and so you you
build these elaborate patterns and I use
that word quite specifically around the
data and what you end up with is like am
this some Faberge egg with a toffee
Center at the middle and the problem is
that that's like giving yourself extra
trouble to deal with you want to deal
with the data as data like in its native
format you want maps and hashes and
vectors and and that kind of stuff so
you need to have functional programming
I mean we know the answer to these
problems both of them because it gives
you a mute ability and it changes the
way you're thinking about the problem
such that it's closer to the Matz the
domain that you're expressing and it's
mode of expression are much closer
together so it's a natural expression
and it makes you more able to deal with
mathematical problems in addition you
have the serous data abstractions you
know I spoke earlier about zippers for
XML but in any of these sorts of things
you need to have proper ways of dealing
with the data on its own terms rather
than behind some kind of a wall the
Select solving the mathematical side but
you need that on the platform as well so
you need to have it in some sort of
powerful thing that gives you the
ability to connect to business processes
data sources and to have quality and
there's a group of languages that
satisfy all of this you know you know
closures one of them Scala F sharp or a
couple of other ones and the simplicity
dividend that they yield as a result of
being functional allow you sort of cross
this event horizon of complexity and
there's a large amount of mileage to be
had in learning these things and solving
problems like data science with them
okay so that sort of like the the
fundamentals why is I closure
intrinsically useful for solving this
kind of problem down to practicums you
know what particular things was closure
bring to the party so in its native
native closure you have a bunch of
libraries like in can
we saw a lot of that yesterday we're
throwing up curves interacting with
things basic statistics basically in
your algebra this gives you a very long
way then for like large-scale problems
storm for distributed computation
Casca log has a nice day log abstraction
over Hadoop atomic for bringing the data
into your process so that you can handle
it like locally and it's a bunch of
other stuff but these are like the
leaders now if you're trying to solve a
problem and your library doesn't exist
in closure you can reach out to the JVM
and get it there and what what what
exists there for for data science type
problems well I've mentioned Hadoop
already but it's closed over by Casca
logs so you would want it like use that
natively mahouts I'm a hood from out I
don't have pronounced that's a machine
learning on Hadoop and that's available
on Java and you can get to it easily
from from closure and they're a couple
of really fun blog posts about that the
the good part about that is is you can
run that from within your closure system
call out to my house get it to do the
analysis bring back the numbers and see
them in your graphs in your interactive
environment and like natively you can't
do that that's really powerful Weka is a
long-standing machine learning package
from I think it's Waikato University in
New Zealand which has got lots of very
good machine learning type things there
are others like in cog and stuff out
there Jai PLAs is linear algebra it's a
very nice compromise between calling out
to Fortran on the native platform and
keeping things in Java so you know Zack
was speaking yesterday about the
difficulties of this and I don't really
know that much about it but it's
massively difficult when you want to
move numbers off the JVM in order to get
native speed you have to copy them out
and that's like an order in operation so
for linear time things you keep them on
the JVM and solve them in Java and if it
doesn't exist on the JVM what you're
trying to do everything talks to the JVM
so you can take one step further out and
use a J&amp;amp;I something like our encounters
a good example you can actually like
take a closure data push it across to to
our get the analysis done in our and
pull it back in again I mean it's a
massive performance penalty and not many
people are using it so it's a little bit
shaky at the moment but it exists and
I've used it successfully for real
problems right so closure solves all
these problems it gives you everything
there are a few things that are missing
like optimizes you know we don't have
really a good answer for optimizers yet
but your tools are there your
mathematical side is there
your platform is there gives you speed
and good language constructs good data
abstractions and concretions that's a
good answer right so okay let's like
part one of the talk sort of like the
hand wavy everything is awesome but you
know let's actually like get done some
brass tacks and and and see some code so
I'm going to start by going into one of
my favorite tools from information
theory which is entropy and it's not
very widely used as far as I can tell
and I thought it'll be a fun crowd I
thought you might enjoy a bit of an
adventure in that so let's start with
with English money it's it's different
to American money it's worth more for a
start but more than that because when
you flick an English coin it comes up
heads 60% of the time and the reason is
because Her Majesty's profile is on
there and she exerts a certain royal
prerogative to be seen more frequently
alright so if we're playing a gambling
game with English money and I'm thinking
the coin I'm gonna say you know what
happens you'll predict heads will come
up because the 60% probability of that
occurring so you predict heads I flick
it again it's an independent event when
you make the same bet right a third time
you make the same bet right 10 times
right something smelly right this is
this is the sequence of the tin or what
sorry this is the single sequence of ten
flips of this coin which is the highest
probability but intuitively you can
smell as something is wrong here right
because you're expecting 40% tails in
them and indeed if I flip one of these
heads to a tail my total probability
does go down and the mistake is thinking
that we live in the world where the most
probable thing happens yeah this is like
common sense this is not how the world
works what your intuition is telling you
is that these two distributions don't
match up so you've got your generative
distribution is what you expect it to
happen
60% heads 40% tails and you can express
that as this histogram or this density
here which says this event heads has a
probability of occurring of 60% and
tails here of 40% and what I saw was
100% tails so your intuition that
something is smelly here is that these
two distributions are not the same as
some difference between them and to get
a mathematical handle on that web to
take a step back and we have to talk
about unexpectedness
like the Fancy Pants word is self
information
but all it is is if you have an event
that's a particular probability P - log
2 of P gives you the unexpectedness of
that event so if you have an event which
has got a probability of 1 it's totally
not unexpected so there's an unexpected
miss of 0 if I flip my coin and it comes
up heads there's the probability of 0.6
so it's over here it's not really
unexpected 40% slightly more unexpected
if I flip the coin and it quantum
tunnels through the floor in front of my
feet well that's kind of unexpected
right so it's got a it can happen but
it's got a very high unexpectedness so
that's like the the first unit of that
now as a single event but let's talk
about collections of events or
distributions if I have many events I
can describe it as a distribution and if
I take the average of this
unexpectedness that log 2 of P over the
whole distribution weighted by the
probabilities so minus P log P I get
this thing called entropy fancy word for
unpredictability so it says if I have a
distribution what's the unpredictability
of drawing things out of that
distribution so if I have you know
equality loving American money 50/50
chance heads or tails is totally
unpredictable when I flick it will be a
head or a tail this no there's no edge
in gambling on that where it's like with
my English money it's slightly more
unpredictable so it's unpredictable
sorry it's slightly less unpredictable
is more predictable yeah triple and
double negatives always tripped me up
right so this thing is slightly more
predictable so it's got a lower
unpredictability and therefore a lower
entropy my coin which came up a hundred
percent of the time it's totally
predictable so it's got an entropy of
zero so in summary minus P log P gives
you the entropy of a distribution which
tells you how unpredictable draws from
their distribution arm and you can say
okay I can see now these distributions
have some difference between them can I
get a closer handle on that and indeed
you can with a thing called relative
entropy so it's the last mathematical
slide I promise right so instead of
minus P log P it's just P log P over Q
where you have two distributions its
distribution P that is distribution Q
and your average over each element from
that so to get the relative entropy
between these two things it's P log P
over Q where like no point sells no
point six times log no point six of a no
point 6 plus no point four times no
point four over no point four right
those come out as 0 so the
between these two distributions is zero
as you'd expect cuz of the same
distribution if they're different
distributions the number comes out as a
positive number so like long story short
this is the lead this is the the
important thing relative entropy is a
simple equation and it allows me to take
the distance between any two
distributions of any parametric form it
doesn't have to make any clever clever
assumptions about them provided they're
over the same space so it allows you to
ask very general and open questions
about distributions okay so that's a
summary entropy is the amount of
unpredictability of a distribution and
relative entropy is a distance between
two distributions on the basis of their
unpredictability okay so that's the the
mathematical abstraction so we've got
some some cool maths that's like the
science part of the data science let's
now see how do we express this in
closure so I have some closure over here
here's some I cooked earlier and of
course Emacs is gonna fight with me now
come on you max you know you want you
can everyone sort of see that to some
extent yeah so okay let's let's go
through it I mean I can't actually see
this on my own screen so I'm gonna have
to rearrange things a more mature okay
so let's start off by getting some
something on my screen okay so let's all
up with some random numbers I have a
million random numbers and they're in
this vector called peas and I want to
say well how would I calculate the
entropy of that that that collection the
most naive thing to do is say okay first
let's define a function entropy which is
just P Times log P direct translation
from the mathematics and now I want to
go over the entire distribution so map
entropy over peas and then reduce with
plus so that's Sigma P log P all right
and if I take very benchmark that up
until yesterday I had a somewhat
different code it just said time in the
front there but Zack Tellman told me
told me better so if you actually run in
proper benchmarks you'll see that on
average that takes 50 milliseconds to
run over a collection of a million now
you say okay well that's nice
let's try do a little bit faster so that
close you give me a handle which is okay
I can't use native Java arrays to make
it faster so the code changes slightly
here it is it's the same thing as
expressing a reduction
over the collection piece right whoops
one-handed Emax nice okay so you get the
elements from the collection and reduce
over its adding it to the accumulator
res if I cry if I benchmark that you can
see I've half the time to about 25
milliseconds if that's not good enough
we can use the most awesome reducers who
reductive know reduces the reduces
library and that gives me access to the
fork-join queue so I can take this thing
break it up put on to a full thank you
and use all of the cause I mean this is
this is a laptop right and it has like
eight virtual cores on it this is like
we got to get get real with us reduces
giving that power and I can take the
calculation time down to eight
milliseconds that's a huge reduction i
absolutely massive encouraged it gives
me that handle so I can write my maths
cleanly and I can make it go quickly
that's that's that's huge so to compare
it oh yeah there's another one I could
try and look at the the native Java
implementation so so so cat ryx is a J
blast wrapper but because this is a
linear time operation it doesn't
actually go off the JVM a actually write
it in Java and so this is an expression
what it does is it takes my what I've
done have taken my million numbers turn
them into a column and then I have
applied log element why is that
collection and then taking the dot
product between P and log P so just a
different way of expressing the same
maths doctors kind of like a
mathematical reduce when I benchmark
that I get 25 milliseconds which is
exactly the same number as I got when I
wrote the Java array reducer which is
what you'd expect if I compare it with
with stuff that's available out there
MATLAB you know 12 milliseconds so on a
single core it absolutely smokes us and
that we should expect because it's able
to to call out to Fortran natively but
because it's only single threaded and I
can call on eight threads aventure can
kick its ass right are 16 milliseconds
is slow and Mathematica at 7-7 seconds
it's not a fair comparison because it's
doing everything symbolically I would
put Python in here but I don't even know
Python well enough to put a benchmark up
and I would hate to be called out and
have nasty things said about me on the
Internet
so so that's like okay this is the point
of the slide to say okay I can express
the math cleanly and I can make it go
quickly
so now let's um take the next step let
us look at excuse me one moment how
would I actually define that that's like
timings so now here's my made a
namespace called entropy and I got the
same thing in entropy and a function
bits native log function is based hence
I don't need to convert all my answer to
base two
so they're expressed in bits so you can
ignore that I've got two main functions
entropy resentfully of a distribution
and that's using the same code I showed
you earlier using the reducers and then
you know I was talking only about
language constructs and how important
that is you know so closely gives you
pre and post conditions so I can easily
mix my maths with some production type
stuff like pre and post conditions and
improve the quality of my code I can
define relative entropy for giggles I've
done that using J blasts and it's the
same thing it's like here's a function
number with P log P over Q and that's
expressed very key media so you divide P
by Q take the log in the dot product
Sigma P log P log of the Q so the way
these functions work is they've taken a
collection of numbers P and they
calculate the density of that so the
density is just a map that says how many
times each element occurred in P right
very simple so here are my two functions
right the point of the slide was simply
to show these things to show that
closure gives you beyond normal
mathematical stuff more powerful
language features now let's connect you
to some data so set of DB funny you
should you expect me to use Potomac in
my demonstration yeah so I've got a very
simple example here so I've displayed
some maths I just played how to write
code about it now let's make it real and
connect to some real data so I've got a
very simple problem here they say I'm
running a bunch of servers that produce
responses and I want to know when things
are getting freaky on my server farm so
I have a simple database it's got one
entity which is a response there's two
attributes which is that's romantic
okay Manny loves his work but honestly
it's got two attributes which is a
server which produced the response and
the time of the response in milliseconds
so just its simplest thing I could go I
don't wanna get wrapped up in all the
complexity of databases so that's a very
simple thing and you know I've made some
data and I've put it into the database
so let's go have a look at some queries
over that okay so I connect to my
database I see if that's working yeah
okay that was a false little bit
whirring okay and now there's also some
substantive questions so I have I have
this data in my database I want to see
now something going wrong so what I can
do is I can grab all the responses so
this is a query says get me all the
responses and the times then aggregate
up this is a new feature inter Tomic
kind of cool so you can aggregate by
server ID and the collection of response
times did you get him pass into the
average function so if I do that you
look at the bottom that's the answer
that comes out so it says I've only got
four servers that I could fit it knife
into the mini buffer server one and a
mean response time of 52 or 53 or 50 and
4 or 50 so the means of these things are
pretty much the same I can do the same
trick and look at the variance and
they're all roughly the same as well
between 19 100 so the point here is I'm
asking a closed question and I'm just
asking a very specific about these
distributions or the means different or
the variance is different this is like
high specific I'm assuming things about
these distributions and as you can
expect like if I ask relative entropy
that's a much more open question to us
because there's not assume anything
about this stuff so how would I do that
well I'm gonna take the relative entropy
to the population so I'm gonna say okay
Sigma P log P over Q I'm comparing two
distributions P is my my population so
if I take all the responses that I've
got in my database and then compare the
response from each individual server and
measure the relative entropy between the
two of them so my earlier slide the
population is the red distribution the
top and the blue ones the bottom are
each individual response I can work that
out so how do i express that in closure
well here's the atomic query that gets
all of the response times and then I
partially apply that to relative entropy
so
eventually you'll remember perhaps us to
leave and work yeah how about that
relative entropy it's a function it's
got two arguments and the two
distributions P is my distribution over
the response times of all the server's
so I've found that in and then I give it
a name so I just bind that to the
functionality of entropy and now here's
here's the lead I can now take this
function and pop it directly into my des
Tomic query so now the Tomic has got my
data locally and I can pass this to my
function using reduces or native J
blasts whatever it is and it like it
just meshes together it integrates
that's like unparalleled power so I said
look that's what does it look like
okay so the difference from one entropy
of one is 0.32 is 0.33 is 10 + 4 is 0.2
do you think I've cooked these numbers
so that comes out this way right so
there's something on something's going
on with the server number 3 and this
point know what it is but because I'm in
an interactive environment I can just
pop up densities so 3 is different so
let's look at what the distribution of 1
2 &amp;amp; 4 are so I get my query from my
database I just change its format
slightly calculate the density and then
view it and it looks kind of like a
normal distribution right so now let's
see what ooh let's see what number 3
looks like this is the one that had the
faulty answer all right look I just
changed up I can interact with my dadís
at the point I can play see things and
oh my look at that what question do I
need to ask of data to say is a thing
bimodal like how would I even frame that
question initially whereas something
like relative entropy just it just pops
out this distribution doesn't look like
the other distributions and that's kind
of like a an awesome thing for for data
science because that's the kind of
questions you want to ask like is
something freaky going on like what's
interesting what's different and this is
by asking relative entropy type
questions you can ask that very cleanly
and openly ok so that's my demonstration
and let's go back oh let's go back I
said right so in summary you can take a
pretty abstract concept like relative
entropy you can express it clearly in
the mathematics enclosure you can it get
a handle to make it go quickly you can
put it on a platform connect it up to
data you can take the data you can
interact with it all in one platform and
that is like the power to rule the
universe well maybe in my mind right so
the ladder enclosure is slightly
different to other ones it's got the
same number of rungs
but unlike the rest it goes all the way
to the top the trade-off is that the
distance between the wrong is are higher
so it's slightly harder to do each
particular thing but it gets you from
from all the way at the bottom to all
the way at the top
what's missing like native libraries
that buy meat which I mean late closure
native libraries we need a lot more work
and stuff in there you can get it stuff
on the JVM but it's kind of ugly and non
idiomatic we need more of that
particularly in things like optimization
and statistics numerix we have no hope
right like that's kind of a trick buy it
by using the the multi-threaded Ness
because we're on the JVM we're never
going to get native fast numerix and
that's just like something on the JVM
you're gonna have to deal with it's just
a trade-off that's being made so what's
the future in the near term more
libraries and ports hopefully that's
what those are going to be produced as
people start uses more and more session
which is a great library from Kovas I'm
not gonna steal his thunder but that
integrated with what I'm talking about
is incredibly awesome in canto 2.0 I
think encounter could be like one of the
killer apps on closure and it's it needs
a bit of love at the moment so I'm
hoping that that'll pick up in the
medium term what can be done
probabilistic programming kind of my
bugbear
so from realistic programming is well
what logic programming is to deduction
for realistic programming is for
inference so instead of having variables
that are logic variables they're random
variables so they're drawn from sets and
associated with not probabilities so
each variable represents one of those
distributions that I put up earlier and
you can then ask probabilistic
operations of it like to marginalize or
condition and these sorts of things if
you can express them cleanly in closure
would be an a massively powerful tool
now there's an implementation that
exists in scheme of course called Cech
which we could use as a template for
that and you know I'm told there are
also things in C Connor and mini Condren
that allow us to do this so I think some
some attention and work there would you
massive dividends so if this is also
awesome and cool like who's actually
doing it right here's a company it's
called Zen robotics it's based in
Finland and what they do is they buy
these robotic arms just the hardware
from Germans and they fit them out with
AI so what they do is they thought
recycling so the robot at the top there
has a camera on it and the the belt
below goes by with recycling waste and
it separates out plastics and metals and
all those sorts of things and the whole
thing is done enclosure there's a
hundred and thirty thousand lines of
closure in this company running these
robots and that's like the biggest
closure company no one's ever heard of
they they've just raised 13 million
euros to scale out and you know I for
one welcome my robotic overlords that
are high on Lisp
that's brilliant right but this is kind
of like we're where we are at the moment
with this closure ecosystems like for
the wizard level problems it's a very
very compelling story but for lower
level type stuff where libraries exist
we're not really there yet because
people can easily reach out to something
like Python and get the stuff done there
and if we make it easy to reach out to
closure we will enable them to make much
higher and more difficult analyses
possible so finally just a quick punt
myself this new collaboration between
Crystal grand Michael Brandon Maya Sam
Aaron and myself called lambda next I'm
going to be providing some closure
training and consulting services in
Europe so I hope if that would be useful
and helpful to you you'll reach out to
us thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>