<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Playing Go with Clojure - Zach Tellman | Coder Coacher - Coaching Coders</title><meta content="Playing Go with Clojure - Zach Tellman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Playing Go with Clojure - Zach Tellman</b></h2><h5 class="post__date">2013-01-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/v5dYE0CMmHQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey I'm Zack I work for factual and
we're gonna talk about a little board
game called go quick show of hands who
here has played go oh this makes it so
much easier okay uh anyway we're gonna
do a quick refresher so go is played on
a board with intersections typically
anywhere between nine by nine to
nineteen by nineteen stones are played
on the intersections first black then
white and each of these stones has what
has liberties liberties are empty
adjacent intersections and when you play
a stone in one of these liberties this
is extending the group these contiguous
blocks of stones in the same color are
now one big group and when a group loses
all of its liberties ADA's remove from
the board and the capturing player gets
a point for each stoning of the board
but also gets a point for the enclosed
intersections each enclosed intersection
is one point and so if black here has
enclosed the corner intersection it has
a point and white cannot play in that
intersection because it would have no
liberties this would be effectively
suicide however if white completely
encircles the black stone but for that
one point it can play in that point and
thus remove the stones now this may make
it seem like go is just a game of
encirclement and Riaan circle management
all this other sort of stuff but if
white plays here even if it's fully
encircled black cannot actually move
this in the board because in each of
these two liberties Oh black cannot play
in either of them right it would be
suicide for it to play there so this
white group is stable it's safe and
that's because it has two eyes or two
liberty is that it's completely
encircled and so go is not a game about
capture so much as it is about trying to
encircle territory in a stable way right
and so it's less a tactical game and
it's more of a strategic game and so
what you'll see is when the game
develops what it is is it's a series of
right by playing one space to the right
black here is sort of implicitly
claiming the right side of the board and
white can have many responses this it
can play to the left thus effectively
sort of ceding that territory though
that may develop over the course of the
game it could play above claiming the
top of the board and seed in the bottom
it could even play within the territory
effectively being claimed by black kind
of stating that it can create a stable
group before black can encircle it and
as the game develops you'll see that a
lot of the territory isn't circled and
not contested right this is the ending
position of a professional 19 by 19
board they haven't really gone and
played out all these territories because
it's not necessary right they kind of
understand that they stand more to lose
by sacrificing a bunch of pieces in
those territory then you know trying to
actually fight over all of it and I
don't recall who won here I think in my
bed white or something but at any rate
uh we want to write a program that plays
go right and I'm interested in this not
because I think I have any neat
contributions to make to this field
right I enjoy go I think it's kind of a
beautiful game but I'm not particularly
good at it I studied this a little bit
in school but it's not something that
like again I have any real expertise
this is just something that you know no
one's really done before right and when
I say not done before I don't mean just
in closure I mean that people typically
write this in very low-level languages
like C C++ I think there are a couple
written in D but like that's as far as
it goes and you know maybe this is for
good reason you know certainly there are
some stumbling blocks here but you know
closure is a wonderful language for
exploration right for experimentation
and it stands the reason that maybe this
is something that you know would be
helpful for us to have this sort of high
level language to be able to kind of
span both sort of the lower level stuff
that closure can do but also the higher
level stuff the closure kind of excels
that so where do we start
most AI is search right and so when
we're talking about you know we're here
this particular position we want
make a movie want to make a smart move
the thing is that we want to search for
a move that will lead to victory
and so in tic-tac-toe we start with an
empty board and we say that this is the
root of our game tree of the the game
space that we're searching and we say
that the children are all of the first
moves all the initial moves that X can
make and then beneath that or all the
responses that o can make and that just
kind of continues down until we get to
the terminal positions to the end points
of the game and this is a space that
we're searching now if this were a
cooperative game if this were solid hair
or if we were playing together and
trying to be nice and all we would need
to do is search through for a path to
victory right just some sequence of
moves that would lead to us winning but
we're competing right and so we have to
assume that as much as we want to direct
the game towards this ending position
where we win we have to assume that our
opponent will be doing his damnedest to
make sure that we don't right and so we
have to optimize our chances for victory
given the sort of adversarial quality to
our search and the approach for this is
called minimax it was invented or
discovered back in 1930 by John von
Neumann and the basic notion is that we
search the entire tree we go all the way
to the bottom and we say that each of
these has a value according to its
outcome and in this case this is fairly
simple right we say it's one if it's
victory zero if it's a tie negative one
if it's a loss and we assume that the
player in the state proceeding that will
choose the best move for himself right
if he will direct it toward something
that's there and so we say that the
value of the node just shy of the ending
condition is equal to the best possible
outcome for that player and then we can
go up one more level and we can say well
the the player will clearly direct it to
the best possible for themselves and
from our perspective right we're
constantly maximizing the outcome and
our opponent is constantly minimizing
the outcome and from that we kind of go
up the tree and discover what the
optimal path of play is assuming that
both people are playing as best they can
and you know if we're able to traverse
the entire game tree this works we can
play a perfect game so you know for
tic-tac-toe we can do this pretty easily
there aren't really that many possible
tic-tac-toe games as has been done for
checkers as well in both cases
it's a tie by the way but you know for
more complicated games this is not
something that we can do this is not
something that's plausible we can't just
enumerate all the possible chess games
or all the possible go games and so we
have to kind of compromise and the way
that we compromise is we say well you
know this is still a pretty sane way to
talk about how we're searching but we
just can't get to the bottom so instead
we go down as far as we can and we look
at this intermediate game state and we
say how likely are we to win here right
and that's a difficult question to
answer and this is it requires not just
an understanding of the mechanics of the
game it's understands sort of the the
fundamental essence of the game this is
something where we require sort of meta
information more than just the rules of
this move leads of this move leads of
this move and this can be difficult for
a number of reasons one is that if we
say have a chess game and we start
counting pieces or something like that
then clearly we can optimize that we'll
have a certain number of pieces at a
certain depth of the game but that isn't
really a very accurate proxy for victory
right there there are pathological
situations where that can like direct us
very much in the wrong direction
similarly we can we have this sort of
horizon that we can't really see very
far into the future and this horizon is
kind of inversely proportional to the
cost of our evaluation function we can
something that's very rich something
that gives us a lot of information has a
lot of analysis that's done but then we
can only see so far into the future so
it's possible that a more naive
evaluation function which lets us see
further could be better
of course that's very difficult to
quantify and so this is sort of a
trade-off where we're trying to kind of
twist this dial and not really perfectly
understanding what the consequences of
that are and finally you know we as
programmers we write this code we write
the recursive search we write the
evaluation function but understanding
the local effects of this function is
not the same thing as understanding the
global effects of the repeated recursive
application of this function right this
thing that it that is pruning this tree
and setting us in one direction at the
expense of another and this is
a bit of a problem I mean this is
actually something which is horribly
frustrating because you'll see this
movie made and you know that it's the
wrong move but you know that if you try
to tweak your evaluation function to
make it so that doesn't make it wrong
move in that case it has untold
consequences elsewhere right and this is
this is sort of the essence of the
problem this is kind of wonderfully
frustrating on some level misses you
know why I am so interested in this
whole problem but you know all these
things apply to go to a greater extent
than pretty much any other major game
and the reason for this is that the tree
is enormous right on a 19 by 19 board
which is sort of the standard you know
size for a board there are 361 possible
moves and even worse the depth of play
the number of moves into the future that
a strong human player can see is fairly
large right and this is because the
board remains fairly static how many of
you have ever played reverse I or a
fellow so this is sort of a variant a
simplification of go and what this says
is if there are two stones of one color
on either side of a line of stones of
another color they all flip and what
this means is that three moves out the
board have can have completely changed
configuration and so it's very easy to
write a strong a fellow AI not just
because it's a simpler game but because
it's really hard for people to read very
far ahead
conversely go remains largely static
over time and so it's fairly easy for
people right basically we're uniquely
qualified to be good go players and so
this is remained kind of a problem and
historically
a lot of people have tried to write go
highs starting back in the 60s there was
a no prize for a while that if someone
could create a program that could beat a
low-level professional player by the
year 2000 it would get a million dollars
this is one of the Millennium prizes and
no one won right a lot of people tried a
lot of people sort of threw themselves
onto those rocks and kind of walked away
defeated and this is because it's a hard
problem and the computer part the
computational power wasn't really there
and so what they would do is they would
try to offset that by being very strong
players themselves and trying to
encode their brains into the program but
that you know only works the effect that
they can perfectly capture their
understanding of the game and this is
this is hard this is harder than I think
most people give it credit for and so
typically speaking this has kind of been
a bit of a backwater or sort of a
failure whereas you know chess has sort
of taken off and kind of capture the
imagination people go as remain this
sort of almost embarrassment in 2006 or
so if someone tried something new and
they use something called Monte Carlo
simulation and to sort of demonstrate
what this is imagine that we have a
quarter of a circle inside of the unit
square and we have a function which says
given x and y-coordinates this is inside
the circle and we have a function which
takes no arguments and simply says for a
random point between 0 0 and 1 1 is it
inside the circle if we just call this a
million times and then we look at the
ratio of truths to the number of sample
so we had that's PI over 4 or converges
on PI over 4 and this may seem like sort
of a trivial sort of clever math trick
but it's actually something kind of
fundamental what it is is it saying we
understand the rules that govern of
space and now we can begin to understand
its structure and you know in this case
it's fairly easy it's geometric we can
kind of say you know here's the space
that we're trying to sample but in
real-world cases this is sort of less
doable and so it's instructive to think
about what would happen if we didn't
really know that it was 0 0 to 1 1 what
if this was a little bit shaky right um
depending on where we skew this can
start to change the value quite a bit
right if we sort of skew down to the
left and all of a sudden PI starts you
know ballooning out and you can also
start shrinking if we go in some other
way and so the thing is that it's not
just that we do a bunch of simulations
we have a bunch of numbers and it all
kind of you know magically comes out in
the end we have to understand the space
that we're sampling we have to
understand these sort of dimensions of
what we're actually trying to search out
and so we can use Monte Carlo simulation
as an evaluation function we can say
from this position assuming that we
simply just play naive moves no real
insight of the game to attempt to make a
good move just
a move and we do this repeatedly tens of
thousands hundreds of thousands of times
and we say you know on average black
wins 60% of the time therefore this is a
stronger position this is kind of cool
because what this means is that we've
taken the rules of go no understanding
of go other than just these simple
mechanical rules and we have arrived at
a determination of what is a better move
right this is something which isn't
really clearly encoded in the rules
except in some sort of very sort of
amorphous way but we're not trying to
talk about the space of all moves that
can be done right you know if we leave
ourselves open to capture and our
opponent ignores that for the entire
game that's not a very likely outcome we
want to talk about plausible games we
want to talk about games that are likely
to be played and so if we go outside of
this range what is a plausible game into
the range of possible games this is
noise this is actually like sort of
dirtying our understanding of the space
and so this is a problem right this is a
balance we have to kind of do again this
is like the evaluation function a
heavier more computationally expensive
evaluation function is that the expense
of being able to see further being able
to in our case have more samples but
there's an additional thing which is
that you know for doing this hundreds of
thousands of times each new game gives
us more insight into the space that
we're trying to simulate and to capture
that to take advantage of that we use
something called a multi-armed bandit
algorithm and the multi-armed bandit
basically says we have a bank of slot
machines and we don't know what the
payout is but we presume that one of
them is better than all the others and
the problem here is that we can go
through and we can continue to you know
pull them all one by one and try to
build above the statistical model but
once we start to have an AI hypothesis
as to which of these is the best every
move that we do every lever that we pull
which is not the one that we suspect is
the best is that the possible expense of
our expected return right we have this
balance between trying to explore all
the possibilities and exploiting the
best known possibility and there are a
number of mathematical approaches of
this I'm not going to talk about them in
any deed
hell the one that is commonly used for
NGO is called the upper confidence
interval or upper confidence bound
method but it's important to understand
that if our probabilities aren't
changing over time as we're sampling we
should expect that we will converge on
the best solution or the subset of best
solutions so if we put these two things
together if we use Monte Carlo play outs
and the the multi-armed bandit this is
called Monte Carlo tree search and it
has basically four steps we have a tree
and this tree is only partially searched
only partially expanded out and what we
do is we go and we select a path and we
use the multi-armed bandit at each game
node each board node to determine the
next move until we arrive at a leaf at
which point we select one more move and
then from there we do a single random
playout using the Monte Carlo sort of
approach and we then take that signal of
loss or victory and we propagate it back
up the tree to all the moves that led
there and since a positive signal will
effectively give a greater weight to the
path that we took the assumption here is
that were going to have a very
asymmetric expansion of the tree which
tends towards the better moves and so
for the rest of the talk I'm only going
to talk about the simulation part of
this because this is sort of the
meatiest part of it and also from an
implementation standpoint the most
troubling so let's look at what it
actually takes to play go for each move
we have to select a move we have to
check whether it's a suicidal or whether
it's a valid move we have to update a
representation of the board we have to
check whether or not we've captured
anything and then we just repeat that
over and over again and these two the
the suicide check and the counter check
are similar problems and also are kind
of a little bit expensive potentially
and consider this kind of pathological
case here if we look at the corner
position black cannot move there right
that will be suicide it would make the
entire group disappear from the board
but to determine that we can't just look
at the neighbors we have to walk that
chain all the way to the top examining
at each point whether or not
you know it has any neighbors going and
continuing continuing they'll finally
find oh no this has a Liberty it won't
be a capture
similarly if white moves there it has to
walk the chain all the way up that
entire chain of black stones checking at
any point whether there are any
liberties and so if we have a very naive
representation of this board right which
is just you know this stone is here that
stone is here this point is empty this
becomes very expensive this is something
which you know we're doing a lot of
duplicated effort each individual move
to determine something that we may have
determined that the preceding move and
so the way around this is that we want
some sort of incremental state we want
to have something which is derivative
right is not this is not a completely
like normalized representation of it but
we want to minimize the amount of
computation we have to do it each
individual step and so when we put down
a stone we can actually keep track of
how many liberties it has right I mean
in this case you put down a black stone
and it has 4 liberties
we've down another black stone and now
we can say that this group collectively
has six liberties and rather than the
previous stone keeping track of its own
stuff it just points to the parent it
points to the owner of the group and we
place down another stone it'll point
there and it's notable that in this case
the highlighted intersection is being
counted twice and this is because we
could try to keep some sort of unique
set of points in order to have an actual
unique count of liberties but that means
that we have to have a whole data
structure to store this this isn't just
arithmetic at this point and so this is
not a Liberty it's what's called a
pseudo liberty this is a fairly common
approach in computer go and we will
double count any intersection that were
multiple adjacent to but if someone
plays in that position it will be double
decremented and so this tells us whether
or not we have zero liberties right it
doesn't matter for double counting once
we're completely surrounded we all have
both zero liberties and zero pseudo
liberties we also keep track of the sum
of neighbors by assigning a numerical
value to each intersection and the sum
of the squares of those neighbors and
the reason for this is that if the sum
squared equals pseudo liberties times
the sum of squares then we have one
unique Liberty and I'm not going to go
into math it's not that hard but it's
you know I'll leave it as a proof for
the reader
so let's go back to these things that
we're trying to do here right we have
these five steps and literature varies a
little bit but you know people can have
talked about being able to do anywhere
between 5,000 and 50,000 games a second
at nine by nine so we have one second to
do ten dozen games we'll say that there
are about a hundred moves a game there
are eighty-one positions on a nine by
nine board but we get captures and so
the same intersection will be played in
multiple times this is actually a little
bit low it's tends to be closer to about
a hundred twenty this means that we have
one microsecond in which to make a move
here are some things that take a
microsecond and you know I mean it's
it's worth looking into like why is this
right I mean we have fast computers
right you know a gigahertz processor
means that it takes one nanosecond
one thousandth of a microsecond to do a
single instruction like why is it I mean
yes we have these abstractions that
we've layered atop this but why and here
are some things from a fairly old
article by Peter Norvig which talks
about how long it takes to do certain
things on a CPU it takes one nanosecond
to do a typical instruction it takes 25
nanoseconds to lock or unlock a mutex
the notable one here is the fetch our
main memory and notice that this is an
article from 2001 this number hasn't
changed since then
now Ram has been getting faster but that
doesn't actually speak to its latency
what it says is that when we do a memory
fetch we pull down more memory in that
contiguous block and this means that if
we're scanning over a contiguous block
of memory these reads are basically
amortized so we do less fetches
therefore it's faster but we don't store
things to contiguously enclosure or in
java we have a lot of references all
over the place and our caches are
getting larger and so this sort of
minimizes a problem to a certain degree
but what this means is that every single
time that we have to go off and search
for something else something that we
haven't seen before every time we you
know allocate some memory which is you
know something that we haven't touched
in a little bit we lose 100 nanoseconds
and
so it's pretty easy to see how some of
these things end up taking they have you
know ten fetches from memory or
something you know around there and so
what do we do right I mean it's clear
that on some level we have to take a
step back from these standard approaches
we might otherwise use so I'm gonna talk
about some of the approaches that I use
and before I do that I want to talk
about why this is not generally
applicable right why you should ignore
some of what I tell you here so in my
day job I work with servers and if I can
get the response time under 10
milliseconds that's pretty good because
that means that probably the latency is
going to turn my response time in to
background noise right um that's not
true here where were throughput bound
also we don't really have the option of
using a smarter approach we can't use a
better algorithm because by virtue of
the method that we're using this Monte
Carlo search the only way we can be
smarter is to do more of it the only way
that becomes he's smarter in the same
amount of time is to be faster and while
maybe there isn't sort of diminishing
return where once we get to a certain
sample size we don't like get that much
smarter anything like this this is
beyond our reach right now no one has
found a point where they're like it's
okay we can stop like the more
computational power the more simulations
we can do the better we will be and that
will just kind of scale fairly literally
so we have to use mutable state this is
from the doc string for def type this is
you know rich telling us don't and he's
right you know this is not something
that you should use lightly this is not
something that you know the fact that
it's available in Java is so freely
there this is sort of the default isn't
an indication of its safety this isn't
like we're being put it in like you know
little waders or something like that
when you have to go into the pool this
is scary stuff and you should read this
book because if you read this book
you'll understand how scary it is and
you'll understand a whole newfound
respect for the ways in which we are
kept on the straight and narrow
enclosure and you you know it's it's
terrifying too and I mean it's kind of a
very interesting book
and if you want to go down the same half
you think that you need to do this I
strongly recommend that you read this
that you internalize this and that you
spend a lot of time really thinking
about how you can shoot yourself in the
foot and not even realize it but here's
the difference between unsynchronized
and volatile if something is only going
to be read and interact with on a single
thread you can use unsynchronized in
every other case you should use volatile
unsynchronized is marginally faster so
here's pretty much the simplest possible
immutable type mutable object that we
can create it has a single long counter
and because it's mutable it's not
actually accessible we can't use the dot
accessors or anything like that so we
have to write a getter and we have to
write a setter and we have to use set
bang inside of the DEF type because it's
not legal to be used elsewhere this
means that if we want to create some
sort of function like thing that wraps
over a complicated use of set bang we
have to write a macro it's ugly but
that's what we have to do furthermore we
if we wanted to say add a number to our
counter this is one you know fairly
obvious way to do it we get the value we
add to it we set it in my experience
this tends not to inline and so you get
a significant performance boost by
bringing the read and the set within the
DEF type and so what this means is that
if you are you know as sensitive the
performance as we are here sort of
artificially you need to do this and you
are mutable data type tends to get a
little bit big and has a lot of
functions and again this is just sort of
the price that you pay so I said that it
took a microsecond to associate the
reason I was able to say that with
authority it was because of a really
excellent library by Hugo Duncan one
that I think is like relatively unknown
and sort of criminally underused and
thats criterium criterium is a
benchmarking library and this allows you
to start to understand how pieces of
your software behave and this does all
the things that needs to do to control
for the JVM this is not the
I'm gonna rap a time Mac around adieu
times I'm gonna run it two or three
times until the JIT seems to stabilize
and boom I know how fast my program is
no you don't you need you should use
this right and you know there are some
caveats um it tends to exaggerate the
cache coherency which means that the
memory reads are going to be kind of
minimized as maybe not a completely
realistic real-world sort of case and
the minimum resolution seems to be
around 15 nanoseconds if things are
taking 15 nanoseconds you may be able to
do them 10 times and they'll still take
15 nanoseconds and so you should you
know be aware of that sort of lower
boundary but what this gives you is the
ability to start talking about
performance in the same way that you
talk about anything that uses the repple
you start to build it from the bottom up
you start to understand it from the
bottom up and this is a really important
way to approach these sorts of problems
you need to take each individual piece
of your code you need to understand how
fast it is and then you need to take
them in combination in some sort of
combat action you understand how fast
that is and this is the only way that
you're really going to be able to
understand where the inefficiency where
the inefficiencies are being added right
you need to build up an intuition for
how fast things should be and you need
to be very sensitive to where your
intuition is wrong right you need to
understand why you couldn't predict how
fast a compound action was going to be
one of the reasons that it can be slower
is because of the indirection that
closure uses there are lots of operators
which or functions which under the
covers go and do several different
things depending on what it's handed the
single equals for instance goes down to
well it also goes down to dot equals but
in you know the sort of simple case
it'll go down to double equals four
numbers identical for reference equality
count goes to a whole bunch of stuff but
if you're using an array as you probably
will be if you're a performance
sensitive the Java laying reflect array
get length is a significantly faster
than count and again I want to emphasize
that you know when I say it's much
faster this is something that in any
normal program would not make a
difference but when we are sensitive
this when we're trying to minimize
everything getting one of these things
wrong adding one of these things can
double triple you know quintuple the
amount of time it takes to do something
fairly simple and so you have to
very very sensitive and you have to be
very very careful about each individual
action that you're doing in this sort of
inner loop another formed indirection is
primitive math and this is a kind of a
tricky one because it's really hard to
know when your math is primitive
if you don't type int it even if you use
unchecked add and some other sort of
stuff if you don't properly give the
compiler all the hints that it needs it
will default to the safest option and it
won't tell you and so when you are
adding together two numbers and you want
to know you absolutely got to know that
it's efficient you basically have two
options which is to attach a profiler
like your kit or use Jen clasp to
compile it and D compile it and neither
of these are fun options right neither
these are things that you know I want to
be doing with my day and you know again
this is not something I do do during the
day but to insert a pursuit of this goal
of you know let's make this as fast as
you can let's write C enclosure which
may be an insane goal this is the sort
of lengths that you have to go to so I
brought a test it's a benchmark it plays
a random nine by nine game and I want to
see how fast that is and it's about 120
microseconds and that's means that we
basically got to it right we're playing
10,000 games a second we could go a
little bit further
I haven't actually implemented this yet
but some things I've been playing around
with are we can emulate C style structs
heterogeneous data structures in byte
buffers this is significantly faster for
the reason that you know we have this
sort of contiguous memory and we take
advantage of this architecture which is
built around the C style accesses we can
also go one step further and you know
one of the reasons that people don't do
this in Java very often is that if we
for instance want to get the enth
element and we want to get you know a
field and then a subfield we have to
create intermediate data structures that
represent each of these intermediate
steps and see that's not the case and
see what it'll do is it'll look at it
and I'll say oh you're going to this
index and you're getting this field and
all it'll do is it'll just
a couple multiplies a few additions and
then it'll read from that position in
memory and this is unsafe for all the
obvious reasons but we can potentially
do local analysis in closure assuming
that we have the right sort of
information everything like that and we
can do the safely as long as we have the
fallback of all these intermediate data
structures and so you know this is
actually kind of interesting for a
number of reasons one of which I'll talk
about this was alluded to in the last
talk coprocessors are coming back right
we have GPUs we have the ps3 cell
processor we have instructions on the
x86 chips that we don't have access to
vector instructions and everything like
that and these are not things that we
can really talk to very well this is not
something that's really within our
purview but what we can do is we can use
something like OpenCL which allows us to
create a C like description of a highly
parallel task and it gets compiled at
runtime and it gets sent across the wire
and we can send it data and it will work
on it and this task actually in many
ways is a pure function it takes data it
returns new data typically it is there
many of these are used in composition
with each other and whereas C which is
sort of what a lot of these api's are
written in is a very good way to
represent the TAS themselves it makes
for a very poor way to choreograph to
compose and while closure is not
uniquely qualified to do that sort of
choreography it's it's well positioned
right this is sort of something that we
do very well we compose things we talk
about you know things that don't have
side effects we we talk about sort of
many things being used in concert with
each other and you know since we're
doing runtime compilation we're not
really limited by the performance per se
we're limited by your expressiveness and
so closure can be an expressive
choreographer of other computing devices
and you know this is hypothetical this
is not something that has been realized
but I think it's an interesting sort of
niche that closure could fill which
hasn't really seen a lot of attention
and so I think that this is this is
interesting
so with that I wrote a go AI that's
called Pushkin it's kind of strong not
really uh what it can do is it can play
against can you go and it can win
sometimes so it doesn't make stupid
moves it's not completely brain-dead but
it doesn't play particularly deep moves
either it tends to get tripped up on
particular life-and-death exchanges you
know I think that a human player
realizing this vulnerability could
probably never lose to it but this is
because I've only taken the sort of
first step here there there are two
spectrums upon which I can improve right
now it's playing very naive Monte Carlo
play outs I can make it stronger I could
get it closer from possible to plausible
I could also take the multi-armed bandit
mechanism and I could try to seed it
with something that is my best guess as
of the best move remember that we're
converging on the best solution so the
faster that we can converge the more we
can exploit as opposed to explore and so
you know these are things that remain to
be done right this is something that I
think is a really fun sandbox for me to
play and for other people to explore and
I want to emphasize that this is not a
well-defined problem space are well
explored one rather you know there have
been a couple people that have written
things typically they as I did stayed
very close to the literature and at the
same time you know they've write in C
and they put all this engineering effort
into it there's not a lot of motivation
for them to go you know wild and there
are performance constraints and you know
on some level it is just more painful to
write code this way but I think that
with the right libraries with the right
approaches with the right sort of best
practices closure could be a really
effective tool for exploring these sorts
of problems and you know if anyone is
interested in this I encourage you to
come talk to me afterwards and you know
I will talk a lot more about this I
guarantee you with that I'll also say
that you know as I said I work for
factual there are I believe eight or
nine of us here at this conference we do
not do anything related to go but we do
handle some pretty interesting data
analysis and systems engineering
problems closure is heavily featured and
if you want to hear more about that come
talk to me come talk to any of us and we
will gladly also talk your ears off and
with that I'll leave the floor open to
questions
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>