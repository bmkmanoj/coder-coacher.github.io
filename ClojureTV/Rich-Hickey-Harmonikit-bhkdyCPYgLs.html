<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Rich Hickey - Harmonikit | Coder Coacher - Coaching Coders</title><meta content="Rich Hickey - Harmonikit - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Rich Hickey - Harmonikit</b></h2><h5 class="post__date">2014-01-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bhkdyCPYgLs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I made a major
how entertaining they were explaining
that how when you have a problem
understanding and paper you just need to
take out CoreLogic and then you have two
problems so uh they asked me when do you
want to have your keynote this year and
I said I don't want to have a keynote I
never get to have any fun these keynotes
I have to try to think of something
profound sounding to say and it's just
it's a lot of work and it's incredibly
stressful and everything else so instead
I decided to pursue this little hobby
project that I had no time to work on
using this device that didn't come out
until November 1st and a whole bunch of
software I had never tried so the first
question really is what is harmonica and
there was a good chance that by today
harmonica would have been a bunch of
random bits that may eventually become
harmonica but I got lucky and had a ton
of a plane time and and actually made
something that makes make something so
what harmonic it is is an additive
synthesizer forclosure written enclosure
using supercollider via overtone and
core async so no dating programs already
it's work in progress but it is open
source and it's on github right now if I
push the right shiny button but don't go
look at that look at this and you can
look at that later so what is uh what is
additive synthesis basically it's making
sounds by adding together sine waves and
particular making complex sounds and and
sounds that have pitch via via that
method but you can use added additive
synthesis for other purposes in
particular you can use Fourier analysis
to produce time and frequencies split
burnt you know data about sound and then
use additive synthesis as a way of
resynthesizing that is not what harmonic
it is
about at all so that's not an aspiration
of harmonica and that's not what it's
going to do instead in the history of
synthesis additive synthesis was one of
the earliest techniques for for models
for doing synthesis via modeling and
it's an it's an interesting model for
harmonic instruments so a harmonic
instrument is something like a guitar or
a wind instrument or trumpet or piano or
something like that that produces tones
that generally have a bunch of partials
at the harmonic intervals which would be
whole number multiples of the
fundamental so it's a fundamental note
then 1/2 times that is an octave up
that's the next harmonic three times the
fundamental is octave benefit four times
as two octaves etc etc etc and it ends
up that you can reproduce a harmonic
sound by using only harmonic partials
and so additive synthesis that's trying
to emulate harmonic sounds does it by
that technique you also need some other
things are and have it be realistic but
the goal of harmonic is to make
something that produces naturalistic
sounds but not necessarily emulative
sounds because we have a lot of ways to
emulate sounds including that
resynthesis technique the spectral
synthesis now there's also straight
sampling right you want to reproduce an
oboe just recorded a whole bunch of oboe
notes and play them back but we want to
make something that that's evocative of
that so it ends up that this is an old
technique this is an old technique and
and it used to be something that maybe
you could do offline or whatnot but it
was computationally intractable to do in
real time as definitely not a problem
anymore we can do this easily with with
computers today the other problem though
with additive synthesis is traditionally
has been that there's just a ton of
parameters right to reproduce a harmonic
sound with any kind of fidelity requires
dozens if not a hundred or more
harmonics you know that many that many
sine waves and what you're trying to do
is you're trying to have sine waves that
vary at least in amplitude over time if
not in pitch so there's a whole bunch of
settings you would make you know
typically if you were to do a Fourier
analysis
you'd say this sine wave has this
envelope and this other sine wave has
that envelope and another one has then
so all those envelopes and all their
breakpoints times all those harmonics
would be all the parameters and this is
just something that's unwieldy I want to
make a sound that sounds like this and
you're like okay go to you know harmonic
17 and set break point 42 a little bit
lower and it sounds like a trumpet it's
that's hard
so it's traditionally been a very
difficult problem there are a couple of
commercial additive synthesizers right
now that take on this problem in
different ways one is alchemy and
alchemy is fundamentally in the
resynthesis camp to do a very good job
of resynthesis they produce arbitrarily
complex envelopes with breakpoints they
do breakpoint reduction which allows you
to look at any one harmonic and say
don't show me 46 breakpoints show me the
six most important ones but the
breakpoints from one harmonic to another
don't co align so every harmonic is its
own story and it's still a ton of
parameters so mostly they're what you
would do is do some generic transform in
the time domain and then then
resynthesize it and you can do some
kinds of transformations that way but
not not most of them and then raise our
native instrument other one that sort of
says well you know an essence this is
really cool but the only thing people
really understand is subtractive
synthesis which is a technique whereby
you start with the sound with a lot of
harmonics and use filters to reduce it
and they basically give you controls
that are like that that just basically
reduce or boost high harmonics with the
same style of control that is tractable
that data that subtractive synthesis
does so what we're trying to do here is
do something that's new in that area
which is to have a human tractable
parameter set and therefore a control
set both for trying to establish the
initial sound the patch and while you're
performing having parameters that you
can manipulate that perform useful
modifications of the sound yet I would
like it to be amenable to analytic
generation later that is to say to take
those same kinds of fourier techniques
perform an analysis but instead of
creating an arbitrary set of envelopes
for an arbitrary set of harmonics to
yield parameters for this model because
this model is tractable for
humans to manipulate later that would be
a magic recipe I have not implemented
all of that but that's the idea so we're
trying for expressiveness and
performance in particular I want to work
be able to work with devices that allow
you to convey energy right we've seen
maybe some demos of overtone using mono
and some of these other controllers that
are like switches you know no matter how
you know you can you can move your bi
around all you want but it's on or off
it's not doing anything different but
there are a ton of controllers like like
this bad boy that are incredibly
expressive they record how hard you hit
you can wiggle them after the fact you
can squeeze them so those are the kinds
of controls that virtuosic performers
need to be expressive so that's what
we're trying to do is route that control
to the model other things I want to
explore in doing this were to look at
core async for control right now in
overtone there are very traditional kind
of eventi models for receiving OSC
communication and MIDI communication and
they have the same kinds of problems
that all eventing models have the kinds
of problems
Corie sync was meant to address so one
of the other experiments of this project
was to go and say could we help out
overtone by starting to use Cori sync
there and demonstrating how to route
MIDI and other controller data with Cori
sync for which it's a fantastic fit and
the last thing I wanted to try was to do
something with one of these I've never
actually owned an iPad I just bought
this iPad air whenever I came out on the
first but the vision was the all these
controls that you need physical
manipulation capability so we'll use a
touchscreen to do that and there are a
couple of techniques for doing that
piece of software to help that so that's
what that's what we did so to give you
some background on the pieces the thing
that actually makes the sound is this
fantastic engine called supercollider
it's what's underneath overtone as a
client-server platform where the server
basically manipulates a graph of
generators so you can imagine as a real
time graph of operators like plus and
times
and logarithmic operations whose
operands are streams of numbers at
different rates some are at audio rates
so if you're listening to samples the
audio rate would be like 44,100 samples
per second and others are a control rate
which would be a 150th of that so that's
SC synth that's the engine that does the
hard work actually sends the output to
the to the sound generation capability
of the computer and the other part of
supercollider is SC Lang which is this
object-oriented language for building
and manipulating these graphs the way SC
Lang talks to SC server is via a new
protocol or newest protocol called open
sound control or OSC and it's it's an
extremely simple protocol I really like
it basically you have a host and a port
and then 1/2 which is arbitrary you know
this / that / that and then some
arguments which would be numbers usually
floating-point numbers and things like
that some basic scalars there's some
other things to it there's some timing
things you can do you can say I'm
sending you this message but don't
process it for five seconds and some
ability to bundle things but it's that's
basically it it's extraordinarily simple
and it is not RPC it's one way to say
blah blah and you can sit you can do two
things with that you can say I'm
informing you of things you can use OSC
for that or you could say I'm trying to
transform you like send messages try to
make you do something different if
you've seen the latest version of
pedestal this terminology will be
familiar it was I mean it has the word
sound and it really has nothing to do
with sound but the people who invented
it imagined it as successor to MIDI
which is the spec that goes back to the
80s for having synthesizers talk to each
other and it's both a protocol of how
what the data is as well as an
electrical protocol for what happens
over the wires because it's a wired
protocol and we've had some ability to
route MIDI over USB and eventually over
Wireless but this is much nicer and much
more generic thing and you can use it
for anything and it has been used far
outside the scope of of sound
and then we have overtone which as we
know is an awesome closure library the
same era worked on with other people and
it does a whole lot of stuff most of
which personally is not really the way I
think about making music it supports a
whole other way of making music you know
me and you max like I don't I can't use
it very well
so like I think you know Emacs is one of
the last things you want to have around
when you're making music you need Emacs
for making music like you need it for
having sex and and for that for the uber
geeks in the audience just to be
specific that is not at all and all the
spouses out there can thank me later but
for the purposes of harmonica overtone
is the primary interface to
supercollider and one of the many things
the guys did in overtone was build an
engine for talking to supercollider that
replaces the SC lang basically says you
don't need SC lang you can use closure
instead and it really does make an
extension to closure that allows closure
to be a first-class language for
defining these algorithmic you gen
graphs and sending them over to the
supercollider engine for rendering in
addition there's a also library support
and overtone for talking with this OSC
protocol which which I used as well so
some great overtone great stuff in
overtone that's the part that's used by
harmonica digging a look well first of
all how many people have ever heard of
additive synthesis or have any idea how
synthesizes work so most of you don't
okay so the approach used here to try to
solve this problem of tractability is to
have a master envelope and an envelope
just says you know it starts here goes
up it goes down it goes down to close
down it goes down so it's it's levels
and rates over time and in evelope
describes you know a shape a single line
over time with a very few parameters
you'll say the rate to attack it was n
and that takes this much time the attack
level may be fixed there'll be some
decay
time a sustained level of fade time in a
release time that describes the their
overall shape usually applied to
amplitude and the idea is then is to
have this sign Bank which is going to
have a hundred different sign waves one
hundred harmonics that express their
envelopes and their gains as Delta's on
this master which means that you get a
single small set of controls the master
envelope that can shape the entire thing
and you can you can customize that a
little bit for the harmonics but it's
not necessary to set every break point
of every harmonic and that's sort of the
secret sauce of this model for keeping
it tractable so you have the ability to
scale amplitude and frequency to scale
all the parameters of the envelope by an
amplitude that means things can get a
ladder or software or take longer or
less time depending on how loud the
sound is and or depending on what
frequency is being played and that's
typical of natural instruments for
instance the envelope of high pitched
sounds is often a lot shorter than the
one of lower pitch sounds where things
make it brighter when you hit them
harder or play them harder than not it
also has a low frequency oscillator
that's that's an oscillator that doesn't
run at Audio rates it runs it runs at
rates you know 20 cycles per second or
less that you use to modulate some of
these other parameters to give you
effects like vibrato vibrato is the kind
of thing a cello will get or a wind
instrument will get and you can hear
it's like a little beating to it that's
actually a slight fluctuation in both
the amplitude and the pitch so use that
for that it also has a frequency
envelope stringed instruments and other
kinds of instruments frequently will not
immediately start at pitch even with
very good player you know you pluck a
string and it's sharp for a little
moment of time and in flatten it comes
back up modeling those kinds of details
is very important for making something
that sounds natural it in addition it
has resonance this is a property of the
instruments themselves so any instrument
that has a body to it will have certain
frequencies which with which the body
sympathetically resonates so violin body
or guitar
body or the actual shape you know the
body of a clarinet will have certain
frequencies with which it's resonant and
it ends up that our hearing is more
sensitive to resonance than almost
anything else right when I talk in a
single tone of voice and I'm making all
these different vowel sounds I'm not
actually changing the pitch that I'm
producing I've made suicide pitch but
the rest of what I'm saying is is
actually pretty even but you can tell
the difference between all the vowels
and the reason why you can and the
reason why you can recognize your
mother's voice is because as you move
your mouth and move your tongue around
and change the shape of your mouth by
speaking you're actually moving around
the formants of your head and your your
vocal cavity and it's that that we're
most sensitive to so modeling residences
in instruments is an extremely important
part of making sounds that are realistic
the final piece which I have not
actually gotten around to implementing
is noise so most instruments are not
super pure like that if you play a flute
there's a little chip to it when you
start if you pluck a string on an
instrument as a fake sound that's done
there a bow will chip on a string all
these things can be modeled by a noise
that's added to the harmonic stuff so it
says I have a diagram only whoa and I'm
sideways there we go
I'm just about as good as using this as
any other computer so this is the this
is like the the model of the model
inside fundamentally any sound is going
to start with the specification of
amplitude and frequency you're going to
say I would like to play this note this
loud and that's the input to the model
the LFO may modify that adding again in
a domain that makes sense so we're
saying adding decibels to volume or
adding sense to a representation of the
pitch and octaves so a logarithmic thing
that allows addition and subtraction
then it'll go through the master
envelope which is going to shape the
amplitude it has those parameters
delaying so you might want to wait a
little bit some sounds don't start till
after the noise so there's a little
noise and then then the harmonic sounds
you might want to delay the entire
envelope attack as they Matt time it
takes to get to its loudest point decay
moves it down to its sustain level fade
is the the ring that you would happen if
you held the note and release is how
long the note takes to go away when you
let go or stop blowing so those are the
normal parameters and for the master
envelope there's they're expressed
absolutely right and then you have the
sine wave Bank there's a hundred
harmonics twenty-four of which give you
these Delta manipulation over these same
parameters that number twenty four came
from that's how many faders I can fit on
the screen on a touchscreen and move
with that you like accidentally hitting
more than one so there's some like UI
feedback to the design of the model and
then and then this similarly is a
frequency envelope which gets much you
know modulated as I described and that
feeds the frequency so the first
harmonic is one times the frequency the
second is two and three and four and
five and it really is just whole number
of multiples again like I said this
isn't for arbitrary noise effects
although I'm pretty good at making
noises and not very good at making
anything else so far but it I don't
anticipate allowing you to set arbitrary
pitches for the harmonics it's going to
remain harmonic the one thing we might
do is stringed instruments for instance
that certain tensions
we'll have harmonics that are sharp so
modeling something like that is in the
spirit of harmonica but arbitrary
pitches for the harmonics is known and
then we get out of the sine way Bank and
we add them all together and that plus
sign over there that's where the term
additive synthesis comes from take all
the sine waves add them together then we
feedback summation through the
resonances and the resonances or filters
you can imagine them they're just like
the body of wood in the in the violin
and you put whatever pitch you've got
through it and if it's not a resident
pitch the body of the violence is boring
now a business resident pitches as well
baby you know and so it sorts wiggling
around and amplifying that amplifying
that so there's four tunable resonances
that allow you to model that aspect of
an instrument and we have the noise
thing again like I said is not
implemented but that will get added so
then you reintroduce the resonance add
it to all the harmonics and the noise
and you send it out voila
that's synthesis 101 okay
demo before I start the demo I just like
to say that doing this was a blast it
took me back to my memories of a much
younger me and the very first piece of
commercial software I wrote was that
thing which as you could see was noted
for having faders and knobs and this was
actually a new thing back in 1987 when I
first did it after having taught myself
see and 68000 assembly language so it's
like oh I have another diagram look at
that
so this is touch screens are great like
computers but they're harder to use
you ever notice everyone's like they
touch the screen like it might explode
so I have a pile of stuff here which I
can't this so we pick up without
unplugging I want to just explain sort
of the high level physical nature of
what you're going to be seeing here
we'll start inside the process so inside
I've started hopefully my computer has
not gone to sleep in oh yeah look at
that
let's make sure I hope it kept it so
that we're going so I in the computer we
have a single process and harmonic it is
the program that's running it's the
closure process it's loaded overtone
supercollider server can run either in
process or add a process in the case I'm
showing you right now it's running in
process we'll see because that's what I
got to work theoretically everything
I've done should run with the out of
process but that might be something for
us to fill around with during the the
unsession later so what happens is a
harmonic it has the model if you supply
it a frequency in a pitch it will make a
sound let's make sure that still works
and we'll test our sound everybody hold
your ears in case it's too loud it's not
loud at all do we have sand
it could be a little louder alright
that's our Monica playing and that's
playing it in the overtone way which
means you type something into Emacs and
say go it's a lot like playing the
violin that except for being completely
different
I actually I don't want to make fun I
mean it's totally fine to use overtime
the way it was intended and in fact
there's nothing wrong with this either
overtone does all of these things and
I'm just using a slice a slice of what
it does so we can drive harmonica
directly from Emacs it talks to overtone
overtone says OSC messages to
supercollider serve or even if it's
co-located it still pretends to do the
same job and supercollider send stuff
out and then I have to control things
one is this cue Nexus which is a little
MIDI device it's actually wired but it's
talking to a driver that turns its MIDI
into OSC so I'm only listening to OSC
inside that's called cheating because I
didn't get time to do a MIDI interface
which would let it talk to anything MIDI
I mean there's a sense in which OSC is
supposed to be the future but it's not
supported by a lot of devices by the way
this is the coolest thing ever look
health illnesses it supports MIDI OSC
and control voltage you can play like
synthesizers from the 70s with this
thing it's really amazing and lemur
which is a piece of software for the
iPad which we'll show you in a second
and lemur is talking to the computer via
OSC over UDP wirelessly and the wires
are only to drive the monitor and keep
it powered up okay Oh actual demo
how are we good
so this is harmonica I look and I want
see that okay let's see if this consists
still talking yes okay so we talked we
talked so I sent a patch from the
computer into a lemur
so lemur essentially it has no sound
production capability or anything else
it's just a bunch of controls that know
what number they're set at if you touch
them they send numbers back we can
quickly get a tour of the architecture
here so right in the middle is the mean
the main deal is to make sure this is
still talking well let's make sure this
is still talking sorry I think I still
talk good okay so this should change the
volume great okay so this is the master
envelope in the middle here
pardon my fingerprints
so we have gain we have delay which is
which is what's keeping from happening
it right away
we have attack so we can make it slow so
for Strings sounds you want to be take
more time and for plinky sounds so
that's that we can turn that on and off
there's also an LFO if I turn this back
to something more sustained so we hear
there oh that's that's the LFO
pretending to be vibrato
and I can make this extreme the step
extreme just to make it noticeable
and to demonstrate the frequency scaling
so there's some frequency scaling set
there that says as you go up higher it
should be faster so if I go up a couple
of octaves successive lower
we're still so that's that and you can
use that to model a vibrato and you can
turn it on and off so that's without any
vibrato it's very unnatural to have that
up top in the center we have the deltas
so that's all the harm unless actually
the first 24 harmonics and you can turn
them on and off individually you'll see
every other harmonic is turned off
that's typical of a clarinet clarinet
doesn't have all those other harmonics
so we can turn the wall on get something
that will seem a lot brighter fuzzier
that's too bright
you
turn down the higher harmonics you can
boast a couple to get like Annie's
League
I can't play and do this at the same
time and when I'm not doing this I also
can't play this is not my instrument
this is just so we can we can adjust the
gain of the harmonics and we can also
have Delta's for all the other things so
we can have amplitude sensitivity for
their harmonics we can Fuu that's why
that wasn't working
so again frequency sensitivity for the
harmonics we can adjust the delay so
let's try this stuff never hear the high
frequencies coming later
that's pretty gross but but there are
good reasons to do that we don't have
any right now we can also make make the
high harmonics come in later that
there's some tuning I need to do of
these parameters in terms of the ranges
I literally made this work on the train
yesterday over here but if this was more
sensitive
let's make the school
that's going pretty slowly but that's
that's the path to brass sounds the high
frequencies were coming later I can't
actually fabricate a brass sound and
similarly you can have the decay very
the sustain very than the fade and the
release / harmonic of the first 24 MOS
and turn them off and on and all of that
stuff we also have this frequency
envelope I talked about I think it's set
to a pretty extreme setting at the
moment mmm
it ends up in in practice your your so
the initial frequency is where it starts
relative to where it's supposed to be so
I can make that more subtle oh and then
where it goes to and we can tighten up
the timing at this point you can hardly
hear it but in the context of a piece in
the context of playing a lot of
different notes those very very subtle
things are the things that will make it
sound like music as opposed to a machine
so there's all of that and then we have
the resonance which has been on this
whole time but I can turn it off so it's
pretty there's not much body to this
right so I'll turn on the first resonant
point and turn the gain way up and sweep
it so you can hear what resonance does
I could use a touch screen that's
starting to feel like the woody place so
I'll turn the gain down on that what's
on the other one on and do the same
thing on set the widths
tight and put it up you can hear that
sort of the sound like ah so there are
certain points you can set these
formants where it starts to sound voice
like because there are four once we
associate with oh that's a person's
voice that's a you know these two
they're two in particular that the
setting of these two formats will you
know this is e this is ah this is o this
is uh one of the things I'd like to do
is have more feedback to the device
about the actual specific frequency here
so if you looked up the formants for an
instrument so do I need two hundred
Hertz you could find it as opposed to
wiggling around
it's it's much more musical you turn
this back off again that's the path to
again more interesting things and you
have four of those to play with in just
a lot of control I think I think that's
sort of all the parameters so the idea
is this is relatively tractable this is
all at one screen you know obviously
you're toggling between these but
they're all doing the same thing as
eight times the same eight times the
same job and that's essentially the
inside of a harmonica the engine here
here so that's the demo there's a lot
left to do
this is brand-new stuff one of the
things that is not the case right now is
the code is not really even a library
one of the things about overtone is it's
extremely oriented towards live
performance so there is a lot of use
like use use use use use uses everywhere
and not only is there a lot of using but
there's a lot of using and then like
sucking the names into a different
namespace so not only is everything used
but if you take a name and like type it
in and press Enter say I'll figure out
what the name space is it's not the real
name space so it actually is quite
difficult to figure out where all these
functions are you can see examples of
use and be like that's the function I
want to use but trying to figure out
where on the namespaces it lies is
tricky so I'd love to go through and
just do that so this is a real library
where everything is properly named space
because we're not looking for that
interactive you know I only want to type
you know one thing so that I can play
music on the key on the computer we also
want to make a library as I said before
some of these parameter ranges could be
fine-tuned so that the sweet spot of the
range is maps to the controller
correctly there is no noise generator
there is a design for it but it needs I
mean the space on the screen for it to
but
no UI or engine for that currently it's
it's mono timbrel so one of the one of
the cool things about this is you know
overtone is great and you can write your
own synthesizers a synthesized like this
is a big job that I can attest that this
is the biggest synthesizer that has ever
been made in overtone because overtone
was incapable of compiling it or sending
it to supercollider without patching and
and I sent Sam the the patch for the
compiling part I'll send him the
shoveling the graph over part but it's a
lot of work and you know I've talked
before about you know the levels if you
want to make music I don't I don't want
to even go back to making the
synthesizer again and a lot of
synthesizer algorithms especially the
small ones that you'll see there'll be a
little bit of code and it makes like
something that sounds a little bit like
a violin if you want something else you
have to write another kind of sense to
make something that sounds like a
clarinet additive synthesis is really
general so the effort we put into this
additive synthesizer is one that will
benefit everyone because you really make
a lot of different kinds of sounds and
to these set you can then it would be
nice for instance to be able to play
more than one sound with the same engine
at the same time if I have time I can
talk a little bit more about the
overtone part of this but it seems like
well how many people use overtone or
hack over time and play over time right
so maybe the maybe the after our session
is a better place for sort of the
details of how that works so there were
some interesting things about how this
gets implemented in overtone so I want
to do that will I make it a first-class
synth right now there's just some code
that I'm triggering but you'd want
something that's more enduring you know
to send the messages to and monitor and
load samples into and drive via channels
right now there's a bunch of code that's
sort of more specific to this Lemoore
software and this device then I'd like
but that's easy to do and finally if you
just want to be a consumer of this you
don't want to work on the code at all
but you're a musician and you want to
play with it I mean
making patches is just you know wiggling
these things around so it sounds like
what you want to hear and then saving
that it makes for a nice little 40 line
bit of Eden and that's what patches are
for this scent so happy to have patches
right now there's no patches this is one
really bad clarinet ish patch so I'm
happy to have people participate just
that way that would be fantastic
and it talked now about three of the
bigger picture the bigger picture ideas
so obviously I did not have much free
time even to make this in the first
place and I'm not going to have more
free time moving forward so it would be
great to get help or these are just
ideas I think would be cool the idea is
to support analytic generation I think
that this model can become the target of
analysis so what you do is you do well
the specific kinds of transforms
specific kinds of Fourier transforms
that are really amenable to resynthesis
but we'd use one of those what it does
is it will produce a set of arbitrary
amplitude envelopes for a set of
harmonic partials as well as a noise
residual given those two things you now
have like a curve fitting problem right
I only have this these breakpoints right
this the model is delay a cat attack
decay sustain fade release every
harmonic has to get that shape the first
thing you need to do is detect the
overall master envelope so that all the
deltas are small and then fit the
individual curves which are arbitrary to
a set of parameters that most closely
fits them in which case you're going to
get something that's not nearly as
realistic as the full analysis
resynthesis stuff I mean you can take
those sounds put them through that
process round trip and not detect the
difference with the source unless you
really have great ears that's not the
point here the point here is it
something that's naturalistic and a
starting point for saying well I took a
clarinet in and did this job
specifically the way to do it or a way
to do it is to take four samples write a
low note at both a low and high
amplitude and a high note at both the
low and high amplitude because we have
all that frequency and amplitude scaling
getting up with an envelope and settings
for amplitude and frequency scaling that
will allow you to fit it I'm saying it
because it's easy to do it like this
it's harder to do it with the program
but I do believe it's possible to fit to
a parameter set and then the point is to
get something that's driven by this
natural this natural inspiration even if
it doesn't sound exactly like it but
then you have all these controls which
are I think quite tractable to to shape
it to be what you like which is what
you're missing from the other the other
ways to approach this another thing I
think is particularly interesting about
this especially given the fixed
parameter set again this is the kind of
thing that's difficult if you have a
hundred arbitrary envelopes but if you
have a hundred very specific envelopes
you can start modeling higher level
control things like a lot of instruments
to some notion of muting right with on a
guitar you rest your palm against the
strings when you play and you get a
different sound and there's a ways to
mute a lot of different instruments so
so having a notion of muting and getting
a control for muting that was sort of a
master control that manipulated a set of
parameters is something that's quite
possible because the other thing is
unlike alchemy and and Razer you have
the source code for this thing so this
is something that we can do overblowing
and the kind of alternate harmonic sets
you get from doing that on a wind
instrument are possible and then the bow
techniques right there's a whole bunch
of different bow techniques and again
we're not trying to make something that
is that sounds like a cello we want to
make something that's expressive like a
cello and kind of cello ish in in being
musical like a cello is musical but not
I mean we could we could learn the play
cello for one to do that another another
area which some of the commercial
synthesizers are getting at but is
incredibly difficult to do well in the
technology they deliver to end-users is
is something called context-sensitive
articulation so when you're when you're
playing and in any kind of instrument
you have all kinds of options I'll just
talk about stringed instruments like
violin or guitar if you're going to play
two notes on the same string
one of the options you have is to
articulate it twice so I'm going to play
this note and then that note on the same
string so this is just higher on the
fret board on the same string I can
articulate this one and then articulate
the next one or pluck this one and pluck
that one or usually I can pluck the
first one and just lay my finger down to
make the transition and our guitar that
we would call a hammer on and on a
violin it would be called a what okay
slur oh look it's right on my slide so
it becomes really difficult to do that
when you're using these kinds of devices
right because there will have like a
slower button and and maybe you're
trying to play with two hands and then
you got to use your nose or foot or some
other thing and but it ends up that
there that that these things follow
follow rules and patterns for instance
if you're playing really quickly you're
going to have a lot more slurring
because you just can't you know you
can't articulate everything so you can
algorithmically figure out at this rate
that the rate these notes are coming in
we're going to slur a lot and
automatically transition to slur style
articulation as opposed to explicitly
articulated stuff and there are all
kinds of things like this you can build
models for instance on stringed
instruments there's often more than one
place to play a note I can play the note
on this string here or that string the
arrow that string there so you can have
a model of well I mean if your hand was
here and you need to play that note next
you're not going to go like that you're
going to play the version that's nearby
which means if you have a model of how
the different strings sound you can now
move to the other string and get things
that are more naturalistic that way so
these are these are this is sort of like
algorithmic context-sensitive rules that
would control these higher level
parameters some of the newest sample
playback engines will pick samples based
around this kind of stuff but they all
have these scripting languages that I
was like you know you know about
scripting languages right
so now you would have closures you could
write you know arbitrary sophisticated
things to do that that would perform
well enough to happen in real time so I
think that's a very interesting area I'd
love for anybody who's interested in
this to try it out it's on github you
know there and there's an unsession
tonight for people want to dig into it
but that's it
I think I have time for questions if
there are any yeah
yes widget is essentially a pair of
things a lemur sorry
lemur is a pair of things it's an editor
that runs on your computer there's also
a way to edit in person on the on the
pad I didn't try that and essentially
yeah you drag and drop controls on a
surface and then for each control you
say what kind of message should it
generate which is the path again this is
OSC self the path and then the range of
values and so you drag and drop the
stuff and move it around and pick all
your colors and of course that took
three times as much time as everything
else but yeah it's quite good the other
alternative is touch OSC it doesn't seem
to be as active to me it's a lot it's
cheaper but lemurs is $50 and it's it's
well worth paying for the guys are doing
a great job so and lemur is scriptable I
didn't use any scripting for this but I
thought I might need to so I didn't want
to be stuck it also supports these tabs
in place which touchosc does not so I I
like it but I haven't figured out a
bunch of things like how to send a
strength to replace patch name with the
actual passionate and things like that
yeah other questions yeah
yeah no it's not it doesn't do that at
all
it doesn't have any audio rate input at
all yes it is not available for Android
but touchosc is so one of the possible
growth areas for this is just to write a
touch osc interface right that's just
the edge of the system the model works
the same
currently the thing that receives OSC
messages is specific to Lemur but that's
just a core async map function away from
mapping Lemur to something generic and
then we could target the same generic
thing from touchosc
which does run on android so and yeah
you can you can make your own interface
for this make alternative interfaces I'm
not in love with this touchscreen so I
have this beautiful livid code
controller with actual real knobs
and push buttons and stuff and the next
thing I'll probably do is is set that up
to drive this because that's a little
more tactile and for some reason I was a
touchscreen stilt like me oh yes
they are not harmonic that's correct
this is the wrong sense for that right
so that exactly that that's that's part
of the the mission for this this is for
harmonic harmonic sounds because the
problem is when you start being able to
do anything like that you lose the
tractability you know if people had to
tune these harmonics you know wow it's
very difficult so but there aren't a lot
of categories of sounds so you could
make a synth for just for in harmonic or
not purely harmonic sounds and do bells
and and ringy things and symbols and
things like that and then you cover a
whole whole additional area people have
done some interesting drum modeling
which is another thing that's not um
harmonic in the same way so I would see
them as complementary I wouldn't try to
make one thing that made every sound
because it ends up making none of the
sounds really well yeah yeah it ends up
that the amount of Cory's thinking this
right now is very small but I but
already I think the benefits are quite
evident when you compare it to the code
that's in overtone for handling OSC and
MIDI I mean immediately they run into
the I have multiple callback handlers
and they need to coordinate kind of
problem and all that goes away also we
have you know nice ways to do mappings
and routing and multiplexing and merging
so I think it's just a gigantic win for
control in this kind of environment and
nothing about using it surprised me at
all
we should not suffice you
yeah no I mean the idea is to come with
them up with the model that acts as a
target if you saw my talk about design
composition and performance you know one
of the problems you have is if everyday
the orchestra comes in with like
different instruments you know you just
can't write music and so making it I I
think this plus noise is is a well-known
set of parameters I mean you have
resonance modeling you have low
frequency oscillation you have frequency
envelopes you have a full harmonic
spectrum and yet what I anticipate is
having two noise generators one for the
initial noise and another for any
sustained noise so for instance there's
often an onset noise and then something
like a flute will have an ongoing breath
noise or our bowed instrument will have
an ongoing bow noise so you have to
noise generators no the idea is to keep
it simple and like because when you do
that then you force all you know again
constraint drives creativity you force
all the energy into patch creation and
patches are things that everybody is
running the same sin can use all the
patches that everybody made so yeah sort
of like the same answer for you know
reader macros
it's Christmas it's actually it's the
same it's the same problem right if
everybody's working in different
language and you can't share you can't
show the patches or the programs other
questions yeah moving between presets
yeah so once it's multi Tamriel then a
possible target is what patched to you
so you could load in a set of patches
and via remote control switch between
patches and and the other growth area
which I didn't mention there is there
are lots more a lot more controls
available on this and usually in
synthesis you end up with something
that's called matrix modulation which
basically says these are all the
modulating x' these are all the
modulation sources and you can
arbitrarily route anyone to any other
and I think Corey's think is going to be
a great tool to use to make a matrix
modulation thing which I think will be
very powerful then you encounter a new
device that has a whammy bar or an XY
control or a ribbon controller on it
there are breath controllers there a lot
of really cool controllers it's
definitely my intention that this
support dynamic control well and that
these parameters would be targetable by
that other questions no no it does two
notes at a time right now except on my
computer is asleep
or they turn the volume down one or the
other
come on baby too loud it's saying it's
too loud
there we go place more than one note now
so multisample is more than one sound
Tambor more than one sound at a time so
you can load up a cello sound and a
violin sound and reveal the sound and
make a little trio that would be the
idea yeah
ah but that's not for me I mean that's a
dirt gazillion things that already
generate modulation there are petals
there are there are you know electric
violins there are breath controllers
that have all the keys of a wind
instrument and in the same order
there are ribbon controllers or XY pads
there are joysticks yeah there's this
MIDI everything so that's just you know
so I wouldn't invent anything there I
would just say well pick your controller
and we'll map it yeah I am I can't do
anything with this yeah I know I haven't
many guitar can play this Shore
mmm-hmm daddy'll date most of those
things map to standard I'll show you a
little bit of code because we have five
minutes
most of those things map to standard
MIDI controller numbers so even though
it's a guitar it's still mapping the the
whammy bar or the amount of pitch amount
of string Bend to standard controls like
pitch Bend and modulation wheel which
are basically say I'll respond to
modulation we all in this six different
controllers with very different shapes
that generate modulation wheel output
yeah yeah there's nothing there's
nothing new in any of this really except
probably the model design the parameters
of the model the model is well no yes
yes
yeah that's the desta generative
modeling thing I was talking about
before I do think that's possible but
what I won't let you do is produce a
harmonic that's a partial that's not
harmonic that's not a whole number
multiple so I just wanted to show you
how cool overtone is these are these are
the async loops that like this handles
the patch editing this one handles the
notes from the keyboard really that's
all the resist this is it's so tiny that
the whole thing is 200 lines but this is
the bit doesn't quite fit can people see
if I make this smaller close enough this
is this is the the main part of
harmonica and and what's cool about
overtone is that you're writing things
that look like functions like function
calls are happening now but what's
actually happening is when you call
harmonic it these functions get run they
decide are these ordinary numbers I'll
do the math right now are these numbers
that who are two sources our control
rate signals or audio rate single
signals if it's one of those the result
of the x or the log call is actually a
huge in specification that's going to go
and turn into this graph but you can see
what's nice as an instrument is
parameterised by the buffer that's going
to get the parameters from the note
number which is a midi thing and the
amplitude from 0 to 1 and a gate which
basically says i've let go of the key so
therefore you should start that release
phase and then you can see that we take
the frequency and we turn it into
cycles per second and we can do some the
LFO manipulation on that which is just a
call to LFO I don't go through these but
the similar you calculate the gain and
whatever you make an envelope out of all
those things you take the signal and you
generate 24 harmonics with full
specification and the rest of the
hundred follow the last one at the
moment we add together that the signal
that's the sum of all the harmonics plus
the four resonators
the moment will add the noise right here
so it's that tractable to look at this
and then the parts are also quite
tractable I'll look at a resonance in
LFO because they both fit on the same
screen
so LFO says you know take the frequency
scale it out from from 1 to 20 decibels
in the in the amplitude range and not at
all in the frequency range and you
create an envelope for that it's just
going to go from 0 to 1 that's the ramp
up the LFO has a ramp up like how fast
it comes in so sometimes usually your
vibrato doesn't kick in right away
source Wells up so there's a ramp for
that that's that envelope and then that
produces a number that's that's going to
go from 0 to 1 as a sine wave that's
going to get multiplied that's going to
multiply against the amplitude and
frequency of the master to have them
follow along so that's the sine us right
there is the actual source of a new
signal and the KR says that's a control
rate so we don't need to we don't need
to design any faster than you know a
thousand times a second or something
like that and the resonance is the same
kind of thing we're going to call this
primitive called resins which is a
resonance modeling primitive in
supercollider that takes the frequency
the center frequency of the resonance
then how wide is it so volkl resonances
are really small sometimes instrument
resonances are kind of kind of wide so
that gives you a taste of this but if
you want to see more come to the
unsession thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>