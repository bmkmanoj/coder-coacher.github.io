<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Clojure for Lisp Programmers Part 2 -  Rich Hickey | Coder Coacher - Coaching Coders</title><meta content="Clojure for Lisp Programmers Part 2 -  Rich Hickey - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Clojure for Lisp Programmers Part 2 -  Rich Hickey</b></h2><h5 class="post__date">2012-12-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7mbcYxHO0nM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so in practice this this combination of
things so look we resolve food this is a
local guy we get the local one now list
we never defined in the user name space
in fact all the closure functions are
auto imported into the user name space
which means we resolve list we see it
says closure list it's the system one
which is neat which means if we write a
macro right this is back quote list who
acts right and expand it look what we
get data structures with symbols but the
symbols have qualifiers no matter what
namespace I resolve listen closure list
resolves to closure list so this system
actually solves a lot of the hygiene
issues from being a list one separating
symbols out I know what spent any more
time on it but I will say I think this
goes a long way towards that SM Auto
Jenson's that's not to say you will
never call Jenson you will and gen but
you'll have to do you'll have to be
writing a more sophisticated macro in
which case you know what you're doing
already closure has pervasive
destructuring destructuring is pretty
cool I think pattern matching is all the
rage and I'm not exactly a fan I like
the destructuring part of pattern
matching but I don't like the switch
statement part of pattern matching so
closure has destructuring but it has it
everywhere but like the other parts of
closure
these structuring is based around
abstractions it's what I call abstract
structural binding so Inlet and loop and
fun and binding lists really anywhere
where you're doing bindings or anything
that's built on these things which
basically is everywhere you're doing
bindings you can use data structures
where symbols would go and you're gonna
get these structuring so you would say
let a1 or let a 42 right now instead of
saying a you can put a data structure
there and there's an interpretation to
interpretations okay if you have a
vector as your binding form it will
destruction
anything that's sequential okay so it's
anything that implements the sequential
interface you can do structure lists and
strings and arrays and anything that
supports ends and it'll pull that apart
of course it'll be a vector with names
in it and those names would be down to
the parts of the thing I'll show you
this in a second you can also have a Mac
as a binding form and that will D
structure anything that's associative
which includes maps and vectors vectors
are associative you could do a map style
binding for him and get the seventeenth
thing out of a vector and call it Fred
so unfortunately I think these examples
are a little bit too verbose but well
this first one we might be able to
understand so that there's not a name
simple name here right the first thing
it's a vector so we're gonna say we're
gonna bind a to the first thing B to the
second C to the third thing D to the
rest and we're gonna call the whole
thing II
and then we're binding that to a literal
vector of numbers so a b c
that's really cool
this nest so this is a vector with two
vectors we're renaming the parts inside
the back door and then we're passing a
vector of two vectors and we're named in
the parts of it so that all does the
right thing this one's particularly
wordy and too large but the idea here is
named key name he named key same as
thing defaults etc etc we bind it we
picked the pieces out we can get to the
false in we can name the whole structure
a/c didn't have or says if you don't get
the key use this
yes you can put these things in function
arguments yes a certain flavor of them
but you'd have to somebody would have to
if you're using Ward somebody has me
passing you something associative right
which the argument list isn't by default
but they passed you a map they could get
defaults that way you can use you can
build all kinds of cool things with this
they nest arbitrarily so if you do a
vector D structure and our map D
structure and then for one of the
arguments who D structure that key as a
vector you can pull all the pieces up
and if you start to slow enough you can
figure out what it says but the idea is
that they nest they nest arbitrarily
without without limit and it's very
powerful yeah it's not even on here
there's other sugar that lets you avoid
saying a a BB CC if you want the same
names you can just say keys ABC and will
pull them out similarly you can pull out
strings that way or symbols that way so
there's lots of you know power user
features inside this but the nice thing
is it's every place so polymorphism I
said closures not a fraternity but
closures not anti PI morphism a very pro
polymorphism I have two fundamental ways
to do polymorphism one is the job away
right you have interfaces all the
abstractions in closure or defined in
terms of interfaces the nice thing about
doing it that way is it's a bridge to
Java if you want to allow extension by a
java java can do that closure can also
do it multi methods of the other way
that's kind of close are specific
because Java doesn't have this kind of
power but what I wanted to do was avoid
marrying dispatch two types I'm sort of
tired of types I'm tired of having like
these these rigid type systems that that
really in current or complexity for you
every time you make a class we have like
all this complexity you know
Sara Lee realize anymore and and fixing
valuable features like polymorphism to
type system which usually only get one
taxonomy for your for your arguments
so what closures multi methods are is a
complete generalization of dispatch what
is what is generic dispatch it's there
are these arguments I don't want a
hardwire what happens when you call this
function with these arguments I want to
do something specific to the arguments
right in Java and c-sharp it's we're
gonna do something specific based around
the type of the first argument okay in
common list we have more flexibility you
can use the types or the values of any
of the arguments but it's still a
hardwired heuristic right unless you get
into su los you know underpinnings
you're still saying it's other types of
values and there's an order dependency
and all this other stuff but the reality
of it is it should be an arbitrary
function of the arguments that
determines what your method is and
that's what it is enclosing okay
the dispatch function is an arbitrary
function of the arguments you want to
have it multi-method give me a dispatch
function I don't care what it is that
dispatch function will return different
values for different argument sets I
don't care what they are you can
associate actual methods with those
values I don't care what they are either
have at it want to build single dispatch
fine if you want to build si la style
dispatch fine you want to do something
that compares the values of arguments go
for it you want to do something with the
first in the third and one of the middle
guys I don't really care so how does it
work you're gonna give me a dispatch
method or dispatch function when you
define the method when I'm call I'm
going to call it on the arguments to get
a value they're going to look up and see
have you associated a method with this
value if you have I'll call it if you
haven't and you've provided a default
I'll call that if you haven't defined in
a default you'll get an error so this is
what it looks like in my silly bunny
example the key thing to remember here
is so we're going to define a multi
method called encounter and dispatch
function is take two arguments and pull
out their species return a vector of the
two species
the trick you have to remember here is
that keywords are functions of
associative things so those are two
function calls the species of the first
thing and species of the second thing
so we're faking types although it's not
the type of the first thing the type the
second thing because you only get one
type it's an attribute of the first
thing in an attribute the second thing
which means you're gonna have other
methods multi methods with different
taxonomy x' you can look at metadata
which I haven't talked about you could
do whatever you want so in this case
we're going to pull out the species so
we encounter if the account if the
dispatch value is bunny and lion that we
run away if it's lying in bunny then we
eat it lion lion they fight bunny bunny
they make then we define a bunch of the
girls b1 as a species of bunny and I
don't care what else I don't care what
type it is don't care how many other
attributes that has or anything I don't
care I shouldn't care and I shouldn't
dictate to you that it be this
particular type in order to interact
with my API that has to stop right let
people just glom stuff on so they can
talk to you and not have to be something
so they can interact with you so
absolutely I don't care right the way
keywords look the way keywords act as
functions is they look themselves up in
the thing using the map interface does
it have to be a map no you get up
species 1 and species 2 and you could
pass two vectors that would work you
know whatever you need to do so then we
would define a bunch of data and then
the n' character things do what you want
I haven't time to update the slide but I
have enhanced this system substantially
by making it such that the values that
are produced by the dispatch methods are
compared via and is a relationship which
will work for equality to things that
are equal will be izi but it also allows
you to define relationships between
really any names as hierarchies that's
called ad-hoc hierarchies so you don't
need to have hierarchies only in types
you can just have hierarchies you can
say oh you know : square is is a :
rectangle you just tell me that and then
you could do this dispatch and say if
it's rectangles do this and if you pass
squares it'll work
not types right why does hierarchy have
to be in types why stick it there it's a
dungeon right so hierarchies a bit
excuse me ad-hoc hierarchies no it has
nothing to do with methods it's just you
could leverage them here because the
multi method system uses is a to
determine what happens
it's a hash-table lookup right so all
that hierarchy stuff is looked up once
and cashed so and then it will track any
changes to the hierarchy system well
yeah the overhead is the hash table
lookup the extra an extra function
calling a hash table lookup yes it's not
that yes yes you could let's just talk a
little bit about that I'm sorry I don't
have a nice slide so is a--
works between any two names you define
what the relationships are okay then you
say well what if I had a vector of these
in those vectors do a per guy is a okay
which still begs the question there
could be ambiguity yes there could be
ambiguity for instance you could use
Java interfaces to do dispatch and
something could implement two different
Java interfaces so which one do you use
if I get an ambiguity I will tell you
well when you first call it and it will
fail but you can then tell me prefer for
this method prefer this to that and that
will resolve the ambiguity
now that only happens once once I get it
once I get it resolved once I cashed
that so it's just a hash-table lookup by
value I see the same dispatch value
which is the result of the dispatch
method and it's hash table lookup if I
fail to find it now I have to do the
work if I do the work and find an
ambiguity I'll tell you if you want to
resolve that ambiguity you can by saying
prefer this for this method prefer this
to that prefer this interface to that
one for instance or some argument set it
ends up being a pretty good compromise
but what it's missing from predicate
dispatch which I really haven't been
able to figure out how to do fast it's a
logical implication right a real
predicate dispatch should know that
being less than 10 implies being less
than 100 but that's this is not a system
but it's pretty powerful and very
general
closure supports metadata right this is
the ability to attach data to any value
that does not constitute part of the
values value it's about the value it's
not a component of the value so it's
orthogonal to the logical value of the
data you can have a vector and you could
say I got this vector from Fred or I
found it on the internet or I last read
it three weeks ago or anything else you
want to say about it that's not part of
the value right if it's a vector of one
two three it should still be equal to
one two three it's just you found it on
the Internet instead of you know pulled
it out of the database so it does not
impact the Equality semantics you don't
see it when you do any operation on the
value but it allows you to adorn values
and it's a very important thing that's
extremely hard to do in most systems
which is track you know trustworthiness
or age or validity or the source or
anything else so you have the ability to
attach metadata to all the closure
collections and
into symbols has nothing to do with it
it's attached to values VARs have a
separate notion of metadata this is
really the real deal
you can't attach metadata to bars but
this is this example is not this example
is about real value operations bars are
not value as far as a references so they
have separate semantics for metadata but
they do have metadata but I want to talk
about that right now because it's too
confusing everybody has to know about
that hash table it doesn't flow through
your call chain nobody can go and
inspect it they have to play metadata
you don't have to play and a real hash
table where everybody had their metadata
is a concurrency disaster right it
belongs on the objects that should flow
it should be copyable and and when you
do that it has to be associated with
identity these things are associated
with values right I can have one two
three and I'd say I found it on the
Internet I could have one two three and
say I got it out of the database what am
I going to put in my global hash table
Erin I'm in trouble I have to put the
identity these things but I don't want
an identity system I want a value system
and I can't have a hash table by value
because they're the same value and I can
talk more about it later but it wouldn't
work
no no annotations of properties of like
stuff not really not everything it's
attached to the class stuff usually not
to every instance yes
in real systems I need this all the time
as soon as you have a big enough system
you find you need this kind of thing all
the time I have this huge calculation
step right i source it with some data I
mean I work on the selection system so I
source it with some data that was from
counties right but the data looks
exactly the same as data that comes from
the precincts now in the middle of the
calculation you know do I have to say
precinct you know map of this county map
today I mean putting in our types is
wrong it's just where I got it from so I
can I can flow that through so
essentially any of the closure data
structures support the attachment of a
map of metadata and you can use it for
whatever you want closure actually uses
metadata in the reader you can adorn
your code with metadata and it's you can
talk to the compiler that way in fact
that's how you give hints to the
compiler because there's literal support
for metadata so let's look at this we
can define needs the vector one two
three
then I can say trusted B is the same
value right with this metadata social to
it so one thing we know about with meta
is what returning a new value then we
can look this carrot is the same saying
man of the thing the metadata trusted B
is trusted I mean the source of the
trusted B is trusted the source of this
thing we don't have it's great
carrot yes is reader syntax for a meta
of blah
most of the things like a social
whatever will build only on the first
guys yeah well they won't automatically
incorporate but all the operations are
metadata preserving okay I can't really
properly combine metadata I don't know
what it means so I can't do that for you
but it's it's really useful
probably I mean when your anointing with
metadata you don't want to have a little
piece of metadata on sub pieces of all
kinds of things it's not that meaningful
you're usually attaching it to things
whose contents are going to be
consistent or you're going to be
responsible for adding or removing those
additions and removals will produce new
values with the same metadata so their
metadata preserving that serve as far as
I'll go and anything beyond that you can
do okay let's get into some of the meat
now this is an important part of the
talk because everybody in every language
is facing this your programs are they
ready to run on 600 cores at one time
are they gonna use them profitably I
don't think so but that's coming what
the basically saying is these computers
are these cores are not getting any
faster will just give you more of them
making use of them your problem its
offer developers Hardware guys are
punting punting they left us out here
so I want to be clear about what I'm
talking about in this part of talk when
I mean concurrency because there's a
bunch of different things we're talking
about interleaved execution and now of
course there was always threads and
there's ways to do green spreads and
pretend but the reality is we're getting
real interleaved execution now multiple
cores means really two things are
happening at the same time we want to
avoid seeing inconsistent data or
creating inconsistent data right and as
the complexity goes up as your as your
units of work evolved more things its
gets more and more difficult to keep
consistent especially if you're using
locks there are also a whole other sense
of concurrency things that have to do
with parallelism right I want to do this
one logical operation and then in the
background you know this vector you know
matrix multiply just put it on all these
cores I'm not talking about that right
now
Java has a really nice library coming up
in Java 7 for doing the kind of parallel
math and closure has a very beautiful
wrapper for it so here I'm talking about
cask level parallelism most typical
applications going to try and leverage
these cores by setting up a few threads
to watch the web interactions
to deal with a database and maybe you
have some streams coming in from this
data source and maybe you have a couple
of calculation engines that you're gonna
use that kind of task level parallelism
is what we're talking about here so this
is my message I don't care what language
you're using except if you're using
something like Pascal or something
already very purely functional if you're
using a system where you're using
objects or shared data structures that
are mutable it is not going to work it
is not going to continue to work you
absolutely have to find some different
way to do it
I think object-oriented programs when
they get to a certain size are just
spaghetti I've never seen one that grew
indefinitely and kept you know being
maintainable so it's just a new
spaghetti code it's all object-oriented
but it's still a disaster it's very hard
to understand a program even an
object-oriented program once you have
all these relationships once you create
a graph of interconnected changing
things but one thing's for sure whether
or not you disagree with that from a
concurrency perspective it's a disaster
and unfortunately it's the default
architecture of all of these languages
including Common Lisp
right you create objects you get these
mutable things and it ends up that even
if you know this and you said well I'll
take a different approach in my
applications doing the right thing is
really hard because it's not idiomatic
it's almost anti idiomatic so for
instance try to do immutable data
structures in java places so although I
did I mean that's what I'm giving you in
the library that I'm the last closure
but it's so so what happens now I mean
even if you're using a list one of the
more cutting-edge Common Lisp that has
threads and everything else chances are
good they have these same old you know
concurrency constructs that you know
people in Java and c-sharp are already
saying don't worry
so copying those is not really moving
forward what do you have applications
have direct references to mutable things
right and what could you possibly do in
that context oh you know it's
essentially each program was written to
be imperative like I own the world
each part of the program I own the world
okay when you don't own the world but
you either have to stop the whole world
that doesn't work or somehow somebody
has to preserve your illusion that you
see the whole world and doing that with
locks is incredibly difficult in
particular because you do accomplishing
that is completely convention you have
to have meetings you say this data
structures going to be looked at for
multiple threads if you're going to
touch it make sure you lock first okay
and then you have all this complexity
well what if I touch the data structure
a B and C well we have to grab the locks
in the right order or you're going to
deadlock what if I'm only using C and B
well you still to grab all three or
maybe we'll have this global lock and
our concurrency is going to go down it
doesn't work if you're just starting to
do this just skip to the end it doesn't
work it doesn't work I could save you
years of grief
you know headache and nightmares because
it's a nightmare I've been doing this in
C++ and then c-sharp and Java for 20
years it just is awful you cannot ever
believe it's working so what do we do
instead of that we're going to say we're
going to indirect references to a
mutable persistent data structure so
this RAF notion it's kind of like
standard MLS ref notion if you're gonna
have something mutable you have to call
it out this could change alright and
then closure has concurrency semantics
for those references so those references
are like cells right all they're gonna
do is point to some bigger immutable
aggregate and if you're gonna want to
change those cells because they can't
change you're gonna have enforced
concurrency semantics and your programs
in closure do not do any locking so this
is what it looks like in the old school
a bunch of parts of the program are
pointing to the same block of memory the
problem fundamentally is this
object-oriented programming done the
traditional way unifies identity and
value you want identities in your
program you know like tomorrow is going
to mean different things as your program
and runs and runs right so you want that
identity but the value of tomorrow or
today's date or the time is something
that's going to change unfortunately
when you say the identity of this thing
is the address where we're keeping its
value you've your game over you can't do
the right thing anything can change at
any time and the consistency problem
goes to the users so what do we do
instead we have the programs refer to
the identity and the identity is that
cell okay that reference and that in
turn points to some immutable aggregate
thing could be a closure vector or map
or any of the closure stuff so now we've
separated identity and value if you want
to obtain the value you need an explicit
dereference okay at that point you can
have appointment of this 100 people can
have a pointer to this is that okay sure
this can't change it's immutable have at
it well look at it from 100 threads 600
course that's going to be great that's
going to perform well because there's no
locking required to look at the value
all right so we're going to explicitly
dereference the values can never change
you could never see an inconsistent
value because they don't change
somebody's gonna make a consistent value
stick it in there you pull it out it's
consistent objects don't change in your
hands so what does it need to do
anything okay
well you've already seen all these data
structures we make new values by calling
functions on the old values and getting
a new value so while everybody is
referring to foo and while foo is
referring to this immutable thing
anybody who wants to could be saying I
got a new better improved food and make
one right it shares some structure as we
saw that's the way these data structures
work it can share structure with the one
that's already in there that's no
problem they're all immutable nobody
who's reading this is impeded by the
creation of this new value it goes on in
parallel and it's not impeded by the
fact that anybody's reading so nobody's
anybody else's way then when we want to
edit we want to change this reference
atomically to refer to the new thing and
that's always coordinated in closure
there are actually multiple semantics I
hadn't say
happens when it happens right you can
have different semantics for that and
enclosure has three anybody who was
consuming the value was unaffected if I
was in the middle of doing a calculation
on this I'm still fine right so the only
thing that kicked off closures data
structures that can change are these
reference types there's three of them
Raph's unfortunate name in this context
which are about shared synchronized
coordinated change right what's the
hardest problem you know in a system
with multiple threads
it's my unit of work touches three data
structures there's this composite unit
of work it's very hard to pull off
so refs do that hardest job change three
things and either have all the changes
happen or none of them happen it uses a
transaction system I'll show you that a
second agents are more of a lightweight
autonomous changed model where you say
you know what just eventually do this
and I don't care what I just want to
return right away and I want you to take
care of this job for me
those things are asynchronous they're
also independent there's no way to move
something from one collection to another
with agents and bars you already saw
fanfare bars you already saw bars have
concurrency semantics when you set them
because they're all thread independent
right we saw we couldn't set it unless
it was a per thread back so closure has
something that's called a software
transactional memory system if you've
ever worked with the database this
should all be familiar to you you can
only change a ref and here I'm talking
about that s TM ref you can only change
them in a transaction right any set of
changes you make inside a transaction
will happen atomically right your
transaction will see a consistent view
of the world while it's running as of a
point in time
in addition closure as an SDM is kind of
unique in supporting consistency rules
for the values that you're going to take
on so you have isolation you have a
atomicity and then you have consistency
you can attach to a ref you can say
validate any data anybody want
put in here with this function if that
validation fails that transaction will
fail I won't take the value you can
attach those validation functions to
VARs refs or agents so they all support
consistency no transaction sees any
other transaction effect essentially
what happens is your transaction sees
the world as if it was a particular
point in time and when you commit it's
as if all the changes you made happened
at a particular point in time the only
caveat with this system is unlike
databases which sort of do deadlock
detection and keep guys waiting and sort
of have a big blockchain thing in test
TM systems typically what happens is
they're semi optimistic or fully
optimistic closures is only semi
optimistic which means you can proceed
along down your transaction and
determine yeah I am NOT going to win I
am NOT going to be able to maintain a
consistent view of the world and have a
successful commit so do-over and that's
what happens in STM so you get an
automatic retry which is great and it is
absolutely what you want but you have to
avoid doing any side-effects in the
transaction I can't enforce that but if
you have side effects and you get
retried you'll have your side effects
happen more than once using this is so
simple
what do sync around your block of code
any changes you make to refs inside that
block participate in the same
transaction including inside nested
functions including if those nested
functions run their own transactions
they all join the enclosing transaction
under the hood closures STM is pretty
unique if you've done any reading about
STM's it's a multi-version concurrency
control system which is unusual yes
no you can imagine them throwing
exceptions it's a very clear image -
although you can do flying reads because
the contents of any reference are is
consistent so I don't care if you read
it outside of a transaction that's
perfectly fine if you want to read a
bunch of things outside of a transaction
and you only care that each one was
consistent that's also fine if you want
to read a bunch of things and know that
they're all consistent as of a point in
time even those reads need to be in a
transaction yes in transaction well you
can call Java you can print you can read
a database you can any language that has
no side effects can only heat up your
computer so yeah that's how might that's
not my life many times redone yeah no of
course
programs do closures is a realistic
language and saying of course your
programs do I oh right of course your
programs may want to have identities
that are associated with values that
change over time
how can I help you do that right I can't
help you with I oh you have to just do
il separately I can help you completely
with this data part
ah no no no in fact no I haven't talked
about agency so hang on to that question
no it's beautiful how you get oh how you
start multiple threads I don't care you
can definitely use Javas executor
framework or thread start or whatever
you can also use the agents which I
haven't gotten to yet if you don't I
mean I I don't care I guess I don't want
to say yes it would be the agents
because that's one way but I'm perfectly
happy to use the for you to use the
executor framework of Java to Lush
threads I don't care how they start
closure does not require your threads to
be adorned by me in any way for this to
work so anyway you could start a thread
in Java this will work including agents
what I'm getting so it's a big thing
that's true of all STM's
absolutely I think we're in a strongly
type system you can have more
enforcement I'm telling you that I can't
enclosure because it's that dynamical
type it's the same as anything I mean
this is a dynamic language so you'll get
runtime errors you'll start seeing
things print three times and be like oh
I'm in a transaction I got retried and
if you're in a dynamic language you used
to dealing with problems that way
there's no enforcement
I can't enforce it I'm not anti
enforcement there are languages to try
to enforce it they come with very
intricate type systems that are not yet
expressive enough in my opinion
but that's another way and and if you do
that you could do more I would love to
try to add just enough effect type
system to this to help with that and
that's something that I'll probably
research in the next couple of years but
right now it's on you
it could happen okay so this is pretty
cool this makes sense from a database
standpoint this is a particularly unique
thing about closures STM which is what
happens in an STM right well there could
be multiple transactions going on that
both want to increment this counter when
they're done in most STM's that means
that one transaction is gonna win the
other transaction is going to retry
which means doing all their work again
in order to get in there but it ends up
that incrementing a counter does not
need to be a read-modify-write action
you could do it that way you could say
look up the counter it's 41 add one it's
42 set it back into the ref it's 42 now
if I do that in a transaction and
somebody else does it in a transaction
one of us will win and the other one
will redo but if you have something that
I call commute you could instead say you
know what I don't care what value was in
there all i care is when my transaction
commits it's one more than whatever it
is if you have a way to say that
then both those transactions can get all
the way to the end and one could win and
the other could win they both can win
either one needs to retry so commute is
a beautiful facility it's actually it
was an old database thing called field
calls or something great idea
and it ends up that you can now build
systems with even better concurrency
because if you only need to you know end
up adding something to a map or end up
incrementing something you can use
commute instead of read-modify-write
sure okay so what is this look like to
use okay we need to find food to be that
map okay so we have a map but look it's
a reference to a map which means that we
want to see the value we have to
dereference it this is just reader
syntax for dear fo-fo okay so just like
quote there's deer F and this meta is a
couple of other ones that keep you from
too many tedious parens so we dear fo we
see that value notice it's in a
different order because it's a hash
thing so this is a way Tecton I can use
that value in calculations this is a
flying read write read the value
associate this thing with it have not
changed foo right I got the value out
there was this a mutable thing I did
some logic on it I got a new value this
is just that value nobody put it back in
food so that's totally fine I look at
food it's the same I haven't really
changed now I can try to commute for the
way commute works as those commute this
reference with this function and these
values what will happen is that function
will be passed the current state of the
ref and those values and the return
value of that function will become the
new value in the ref it's beautiful
there's also alter which is the read
modify write but commute is the one that
says whenever I'm done do this so it's
nice it's a functional interface you say
apply this function to the value that's
in that reference and that result of
that function becomes the new value in
the reference so we do this right we ask
before can we just do this with a single
guy no you can't do this anywhere that's
outside of transaction this
transaction this is one in a transaction
start with do sing I do that I could
have done a bunch of things inside this
do sync but this is just one now this
works and when we did reference foo we
see the changed value it's pretty easy
it's very easy and it when and I think
the nice thing about it is you end up
reusing a lot of the functions you
already wrote I could test this function
right now I just did right in fact I
could do it with any piece of data I
want so because you're applying these
functions in transactions means you can
test these functions on values not
burden your whole system with mock
objects and also the nightmare stuff
test your functions you have some data
you can apply this function it's
supposed to do this transformation and
return this revoke result do all that
before you get involved in references
there's nothing about that that involves
references then you say oh I want to
store these things in references okay
alright so the second yes no I mean you
can write out the references they all
participate in the same transaction same
thing you can commute you can commute
some references in a transaction and
alter others it's totally fine no
completely not because all those things
participate in the same transaction
they'll either all gonna succeed or none
will succeed so
oh the commuting no the commuting
function has to be pure huh
no I can't check it I'm a dynamic
language that no that's an interesting
idea though checking it dynamic that's
like I could do that yeah I could do
that one yes
it's already in the library sure right
so you say commute X Inc and that will
happen when that commits
but right yeah yeah yes they don't
commit at the same time what ends up
happening is commutes get all the way
through but any transaction that
involves a commute happens all the way
through to commit time right now
typically if it's read-modify-write
they'll still see the conflict two guys
try to modify food one will win other
one will go back with commutes what ends
up happening is two guys trying to
commute food he will this guy will
second guy in will wait this guy will
finish he'll go so he'll do 42 he'll to
43 no no it had whatever happened inside
your transaction in a commute is a
temporary value it's just to make you
feel good at commit time whatever actual
value is in the ref is going to have
that app function applied to it then you
can happen twice it's gonna happen twice
and it's a pure function and that's the
cost
are you doing what you could have done a
hundred other things though let's say
you have a really complicated
transaction and you just it's completely
independent from the souther one but
both of you have to increment the same
counter well if you're really doing that
with read-modify-write you've made both
of those transactions completely restart
in conflict with each other with commute
they're not you do whatever you like I
mean I'm just saying you have this
facility and it has this property and
you can leverage that in your designs to
get more throughput okay no no do not
you know no side effects I'm going to
give you a recipe for that in one second
yes yes that order will work the other
order will not work I will track when
you try to use that community value
which is really just a junk value to
make you feel good it can be useful for
instance if you if you commuted
something that was empty your
transaction would see that it had
something in it if you didn't care about
the value that was in it you can at
least see that non emptiness which is
important sometimes yes
you can go back and read not otherwise
it's very cool except this software
transaction systems you read the papers
about don't work like this yeah this is
very much database driven MVCC and
everything else is really inspired by
like Oracle and PostgreSQL and that
database stuff yes it's a very database
the kind of thing all right let's talk
about agents so agents are for managing
independent state right we sought
transactions are super powerful it lets
you change more than one thing
atomically which is very powerful but it
has some you know overhead to it
sometimes you just you just don't care
you like you want to make a system where
you have loosely couple processes and
they just need to communicate with each
other so agents are a way to do that if
you've read about actor model or
whatever agents are sort of similar but
I dare not the actor model in particular
the actor model requires messages to
read the values agents do not so you get
an independent state you you have
actions which are again just functions
you say apply this function to your
state at some point in the future it'll
happen in a thread pool I don't care
when and that will transform your your
state they happen immediately when you
sense you call send or send off you pass
this function you return right away and
then sometime later that will happen
okay and ends up happening
asynchronously and synchronously in a
thread pool the system makes sure that
only one thing is happening to an agent
at a time and it makes all other kinds
of great promises you can dereference
agents and see their values but remember
all kinds of stuff is happening at the
same time you have to start programming
that way if you're still programming
from a perspective of the world is
stopped any time I want to look at it
you're gonna have to change that when
you get 600 cores you have to start
having looser ideas about how much of
the world needs to be consistent in
order for you to make decisions
agents let you do that
what's neat about this is if you send
actions during an action they'll be held
also if you send actions to agents
during a transaction
they'll be held so they will happen once
and once only when you commit this is
your way to do side effects because
agents can do side effects so you're
doing a transaction that's part of the
transaction and send a message I'm gonna
tell somebody and that will only go out
when you commit so that's kind of a cool
thing those two systems work together
yes they're actually two no not so far
but I probably need to give you some
more control to say these set of agents
live in this pool I don't have that now
right now there are two pools for two
different kinds of work and then again
as I said they're not actors an actor
model is a distributed programming model
the agent model is only a local
programming model the same process so
what does this look like it looks a lot
like the transactions which is a good
thing we say death food to be an agent
with this math value we can dereference
it we can see what's in it
no problem we can send foo look um
somewhere let's look to commute law or
altar block send through a function and
maybe some arguments that function will
be applied to the state of foo the
arguments will be passed to it as well
and that will become the new value of
foo if I save this and immediately go
and look it may not have happened yet
right it happens asynchronously a wait
will make sure anything I've sent from
this thread has already been consumed
then if I look at it I will see the
change so this is a powerful way to do
asynchronous programming this is a way
to launch threads right there's a
question about how do you launch threads
well this those things and threats
effectively what happens is to put some
message in the queue and waits for it to
be consumed it's a lot it's a way to
allow you to coordinate I want to make
sure you heard everything before I tell
you more but you have other people could
be talking to the same agent okay it's
the last leg you guys are doing great
look we're good but we're not pretty
good I'd like to have enough time for
some good talk so I'll try to get
through this quickly so any lingering
questions Matt you see wall of closure
maybe you put it together so closure is
specifically hosted I haven't shown you
much Java stuff but again the
integration is not a mere implementation
detail I want to be able to call Java I
want to be able to interact with it
Java is my low-level language and the
nice thing about a language like Java
being your low-level language is it
actually shares the same GC your memory
model or threading model and everything
else may think about all those issues
you have when you try to start doing
multi-threaded program or even just GC
the interactions - GC and calling out to
see it's a nightmare
yeah I'm sure what people like it's bad
so jaebeum's by runtime I can't say
enough about how high-quality the
infrastructure is in these JVMs you have
a wide range of choices
my son has their thing but you can also
get you know J rocket and IBM has
excellent VMs and this is a really
mature platform with a lot of
competition a lot of extremely bright
people working on it
this is excellent technology as goofy as
Java is the JVM is stunning technology
you cannot ignore it these just-in-time
compilers and these GC systems are the
state of the art closure allows wrapper
free interaction with Java a lot of
languages that are hosted on Java they
put their own classes around every Java
class there's none of that you call Java
you get a Java call of course the other
advantage of being on Java is this is
like they're absolutely libraries for
absolutely every single thing you ever
could possibly want to do and they may
not be the best but there
there there some are better than others
you know I'm not saying job is perfect
or anything like that but there will be
choices of libraries and in every domain
so what is the integration what form
does it take there's as much unification
as I can possibly make happen for
instance Java strings are immutable
that's perfectly fine for closure
strings they're immutable they're
Unicode we're done
closure strings aren't Java strings the
numbers I use are the Box Java numbers
the only thing I had to add to that set
was ratio otherwise it used the capital
you know i integer and things like that
all my collections implement the
collection interface of Java so if you
want to use them from Java you can pass
them if you have a thing that uses
collections or iterable they're all
interval all my functions are callable
and runnable so you want to use a
closure fun you know closure a closure
closure as a callback for a swing you
don't have to do anything you just pass
it because it's runnable and I showed
you before the closure sequence library
works with everything Java you know
iterable strings arrays the works you
can implement Java classes and
interfaces in closure which is nice
in addition I do support primitives Java
primitives as locals so if you have a
core piece of code that's you know your
inner loop where you want to max out the
performance you can make a few little
type declarations and say this is an int
this is along this is a array of floats
and you'll get the job of primitives
that correspond to that in addition when
you start doing math with those things
they'll get unboxed primitive math that
doesn't mean you'll necessarily get
unsafe math okay because so there's two
different levels there's and do I have
the Box in which you turn off with the
declaration and then you're going to
have to tell me explicitly I want bad
you know plus
I'll give you bad plus it ends up that
the boxing is much more overhead than
than the overflow detection so this is
what that looks like you can access
static members just directly it looks a
lot like that name space syntax doesn't
it
because that's really what static class
members are there things in a namespace
for the namespace is the class so I just
unify that you can call methods this is
a macro dot right says put dots in
between everything properties get Java
version and so this has no more it has
fewer parentheses than the Java version
you rapidly have fewer parentheses than
anybody for Java is like Oh lists parens
you just show them this one right right
do to a new jframe add a new label with
the low world and then pack it and then
show it it has a third of the number of
parenthesis and and blinds well you can
make java completely easy and
interacting with java stuff if you use a
sequence library didn't even know it's
java you totally don't care things like
this this doesn't look like job alright
this looks like list into a map filter
with this this is shorthand for fun
right seems like the most concise lambda
expression you can do a do this regular
expression fine across ooh this is
actually Java it's the only Java part of
this but it it's just transparent you it
doesn't turn your list code into Java
code
it turns Java code into list code that's
the beauty of it so don't be afraid you
know closure is Java with parens because
there have been lists from the JVM that
went that way this is what it looks like
to do swing some imports you know it's
this is a callback right we're proxying
this is a one-off implementation of a
Java interface it's an anonymous inner
class effectively with you would use in
Java and again this is so much more the
Java the Java for this is
three times the size I really like the
JVM it is a great platform it is serious
piece of technology my main complaint is
the lack of tail call optimization as I
said before I'm hopeful they'll get that
I can't also say enough about hotspot
and I'm using hotspot which is like Sun
branded thing there are equivalent ones
from IBM and from J rocket and whatnot
but these Jets are amazing for instance
I talked about that primitive math
actually closure doesn't emit any of the
primitive arithmetic byte codes if I can
get to a static method call on primitive
types those chits will finish and finish
emitting a the byte codes for Java for
arithmetic and be turning that into the
right instructions for the CPU and then
words I only have to get as far as a
method call and these optimizers get me
to optimize machine code which runs as
fast to see and often faster now because
they're doing runtime profiling there
are things you can optimize only by
looking at a running program and that's
the way these optimizes work as I said
before a ephemeral garbage is extremely
cheap I leverage that you should too if
you're not aware of it it's great and
there's so many other features you know
that it's verifier the security there's
a lot of the ability to load code over
the wire and Java has a lot of stuff
under the hood so the benefits are you
can just focus on your language if
you're looking to write a language and
want to target this of course I
recommend just starting with closure but
for me it really let me focus on the
language the infrastructure was great
sharing with the implementation language
especially these kinds of things do you
see big deal
you get tools for almost nothing i omit
the correct stuff they're correct
debugging information you can debug
closure step debug breakpoints the whole
works I mean I'm a list Forks user that
stuff only came a couple of years ago to
list works you have excellent debugging
excellent profiles and your choice all
work out of the box with closure and
then there are libraries for everything
you know closure users were instantly
doing all kinds of stuff I know I
couldn't possibly imagine in advance
they were just talking to databases and
doing you know net kernel stuff and big
document processing MapReduce Hadoop
lots of cool stuff
there's also excellent infrastructure on
the JVM for implementing things like the
STM this Java util concurrent library is
really good there's a lot more de
closure
it has list comprehensions ad hoc
hierarchy as I mentioned before with
type hints you can get Java code to run
exactly the same speed as Java so
closure is fast I hinted at the
relational set algebra and the parallel
libraries for doing parallel
computations automatically leverage all
the CPUs to crunch big arrays and
namespaces there's zippers like it's
paper and XML
questions generic generic plusses uh
it turns into a Java you know type tests
quickly and then branched to in my
library individual types which implement
logic for that type they will do an
automatic promotion to the bigger type
between the thing is that these
optimizers optimize a lot of that stuff
away
in fact they really can take something
where you have an even hand coded a fast
path and they'll chop it out and they'll
stick it over here a little say one you
know let me just try running that in all
in all cases and I'll have a little very
inexpensive test I'll use to see if it's
still the right way to go and then I'll
slope half the others so you know I
couldn't say because each JVM does
different things but it's pretty fast
the main optimization required moving
forward is something that they call
escape analysis where if you knew up a
box number and immediately consume it
they should be able to completely avoid
that allocation and that's something
that's just coming into the next
generation of optimizes for the JVM so
that will help all of these things and
in addition like I said if you really
care and you need to go right to the
middle you say int X and you don't know
no just best know nothing it's
using max there's Emax plugins there's
slime there's all kinds of cool stuff
already ported foreclosure on there's an
Emacs mode there's a VI mode it's not as
sophisticated there's a environment for
NetBeans a plugin for NetBeans which has
syntax highlighting and everything else
that has the best debugger support right
now the netbeans plugin but you can use
any debugger you can use J SWAT or gdb
or whatnot profiled with your kit which
is just gorgeous piece of technology
really all the tools work but in terms
of editing I added Java code with
IntelliJ and I edit closure code with
Emacs and I don't do no I'm not going to
do that because these debuggers are so
good though these debuggers when
debugging closure debug closure language
when I'm saying breakpoints and stepping
you're stepping through closure code
you're setting breakpoints in closure
code closure omits what a mapping file
and line number information that's
necessary for Java debuggers to say line
42 is over here in the closure
right
attach the debugger you can attach these
debuggers you don't have to be in debug
mode in closure if you start it with the
debug API live you can attach a Java
debugger to it whenever you want
including right then but I'm not going
to re-implement kannan list style
debugging because this stuff is you know
it's not the same but it's really good
and I don't have time for the other
somebody wants to they could but sure
right well that later is still I'm
waiting for later to know I started
closure for both platforms closure ran
on both platforms for a long time I just
got tired of doing everything twice I
also wanted to make a decision about
what will library authors do how will
the library for closure grow and as much
as I'm expert enough to do see sharpened
Java and many other people are everybody
isn't and it's a big thing to take on
having to do everything twice and and
you know do the least common denominator
and everything else so I abandon this
c-sharp report maybe two years ago now
it's certainly possible to do yes
c-sharp is everything you need to do
this three years it's been out since
last October so it's coming around a
year I'm just it's really taking off I
mean I have a a big group of users and
have over 500 people on them mailing
list and we get 5 or 600 messages a
month and I have you know thousands of
SVN hits a month so I think I have a
couple of thousand users
well you know I don't hear from people
unless they have a problem so I wish I
knew I do know there's a couple of
companies using it and it's sort of like
their secret weapon thing you know they
do document processing and some other
stuff I've seen interesting database
work I've seen interesting graphics work
and XML things this some really neat
stuff like there's a zipper library
which allows you to sort of pretend
you're manipulating something in a
destructive way when you're really not
and producing a changed version of a
data structure and somebody wrote a
really neat like XPath like way for
processing xml functionally with that
excuse me
400k fits on a floppy disk if you could
find a floppy disk and half of that is
the ASM library that I use to emit the
byte code those is about 250 300k
sure Haskell and all the STM work and
basically anything I could get my hands
on to read a lot of database stuff went
into the SDM you know that old undressed
writer book whatever which will make you
really never want to use the database
that's not MVCC ever again really
whatever I could get my hands on to read
I like to read closer verses Scala well
Scala is statically typed and has one of
these sophisticated type systems I think
closure is more strictly functional
because it defaults to immutability and
defaults to the data structures are
these persistent data structures it also
has a recipe for concurrency built in
there are some library work for that for
scallop but Scala is really still a
multi-paradigm lock language where the
objects are still those old share the
reference to the block o memory objects
and I think that is doomed yes yeah I
highly recommend it it's so much fun
well they found well he found it did on
this problem of course you know the
whole thing with that stands everybody's
like STM is this holy grail and and when
you try to say something's only gravel
it's it's gonna fail right because
nothing can it's do everything you still
have to architect your programs you
still have to have some sense of what is
the contention profile in my program you
still may run into performance
bottlenecks that you have to solve by
changing the contention profile of your
program I mean it's not a silver bullet
what it is is the way to write something
that's correct
easily and the tools for doing that but
there's still going to be you know work
if you've ever written programs with
locks I mean you can be wrong on two
cores right away it's you can be wrong
on one core it's so easy to be wrong my
brother did it for me it's the Willing
in the angle lambda yeah he's good
yes it's not the same thing because
Haskell everything is lazy right so
that's a big difference when everything
is lazy it's very difficult to tell when
you're gonna have this explosion in
memory requirements and that's the
problem people are going to with Haskell
with closure the laziness is limited to
these sequences and in particular I'm
very careful that inside a sequence
operation as you move through which is
usually you're doing usually you just
maybe have a concatenated set of
operations but you're walking that
window through your data set I make sure
by cleaning up the stack that you don't
have you don't retain the head it's easy
to retain the head accidentally in
hospital in which case as soon as you've
realized this thing you've realized the
thing as soon as you've walked it
clutched it you have the whole thing in
closure you walk it you don't have the
whole thing in fact you can erase as you
go I mean it can get GCD as you go so I
haven't seen that be a problem in fact I
think the laziness is a real attribute
in the low memory utilization of closure
programs
it's about 15,000 lines of Java and
4,000 lines of closure
absolutely in fact when you define a
Java class enclosure you end up with the
Java class that's extremely dynamic much
more dynamic than a regular Java class
in fact all it is is a set of stubs that
hook into closure bars so you can notice
it's not it's not funny it's very
powerful you can you can write Java
classes in closure that you can fix
while they're running you can you can
fix the definitions of methods you can
also write transactional Java objects in
closure you can write Java objects in
closure who's whose data can only be
changed inside transactions it's cool
yes well you know how it is when you
have something that works there's a
reason that the data structures are
written in Java and and the interfaces
are written in Java and that's so that
consumption from Java is is
straightforward closure does not yet
have all the mechanisms in closures Java
emitting syntax to do the lowest level
like field type declarations you need
for the highest performance classes and
I'm not sure I want to go there because
it'll end up being Java with parentheses
by the time you have private protected
whatever and all the declarations you
need to support exactly what you would
do in Java so the biggest thing that's
in Java that probably I would like not
to be in Java is the compiler itself
it's about four thousand lines of Java
and people have asked about
bootstrapping that that's certainly
would be possible to do it's the old
it's working right now kind of problem
and I'd rather do new things so I don't
have a big thing I mean I know it's like
sort of a chest-beating proof of
whatever I really just don't care
you know some people have tried to do
that I mean unfortunately even 450k is
is it's a bit much but one of the other
challenges is just that I do need a fair
amount of Java concurrency mojo like I
only go as low as Java 1/5 because I
need a lot of the job you to a
concurrent stuff to support some of the
things so that's definitely something
I'd like to do another thing that's
tough on the mobile phones is dynamic
code generation the bytecode loaders and
some of the things are secured that way
one of the things on my to-do list is
ahead of time compilation to buy code
which will let me target some of those
static platforms like Google Android so
yes
I don't do it that way know it that that
we'll walk through and just like okay
like I said just this guy you'll have to
walk to get to ten billion but it's
going to throw everything away on the
way it's not a chain it's there's no
realized chain if you haven't hung on to
the first thing you don't have it if you
say drop you know ten billion from cycle
whatever and then take three you'll have
those you know the head of that three
and you don't have 10 billion anything
it's not a chain of promises now it's a
cleans up as it moves that's the truth
what happens is there are suspended
expressions yes in the first in the head
when they are realized they're discarded
now the realized versions are cashed now
we move to the next now we have new
expressions now we evaluate those now
the expressions are let go up the values
are there in addition if this was held
on the stack and this is a nested call
or some reduce or something like that no
one else is looking at this we raise the
reference to this boom what's left one
guy two values no lingering anything so
no is the answer we don't it doesn't
build up no I can't talk about Haskell's
implementation all I can say is it is a
known problem with some Haskell programs
that the laziness has these interactions
that make it difficult to predict the
rememory usage of your program in
advance I'm saying enclosure that's not
the case because you the laziness is
limited to these sequences and I've just
told you their behavior that makes it so
that they don't accumulate anything that
you haven't asked to hang on to if you
hang on to the head and then go for
billion next and it rests well you know
you're now hold on to a four billion
item thing but but you didn't have to do
that and I will do that
accidentally for you
yes yes
yeah it is there is hope right now I
have the same that Java does it's the
same thing arrays are arrays of arrays
multi-dimensional arrays arrays of
arrays but I've seen some cool stuff in
IBM's X 10 language where they take
being like a giant array and then they
pretend as multi-dimensional even though
Java does to support it and they have
some very neat syntax for using little
tuples to do sub ranges and to do
multi-dimensional indexing and I was
inspired by that and maybe if it comes
to it I may copy something like that
guys the neatest I've seen it gets
around those problems
datalog maybe no my good datalog
implementations yes I'd like to add some
where closures going as I'd like to add
some declarative data access stuff not
really Prolog because it's not like that
great for database work but data log
which is sort of a subset of Prolog for
which a lot of research has been done in
optimization would be a good mini rule
system plus data access that that's
pretty you know it supports recursion
and things like that so I'm still
researching whether I'm gonna roll my
own or use iris reasoner which is the
java one that's open source Maps yes
there is there is actually something
called a struct in closure and it's an
optimized implementation of map where
you know you say I know I'm gonna have a
10 million of these things they're gonna
have fields a B and C so repeating a B
and C and all those little maps is kind
of a waste of time so I can make that go
away but it still implements the map
interface and for all in terms of
purposes it is a map you can still add
extra stuff to it just like you did you
cancel a social so it's nice it's the
best of both worlds multiple values you
do whatever you want but I don't have
them on the stack I can't do them
closure is stack compatible with Java so
there's no multiple returns
no no I mean you know that like I said
most of the transfer transformative
functions of values will be metadata
preservative so and you're just going to
pass a function to the transaction to
say modify the value with this function
which will be something like is so sure
or something you wrote with based on the
source will still preserve metadata
metadata is very neat you can you can do
multi methods that key off metadata so
do this if it's data I don't trust that
kind of PI morphism is something we need
in doing everything types really has
limited us
yes I learned that those guys need to
learn a lot more about languages that
aren't a lot like small talk no I mean
they're their first cut is to try and
support the the popular languages they
are which are JRuby and JSON which you
have very similar object models so they
have a distinguished receiver and stuff
like that in the mop and I did try to
tell the guy look just you know move the
parenthesis over and let's just let's
just realize it's all functions right
could we just do that you know there's
no such thing as weapons
all the deaf ones in the other classes
right well and there were some of these
languages need to you know generate tons
of classes in order to like for instance
do those rappers I said close your eyes
rapper free access to Java a lot of
these languages don't in addition a lot
of these languages have you know they're
like Ruby and Python they're written by
guys who writing something fun for
themselves they weren't thinking about
compiling those languages when they
wrote them now you know these Java guys
doing JSON and JRuby you're trying to
compile them and it's very challenging
so one of the things are trying to do is
you know polymorphic inline caches and
all that stuff and when they generate
any code in Java you have to generate a
class that's the unit of code so they
are doing a lot of ephemeral class
generation and classes have an impact on
this perm gen really doesn't do any of
them yeah which is not that many unless
you really need to fix that function a
lot well you know those things are all
compiled so you know even if you see
funds that's not like a new class at
runtime
it's a classic compile time so that's
the stuff that they're talking about
yeah if you were writing generic
programs right he needs to do a lot of
evaluation the function that furnace
from store you would get into permian
issues yes yes
I think anything I mean right now if you
want to write a program
I mean closures designed to be useful
anywhere you would use Java and Java is
being applied
you know people already asked about
phones and the 600 CPU machine so it's a
wide range it's the same question for
lisping what is list good for it pretty
much anything and if anything that you
can think of a way to parallel eyes I
mean by the time you get to 600 course I
actually think most applications will
never be able to leverage 600 cores
there'll be certain kinds of things that
can in most applications I talked about
that task parallelism most applications
were being able to number their tasks in
the low dozens I think really so the job
of those mega machines will be to run
multiple of those applications the main
thing for closure is you can write that
multiple dozens of tasks parallelism
without error and in terms of
applications I mean every application
I've ever written has needed to do that
and struggled to get it correct so I
think it's good for for a wide variety I
wouldn't want to pin it down yes
no no it's a runtime thing in a
transaction it's just a thread local
thing that we're in a transaction so the
strands racks are going to be in a
thread and then the transaction starts
in the thread and there's a transaction
object references all interactions
references is going to test for the
presence of that object to make sure
that you are in a transaction that's how
we got that exception before you have to
go through references that's the beauty
of this SDM you have to have identified
the things that can change either
they're in an agent they're in a bar or
in a rack correct multiple questions
yeah that's correct except I do not
track reads closures STM is unique it
does not track news right it's MVCC
you know that I looked at that I mean I
I think I actually think that the
condition system is in a hard-coded
special case and Kondylis that if you
had some more general primitives the
condition system would just be one thing
to get implement with them enclosure you
have two things you can utilize to help
you with those kinds of problems one is
the exception system which allows you to
travel up and down the stack the other
is that dynamic binding of functions you
want to have a function I'm going to
bind this function to something that you
should call if you have a problem well
now you've got that ability to call some
code from above down low to see what you
should be doing combining dynamic
functions and exceptions gives you some
of the conditional system but you don't
or an exception that's what I'm saying
let's say let's say you're you're
somebody who needs to talk to to the
file system right and you say if I have
a problem talking to the file system I'm
going to call I had a problem talking to
the file system somebody above you
combine that to do whatever you want
you're gonna call that use the return
value and not throw right and so I think
that gets you most of the way there
dynamically really bindable functions
and exceptions I think is enough I like
the condition system but it seems to me
to be a hardwired special constructor
yeah
you know I've looked at you know whether
or not you should instead of having
everything be potentially dynamic you
call out the things that you're going to
allow to be done now the problem with
that is you know you don't know now your
program is running and you say oh we're
having this problem in here I wish I
could log this function
well you didn't declare it dynamic so
now it's stopped the running system and
so rather than do that I've made it so
that all of ours were potentially rebind
able and I think that's a better way to
go only because I was able to make the
check extremely inexpensive so that it's
it's it you can incur it everywhere so
far that's worked out the cost of
calling them out would be you would be
couldn't on an ad-hoc basis say oh I
wish I could dynamically bind this
No
there was there was talk about it at the
JVM I mean if the JVM supports them I
don't know why I wouldn't but otherwise
I think they're too complicated for me
continuations
No
no no I mean I think the system is good
you know if you're if you're coming from
Common Lisp and you get your head around
how this is different you'll see it does
get rid of I think eating plus percent
of the hygiene issues really just go
away because this Mac when this macro
was written list man the list function
in closure it will emit something that
will make sure that gets that binding
and that is what hygiene is about but it
doesn't have a sophisticated renaming
system I also don't understand those two
especially the implementation is like
the sourdough implementation of that
right and no one ever reimplemented
everybody just passes this one thing
around which means if you if your
language isn't scheme you have to you
know what do you do right I seem to see
this one implementation of hygienic
macros reused let's say everywhere it's
complicated
no just the stuff just the material on
the site there's a lot of material on
the site but we have a good group and
you know any question or dialogue you
start will you know inform everyone so I
encourage anyone who's using closure to
join the Google group and you know I'll
be happy to expand on any details all
right well what zipper some French guy
whose name I can't quite pronounced who
at weight or hue or wet Huet wrote a
beautiful functional pearl on zippers
which is a way to navigate through a
tree-like data structure as if it was
imperative and you can go through and
you say boom and get here and say
replace this with something else and
then you can say up up up up up above
you go back up to the root of the tree
and what you have then is a changed
thing there's an implementation of that
here in closer
okay thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>