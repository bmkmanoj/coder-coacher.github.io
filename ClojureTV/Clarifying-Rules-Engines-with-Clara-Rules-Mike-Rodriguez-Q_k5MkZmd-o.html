<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Clarifying Rules Engines with Clara Rules - Mike Rodriguez | Coder Coacher - Coaching Coders</title><meta content="Clarifying Rules Engines with Clara Rules - Mike Rodriguez - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Clarifying Rules Engines with Clara Rules - Mike Rodriguez</b></h2><h5 class="post__date">2016-12-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Q_k5MkZmd-o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Mike Rodriguez and today I want to
talk about rules engines and I've been
using rules engines for about the last
four years now at cerner and the
healthcare space and today I want to
talk about what rules engines are what
problems they solve and how they work
okay so throughout the talk I'm gonna be
using clear rules to demonstrate and
clear rules is an open source rules
engine it's written in closure by a Ryan
brush who also works at Cerner we've
been using it and contributing to it for
about two years now and we use it in
production we used to use drools
exclusively before that and and the
goodnight good thing about clarus it's
been able to perform competitively with
drools as we've transitioned and that's
been a really important benchmark for us
because we try to run thousands of rules
against datasets that sometimes have
hundred thousand plus data points within
them so we're going to talk about clear
a little bit more as we go so the rules
engines I'm referring to today will be
the forward chaining inference engines
they're derived by some variation of the
the Reedy algorithm Paula
yesterday and the Naugatuck discuss the
Reedy algorithm a little bit and today
I'm gonna have a little bit of a more
discussion on it towards the end just as
it applies to Clara and in the examples
that I have today
and so the Reedy algorithm was around in
the 80s and most of the rules engines
today most of the forward chaining style
ones are based on some variation in this
algorithm and that includes clear rules
so when we're talking about rules
engines first let's talk about what a
rule is and rules just an if-then
construct and we have a left hand side
in the right hand side and the syntax
I'll be using today is gonna divide the
two sides by this this arrow the symbol
arrow so the left-hand side is the if
side of the offend and the right hand
side is the bin side and so a rule is
considered activated when all of the
left-hand side conditions are satisfied
and then when a rule is activated that
just means that the rules engine its
eligible to be fired by the rules engine
and firing a rule just means to execute
that action on the right-hand side so
rules are evaluated against the data set
and this data sets stored in memory we
usually call it the working memory
every data point within working memory
is called a fact so the the right hand
side action of rules they perform
arbitrary side-effects but the important
one in the most common is that they can
update the state of working memory and
since so they can insert new facts they
can retract and update existing facts
and since they can do that they can
influence the behavior of other rules
because the changes to working memory
will influence if other rules are true
or false so when you compose rules
together you can form more complex
conditional logic based on this alright
so the basic job of the rules engine is
just to evaluate this set of rules
against this working memory state and
the basic evaluation is like this is a
loop with cycle where we where the rules
engine determines which rules are
activated it picks one of them and fires
that one and then it just re-evaluate
Stussy which rules are now activated
because things might have changed cuz
working memory might have changed and
eventually you run out of rules that are
activated in the loop stops and once you
stop the rules engines in some sort of
steady state at that point and that's
when you would query on it to figure out
what happened what facts are involved
and what what information was derived
during the firing of the rules so I want
to take a minute couple minutes to look
at Claire rule syntax because I'm gonna
use some of the syntax as we go and some
examples later on so starting off just
real basic here's a rule def rule
defines a rule it's a macro the rule a
it's a saying the rule name is rule a
this rule is not do anything useful or
interesting it's just about the
structure there's a left-hand side in
the right-hand side they're divided by
this arrow symbol like I showed before
and this rule has one condition in it
and conditions are always surrounded by
these square brackets like a vector and
so a rule is this condition here is a
fact matches this condition if it has
the type of fact type 1 that's what that
means and then it also has to satisfy
all these constraints that follow the
fact type and here I have this
constraint F in X some value and I'm
just putting that that there to show
that it could be it's any function you
can use any chain of functions you want
right here and your functions are just
going to act as a predicate so nil and
false or false everything else is true
and the X is referring to the field
named X of the fact that we're talking
about
so the Claire will syntax does allow you
to access fields directly by their name
but other than that the function call is
natural like some value is just a
keyword and I'm just showing I'm just
putting it there to show that calling
functions is how you expect function
calls to work but the second constraint
is special and so any symbol you see
that has a question mark to starting it
is what we call a variable binding and
what variable bindings are pretty much
it look like a local variable that can
be used throughout the whole body of the
rule and so why binding here is being
bound to the value of the field Y and
you can see I'm using it in the right
hand side so it's like locally scoped
and when this rule fires so the right
hand side you see insert that's a
function call and Clara that's that
mutates the state of working memory so
it's inserting a new fact in a working
memory and you see that I'm just making
an object called thingy and it's but
it's using that that Y binding valued as
we derived the new information so
looking at another rule this one's
pretty much the same rule as the first
one I just added another condition on to
it to demonstrate another feature so
looking at the second condition I have
join FN which again that name doesn't
mean anything be any functions you want
but the arguments to it are important
taken y&amp;amp;z but notice that Y is a
variable binding and that it's bound to
the field Y of the fact on the first
first condition but Z is a is a field of
the fact from the second condition so
we're putting two facts together so
we're creating a join sort of logic on
those two facts so this is how rules can
express joins like in relationships
between facts and this rule would be
activated and it would fire for every
every possible join between the two sets
of facts I also demonstrated a little
bit more syntax in that second condition
just to show it it starts off with this
variable binding called fact - and then
this arrow that points to the left and
all that means is it just says bind this
this fact to variable - to the entire
result the entire fact that matches this
condition instead of just the field at a
time like I've showed before
but other than that that's just a normal
variable binding you can use it the same
way as the other ones this rule the only
thing special here is the second
condition is a negation condition they
start with the key
not and then have a nested condition
inside of them and this is going to be
what you would expect from negation it's
it's true when the nested condition is
not satisfied so it's it's checking for
non-existence of a match and then one
more style of condition I'm
demonstrating with this rule is what's
called an accumulator condition it's the
second one has the keyword from in it
that's how you can tell it's accumulator
and after the from is a nested condition
before the from is an accumulator and
base what these do what these conditions
do is they take every fact that matches
that nested condition at once hand it to
the accumulator the accumulator produces
some value based on that and you can use
that aggregation value instead of just
the separate facts that made it up so
these are important when you want to
have a condition that reasons about a
whole set of matches at the same time
rather than one at a time like the
normal rule matching goes using a
variable binding called all that just
binds to that result of the accumulator
and then I can use it in the right-hand
side or anywhere else you could usually
use variable bindings the other thing is
ACC all that ACC / L that's just a
built-in klara accumulator that takes
the facts all the facts that matches and
it just makes a collection of them and
returns it so it doesn't really do any
work besides this pass the collection
along there's also more interesting
things you can do with the accumulators
like find the best match of all the
matches by whatever definition the best
is such as maybe the newest one if
you're looking at dates so any kind of
arbitrary aggregation operation and
they're customizable you can write your
own accumulators so the last kind of
important feature of the rules engine
that i want to talk about is what's
called the truth maintenance system and
i'm just going to explain what that is
just by looking at an example so there's
two rules here we have find a and find B
and find a just it's satisfied whenever
we have a fact of type a and when it
fires it inserts the fact that type B
find B's like the mirror image of it but
it just looks for facts of type B
instead and inserts the facts of type C
so if we had working memory with nothing
in it originally and then we add a fact
that I'm gonna call a one which has type
A then we fired the rules then find a
would be satisfied
and then we would insert a fact of type
B I'm gonna call that b1 and then when
that happens the find B rule is
satisfied so then we will create a fact
of type C and call that c1 so after we
inserted a one we got a 1 B 1 C 1 so
then let's say that we want to retract a
1 at some point later either you could
do this like an another rule maybe that
wasn't involved here or like the
external application could retract it so
either way that happens if we're
attracting a 1 what's going to happen by
the truth maintenance system is it's
also going to retract B 1 because it's
it remembers that B 1 was inserted
because a 1 existed and now a one's gone
so B 1 has to be gone too and
transitively the same things gonna
happen to C 1 it was only supported
because of b 1 and b ones gone so we
don't have c 1 anymore so retracting a1
alone retracts a 1 B 1 and C 1
the reason I'm bringing this up as an
important feature in most rules engines
habit and including clear is because it
allows you to write these complex sets
of rules that where you don't worry to
have to worry about the order that they
fire and the way they interact with each
other like you don't want to be
concerned that if one fire is too soon
that it'll make another rule false that
you've already fired you so not having
to deal with this problem of when things
are happening instead what you get is
after the rules of fired you know that
the state of working memory is going to
be logically consistent with the
left-hand-side conditions expressed by
all the rules so with that out of the
way I want to try to drive some some
reason behind why you might want to use
a rules engine and B the two main big
points I I say that might be of interest
is you can declare to the express
complex conditional logic and the other
thing is the rules engine tries to be
efficient and avoiding recalculating
this intermediate states that are
involved in different paths through the
logic and I'm going to use an example
and kind of walk through it so that we
can see some some kind of concrete
visualization of what might be happening
how the rules engine might help so my
example problem is a really simplified
version of just looking for hypertension
which means high blood pressure and
we're the rules here are going to be
that a person's hypertensive if they
have a blood pressure that has a
systolic value greater than 140 and the
diastolic value greater than 9
and it was taken in the last year so
that's what you call greater than 140
over 90 the other stipulation I'm gonna
add is that blood pressures aren't just
gonna come into the system pair it up
already instead we're gonna get
individual data points on a result model
and they're gonna be either up types of
static BP or diastolic BP and we're not
and we have to put them together to get
valid pairs before we can test the
values so to get a valid pair you would
you join them by having the same day
okay so I'm gonna start off with using a
function composition style approaches
what I what I mean by this is just kind
of your standard how would you do it and
some close your code kind of kind of
approach and you might end up with
something like this I'm pulling out all
the pieces to make it really clear
what's happening so I have these kind of
helper functions and then I have this
hypertensive function that really deals
with the the actual problem statement
and so the hypertensive function you can
see this composes everything together in
the end
so my helper functions are little things
like I have results and I have a BP type
so I just want to get the results that
have that BP type then we have a
function that combines blood pressures
takes systolic blood pressures and
diastolic blood pressures and puts them
together and then we have a function
that could take blood pressures and
narrow it down to only the ones that are
within the given period relative to some
current date and then a value testing
function but then the hypertensive the
actual function implements the logic
just threads them all together and
that's pretty common you have all these
simple composable pieces and you compose
it all together to deal with your
problem so the only thing that's
interesting at the end we just look for
one that has a value greater than 140
over 90 which was our original problem
so this is straightforward and this this
doesn't require any further thought
really but usually what happens is these
problems don't stay this easy like I
probably don't only want to ever know if
the person's hypertensive if I'm trying
to do some kind of figure out some
information about a person's data like
health care so I might want to ask more
questions as the system goes as time
goes on so I might have new logical
branches that are related but not the
same as the one I have here the one I
started and then also you might want to
just make it more advanced with how do I
find blood pressures it might get more
complicated than what I have this is
pretty pretty basic I just take every
result and join them together
the same day someone to look at a couple
ways to extend the original problem I'm
calling that evolving the original
problem and see how that how that
affects what we have so far so let's
look at finding hypotension which sort
of confusing that's almost the same work
but it means low blood pressure and
we're adding that we still want to find
hypertension but we also want to look at
hypotension at the same time because we
want to know either way which one that
which one a person might be so the rules
for that is just they're hypotensive if
they have a blood pressure with systolic
value less than 90 diastolic value less
than 60 and it was taken in the last
year and all I add that like any of
these numbers I'm using I'm just making
them up don't think that you have
hypotension or hypertension or something
like a some kind of standard anyways
look so this is what these are the rules
that I would add maybe to solve this
problem just the easiest way it's just a
new new function that testable blood
pressure is values less than some value
because I was doing greater before and
then I have this thread of logic to
figure out their hypotension if they're
hypotensive and it's exactly the same as
hypertensive except at the very end I
just check a different value I look at
less than 90 over 60 instead so that's
sort of undesirable just like you would
think I have two functions they're doing
pretty much the same thing so you're
you're thinking that's a code issue
you're having duplicate code but the
other thing is that's probably more
important a lot of times is it could be
expensive to redo that with the common
work so you don't really want to keep
doing that over and over again and let's
say we don't want to do that over and
over and over again so we're gonna have
to do something about manage getting
that common part out and there's a lot
of ways but basically what it comes down
to is do the common part at some prior
step make it available to ask the two
questions that are both involved both
using those blood pressures as long as
using a wet binding here you could have
make another function that wraps those
but doesn't really matter and and so
this solves it again but notice that the
addition of hypotension is a problem
mamie have to go change the original
hypertension problem function so I had
to go completely refactor everything for
this and you could also think that this
was very manual that I had to figure out
this counter that I have some common
state that I want to deal with
I have to pull it out myself and kind of
manage where I where I store these
intermediate results and how I'm going
to get them down to all the logic
branches and like I said things could
keep getting harder like you could think
maybe I don't want blood pressures just
in the year maybe I want the ones in a
month in the month for some different
problems so now I'm kind of like
starting to deal with another chunk of
blood pressure that I want to use for
some other problems and he was gonna
keep breaking down the branches storing
all these intermediate states to try to
solve all these problems so we're gonna
come back to this when we look at the
rules but keep that in mind going on to
a different style of change to the
original hypertension function now let's
say we want to filter out any blood
pressures that happen with an emergency
room visit and you might want to do that
because somebody could be on medication
in the emergency room or in critical
condition so you don't want to say they
have high blood pressure just because
they're they're hurt or something so the
emergency room visits they come on a
different kind of fact let's say they
come on in model we're calling encounter
and we just want to get rid of blood
pressures when they happen when they
occurred with that but with that
emergency room busy going back to that
hypertension hypertensive function from
before I'm just extending it to try to
deal with the new logic this stuff about
emergency rooms now so I have a function
visits for type it just deals with
filtering encounters down by type that's
why we get the emergency room visits has
visit just takes a blood pressure in a
visit and determines if they go together
and then down in the height now
hypertensive used to take current date
and results as an argument but now it
takes current date results and
encounters because now we have this
other chunk of information we need to
know about to solve the problem and
inside I'm grabbing the emergency room
visits out of the encounters and then
I'm taking blood pressures I made a
helper function to take a blood pressure
to see if it goes with any of those
emergency room visits and then I add
this remove step remove has ER visit to
the original chain of logic and and then
it's done that pretty much solves it
again but the interesting issues of this
one are harder to see but if you on the
surface you can tell that I mean
hypertensive had to take a new argument
to deal with new logic I mean that makes
sense because it's a new thing we need
to consider but it ends up causing this
function to be pretty coupled with with
the idea of finding an emergency room
visit
before so it can use it later later on
in its chain and you can keep breaking
that out to separate functions like I
could have another function that makes
ER visits ahead of time but then they're
gonna have to come here as an argument
anyways I can solve the other argument
and you could try to do stuff with
closures and stuff too but I either way
you're still trying to get this
information down the stack somehow and
you could I also see you also see
patterns sometimes we're like combined
bps that in the middle like the second
part of the thread it might want to take
the encounters and do the emergency room
visit logic itself instead of
hypertensive so then what you would see
as hypertensive would be passing
encounters through two combined bps and
it won't even be doing anything with
encounters so it just becomes the
middleman and you see that a lot of
times when you start trying to thread
that compose a lot of functions together
there's a problem of wiring them
together and figure out how how am I
gonna get an input from way up here and
all the way down here in the second and
there's some solutions of that like one
big map being passed around or some
global State thing or dynamic VARs but
in general it's it's a bit of an issue
so gonna look at the rule driven
approach to try to show that rules
engines help address concerns like this
and going back to the hypertension
problem I'm gonna start writing some
rules to solve that the original one so
we have a rule for finding systolic
blood pressures from results when they
have the types of static blood pressure
we insert effect we're gonna use fact
types here like systolic BP to indicate
that that we found a systolic blood
pressure so we can use that as like a
higher-level model for questions we want
to ask later we do the same thing for
diastolic BP then we have a function for
combining blood pressures together so
you take for each systolic blood
pressure and diastolic blood pressure
pair they have the same day we we insert
effect called BP that has the value of
both plus the date and then remember we
want the blood pressures within the year
last year or whatever it was so we take
a current date and a blood pressure and
for each one that we find that has that
same year as that current date we
inserted another fact we're calling
current year BP just to mark it as you
know we found a blood pressure for the
in the year and we do that for every one
of them current date as a fact here I'm
just that's this kind of a common model
for how to do it and rule so I'm not
showing any
with that you can imagine the external
application inserted the current date
just makes it easier to think about the
current time that when you hit think of
it as a fact just as another fact in the
rule and then finally there's a rule to
find the hypertensive which is the the
problem that we were actually trying to
solve in that original one and it just
takes current year BP's and looks for
ones that have a value greater than 140
over 90 and when it finds one it inserts
a fact called hypertensive and the entry
was interesting things going on here
though so the hypertensive fact it's
being inserted notice it's it's taken as
an argument that BP that caused it and
also notice I'm using an accumulator
because I might have more than one in
the current year that is over 140 over
90 but I'm gonna make a decision here
saying maybe I don't want to this insert
a whole bunch of hypertensive facts
because that might not be that useful
maybe I just wanna take the newest one
so that maybe that's the most relevant
since it's more recent than the other
ones and if I attach it to the fact if
my external consumer wants to look at
that they could use that for debugging
or tooling or even just to show it as
supporting evidence of why I derived
this information so instead of just
saying the other hypertensive but now
you can also make a chain of the
reasoning behind it and it's kind of
automatic like at least it kind of flows
naturally with the rule the rule forward
driven approach and then I have to
define a query I'm using a macro called
def query from Clara it's the same as
def rule there's just no right-hand side
and but what queries are what queries do
is they allow the external consumer or
application to be able to look into
working memory for things that they're
interested in so I'm making a query so
they have a way to get in there and look
for hypertensive attacks that may have
been inserted when the rules were fired
just a doubt this is demonstrate this is
some way that you could run rules just
to make it clear how that works
Clara has a function called make session
it takes rules and it produces what we
call a rule session which is just a it's
just a set of rules and some state of
working memory and then I'm threading it
along so insert all is inserting all
those facts into that session and then I
could fire the rules that runs that loop
until the rules stop until we're at a
halting state where the working memory
is stable
and then we query the session to find
hypertensive results so I want to go
back to this evolution of the problem
that the two different branches we had
before we'll start off with define
hypotension so given the rules I just
talked about how do we add this
hypotension question along with those
rules and that requires these two rules
well actually it's a rule in a query so
fine' hypotensive looks like fine
hypertensive but not-it's looking at
current year blood pressures that are
less than 90 over 60 instead and it's
inserting a fact for hypotensive instead
and then we have a query to get that
different type of fact out for the
external application to grab the cool
the cool and the interesting parts here
really is that I didn't have to go touch
anything to do with hypertension which I
did have to in the first example and I
also get all the anything that they
share in common like the current year BP
that's the fact they share in common I
don't have to there don't have to worry
about recalculating anything or where to
store that intermediate information it's
already handled by the engine so they're
getting their branching off of just two
different points of the rules and
they're getting all the Speight this
shared state or whatever I'll just
shared intermediate results that they
could have and I don't have to do any
work for that so it made it extending it
with the new logic branch was was easy I
could just throw it off onto the side
and there was and I don't have to be
worried about what else was happening
anymore I don't have to deal with the
branches that aren't related so looking
at the second example from before where
we were saying filter out blood pressure
ease when they had a emergency room
visit you might have to add some rules
like this and the first rule takes
encounters that are they have the type
of ER visit which is emergency room and
it inserts a fact called the ER visit
when it finds one of those and then I go
back to that original combined bp's rule
and i just add an occasion condition to
it that not ER visit and that's where
that's where i say that i don't want to
consider any blood pressures for any of
my logic that come from an emergency
room visit so i just put it here and I
don't have those blood pressures anymore
and that applies any branch I ever have
up at this point and and like I said
this one's a little bit harder to see
but remember remember I said encounters
really didn't have any business with the
other logic that like an emergency room
visits were what we want to figure out
and we don't that could be a harder
problem than just encounters that have
this type it could be a bunch of rules
that decide how to find an emergency
room visit that takes a lot of different
data points right so but what what they
do is they insert the fact when they
find what we're looking for and then so
then we just have this single the single
fact to think they use and we we put it
in logic where it belongs like naturally
in the requirements and then we're done
so it's easier to add on these extra
conditions because you can go deal with
how to how to figure out this extra
information on the side and you can get
it and you could say just you could just
refer to it from one of your other rules
and all the wiring about how to get it
there is done for you you don't have to
worry about how to pass this encounter
information down some stack they figure
out how to get it to this rule you don't
have to do that you just say it makes ER
visits this rule uses ER visits and the
engine will make sure that it gets
tickets there so I hopefully have
motivate some reasons why how the rules
engines can help with this kind of
extending problem and I just want to
look at a little bit of how they work to
make it a little clearer what's going on
and especially how that pertains declare
rules and we're gonna discuss the
reading algorithm a little bit and it
was around and like 1979 and 80 and 82 I
think there was several papers by doctor
Charles 4G about this and I think one of
the more popular ones is this one from
1982 I think it was one of the more
official and but basically basically all
we're trying to do is take the rules
they have conditions inside of them
we're trying to turn those conditions
into nodes and make a network of nodes
and some and have like the data flow
down the nodes of the network and that
typically looks something like this and
and the way I I made I hand crafted this
diagram and it kind of it kind of looks
like sort out Claire would represent
Claire rules would represent the Reedy
network it's a directed acyclic graph
and the first you have working memory it
propagates facts out to the first nodes
and if and every time that satisfies a
node they just propagate those those
matches down to their child nodes so the
very first level of discrimination
across the facts or partitioning is just
by their fact type and then from there
it goes into what we call the Alpha
nodes when
you find matches and Alpen those are
really just extra filtering they're only
they're only involving one fact at a
time just like is your type systolic
blood pressure and if it is it
propagates it along and it gets to these
beta nodes and they're represent complex
joining between more than one fact at a
time two or more and you can join a lot
of facts at a time you can it can go
deeper than like just two facts together
it could be two or three or four and
what you're gonna see is you're gonna
see beta nodes sort of start chaining -
they're gonna 2 or 3 or 4 beta nodes
represent that because each beta node is
responsible for like one part of that
joint as you as you go down a rule so I
want to look more directly at the Alpha
nodes and they're often called one input
nodes and the reason is like I said
they're really just they're only
concerned with the property about one
fact at a time so that's their one input
taking one of the rules we had from the
example hypertension problem we this
might be a little many reading network
that comes out of it and you see that we
have working memory propagating facts to
the fact type result which is the only
one the only type we care about in this
network and there's an alpha node to do
that test of is your type systolic blood
pressure and then when that's satisfied
it propagates it to its child nodes and
here I'm using these red trapezoids the
main terminal nodes which they really
just represent that the rule is fully
activated said it's satisfied it's
eligible to be fired so and I just
labeled it with the action that it would
take in that and that right hand side if
when we fire it but beta nodes are a
little bit more interesting they have
they're often called two input nodes and
what their inputs are is is that they
have on one side they have a fact just
facts coming from alpha nodes so just
single facts but on the other side what
they're getting is collections of facts
that have already been joined and what
they're trying to do is see if they can
get that new fact to join into that same
that collection to create a collection
that's one fact larger that's been
joined and then propagate that down to
their their children nodes and they
chain together so they keep making a
successful successively bigger and
bigger join looking at one of our rules
this one's simple we only have one join
but I'm just just keep in mind it can go
further combined BP's it's it's nuna
it's doing that same day join between
this
like blood pressure and a diastolic
blood pressure fact and it's reading
network might look something like this
I'm leaving out alpha nodes when there's
really nothing there's no there's no
alpha nodes need it you can think of the
fact that nodes there really just an
extension on the alpha alpha nodes
anyways because they're the type of
effect is still just about one fact at a
time so the beta node that I have in a
square that's labeled beta node that's
that's the nth one doing the interesting
work here and it's taken a diastolic
blood pressure if the facts that are
matching that on one side and it has
taken the branch that comes down from a
systolic blood pressure the facts that
match that on the other side I talked
about how the beta nodes chain along in
the network and they always take the
input of a of another beta node but that
has to start somewhere so usually you
just have some kind of dummy top node
that pretends to be a beta no that
doesn't have to do any join so I'm just
representing that as this first blue box
that just says equals date-date that's
setting up that variable binding so then
when you get to the beta net we're
looking at though it's when it looks at
both sides it gets an input from the
systolic blood pressures and the
diastolic and tries to put them together
by that that constraint which is do they
have the same date and if they do it
propagates it along to its child nodes
which the note there's only one and it's
it's the rules fully activated at that
point so it's just a terminal node again
that's indicates that we need to it
would be an act it would be inserting
the BP when that rule fires so the other
important part of beta knows though is
that they have memory and they remember
what they've seen on both sides and we
usually call it the left and the right
side since it has two inputs coming in
and because there's a good chance you at
some point this beta node sees a
diastolic blood pressure but it hasn't
seen any diastolic pressures yet because
they just haven't propagated through the
network but it remembers that it's all
that diastolic blood pressure and then
later on if we do get this systolic
blood pressure it looks in its memory to
see what does it seen before and tries
to do the joins and that's important
because the working memory is is
changing through these cycles and the
problems get harder than this where you
have inference happening and new facts
are being derived and you want to you
want to remember what you the nodes have
these this memory so they're trading off
a little bit of space to hold these
references to things and and the benefit
they're getting is time
because you don't have to recompute
these values so when working memory
changes only to bring only the path
through the network that's affected by
that change has to make do but do work
again all the other paths are already
today they already know what their what
the work is that they've already done so
you can you don't have to compute both
sides over again when you're trying to
do the join putting together that whole
picture of the hypertension example it
doesn't really matter if you can read
every bit of it or anything I just kind
of show demonstrate it all those rules
put together you have like the alpha
nodes on this rightmost side of the
dotted line you would have the beta
nodes in the between the dotted lines
and then the leftmost side of that the
last dotted line is those terminal nodes
and I haven't really talked at length on
retraction but mostly because retraction
is just modeled typically like insertion
so it's you still say I'm going to
retract this fact and you try to
propagate it down through the network
the only difference is as it satisfies
conditions it removes itself from those
beta node memories and is any kind of
local memory and it removes itself out
of joints and that can cause rules to be
no longer true so it can turn activated
rules and they're not activated rules
you can do there's interesting
optimizations that could be done around
this because when you insert it the fact
you could gather more details so that
you could try to make the retraction
faster and Clara does some some work
around this and so did a lot of rules
engines I'm not going to get into many
details on that optimization at this
point though for more on the Reedy
algorithm I think a really good paper is
this this one here by Robert B Doran
borrows from 95 and it was you know
that's about 10 years later than the
original ones I think there was some
really good description of how the
reading network looks and they made a
big system out of it and but he also
talks about performance considerations
and they're old now but they still do
have value when you think about evolving
the algorithm as originally described
because the original description is very
very simplistic so I didn't get it I'm
not gonna get into a lot of details on
clear rules today there's a couple great
talks already out there for that I'm
gonna reference them in a minute I will
give some highlights though and so Clara
rules is a lightweight library it's just
meant to solve the
problem of complex conditional logic it
doesn't bring anything else big for that
to do that do that you really can think
of it as just like a sophisticated
control structure to drop into your your
application where you might have
situations that come up like this where
you have this heavy business logic or
whatever you want to call that so it's
not trying to be this general-purpose
programming environment or anything like
take over your application and make you
write everything and rules like that is
kind of happened before in rules engines
the other thing is the working memory of
the of the rule sessions
it's a mute up there they're immutable
and they're done through persistent data
structures the closures persistent data
structures so it performs well does some
transient things that it be mutated
faster while it's in local scope but
that gives you all those benefits of the
thread safety you can look at changes to
the the rules working memory state over
time you can store off different
different time points in time when the
rules were fired before you did other
changes it's all those kind of benefits
and the rules in Clara have a they have
a first class data model which I think
is an important thing I've been showing
a lot of DSL and stuff but if you want
to communicate to Clara making rules in
a different way you don't have to try to
build a DSL out programmatically there
they're described in terms of you know
traditional like maps or records and
things like that and that's its first
class so you can you can skip the DSL
you can make your own DSL and we have
made a few higher-level constructs that
directly generate these rules but in
general you can generate the rules
programmatically you can manipulate them
you can build tooling on them and those
sort of things the other thing that's
probably people probably get upset about
as I talk about fact types and a lot of
this and people think maybe enclosure
that I just use maps for everything so
that's not going to work so the clear
rules doesn't make you use classes and
types to do that level of dispatch
that's an arbitrary dispatching function
and you can opt you that's actually an
optimization to try to to try to
dispatch on something that separates
your data better but it's pluggable and
it's in that way it's more like a multi
method in that it can test some
arbitrary property of the
fact that's being propagated instead of
being like a protocol where you're
you're rooted on just type based
dispatch and the last main thing I want
to point out is that clear rules has a
has a durability layer it's pretty
pretty new and the API is still a little
bit in flux we have it marked as
experimental but we've started using it
in production and I just think it's a
pretty cool feature it's where you can
you can take rule sessions and store
them out of process and restore them
back into process again and one of the
key things is that when you deserialize
it it doesn't refire any rules it just
comes comes back again and the state
that it was in before and this lets you
maybe have some you might run a some
really heavy batching work to generate
some state of working memory you can put
it off well offload at the disk or
something and then maybe on the service
you fetch it again for a particular case
for you fetch a particular working
memory back into memory again pretty
fast and make small changes you know
fire that fire the rules again and then
persist that so you can make these
incremental changes that lasts longer
than just a single lifetime of one
process and there's a lot of details on
that issue about some of the goals and
so I just linked it on here and like I
said there are some they're two really
good talks given by Ryan brush at
strange loop and at Midwest IO him he
would created clear rules and I think
they do a great job of really a
demonstrating clear and showing off its
features and goes live demos and stuff
so I I left that for for those talks to
be to be seen if people are interested
in that I'm and that's that's all I have</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>