<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ian Eslick -  Probe: Program Traces as First Class State | Coder Coacher - Coaching Coders</title><meta content="Ian Eslick -  Probe: Program Traces as First Class State - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ian Eslick -  Probe: Program Traces as First Class State</b></h2><h5 class="post__date">2014-03-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yroKdhAt8as" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this talk has nothing to do with
aliens or silver probes it's a
discussion of a little library we put
together to manage some problems we had
in building distributed systems to try
to make our life easier and I think it's
a tool that might be useful to others
and we certainly will invite anyone
wants to come contribute and extend the
tool to join us in our quest to make
more sense of what's going on in complex
distributed systems so I'm the talks
going to go in for little stages quick
teaser is what am I going to be talking
about today probably about five minutes
on the system context that we're coming
from so what are the problems that we're
particularly trying to solve and why do
we end up in this particular place in
solving it and then it's the specific
motivation for the library and that a
deep dive and tore through its features
so one of the things I've observed over
the years is as we write a program there
are the things that the programs are
designed to do the function that it is
performing and then there is a whole set
of secondary operations and often
represented as side effects and these
might be logs rights to a database
metrics things that are side effects of
the program's operation but are often
not considered as the primary design
goal of writing the code and so we've
developed as a community a set of habits
you know we'll put in log statements so
we can tell what was going on in our
program while it was performing its
primary function and it's easy to get
caught up in the primary function and
sort of forget about all these secondary
and tertiary things we need to do when
we build real systems that run in the
real world and so the idea of probe is
really to disintermediate a lot of the
the heterogeneous ways in which we
expose the dynamic state of our programs
to other systems whether that's storage
or internal state that it then comes
back and uses later and so we want to
create a single point of interface where
all the stuff that's happening while
we're computing our primary function
goes into this channel and then I can
choose i can late bind and choose what
i'm going to do with that state whether
i want to enable or disable logging of
that state transformations over that
state etc this talk bears some
similarity to talk and I'm forgetting
the author about a lift which I believe
last year had very similar aims and
perhaps a slightly more complex
machinery so we're working on a health
care platform runs on Amazon uses a
variety of distributed storage systems
and itself runs on the imminent jboss
platform and consists of a whole bunch
of application nodes sitting on top of a
whole bunch of database nodes and this
projects called switchboard it powers a
set of mobile applications and a desktop
application and it has the typical
structure of any one of these
applications and what's wonderful about
the world we live in today is there are
many services that you can pick up and
run whether their high-end expensive
things like splunk you can install log
stash there's lots of systems we can
build around this core infrastructure
that looks a lot like many of the
systems we may be building but we're
faced with a slightly harder challenge
in that there's a lot of regulatory
restriction on what we can do with
third-party systems what we can expose
to them and our customers are often
hospitals and they're inverted the is
departments and hospitals are
extraordinarily conservative and for
very good reason because wrong data
means people die and you have to be
extremely careful and rigorous about how
you manage not just security and
liability but the integrity of the data
and the integrity of and function of
your systems so as a consequence we are
striving to keep our system as simple as
possible so we can reason about all
these properties for which we are
beholden the system itself is designed
as a loosely coupled system of modules
so relatively self-contained pieces of
functionality and they're designed to be
durable that means that they at any time
a node may go down the function that it
was performing they be prematurely
terminated and the system has to be set
up so that function eventually gets
completed and one of the ways you make
your life easier is you have it and at
least one semantics it will eventually
get completed but it might get completed
twice we want to infer minimize the
infrastructure components we're still a
very small operation so the operational
complexity of bringing in a lot of these
other systems that I mentioned even if
it's simply via an API becomes a lot to
manage for a team of three or four
people getting involved in a project
this complicated so we only use two data
stores for all of our operations wheezed
atomic for all
of our complex data modeling and
Cassandra for time series and for all of
our bulk storage and we prefer processes
that are easily managed single process
single node easy to manage shared
nothing kinds of architectures and I've
had previous experience with HBase and
cassandra has been quite pleasant in
contrast so the the unit of system
composition are one of these modules it
might be an API call a queue handler
that fires and then there is often
reading state from the database on that
particular node and use a series of
functional transformations which end up
in either another message a side effect
to a database or a network iya network
iOS of course are a special case now
these are relatively easy to reason
about what gets difficult is when you're
dealing with an asynchronous chain of
events will call that an operation which
is some logical end to end side effect
that say a user is expecting to see or a
downstream system is expecting to see
and that has to complete reliably and it
doesn't always do it and it turns out is
a lot harder to reason about the
behavior of an operation that it is the
reason about the behavior of an action
to give you a sense of some of these
actions in our system this was an early
sketch that we put together with help
from actually some of the folks at
cognate act and just thinking about the
different modules that we needed to
perform we need to ingest and validate
some data we might want to perform an
administrative operation which is fairly
straightforward but we do a lot of
dynamic workflows where we're taking an
operation that you might often write as
a single coherent block of code and
breaking it up in time it might run over
months or years and it's constantly
handling state changes that take place
in human time so five weeks from now do
X and then if the user does you know why
go doozy and so those decisions need to
be durable and managed on the platform
as things systems come up and down it's
all connected via a queuing layer so
when we're debugging things that go
wrong it's fairly easy given an input
and the database timestamp thanks dude
atomic we're able to get essentially
referential transparency at the module
level or the action level which is we
could take an input database state and
we get the same result there
time so it's really easy to reason about
local errors and maybe a hole in our
testing but these are also fairly easy
to test so they tend not to error very
often the errors take place when an
assumption in one operation doesn't
quite line up with an assumption of a
downstream operation or that the
coordination among operations is
something we didn't reason about
correctly up front this may be a failure
of imagination but it's also a practical
reality of building systems like this so
the first problem we're trying to solve
is that our operation level function is
is impaired we don't really get peer
functions oftentimes because these steps
between operations are dealing with
foreign systems where I don't get that
nice item Putin's guarantee I have to be
careful to debounce and never send to
network requests the data that I read is
not always going to be the same so it's
unless I'm saving everything at that
boundary and working with it carefully
which can be a pain you end up dealing
with having to figure out what's going
on with your operations and oftentimes
at runtime the user says well I clicked
on the button and nothing happens and
I'm a 0 there on the other side of the
country on a mobile phone with a
particular last version you haven't
tested yet now how do we dig in and
figure all of that out we also find that
we want instrumentation of what's going
on in our system so whether this is
monitoring or making sense of the
internal performance of the system
understanding where the latency
bottlenecks are these are one of these
secondary functions though the code has
its function it also has its performance
footprint and the way that it interferes
by the use of shared resources with
other things that you're trying to get
done so if you're having a latency
bottleneck in your system you want to be
able to reason about the relationship of
all the parts so we want to store state
to characterize that particular part of
our system we need to audit anybody who
looks at a piece of data we pull off of
an electronic medical record we need to
know who that person was how they were
authorized and have a complete report of
everybody who ever saw that piece of
data not so hard in the era where
storage is free but we have to reason
very carefully about our system so that
we understand when somebody comes in on
an API request that we have an
authorization associated with that
request and that all gets logged and
again that happens outside of the main
operation of looking up a time series
we often are starting to work on
building models so if we're presenting
something to the user there's their data
but how does their data compared to the
population so we're constantly updating
online population models and some of
this can be done in batch mode and done
offline but oftentimes the the offline
batch mode is more of an administrative
complexity than simply having one of
these workflows that i described fire
update the model dynamically as data
changes so when we started looking at
the issue of reasoning about our system
in the context of all these other
constraints the idea of writing logs is
kind of important to me now now logs
don't get me wrong logs are powerful
they're easy to generate they're mostly
human greed able everybody generates
than all of our other systems generate
logs and there's all this infrastructure
for taking these text strings mushing
them together searching them sorting
them visualizing them building graphs
from them and there's you know there's
big ecosystem of supporting systems that
we really don't feel we can use
adequately for all the reasons I
mentioned earlier and so I just it's
been bugging me for years that logs feel
like premature serialization why am I
going into this textual format that I
now have to go through work to make sure
i generate correctly parse correctly
later now a lot of people use JSON is
their serialization format which means
you can do structured analysis over the
data but you're also throwing away the
context of the system the data was
collected in so if I have a reference to
a model object and I'm trying to reason
about the behavior of my system I don't
want to dereference a uuid in my head or
have to track you know which uuid is
going through the system I'd like to
actually be able to track the model so I
want to be able to take the state that
I'm storing the reason about my system
and use all the state that's in the
system to be able to work with it so
maybe we can keep all of the data in our
system and solve all these problems at
once so the idea of probe is a simple
interface to capture runtime state we
want to minimize the performance impact
on the current thread so that all this
other stuff can happen and on a parallel
threat or a parallel CPU we want to
encourage late binding decisions
wherever we can so you decide what the
semantic needs of your system are
capture that state and then have some
flexibility we might want to later say
gosh I really wish I had
instrument at that particular particular
method say was doing authorization so we
have some ways where you can go and
instrument functions at runtime to
capture that state stick it into the
probe chain and then manipulate it the
way that we manipulate everything else
and I'll give you some good details on
this in a second so we also want to know
whether to capture so we want to be able
to turn on full tracing look at the
entire system and then shut it back down
maybe we want to do that just on a
per-user basis so we want to get all of
this that all the stuff that's going on
but we're just trying to figure out one
users problem so rather than dragging my
whole system down I want to put in a
filter that says hey just log for this
user that's a nice thing to do that log
systems don't make really easy unless
you build infrastructure around it we
want to do transformations over the data
I don't I can generate an ungodly amount
of data at every point in my programs
execution I don't necessarily want to
store or see all of that data so
actually filtering down the stream of
all the dynamic program all of the
dynamic program state its critical
function and then eventually we are
going to serialize and store this if
we're dealing with lots of data but
sometimes I just want to keep a rolling
buffer in memory and then say stop and
say okay what was what were the last
hundred transactions that this user took
place on my system so i can go in in the
rep will watch what's going on connect
it back to the database state reason
about the bug and then go back to my
evaluation systems try to reproduce the
error and so these are the kinds of
interactions on a complex distributed
system that we want to start to enable
what we do but we want to keep it
friendly for the habits we've all built
around the way that we write our logging
statements and keep it as simple as
possible so probe have is simple
namespace and you call probe with a tag
set and then a set of key values sounds
pretty simple it's very very much like
logging JSON which I see is a nice
closure convention where you log key
values and that gets serialized as a as
a readable edn string or a JSON string
the tag list is how we decide what we're
actually going to look at at runtime so
the tags or how we do the matching as
opposed to a log level and we what we do
is we roll the namespace in the log
level into the tag set so now you can
you can use both the context in which
the data was captured the namespace or
you can use any user defined additional
tags you might
want to parse your data out more finally
so when this probe function runs and I'm
going to give you a little bit more
Brody details about exactly what could
be captured at a probe point later in
this case this is a simplified view of I
capture the tag set and the key value
sets so these probe states now are being
generated and we've got to do something
with them well the first thing we're
going to figure out is where do we want
these things to end up eventually so
this is an example of a memory sink so
we create an atom create a memory sing
and you can actually create a memory
sink that's finite so it's a rolling
buffer and you just say add sink so go
we now have named sinks and then some
function which is going to take a
sequence of maps in and then do
something with them let's see you ok
that's coming later so this is an
example of a memory sing these are these
are relatively simple functions so all
this is doing is resolving the atom and
then in the function call essentially
updates that atom in place so a memory
sync this is the sink that we use
actually for almost all of our system
data that goes into Cassandra so we keep
essentially an infinite log of things
that we care about on Cassandra for
auditing purposes and many of the other
purposes that I mentioned including the
ability to trace the entire system and
so it's just essentially we have a
schema we unpack things we tend to want
to search on and then everything else
gets dumped into a into a blob and
storage Cassandra so the last piece of
probe we have a probe point and we have
a sink where it might go and then we got
to get it from point A to point B so
subscriptions are essentially a
conjunction of tags that map any any pro
point that matches that conjunction of
tags will generate a probe state and
send it off to that particular sink and
this is an area where I'm not entirely
pleased with the API so this is
something for which I'd be more than
happy to get critique and suggestions
for a better way in which we might
structure the interface to the
functionality and the subscriptions
could be added and removed at runtime so
the subscription mechanisms based on
poor a sink
which gives us a lot of nice properties
and one of which is we can use its
composition operators to perform
transformations within a subscription so
if you think if the subscription as a
pipe that pipe can do a series of
filters and transformations on data and
then dump that into a sink and we had
thought about doing a more complex
topology and we thought we'd start with
us see how far we got and then consider
whether or not we wanted to do some
sharing there's one problem with this
current structure is that if you've got
to tag conjunctions that generate the
same state and they end up going to the
same sink you end up with duplicate data
and so there's some questions about do
we do time-bound deduplication etc
mostly we just are careful about how we
design our tag sets so the probe data
flow is pretty simple my programs
running away I had a probe point in the
lexical structure of my code so at
runtime that generates a sequence of
these probes States those go through
whatever functional transformations I've
set up and get written into a database
for forensic use later for auditing
queries later so the probe is actually a
macro because it allows us to get at the
form and to get some extra information
about the lexical context of that probe
point much like most logging systems do
so we have essentially the notion of the
line number here and then the interior
of the probe function can grab the
dynamic bindings that are present at
that point in time so I can actually
turn on a global grab all these dynamic
variables at every probe point that gets
thrown into the state map and then for
the stuff I don't care about I filter it
back out but this allows me to look at
any dynamic context that I may be
passing around my system and while I'm
sure if Stewart is the audience he'll
he'll come and hit me on the head later
we do use dynamic context around a lot
of our methods to capture the essential
what are the databases that are active
what's the authorization context of this
operation because I did build a system
where everything was explicit I got
tired of all the extra typing so was it
was a pragmatic trade-off what I don't
claim that his superior to other
approaches so the full lexical context
gives you a map that actually looks like
this we've got a set of tags timestamp
of which it was captured the thread ID
in which it was captured so you can see
what
is happening on the same thread what
hopped against among the threads the
namespace it was captured in and so on
so this is what I just mentioned the
dynamic context so you essentially say
capture bindings you give it a list of
ours and it'll look up the valleys of
those bars and slip them into a map for
you in that state that state variable so
this is an example of what we capture in
our runtime systems today it's quite a
bit of state but it's quite useful so we
now have the node the lexical context
the the runtime context we've got the
master database which is the sort of
master for our whole system then every
with a multi-tenant system so every
system has its own de Tomic database so
they're completely isolated so I have
the timestamp of my database the
application ID so I know which database
that's that's associated with so I now
have essentially the entire state of my
system at that point in time is now
available in my log and the one
exception is Cassandra and there we
don't do a lot of complex stuff so we
can either design a table to be
idempotent or to not have duplicates or
we can store explicitly the time data
that we need to do reconstruction and
that keeps our system relatively simple
the other thing that we have is I
mentioned from the dynamic context we
pull out the authorization and then a
tracer we call cause ID whenever a new
API request comes in we instantiate a
cause ID and then that is passed through
the sequence this operational state so
now I've got a tag where I can go back
into my logs and say hey give me my
program trace for this API call so now I
know that this easier at this time did a
call here were all the things that
happen in the system and all the side
effects and I can reconstruct that
programmatically on the live system so
we have a forensics library that we're
working on I think at some point we'll
abstract this and roll it into the probe
library but essentially it is just
starting to build some abstractions
around of filtering over common things
extracting out subsets and starting to
build up some representational apparatus
for thinking about traces as first-class
entities and I think that we're not
perhaps as far down the road on that as
we'd like to be but I would love to have
discussions people were interested in
this about how do we think about the
trace as itself a piece of
representation that we can then build
higher order functions over for now what
we do is we treat them there's see
of maps that tend to have some sort of
coherent so either they're all of the
same cause they're all for the same user
you can do session ization where you say
okay if there hasn't been any activity
in an amount of time then I'm going to
break these into chunks so I now have a
sikh of sikhs so there is a sikh of all
this was the user's transaction today
they got back online later that day and
they did the following activities and
it's all traced at the lowest level
we're adding another tracing level to
kind of that goes into the probe
architecture which is from the client so
the clients based on cognate X pedestal
architecture a little departed from it
at this point but basically we have a
explicit representation of all the state
transformations and all the actions that
people are taking so it's not hard to
have a back channel from the client down
to the server to essentially capture all
the essential state and so just like I
described on the server side we can now
click a button and say hey next time the
user connects turn on their tracing
apparatus and you'll start sending me
dumps of that users experience which I
can turn it on and off and we turn a
certain amount of it on because we do a
lot of work with researchers who want to
know what users are doing so now we can
build up a representation of all the
user activity per session or per time
that the app turns on and that's all
again represented in this the context of
our system where we've got all the other
state to work with so we can build
actually quite powerful reasoning
methods over all of this information
rather than having to go out to splunk
and like search through text files which
I've done and hope not to do again the
other thing that we know of course is
that in a functional system if you've
done a good job of design many of your
functions are quite useful as probe
points so rather than having a function
definition and then a explicit probe
point you can simply turn on probing at
the function level this is not the
cleanest way of doing it we're monkey
patching the function basically and we
try to be smart about not doing multiple
monkey patching and being sensitive to
that VAR being redefined during
development so i won't claim that that
is one hundred percent solid so i
currently use it your own risk but it's
another good area to discuss what it
does is it gives us the arguments tells
us whether it was at the entry the exit
point of the function so one of the
things I find sometimes when we haven't
done perhaps as fantastic a job of
testing the whole system as we'd like
some data will come in triggers a
condition we hadn't accounted for and
boom we don't get an exit function so we
turn on tracing we see it go in we say
ah here is the input that screwed the
function that functions Pierre so now
it's easy to go back to our testing
system reproduce that state and then
this is the exit so we get to see the
return values to the extent that those
things are can be serialized but one of
the things you can do in your
transformation function is you can walk
the state model and turn everything that
might be some structure that can't be
easily serialized and you can turn it
into some form that you can then reify
later we can also capture probe points
over state so any we can add Watchers
two state variables that are baked into
the language and get the state
transitions that are coming out of those
as well throw that into the same
infrastructure and there's a
administrative capacities and some we
expose some functions right now for
doing function composition so we can do
these transformations and I moved at a
much faster pace than I thought so we
can actually have a nice discussion so
the general thing that I hope you take
away from this is that we stop thinking
when we design our systems about all the
other stuff that happens it's not the
function we're here to perform and think
of that as as first-class design goals
for the system how do we design for all
of the stuff that comes down stream of
having a functional spec in writing a
piece of code so that we can actually be
more effective over the lifetime of our
program rather than just effective at
meeting the current testing goals and
i'm not against logs i think logs for a
whole variety of reasons are still
useful in our case we just use them for
operations so is the database up what's
going on with the primitive systems not
what's going on with our application
logic because we don't want to throw
away all of that context so with that
I'll take questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>