<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dependency Heaven - Alex Miller | Coder Coacher - Coaching Coders</title><meta content="Dependency Heaven - Alex Miller - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dependency Heaven - Alex Miller</b></h2><h5 class="post__date">2017-08-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sStlTye-Kjk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm Alex Miller and I've been working
with closure for about seven years and
working on closure for about four years
at cognate echt and I work on the core
team and help develop new features and
things like that this is actually the
first time I've done the technical talk
at a closure conference because usually
I'm emceeing them so you get the first
leg so this talk is called dependency
heaven which maybe is not a place that
we will actually reach that may be an
unattainable goal but it's really in
opposition to dependency hell this was
really just a fun opportunity to make
the slide which is something that a lot
of developers describe as sort of the
nuts and bolts of their daily existence
of managing dependencies on their
project and using dependencies and
things like that and this is something
that we've actually been working on the
core team some different things for off
and on for probably eight months or more
more seriously for the last month or two
really because it is in the line of
trying to get closure 1 9 out the door
and I'll get to why that is here in a
little bit but what are the problems
they're actually hold several clusters
of problems related to dependency
management and I've sort of bucketed
these into virgin resolution our
artifact focus and getting started so
this is a one slide summary of Rich's
speculation keynote from the Conch last
year it is well worth your time to go
watch the hour plus talk version of rich
talking about these subjects much better
than I will be able to but I this is an
important sort of background so I wanted
to at least talk about a few different
things one of the key things in his talk
is really about this notion of change
which is a word that we throw around a
lot and software and he wanted to make a
distinguish between two different kinds
of change
and breakage where growth is really
accretion which is adding new things
that you can use relaxation relaxation
which is where you either require less
from people to call you or provide more
to people to call you those are ways
that don't break existing code or
fixation just actually fixing the
implementation of something without
changing its interface or things like
that and then breakage is something that
people also call change and that's when
you require more from your consumers
either they're calling new api's or
they're you require them to call new api
is require is going to be passing more
stuff or you provide less on the return
those are all kinds of changes that
basically break an existing consumers
use of your code and the key insight
here is that if software only uses
growth only uses these those techniques
it's always okay to use a newer version
there's never any problem with sort of
hitting a breaking version because your
software does not break and this is
something we strive for in the closure
API which is one of the reasons that it
has a lot of stability a lot of for a
long time that's been sort of implicit
this is sort of making that more
explicit and something where you want to
be more serious about and and would like
other people to be more serious about -
because breaking software or sucks and
so we should just stop doing that so one
way to avoid breakage is by making your
names and so we should not be afraid to
make a new name that for an existing
function give it some new name and leave
the old one their existing consumers
continue to use it new consumers can use
the new one if you need to remove a
function or significantly modify things
put it in a new namespace that's fine so
there's ways to do this at the sort of
collection level as well and one tool
that we have in 1/9 now is specs and
specs allow us to make commitments about
our code there in specs are really about
what you can do not about what you can't
do and some of the things you can't do
in spec are specifically designed around
avoiding prohibiting things prohibiting
is the thing that turns growth into
breakage so if you suddenly need to
require a new attribute or anyone need
to allow
new attribute and before we had a spec
that said you were not allowed to have
that attribute then you've turned growth
into breakage and so we don't want to do
that that's the wrong direction and then
rich also talked at length about
semantic versioning and how semantic
versioning is basically has these three
levels of major minor and patch changes
and change at the might at the patch
level is just fixing it's really
fixation change at the minor level is
really accretion or relaxation and
change at the major level is breakage
and so Rich's point there is that
semantic version itself is broken it and
that it allows breakage and you don't
have to break things you can just add
instead so dependencies another so this
is moving into the second part around
artifact focus artifacts right now we
declare dependencies at the artifact
level we declare that we depend on core
a sink or composure or whatever and
those artifacts are stored in maven
repos so the but there are some good
things about this the the maven repo is
an immutable append-only distributed
store all that is awesome that's the
same things we like about persistent
data structures about get about de Tomic
all of those things have the same
property of being immutable append-only
stores so like last year when clay jars
had some downtime it is conceptually
architectural EEZ to add a mirror for
that stuff because it's just caching its
you're taking this stuff and I'm going
to cache it somewhere else and I can go
choose what I do with those caches
caching is a really easy thing
conceptually compared to building a
distributed system that has to deal with
updates and deletes things like that
maven the RHIB maven repo system also
gives us access to a vast Java ecosystem
of libraries that already exist and so
that's goodness we don't wanna get rid
of those things the bad things closure
doesn't actually care about artifacts
closure doesn't when you start the JVM
you don't give it you don't talk about
artifacts you're building a class path
closure doesn't actually require stuff
to be built at all you just need closure
files that are on the class path
somewhere
and so we have sort of added this
constraint around how we use closure
code that is artificial and it is it has
the downside as the upside of allowing
us to play in the Maven eco system and
do those kind of things but has the
downside of disallowing certain things
that the JVM allows and the closure
supports that would be useful so we've
we've we've also sort of entangled this
problem of dependency management how we
say which code we need to use and
artifact production our build systems
our build tools and things like that
those two things are entwined in
something like Lanigan or boot or maven
all those kinds of things there are lots
of cases where we run into this
restriction I don't know how many people
have needed a database driver that was
not in a public maven repo that's a
common thing so that's an example of I
might have a jar file I want to use it
on my class path but I can't get it out
of a repo in that case you have to do
all sorts of crazy workarounds to make
that work and that's dumb or you might
run into the case where you're
multiplying your you have your project
split into multiple code bases right you
have multiple your application is split
into multiple projects in that case you
have to do this cross project dev and
you use check outs or something like
that
to deal with that but that's silly that
you would silly that we have to do that
there's no reason that we can't start a
ruffle and include all these different
source files that are all over the place
and work with them directly the JVM does
that closure does that our artifact
focus has prevented us from doing that
and then the other thing is that the
source of truth for most of us now is
files in git on github and we can't just
use those things directly right now but
it would be useful to do so and so I
think that's something that also like
there are five closure files in get in
github that we could get to and we don't
really care about the fact that they get
packaged in artifacts they might be
useful without that and the ugly part of
it is that our dependency declarations
are lies they're actually not even true
what we say when we specify a library is
we are requesting this version of the
library but when we go actually build a
class path we build a new bridge or
whatever you're actually running a maven
algorithm it's going to expand the full
tree and might find multiple versions of
a library and it's going to pick a
version for you based on a bunch of
constraints and rules some of which are
based on semantic versioning which has
these issues that we've talked about so
you it's very possible and actually
likely for you to end up with a set of
version 2 artifacts on your class pass
that are a set of versions that you
never specified and that you've never
tested with that's actually a pretty
easy thing to happen and so that's
that's pretty ugly we would really like
the things that we do right now is
things like dependency management and
maven or flying it without and line
again
it was added within the last year or so
it's really the ability to specify an
external source of truth for dependency
versions we should be able to do that
that's just a thing that's useful and
there's lots of cases for that so moving
on to the third set of problems the
getting started experience for a long
time you've been able to just download
the closure jar and run closure main
directly out of the closure jar and that
was maybe not the friendliest thing that
you could do but it was at least
relatively easy to do as a closure 1-9
closure itself has multiple artifacts
now closure depends on spec it also
depends on the closure core specs
library so there's actually at least
three jars that you need in your class
path to start closure so a new user is
immediately confronted with this problem
it is no longer we've we've sort of
moved past the point where that was
possibly tolerable this seems like a
something that we had to have a better
solution for in 1.9 and that's what how
this has sort of gotten into my the top
of my queue basically because my primary
goal right now the top-line goal is
getting 1.9 out the door and this is in
the way of that so this is does the
reason I've been working on it lately so
what are we going to do about it
so we've been working on our new
contribu tools depth
dot alpha initially I expect that
initially that's going to be or
relatively soon that will move out of
alpha and I move into a more stable
release I'm not sure if that will happen
before 1:9 or after 1:9 it's really not
particularly important for most of the
other stuff a closure installer that can
provide a way to get the latest version
of closure and tools depths onto your
system the closure installer does not
assume closure so it's not written in
closure it's written in Java we do make
that assumption that you're going to get
Java on your machine somehow beforehand
and then system specific installer
packages for brew or apt-get or
chocolaty or whatever is the right thing
for your system so these are the things
that I've been working on and a
substantial portion of this is now
exists and works and will be released
soon whenever I have time to do all that
so tool depth alpha the high-level
constraints here are the sort of ground
truth of what we have to deal with is
that when we start the JVM it takes a
class path and so we have to be able to
build a class bat we have to be able to
do transitive dependency traversal
that's just a fact of life dependencies
depend on other things we have to be
able to download artifacts from maven
repos so those are all things that we
know we're going to have to do sort of
the high level process that we've
settled on after a lot of discussion is
really starting from an initial set of
dependencies applying this operation
called resolved ups that can expand the
transitive dependencies resolve version
differences fail on version conflicts if
you find those doubt and download those
artifacts to your actual system and the
result of that is going to be a thing
called a library map which I will talk
more about there's also some extra use
cases there on the bottom I will also
talk about those more and then a second
operation make class path that really
takes a library map and then produces
the actual class map out of that which
is a simpler of the two operations so
what are the steps in resolving depths
we have to start with the initial depths
expand the transitive dependency graph
resolve these version differences and
return this library map three extra use
cases that we've drilled into we looked
at a lot of ways that people use like
Lanigan profiles and different features
out there in the wild today and these
are the three use cases we focused on do
you need to add extra dependencies when
we're creating a class pass and that's
common when you're doing sort of
development time or your at development
time and you're trying to add some extra
testing libraries you might want to add
criterium to do benchmarking or whatever
something like that so it's not part of
our core dependency set it's not what
you need to use the software but a snack
store a library that I want to use right
now for whatever purpose we have the
problem of overwriting dependencies so
say I know that I'm gonna have this
dependency show up somewhere in the
expanded dependency graph and I'm going
to tell you that I'm going to use
exactly this version of it and I don't
care what it version comes out of all
that stuff I'm going to override to just
this one and then default dependencies
in the case where you have a dependency
that shows up in the dependency graph
and it doesn't have a version or doesn't
have a version specified then use this
version I'll tell you what using of you
using version to use by default and then
I think a fourth case maybe that needs a
little bit more thought as exclusions
and so that's Richard and I had a chance
to talk about that in depth so I will
table that one so the output of all this
is a library map the library map has as
a key the library the user's intent to
use composure as the value it has a
coordinate which is both a version and
some particular implementation to use
and an actual path on disk of where I
can go find it and so it's implicit in
this thing that part of doing resolved
EPS is that it's actually got to
download a jar or make a path available
somewhere on disk anything and then so
making a class pass now our goal here is
to generate a class path which is
just a you know a past separated string
and what is the class path class path is
an ordered list of class path routes
those routes can be jar files they can
be directories there's also some special
syntax to include like a glob of jars
but really the key thing is it's either
a jar file or a directory what are its
characteristics and this is something we
looked at one of the things that you
note will notice immediately when you
look at it is that classify has an order
it's a sequence of things and that order
is important because that's the order
that that's the order that the JVM will
look in those different routes for
things so the question is is that order
actually important note is it is
actually relevant for the class path the
only case were so if all of your classes
exist only in one of your routes then
it's not relevant
it's the JVM will find it along across
one of those routes and it really
doesn't matter the cases where it is
relevant is when it's in more than one
of those class path routes
I'll contend that most times this
happened that's actually above I don't
know how many how many people result of
debug something where you have the same
class multiple jar files
that's awful right it's really hard to
figure out and most of it most commonly
happens when you like accidentally Ã¤Ã´t
compile downstream dependency classes
into your jar file or something like
that
so I'm going to contend that's a bug and
we should not do that
and if it does happen it's it's a
problem not not an intended use case the
other case that you do see fairly
frequently is including a another class
file into your class pass in a different
route specifically for the purpose of
overwriting the one that is already
there and so that one's kind of
interesting is like I have this class
path I'm getting this class file from
somewhere but I actually want to use a
different version of that for you know
I'm going to override it with us to
their version so our contention is that
that's really that's that's really a
good use case and we should we should be
able to be sure to support that but the
way that people do that with prepending
is
really more of a hacks and doing what
they want to do which is to say I want
to go to this particular thing in the
class Pat and replace it and so we
should support replacement that's fine
but we don't really have any goal or
interest in supporting prepending for
the purposes of overriding and so if
you're get rid of that and if you say
then we could say basically that order
is not that important and so we're going
to give up on trying to maintain the
ordering in a class path and instead try
to provide other operations that give us
that same functionality so we have so
around tools steps we have another
script script is called clj the real
point of clj is effectively to call to
run closure main and you run closure
that main by running Java so Java has
some JVM args we need to have a class
path so that's where we will do more
work we're going to VOC closure that
main and then take Argos for closure
remain close remain can you be used to
run a ruffle that's the default with no
arguments it can be used to run a
closure expression and just give you the
result back and it can also be used to
run the - main function in any namespace
so you can use it as a general runner as
well and it could be used to run tests
even that way with a little bit of
additional glue code so that's all
useful the main question here is how do
we construct the class path and first
the first thing we need is some way to
remember which dependencies we care
about in the current context current
directory and we're doing that by
storing that in a file called DEP
speedin which is obviously a needs file
and it has a number of different keys in
this map the depths key is the main one
and that will store a mapping from the
library to a coordinate you'll notice
that the chord that this is slightly
different than the syntax in line again
or boot or other places and there's a
reason for that we're trying to add some
additional context here about where this
particular library is coming from and
right now it's coming yeah you know
everything's gonna be coming from maven
are sort of expanding the ability to
sort of build pluggable systems that
pull artifacts or directories even from
other locations so there's imagine
there's other kinds of types there as
well
like files and maybe github things like
that depths dot even can also include
aliases to cover any combination of
these different use cases that I talked
about override depths extra depths
things like that looks like it's got a
typo in there on extra but so here I've
created a couple different aliases one
called bench that includes criterium I
also included one for 1.9 you'll see a
lot of times in lining and profiles
people will have profiles for a bunch of
different closure versions to do you
know matrix testing type stuff and
that's something that's easy to do here
as well and could be done even at a sort
of user wide level rather than at a
project level
I mentioned coordinates a little bit
library version coordinates contain this
type indicator I already mentioned most
of this stuff it's a that type flag ends
up flowing down through some multi
methods to an extensible system so this
closure script also takes some extra
arguments that allow you to activate
aliases that are used to build the class
pass and so this - R will give you some
additional resolve arg aliases that can
pull in additional functionality and
then you can use multiple of these as
well so a command line like this will
actually pull in both the benchmarking
alias which included criterium as an
extra dependency and 1.9 as a way to
override my closure dependency and use a
specific version of closure and I think
that these things can be sort of mixed
and matched and combined to cover a wide
variety of use cases most of the things
that most things that I'm aware of out
there you can also specify these sort of
last-minute class pass overrides the
overrides that you get and
making the classpath to say I want to
specify a hard-coded directory location
or jar file to use instead of whatever
you found during the transit or pensee
walk you can either use C to pass an
alias that were maps to something that's
in the Deaf student file or you can use
dash P to build an explicit map actually
on the command line directly and so you
can sort of swap something in if you
need to debug with a specific version or
something like that
another benefit we get here is that one
reason we built all this stuff into
aliases have names for accommodating
single or combination of these things
that activate the building of different
class paths and so both the intermediate
libs map and the final class path are
cached in the local directory and a dot
directory if the class path given the
set of flags you specify it exists and
it's newer than deaf site aidan so
nobody's changed but those things mean
then that cache CP file can be used
instead and you can avoid invoking
another JVM with tool steps to build the
class path you already have the class
path sitting in a file is just a string
in a file and you can just spit it
directly into the class path into the
command line that's going to start Java
what steal J does not do is compile the
Ã¤Ã´t compile things it doesn't package
things into jars the deploy thing to
close our is it doesn't do any of those
things and that's pretty intentional is
that we don't we want to disentangle
these sort of build and artifacts
deployment kinds of use cases from the
actual dependency management use case
so the initial audience here is really
focused on new users that are just
getting started or any existing closure
users who wants to do sort of more ad
hoc repple based development things like
that it will work really well for that I
think there are vast opportunities to
integrate these things with Lanigan
but-- whatever in a couple different
directions either coming from those
tools or going to those tools and all
those things are just just a little bit
of glue code
I think to do those migrations and I
think it will require a little bit more
work to figure out what the best way is
to to do those kinds of things and we're
where they make sense we also need some
way to get all of the stuff onto the
actual system and so we have a new
closure installer and this is a Java app
that basically uses maven resolver which
is the thing that used to be ether that
stuff has been pulled out of Eclipse and
moved into an Apache project and is now
called maven resolver but that's
basically using standard maven api's
define the current the newest stable
version of closure and tools Deaf's
alpha and so it's going to go out there
and say I'm going to find closure 1:8
I'm going to use you know tools depths
0.3 or whatever version that is and it's
then going to record that into a system
level really user level def seeding file
so you can remember that and that will
actually be used by the CLG a thing as
well so if you try to run the clj script
and you don't have a local depth seat
and file it'll use the sort of user wide
def seeding file so you can just start a
closure Ruppel anywhere by just doing
clj it also writes the class path for
tools depths for using tools depths
itself so inside that clj script if we
determine that we need to build a class
path you have to then invoke tools
depths which means you need to run JVM
which means you means you need a class
path and you need this class bat and so
that's a bit of work to do that but
that's a one-time thing to do that and
then after that point you basically have
tools depths on your system you actually
have enough enough functionality at that
point to effectively do that work again
anytime you need to so this is a sort of
a bootstrapping operation
I've written a brew formula for OS 10
I'm on OS 10 so that's what I care about
most immediately and what I can easily
test
and so that's where I've started
obviously there's a lot of other things
as well and I would welcome help and
making those things and we'd love to
start making closure packages that on a
regular basis it's not a thing that you
actually we don't actually need to
update this every time that you run
closure because the Installer has the
ability to find the newest able version
of closure when 1.9 is released the
existing broof women would actually find
the newest version of 1/9 and and use it
when you ran it so the only time you
really need to rot install a new version
of the Installer is when is when the
Installer itself changes which is it's
basically like 50 lines of Java code or
whatever
so hopefully that would well the other
thing in installs are the scripts so the
clj script itself and so that would
video there kind of a change that would
require updates but I envision that this
is sort of thing that after the initial
period of development could probably go
lengthy periods of time without being
modified at all across multiple closure
releases that is at least the goal so
there is more work to do on the
different provider types I've done some
tinkering we've started to do some
serious work around sort of using local
directories that and depending on local
directories that have their own depths
eaten file and allowing that stuff to
all work outside of any artifacts and
that's sort of in work and then we've
done some talking about utilizing get
and github and things like that haven't
actually done and you work on that yet
it is a open protocol so it is possible
to add other things as well if people
have ideas oh I'll tear those there are
a few different niceties on the command
line that I would like to have that I
have not added yet some more assistants
around the format of the Deaf's Eden
file and ways to dump the classpath out
of the cache and things like that one
scholar has already mentioned an
integration with
- I've already mentioned so those are
all things for the future and I think
that's it that's all I have and these
things don't exist yet but they they
will as soon as I get a chance to make
them and I think I have another ten
minutes so I'm happy to take questions
but I'm not going to run up the mic with
you because I can only do so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>