<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Melanie Mitchell - Visual Situation Recognition | Coder Coacher - Coaching Coders</title><meta content="Melanie Mitchell - Visual Situation Recognition - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Melanie Mitchell - Visual Situation Recognition</b></h2><h5 class="post__date">2015-04-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/I1ay-iwk2sI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Alex asked me to talk a little bit about
my own current research which is in the
field of artificial intelligence and
machine learning and in particular in
applying those two visual situation
recognition so I'm going to talk a
little bit about that it's very much
work in progress so you won't see the
end of this today but hopefully I get a
general idea of what I'm up to let's see
if I can get this to work so in 1966
Marvin Minsky you probably all know who
he is one of the founders of artificial
intelligence asked his undergraduate
student Gerry Sussman to spend the
summer linking a camera to a computer
and getting the computer to describe
what it saw ok so this was a good
undergraduate summer project
okay so 50 years later Minsky realized
that we learned a lesson which was that
easy things are hard computer so vision
right but describing what you see in a
picture is a very easy thing any you
know two-year-old who can talk can do
that very easily but it turns out to be
very difficult for computers so recently
within the last 10 years or so
artificial intelligence and in
particular computer vision has taken a
big leap forward there's been a lot of
progress due to these things called deep
neural networks this is a particular
network called a convolutional network
that will recognize objects like a
number in an image by extracting a lot
of features over many layers sort of
inspired very roughly by the visual
cortex and then take those features and
classify them as being one of some
number of possible objects like the
digits 0 through 9 in this example okay
and the these kinds of neural networks
have been around for a long time but
more recently they had the advantage of
very massive amounts of data to be
trained on and innovations in that make
them faster to train by using parallel
computing ideas so that's shown that
kind of very almost brute-force approach
has seen a lot of success on object
recognition in images so this is just a
very small array of images from the so
called imagenet data set which is a huge
data set of millions of images of
particular objects and neural networks
of the kind I just showed you have been
quite successful although not yet at
human level in recognizing what
kind of object is in a particular image
okay so that's that's really been quite
impressive but one thing that they can't
do yet is something that is really at
the core of human level vision which is
recognizing not individual objects but
situations where a situation is a
collection of objects in an image say
that have some stereotypical
relationship to each other so here's my
situation recognition task which is I
think any two-year-old could tell you
that this is a dog-walking situation ok
we have a person with the dog connected
to a leash very simple a kind of
configuration and so a challenge would
be to get a computer program which might
be good at recognizing dogs and images
or might be good at recognizing people
to actually recognize what humans might
characterize as a dog walking situation
and many other situations so this is
just an example of one of any infinite
number of situations that people
potentially could recognize after very
little training so that's something that
computers can't get do and that's really
the goal of my own research is to try
and take low-level visual systems that
can recognize simple features like
oriented edges combine those into simple
shapes and textures and do object
classification this is roughly what
these deep neural networks do and I'd
like to make a bridge between what we
might call high-level perception or the
situation recognition in which we have
analogy making which I'll talk about a
detail in a little while which is able
to recognize that one situation is
analogous to another situation and thus
get to this ephemeral idea that humans
call meaning the fact that these images
of dog walking situations mean something
to us we understand
them how could we get computers to have
that kind of understanding so that's the
question that my my research is aiming
towards people have called this the
semantic gap so this is the idea that
computers can do these kind of thing but
in a very strong sense they do not yet
have this notion of meaning this ability
to apply their recognition capabilities
in a very general way of the way humans
can and to actually use the in some way
that shows that they understand the
meaning one one example of this semantic
gap is the fact that people have seen
that if you can train one of these deep
neural networks to recognize say cars
and they do very well you can actually
create sneakily create what people call
adversarial images which are images in
which you change a couple of pixels in
such a way that a human couldn't even
tell the difference it still looks like
a car but the network now thinks it's an
ostrich so people have figured out ways
to find these adversarial images which
really show that the networks aren't
quite getting it in the same way that we
humans do okay so that's the goal and so
the goal is to integrate these deep
neural networks with their great ability
to extract features with a system a set
of systems that I've worked on in
collaboration with hofstetter and his
group called the active symbol
architecture for high-level perception
so in the time I have to talk to you I
can kind of sketch this and give you
some sort of pointers to learning more
about it and the goal is to build this
kind of a bridge okay so this is the
goal of my group is to perform get
computer programs to perform situation
recognition without any kind of
exhausted
or brute force approaches and I'll talk
a little bit about that in a while and
to do that by incorporating conceptual
knowledge something these deep neural
networks don't have allowing the
perception of context and integrating
both feed forward and feedback modes of
processing so those are three key ideas
and our initial task is to recognize
particular situations if I give the
program a picture I want it to tell me
is it an example of a known situation
like dog walking and if so how good an
example how good an instance it is okay
so how would we characterize the
continent situation of say dog walking
well here's a really simple semantic
network or ontology if you like of this
situation okay there's a person who
holds a leash there's a dog that's
attached to the leash and they're both
walking this kind of falls apart this is
obviously a dog walking situation you
know somebody labeled this dog walker
but there's not a so there's not just
one dog there's a group of dogs and
there's also some other stuff like this
stroller which really isn't part of the
dog walking part of this situation so we
have to figure out how to say group the
dogs to say what plays the role of the
dog here well it's a group of dogs and
ignore things that aren't relevant
here's another example that fails under
my ontology people aren't walking
they're running well humans are really
good at being flexible about this kind
of thing saying okay well they're
running runnings similar to walking this
is this is a good this is a dog walking
situation a little bit stretched from
the prototypical concept okay so we call
that conceptual slippage so saying that
walking is part of a semantic space
in which running is can be kind of a
analogous or equivalent concept
similarly we can group objects like dogs
into groups that play the role of the
thing that is being walked okay so
that's this conceptual slippage is in
general is what really allows people to
be very flexible and computers that
can't do conceptual slippage are very
rigid about their concepts so that's one
of the problems in in recognition
envision and language in any field that
we really to get to human level you have
to incorporate this notion of
flexibility or what dog hofstetter my
former PhD advisor called conceptual
fluidity okay this is a very unhappy cat
so is this a dog-walking situation well
no it's not but it's certainly analogous
we could say what plays the role of the
dog here well it's this cat okay so
people might group this in the same
general conceptual realm here's a nice
this is really a knight convenient
because this animal comes with its own
leash ok so we you know start having to
make more and more conceptual slippage
a--'s here's a weird contraption that
you can attach to your bike okay this is
dog walking okay well this person's not
walking she's riding a bike okay and
these are kind of weird leashes but will
accept that you know here's another
weird one okay this is called dog walk
walking dog okay so people are really
flexible about this right walking dog
but here we have nobody's walking
actually okay you know we see things
like this if you're from California you
might see things like this
or even you know it you know everybody
thinks this is hilarious and this kind
of shows that that you know a lot of
humor is grounded in sort of weird
analogies are now that you know kind of
strange analogies and and it's funny but
yet it's dog-walking we accept all of
these we as humans except all of these
as dog walking situations but I'm
showing all of these to you just to show
how kind of stretched the concept can
still be and we recognize it and it kind
of shows you the challenge that's faced
by artificial intelligence to try and
get computers to be as flaking a
situation and be as flexible as people
and you know when how many people here
know about Ray Kurzweil and the
singularity probably yeah most people
the idea that we're going to have human
level intelligence in i forgot what his
date was 20 29 or something we're still
as it turns out pretty far away i don't
know if we will or not by 2029 i tend to
think no but i think people a lot of
people who talk about you know where
artificial intelligence is going and how
dangerous it is and all of that have
overestimated where we are in terms of
what computers can do they can't even
recognize dog walking you know so how
much of a threat could they be so
conceptual slippage is kind of the the
heart of the matter and to approach this
Doug Hofstetter probably many of you
have heard of Doug Hofstadter he wrote
this book girdle ish urbach which if you
haven't read you you should everybody
should try and read that book it's great
it got me into computer science it
probably got you into computer science
as well if you're of a certain age so he
developed this architecture that was the
basis for a number of programs that
could make analogies so
copy cat was my PhD dissertation I'll
show you a demo of it in a few minutes
and some other programs which were all
summarized in this book fluid concepts
and creative analogies computer models
of the fundamental mechanisms of thought
and here's hofstetter showing one of his
pictures of this is a picture of the
letter A in many different typefaces and
shows how kind of fluid a is you know
just the concept of an a being able to
recognize a and many different really
crazy fonts okay this book has has a
little nice piece of trivia associated
with it which is oh and this is Doug
Hofstetter in the fluid analogies
research group that was our research
group at Indiana University first
University of Michigan than Indiana
University it was the first book ever
sold on Amazon and in fact amazon named
one of their buildings after the
customer who bought it which is really
funny anyway um I also wrote a book but
nobody seemed to notice that but anyway
copy cat which I'm gonna talk a little
bit about copycat then I'll talk about
how they were extending these ideas to
this visual situation recognition copy
cat was a program that I wrote in the
1980s in common lisp so I you know
really like functional languages and
everything I was writing on sun
workstations back in the day when Sun
was around and copy cat made analogies
and a micro domain okay that back in
these days it was it was okay for
artificial intelligence to bit to work
in these so called micro worlds and in
fact that's what science usually does
they use micro worlds they scale down
phenomena to us too
to sort of their essence so that we can
understand them and so you know this can
be really useful I don't know if anybody
will get this joke I that this is carl
sagan as a kid right some of you are too
young but if look for somebody kind of
older in the room and ask them to
explain it to you okay anyway what we
did was looked at many situations made
up of letter strings so this is a
situation think of it that way it has
objects and it has relationships between
the objects that are in some kind of
sort of stereotypical way ABC it's a
little sequence in the alphabet and we
say well what happens if you change that
to a BD what should be the analogous
change to I JK okay well this is a look
a little situations like we're it's like
I show you I say I show you a picture of
somebody walking a dog and I say okay
and then I show you another picture of
somebody walking like 10 dogs and I say
if I change you know what plays the role
of dog in this situation oops and most
people will say i jl replace the
rightmost letter by its successor but
you could have said i JD replace the
rightmost letter by adi that's what we
did up here that's being kind of literal
or you could say I JK replace all seized
by D's there's no seas in here so you do
nothing abd
place any string by a BD why not so this
is a this is a you know we would think
of this is a very boneheaded thing to do
but you know why do people prefer this
kind of answer to this answer there's no
you know no overriding goal here well
one reason is that it takes into account
the structure of this string whereas the
other ones don't the fact that there's
successorship relationships okay so
here's a another problem where ABC
changes to a BD what does iij JK k
changed to well if we do if we're very
literal we could say will replace the
rightmost letter by a successor just
like we did before and that replaces it
by an L but the problem is that doesn't
take into account the group structure
kind of like our group of dogs and most
people will say well there's a slippage
here between letter and group so i put
letter and quotes because we're
replacing a we're not replacing a letter
we're placing that letter right you know
the the thing that corresponds to a
letter okay another example would be
this one where we turn it around
backwards and hear you you know you
don't want to say k JJ that doesn't take
into a kiss does the literal thing but
if we see them both is going as strings
in the alphabet this one's going forward
this one's going backward we might say
well the what the rightmost letter here
is actually the leftmost letter or
another way to think of it is instead of
replacing the letter by its successor
replace it by its predecessor which is
playing the role of successor so you get
the idea that there's this this little
micro domain captures some of the issue
of how do you make appropriate
conceptual slippage a--'s okay here's a
final one baby C goes to a BD which is
XYZ change too okay well most people see
that and say X Y a okay because you know
we know
that the alphabet sometimes is used
circuit in a circle our program didn't
know that so we didn't allow it so he
said okay so you can't do that what what
can you do what would you do so now
there's a lot of this X Y D is looking a
little more a little better or even a BD
but you might notice that these two
strings have something in common where a
is the first letter in the alphabet kind
of wedged up against a wall and c is the
last letter in the alphabet so you might
make the mapping going this way and
instead replace the right the leftmost
letter by its predecessor sort of going
backwards so we played with these
analogies ad nauseam this is this was I
spent you know four years in graduate
school sort of writing down little
letter strings was it was quite fun and
built a program then built to finally
sat down and wrote some code and built a
program that uses kind of a multi-agent
approach where each agent it's trying
has a hypothesis about say that the
successorship is involved or predecessor
ship is involved or letter a is
important or grouping is important and
they all kind of get in there and fight
it out and I'm going to show you a
little demo of this working just for fun
so let's see if I can make this work on
this is a version of copycat called
medic hat that was actually written by
Jim Marshall because my my version of
copycat doesn't run on in this on this
machine but this was written in scheme
let's Jutes do I ijj kk okay and so what
you're going to see when i run this i
can't show you everything at once
because the monitor is too small okay
i'm going to slow it down what you're
going to see is a bunch of these
agents trying out various things like
different possible relationships some of
them fail some of them succeed and
whether a relationship is dotted dashed
or solid is how strong that relationship
is perceived to be and different
relationships support each other so if C
is mapped to the the leftmost is sorry
the rightmost is mapped to the rightmost
that supports mapping the leftmost to
the leftmost and what's going on is
these agents are little pieces of code
that we call them code 'let's that
compete not for computation time and the
ones that get there's feedback in that
the ones that are supported whose
hypotheses are supported by other
structures get more time they could have
a higher probability of running and that
allows the system to use feedback as
percept things are perceived so it's
using context as as concepts are kind of
instantiated to narrow down the search
for a solution so now it's got it
everything's very nice and oh but it
messed up this is a problem see that the
program is stochastic there's a lot of
probability in it and it can get
different answers on different runs and
if it see it made this all this really
nice structure but it somehow ended it's
it's probabilistic when it stops and it
ended before it actually made a link
between C and the group of case so it
just changed the k2 an L okay well so
it's not smartest people that's for sure
we'll try a different one I'll just try
one more to show you
kji let's try that one go and in the
background here let's see is a network
you will be able to see this very well
but a network of concepts that have
different activations you can see all
the letters these are like the Platonic
concept of the letter A and the circle
is the activation percentage and
activated concepts have a more of an
influence on what's going on here in the
workspace as we call it and there's also
as things get perceived that activates
the concepts and there's one more little
structure i want to show you which I
can't find right now okay here got k JJ
is just doing very poorly on this demo
oh well I've lost it but there is a
temperature it's a little thermometer I
don't know where it went but it measures
sort of how well the program thinks it's
doing as it goes along and I guess I
must have closed it by accident but it
doesn't matter I want to show you the
program doing something well so I about
to run out of time on showing you this
but let's just try ABC goes to a BD what
does XYZ go to and will speed it up and
what you'll see is it's going to try to
take the successor of Z and it's going
to fail because he has no successor
let's see if it does anything here
oh it went really fast but it tried to
do that there you saw a little X appear
here it said it was trying to take the
successor of Z and it didn't work so
that makes the temperature go way up
when the temperature is high things are
more random and so structures are going
to get broken other structures are going
to get tried out we'll leave this for
now and come back to it well let's see
if it actually gets an answer sometime
so it keeps trying to take the successor
of Z medic at which is this program that
was an extension of copycat that
actually reasons about its own reasoning
that's why it's called meta cat and it's
supposed to reason about the fact that
it has it that that it's that Z is the
problem and figure out that oh
okay well all right well you you all
understand that demos never never go
very well oh here's the temperature okay
well it was hiding all right well let me
just so I'm about to run out of time
okay go back to this so this got me my
PhD believe it or not and here's a
little picture of me from 1990 with Doug
Hofstadter my advisor and John Holland
my co-advisor you may know John Holland
was the founder of the field of genetic
algorithms hits at University of
Michigan so that was a very exciting day
for me I look very hot that's like the
happiest I ever looked at my whole life
but now many years later after doing
lots of different things I kind of come
back to this to apply some of these
ideas to the problem of visual
recognition as I was talking about and
we were developed my group is developing
a program called scituate which is
supposed to rip do with situation
recognition integrating these deep
network ideas with this copycat like
architecture for analogy making okay and
I don't have time to tell you in great
detail how it works but all I'll try and
sketch it how much time do I have like
okay well I'll go for another few
minutes the idea is that we have a
concept network which gives our prior
knowledge about say a situation we don't
learn that that's like a future work to
try and learn that learn about situation
concepts we're not we're giving it the
situation concepts but we're saying
apply these flexibly according to the
situation these are supposed to be these
little code 'let's these perceptual
agents that each have a hypothesis and
do this kind of fighting it out and a
temperature which measures how well the
system thinks it's doing and this
workspace so that's kind of the
architecture concept network knows about
people dogs leashes
it knows all kinds of different possible
sort of semantic associations I can tell
you more about that later and so the
concept network interacts with this
workspace and with the deep network that
is computing low level image features
and they all feed back to one another
that's kind of the idea and if an object
is recognized that constrains the
program because it has some learned
knowledge about where associated objects
might be so if you know where a person
is that constrains if you know if you
think if I ask you is this a dog-walking
image that gives you some expectation of
where you might look for the dog and so
that makes it more why is this not going
forward oh yeah recognize components
feedback to influence activations of
concepts and create context for
subsequent recognition so it gives you
some expectations the temperature as i
mentioned controls the randomness with
which these perceptual agents these code
'let's perform their actions if the
temperature is high which reflects the
fact that the computer the program
doesn't have much understanding it
hasn't built many structured
relationship or object structures that
causes actions to be taken more randomly
because there's little information as
more structures are built the
temperature gets lower and that means
that the program has more confidence in
its decisions and it decisions are made
more deterministically and this is sort
of a this kind of transition in
perception from being very stochastic a
little bit less focused searching
randomly and transitioning to more
deterministic more focused and so on
that's seen in human perception
and human recognition so we're in the
process of building this program and we
can do things like look at what's called
week segmentation where you try and take
an image and figure out where are the
objects roughly and then we can use that
as a probability a way to get a
probability distribution over the image
for looking at different objects these
are called heat maps and basically the
code 'let's look for specific objects
based on these heat maps and the heat
maps are updated as new objects are
tentatively recognized and so you might
have many different code 'let's looking
for dogs or sidewalks and they get some
kind of rating from our deep network
that says how likely they are to be that
kind of object and as if their rating is
high enough the system will actually
build a definitive data structure which
could actually be broken later but say
now i think this is a dog and that makes
it more likely to look for other things
related to dogs in places where the
program expects them to be from prior
knowledge and starts that constrains the
search for people so these are this is
all the program actually does some of
this now but a lot of this is still kind
of vapor where I guess you call it and
I'm not going to tell you all the
details but essentially let me just skip
through this well so this is what this
this is so this isn't actually what the
program does it but it we're hoping that
it would be able to group objects and
map its structures that it biltz to
prototypical situations that are encoded
in the network performing slip
as needed so like a dog slipping to a
dog group and if the resulting
temperature is low enough it would say
yes I would classify this scene as
positive yes it is a dog-walking example
and the temperature tells you house kind
of good it is or stretched it is how
close it is to a prototype okay and if
this if it's this doesn't work out if
the map matching between the structures
built and the situation in the concept
network isn't strong enough after
several times after enough times the
system will stop with a negative
classification okay so this is this just
shows how all this is very similar to
things in neuroscience and cognitive
science and I'll end so that's kind of
what we're hoping to do and I I think
it's the analogy making in some sense is
really a key to this kind of human level
recognition of more abstract situations
and vision vision and beyond this is my
group group former and current students
and my collaborator Garrett Kenyan were
supported by the National Science
Foundation and maybe I don't know how
often this conference happens in
Portland but if you come back in two
years i'll be able to show you a working
program this okay thanks that i'm happy
to answer questions
any questions yep yes so that you can
kind of do multiple multiple partial
beliefs and kind of let other other
things that you start to learn effect
which of those might be more exact so so
the question is you know is there some
confidence associated with a object
recognition like a dog and yes so our
system has a way of computing confidence
by the the object recognition network
will give a confidence for its
recognition and also our system can
incorporate that with confidence like if
there's a person here and it thinks
there's a dog here I mean has certain
confidence that there's a person here
and it has certain confidence that
there's a dog here it can combine its
the confidences via what we what's
called a belief network too so that that
the system can reason about other where
other you know it can update its whole
probabilistic model of where things are
likely to be so so we're using
techniques from what's called graphical
models to do this kind of belief
updating other question yes look at what
you're doing is it possible to play it
backwards almost and have the computer
generate a dog-walking situation uh-huh
that's a really good question so could
the computer play it backward and
generate like a beautiful artwork of a
dog-walking situation and that's
something that so in machine learning
people talk about so-called generative
models which can generate examples by
sampling from probability distributions
and in fact I think
are this is something that our system
could possibly do and that would be a
very interesting thing to try I like
that idea yeah so have we looked at like
video for example multiple object or
movement multiple objects in a row my
group here hasn't been doing that but my
collaborator Garrett Kenyan at Los
Alamos has looked at sort of object
recognition and video and it's actually
helps quite a lot as you can imagine
yeah yeah is it open source yes so any
part that we finish and feel confident
that it sort of works it's open source
and we will make everything open source
including all of our dog walking images
and all our code yeah absolutely yes so
by prior knowledge i mean just knowledge
that the system has previously learned
or has been programmed into it before it
starts running that's all I mean by
prior knowledge a prior and bayesian
statistics is a probability distribution
over something so you know you a prior a
bayesian prior might be incorporated
into our prior knowledge that's right
yeah
yeah so definitely we do use these this
notion of Bayesian priors because
because we're using Bayesian belief
networks yeah is there in the back there
it's hard for me to see you by correct
do you mean so so we have a network of
concepts we do don't do any verification
as to whether that network is correct
that's been given to the program then
the program constrict constructs its own
network in the workspace which is trying
to map the concept network into the
workspace and say how do these concepts
apply here and we are able so the
program will take what's been built in
the workspace and compare it to the to
the permanent concept network and say
you know how well does it match and
that's how it asks like is this a
correct you know instance of this
situation the concept network is its
topology is not in flux it's activations
change depending on what the program is
seen at the given time that's right yeah
so he asked with our concept network is
there any compatibility with the work of
Doug lenet who's been trying to build
networks of common sense knowledge I
there probably is i don't know a lot
about what about that work i think you
know that's much larger scale than what
we're trying to do and right now and
he's trying to i think i don't know how
much learning his group is using but
yeah I mean I assume that there there
could be there's also a lot of work at
Google in trying to build these very
large ontologies for understanding you
know documents and so on that might be
compatible
yeah so eventually so right now we're
just trying to test out the general
ideas but eventually if this was ever
going to be applied more broadly we'd
have to figure out ways of getting these
so-called networks semantic networks or
ontology yeah okay yes
I i we see kind of complicated dynamics
I guess I'm not sure how to characterize
it and I haven't compared it with it
like any human learning dynamics but
that that would be an interesting way to
go but definitely it had what's what's
interesting about I think one of the
things that's different about this work
and the process of recognition actually
has dynamics as opposed to the people
who are just looking at these
feed-forward networks which really have
no dynamics it's just total feed forward
right there's no feedback at all okay
yes so do you think that there's
potential for other kinds of analogy
problems to use this system that you're
building that's meant for visual
problems but have other problems that
could be mapped onto like an abstract
space yeah so the question was could
this be generalized to other modalities
than vision and I think the answer is
yes I don't think there's that our
mechanisms are specific to vision I
think they're more general and so I you
know I would love to see it in fact for
copycat people have actually applied it
to like natural language and some other
non visual domains so I'd love to see
that kind of thing yeah yes
language a situation what language is
situate being written in so there's a
few different languages and we're sort
of prototyping things right now so we're
pro some of its written in Python and
some of the visual the very kind of core
visual routines are written in C for
speed and some of the stuff word using
is being prototyped in MATLAB i would
love to see a lisp like language applied
to it because that was like my first my
first programming was in lisp and your
first programming's like your native
language right you never it's hard to
beat it you love it but right now you
know I'm like the big manager and all my
students are doing the programming in
Python and so on so yeah we're not using
anything right now for a database we
have status sets of images that aren't
really I mean there they have they're
labeled right now it's very it's you
know fairly small networks that we're
talking about so we haven't gotten to
the stage of trying to scale it up yes
so will the processing power needed
increase probably yeah I mean one of the
things that we're trying to do is have
something an architecture that scales
that scales well that is that unlike the
work and object recognition where the
reason it's gotten so much better is
that you can now throw you know billions
of training examples at it I don't think
that's what humans do and so one of the
philosophies is to try and build
mechanisms that really won't need that
because of the ability to perceive
context and be constrained by context
that they won't you won't need billions
of training examples and you won't need
to try and apply all of your different
categories with equal probability as
hypotheses so the goal is to not have to
scale to have it scale in a bad way but
we'll see yeah yes greatly ramify your
concept networks such that you're now
recognizing concrete and shoelaces and
all these individual pieces that help
you construct you know work up to these
high-level concepts and not rely so much
of a deep network and it's sort of you
no difficulty in guessing whatever
things a dog or a dog shaped you know
right so um that the question was it
would it be useful to sort of recognize
more things at the level of the concept
network like you know small pieces of
like a dog paw or a dog ear or something
I don't know actually because you know
the deep networks in some sense our
learning features and it may be that
those are the features they're learning
it's a little bit hard to open the hood
look under the hood of what they're
learning but if you could do that it may
be that that's precisely the kind of
thing that they're learning to recognize
so I'm not sure what the answer to that
is but it's a good question yeah
explore the search space doesn't what
how would you characterize it because
you are covering a large search space
right belief propagation so it's not a
kind of a simple yeah I don't think it
has it has a name so Hofstetter called
it a parallel terrorists can which is
kind of a weird name but the idea is
that you're exploring many different
possibilities in parallel or potentially
in parallel with these agents they could
run in parallel for example but not
everyone is exploring at the same rate
the ones that seem more promising get
more processing time but that changes
dynamically as more information is
gained so he called that a parallel
terrorists can there's probably a better
name for it but I don't know what it is
yeah
so they communicate via the structures
that they build in the workspace that's
so it's kind of like common blackboard
system yeah yeah
I yeah I'd love to be able to predict if
something's going to be funny or not and
I know people people have theories of
humor but I'll just say that's not the
goal of this particular project but it's
a potential NSF proposal maybe I don't
know yeah reliably conclude what an
image shows what would that lead to as
the next okay so if you could recognize
what situation an image was that would
be great because you could finally
organize all the photos on your phone
right that's the main application right
sakes please give me all the pictures of
birthday parties what's the next hard
problem Wow well there's a lot you know
I guess there I'm not I don't there's a
lot of hard problems I mean you know
being able to I mean that's kind of an
open-ended thing though being able to
recognize situations because I might
want to say now give me all the sad
situations right it's kind of a meta
situation yeah well I mean it's trying
to build something that can do something
humans could do really well but
computers can't do really well and
that's kind and that's the why and I
think that there will always be things
that humans can do well that computers
can't do well I mean that's just my
belief but I think we're getting you
know closer but that's that's the reason
we're doing it and I'm really interested
in how you know how people do it too so
I think it maybe we'll give some insight
into human cognition and you know I
think no well that's a whole that's
another subject so i will get into that
okay maybe one more question that does
anybody have another question okay in
the balcony oh I don't even know there
was a balcony okay yeah
so what will be the bottleneck yes so so
there's a lot of bottlenecks obviously
but learning concepts learning what what
characterizes a particular situation
also you know what we're doing now is
much simpler than what humans do I mean
what we're doing now is saying is this a
X kind of situation but instead of that
what humans do is I give you a picture I
say what's this a picture of I don't
even give you any hints right and you
tell me so it's like you retrieve the
kinds of situations that it could be how
do you do that I you know that's a sort
of modeling memory and that's that's a
very hard thing I don't I don't know how
to do that but you know I think it has
something to do with analogy making also
so how our memories are stored as
situations that are connected in an
illogical ways I don't know if that
answered your question but ok well
should we stop now thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>