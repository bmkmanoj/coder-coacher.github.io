<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Power of Lacinia &amp; Hystrix in Production - Tiago Luchini | Coder Coacher - Coaching Coders</title><meta content="The Power of Lacinia &amp; Hystrix in Production - Tiago Luchini - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Power of Lacinia &amp; Hystrix in Production - Tiago Luchini</b></h2><h5 class="post__date">2017-10-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uL9QavmAInw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so first things first thank you very
much and I was 10 a.m. in the morning
Friday the 13th and you are here you
know to talk about history and licinia
in production so my name is Thiago
Luchini you see my my handle there maybe
we start even there like saying hi
you know I'm Tiago Luchini I'm
partnering technology for a company
called working company we'll be talking
a little bit more about that in quite a
bit but just before we dive into into
the content I want to present myself a
little bit better with something that is
not related at all with with technology
or or development so if you throughout
this 30 minutes 40 minutes we're gonna
be talking here you find my accent a
little bit weird here's the reason so
during the last 12 13 years I have being
all over the place I have been you know
moving following the money following
different projects different interesting
things and research and if you really
want a more accurate depiction of that
because this is this is cool right this
is a this is our designer friends would
love it cuz like it looks pure just a
flags but the penis' diagram is like
this and that probably explains and the
dotted lines there is because my first
name is Portuguese my last name is
Italian I was born in Brazil and then I
kept moving back and forth like on this
places so this is going to be relevant
quite a bit something else that that I
want to be very open about is that when
I'm not coding when I'm not working I'm
doing this I'm a distance runner and
what it means in practice is like for
instance this race last year was a 60 K
so you know it's 50 miles 100 miles and
preparing for a 200 mile next year and
this is a not such a big room but if you
get if you in the back cannot recognize
me I'm not the hot looking one on the
left the one looking rather intent on
the right
side and overly equipped of course we're
engineers so I have to carry all sorts
attack with me of course the last four
years have been working with that with a
bunch of friends in a company called
working company and so we are around 230
people now we have offices in six
different places we are kind of a global
company and the kind of stuff that we do
is that we design and develop products
that people use every day so what kind
of products and uh so I compiled here
very brief list off some of our clients
so you probably have used some of our
products before they are digital
products that we interact from my Eider
and app perspective or an embedded
perspective or or or even web so cool so
that's a little bit about me I want to
hear a little bit about you guys so that
we can continue so I don't know how many
of you have heard worked or anything
about Ksenia so show of hands who has in
it so that's cool I can actually
probably summarize things a little bit
anyone has used graph QL in something
else like JavaScript shame on you guys
so what about history who has used
played with history cool any other
circuit breaker out there anyone using
another circuit breaker who I want to
talk to you later
anyone tried to combine licinia and
history together awesome so we're gonna
get to the conclusion very quickly so
just for those of you who don't know
what lesson is very quick primer so
latina is is an implementation from
sponsored by Walmart labs of the graph
QL interface graph you always Facebook's
query language for api's we're gonna
have a little bit of a primer of what
that means before we dive deeper into it
but in a nutshell
licinia really helps you provide this
kind of API interface and it's super
fast
what's history history is a secret
circuit breaker implementation it's a
it's a very interesting architecture
that has helped us a lot in quite many
resilient application
we're also going to go a little bit
deeper into what is a circuit breaker
what it what it means in practice and
why both are interesting together but
just keep that in mind
Netflix has been using it it's sponsored
and maintained by Netflix it's super
cool
so why both of them together and I truly
hope that we can answer that at the end
of this presentation so but from our
experience that we have been using
either lesson 18 isolation or histories
and isolation and when we start
combining them we were like wow we have
a very interesting super-powerful
combination here so you know by the
power of composition and getting the
best of every single world we got to a
very interesting in solid architecture
that we want to share so let's start
with a very simple example and then I
want to use your even a case that you
guys would eventually recognize because
it's an e-commerce website all the shoes
is one of our clients they came to us a
few a few few months ago with this
mission of renovating the whole website
the whole digital experience and it's a
it's an e-commerce here this is the
future and a selection page the the
product selection page you have
different futures if in categories and
it's what you would expect on an
e-commerce website right you have
products prices images futures
categories so let's say the for instance
we are tasked we're gonna do it here a
simple example using this kind of domain
so I I'm a little bit old-school so I
like starting my implementations by
singing the the model at least a schema
and how things relate to each other so I
quickly designed here a very simple
model on how of a very simple schema on
how this would work of course you see
lots of relationship lines there and
that's because even something as simple
as just like relating products and
categories might be a little bit more
advanced I created the several different
ways of relationship between these guys
just to extrapolate the model a little
bit so the product has categories but a
kateri has parent categories and also
children categories and we also have
breadcrumbs because I want to be able to
actually see the whole path
to get to a certain product so I kind of
extrapolated a little bit so that this
wouldn't be a super boring example and I
also wanted to show a little bit some of
the power that we have in our hands but
as I said this this is me right this
looks a little bit like UML but it's not
it's kind of a UML like notation we use
graphics to render this and and we I'm
gonna get to more details about this in
a bit but if you don't want to see it
this way of course let's get to some
closure
edan here so that we feel more at home
so it's the same stuff right like this
that initial diagram just renders into
this even file this is the way the
licinia actually understands it licinia
needs a file like this to bootstrap the
reason why you know I have that
beautiful diagram is that as part of our
tooling internally we have this neutral
schema language that we define called
umlaut we have a beautiful insta parse
tool that just generates all sorts of
schemas for us we just write we don't
like repeating ourselves as most lazy
developers and the good ones are old
lazy ones so we just write it once and
then we have generators for Alice in a
schema for graph is foreclosures back
because of course we want everything
validated and even for those crazy
people that want to do graphic you out
in JavaScript we just export for them
and the good luck so going back to my
schema that's my schema for something
very simple and the way the last senior
works is that you combine a schema
definition we're a bunch of resolvers
and those resolvers all have the same
signature they also receive a context a
bunch of argument which is a map and the
value that is been created so this
resorts are being called recursively to
build the output that you want you wrap
these guys up into this box called
licinia which is a licinia executor you
wrap licinia up into a an HTTP pedestal
ring you name it and then what you have
is something super cute which is you
send graph QL queries to your API and
you get JSON responses on the other side
what does this mean in practice this
means you know this
as very simple graph QL query for this
domain I just want the name of all the
products and then you get a response
like this in my memory very overly seem
to simplify database for this domain so
showing that I'm cold this is the way
that I'm actually just loading up my
licinia schema of course you see the
magic here is just a thread macro very
simple trad macro the first three lines
are just like creating the schema
because i'm creating out of my my
definition file I attach a bunch of rows
overs which are just a bunch of
functions that I have in a different
domain in a different name space and
then I compile this schema and I have a
almost ready
licinia system in place of course I have
to weave wrap a little bit with my HTTP
server separately but that's out of the
scope of this conversation but this is
interesting this is this is that
probably the next interesting part of
last scene implement a licinia
implementation you are resolver of
course for something like this super
simple I only have two rows over so this
is my product resolver right so you
don't have to worry too much about all
the parameters I'm passing around but
what it's it's doing in practices
querying a database so it just squares a
database you can actually do a little
bit of transformation if that's the case
and exposes that back to my to my
consumer right one cool thing about the
graph QL ecosystem if you will is a
thing called a graphical or you know we
didn't know how to pronounce it
initially when we're like graphic iql
they put an eye there and they call it
graphical for some reason it's a react
application
licinia has it by default you just send
it true and it will create an instance
of it for you when you so when you bump
it up and what it does is that it allows
you to interactively check and
interactively deal with your data model
and with your with your queries and I'm
going to show you here a very simple
example so what I'm doing here is that
you know you can see on the right hand
side I have all the documentation I can
explore my model in further detail
and I can also without a complete on the
left-hand side I can just create the
queries I want so something super simple
as I want the name and the images play
there you go I have the name of the
images in my database if I want to
extend a little bit for instance I want
to know the category of each one of the
products I refer to the author is over
category name I have the name of those
guys great can go a little bit deeper
for instance agreement remember I told
you I had breadcrumbs so I want to see
the breadcrumbs of all these products so
all the categories to get to that
product great easy as hell and because
these models are self referential my
categories also have products so I can
even go deeper into my categories and
get the products of those categories
this is another interesting tool the
offer of graph QL
you can create aliases so I also created
a tiny little future by ID on my
products endpoint and I'm saying give me
the product that has a by the ID be AR
and I'll call it prod 1 and then call it
prod 2 for my ID
SDE and i want the name and the image of
each one of these guys name an image
play and there you go you have those two
right so this is a super quick primer
just to tell you that we're giving a lot
of power to the front-end when you do
something like this because the
front-end can kind of change and evolve
in tiny little ways that make it super
easy for for for us to accept change at
the end of the day but I want to talk a
little bit about something even deeper
like things change drastically in
production especially when things are
already out there out live and this is a
very dear subject to my heart because
you know I moved a lot and what I
noticed my native language when I was
preparing this is that important he's my
native native language the word move and
changed they are the same I had never
noticed that and and I quickly checked
on the dictionary and I realized that
move in English actually says advance or
progress it's one of the meanings right
so we're always moving forward and
trying to advance and people kind of
hate change you know every now and again
but it's one of the only ways to
progress
I really love that let's let's change
something a little bit deeper into this
thing you saw this payload over there
when we work wearing it and you I don't
know if you notice but the images were
quite big we were talking about 3200 by
3200 images they are huge so as you
probably know out there when we have a
situation like this our users will want
our front end users they will want
something a little bit more adaptive
they want images you know for the size
of their devices for the size of the
wearables and 3200 is a little bit too
big you don't want to send such a big
image anyway so let's make that happen
let's make that change right let's start
with the initial model that we had and
I'm gonna extend it you know by magic
zooming in very quickly and you probably
notice that I kept the old image over
there because I don't want to break any
app anything that is using that image
I'm creating something that I call image
object
I created a separate schema called image
that encapsulate a little bit more data
in this case the URL and the width and
the height of the image that I'm sending
back and I also added two parameters two
arguments to this node that I call the
width and the height of the image I'm
trying to fetch from the database or
from any system in between in this case
so how do i build a resolver i had to
trade it resolver specifically for
images and this is it
and what's too much
so I created resolver just for it and
you can seem this resolver that I have
the width and the height I'm getting
this width and height from the arguments
I set a default without 3,200 just to
keep the same similar behavior and then
I have some magic of course I hit that
that magic and in a separate namespace
here in the function called parse image
prep there ends that that goes through
these things and calculates what the
size of the image should be you know
fetches it from from a local storage or
remote storage or do whatever or even
does the the dynamic resizing if that
need be but it's hidden somewhere so
let's see that in action you see those
those arguments they're the parameters
as I said my magical function and then
let's see this in practice let's it
isn't graphical so in graphical and of
course as you would expect of course it
has updated the the right hand side you
can see the two different images there I
can see more details this is great for
your users on the other side of this API
because they don't need to actually go
into swagger or anything like this they
can just like browse and explore your
API you know as they go so I'm gonna
just do a query where I ask for the
image object and you see the basic image
there I copy and paste this image or
just wanted to make sure that it's the
wrong and big one should be a gigantic
image it took even a while to them to
refresh there you go super big so you
imagine if you were in a mobile device
you don't want that that huge picture
you want something smaller you want
something like you know ten times
smaller and I get a different URL for a
different asset this asset in this
example is statically rendered but but
in some of our cases we dynamically
render this assets as well just in case
and then we cache them but there you go
this is a much smaller image super easy
and of course you can change any kind of
resolution you want and one good thing
is that because you were combining the
resolvers and building on top of the
reserves you already had I still retain
the autores over that already had the by
ID so I can still combine and I don't
really change much from the from the
client perspective so what this means in
practice is that for our production
environments let's see implementing
something like licinia and by using
tooling like like your mouth you will
out for instance we can change fast
we can change super fast but in
production there is something else that
happens you know things go wrong and
they go wrong very very often and this
is also something else that is very dear
to heart to me so this is me in a in a
very desperate position in my last
attempt to run a hundred miles non-stop
this was probably around our sixteen I
don't know I know I stopped counting at
that point things were going badly
things were failing it doesn't really
show in the picture but I had almost
fell down a cliff and my leg was
bleeding and it was 16 hours it was
tired and I was it was depleted of
energy and the funny thing is and I even
have a video I you know I prepare for
everything you know that there is at
that orange folder you see in one of the
shots there it's a 40 page document that
describes how to even change the battery
of my watch if it fails because you know
I've been doing this for four years and
I know I'm kind of prepared for
everything that can happen but things
still go wrong every single time that I
try something like this so one thing
that I learned with with this with the
Navy SEALs is that they say there's all
the time embrace the suck and what it
means in practice is the situation is
bad just just deal with it just like
deal with the situation and I love the
fact that situation is bad period no I
really want to emphasize that it is bad
period and do we in the tech space as
engineers deal with the bad stuff and I
want to tell a little bit of a nun adopt
for the next slide this is a and I'm
paraphrasing the next slide because it's
a it's a project we're actually running
currently and
we're running as a client-side we have
an app and it's super slow when we heat
the backend the backend is so slow that
it times out and it times out over and
over again so we asked our our our
friend engineers on the other side guys
please have a look at it you know what's
happening and this is what they wrote to
us
so great you know they found the source
of all evil the source of all evil is
that there's more evil like the stuff
breaks and it's okay right like it's a
we are all engineers we're all friends
we understand this this is the way it is
but I didn't show you the whole message
because for me the conclusion was a
problem so it's correct the shrug the
shrug in a meme and and that's it like
oh the results we can do it it breaks
all the time
and I I don't like that right like I
think that maybe because of my Ronnie
stuff happens we prepare and when it's
bad we fix it again and we keep fixing
and we keep making it better especially
for production why this happens and I
have a theory this this happens because
we believe in the happy path and the
happy path here is like we have a user
the user hits our server
it's our HTTP server the and then we
have like all these dependencies and
everything is green everything is happy
there's nothing goes wrong we have these
external dependencies you know here
artistically you know one could be a
database another one is an external
server a web server some soap you
have to do but our HTTP there is
basically sitting and doing this
orchestration everything is fine but
what happens when one thing goes wrong
so same diagram same user no we heat a
our web server but one guy there is
eiders is slightly slower or just like
problematic for some reason and very
quickly if you have a a constant rate of
requests let's say 50 requests a second
heating this server all the threads of
the of the HTTP server can be blocked
the super super fast you know it's what
I call like tiny problems big
repercussions like it can really scale
super quickly so using our example you
know I since everything is in memory and
it was closure closure is super easy I
implemented a simple latency simulator
so my simulation here is like let's say
that our products and categories and
whatnot they're in a database I have to
get
the data from that database but I have a
tiny latency there that runs an average
of 100 milliseconds you know oscillates
a little bit has 100 milliseconds of ice
under deviation and let's see what at
what happens you know let's run some
some load on this server and this is the
latency diagram that I got and then if
you're not used to a ladies latency
diagram a very quick primary right so
what this means in practice is that 99.9
percent of our requests to the server
they they get a response within 500
milliseconds right 493 or whatever but
if you calculate this based on your your
usage behavior you might get something
like this that you know around 6% of
your users are seeing at least one
request that takes 500 milliseconds so
even with something as Tiny as a 100
millisecond there can scale all the way
up to 500 a failure point whoo beautiful
numbers you know what this means for me
and I'm you know sometimes I try to wear
the hat of a business guy this is money
on the table because if my users leave
my website because they're expecting a
response in 200 milliseconds and I have
6% of my users hitting it at 500
milliseconds I'm losing money like my
users are not really they're just going
to a competitor right so this is bad
already but I kept like moving forward
so I tried to simulate something else
here tried to simulate well what if my
products are coming from a query and my
product my products are coming from one
and categories are coming from another
one so I have two dependencies or I have
like whatever a web server for one and a
database for the other one or two
queries
it doesn't matter two dependencies and
they follow the same standard deviation
right the same 100 and 104 for both and
I simulated the very same load once
again and I put them side-by-side not
surprisingly he doubles right again this
means like almost a second 4 4 4 6
percent of our users great now let's
simulate that one tiny problem happens
and this is tiny right well this one
database sometimes takes 2 seconds
sometimes takes 0
six one sometimes six four we don't know
it's just like slow because there is a
kind of problem in the network or in the
infrastructure but I'm simulating that
here by like bumping it up to a two
second average and two second standard
deviation and this is the very same load
and uh you're gonna be surprised
it goes up super fast and then I'm
zooming in very quickly here because
this is ko is completely out of
proportion right we were talking about a
minute and a half almost two minutes for
some users minute and a half it's super
quick for my opinion and just to put
that in perspective like the blue line
there was our worst case scenario before
right so this is so out of proportion
that that it's it's unfathomable and put
put some numbers because uh a hundred
percent of our users saw twenty thousand
milliseconds twenty seconds
seventy percent of our requests were
lost and the server performance actually
is lower you know
what's five times slower so it's like
completely out of our over I cannot even
think of something like this and then if
you can't as well and you think that
your servers are perfect there is a
little bit of a support of mine because
I keep going through the front-end code
or arc of our projects or open source
projects and I look for stuff like this
and I'm zooming in have you guys never
seen this I've seen there's so many
times and I love when he happens like
this the the default timeout is one
second and then he bump it up to two and
then five and then 10 and then 60 this
one's gonna be 120 quite soon right it
does happen it does happen see if you
don't you doubt me just go ahead and try
so
let's welcome circuit breaker so if you
haven't seen a circuit breaker physical
one that's how it looks this is a
circuit breaker for you our electricity
for our electrical installations and
what it does is that it protects the
tree of within the grid right so if
there is a short circuit in your
apartment your unit you don't want that
short circuit short-circuit your
neighbor or the whole building and so
you have this tree of circuit breakers
that keep like protecting it increasing
increasingly more powerful and bigger
chunks of electricity so what do you
mean in practice for for us on a
software perspective is something like
this the same diagram I had before the
user hits a HTTP server but instead of
heating directly the dependency you have
a secret breaker in between and in this
case we're gonna be talking about
history and if there is something that
is wrong down down there in the
dependency this secret breaker notices
that and controls the the feedback loop
all the way up to the to the consuming
side right what it means in practice
let's see that on the code level so here
I imported history so you have two ways
of using history so you can import it
directly to implement it in Java so of
course we are in the Java ecosystem we
can do whatever we want but I'm using
their official wrapper that is part of
the package is super super well designed
and this is it it provides a def command
McRib so what the dev command does it's
a very similar signature as the DEF and
macro and as you can see I just created
a def command called fetch products that
uses the same signature that I already
had elsewhere and kind of isolates just
wraps my in my external dependency and
you see it down there what I call it
that I'm instead of calling the query
directly now I just call fetch products
and the magic that is happening when I
do this kind of stuff is that now
History's is controlling this one there
is a command patter pattern around this
function called fetch products that
controls the quality of this dependency
so you can have a lot of configuration
you can fine-tune any way you want this
one specific integral
point but by doing just this it means
that the very basics taking place for
instance if there is a one millisecond
1000 millisecond delay or timeout you
would immediately say well there is
something wrong with that dependency let
me open the the circuit breaker and let
me stop like people are not going to be
able to actually reach this this guy
anymore I'm gonna air out before trying
it again and then every now and again I
just try it once again see if that it's
healthy now if it's healthy I close the
circuit and everything is back the back
on live if you just do like this your
products gonna be much better your input
your server is gonna actually act much
better one practice that we have is that
for every single external dependency we
even wrap them in a map called external
dependency every time you need to
actually use any one of those wrap it up
on it on a def command because that's
gonna make your product better so this
is this is more than enough but I want
to show you something else I added this
one line here it's part of the macro
it's it's a map where you can subscribe
you can send lots of fan configuration
to history but one of the things that I
really love is the fallback strategy
it's a it's a function with the same
signature as your incoming function and
this is like when stuff goes wrong what
do i do so in this case what I'm telling
hysteresis if your dependency fails you
cannot hit reach the database for some
reason just return with a with an empty
vector just return something right this
is called a fail silent strategy we I'm
gonna go a little bit deeper into that
soon but I run the same performance load
over it and completely different curve
and what's beautiful about this curve is
that anything below one second is super
fast because it flattened out about one
second it means well this is your
protection this is where your your
secret breaker is being triggered and
just like in comparison this was like
the two dependency approach that we had
before so even for is a very simple
example like this it already made it
much faster and and and that one and and
the one with a bump is the one where
it's acting up that one of the
appendices is actually broken so that's
super cool so you might be saying well
but sending
empty vector is kind of dumped and I
agree is dumped so there are a few
different strategies for fall back to
simple ones one is fail fast just like
no fail and send an error message the
client like I can't I can't do this now
there's a problem
failure silently just in the nail what
true or false or an empty vector like I
did there are more advanced things like
send us in a static content because I
you know that 90% of people need the
static content so let's end this put
this stuff stub content like a inferred
what the response could potentially be
out of a parameter that's a there's
something interesting the one that I
really like is the cached one just like
hit the main cache or some kind of
memory cache that you had before or a
similar query in the send it back
and you can also do very advanced stuff
like chaining fallbacks the same way you
can you can connect several circuit
breakers physically one after another
you can also do that with with fallback
strategy you can have like a def command
that calls another def command that
cause another one and they have
different strategies so if the first
fails the next one actually works the
next one doesn't so far and so on so
where we get here is that hysteresis
allows us to fail fast and this is super
important for production so just as a
wrap-up I want to I want you guys to
have like seven takeaways out of this
whole thing so first this in production
you have to embrace change some big
stuff will change and you have to
embrace it
don't don't don't stay there saying like
wow this is gonna take a while we have
to be as fast as possible to embrace
change second with something like
hysteresis and circuit breakers you can
embrace failure stuff will break will
fail just accept it just like embrace
the suck like the the CEO say a third
point is Dracula is just part of the
equation right it's not the whole thing
and people complain a lot about
graphically well and with reason because
of two big problems they say well
resolvers may get too complex and
everyone again they do so what you do is
easy if you put a history here you can
externalize some of this complexity to
an even an external service call it a
micro service if you like it
and voila your resolver is much simpler
people complain as well depth in graph
QL there is no browser cache because
each query is unique and use post to get
the query and there right you don't
really get a you don't really maximize
the cache on the browser side great by
using something like men cache D
connected directly with your history and
just lower your your your your
configuration on history for instance
for for for giving up and triggering the
fallback and you're gonna get a cache
that actually hits 50 percent of the
time 60 percent you can make the map so
my conclusion here is let may take away
is secret breakers they covert the
shortcomings that you normally have in
graph QL so combining both is actually
super powerful there's one thing that I
initially was part of this of this demo
but I didn't have time to put together
for you guys and we won't have time to
cover it is the Hat the history it's
dashboard it comes to free like it's
already part of the package this is a
dashboard showing every single
dependency every single function you
have how healthy or how unhealthy it's
behaving along the time and in real time
if you have a cluster this is
interesting this is showing like 500 581
nodes running within a cluster and it
collects data from all these guys we
have been putting these things together
and they are so useful now we have
DevOps people just looking at this and
being able to say system X is failing
function y is taking too long and I
truly recommend it so my fourth takeaway
here is like Mon you're gonna be able to
monitor at the function level so the
more def commands you have the more your
ability to actually have something like
this v 1.is is what we call the consumer
driven mindset by the money isn't one
carrying the money that's re the user is
the one carrying the money that's what I
meant with this picture right so user
knows what the user wants referring to
to what region and rich said yesterday
no the user doesn't really care if we're
using types or for using X if we're
using y they
Carrie if this stuff works right so and
they have the money and then every now
and again we have users coming with
money and saying like I just want this
done and we have to be the ones saying
this can be done and when we are the
ones saying this can't be done it's it's
it's a little bit annoying because we're
living money on the table so the value
starts at the consuming side and let's
highlight that when we do we do
Solutions 6th one you know even though
we talk a lot about performance with
hysterics
it's not about early optimization right
don't really consider this a performance
issue it's not it's all about failure
first just accept the fact that it's
gonna fail performance can come later
right you know performance will come
just by by by fine-tuning your your
history's configuration so this takeaway
for me is you are forcing yourself to
think about fall back every time you
know something will fail think about a
fall back and then last but not least we
talked a lot about production issues
right so we talked a lot about
production issues but when we see a
product we see features and production
issues that kind of overlap together and
I really like the whole idea of what is
called the whole product that when we
were building products for for end-users
and for consumers we're thinking about
everything we're thinking about how it's
gonna break how it's gonna be make
people happy what's gonna will be the
value delivered to users so my seventh
takeaway here is I think in terms of the
whole product don't really just focus on
on one tiny little thing thank you very
much
so we might have time for one question
or two one at a time
the question is do circuit breakers
introduce latency and the answer is they
may they may like in some of these tasks
that when we do those tests we can see a
little bit of a bump especially at the
upper end when it's doing its own thread
management so it does introduce a little
bit but not on the lower end sure it
already is actually actually if you
check on my website and you follow the
links for this presentation or even for
the open-source projects we have it's
already open source so one more sure
so the question is how sophisticated
history is and especially when you have
multiple fall backs or you don't want
fall backs or and I have to say we've
been using it for almost a year already
and we haven't explored everything it's
huge it's huge huge huge the only thing
that I say is every now and again the
the wrapper the closure wrapper doesn't
doesn't cut it and we have to go to Java
we have to fall back into just doing
basic Interop but it's super powerful it
allows like the creation of contexts and
then you can do me some memorization
within the same session it's super
flexible in terms of like multiple
fallback strategies or what else that we
have done before because that covers all
oh yeah even a threading problem because
it's multi triage so you can also like
control the trading system that
everything so if you really know what
you're doing at the JVM level at the
bare metal level you can optimize a lot
like I've been I'm not even the expert
anymore at that point cool thank you
very much guys
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>