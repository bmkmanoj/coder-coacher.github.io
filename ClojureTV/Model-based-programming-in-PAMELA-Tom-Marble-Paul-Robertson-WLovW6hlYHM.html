<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Model based programming in PAMELA - Tom Marble, Paul Robertson | Coder Coacher - Coaching Coders</title><meta content="Model based programming in PAMELA - Tom Marble, Paul Robertson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Model based programming in PAMELA - Tom Marble, Paul Robertson</b></h2><h5 class="post__date">2016-04-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WLovW6hlYHM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and I'm going to be talking to you about
a new project that we have launched as
an open source project as of this
meeting so this will be the first
meeting in which we talk about the
unroll unrolling of this new capability
over the coming year I'm going to start
off by talking a little bit about the
team I want to tell you about what
Pamela is Pamela is the name of the
project with it consists of many pieces
not all of which are available today but
some of which are I went to give a
history of the origins of the capability
an outline of what the pieces are very
briefly I want to try and give you an
idea of what we mean by model based
programming what this modeling language
is to see so that you're able to judge
whether it might be useful for things
that you're doing or or for people who
that you know might be useful with it
for it might be useful for I'm going to
talk a bit about backends backends are
things that plug in that the language
can compile down to and we're going to
talk quite a lot about visualization
because a large part of what we have
open sourced as of today includes the
visualization piece are largely due to
top marble who will give a demonstration
of how that fits in with the overall
story that I'm going to outline so
really my job here today is to try and
tell you what it is that we're bringing
to the table and we also have an
unsession this evening so whereas i get
a given an overview if you want to drill
down and ask detailed questions or have
an online session in which we look at
the internals a little that would be for
this evening so we hope you come ok I I
work for a small research company in
Massachusetts we do government-funded
work mostly mostly funded by DARPA on
this particular project as myself
andreas Hoffman who
were who did who worked with similar
technology on his PhD thesis at MIT for
cash money and Dan seers who are both in
the audience somewhere and Tom is a
consultant for our company I was made
playing a major part in a major role in
the construction of this capability and
of course we're open sourcing the
project with the intention of building a
wide community which is primarily why
we're standing here to try and attract
people to contributing as well as using
the capability so we hope that some of
you within the audience will become
contributors over time so what is Pamela
I've already mentioned that it's open
source I should say a little bit about
that we're funded almost entirely from
government contracts research contracts
the majority of what we do is ends up is
articles in journals and in conferences
or final reports there's not much that
we deliver that's real but over the last
15 to 20 years the government has been
pushing for the research performers to
produce their results in the form of
open source software largely this means
that people either say no we're not
going to do it or they say okay we will
and at the end of the project they
begrudgingly put something up somewhere
and you usually need a password to get
at it and is essentially useless we
actually wrote into our proposal for the
base Pamela project that we were going
to make this not only open source but
attempt to build a vibrant community
using it and I'll tell you why in a
minute so what what is the philosophy of
this language the lang the idea is that
we we build a lot of complex algorithms
AI algorithms I'm talking about
particularly constraints overs planning
planners
learning algorithms they require a lot
of expertise to use well and it's not so
easy it's easy to build a little
learning example that does learning over
a fixed data set but if you want to
build a complex application in which
learning is just part of it and another
part of it might be constraint solving
what tools do we have for for building
systems like Burton we're hoping that
this is an answer to that that so the
the essence of the idea is we want a
modeling language that makes it easy to
express problems which involve complex
algorithms to produce them and hopefully
this will lead to the ability to build
more interesting applications especially
in things like robotics because a large
part of a modeling languages that we are
modeling other systems they're not it's
not just a piece of software finally p
ddl for those of you who are intersect
with the planning community will know
that p DD l is the language default for
defining planning problems it's grown
rather old and it has some baked in
constraints they are now a large number
of different splinter versions of p DD l
but they're all constrained by some of
the constraints in the original version
of PE dl that are hard to get away from
we are proposing to replace that
wholesale while supporting all the
capabilities of PE dl in its various
incantations like three point 0 while
removing the limitations that get in the
way of many of the things that we want
to do in our research and hopefully
others in the planning community will
too so those things we'll talk about in
future conferences but this is the
philosophy and the drive that we have
for getting is out into the community to
help our research community but also
people building complex applications
I've got the blue screen of death well
you can describe the spacecraft and yes
if people excited about picture if you
will ah there we go yes yeah that's
right so it's important to this this
Pamela project is building on 20 years
of research and development it spans
back over a lot of a lot of languages
I've got a short list of language
antecedents there I mean the
documentation documentation we have more
this isn't an idea that we we just baked
up last week this is an attempt to
finally get out into the world something
that has been around for a long time but
it's only existed in individual research
institutions examples are Xerox PARC
NASA and MIT Brian Williams with whom I
worked at MIT and my colleague andreas
Hoffman also worked has an
implementation of our npl that in fact i
implemented while i was there but no one
can use it because it's not open source
and not willing to give it out
constantly under change the same is
essentially true for much of it many of
these languages and that's the problem
the problem is that people who want to
do this are left with having to start
from scratch and it's a lot of work so
finally we're going to have something
that cat captures the elements of all
the things that can be done in these
languages in a way that is ideal
especially for closure dating back as
far as 2001 in the Deep Space 1 mission
on the autonomous system the spacecraft
depicted in the in the picture there ran
autonomously for a period of time as a
as an experiment in which it was able to
reason about the state of the spaceship
and correct failures that were induced
deliberately by NASA to test the
capability
so that's an indication of how far back
this technology goes at the bottom of
the the thanks to DARPA for funding two
of the con tu of the contracts that are
providing for the development of this
okay so one of the ideas that we have
here is that if we want to have a
vibrant community of models and and a
vibrant community building upon the
capabilities provided by pamela we want
some way of exchanging useful models
i'll give you an idea in the moment by
what what i mean by a model but i mean a
model for things like like a cell phone
or like a robot that can that has so
many degrees of freedom we shouldn't
have to start from scratch every time in
the 3d printing world we have things
like Thingiverse well we can go online
and we can find examples of models that
are close to what we want which we can
then manipulate into what we really want
if we can do that with with models of
cyber physical systems simple ones like
robots and phones or little thermostats
whatever we can start from other
people's debug capabilities and subclass
them and and create better versions so
for that we will be providing a database
an online database capability based on
the idea of the universe and providing
an open source free platform for other
people's models in the back end area
arena the the modeling language
interfaces essentially with backends
when I spoke about having complex
solvers that we would compile down to
those of the backends we will be
providing some of those backends
ourselves we'll be providing interfaces
to existing backends especially the free
ones but also to some of the ones that
are not free but people really want to
use like like cplex
and an matlab that some people
absolutely require we can provide
interfaces to those visualization is
very big debugging these systems isn't
easy and we want to be able to see
what's going on and see what the system
thinks is going on which is why we will
spend the better part of this talk
talking about visualization so what is a
model based program we're talking about
cyber physical systems it's not a
program that that runs all by itself on
the computer somewhere we're talking
about modeling something that exists on
the other side are they on the other
side of a flap of the dividing line so
this dividing red line here divides the
the plant which is the cyber-physical
system it may be a totally software
system like a speech recognition system
but it may be a robot that has some
software running on it already and we
can interface with it we can monitor its
behavior and and our models live up here
we can divide the model essentially into
two parts the model that describes what
goes on built beneath the the red line
what the capabilities are what commands
can we send to it what observations can
we get from it and then a control
program in which commands are pushed
down to the platform in response to what
the program tells us to do so it's like
a conventional program except it's not
running on the computer it's pushing
commands down to a cyber-physical system
of some kind and the various components
in the architecture involve interpreting
the observations which largely means
build understanding the state of the
system based on what we observe and
building a plan for how to get what the
program is asking us to do which is
described in a high level achieving a
state by a sequence of commands given
while tracking the state that the system
believes that it's in so these are the
broad category of pieces in the system
so given that let's take a very simple
example and I'm not going to talk about
the language syntax but i am going to
give some example that have a large
number of parentheses in it so that
everyone's happy in this example picture
if you will a battery a battery right
there and they a switch there and a
light bulb here we have a simple circuit
that when the switch is closed the light
goes on we could imagine that there is a
a sensor that can detect whether or not
the light is on it's not part of the
circuit but it's part of the interface
with the model and we could also imagine
that we could have a control for this
switch that switch could be a physical
switch of the human throws or it could
also be controllable by sending a
command that says on or off which flips
the switch so if we want to model that
we can divide it up into components most
interesting systems are made of
collections of components here we have a
system in which on the left I've
arbitrarily divided it into the battery
and the switch so there we have a single
component which is the battery and the
switch and that we could have had the
battery in the switch of separate
components how we divide it up is
arbitrary and over here we have the
light bulb there you go there's the
light bulb and so we have essentially
this component with two terminals this
component with two terminals and some
connections that wire them together
that's what we need in our model so
let's see how we do it I'm going to go
through this quickly don't worry about
the syntax and I'm I'm not going to
explain everything all we need to know
about this is that we're defining values
what are going to be used for the power
values high and non the developer power
can be high or it can be non-existent
depending on the switch and we can
define a class the pull of powered
switch and now i'm going to add piece by
piece to that definition so first of all
we can have fields so you can think of
it like a data structure what we want
for the powered switch is a terminal pin
for the ground and the terminal pin for
the power and we need some value that
represents the state that this object is
in its going to be a power value its
initially going to be non so that when
this model starts up it will believe
that the power is off regardless of
anything else if we start getting
observations to the contrary that will
change but it will have an initial value
of none so now we can define modes a
mode says what state something can be in
and and when something is in a mode
there are certain things that are true
we can specify modes in this case we
have three obvious modes the mode that
the switch is on which would have the
condition that the power is high if it's
off then the power would be none and is
also the failed state which doesn't have
any condition at all because you can be
in a failed state without having any
conditions on it can just break so at
any point it could be it could be broken
and we and it could be showing signs of
being on it's ambiguous if the if the
power switch is on and the light is on
it looks like it's okay but if we turn
the power off and the light stays on
then it was actually broken all along so
these these can be in conflict and it's
for the reasoning our rhythms to decide
what state it believes it in but for
that we have a belief state if we have a
state we can transition between them
here we have transitions that
non-deterministic transitions that can
happen for no particular reason these
are just the names of the transitions
but this says we can go from the off
state to the on state
we can go from the on state to the off
state and we can go from any state into
the failed state with and we can even
specify the probability that will happen
based on statistics of how often these
things fail how would it transition from
after on if it was a switch that was
human operated that just means a human
changed it we knit the system knows that
it's possible to go from off to on
without being commanded and if we have
observations then the reasoning system
will update its belief state to believe
that the human turned it on sometimes
however we want to control it and
explicitly tell it to go on by sending
it and on the command so we can have a
method this turn on method doesn't have
a body it's a primitive method it's one
of the ones that you can push down and
this says that if we are in the mo in
the off mode to begin with we will end
up in the on mode and it will take
between one and three time units to get
there it's useful to know how long it
will take when sometimes when you switch
something on it's not instantaneous and
the reasoning system that wants to
reason about what's going on needs to
know if after five seconds we've
switched it on and it hasn't happened
that probably means it's broken but if
after two seconds it hasn't come on yet
then we can wait a bit longer it's too
we shouldn't jump the gun and assume
that it's not working so time-bound till
they enable the reasoning algorithms to
better reason about state transitions
and I've only put one of the methods
here because the other ones are obvious
so what we have here is a model that
essentially gives us this we have our
three modes we have transitions between
on and off that can happen without being
commanded such as by an external event
like the human turning it on we have
methods that can explicitly turn it on
and off and the planner can schedule
those commands to be called in order to
achieve an intended state and we have
failure possibilities and very often we
have a reset function so that we can try
to get out of a failed state by doing a
research and we can have probabilities
on how
likely it is that that reset is going to
work okay for the light bulb very much
the same thing we have bright and dark
as light we expect it will have
observations from a sensor that will
give us evidence in support of the light
being on or not and we have feels both
for the estimation of the illumination
and the sense input yeah I think we've
we've covered the essential elements of
that finally there's the wiring up of
the model here we have a circuit we have
rien Stan she ate a light bulb we
instantiate a powered switch and the the
source and drain variables here are the
same we use logic variables very much in
the same form as with with prologue to
do the wiring up so we can we can have
an arbitrary number of components that
are wired up use automatically using
these logic variables once we have a
circuit in place then the entire model
that we've created gets compiled down to
a data structure representation and the
back end solvers can reason about state
based on observations it can run a
program that wants to achieve a desired
state by planning out a sequence of
commands that it pushes down and all it
needs to know is the model that we've
provided and that can be for a for a
cell phone that you can send it to
command the start start recording voice
or stop recording voice generally the
cyber systems that we're dealing with a
complex systems that are doing a lot of
things by themselves and we have a
rather crude level of control of the
night turning things on or off sensing
things that are rather crude level like
is the light on or not enough to be to
be useful
but the cyber physical systems are
generally have their their own life and
an enormous amount of complexity that we
don't represent every piece of in the in
the program so I've spoken about at
wanting to achieve a desired state so
how do we do that so these are done
using control programs control programs
have a lot of capability to to measure
things like the values of herbs of
states we have state variables and it's
beyond the scope of this talk to go into
what we can do with state variables but
if we run something that establishes
some values we can we can do something
or not do something based on whether
those values are a certain value or as
long as they are or until they become
and so on I should mention that there
are there are various back-end
representations of these some of which
you're going to see in a moment one of
them is the temporal plan network that
allows a temporal planner to reason
about the timing constraints and the
dispatching of commands that are pushed
down to achieve this so let's take a
quick look we have one of the projects
involves a quadcopter here we have a
simple program that you're going to see
running in the moment in the
demonstration so it's works worth
talking through the the idea is that the
quadcopter is going to fly around a car
it's going to find flat tires and then
it will talk the user through changing
the tire someone who doesn't know how to
change tires the quadcopter walk have a
repair manual in the model and we'll
give verbal guidance to the user on how
which lug nuts to remove and so on it's
a sort of a a simple example of a robot
assisted repair repair manual
and so here the plant goes to a
particular way point this is a four-way
point example gives the way point a it
takes a high-resolution image it
processes the image and moves on to be a
processes the next image that was taken
from B and moves on to see it processes
the previous image c and moves on to d
and it then it finally processes the
last image and as as you would expect we
have other methods to implement those so
for processing we extract evidence from
the image and then based on what we've
found and this is where the state
constraints come in but I don't have
them in this example so as to keep it
simple in parallel we choose one of the
three interpretation algorithms based on
the evidence and and finally to process
and move on in parallel we go to a
waypoint and we do the plant process
which is all of this so we can build we
can build complex models complex control
programs and depend upon planning
technology to make sure that they get
sequence correctly and and state
estimation to make sure that the states
that we depend on our actually achieved
when we run them so at this point I'm
going to hand over to Tom and great so
now now is the time that we get to do
live demos which are awesome I'm really
excited about the chance to do this so
thank you Paul so Paul was showing you
the temporal planning networker tpn
implementing the quadcopter mission and
so in addition to the Pamela language
one of the things that that we've been
working on most recently as planned is
which is a Planning network
visualization tool and let me start by
just saying briefly that we have as Paul
mentioned pushed all this code up to
github under the doll
ABS organization you all probably know
how this works I just want to highlight
a couple of things about the open-source
process the code that we've published is
under the Apache to license and it's
using the very simple inbound equals
outbound licensing model which means
there is no contribution licensing
agreement that's required we're hoping
to get the community involved in
developing all the pieces of this puzzle
and have high ambitions for it becoming
not only used for research but also in
the entire planning community in general
so with that let me move on to actually
showing you a plan viz so this is our
visualization tool which is in a web
browser and it's actually developed
using closure script and I've used on
next as the visualization framework I
think that it's I want to just make a
brief digression that there are a lot of
different bindings to react Facebook
react with in closure and I think that
for me on that next is that but most
importantly I think um next brings us a
very powerful data model a very
idiomatic closure data model that gives
us the ability to do things like what
I'll just say referential integrity and
it's extremely powerful and its
expressiveness in addition what I've
tried to do here with plan vis is use
the tools in the browser to do
visualizations specifically SVG drawings
browsers now are smart enough to render
SVG natively and I wanted to actually
take advantage of that in in the work
that we're doing here so what I want to
do is I want to show you this is a TPM
temporal Planning network that
represents the bit that Paul was talking
about earlier in this you see that this
plan proceeds from left to right and we
have the state nodes
we're we're in between which there are
activities that are time bound and then
when you see a node like this with
parallel bars that means that both of
these threads if you will are proceeding
in parallel so after we capture the
images from waypoint a in parallel the
quadcopter is going to go to way point B
and we're going to analyze the evidence
from way point a and then based on that
will choose and that's what the circle
node means we'll choose which of the
activities to take next in terms of how
to interpret that data once we've done
that for waypoint a we're going to move
on a process way point B as the
quadcopter moves along to Waypoint see
and we'll do that again we will analyze
the data from see as we move to D and
after we've we've done that we'll simply
analyze the data from D now did I
mention that this is an SVG and then I
say how excited I am it's an SVG that
means you can zoom in it means you can
zoom in all day long means if you really
want to zoom in you can get in really
close and you can zoom in and I just
love that about SVG the other thing is
did i mention that it's just standard
standard web technology this is all
standard SVG and CSS so when I come and
I mouse over a note this tool tip it is
an even closer script I get that for
free with CSS if I come over to an
activity and I mouse over it I get a
tooltip for free and that's just CSS
there's no nothing complicated going on
if I want to let's say I want to come
out and I want to select an activity I
can click on a node and I can get nice
yellow highlighter around it it's so
exciting its interactive in its SVG and
it's all next and it's fun fun fun tools
that I get to play with so this is kind
of the technology stack of of plant is
now let me show you another kind of a
Planning network it's basically a deer
current view into the same plan this is
instead of moving from left to right in
time what I'm showing you here is a
hierarchical task network or an HTM so
what's in htn and htn is basically a
modular decomposition of our plan so we
start off at the very root node which is
we have a mission and then we have major
sub parts which is we're going to go to
Waypoint a then we're going to interpret
the data from a and go to be interpret
the data from be go to see interpret
theatre from C go to D and then friendly
and interpret the data from from ddc I'm
panning and zooming around here this is
so much fun so and then we have the
detail so at every point the plan it it
gets more detailed so for example after
we have the evidence from 1.8 we in
parallel we're going to imperil all here
we're going to start moving to to be but
once we have the evidence we're going to
choose one of these three notes for this
next step one of these algorithms for
interpreting it now this is important
because i'm going to show you in the
live demo of both the temporal view the
tpn view of the plan as it proceeds left
to right but i'll also show you this htn
or hierarchical view of how things are
moving forward so with that let me just
show you the the this this other screen
where I'm going to start to set this up
a little bit first of all one of the
things that we did is we wanted to make
a sort of a friendly command-line
interface for people that might be
familiar with IRC commands so that's the
way that that this works I can simply
type in a command and find out things
that are going on I can interact with
the system I can call this top window
the top window I can call the bottom on
the bottom one I can do things like a
private message I can say are you ready
and I can say
yes as a broadcast message sort of like
IRC so wait a minute how's that hat wait
a minute what just happened there there
are two different browsers two different
clients so it's yes it's a traditional
chat application the difference is that
they're not just connected in the plan
Wiz server but that plan dress server is
sitting on a rabbit and cue network and
the reason that we did that is when we
have mission execution engines and
dispatchers and quadcopter interfaces we
want them all to participate in there on
the RabbitMQ network and plan vids is
going to visualize that and we actually
have a demo of what that's going to look
like before i get into that let me just
quick show you the view of having now
i'm showing the TP on the top and bottom
and the reason i wanted to do this is i
want to show you this this thing that
we've got which is car automatic mode or
collaborative mode the idea is you know
about pair programming you have people
that are looking at the the same thing
maybe they're working remotely wouldn't
it be nice if you could do that for
visual things so if I'm I'm just trust
me i'm clicking in the top window i'm
going to pan and zoom in the top window
and look what happens in the bottom
window the remote user is seeing exactly
what i see and it's tracking exactly
what I'm doing so that is fun I can also
come in and i showed you highlighting
before but let me show you this now if i
have the the hierarchical view down
below and the temporal view let's say i
want to see what this first block looks
like i'm going to click on it here in
the htn view and look in the tpn view
it's highlighted i get yellow
highlighter that shows me what is what
is this block mean when it's actually
expanded in the temporal plan and going
vice versa I could click on one of these
activities I could say well what is what
have you know which one is this this one
interpretation thing and it highlights
it for me in the htn so i can see the
correspondence between those two so
that's that's part of our multi user
experience where we can have multiple
people collaborating on these
plans in viewing different parts of them
just briefly I want to show you a actual
quadcopter video and I'm gonna have Paul
Walker's through this it's very short
tell us what's happening Paul you can
see the quad you can see the quadcopter
up in the top left it's flying between
the way points that are described in the
program before what's happening is it's
trying to reason about what's in the
image to use the best algorithms for
interpreting it to deal with with
difficult environments it's it's it's
taking images it's thinking about what
algorithms would work best given what
it's got and it's moving on to the next
Waypoint and doing more more reason and
you can see matches that it's making
down in the bottom right and that this
is video captured from from a live run
eventually we'll have a much longer
version that in boo involves the
changing of the tire but for the moment
that's at now we can see a simulation of
the same thing running on the system so
i'm going to leave the quadcopter video
running here in the lower right and i'm
actually going to run a simulated
mission dispatching it over the RabbitMQ
network and plan vis is going to show us
this plan as it executes both in the htn
and the tpn of course this is going to
work the first time I should point out
that the video is not in any way
synchronized with the run it's just that
but you could imagine it's tqm use so so
what's happening here is you see the
nodes and the tpn are highlighting as we
move from left to right on and I can
actually oops I didn't want to do that
something had to happen it's a demo so I
wanted to zoom in here as this is you
can see the colors changing what i'm
doing is i'm taking the state that's
coming over RabbitMQ and I'm mutating
that within plan vis and using just CSS
to color these things nothing could be
easier and it's so much fun what's
happening the htn is when notes start
they turned blue and as soon as they're
completed they turn green and when all
the children are green then fund the
note above
turns green and then when we get to the
end of the plan that means the last
thing is done the root node will turn
green yay and so now our plan is
complete and we've done we've done the
planet we've understood it from top to
bottom left to right and with that let
me end by saying we probably don't have
any extra time for QA maybe just a brief
one but I wanted to call your attention
to the fact we have an unsession tonight
at eight-thirty next door in ABC and
we'd love to go into more detail and
show off you know development
environment having a connected browser
rep well and a server Ruppel at the same
time how much fun is that so with that
is already are there any quick questions
okay well great thank you so much and
hope to see you tonight at our own
session</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>