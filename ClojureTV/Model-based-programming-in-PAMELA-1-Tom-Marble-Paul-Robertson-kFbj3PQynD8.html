<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Model based programming in PAMELA 1 - Tom Marble, Paul Robertson | Coder Coacher - Coaching Coders</title><meta content="Model based programming in PAMELA 1 - Tom Marble, Paul Robertson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Model based programming in PAMELA 1 - Tom Marble, Paul Robertson</b></h2><h5 class="post__date">2016-04-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kFbj3PQynD8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and I'm going to be talking to you about
a new project that we have launched as
an open source project as of this
meeting so this will be the first
meeting in which we talk about the
unroll unrolling of this new capability
over the coming year I'm going to start
off by talking a little bit about the
team I want to tell you about what
Pamela is Pamela is the name of the
project with it consists of many pieces
not all of which are available today but
some of which are I went to give a
history of the origins of the capability
an outline of what the pieces are very
briefly I want to try and give you an
idea of what we mean by model based
programming what this modeling language
is to see so that you're able to judge
whether it might be useful for things
that you're doing or or for people who
that you know might be useful with it
for it might be useful for I'm going to
talk a bit about backends backends are
things that plug in that the language
can compile down to and we're going to
talk quite a lot about visualization
because a large part of what we have
open sourced as of today includes the
visualization piece are largely due to
top marble who will give a demonstration
of how that fits in with the overall
story that I'm going to outline so
really my job here today is to try and
tell you what it is that we're bringing
to the table and we also have an
unsession this evening so whereas i get
a given an overview if you want to drill
down and ask detailed questions or have
an online session in which we look at
the internals a little that would be for
this evening so we hope you come ok I I
work for a small research company in
Massachusetts we do government-funded
work mostly mostly funded by DARPA on
this particular project as myself
andreas Hoffman who
who did who worked with similar
technology on his PhD thesis at MIT for
cash money and Dan seers who are both in
the audience somewhere and Tom is a
consultant for our company was made
playing a major part in a major role in
the construction of this capability and
of course we're open sourcing the
project with the intention of building a
wide community which is primarily why
we're standing here to try and attract
people to contributing as well as using
the capability so we hope that some of
you within the audience will become
contributors over time so what is Pamela
I've already mentioned that it's open
source I should say a little bit about
that we're funded almost entirely from
government contracts research contracts
the majority of what we do is ends up
with articles in journals and in
conferences or final reports there's not
much that we deliver that's real but
over the last 15 to 20 years the
government has been pushing for the
research performers to produce their
results in the form of open source
software largely this means that people
either say no we're not going to do it
or they say okay we will and at the end
of the project they begrudgingly put
something up somewhere and you usually
need a password to get at it and is
essentially useless we actually wrote
into our proposal for the base Pamela
project that we were going to make this
not only open source but attempt to
build a vibrant community using it and
I'll tell you why in a minute so what
what is the philosophy of this language
the lang the idea is that we we build a
lot of complex algorithms AI algorithms
I'm talking about particularly
constraints of as planning
planners learning algorithms and they
require a lot of expertise to use well
and it's it's not so easy it's easy to
build a little learning example that
does learning over a fixed data set but
if you want to build a complex
application in which learning is just
part of it and another part of it might
be constraint solving what tools do we
have for for building systems like that
and we're hoping that this is an answer
to that that so the the essence of the
idea is we want a modeling language that
makes it easy to express problems which
involve complex algorithms to produce
them and hopefully this will lead to the
ability to build more interesting
applications especially in things like
robotics because a large part of a
modeling languages that we are modeling
other systems they're not it's not just
a piece of software finally p edl for
those of you who are intersect with the
planning community will know that p DD l
is the language default for defining
planning problems it's grown rather old
and it has some baked in constraints
they are now a large number of different
splinter versions of p DD l but they're
all constrained by some of the
constraints in the original version of p
DD l that are hard to get away from we
are proposing to replace that wholesale
while we supporting all the capabilities
of PE dl in its various incantations
like three pointer while removing the
limitations that get in the way of many
of the things that we want to do in our
research and hopefully others in the
planning community will too so those
things we'll talk about in future
conferences but this is the philosophy
and the drive that we have for getting
is out into the community to help our
research community but also people
building complex applications
I've got the blue screen of death well
you can describe the spacecraft and yes
if people excited about picture if you
will ah there we go yes yeah that's
right so it's important to this this
Pamela project is building on 20 years
of research and development it spans
back over a lot of a lot of languages
I've got a short list of language
antecedents there I mean the
documentation documentation we have more
this isn't an idea that we we just baked
up last week this is an attempt to
finally get out into the world something
that has been around for a long time but
is only existed in individual research
institutions examples are Xerox PARC
NASA and MIT Brian Williams with whom I
worked at MIT and my colleague andreas
Hoffman also worked has an
implementation of our npl that in fact I
implemented while I was there but no one
can use it because it's not open source
and not willing to give it out
constantly under change the same is
essentially true for much of it many of
these languages and that's the problem
the problem is that people who want to
do this are left with having to start
from scratch and it's a lot of work so
finally we're going to have something
that cat captures the elements of all
the things that can be done in these
languages in a way that is ideal
especially for closure dating back as
far as 2001 in the Deep Space 1 mission
on the autonomous system the spacecraft
depicted in the in the picture there ran
autonomously for a period of time as a
as an experiment in which it was able to
reason about the state of the spaceship
and correct failures that were induced
deliberately by NASA to test the
capability
so that's an indication of how far back
this technology goes at the bottom are
the the thanks to DARPA for funding two
of the con tu of the contracts that are
providing for the development of this
okay so one of the ideas that we have
here is that if we want to have a
vibrant community of models and and a
vibrant community building upon the
capabilities provided by pamela we want
some way of exchanging useful models
I'll give you an idea in the moment by
what what I mean by a model but I mean a
model for things like like a cell phone
or like a robot that can that has so
many degrees of freedom we shouldn't
have to start from scratch every time in
the 3d printing world we have things
like Thingiverse well we can go online
and we can find examples of models that
are close to what we want which we can
then manipulate into what we really want
if we can do that with with models of
cyber physical systems simple ones like
robots and phones or little thermostats
whatever we can start from other
people's debug capabilities and subclass
them and and create better versions so
for that we will be providing a database
an online database capability based on
the idea of thingiverse and providing an
open source free platform for other
people's models in the backend air arena
the the modeling language interfaces
essentially with backends when I spoke
about having complex solvers that we
would compile down to those are the
backends we will be providing some of
those backends ourselves we'll be
providing interfaces to existing
backends especially the free ones but
also to some of the ones that are not
free but people really want to use like
like cplex
and an matlab that some people
absolutely require we can provide
interfaces to those visualization is
very big debugging these systems isn't
easy and we want to be able to see
what's going on and see what the system
thinks is going on which is why we will
spend the better part of this talk
talking about visualization so what is a
model based program we're talking about
cyber physical systems it's not a
program that that runs all by itself on
the computer somewhere we're talking
about modeling something that exists on
the other side are they on the other
side of a plot of the dividing line so
this dividing red line here divides the
the plant which is the cyber-physical
system it may be a totally software
system like a speech recognition system
but it may be a robot that has some
software running on it already and we
can interface with it we can monitor its
behavior and and our models live up here
we can divide the model essentially into
two parts the model that describes what
goes on be beneath the the red line what
the capabilities are what commands can
we send to it what observations can we
get from it and then a control program
in which commands are pushed down to the
platform in response to what the program
tells us to do so it's like a
conventional program except it's not
running on a computer it's pushing
commands down to a cyber physical system
of some kind and the various components
in the architecture involve interpreting
the observations which largely means
build understanding the state of the
system based on what we observe and
building a plan for how to get what the
program is asking us to do which is
described in a high level achieving a
state by a sequence of commands given
while tracking the state that the system
believes that it's in so these are the
broad category of pieces in the system
so given that let's take a very simple
example and I'm not going to talk about
the language syntax but i am going to
give some example they have a large
number of parentheses in it so that
everyone's happy in this example picture
if you will a battery a battery right
there and they a switch there and a
light bulb here we have a simple circuit
that when the switch is closed the light
goes on we could imagine that there is a
a sensor that can detect whether or not
the light is on it's not part of the
circuit but it's part of the interface
with the model and we could also imagine
that we could have a control for the
switch that switch could be a physical
switch of the human throws or it could
also be controllable by sending a
command that says on or off which flips
the switch so if we want to model that
we can divide it up into components most
interesting systems are made of
collections of components here we have a
system in which on the left I've
arbitrarily divided it into the battery
and the switch so there we have a single
component which is the battery and the
switch and that we could have had the
battery in the switches separate
components how we divide it up is
arbitrary and over here we have the
light bulb there you go there's the
light bulb and so we have essentially
this component with two terminals this
component with two terminals and some
connections that wire them together
that's what we need in our model so
let's see how we do it I'm going to go
through this quickly don't worry about
the syntax and I'm I'm not going to
explain everything all we need to know
about this is that we're defining values
that what are going to be used for the
power values high and non the power can
be high or it can be non-existent
depending on the switch and we can
define a class with a bullet powered
switch and now i'm going to add piece by
piece to that definition so first of all
we can have fields so you can think of
it like a data structure what we want
for the powered switch is a terminal pin
for the ground and the terminal pin for
the power and we need some value that
represents the state that this object is
in its going to be a power value its
initially going to be non so that when
this model starts up it will believe
that the power is off regardless of
anything else if we start getting
observations to the contrary that will
change but it will have a an initial
value of none so now we can define modes
a mode says what state something can be
in an and when something is in a mode
there are certain things that are true
we can specify modes in this case we
have three obvious modes the mode that
the switch is on which would have the
condition that the power is high if it's
off then the power would be none and is
also the failed state which doesn't have
any condition at all because you can be
in a failed state without having any
conditions on it can just break so at
any point it could be it could be broken
and we and it could be showing signs of
being on it's ambiguous if the if the
power switch is on and the light is on
it looks like it's okay but if we turn
the power off and the light stays on
then it was actually broken all along so
these these can be in conflict and it's
for the reasoning our rhythms to decide
what state it believes it in but for
that we have a belief state if we have a
state we can transition between them
here we have transitions that
non-deterministic transitions that can
happen for no particular reason these
are just the names of the
but this says we can go from the off
state to the on state we can go from the
on state to the off state and we can go
from any state into the failed state
with and we can even specify the
probability that that will happen based
on statistics of how often these things
fail how would it transition from after
on if it was a switch that was human
operated that just means a human changed
it we knit the system knows that it's
possible to go from off to on without
being commanded and if we have
observations then the reasoning system
will update its belief state to believe
that the human turned it on sometimes
however we want to control it and
explicitly tell it to go on by sending
it a noncom and so we can have a method
this turn on method doesn't have a body
it's a primitive method it's one of the
ones that you can push down and this
says that if we are in the mo in the off
mode to begin with we will end up in the
on mode and it will take between one and
three time units to get there it's
useful to know how long it will take
when sometimes when you switch something
on it's not instantaneous and the
reasoning system that wants to reason
about what's going on needs to know if
after five seconds we've switched it on
and it hasn't happened it probably means
it's broken but if after two seconds it
hasn't come on yet then we can wait a
bit longer it's too we shouldn't jump
the gun and assume that it's not working
so time bansal they enable the reasoning
algorithms to better reason about steak
transitions and I've only put one of the
methods here because the other ones are
obvious so what we have here is a a
model that essentially gives us this we
have our three modes we have transitions
between on and off that can happen
without being commanded such as by an
external event like the human turning it
on we have methods that can explicitly
turn it on and off and the planner can
schedule those commands to be called in
order to achieve an intended state and
we have failure possibilities and very
often we have a reset function
so that we can try to get out of a
failed state by doing the research and
we can have probabilities on how likely
it is that that reset is going to work
okay for the light bulb very much the
same thing we have bright and dark as
light we expect that we'll have
observations from a sensor that will
give us evidence in support of the light
being on or not and we have feels both
for the estimation of the illumination
and the sense input yeah I think we've
we've covered the essential elements of
that finally there's the wiring up of
the model here we have a circuit we have
rien Stan she ate a light bulb we
instantiate a powered switch and the the
source and drain variables here are the
same we use logic variables very much in
the same form as with with prologue to
do the wiring up so we can we can have
an arbitrary number of components that
are wired up use automatically using
these logic variables once we have a
circuit in place then the entire model
that we've created gets compiled down to
a data structure representation and the
back end solvers can reason about state
based on observations it can run a
program that wants to achieve a desired
state by planning out a sequence of
commands that it pushes down and all it
needs to know is the model that we've
provided and that can be for a for a
cell phone that you can send it to
command the start start recording voice
or stop recording voice generally the
cyst the cyber systems that we're
dealing with a complex systems that are
doing a lot of things by themselves and
we have a rather crude level of control
of them like turning things on or off
sensing things that are rather crude
level like is the light on or not enough
to be to be useful
but the cyber physical systems are
generally have their their own life and
an enormous amount of complexity that we
don't represent every piece of in the in
the program so I've spoken about wanting
to achieve a desired state so how do we
do that so these are done using control
programs control programs have a lot of
capability to to measure things like the
values of odds of states we have state
variables and it's beyond the scope of
this talk to go into what we can do with
state variables but if we run something
that establishes some values we can we
can do something or not do something
based on whether those values are a
certain value or as long as they are or
until they become and so on I should
mention that there are various back end
representations of these some of which
you're going to see in the moment one of
them is the temporal plan network that
allows a temporal planner to reason
about the timing constraints and the
dispatching of commands that are pushed
down to achieve this so let's take a
quick look we have one of the projects
involves a quadcopter here we have a
simple program that you're going to see
running in the moment in the
demonstration so it's works worth
talking through the the idea is that the
quadcopter is going to fly around a car
it's going to find flat tires and then
it will talk the user through changing
the tire someone who doesn't know how to
change tires the quadcopter walk have a
repair manual in the model and we'll
give verbal guidance to the user on how
which lug nuts to remove and so on it's
a sort of a a simple example of a robot
assisted repair repair manual
and so here the plant goes to a
particular way point this is a four-way
point example gives the way point a it
takes a high-resolution image it
processes the image and moves on to be a
processes the next image that was taken
from B and moves on to see it processes
the previous image c and moves on to d
and it then it finally processes the
last image and as as you would expect we
have other methods to implement those so
for processing we extract evidence from
the image and then based on what we've
found and this is where the state
constraints come in but I don't have
them in this example so as to keep it
simple in parallel we choose one of the
three interpretation algorithms based on
the evidence and and finally to process
and move on in parallel we go to a
waypoint and we do the plant process
which is all of this so we can build we
can build complex models complex control
programs and depend upon planning
technology to make sure that they get
sequence correctly and and state
estimation to make sure that the states
that we depend on our actually achieved
when we run them so at this point I'm
going to hand over to Tom and great so
now now is the time that we get to do
live demos which are awesome I'm really
excited about the chance to do this so
thank you Paul so Paul was showing you
the temporal planning networker tpn
implementing the quadcopter mission and
so in addition to the Pamela language
one of the things that that we've been
working almost recently as planned is
which is a Planning network
visualization tool and let me start by
just saying briefly that we have as Paul
mentioned pushed all this code up to
github under the doll
ABS organization you all probably know
how this works I just want to highlight
a couple of things about the open-source
process the code that we've published is
under the Apache to license and it's
using the very simple inbound equals
outbound licensing model which means
there is no contribution licensing
agreement that's required we're hoping
to get the community involved in
developing all the pieces of this puzzle
and have high ambitions for becoming not
only used for research but also in the
entire planning community in general so
with that let me move on to actually
showing you a plan viz so this is our
visualization tool which is in a web
browser and it's actually developed
using closure script and I've used on
next as the visualization framework I
think that it's I want to just make a
brief digression that there are a lot of
different bindings to react Facebook
react with in closure and I think that
for me on that next is that but most
importantly I think um next brings us a
very powerful data model a very
idiomatic closure data model that gives
us the ability to do things like what
I'll just say referential integrity and
it's extremely powerful and its
expressiveness in addition what I've
tried to do here with plan vis is use
the tools in the browser to do
visualizations specifically SVG drawings
browsers now are smart enough to render
SVG natively and I wanted to actually
take advantage of that in in the work
that we're doing here so what I want to
do is I want to show you this is a TPM
temporal Planning network that
represents the bit that Paul was talking
about earlier in this you see that this
plan proceeds from left to right and we
have the state nodes
we're we're in between which there are
activities that are time bound and then
when you see a node like this with
parallel bars that means that both of
these threads if you will are proceeding
in parallel so after we capture the
images from waypoint a in parallel the
quadcopter is going to go to way point B
and we're going to analyze the evidence
from way point a and then based on that
will choose and that's what the circle
node means we'll choose which of the
activities to take next in terms of how
to interpret that data once we've done
that for waypoint a we're going to move
on a process way point B as the
quadcopter moves along to Waypoint see
and we'll do that again we will analyze
the data from see as we move to D and
after we've we've done that we'll simply
analyze the data from D now did I
mention that this is an SVG and then I
say how excited I am it's an SVG that
means you can zoom in it means you can
zoom in all day long means if you really
want to zoom in you can get in really
close and you can zoom in and I just
love that about SVG the other thing is
did i mention that it's just standard
standard web technology this is all
standard SVG and CSS so when I come and
I mouse over a note this tool tip it is
an even close your script I get that for
free with CSS if I come over to an
activity and I mouse over it I get a
tooltip for free and that's just CSS
there's no nothing complicated going on
if I want to let's say I want to come
out and I want to select an activity I
can click on a node and I can get nice
yellow highlighter around it it's so
exciting its interactive in its SVG and
it's all next and it's fun fun fun tools
that I get to play with so this is kind
of the technology stack of of planned
res now let me show you another kind of
a Planning network
it's basically a different view into the
same plan this is instead of moving from
left to right on time what I'm showing
you here is a hierarchical task network
or an HTM so what's in htn and htn is
basically a modular decomposition of our
plan so we start off at the very root
node which is we have a mission and then
we have major sub parts which is we're
going to go to Waypoint a then we're
going to interpret the data from a and
go to be interpret the data from be go
to see a terp rehtaeh dated from c go to
d and then finally interpret the data
from from ddc I'm panning and zooming
around here this is so much fun so and
then we have the detail so at every
point the plan it gets more detailed so
for example after we have the evidence
from 1.8 we in parallel we're going to
imperil here we're going to start moving
to to be but once we have the evidence
we're going to choose one of these three
notes for this next step one of these
algorithms for interpreting it now this
is important because i'm going to show
you in the live demo both the temporal
view the tpn view of the plan as it
proceeds left to right but i'll also
show you this htn or hierarchical view
of how things are moving forward so with
that let me just show you the the this
this other screen where I'm going to
start to set this up a little bit first
of all one of the things that we did is
we wanted to make a sort of a friendly
command-line interface for people that
might be familiar with IRC commands so
that's the way that that this works I
can simply type in a command and find
out things that are going on I can
interact with the system I can call this
top window the top window I can call the
bottom on the bottom one I can do things
like a private message I can say
are you ready and I can say yes as a
broadcast message sort of like IRC so
wait a minute how's that hat wait a
minute what just happened there there
are two different browsers two different
clients so it's yes it's a traditional
chat application the difference is that
they're not just connected in the plan
Wiz server but that plan dress server is
sitting on a rabbit and Q network and
the reason that we did that is when we
have mission execution engines and
dispatchers and quad copter interfaces
we want them all to participate in the
RabbitMQ network and plan bids is going
to visualize that and we actually have a
demo of what that's going to look like
before i get into that let me just quick
show you the view of having now i'm
showing the TP on the top and bottom and
the reason i wanted to do this is I want
to show you this this thing that we've
got which is car automatic mode or
collaborative mode the idea is you know
about pair programming you have people
that are looking at the the same thing
maybe they're working remotely wouldn't
it be nice if you could do that for
visual things so if I'm I'm just trust
me i'm clicking in the top window i'm
going to pan and zoom in the top window
and look what happens in the bottom
window the remote user is seeing exactly
what i see and it's tracking exactly
what I'm doing so that is fun I can also
come in and i showed you highlighting
before but let me show you this now if i
have the the hierarchical view down
below and the temporal view let's say i
want to see what this first block looks
like i'm going to click on it here in
the htn view and look in the tpn view
it's highlighted i get yellow
highlighter that shows me what is what
is this block mean when it's actually
expanded in the temporal plan and going
vice versa I could click on one of these
activities I could say well what is what
have you know which one is this this one
interpretation thing and it highlights
it for me in the htn so i can see the
correspondence between those two so
that's that's part of our multi user
of experience where we can have multiple
people collaborating on these plans and
viewing different parts of them just
briefly I want to show you a actual
quadcopter video and i'm going to have
Paul Walker's through this it's very
short tell us what's happening Paul you
can see the quad you can see the
quadcopter up in the top left it's
flying between the waypoints that I
described in the program before what's
happening is it's trying to reason about
what's in the image to use the best
algorithms for interpreting it to deal
with with difficult environments it's
it's it's taking images it's thinking
about what algorithms would work best
given what it's got and it's moving on
to the next Waypoint and doing more more
reason than you can see matches that
it's making down in the bottom right and
that this is video captured from from a
live run eventually will have a much
longer version that in boo involves the
changing of the tire but for the moment
sir that's a now we can see a simulation
of the same thing running on the system
so i'm going to leave the quadcopter
video running here in the lower right
and i'm actually going to run a
simulated mission dispatching it over
the RabbitMQ network and plan vis is
going to show us this plan as it
executes both in the htn and the tpn of
course this is going to work the first
time I should point out that the video
is not in any way synchronized with the
run it's just that but you could imagine
at stake you amuse so so what's
happening here is you see the nodes and
the tpn are highlighting as we move from
left to right on and I can actually oops
I didn't want to do that something had
to happen it's a demo so I wanted to
zoom in here as this is you can see the
colors changing what i'm doing is i'm
taking the state that's coming over
RabbitMQ and I'm mutating that within
plan vis and using just CSS to color
these things nothing could be easier and
it's so much fun what's happening the
htn is when nodes start they turned blue
and as soon as there can
included they turn green and when all
the children are green then fund the
note above it turns green and then when
we get to the end of the plan that means
the last thing is done the root node
will turn green yay and so now our plan
is complete and we've done we've done
the planet we've understood it from top
to bottom left to right and with that
let me end by saying we probably don't
have any extra time for QA maybe just a
brief one but I wanted to call your
attention to the fact we have an
unsession tonight at eight-thirty next
door in ABC and we'd love to go into
more detail and show off you know
development environment having a
connected browser rebel and a server up
at the same time how much fun is that so
with that is already are there any quick
questions okay well great thank you so
much and hope to see you tonight at our
own session</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>