<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Onyx: Distributed Computing for Clojure - Michael Drogalis | Coder Coacher - Coaching Coders</title><meta content="Onyx: Distributed Computing for Clojure - Michael Drogalis - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Onyx: Distributed Computing for Clojure - Michael Drogalis</b></h2><h5 class="post__date">2015-11-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YlfA8hFs2HY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everyone thanks for having me today
we're gonna be talking about onyx which
is the new distributed data processing
platform for closure my name is Michael
realice and I created onyx I started
this project about two years ago during
the day I'm a developer and bias at the
company that designs geosynchronous
satellites I also recently co-founded a
company named distributed masonry whose
responsibility is to officially look
after the growth and support of the onyx
platform lately the focus of my career
has been around building distributed
systems and commercial analytics
products these two things are very dear
to my heart and I wanted to do this
project to lay a better foundation for
the kinds of systems that I've been
encountering lately if you're less
familiar with distributed systems and
analytics in general the workloads for
these kinds of tasks often come in two
different flavors batching streaming and
these problems are in fact nothing new
that state of processing for example
takes a static bounded immutable set of
data and applies a series of pure
transformations and produce produces a
series of immutable output views based
on the original corpus and presumably
you would do this because you have some
aggregation or indexing to do for
example and the trick is that presumably
you have so much data that you've
exceeded the capacity of a single
machine in terms of storage or compute
power and so you need to parallelize
your operations over a cluster of
machines and we're actually pretty good
at doing this efficiently at scale in
terms of the mechanics because we've
been doing it for so long on the other
hand streaming workloads are a much
trickier thing to deal with instead of
having a bounded data set you receive
pieces of your data at little bits at a
time think of a series of tweets or a
stream of network packets they have no
theoretical end and they may be infinite
so you never get to look at the whole
data set at one shot and and the thing
that makes it hard is that your
computations now effectively have to
become a stateful if you're going to
maintain these same views again because
you can only see little pieces of data
you can't do a peer a functional
transformation over them and so there
are things in streaming that are
inherently difficult they're not
incidentally complex we didn't shoot
ourselves in the foot or
now we're kind of nursing it back to
health there are things like dealing
with idempotency and atomic state
updates and stream disorder which is
like when pieces of your data come in
out of disjoint logical order and
stragglers and pieces of your data come
in very very late and these things are
hard so I'll let you in on a little
secret if you're not familiar with
distributed systems and I don't really
know what the politically correct way to
say this is but as far as building
distributed systems as an industry we're
not not very good at it at all actually
because the amount of intellectual rigor
to do the same amount of work is in a
local runtime is much higher that
doesn't mean you need to be any smarter
to do it it just means it's gonna take
more time and effort to do roughly the
same amount of work because the thing is
we try to go and build little
distributed elements alongside of our
applications because we reach and we
need to keep moving so when you tell me
that you implemented your own heartbeat
mechanism to serve fault tolerance see
on your mobile application I know that
your distributed system that you rolled
from hand and didn't look at algorithms
or the literature really looks like this
under the hood there's there's no way
you got it right I mean I've worked on
teams that have implemented their own
leader election protocols and someone
was on call at 2:00 in the morning when
the algorithm elected like 16 leaders
and someone needed to go fix that it's
just it's crazy what's out there so I
built onyx to have a set of distributed
primitives that could reliably reach you
with a high degree of confidence that
was going to work I didn't want to reach
all I'm trying to do my application
level work so we focused on the
distributed elements here so if I was
gonna give you the 60 second elevator
pitch about what onyx is I would tell
you that is a scalable distributed fault
tolerant high performance data
processing platform that is able to
handle both batch and streaming
workloads through a hybrid interface
with a technique known as punctuated
streams its architecture is almost
entirely unique in this space and that
it's coordinated through a machinist
protocol with a custom network overlay
for fault detection it's written purely
enclosure in a relatively slim 6,000
lines
and as a result the programs that you
write on top of onyx are very idiomatic
closure programs but finally the result
of the sole reason for onyx is existence
is to in advance an idea I had to
divorce the traditional model of
distributed execution and I wanted to
split it into two pieces a set of
behaviors and a specification of
execution for it to do with those
behaviors and everything else that I've
done with this platform is secondary to
this goal I'll spend the rest of the
talk discussing why this is important
and how you actually leverage it so
engineers I guess I have basically been
at it for decades making tons of
frameworks to try and make it easier to
process data at scale with a variety of
interfaces api's consistency guarantees
how many of you you in here have used
one of these before something similar
yeah a lot of you right it's it's
getting really common now so if you're
gonna do something new in this space you
have to you have to pass what's called
the sowhat test because you're gonna get
burned by another project that has more
time more money or more people just a
lot of competition here and I've used a
fair number of the frameworks on this
slide or at least I studied them while I
was designing onyx and I'll assert that
virtually all of them are suffering from
a critical flaw that's making
development tougher in the face of
increasingly difficult requirements from
the analytic space and it's this
insidious problem that revolves around
our basic understanding about how we're
building these kinds of systems in the
first place and that is a relatively big
claim to make so I want to move from the
abstract back in an example that's more
concrete so this is a pretty typical
slice of a program that you would deploy
to a cluster if you were writing a
distributed system and this happens to
be a patchy storm which is a streaming
framework for java and closure and the
idea is that you sit down into your
editor and you write your program and
you specify what the steps of your
computation are what the actual
computation is how its wired together
what the fields of the data look like
and your serialization policies you
specify the whole nine yards in this
program and and there's the idea is that
you have the illusion and the
abstraction that everything feels local
to your language because you're
programming against storms API
the moment when you finish articulating
these details you sit down in a terminal
and you compile your program and for us
enclosure that means you make an uber
jar you take your program which is now a
binary artifact and you pass it to
storms main coordination node known as
Nimbus and Nimbus will orchestrate the
transfer of your artifact to the worker
machines and when it lands on those
machines your program is off and running
as storm is able to hook into it and I'm
not picking on storm during this talk
this is a very stereotypical workflow
with how you would use these kinds of
systems you work in an editor you can
pile you deploy and so the question I
had when I was exploring and
conceptualizing what Onix could be was
what happens when the amount of
information you know about your program
progresses towards zero at compilation
time and what does that mean and why is
that important and what I discovered was
that there's this revelation that we
hurt when we relentlessly cling to code
and we have an absence of data which is
very contrary to the way that we work in
Lisp look at that code again from the
previous slide but you'll see some
amount of data structures but it's used
in a utilitarian sense it's not part of
you know the philosophical design of
that API so I started to look at things
differently and I wanted to see how do
you pull this apart and so in onyx this
is how it happens to work instead of
having a program with everything in it
we slim it down and you have an uber jar
with just a collection of behaviors
they're just functions really they don't
do anything they just wait to be invoked
and via some arbitrary deployment
mechanism we deploy it to the cluster
and your program will land on these
machines and once they're there up
theirs they're often running and still
nothing is happening because you just
you have idle behavior no one's no one's
actually invoking it this is the code
piece at a later point in time you
fabricate what is known as the execution
specification I kind of made up this
term for this talk because it fits the
theme really well but if you actually go
into onyx parlance this is called the
job so this is what you actually do with
those behaviors and this is the data
piece it's heavily divorced via a more
specific deployment mechanism we deploy
that onto the target boxes and once it's
off on the machine
they kind of find each other and then
your program is often running and so
there's this critical gap in time
between these two things I've found each
other and it ends up that that is a very
critical leverage and it's the key for
simplification for doing more advanced
analytics all right so here's the deal
most of us here have built careers at a
manipulating data in its essential form
we have techniques for extracting
petabytes of data from remote storage
rolling it up and turning it into single
screen executive summaries why is it
that when it comes to this specific area
in software engineering we throw away
our data-driven mindsets I think it's
fascinating that we've elevated
programming language to the singular
mechanism by which we now capture
computation and the API is used in
existence for today are in my opinion
superficially different they're
essentially all the same and they will
continue to manufacture our own design
problems as long as we continue to do
that but what's more criminal are the
trade-offs that we make in the process
because we frequently find ourselves
trading away simplicity for flexibility
these two attributes are not competing
and it's a shame that we being
implicitly trained to think that they
are by doing it again and again we used
overstretched language abstractions that
turn application designs into prisons
and it will basically remain here until
we have more conceptual independence
upon the things that we're building but
on top of all this we're an easily
hypnotized Bunch when we see a repple or
an ultra succinct api we get distracted
in this apparently never-ending quest
for more concision and I'm not saying
that any of those things are bad but we
need to be cognizant of what we're
building on top of otherwise it's gonna
hurt in the next five years because
requirements only ever get more
difficult and here's the thing what's
obviously happened in the last decade is
that the price of computing Hardware has
dropped drastically but what's more
subtle is that the cost of actually
writing these distributed applications
has also dropped because the skills
needed to do so have become
significantly more mainstream but what a
skyrocketed on the other hand is the
cost of understanding and debugging the
things we build at scale and at higher
degrees of complexity and this is a
systemic failure of the way we've grown
our own infrastructure and so on exceeds
to be the most economical option when it
comes to this last
I wasn't interested in building the most
raw high performance framework and I
wasn't even interested in building
something where the application
developer can get up something running
faster than anything else
those weren't important to me at the
moment the ability to reason is
paramount to me because you can always
go back and redesign under the hood to
get higher performance
you cannot bolt on an ability to reason
better about your abstractions and and
so I really couldn't have come up with a
better picture - as an analogy for how I
feel about distributed computation right
now this not is so visually appealing
it's very nice to look at all these
strands moving in different directions
and in my analogy these are features
they don't overlap they kind of compose
if you can think about moving the knots
around but there's that knot in the
center that represents the programming
language because if you yank on any one
of their strands everything else must
come with it and if you yank on all the
strands at the same time you can't move
anywhere because you're bound at the
center inside the language and so I had
all these thoughts kind of brewing in my
head and last two years while building
this and the underlying theme was always
the same and it's that dynamism
necessitates distance if you want to
build something that's truly dynamic
that's ignorant about its own details at
its incarnation and that is resilient to
runtime decision-making you must put
distance between that thing in its
target environment and we have the
ultimate tool for doing that in closure
data structures data structures are
awesome they put distance in time they
put distance in space there's a whole
host of properties that do this and so
to that end we're gonna spend most of
the talk discussing onix's core api
which is fully information driven that
is to say there are no functions in
onix's core API it's just a pure data
structure approach that passes data
structures from process to process and
we're gonna look at it from five angles
these correspond to five features and
how we move things from the programming
space into the information space and so
the first thing we're going to look at
is structure and this is perhaps the
most obvious thing we can take apart but
it's interesting how rarely we actually
do it and the idea is that we like to
conceive of our
programs as directed acyclic graphs
where the roots of the graph are inputs
the leaves of the graph are outputs and
nodes in the middle are transformations
to be applied with the edges denoting
where data it can flow between now this
is almost universally a good idea for
what we've been doing so far because we
have the formal logic of graph theory to
aid our understanding as these things
get bigger and more complex many
frameworks do you purportedly offer this
abstraction we take this SPARC code for
example I just pick this off the website
we're just reading in some text doing
some filtering and then counting what we
found and if you read this code you can
clearly see that there's direction in
where the data is flowing and anomie or
five lines of code it doesn't it seems
like a curiosity that you have to read
the program and know what it's doing to
understand the actual direction of where
data flows but as these programs get
bigger and more complex or more more
insidiously
assembled by other programs your ability
to understand where data is flowing is
really really important to getting this
stuff right so interestingly enough
sparks sort of does give you directional
navigation and that you can ask any one
of these objects that you get back for
its successors or its predecessors the
problem is that you can't get an atomic
snapshot of the structure all at once
and so you because you can't do that you
you incur all the problems of
concurrency and being able to see the
same thing at the same time and
additionally it gives you its answer in
terms of RDD which stands for sparks
resilient distributed data set I believe
so it's a foreign abstraction and so my
tools for working on actual directed
acyclic graphs know nothing about RDD so
code reuse just takes a huge hit so
rather than having something that is
implied and is in a foreign interface
life takes a very different approach you
submit something known as the work flow
along as your X with your execution
specification to explicitly and
declaratively denote the flow of data
and so the idea is that you have pairs
of keywords in a vector a vector than to
note logical stages of work and you
enumerate all the edges in your graph so
now this isn't implied anymore it's
explicitly stated and secondly there
there's no boundary between my tools
that work
graphs like Stewart's here in dependency
I use that a lot and this it just worked
I didn't have to do anything extra
because there wasn't a like an interface
that I designed in between these two
things so I got both of those things
back now
something weird starts to happen when
you've isolated direction in your
programs so I rolled up because you've
abdicated your ability to use the
programming language constructs to piece
to piece your program together and
people get weary of this but it's just
something kind of to get over and you
know tolerate for a little while so we
need to back off for a minute and talk
about how we connect behavior back to
actual structure if we look at that same
bolt that we were looking at again in
storms model the bolt is the basic unit
for behavioral abstraction there's a few
things going on here so I wrote some
code in production about a year ago and
I picked this off and change the names
customs for a client so there's any
syntax errors sorry about that but the
idea is the same and if we take it apart
we see storms closure API gives you a
macro deaf bolt which you declare your
structure with and sort of gives you
this function feeling thing kind of but
there's all there's this other stuff
going on here right so I was basically
trying to stick a piece of data in a
database that was that was the goal of
this bolt for storm but as it turns out
all this other stuff has to come along
with it right in here for example
there's this prepare phase where I'm
setting up some stuff for my computation
there's air handling there's failure
policy
I had to bootstrap a database connection
and that's fine I needed all those
things it's really important but the
problem is that it all comes right here
because storms API is so coarse that I
had nowhere else to put it
it essentially belongs here so I wanted
to bring this back again and take it
apart and pull it back to its more
essential pieces so we have I sweat when
I see abstractions on top of functions
for these kinds of frameworks we have
this awesome thing in closure I don't
know if you know about it it's called
the function and it moves and moves data
from A to B right so we it more
importantly functions and onyx are
playing closure functions that take data
Maps and return Maps
or sequences of maps and there was
nothing about onyx this is a really nice
property and so I've slimmed this back
at the expense of moving all that stuff
out and deleting it off the slide it was
so easy but we'll talk about how we get
all that stuff back later but you can
you can further parameterize these
functions but the fact that they're
plain functions is really win for repple
testing already now we need to connect
these actual functions to positions in
the workflow so this is the second
construct known as the catalog each
entry in the catalog is called a task
which is going to denote a logical stage
of work to be executed the first key
onyx slash a name is going to going to
denote the place in the workflow where
it connects to and this other key second
one
onyx slash FM is a keyword representing
a fully qualified namespaced function
this is an idiom I use pretty heavily
where you can you can name your
functions as a keyword and then at
runtime we actually strip away the
keyword and then resolve the actual
symbol on your class path so it's part
of your your set of behaviors we go when
we look this up at runtime as your
program gets larger you'll build up a
full catalog which is a sequence of task
specifications and it's a major point of
leverage because here you can
parameterize each task with functional
shape functional changes tune
performance knobs document usage and the
list really goes on but more importantly
no particular function in its behavioral
scope is tied to any specific set of
parameters so you can tune this on a
task by task basis okay the third thing
we're gonna pull off from the language
is side-effects or at least the
application of the side-effects so
you're programming along and all of a
sudden you need to connect to a database
and your beautiful little design is
ruined because there is no where to do
it and you pull in dynamic scope or
something like that experience this too
many times
so coming back to the same example again
our saying I had to bootstrap a database
connection and the way you do that with
storms closure API is via this prepare
statement and what this lets you do in
effect is build a lexical closure around
an inner bolt that fourth line storm
slash bolt that's where the actual kind
of functional piece is taking place but
the things above that like that
inside the let are executed exactly once
so you can set some stuff up and then
pass it down to yourself and you don't
have to like connect to the database
every time because that would be really
really bad
so here I've drafted database connection
there's there's two problems with this
so the first one is that in terms of
modularity I had to actually do the
footwork to set my stuff up inside this
macro itself so composability and being
able to reuse these these side effects
across pieces of my application was
really difficult
further having extra configuration that
is runtime discoverable is difficult
because if you want to have more
configuration than you have at that
point in the let block you need to reach
up into the global context and this just
shattered my program I couldn't think of
a way to do this without having some
kind of dynamic scope that was
problematic and I tried to have a lot of
sympathy for the application developer
here because it feels kind of bad when
this is considered cuz this is really in
the trenches stuff you don't think about
the stuff until you're building your app
so the construct in onyx that
facilitates creation and destruction of
state are called life cycles and I'll
depict it visually before we get going
into code so what I'm moving left to
right we think of the tasks in the
center as being the functional
transformation data goes in data comes
out with new values there are various
points in time when you're going to want
to do stuff you're going to want to
execute code add values you do something
very specific points in time for
instance before your task begins after
it ends and before and after every batch
of segments that you see which is like a
segment by segment view basis and you
can you can hook into these things as
many times as you want I happen to
balance these things but you do I know
me is need to have all of them or any
balanced amount so the idea is that at
the before task stage you're given a
context map which we frequently call
event which contains a number of useful
keys about what what current computation
is running at every stage in your life
cycle you're given this event
and you're allowed to add remove or
modify keys when you do that the map is
durably sent or persistently sent
downstream so you get get the last thing
that you you actually you updated so you
can pass values to yourself and so you
start on the left and then you move
towards towards the right and you kind
of cycle as you have more segments just
rotating back and forth between before
and after batch and eventually you
finish out if your computation is one
that has completion semantics so in
terms of code we'll look at this first
this is this is like half behavior half
half execution specification because
it's very side effect you were doing
things so I want to do two things I want
to log a batch of segments and I want to
inject a de Tomic connection in both
these cases they're just plain closure
functions that take two parameters
looking at the log batch function first
we take the context nap or the event nap
is the first parameter and in our and
our function we we peek into it and we
look for this results key which is like
kind of a predefined thing you can find
in the documentation what that stuff
means and then we iterate through it and
do our logging and we return an empty
map because there's nothing to really
merge back in it was just a pure
side-effect that's kind of a pun so in
the second case if I want to inject a
connection like a database connection at
the start I'm again gonna peek into that
task map and there peek into the event
map and grab the task map that is
currently executing on this machine
again I'm gonna key into it and pick out
des Tomic slash URI so this is something
that would be in your catalog presumably
I'll connect to the database and then
I'll return it as a key in the map which
is merged back into the main map so then
I can use it downstream however it
however I want so I have the behavior
but I didn't say when it runs so that's
where this third symbol is inject hooks
so again these are predefined keys that
you find in the documentation what they
mean and how you use them though then
you you bind them to actual closure
functions so this is a symbol I haven't
done anything fancy here it's still just
all all regular closure so that's the
behavioral piece now the information
piece is this is how we kind of move
things out of the language
to degree that you can of interest you
say what tasks these are gonna run for
and you also track the symbol my NS /
inject hooks so now we resolve this part
at runtime in order to execute your
behaviors so this ended up being a
particularly powerful abstraction offer
when you consider that you can
arbitrarily chain as many of these life
cycles together as you want and change
their order of execution as part of your
specification which gives you fantastic
modularity for side effects across
projects but it's particularly adept at
letting you intercept the event map from
like a third-party third-party lifecycle
I like changing it a little bit to suit
your application or do some debugging
because something went wrong few of the
implementations could do with this
fluidly because they're usually based on
inheritance and everyone here knows the
caveats of that again next part we're
gonna talk about is flow and this is
interesting because it's often not a
first-class thing in a lot of frameworks
and so you're in you know in terms of
the work flow you're denoting all
possible paths that data can flow
through but it's not always the case
that all pieces of data should float to
all downstream tasks it's a runtime
decision whether you want to do that or
not so if you're at a part of your sub
graph function one and you have a piece
of data do you want to admit it two
functions two three and four how about
functions just just two and four or
maybe only function three or none of
them I don't know it's it's a runtime
decision right so instead of having a
cond just buried in your program or some
like I think dupes abstraction is output
collector or something it's a little
it's a little thanks yeah it's a little
random it's kind of pops in your program
so instead of that this is a more
compositional approach known as flow
conditions so now you have a vector of
maps where every entry denotes where
data comes from where it may go to and
when it may go there be a predicate and
those predicates are again same theme a
key worded function those functions are
playing closure functions that take at
least four parameters but the the two
interesting wants to call out are
fact that it takes an old and a new
segment so this is before and after we
applied the transformation so you get
this before and after.look which is very
handy flow conditions also ofter offer a
basic pattern matcher runtime
parameterization logical composition
with an or not support for exception
handling and automatic message retry it
got quite sophisticated from how I
initially designed it but I'm happy that
all those things came out with it
because the things that you can compose
and Express are very pleasant when you
do it at this level other than just
bearing it inside the program okay the
last thing I'm going to talk about for
the API is process and this is how we
accrete state over time because many
streaming computations end up actually
being stateful so this is all the new
stuff in the 0.8 release that came out
last week and we did a really heavy
amount of research with how best to do
this and adapted pretty much all of our
solutions straight from the literature
or industrial proven solutions onyx
offers a feature now known as Windows
along with a companion feature known as
triggers the windows are a notion for
denoting scopes and time in which pieces
of your data fall into and specific
instances of Windows known as extents
track that data in a running compounded
aggregate the gold standard for
windowing implementations is being able
to bucket based on features of the data
itself this enables really sophisticated
kinds of analytics and really happy to
say we were able to pull that off
but there are different kinds of windows
that you're going to want to do for
example you might want to have fixed
windows so fixed windows have a specific
range and they do not overlap so you can
think of those markers at the top as
time periods and the effect is that
pieces of your data fall into exactly
one window so they're good for queries
like give me the total number of clicks
per page per hour but we support
different kinds of windows as well a
more sophisticated one is the sliding
window so again they have a fixed range
but they can overlap by some amount
meaning that pieces of your data can
fall into multiple windows and so then
you can answer questions like how many
users signed up for my website in the
last 60 minutes reporting every five
minutes you always have a 60 minute view
but you get an update every five minutes
I don't have time to go in-depth but for
anyone who's familiar in the room with
these kinds of things we also support
global and session Windows Global
Windows span all time for cases where
type the time isn't really a relevant
factor for your aggregation and session
windows are very expressive thing that
lets you dynamically grow the bounds of
your window based on tracking a specific
entity such as like a user on your
website and then didn't know where the
session ended so as you see more data
you can continually grow our API for
Windows and triggers as heavily derived
from a recent paper at the very large
databases conference by Google with
their dataflow paper and on other pieces
of the implementation are taken directly
out of research from the University of
Portland so it's awesome when people do
things in academia and you like read the
papers and then you implement it and it
works it's it's fantastic you should
definitely give it a shot so the API for
doing this is is another mostly pure
data thing for every task that you want
to be stateful you have one or more
windows over that task that point you
know where the task is and then for each
of your windows you have one or more
triggers windows are going to accrete
the data triggers are stimuli that
actually do something with that data so
if we pick this apart a little bit
this first window is an aggregation
we're gonna look for the minimum age key
in all the incoming pieces of data that
we see this is going to be a sliding
window of range one hour that slides
every 30 minutes and we're actually
gonna look inside the data that's coming
in and pick out this event key and
that's what we're gonna use to window
the data on we're not doing it based on
processing time like wall clock my time
time of the specific machine that's
doing it because that doesn't let you
handle stragglers and stream disorder
this is the really critical thing to be
able to handle that gracefully so as
your window is accreting data eventually
you're going to want to do something
with it this is where a trigger comes
into play this specific trigger will
fire every 500 segments that you see and
it will call a user-defined function for
you for example we'll just like sync it
to dynamo or something after your
trigger fires you might want to do
something with the contents of
that window in this case I'm just gonna
discard it and say back to back to your
regular state I could accumulate state
over time and simulate something that's
like more progressively accurate answers
if that makes sense for your your target
application we also support timers
punctuation x' watermarks and percentile
watermarks as triggers so there's a lot
of out-of-the-box stuff that you can put
together to have a really powerful story
for moving data on demand and the trick
that we're pulling behind the scenes
here is that we've taken care of the
item potency problem for you because
normally when you're doing aggregation
in distributed system you need to be
aware of not like double counting pieces
of data in the event of maybe like a
transient network partition or something
like that and the short story with how
this works is that we we took a really
similar approach to Sansa and that
updates are serially striped to a log
abstraction which we're using bookkeeper
and that we use rocks DB and Betty key
value store with an in-memory bloom
filter inside of rocks TV to detect
duplicates as they come in but that's
really all I can say about that for now
if you want to know how it works more
come find me after I'm happy to explain
and so that is how you move things out
from the language and into the data
space and by doing so you harness much
more power to have more dynamic
analytics I wanted to spend the rest of
this talk catching you up on what the
state of onyx is and what the ecosystem
around it looks like so it can process
data pretty well but you have to
actually talk to things and then write
to things so the cop got in the atomic
support is really good we focused on
that a lot sequel and Redis support is
pretty okay as well less battle-tested
for development you can use core async
to send data in and out of onyx
orderable q we're just an arbitrary lazy
seek and because everything is
predicated on the catalog for what to do
the ability to switch between any one of
these mediums is is pretty thin as far
as using this like a full stack approach
with closure with onyx stay tonic and
home it's really sweet it's not like we
just ran a full Ruby stack and we share
an operational environment that's really
nice but these these three specific
pieces of software three different
designers with the same taste granted
two of them kind of derive
from the first but but the idea is that
you're not just sharing an operational
environment the the philosophy up and
down the stack is really the same and so
it makes for a very pleasant experience
this is totally not a toy I did not hack
this up in a weekend about two years of
pretty intense engineering effort and
while I said earlier I didn't do this to
have like that most high-performance
thing performance still is really really
important to me so it's easy
le's easily able to handle industrial
levels of load and into the millions of
messages per second without much of a
big deal and as far as I can tell it
scales linearly at least I ran out of
money benchmarking it's like I can only
tell who the certain point to give you a
sense for the areas that that onyx is
covering at the bottom everything that
everything is being held up by a
streaming engine essentially even the
batch computation mechanics there's
there's a involved local you know
locally threaded environment sort of
like an IPC thing to have efficient
execution on the box as well as the
coordination primitives for doing fault
detection over that is is the
information model which we pretty much
discussed at length today as well as
being able to do side-effects and
accumulate state specifically the
scheduler for onyx is another tricky
piece that requires a lot of time and
it's not as easy as just like throwing
mezzos at it because there are very
specific things that onyx needs to be
able to understand when to allocate
resources and I haven't really found a
good fit for doing that yet so this is
another time consuming piece if anyone's
really good at these things I could
totally use some help over that is a
dashboard for seeing the state of your
cluster and what jobs are executing as
well as metrics and monitoring to get
very fine-grained details about the
health of your cluster at any given time
there's also deployment infrastructure
so ansible for setting all the stuff up
but the thing that I really want to
stress is that there's tremendous
opportunity for compilers what we
discussed today was fully information
driven and moreover it's documented in a
CL JC Eden file which we try very hard
not to change and keep it stable so
there's opportunity to write compilers
from custom api's to these data
structures to execute on onyx natively
and we can do things like you know stack
the analyze closure data log or even
sequel or a continuous query language
and you don't need to coordinate with me
at all because there's a published
information model with how you compile
from A to B and well always try to keep
it that way
so I I don't want to say that onyx is
like super battle-tested because it's
not and we still find bugs and stuff but
people run this in production now and
some some companies run this as really
the backbone of their data processor so
that's really awesome and I'm thankful
people who trust me for doing that
finally I just wanted to say a huge
thank you there are so many people that
I could thank for helping push the
platform to this point but the one that
I really wanted to thank was Lucas
Bradstreet I met Lucas about a year and
a half was doing some consulting for him
and he saw what I was doing with onyx
and he started helping out sending poor
requests and eventually he ended up he's
still working with me on this full-time
for the last year and to have someone
kind of take interest in your project is
really awesome and I hope everyone in
this room if you have not yet eventually
gets to feel what that's like because
it's great but to have someone drop
everything that they're doing when I had
no money to give and no opportunity to
speak of and want to wake up every day
and build this over and over and over
again is just beyond the most awesome
thing ever he couldn't be here today I
know he really wanted to be but thank
you so much Lucas there's no way it
wants to be as nice as it is without him
so send him a tweet and say thank you if
you liked what you saw we have a website
as well as get help of organization so
you can kind of see pretty much
everything come talk to us and get er a
slack we're pretty responsive in there
and if you want to get up to speed
really quickly there's a self-guided
workshop that you can you know do some
training in and understand the basic
parts that more fine-grained details as
well as the lining in application
templates that can get you have to see
with idioms really quickly that is all I
have thank you so much for listening
thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>