<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Using spec to Transparently Replace a Legacy System - Daniel Solano Gómez | Coder Coacher - Coaching Coders</title><meta content="Using spec to Transparently Replace a Legacy System - Daniel Solano Gómez - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Using spec to Transparently Replace a Legacy System - Daniel Solano Gómez</b></h2><h5 class="post__date">2017-03-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vTw7mWtaGw4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm a developer at outpaced systems and
we are a relatively small company
we're a distributed fully remote company
you know we're all based in the US we
are a closure shop so we use closure on
our back end and for the front end we
use closure script and our main product
is what we call the targeting engine and
to explain how the targeting engine
works I need to talk a little bit about
our clients so our clients are people
who have a lot of customers
I cannot say who exactly our clients are
due to the confidentiality agreements
but for this particular talk our client
is a very large hospitality chain with
over 4,000 properties over 10 million or
in tens of millions of loyalty members
and for each one of these members I mean
they know a lot about those members both
in terms of things that the member has
told our client like where they live and
also from the behaviors of the client
you know does a client like to stay in
at beach resort so they prefer more like
ski resorts or something like that so
they have all this information about
their customers and they also have a lot
of offers that might be of interest to
those customers so these are going to be
things like you know stay two nights get
the third night free or you know earn
bonus points towards the rewards program
maybe a spa credit and and we have lots
of these like for currently active we
have over 10,000 of these for this
customer or for our client and so what
the target engine tries to do is at a
given time you know for for you know
they know they want to present some
offers to their to their customer and we
need we help them find out what is the
you know the most relevant offers for
that customer and in some cases we don't
know anything about the the customer
because it's an anonymous user in which
case we just try to get them
you know the best-performing content so
we integrate into lots of different
channels we have JavaScript that we
published that is included in our in our
clients website to inject a the content
directly into their website we have a
user interface that our client can use
to do batch processing for example for
an email campaign and we also have API
is that our client can call directly for
things like their mobile app and for
booking abandoned which is the the flow
that I'll be talking about today
so booking abandon is a common pattern
where you have a user that goes into a
website and starts doing something no in
this case starts booking a hotel room
but for whatever reason the user leaves
and at some point later the client
notices that you know there's is this
booking that was started but for
whatever reason was never and was never
completed so they send us that
information about that booking you know
the user ID and you know which hotel and
you know which dates if you know if they
have that data and we tell them well you
know based on the information you've
given us your you know your customer
might be interested in these offers at
which point the client will then create
an email that they send to their
customer which will hopefully result in
the customer saying oh yeah I might be
interested in this offer and they they
sign up you know that may or may not
happen on the problem that we have is
that our targeting engine was not what
was being used we originally developed
you know the first iteration of our
targeting engine was crafted really for
this client and was not suitable to be
reused as a product and so over time we
rewrote it and now we want to transfer
this flow from using the old product to
the new product and we want to do it in
such a way so that we have zero impact
on our client no downtime no code
changes on their ass from their side and
so how do we do that
and the way the approach that we decided
to do is treat the existing code base as
like a black box you know so we just
want to see how the current system
behaves without really going into how it
actually does what it does so things
like unit tests and all that you know
don't really apply in this in this
scenario so I want to answer you know
five questions you know the first two
are about you know the existing system
you know what kind of input does it get
and given those inputs what kind of
responses do you again once you know
that then you can look at the new system
and ask well does this new system you
know accept those inputs and produce
outputs that are similar and finally I
mean even if everything is the right
shape in the right type you have to ask
well is it actually correct are we
getting the real result so let's see how
we can answer these five questions the
first step is dealing with the input so
the inputs in this case you know we're
dealing with a REST API so it's things
like you know the HTTP method query
parameters headers body you want to you
know can I classify all these different
inputs what kind of values do they have
and are there any patterns in the
requests that you know you need to be
aware of or you'd like to exploit and
there's all sorts of different ways that
you can get that data you can get it
from access logs you can use like a
network sniffer to get that stuff off
the network or you know if all else
fails you can we just put a proxy in
between you know the client and your old
system so that way you can see fully
what's going on now in our case we're
dealing with gets so it was very simple
to just pull down engine X access logs
off our servers and work with that so we
started with like taking
a few days worth of access logs and you
know using just standard command-line
tools like grep to to kind of filter out
just the request so we're interested in
replacing and then you know once we load
that into file we can use closure to
convert those you know lines of log into
into just a map of information about the
request so like in this example here you
know we can ignore the the path but you
know we take that 42 part of the path
and it becomes the user ID and then the
rest of the query parameters or pretty
much just pasted in we don't do anything
special yet so at this point now we have
like this large collection of input data
and now we need to figure out well you
know what is all this what are you know
what are all these different data types
what do they mean and this is a part
where spec starts coming in essentially
you start specifying you know all of
these all these inputs to see you know
what are the types you know what Keys
are present you know you might want to
consider when you're doing this to do a
lot more parsing than you would normally
would say if you're specifying the input
to a function so you might not just
verify that something is like a string
of digits but you might want to you know
parse it into natural integer and see if
it's positive or negative or whatnot
another thing that you normally wouldn't
do in a lot of normal spec usage is like
reject unknown keys but in this case
since we're really trying to understand
like a corpus of data you know we want
to be sure that we're not ignoring
anything so what this kind of looks like
in practice is that we have our parsed
entry and you know we will write a spec
that will try to that when you conform
that entry to to that spec you get this
conformed entry so we create you know
kind of regular keywords for for each
one of these inputs and we can even do
some parsing there
so like our user IDs are very very long
so they don't fit too long that's why
it's 42 and it's a big int for things
like num rooms and them adults we can
you know go further and say well these
must be positive
no I'm children must be non-negative so
at this point we should have a pretty
good idea of how our API is being used
and more than that now we have these
specifications that we can use for doing
things like input validation like we can
take these specs and put in put them
into our new system and say you know we
can use this to just validate that the
input that we get is is valid if you
attach generators to these
specifications now you have a way of
just generating inputs for your system
and you can use that for testing so at
this point we've answered like the first
question you know what kind of data does
our you know how is our clients calling
our application are our legacy systems
so the next question is well given it a
given input you know how does the output
look like and and when you're doing this
I mean you want to check not only valid
inputs which hopefully that's what
you're getting most of the time but you
also want to check invalid inputs so
there's a couple of ways again that you
can go around but get around to
collecting this data the simplest way is
to just invoke the endpoint you have you
have a bunch of input data you just
invoke the old system and see what it
does in a case where you know this is
impractical or not possible I mean
you'll have to do something like you
know sniffing the network or proxying
the endpoint to get that data so in our
case we could just you know collect all
that data and and then once you have the
results you know it may contain things
you don't care about like in you know
there's all sorts of headers that you
may not care about there may be
I mean there may be stuff inside the
response that you don't really care
about but in other case what you want to
do is collect all the data and now again
start specifying things so in our
example we just invoked the end point
and you know we have like the map that's
returned from our our HTTP client so
there's things we don't care about like
the options that were passed in with the
request we don't care about headers we
don't really care about what we do care
about is like the status
you know if it's 200 that means that
this is a Nokia response if it's
something else it's some other type of
response and the body now the body is
just a string as we can see a string
contains JSON and what we actually want
to end up doing is when we write the
specs for our output is we actually
parse that JSON into closure data
structures and then we can even do more
beyond that so as we can see that kind
of the conformed result of this response
is that it's an okay response and you
know it has some offers in each offer
just consists of a name so at this point
we have an idea of not only the inputs
to the legacy system but also the shape
of the data that comes back out of it
and again because we've created these
specs now we have specifications that we
can use for example you know we will
definitely use them when we when we test
that our new system conforms to the way
the old system works but say you were
also working on a client for this
particular API well now you have a
generator or sample data that you can
use for testing your client now in our
case we didn't we didn't
you know we didn't write the client we
have nothing to do with the client so we
didn't use it for that so the next two
questions that we need an answer are now
about the new system now that we think
we have a pretty good understanding of
how the old system works we need to see
if the new system works the same way and
we could tell a priori that it doesn't
we know that the new system you know it
doesn't accept certain types of input
parameters and may or may not you know
produce the right output so one of the
tools that we decided to use is Amazon's
API gateway and the API gateway can do a
lot of different things but we're
interested in it primarily for two
purposes it serves as a proxy that can
do transformations of requests and
responses so that allows us to make our
new system behave more like the old
system without actually changing the
code in the old system and as we'll see
you can have towards the end of this
talk we'll see how using API gateway
made deploying from the old system to
the new system very easy to do so an
example of some of the rewriting that
that this can do is you know we have an
input and we want to invoke the our new
endpoint in a certain way so you know we
tell it okay this is where the new
system lives you need to invoke the
endpoint here and you know here's the
old path but we actually want to call
you know this new path and in fact this
42 which is part of the path in the old
system we need to turn it into a user ID
and over here this number of offers to
get well that's just a num in the new
system so this is all really easy to do
in an API gateway an API gateway you can
also rewrite the payload of a request
using a velocity template and we
consider doing this but opted not to
and there are a couple reasons for this
velocity templates that we'd have to
write would be very verbose because like
the responses are very large that we're
sending back and since this was in an
endpoint that was only going to be
called for this one client it was a lot
easier to just change our new system to
return responses that behave like the
old system but if you're in a situation
where that wasn't an object option then
API gateway kind of helps you in that
respect so our new architecture is going
to have you know we have our targeting
engine the new version is sitting behind
the api gateway that's doing the
transformation and now that we've set
this up we can start exercising the new
system using the data in the
specifications that we created before
and so if you wrote your input
specifications so that you can generate
inputs you know you can use that in our
case we had you know tens of thousands
of sample calls that we you know we just
replayed through the new system and
we're able to check that the responses
that we're getting at least conformed to
the specification for the output don't
forget of course again you know errors
are a part of your API and you know you
need to be sure that the error is that
your return also conformed to the old
system so at this point we have two
systems that a sensibly behaved the same
way they accept the same input and they
produce the same sort of output but
there's still the question is is the
output correct
are we actually returning the data that
we need to that we're supposed to be and
you know that's the last of the five
questions that we need to answer so how
do we do that if your endpoint happens
to be a referentially transparent then
this is trivial you just invoke both
endpoints with same with the endpoint
what
both endpoints with the same input and
should have identical output but most
systems are not like that you know they
have some sort of state or something
that that you need to you that affect
the output and fundamentally the
technique is the same you just invoke
both systems with the same input but
then when it comes to considering what
the output is and is the output correct
I mean this really depends on your
particular application again you know
error conditions don't forget about them
so in our case of booking abandoned
there's two parts of it that were you
know that effect of the response is that
the first one is that each one of these
systems maintain a database of the
available offers for each property
secondly there's a client endpoint that
we invoked to find out if particular
offers are available for a given date
additionally I mean there's some things
that naturally varied between the old
system and a new system the algorithms
although they're doing essentially the
same thing or slightly different so you
know rankings of offers might be
slightly different the calculated values
that we produce might be slightly
different but that's fine you know those
are still within you know this is
correct and so the way I ended up doing
this and which was kind of a tedious
process is you know I have a ticket
sampling of input I forget how many it
was I was in the thousands and I invoke
both endpoints and essentially now I
have like this massive data structure
that contains like the input in the
output from each each system and what it
what I ended up doing is just kind of
looking at you know little bits of the
output kind of a little bit at a time
and you're running like closure data
diff to see are these the same if not
you know how are they different are they
different in such a way that you know
one of the systems is wrong or they
different such a way that you know it's
okay so some examples I have out of this
you know might look like you know it's
an exact match
I mean that's trivial you know if you
have a case where there's missing offers
well you know why is that is it that you
know the old system has offers that it
shouldn't have or is it because a new
offer the new system has offers or
doesn't have those offers and it should
so this you know if we run into this
situation we have to go and investigate
well you know what's going on here you
know if something happened like you know
we get the same offer throw in a
different order in that case you know
this is okay you know we don't have to
worry about that in other cases maybe we
have slightly different offers again I
mean this is something we have to look
at know why is this the reason is it
because I offers missing from one of the
two systems or is it simply because well
there's eight offers to choose from and
we're only picking the top two in each
system ranked to them differently so
this is a very tedious process to kind
of go through and make sure all that was
correct but we did find a number of
things this is a very valuable exercise
one of the examples is that some cases
this endpoint was invoked without dates
and there's some slight differences in
how we handle that so we fixed that we
found differences in how the two systems
synched offers we fix that we discover
that the old system had a bug that we
had never discovered up until now that
when the client asks for like French
offers we'd give them English ones
instead so you know that's something
that our new system fixed and that was
nice to see so now that we had gone
through this process we had a very high
degree of certainty that when we made
the switch I mean the it should just be
transparent to our to our client you
know that you know they didn't have to
change any of their code in order to you
know be using our new system so now that
we've answered all our questions and and
have developed a certainty the last bit
of this is to deploy the new system and
so we have you know version one that's
running and we have
version two you're running behind the
API gateway and right now like the the
DNS name that the client is using is
goes directly to the old system so our
first step was to add a new version of
the API in the PI gateway that just
passed things through so once we do that
you know we can check that
you know invoking it through the API
gateway and invoking it directly result
in the exact same thing you know once we
do that we can switch the DNS to good
now go through the API gateway now at
this point you know we're also we all
the only thing that we have to worry
about or is just getting the okay from
the client to make the switch and what
we do it's it's really just like
clicking a couple of buttons in the ad
based console where where we just tell
the API gateway instead of running the
pass through you know running run
through the transforming and that was it
I mean there's no downtime and within
minutes all the requests are now going
to the new system and because we we
spent all this time verifying that the
new system behaves just like the old
system I mean there was no interruptions
in no code changes for our client and
this for us was a big success I mean it
took a few weeks worth of work and at
times you know creating these schemas or
or specs you know was very tedious but I
mean the end result was a complete
success essentially we treated our old
system as a black box that we knew
nothing about except for what goes in
and what comes out and we are able to
replace it with another system that's
completely unrelated completely
different infrastructure and we're able
to do it with that impacting our client
at all well that's not entirely true
I learned that several months later
someone was trying to manually call our
API it's normally only called through a
machine and they were calling with
different parameters that we weren't
expecting and so it failed validation
but
I was still a success so some final
thoughts on this
it just said this was a very useful
experience for us to go through and and
you know we use closure suspect
primarily because I mean that's the
latest greatest thing and we're you know
we're developers and we like to you know
brand new shiny thing but you know you
could still use like climatic schema you
know it has most of the functionality
that you need to be able to do the same
thing and its really nice that after all
of this now you have artifacts that you
can use in your new system for things
like testing and input validation you
know that's a great result to have on
top of you know having been able to do
this this replacement and finally I mean
there's there's room for like exploring
like how you know where can you take
this you know can you you know use this
to document your endpoint in such a way
that the client can you know better make
use of that and I know there's some
efforts out there that that you can take
like a open open API specification and
turn it to a closure spec specification
but I wonder you know it's a possible to
go both ways or whatnot and that's it
thank you very much for your time I
guess</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>