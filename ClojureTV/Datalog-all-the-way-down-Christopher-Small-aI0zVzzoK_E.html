<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Datalog all the way down - Christopher Small | Coder Coacher - Coaching Coders</title><meta content="Datalog all the way down - Christopher Small - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Datalog all the way down - Christopher Small</b></h2><h5 class="post__date">2016-04-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/aI0zVzzoK_E" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning my name is Chris small and
as Alex kindly introduced this is data
log all the way down you can find me on
Twitter and most other places as meta
Soros so if you're just getting in touch
with me that's there and my websites
that meta source home real quick a
couple things I'm a co-founder of polis
we're a startup that makes massive
online conversations make sense with
machine learning and data visualization
and we've been used in Taiwan and Korea
to affect political change and are
currently talking with online newspapers
about replacing the existing message
board system so if that sounds
interesting to you I can check that out
at pol is also I do contracting and
consulting work is thought note software
so if you'd like to get in touch about
anything along those lines about node
comm so this talk is really about how we
can leverage the superpowers of the
atomic enclosure to build more
composable data-driven web applications
and this story starts with one of the
first web applications that I ever built
it was a mostly a rails crud app right
saving viewing data but what was
interesting about it was that I had a
really complex domain model and this led
to a lot of object relational mapping
and user interface challenges but the
other thing it was really interesting
was that there was a sophisticated query
system for traversing this data and so
you know there was some there's some
interesting problems and it was a fun
project and we built something really
cool that solved some very real problems
and recently I started talking with this
company again about doing some extension
on this work and this really involved
coming up with a much more complex data
model there was a capable of much more
flexible relationships but also in every
as a result of this dealing with more
challenging user interface and and query
problems and I wasn't really interested
taking a big rails project at the time
I'm pretty happy working with closure so
we started to think about what it would
be like to write this in closure what I
didn't really expect was that they Tomic
would factor so heavily into a lot of
the decisions we made the atomic has
data log as a query language and that
meant that we'd have a lot more Express
power in our queries and that we'd be
able to compose queries more effectively
because queries are just data and atomic
we also realize that the more flexible
schema from the atomic meant that he's
really flexible dynamic relationships
that this this this company had to deal
with would be much more easily solved in
the system and finally persistence would
be a huge win for accompanied with
concerns about data integrity and
auditability they care about their data
and want to make sure that the data
that's there in the database is the
right data so these were all really
great things but one of the clinchers
was really and perhaps the clincher was
really that with the system we'd be able
to build on top of the Atomics
extensible schema and what that meant is
that we'd be able to build user
interface which helps them manage what
data they track and manage the
relationships between that data and that
this would lead to an ultimately much
more level leverageable system for them
so I would never advise a rewrite
lightly but in this case there were so
many tangible benefits in the scope of
work building on top of what already
existed was so great that I realized
we'd have a vastly simpler and more
powerful system if we did this free
right so we did it and at this point of
course we had to decide what the
architecture was actually going to look
like I mean data they taught knowing
that you have the atomic and closure in
the picture is is really just a pretty
minimal basis so one of the front end
architectural patterns which came to
light recently for me and which I which
which really kind of resonated with me
is the reframe architecture and so
reframe is a micro framework built
around reagent which itself is a reactor
es wrapper and it has this it really
it's just a set of patterns for dealing
with state and reframe sorry reagent
region is very flexible about how you
use state and reframe to sort of kind of
guide you into particular way of doing
things and that particular way of doing
things is to start with a central
message log as your as your central
database for your your front-end which
is which is nice for a lot of reasons it
it makes things like certain testing
situation generative testing a lot
easier
you have you have the ability to go back
back in time and look at what happened
auditability debugging there are a lot
of really nice things that come out of
this but one of the things that's
unfortunate about it is that actually
basing all of your UI decisions on this
this giant log of offense isn't very
efficient if you want to do something
for instance to show the number of
connected users to a system computing
that every time from the log is going to
be a huge mess and the solution to this
problem is to to use reagents reaction
or reactions to compose this sort of
materialized view graph this signal
graph on there are the different
frameworks kind of call this different
things but the basic idea is that excuse
me we have some computation which is
always up to date based on the central
app database and any other further
reactions which it might depend on and
so this starts to look like the concept
of materialized views from the database
world and in particular the architecture
of Apache Samsa which which heavily
inspired reframe and so there are a
number of things that I really liked
about this one is that there was some
conceptual convergence with elm and
redux to very kind of popular directions
or no hopalong as well you know there's
there's there's a bunch inked chaplain
maybe that's a part of hop on but there
are a lot of things that are moving in
this direction and I think that's that's
a sign that there's there's there's a
real pattern here that's that has some
value but but I think what I liked even
more was that it was really thinking
about the user interface as part of a
distributed system these systems have
eventual consistency which is a really
nice property for dealing with with a
lot of the things that we care about and
I couldn't have asked for a better talk
to follow
Michaela's michaelis talk was really
wonderful I think you know I think she's
I think's right like this is the web
development is distributed systems
development and so making sure that
you're actually thinking about that is
is important so it wasn't long before
getting into reframe that that I found
out about data script and I think I
heard about it at some point but just
sort of assumed that it was it wasn't
going to be as impressive as it was
honestly it is an extremely
impressive day Tomic like in-memory
database solution for both closure
script and closure and we have we have
data log queries we have pull
expressions we have transaction reports
and listeners um we have a really
amazing amount of coverage over the the
day Tomic api there's some things that
relax like durability in history that
you kind of there that aren't too
surprising to be missing on on the
client and some things like idents that
aren't that haven't been done yet and
other subtle differences but but all in
all it's a really amazing system and
what I really liked about this idea was
when when we're talking about ohm or
reagent or you know any of these any of
these development frameworks we're often
talking about some central atom as our
app database right well why not make it
an actual database so that you actually
have relations and you know you have all
the things that we'd like from more more
expressive databases so this seemed
really compelling to me but there is a
problem which is how do you connect the
data script database to your user
interface react or sorry reagent kind of
only knows how to work with its own
version of atoms and reactions and
fortunately I found a solution in this
problem there's a library called posh
which which does this kind of connection
work for you but it goes much further
than that it it actually sort of takes
inspiration from the reframe library in
coming up with this architecture
reimagined as reactive data script
queries and this is a simple example of
what this might look like the first
function we have here is a call to juice
and it returns a reaction which we
define using the posh cue function so
posh cue function takes our database
connection and it takes a data log query
and it returns returns this reaction
which is just this again it's this
always up-to-date computation based on
our database state so below in this
reagent component raging components are
just functions which return pickup data
sort of version of of HTML and in here
we we call the seduce function get this
reaction and we dereference it just like
we would some atom
state and region hooks things up so that
anytime this this reaction updates this
component will also update so then you
know we can we can take we take each one
of these one of these to-do items that
we get from this this reaction and
render it and I'll just mention really
quickly you know we don't just have Q
here we also have poll and we're working
on a number of other of other functions
that do things here I say we I should
say Matt Parker has been doing this I've
been thinking with him a lot on it but
so the again one one idea leads to
another it wasn't long before getting
into Data Script and posh that I came
across the web after tomorrow which is
this wonderful blog post by Nikita
Procope ov who's the author of data
script and I think the fundamental point
that he makes quite well is that the
REST API is an anachronism it's a relic
of a bygone era and things would be much
nicer with seamless sync if we had front
ends which just had some subset of your
central app database and could
efficiently subscribe to to changes on
that database based on security and
scoping filters scoping filters being
some restriction of what data to
actually need to render the page so you
don't have the whole database on on the
client then you'd be able to kind of
forget about the server right which is
kind of the direction things that are
moving I think that you know the client
is where all this kind of dynamic stuff
is happening so the more you can move
logic there the better I think and he
also makes a really strong point that
they comic and data script are perfect
for this right there they're log based
so they have a lot of these really nice
properties for being able to to build a
system like this and I think this is
really compelling there's this isn't the
only sort of instance of folks talking
about moving away from the traditional
rest architectures that we all that we
all know and maybe love or hate but I
think I think the fundamental problem
here is that rest api's are terrible way
to approach distributed systems they
hide a lot of complexity
and there's a really great post by Chaz
Emmerich called distributed systems in
the end of the API which I think really
clearly elucidates this so you can find
that in quilt org if you're interested
but but but it's not alone they're there
they're there been a lot of ideas that
have moved things in this direction
meteor GS is doing very like Web After
Tomorrow style subscriptions on Mongo
collections um next Falkor graph QL
relay etcetera are letting components
directly query for data and and are able
to do this in a way where you know you
have some static description of all the
data you need and you get it all in one
fell swoop so you're not dealing with
issues of multiple round trips and
consistency as a result of that
consistency problems as a result of that
butBut another really interesting
direction are convergent replicative
data types
these are data types which are sort of
guaranteed by this merge operation to to
converge and to be consistent when you
take two systems and say hey here's my
view of the world here's mine and you
know you merge them and you get
something that's that's consistent and
so this is this is something that solves
a lot of problems and distributed
systems as soon as you don't have to
worry about these consistency problems
with the data that you merge it's it
makes a lot of things simpler so so this
really felt like the right direction to
move distributed systems are hard so the
idea is isolate the hard part and and
this is really similar to emerging
patterns of state isolation I think in
functional programming and and quite
related right like they're really kind
of mirror reflections of each other but
a lot of problems come up here there are
a lot of things that haven't been sort
of worked out yet with the web after
tomorrow how do you describe the scoping
filters and how do you describe them or
process them efficiently so that so
you're not for instance running a query
for every single user for every single
transaction hits the database and this
isn't this isn't really a trivial
problem with CRD T's there's the problem
of garbage collection and I think
there's been a lot of active work here
but my impression is that there's still
kind of some unsolved problems that we
still kind of have to wait to see how
things settle out there but but they're
human you know mashup ideas what if we
were doing the
after tomorrow via CR dt log
distribution that that could be a really
powerful way forward that would have
some really nice advantages for being
able to take any two given clients and
have them urge data share data with each
other without having to go through a
central server so peer-to-peer but
taking a step back this is a lot of fun
thinking but for my client's case
fortunately we had a small enough set of
data that it could fit in memory and the
local the the the point was on a local
area network which meant that we didn't
have to worry as much about security and
authorization authentication all client
stuff full permissions and there's no
need for optimistic updates or offline
availability so I really only needed to
solve a a subset of this problem and I
thought why don't I do this and provide
a basis for something that we can we can
grow into a more general solution so the
picture as it stands right now is we
have at atomic database which is our
central system state and we stream
transaction changes to all the clients
and in this case we're just streaming
all transaction changes because that's
fine for our particular use case here
but this is of course where you can
introduce mechanisms to make sure that
you were you weren't sending data out
that there was an authorization for etc
each one of our clients then takes those
transactions and transacts them into its
local local data script database so in
the sense then each local data script
database becomes a materialized view of
our dynamic database from there we can
compose these reactive signal graphs
based on our data script database and
that's that's kind of the data flow
right there the the only thing we need
to complete the picture is we need for
clients to be able to send transactions
to DES Tomic so we open up we open up
that ability and all you have to do that
really is once you send that transaction
through the transaction reports will
come out of the the flow that we've
already described here so so this looked
like a really really approachable
architecture and had a lot of benefits
we'd have a really light server where
you know we'd have almost no logic on
the server we'd hook up this sink
stuff and then kind of forget about it
unless we needed to do some kind of
heavy computation on on the server to
reduce strain on the clients strong
consistency is good when it's not a drag
you know it's thinking about how we
would do offline editing and all that
sort of stuff is great but we don't
really need it in this case and so you
don't have to worry about that client
components can be based on these
expressive data log and pull queries
which is really awesome again we're just
like we're just syncing the databases so
we have the full expressiveness of data
script to describe the the data that
goes into our user interface and finally
I was able to do at least enough
thinking to feel like there was there
was a direction forward here to grow
this into something more more general
that solve you know or more robust set
of problems
so all the students look really good and
so I started to work one of the first
things that I set up was the data sync
because that was obviously pretty
important for everything else to work
and really here most of the work was
just in creating translations between
the transactions so you want to make
sure that you can translate entity IDs
between the two systems and such and the
rest of it was really just hooking up
the data flow so I've put together a
library called that sync which has some
utility functions for doing this kind of
work
for syncing the atomic and data script
databases the only thing that's
supported out of the box right now is
this kind of full database replication
and all clients get all transactions but
you know we're gonna we're going to work
on solutions towards the more general
problem and this is on github at meta
Saurus dat sync so again most of the
work is in the transaction translation
particularly with the NT IDs and remote
versus local versus temp IDs etc and the
next thing that we do that's kind of
useful is we can automatically update
data script schema when de Tomic schema
changes come in and this is actually
updating the data script schema data
script by default once you create the
database the schema is fixed so you
actually have to drop the database and
create a new one with the new schema so
this takes care of that problem you know
that you just don't have to think about
the schema on data script anymore you
define it in day Tomic goes over to day
script we flatten nested map structures
for you when you try to transact them
and this means that you can do a pull
request on the atomic and send that over
as a transaction and it'll work and
hopefully again this will be the basis
for for more general work in the future
so here's a quick example of how this
would be set up with sent a WebSocket
server framework on the client you would
have an incoming message handler which
would dispatch on some key say that sync
transaction data and all we do is just
take that data and apply our dat sync
apply remote transaction function on the
server we do almost the same thing we
wait for this message with the same the
same key and and use the server's
version of the same function and
optionally well right now it's also
necessary to hook up some kind of a
bootstrap function so that when when
things load it gets the initial the
initial database state but hopefully we
won't need to do that once some of these
other things kind of get smoothed out
the next bit of work to do is to hook up
our transaction reports so to do this we
use des Comics TX report q function
which returns a Java blocking queue and
we pass that to start transaction
listener which is which is a dat sync
utility function that takes as a second
argument some handler for what you want
to do with that transaction data so in
this case the first function which you
define handle transaction report just
sends sends all this data to all clients
broadcasts it so if you wanted to do
something more interesting only send a
to certain clients etc this is where
that would hook in and of course we want
to build things to make that a little
bit more automated but that's that's
what there's right now so that's it
that's the server again annulling me to
do heavy heavy heavy work there that's
that's kind of all there is to it so now
towards building flexible views the
again this this goal of the system was
to be able to take in really kind of
flexible flexible data and and have
things be really dynamic and users could
add their own
entity types and such sitting attract
change how the data works in their
system and I realized that this meant
you know we couldn't be hard-coding in
views for specific kinds of entities we
had to have something very general that
would just take data and render user
interface and maybe wouldn't be perfect
all the time but at least that they you
know they'd have this ability to add
some data type to their system and and
have it work so I pretty quickly
realized that the de Tomic schema was a
perfect starting place for for
describing the data that we need to do
this we already have a bunch of data
here that's really useful we know the
value types of our attributes we know
the cardinality we know the docs string
a doc string for instance can be used as
a tooltip but we can add our own
attributes as well we could add
something like attribute label to an
attribute have a meta Tribute if you
will which which would say that anytime
we want to render a value which is an
entity name we want to put the label
name pretty straightforward and I mean
this is maybe something you could
automate too based on the ident keyword
but but at least you'd have this ability
to override it pretty simply and so this
this leads us to this idea of defining
our own semantic extensions to the
diatomics schema which i think is a
really cool and powerful pattern but one
of the things that we need here is the
vocabulary around entity types
so again if users are going to be adding
their own kind of types to the system
and all this stuff has to work kind of
in an automated fashion you need some
description of what the types are in the
system and the atomic is adhering the
polymorphic it doesn't it doesn't care
what attributes you put together has no
notion of types or tables or anything
like that so we need to build something
in that does this for us and I think
it's really cool that you can so simply
all that we do is to find some entities
with an ident and that ident is kind of
what we think of as the type so in this
case we have it's do type and we can
specify that this to do type is
associated with the atributes entity
name so pretty simple this would
assuming that if we wanted to render a
view for a to-do item automatically we
would know that we need to give it a
name field and then to to assign a type
to some entity we use this entity type
attribute and that's it now this thing
is it to you item for references there's
a little more work to do we need to we
need to say what kinds of references
something can point to there might be
cases where you really don't care and
that's fine but typically you're gonna
want to for instance populate a
drop-down with some set of items and and
for that you're going to need to know
what kinds of items do I need to
populate so here just having an
attribute 'href types attribute which
points to the types that you can assign
for this for this attribute is is is the
solution here and there's nothing
statically enforcing this of course this
is just this is just sort of a
convention and you could obviously work
around it which i think is kind of cool
it's really flexible but um but yeah
it's all the guidance that's needed to
to make these things sort of automated
now putting things together interview
functions I'm kind of whitewashing or
sweeping over all the work in making
these really general functions because
there be a lot to explain there but but
basically what you can what you can note
here are the pull view and edit entity
view functions used in the to-do app
component below these are these very
generalized functions which just take in
data and based on whatever whatever data
you've put in the schema will render
view for you so edit entity view would
specifically give you an edit form based
on some sort of in this case we're just
providing sort of a prototype of what we
want the entity be we want to say that
it's a to-do item and then based on that
it's going to be able to you know render
all the fields that are necessary for
entities at that type below below that
we have we use the pole view component
which just takes some pull data which
you might get from from a data log query
like the one above and it will just
render whatever data you pass it to it
again based on based it on the schema
metadata and
any sort of customization that's defined
there but just to kind of see where this
can head we can abstract things a little
bit we can we can to make them a little
more general here's an example of a type
controller we pass in a connection and
some type ident and we just sort of
build everything dynamically like we did
before but where we just put pass in
whatever variable type ident is and so
now our 2d MVC app becomes type
controller con entity type to do that's
it so you can imagine now how you could
build your application if you had a
bunch of different kinds of entities
that you wanted managers for you would
just call this little function for them
and you know about that to which type
you were you're you were on I mean this
looks really this is just you know when
you think about the scaffolding that's
involved in rails and like the massive
amounts of code that produces that you
have to maintain have fun with that we
don't have to do this here right this is
these are functions we can just use
these drop them when we realize that we
don't need them anymore so it's it's
simple unfortunately though there are
some problems nothing would be complete
without some problems to solve and in
this case I think the biggest problem
has been performance this is kind of
wildly non performant the way I wrote it
and I kind of I kind of wrote it this
way on purpose to really push the limits
of like what can you do with with Posche
in this in this architecture and
unfortunately yeah you have to be a
little bit careful that that is sort of
a reality here if you have tons of
queries going on there there's interfer
getting into problems but really here a
lot of the a lot of the problem that we
had was really specifically with this
dynamic dynamic view stuff I think for
for kind of simpler things going on that
you were just doing yourself you
probably wouldn't be using as many
queries the problem here is we had all
this very kind of granular nested stuff
because we had to make it all very
general and there's lots of kind of
layers of queries for each component and
additionally the the actual domain data
that we were rendering we were sort of
defining things such that it would query
for one entity and then
it was separately query for all of its
sub entities and of course this is bad
right this is you know we're doing a lot
more querying than we need to and so the
obvious solution here is don't through
as many queries you know dot view is
something
sorry I haven't to find that for you yet
so this this generalized view code is
something that we can kind of do that
work upfront with we can we can kind of
you know we can do the work of tuning
that so that you only have to worry
about tuning your own set of your own
set of queries which which should make
things a lot simpler but Pasha also has
a number of things which are coming out
now which which should be able to help
us so Posh has pattern matching kind of
built in and what that means is that as
you when you define your queries it's
able to statically look at them both
pull and some some data log queries it's
able to look at them and and often
figure out ok this transaction doesn't
have anything which has a chance of
updating this query so I'm not even
going to rerun that query that means a
lot less work in in getting things set
up
additionally Posche by virtue of you
know producing these these reactions
which behave like materialized views
they're kind of like little caches right
so once you've created a reaction and
you've done that computational work as
long as it's not updating you have
something that's not changing all the
time
it's it's pretty efficient once that's
set up it's it's mostly on kind of this
initial load that we have this this
problem so one thing that we really
useful is for things that you know we're
going to kind of swap in and out
frequently but there's there's not
enough of it to really worry about
dropping it all the time you can just
specify something in Posche that would
that would keep those reactions alive
and sorry I should measure something
specific so Posh actually casas
reactions even between components so if
you have multiple components using the
same query they're not going to get
rerun you know it'll only ever run once
so but again if there's something that
we only had wanted to run once once we
started the application and then keep
alive we could do that and then it's
just effectively a hashmap look-up away
but we can also take a play from the
refrain book which is we can chain
reactions together to kind of gate the
computations that we're doing and so
some things that we're working on our
posh filter which is sort of a version
of data scripts and a tommix filter
that restricts the database so that your
scans are shorter so this this is
potentially a big win for for this
flexible schema stuff because really all
we need there is the schema data and so
if we do a filter so that we're just
squaring on the schema data we're now
looking at a lot less data and that
should make things a lot better there as
well so how did this turn out amazing it
was every bit as awesome as I'd hoped
I mean it's like what you saw it like
you say render stuff for this entity
type and it does it and that's pretty
cool
there's some stuff it doesn't solve yet
you know there are definitely some
problems but it it was it was really
nice it did the thing the
domain-specific query system just kind
of feels like a side note to audio stuff
that's going on but it's worth
mentioning it really worked wonderfully
comparing the solution in be able to
come up with with the atomic to what we
had to do in Ruby on Rails with you know
sequel databases just a world of
difference so much easier to take some
input data from the UI and sort of
translate that into the state of law
query which again it's just data
you're not composing sequel it's just
data so looking to the future security I
think is one of the next big things to
figure out and here I think there's
something that I mean I'm I'd really
like to hear people's opinions on this
but I think rest api is have been
entangled have become entangled with
security and authorization concerns and
I think this is actually bad because
there's a lot of complexity to REST API
and I think that coupling these things
has a potential for leaving little
wiggle room for for things to happen
that you that you weren't aware of in
the architecture which we're talking
about here though everything is just
streams of transaction data and I think
that that uniformity could lead to some
really nice patterns in authorization
and security and I'm not a security
expert so take that all with a grain of
salt but yeah I think I think it is
compelling and there may be some work to
do to really get that right and to
figure out what the right patterns are
but but I think that there is a way
forward and I think the rough basis for
this how
this might work is from server to client
we need to be able to send transactions
that that hit the server and I think the
idea here is you know people talked
about well you know one of the nice
things about they Tomic is we can create
this filter database and filter out
things that someone doesn't have
authorization for but we could also do
this reactively so that again we have
this thing that's sort of like cached
for us and updates whenever whenever
whenever it needs to and this reactive
filter then could be the basis for
filtering by entity ID and attribute for
any given user
what transaction data they actually are
allowed to see and so only those only
those transaction datums would get
passed on but they'd have to get passed
on to then some scoping filters and the
scoping filters again are what we would
use to describe what data any given
client actually needs to see from client
to server you have to be pretty careful
because right here's where we're
actually writing to the de Tomic
database so we want to make sure that
the anything it does get written is is
okay and I think for this we can do
something based on pattern matching of
our transaction forms with whitelisting
and custom per per operation filters so
that if you had your own transaction
functions to to the to the system
they're not going to be permissible from
clients unless you explicitly say this
is how you translate this and this is
okay this is why I listed for more
expressiveness though we can also use
database snapshots on peers together
with the de Tomic width function which
gives us sort of this imaginary world
which is what the database looked like
if I transacted this data don't transact
it just like tell me what it would look
like if and so that gives you both the
database before and after and also the
set of datum is produced by the
transaction so that's a lot of
information off of which you can you can
do some creating and figure out whether
or not these datums are allowed by this
by this user and typically this isn't
something that would need to be run in a
transaction function but and you
probably wouldn't want to because that
puts extra strain on the trans actor but
you know as long as as long as you're
basing things off of a consistent
snapshot which which is what
the atomic helps give us you you know
that this the if something was
authorized recently it's probably okay
to still allow it now so so that's a
thing scoping subscriptions posh again
has this awesome pattern matching
ability so what if we use this for
scoping on the servers and I think this
is really cool because now we can start
to see a convergence between some of the
ideas from home next and this
architecture of data flow that we get
from refrain right so we described these
queries that we just statically sent
over to the server the server does some
analysis on them does this pattern
matching stuff and builds these builds
these these reactions which which which
do the scoping work for us so this work
that I've been putting into this really
flexible schema I'm calling that view
just as a pattern right now I hope to
eventually make this a library and you
know for I have high aspirations it
might end up being something that's just
like if you need some like ugly user
interface to like look at your diatomic
data and don't don't really care what it
looks like then it's fine but I'm really
hoping that that we can make into
something more general right now there's
a lot of refactoring going on again to
make things more performant but um but
the stuffs there I mean we it has been
written and it works so it's really just
a matter of retooling it and organizing
a little bit better there are a lot of
challenges here you know we want we want
this at the bare minimum be a set of
useful helper functions for describing
more custom components but ideally what
we'd have is the ability via pattern
matching dispatch to to specify how we
want certain shape of data to render so
by default everything would render just
kind of by these you know these defaults
that we set in the system but for any
given thing that maybe had a certain
type or a certain property between
between things we'd be able to customize
the the rendering and yeah hopefully we
can do that in a way that's really sane
and and and makes sense but I think it
we also ideal if we could separate out
style and layout specifications as
orthogonal concerns
that we can kind of mix and match and
and share and compose etc there are lots
of other problems to solve offline that
sync availability of course I think we
could do I 18 n as as schema metadata or
as the atomic data efficient validations
is kind of a problem you you know if
you're running every single transaction
in transaction functions that assert
some validations that again puts more
strain on your your trans actors so
coming up with some good patterns there
I think is um is interesting question
that view query composition tools so I
think one of the great things about um
next is that it uses it really just
focuses on pole expressions we have pull
expressions in posh and we have data log
but the nice thing about pole is that
it's really easily composable right I
mean if you saw like some of the talk
like the time from yesterday are you
doing anything with them next you can
see like you just say well this is what
it's the sub component means so let's
just put that in here in the pull
expression and that's really easy and
simple and I think we can copy some of
that sorting yeah some utilities for
doing things like sorting and pagination
but I think something that's really
interesting in that I was just talking
to to some the Onyx guys about is this
idea of compiling to these reactive
graphs that we would create to onyx
workflows of data log and pull queries
and I think this is a potentially really
powerful pattern so this means that we
can you know build something on a small
system and then just really quickly
scale it out to to a Nanak Sun on
exposure there's a lot of work to do
here obviously but it really feels like
there's a coherent direction and some
really cool patterns which are emerging
and I hope that you all can kind of take
take what seems interesting from it but
if you're if you're interesting kind of
looking more into all this stuff I've
put up at alysus which is just sort of
an application template with some of
these patterns and so specifically if
you want to see what dot view is
currently and what its kind of morphing
into you can do that but also if you
want to see an example of how dat sink
excuse me in a system you can take a
look at that there as well
this may eventually evolve into a micro
framework but again for right now it's
just sort of an example application the
vision though just take a step back and
think about think about everything we've
discussed here we want to be able to
programmatically build web applications
around schema metadata data script
queries and transactions and declarative
data sync and there's a really nice
convergence of ideas here which I think
makes this very compelling um next
Street relay Falkor refrain the other
one yeah i graph thank you graphic you
i'll reframe some zalim all this kind of
streaming materialized view stuff the
web after tomorrow
they Tomic data-driven programming in
general there's a lot of really great
stuff that I think is converging here
and I really feel honored to be standing
on top of the shoulders of giants with
all this great thinking and to be able
to put some some pieces together which I
think are interesting and I'm really
excited to to hear what what folks think
about this so with that thank you there
there's a few people I want to thank
here Matt Parker creative posh aquatic
RNA is spending a lot of work helping
put catalysis together and learning web
application development along the way
Christian Mann drip who's here actually
and has contributed a lot of Doc's to
this system and infinite cloud for for
supporting some of the work and thoughts
on security stuff so that's it thank you
we have time for questions is there time
for questions maybe like one anyone yeah
yeah yeah so the question was how is
this different from kind of the fat
client of old and I think I mean so in
the in the specific application that I
built certainly we could have done that
but yeah I think the difference here is
that we're really thinking about about
this from this distributed systems
perspective I think that a lot of the
fat client architecture of old wasn't
really wasn't really doing that and yeah
I think I think we have a lot of new
patterns here that we can use to tackle
some of these challenges with those
architectures that we saw one more No
yeah
yes
yes oh I think so let me try to recap
that are you concerned the question is
are you concerned about corrupting the
central the central view of the world
the central database in the system and I
think you're the key to this is that
because we have this kind of reactive
reactive flow topology at any point the
only thing that's actually going to
update the central system is a
transaction that you send out so so
there's a distinction from what anything
that you might compute just locally on
the client to say you know have some
materialized view that represents some
efficient computation which you need for
the user interface you separate that out
from anything which should actually be
saved onto the client and so there there
is a problem here though which which I
think you do touch on which is that you
know we are just saying here clients can
just send whatever transactions they
want and that that is definitely a
security problem right we need to be
able to think about how we ensure that
that is safe but but again I think that
thinking about it from that perspective
may actually lead to some really nice
patterns because we can actually just
say it's just the stream of transaction
data and and reason about that okay
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>