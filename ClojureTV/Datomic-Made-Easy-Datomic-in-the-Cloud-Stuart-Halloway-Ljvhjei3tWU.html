<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Datomic Made Easy Datomic in the Cloud - Stuart Halloway | Coder Coacher - Coaching Coders</title><meta content="Datomic Made Easy Datomic in the Cloud - Stuart Halloway - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Datomic Made Easy Datomic in the Cloud - Stuart Halloway</b></h2><h5 class="post__date">2017-10-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Ljvhjei3tWU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this is novel it's great to be back
I've been at every cons since the first
one in my neck of the woods in Raleigh
Durham North Carolina and I'm gonna be
talking today about this little database
project that I and some other people
have been working on in closure called
the atomic you may have heard about the
atomic it has a set of characteristics
that preserve the things that I like
about sequel and add some things that
address limitations now in particular in
particular I want to build data of
record systems typically and so I want
the acid transactions that I'm used to
having from sequel and I also want to
have a powerful query language it
doesn't have to be sequel per se but
something logic based but at the same
time there are things that I don't like
about sequel and that's being stuck in
tables and so it's nice to be able to
model sparse data or hierarchical data
and to be able to make more granular
statements about schema and have that
kind of flexibility in addition what
else is there to say what other words
are on there indelible that's a good one
so I also want to have a database that
remembers so not just knows what's true
right now but knows what was true ten
minutes ago and two hours ago and once
you have an indelible system you also
have a straightforward path to
chronology right to understanding what
happened and what followed happened now
these are the words that we've been
using to talk about the atomic for the
last five plus years but it came to my
attention today that these words are no
longer inverted pyramid compliant so
apparently apparently I have to update
my spiel to match the new inverted
pyramid of programming problems and so
luckily I know how to zoom in on things
so I can make graphics big enough that
you can read them
so the red arrows point it where it's
not surprising right that the atomic and
closure are philosophically aligned
right designed by the same person but
the arrows are just sort of connecting
the dots between some of the things that
which said this morning and what the
atomic is about sewed atomic stands
against place oriented programming right
we don't have places we have values the
value of the database and we have
managed references the atomic gives you
help with concurrency admittedly the
kind of help that databases have always
given which is asset transactions and
also deals with the problem of
parochialism right the atomic has you
working with open associative
collections and having those things have
good names right taking advantage of
strong names so this is all directly
overlapping with things that rich said
this morning that were motivations for
why he built closure he wanted to
address these problems in the middle and
not necessarily address the problems
down at the bottom because they're too
trivial to put a lot of effort into and
we know that the problems at the top are
super hard right misconception in the
domain so we are not going to
necessarily address those directly with
our tools at least yet but at least we
can make some headway against these
problems in the middle so that's pretty
cool and the information model in DES
Tomic has been unchanged since its
release there have been new capabilities
operationally but the information model
has stood up well because it was generic
in general I'm not going to talk any
more about it today because there are
some things that are not so great if you
wanted to sit down and build an app with
the database the atomic was originally
designed to run on the cloud it was
originally designed to run on the AWS
cloud and there's a lot of value
propositions and promises that the cloud
makes that are still pretty hard to get
to when you're thinking systemically not
just thinking about this this box that
represents my database process or this
box
that represents one web app process or
this box that represents you know some
other application and some of those
things include well include a pricing
model that sort of pay-as-you-go and the
agility that comes with that
another thing that
that you really want is to have scaling
that's elastic right so the ability to
say that your system can flex up and
flex down in responses to things that
are happening in the world are in
responses to things that you say that's
sort of the promise of virtualization
and so this isn't necessarily awesome I
mean the Atomics Information model does
nothing to make any of these things also
let me put it that way
all right the information model is cool
but it doesn't give you any of these
operational characteristics
automatically meanwhile users have
changed in what they want since we
started building the atomic and there's
a big move to more ephemeral processing
there's a big move to processing
happening on weaker less reliable
hardware and software there's a move
towards micro services and things
running in containers and all of this
sort of advocates for having a model for
interacting with your database that's
very lightweight on your side right that
doesn't have you sort of participating
inside atomic Spearmon so that's a
challenge and when you sit down to put
this together in AWS there's a lot of
pieces and these pieces are simpler than
a monolith I said simple once right
there's some kind of drinking game I
know some people are playing so that was
the first time these pieces are simpler
than a monolith and some of the
individual pieces are pretty simple and
some are not but in any case putting all
of them together still requires a lot of
knowledge a lot of knowledge about the
semantics that you want from your system
and a lot of knowledge about the
operational characteristics that you
want for your system and regardless of
what your database is you know some of
this stuff is still going to just be on
you so what can we do how do we make
closure an awesome environment for
building things on AWS and in particular
in the subject of this talk how do we
make de Tomic easy and a great choice on
AWS for closure programmers so you're
running if you're running on AWS you're
writing code enclosure to have the
atomic be a tool that fits your hand
when it can
and so what we've been working on for
the last couple of years is thinking
through the possibilities there one
possibility of course would be to have a
service and a service would be fantastic
because it would take all of those
complicated pieces that you have to fit
together that I showed on that previous
slide and it would put those into behind
a dotted line called magic where
somebody else does it for you so you
know that would be super great and
obviously it would deliver on the sort
of operational promises of the cloud
because really all the operational
promises become the providers problem so
that would be cool but in talking to our
users we came to realize that there were
some pressure points mitigating against
service so not everything is all about
service when you're talking about your
data tier you don't want to read the SLA
you want to write the SLA that makes
sense right you don't want to consume an
SLA from somebody else and you're sort
of stuck with it now you want to be able
to say here's what I want to be able to
deliver also it's been a value
proposition of day Tomic from day one
that you can write code that lives near
your data and one way to do that is with
a tom experiment if you're familiar with
it's not the only way but that's one way
to do it and code that lives near your
data is challenging in a service because
now you're asking the service provider
to run your code and that's also you
know typically gonna be a problem and
then maybe the worst thing and this is
kind of a Goldilocks problem is what you
really want to have a service is your
hands are completely off of it you don't
have any worries but if you ever are
worried you can grab the control stick
and put your hands back on it and be in
control of it and so I have a simple
visual diagram to show you what that
looks like all right so at the top left
that's the cockpit of the Concorde I
believe and so when you're ready to put
your hands on the controls having never
hand your hands on the controls before
right when something bad happens it's
like okay yesterday I've never touched
the controls today something bad
happened I want to put my hands on the
controls and you look at those controls
for the first time that's not going to
be a good experience on the other hand
Jonnie cab in the bottom here if you
remember the movie right Johnny cab
drives Arnold Schwarzenegger around but
he doesn't
actually give any control and the kind
of frustration you have with that kind
of hands-off in a service it's pretty
evident when Arnold rips is the little
robot guy's body apart so we don't want
to be there either
so the question is and this question is
going to have trade-offs in it and so as
I give this talk I think you should
think about what the trade-offs are but
the question is what could we do to sort
of stand in between there and have our
cake and eat it too to some degree and
so what we've done what we're working on
right now is a new date AMA called
atomic cloud on the AWS marketplace and
what this is going to give you we hope
is a sweet spot in between those two
extremes so there's going to be
automation for putting together all the
pieces that you need to run the database
in the cloud you're going to press a
button and then you're going to come
back and you're gonna have a database so
it's gonna be like turning on a table in
dynamo dB so that aspect is going to be
service like but as a marketplace first
up how many people have run a
marketplace application in AWS anybody a
few so the way that marketplace works is
you say you go and click through a thing
and say yes I'm willing to run this and
then you get to launch a special ami
or as AWS it turns out they pronounce it
ami which I didn't know but we had to
talk to the marketplace people and they
keep saying ami and we keep not knowing
what they're saying
it's their word though so I'll try to
say ami for the rest of this talk so
today you run an ami and then this just
shows up on your amazon bill right it
just shows up as a line item on your
amazon bill you've got dynamodb s3 and
now you would have they talk and just
shows up on your regular amazon bill so
what's that going to look like and I
actually am going to come down where I
can see these slides that I remember all
the points the primary entry point for
this is a thing called the solo topology
so the solo topology is an instance of
de Tomic cloud that is suitable for
development suitable for your test
system suitable for CI our CI system
uses one of these suitable for personal
personal projects it delivers the full
programming model of the atomic and it
integrates
AWS security grates monitoring it's
triply redundant durability so
everything in the atomic cloud is stored
in dynamo and an s3 and on EFS and there
is a fashion server for dev access so
you can actually who's this it's secure
it's running inside of a created V PC
which you have to get your application
inside of or VP CP or whatever right all
the serious grown-up go to production
stuff but for development there's a
Bastion server that you can SSH onto
inside your client API call so you can
configure the client to say use SSH
locally and socks proxy on to the
Bastion and get on that way so it's a
the atomic instance that's available
over the web for dev purposes if you
want it to be and the AWS line item for
this if you'd leave it up running 24/7
is going to be about a dollar a day and
the programming model is clients so
about a year ago we started doing de
Tomic clients I gave a talk at last cons
about ETL jobs using des Tomic clients
and clients obviously are something
that's going to need to happen if this
thing is going to run over there in the
cloud and your application is going to
run somewhere else these clients are a
sink and sink so the bottom model is a
sink using cord out async channels and
transducers and all the sort of goodness
when you want to have your you know high
level of control and then on top of that
there is a sync API and importantly this
still delivers the diatomic information
model completely so when you call get DB
on the connection you get a value of the
database and you can query and operate
you know six times against that value of
the database and know I know that you're
still working against the same baseline
and so this is what that looks like the
solo topology is a storage resources
which we'll talk about more in a minute
and then there's a primary compute cloud
formation stack this is a great chance
to learn a ton of icons if you want to
take an AWS exam that little green
bricks are a cloud formation stack
there is an auto scaling group that
keeps up the solo which is a tiny AWS
tip since there's another auto scaling
group which keeps up the bastion if you
want one application clients live inside
the V PC so your programs that in
production live inside the V PC or if
you're super fancy networking person
they VP CP or whatever you want to do
and then for convenience of dev you can
SSH Sox in from the outside
that's what solo looks like and I've
just got a couple of pictures of some of
the AWS stuff that's automated solo has
a cloud formation dashboard when I was
talking about this in the day Tomic
class yesterday a couple of experienced
AWS hands were flabbergasted that you
can programmatically create AWS
dashboards now so if you didn't know
that if you're an AWS person that's only
true in the last what several months but
this is super cool so when you stand it
up it automatically creates the
monitoring stuff for you this is a
picture of the outputs from the cloud
formation template and all important
Diet Mountain Dew break how many of you
can read all the line items there my
objective is not to show you what those
are the important point I'm trying to
make here is that what has to happen
behind the scenes to fit this stuff
together is a lot of little pieces a lot
of little fiddly bits and all of this
stuff is designed to incorporate what we
believe to be best practices for running
the atomic in the cloud so every line on
there is something that in today's world
you would have to get right if you
wanted to automate deploying to AWS and
in this world you press a button and
stun logging is integrated the logging
so this is me doing a search on the log
to see a report of all the transactions
that have ever run you can do log
searches against individual instances if
you're troubleshooting where you can do
log searching across the entire auto
scaling group in the case of solo that's
not going to be very different because
solo is only running one instance
everything is tagged with AWS tags so
all the SIS ops people are gonna be
super happy when they go in here and try
to understand
what's happened they can do a tag search
and say show me all that atomic
resources for this particular system or
show me all the de Tomic resources for
all systems or you know whatever else
you want to do using a SS is tagging in
query language and then integrated
security so it's been a long-standing
desire for people to have encryption at
rest with DES Tomic and an obstacle to
that when you're running des Tomic as it
exists today
is the atomic as it exists today is
on-premise software
it's architected for the cloud but
people are running it on premise at
least half of the time people are
running it backed by Oracle people are
running it backed by Cassandra people
are running it backed by my sequel
Postgres whatever and what that means is
there is no standard way to say hey
we're gonna do key management right if
we're gonna make encryption at rest in
the existing day Tomic stuff it would
have to be some sort of integration
point that you would have to meet it
would have documentation and it would be
a pain in the butt and it would have
different flavors and so on and so forth
the great thing about integration with
AWS is choices are made for you so all
this is now just taken care of
you have encryption at rest everything
is encrypted using keys that are managed
by Amazon's key management service the
clients connect and they authenticate
via the AWS HMA algorithm so if you
trust communicating with s3 or dynamo
today then you should trust this it's
the same algorithm that AWS uses
everything is isolated by VPC and
there's a fine-grained permission model
that is based on I am this is actually
super cool and so I'll just throw this
out as a puzzle for those of you who I
know we're not supposed to do specials
were supposed to solve problems but I
will throw this out for you as a puzzle
normally it's not possible to extend
im's permission model because it's kind
of parochial to AWS right they have I am
permissions for their services but they
don't have an extension point so that
you can make I am permissions for
something that you're making but we came
up with and it's kind of a hack but we
came up with a cool trick that lets us
actually integrate directly with I am so
you can specify I am permissions to do
fine-grained permissions and one of the
fine grained permissions in the initial
ship is read-only
databases which is something as another
long-standing thing people have wanted
now let's talk about durability for a
second durability is another place where
people want to have their cake and eat
it too when I'm operating against
storage I want those operations to be as
low latency as possible and so I want to
use something like what I really want is
to not actually be storing things to
have a giant cluster of memory redundant
so everything that I want to get to is
in memory and I'm getting it at memory
speeds we're failing that maybe SSD
drive speeds but I want everything to be
super cheap so scratch what I just said
and instead what I want is everything to
be on something like s3 and which by the
way has horrible latency you know by
comparison to three orders of magnitudes
worse but hold on a second I also want
to have acid transactions so I need to
have something that has underlying
primitives
that will support acid transactions so I
want something like dynamodb which by
the way is categorically more expensive
than all these other things but I also
want to have you know whatever AWS says
eleven nines of durability reliability
so I'm back to something like s3 and
this is another one of those sort of
went to have my cake and eat it too kind
of moments so what do we do well we take
advantage of simplicity set it twice and
we know we know these ideas right this
goes back and this this is cool I want
to point this out because rich talked
about these ideas this morning in the
context of problems of programming but
this is going to be a moment we're doing
something simple turns from a
programming thing to an ops thing it's
going to have operational consequences
and so we're gonna make a couple of
distinctions that are not always made
we're gonna distinguish reads and writes
so we might actually write things over
here and read them back over there from
a different kind of storage we're gonna
distinguish and this is the critical one
we're gonna distinguish bowels from
managed refs this is exactly the same
distinction that closure makes right
vowels are the immutable data structures
and atomic those are trees just like
they are enclosure and then the managed
ref what's an example of a managed ref
type enclosure an atom or an age
right there's one manager f-type and
atomic it's connection right connection
is in fact a manager f-type so it's the
same concept and we're also going to
distinguish once we're storing things in
multiple places we're going to be super
careful about the words must and should
write because if you know you're
redundant ly backed up somewhere else
your semantics maybe should and not must
and once you put all these three things
together you're capable of doing
something that's crazy good and that is
store all data in the system in four
places
dynamodb s3 EFS and local SSDs when you
want to read it back read it from the
fastest place first right so read it
back from the local SSD failing that
read it from EFS failing that read it
from dynamo DVRs three depending on the
kind of things being stored you still
want the acid semantics so every time
you need to advance a transaction
pointer you're gonna touch dynamo DB but
that touch of dynamo DB now is only a
pointer move it's not the trees it's
just the pointers what this means is
that the actual load that's put on
dynamo is going to go down by an order
of magnitude compared to targeting
dynamo the way the atomic targets dynamo
today and the right reliability
guarantee of this is crazy good right
because the data is in s3 and in dynamo
DB and an EFS and the architecture
supports auto repair' across those so
you don't even have to trust EFS a--'s
or s3's eleven nine you can be like I
like that but I'd feel better if it was
also over here on this machine and we
can repair it and that can all be done
transparently behind the scenes this
represents
thinking about this problem off and on
for almost a decade right the original
architecture of the atomic had a really
cool storage architecture that
represented the first five years of that
thinking and this beats the pants off of
it this beats the pants off of it so
much that things you can't even create
this from an existing day Tomic storage
representation this has richer
information in it that existing day
Tomic can't even capture today
and of course you get out of scaling so
here is a picture of DynamoDB
auto-scaling during an import job so at
the beginning of the import job the
lines are on the floor then the import
job happens in every five minutes dynamo
Duty goes oh crap too much is happening
and scales up and then the import job
finishes and DynamoDB turns it back down
for the kinds of loads that you're gonna
run in dev and CI and so forth dynamodb
is get turned back down into the free
tier anytime you're not actively
pounding it which is super cool and then
there's the production topology so
everything I've said so far is the solo
topology the production topology is all
of that plus operational goodness that
you want in production in particular
everything's always clustered so there's
no single point of failure and there's
no longer any different kinds of
processes so where do Tomic today has
peers and trans actors this is always
nodes there are generic nodes that are
managed by auto scaling groups there's
an application load balancer for H a so
again the H a story is integrated with
AWS sha you can go and look at the a the
load balancer see what it's doing
instances respond to health checks and
so forth and there's auto scaling groups
so you can actually have a database that
scales by launching new instances as
load comes in and then and this is the
this is a by the way these kinds of
things you could always have done for
yourself but it was enough work to set
it up and enough decisions to make that
people typically didn't and this last
one is sort of the icing on the cake
there which is load specific query
groups so you can set up a group of
machines dedicated to a particular job
and then the load balancer will route
the queries for those machines so for
that job to those machines and so this
facilitates doing something like my
primary compute resources are going to
serve the web traffic that you know and
this stuff that's coming in
transactionally and then we're going to
run analytics out of the same system and
we're gonna stand up a query group for
analytics and those two things are going
to compete with each other at all are
there gonna be a completely disjoint
resources and what makes all this
possible what makes all this sort of
almost easy architecture Allah is
immutable
right all of this falls out of not doing
place oriented programming because if we
were doing place oriented programming
what would we have to do we would have
to go back and define coordination rules
between all these pieces and what are
the coordination rules in this world the
same is Enclosure there is no
coordination everything just accumulates
there's nothing to coordinate right you
know about things up to time 11 I know
about things up to time twelve no
coordination necessary that's fine and
there's a picture of the production
topology and you'll see that it looks a
lot like the solo topology except that
now there's a load balancer in front of
multiple nodes in a primary group and
then there are as many additional query
groups as you want and so here I'm
showing our sort of the typical use case
we think of internally when we're
building this which is the transactional
load goes to the primary group there's
an analytics group for for heavy
drop-off and not put on the regular
transactional system and then there is a
dev query group and the devs don't have
much of a budget so we only let them
have one machine in that group if you
have a healthier dev culture you can
have more machines in the dev cluster
and fewer machines that's totally up to
you however you want to do it and the
production dashboard obviously you can't
read the pieces of this but it's much
more elaborate and all of this was
finely tuned around AWS pricing all the
stuff in the solo dashboard is tuned to
hit that approximately $1 a day target
and everything in the production system
is tuned to give you the best possible
experience so that's that's sort of the
boundary between those two things and
then query groups I've kind of already
said this there are additional compute
resources that you can dedicate to jobs
they come and go with no disruption to
primary compute and what this does and
this is important is it gets you out of
upfront decisions on a lot of systems
people say well we might have to do this
we might have to do that we might have
to do the other thing and so we're gonna
make a decision in advance we're gonna
put this data in bucket a and we're
gonna put this data in bucket B and then
for the rest of forever programs have to
know about bucket a and Buckett B and
programs that want to know do something
with bucket a have to go there programs
that want to do stuff with bucket B have
to go there and you real
feel bad for the program questions about
both right because they have to go to
both places and then sort of seem things
back up with this architecture you don't
make those decisions in advance you just
put your data in the database and then
if you decide that there's a group of
stuff called a that matters you create a
query group called a and how does the a
stuff get hot in the query group just by
use right you start using it and those
machines build up a cache of the a stuff
you start using the B group those
machines build up a cache of the B stuff
and if you have some unlucky person who
has to talk to a and B they can build up
a machine they might need a bigger
machine because their cache has to be
bigger you can make a query group for
them that can do both or you can put
them on a piddly machine and just tell
them I understand what you're doing is
important but it still can take a while
so but you're not we're not gonna hurt
the caches for the other people that
have the other jobs and so then what you
can do is auto scale compute and you
cannot a scale compute on the
traditional things so you can auto scale
compute on you could look at CPU
utilization on the boxes or memory
utilization on the boxes but there's a
nicer thing that you can do which is
that the atomic keeps track of pending
requests or ops that are in flight and
so you could auto scale on that so you
could say when there's this many
requests in flight I know that that
means my machines are starting to get
loaded in addition to that sort of ops
and flight metric there's also a
pushback just like with dynamodb well
not just like because Dynamo is a
capacity guarantee and this is more of a
you have whatever capacity your queries
or whatever shape they are so we don't
know that but the idea is that your
system gets a message back from cloud
saying hey you're putting too much load
on this machine come back and retry
again and just that's with the AWS
clients that deal with systems that work
this way the client automatically
retries with an exponential back-off and
eventually gives up and you can see all
of that in the metrics and you can auto
scale on it so you can say hey I am
super super concerned about latency on
my client and I have a lot of money so
my rule is if I see anybody getting
pushed back even a little bit I'm gonna
you know turn it up or you can say you
know what I'd like to sort of split the
difference I'm happy to have one out of
a hundred operations get pushed
by 20 milliseconds or 50 milliseconds
100 milliseconds so I'll tolerate that
and I'll tune in a different way so win
now it so this is this is going to be
released in q4 2017 which means that
right after here I need to run out and
keep working on the final polish and
query groups will not be in the initial
release
so the initial release will be the solo
topology and the production topology and
then query groups will follow in short
order so this is kind of what the day
Tomic team has been up to for the last
couple of years among other things and
they're super excited about it and we
think that it addresses sort of two big
problems one problem is that there's a
ton of decisions that you have to make
when you want to run on AWS and you
would like to have them made well and
put these pieces together and sew it on
of it encodes those decisions and
automates them and it still leaves you
in control so it's not a service you can
go and look at the cloud formation
template you can see how the pieces fit
together you can go in and say hey what
would happen if I change this knob and
you can change the knob and see what
happens you might want to open a support
ticket and say what's gonna happen if I
change this not before you do that but
you can you write it's yours so you can
put your hands on it if you want to and
if you don't want to put your hands on
that's fine right you can just use it
and it continues to deliver the full day
Tomic information model at a price that
we believe is reasonable for Hobby use
and development projects and testing and
CI and those kinds of places so that's
the atomic cloud and because I'm
standing down here I don't have any idea
what time it is so I think I'll open up
for a few questions
so can somebody give me a time check
5:50 alright we'll do this just briefly
and then we'll break and I will stick
around during the dinner hour if people
on to talk about it I'm happy to discuss
yes yes so the client API is already in
maven central so you can just go look at
it the only thing that's different from
the client API that people are using to
connect to the peer server today is the
connect function is basically the only
difference right that all the all the
semantics are the same but the
connection the connect function is now
like a multi method under the hood so it
can be I'm connecting to peer or I'm
connecting to cloud and so the
connection arguments look different but
there's essentially the same and as part
of the release process we will be
removing the Alpha from the namespaces
and locking in on what the model is yes
not at present not at present so the
peer and trans actor model does not
exist in cloud this is a a seamless you
run it everything is all the processes
are homogeneous model we are eager to
have conversations with people who are
looking at you know I want some of this
and some of that and some of the other
thing and we're happy to have those
conversations if you don't know this
there is a and maybe Marshall can drop
this into the closure conscious lack
there is a receptive site for feature
voting Fred atomic so you can drop in
there and say you know here's the
particular thing that I'm worried about
is there a feature that addresses this
um it is certainly the case right des
comic Pro ain't going anywhere right
it's now we're now calling it on prim to
make the distinction clear of where
people are likely to be deploying it
that's not going anywhere and the atomic
pro is going to continue to be suitable
for most of the people who are using it
today my our internal guess was that 90
percent of existing Pro users will stay
on Pro right partially because they're
not in the cloud that's one of the
biggest reasons partly you know they're
running on Oracle they're running on
something else partially because they
are committed to an in process
application and process with their data
model through peers so there's various
reasons and now that
still continue to be the case yes
is this a cross region so the way
marketplace works is it clones the ami
and you can launch the ami in any region
you want but there is not a cross region
replication capability I that's my
favorite feature to work on next once we
ship this and everybody should go vote
for that so I can tell rich that you all
agree because it's super cool and we
know how to do it and by the way cross
region replication is another example of
something that gets crazy easier because
everything is indelible right because
you have this model it's not place
oriented programming in order to
replicate from one region to another all
we have to do is stream stuff from one
place to place we don't have to do any
coordination that's like oh my god the
thing over there changed all right all
those kinds of problems go away it
almost feels like cheating right it's so
much easier to solve some of these
problems that people have when they're
doing things immutably yes
will there be functions support for
database functions and schema
transactions so as of right now we are
going to have a code story code in the
database story with cloud that is going
to be I think different than what's in
pro I mean there's certainly a
possibility right now transaction
functions are not in that code bath
because we would like to do something
better and just to give you a partial
tease of some of the kinds of things
that we think would be better spec
integration so instead of having to do
imperative or functional things being
able to do something declarative with
spec just say I want to be able to
declare validation rules and have the
database take care of it another thing
that we think would be cool would be
able to automate class path enhancement
so you specify maybe an s3 bucket that
says I want all the jars in this bucket
to also be loaded on my node and then
you could call the functions in those
jars inside transactions inside queries
or whatever so we're looking at doing
something that is richer than the
transaction function capability that's
currently in Pro but that probably will
not be an initial ship so that's more a
little bit
down the road yes on the new version are
all the rights still serialized through
the singer trans actor this is a double
pack of candy question for everybody who
was in the training course it's a great
question and I'm gonna end with this
question because it's interesting to
explain this so there is a potential
misconception around how the atomic
achieves the acid properties so if you
look at the weight atomic pro works
there's an active trans actor and a
standby trans actor and there's a
protocol for how that changes right the
active trans actor decides I'm not going
to be active anymore and goes away the
standby decides I'm going to become
active and start processing transactions
it turns out that everything about that
hand off protocol is a performance
autumn ization semantically if all the
processes in a day Tomic pro system
thought they were the active trans actor
we would still have the acid properties
right because the acid properties are
actually guaranteed by conditional rites
at the data level and so what would
happen is a 10 if 10 processes thought
they were the active trans actor and
they all wrote one of them would win and
nine of them would fail and then die so
the the it's it's an interesting
separation another example of simplicity
right the the keeping track of who
should be writing is a best-effort thing
like if you've failed at it you would
still have the acid properties which is
super cool because now in cloud we're
using consistent hashing to pick which
machine machine processes transactions
so if you scaled up you might have a 10
machines 'ran 20 databases in it and
consistent hashing would be saying well
for this particular database this one's
going to apply the transactions the
other machines in the cluster forward
transactions as they come in to that
node which then applies them but again
all of that to performance optimization
if every single thing about that is done
wrong then machines are just going to
race and only ones going to win so it's
different and better in cloud and that's
one of the decisions now no longer a
notion of active versus passive it's a
consistent hash routing based system but
again that's just a admittedly it's a
critical performance optimization right
if everybody was racing all the time to
write it would
work very well as a system but it's not
required for the semantic correctness
guarantees of the system that that piece
of it work at all all right thank you
very much please come back for the
unsession tonight I'll see you there or
I'll talk to people up here</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>