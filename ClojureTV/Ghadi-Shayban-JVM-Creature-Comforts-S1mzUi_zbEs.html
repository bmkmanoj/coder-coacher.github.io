<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ghadi Shayban - JVM Creature Comforts | Coder Coacher - Coaching Coders</title><meta content="Ghadi Shayban - JVM Creature Comforts - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ghadi Shayban - JVM Creature Comforts</b></h2><h5 class="post__date">2014-11-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/S1mzUi_zbEs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so today I'm going to talk to you about
a topic that doesn't get too much love
in our community and that's the the
low-level aspects of what we do the JVM
is is an amazing piece of engineering
it's got man decades of thought and work
and rework put into it it's it's just an
incredible platform and I'm gonna show
you where it's it potentially can go in
the future and where it can relate to
closure so I think I have the honor of
putting the first transducer on on the
slides today but what what we ask from
the JVM is both we performance we have a
lot of Interop we have a lot of
libraries that we can leverage but today
I'm gonna focus on how we can get the
same high level abstractions we have in
closure like functions data functions
that assemble data remembering data and
making new functions we can we can look
for leverage downwards - we can look for
leverage from the actual host platform
and not just the high level leverage so
today we're gonna walk sort of 20 miles
out into the field and we're going to
turn around and look around us and see
what's available I'm not going to
prescribe a particular future I can't do
that but I will what I want to explore
the the many different avenues that are
available to us
so um two of the topics will cover our
invokedynamic we'll do a deep dive into
that and a new framework from Oracle
called truffle it's actually from Oracle
labs so it's still researched but I
think it's a fascinating fascinating
approach and something we should be
aware of in our periphery so before we
get going I have a little bit of my own
legal slide to tell you that that
closure is already fast it already gives
us a lot of abstractions to do
what we need and get the performance
that we require we can use core async
we have reducers we have folders there's
there's so much and but there could be
so much more from the host platform so
we hear about the the premature
optimization quote about it's the root
of all evil but the rest of the quote
says we shouldn't pass up any
opportunities that are available to us
so to get started we have to figure out
how closure goes from the high-level
constructs and how that actually Maps
down into something that's executable by
the virtual machine how do we fit this
on to the JVM all right
I know what you're thinking kids these
days are probably not thinking of
transducers but they could and it's
still we still have to figure out how to
get the high-level concepts like
transducers folders like just simple
functions how to translate that into
executable code and the way we do that
is through byte code byte code is the
way the compiler talks to the virtual
machine it's it's really the common
language most of the 200 byte code
instructions are grouped into about a
few categories we have our control flow
jumping from one set of instructions to
another set of instructions comparisons
go-to we have our basic things that get
things in and out of objects we have a
ton of value manipulations math casting
bit operations shifting your
run-of-the-mill constants there's a
handful of ways to invoke things on the
JVM you can call static methods on
classes you can do virtual and interface
calls on objects you can call
constructors to those the sirum sort of
special cases a two of them two of the
important categories of instructions are
stack manipulation since the JVM is a
stack machine and local variable
manipulations
so when instructions run
they operate on this logical stack they
can place elements on the stack that can
pop odd elements off they can duplicate
them they can do various twiddling of
the things on the stack and things that
need to transcend a few operations too
that need to live a little bit longer
can be stuffed into these local
variables and there's things like
arguments there's a lot of intermediate
values that are generated that you
probably want to save on the stack
between it's between expressions and
between function calls all of these byte
codes by the way are tight and that's
one of the features of JVM specific byte
code that sort of distinguish it from
other byte codes and at least maybe from
machine code on x86 or arm so this is
just a summarized by byte code is
executable data but it's particularly
awful data that deals with identities
and locations and and places so more
more background I don't expect people to
know this so I'm going to sort of play
human disassembler with a closure
function we have a simple function that
takes two arguments a and B and it
returns you a new map taking a and a
socking B at the keyword K all right so
how does this map I've decompiled this
function and put the logical
instructions here so at the outset you
can see that what is generated is some
class that implements closure laying eye
fun it's a the name of the class is an
auto-generated symbol this one's
particularly awful because I ran it in
the repple and that's that's just what
happens so all of functions get iPhone
as their super type before a function
can be invoked we have to sort of
assemble all the information that's
going to be used later in this case we
have to get the VAR a sock and we need
to get the keyword
kay those are going to be constants for
the for all indications of this function
so we load them up in a static
initializer
there's about 25 bytes of bytecode here
and the high level features this we have
two static final fields on this one of
them's the VAR one of them's the keyword
we have to find the VAR stuff it in the
final slot and we have to find the
keyword and stuff that in the final slot
so basically define the VAR we call this
LDC instruction which is load constant
we put the namespace closure core and
then the the name of the VAR a sock
those go on the stack so the stack has
two elements then we call the run times
VAR to resolve that var and to grab a
handle to the bar we do a check cast and
then we put the put that in the static
in the static field same thing happens
for the keyword we called the run times
keyword command and we when we finish
this static initializer so this is
logically like the static initializer in
a java class so this is just assembling
what's going to be used for the
indications of the functions to actually
invoke the function we see that there's
a method generated with two parameters a
and B it will the first thing it does is
it grabs the handle to the VAR puts that
on the stack and it calls this get raw
root method call on it and what that
does is it basically dereferences the
bar that gives you the actual
implementation of the sock rather than
the VAR a sock we cast it to a function
and then after we have this function on
the stack we're gonna load the arguments
we're gonna load a we're gonna load the
keyword kay and then B and then on you
see on on line with the number 18 that
now that the stack is populated we call
invoke and re return we return the
results so that's basically how just
about every every function works in
closure in the JVM there are a handful
of ways to invoke things to call methods
and to return from methods we can call
constructors through special virtual and
interface
calls we can call static calls but the
new instruction on the block I say new
but it came out in in JDK seven and
that's invokedynamic you can basically
think of this as function pointers in
the java virtual machine it was the
first instruction added to the virtual
machine since 95 so that's I mean it was
a big big undertaking closure does not
currently use any invokedynamic
instructions during compilation but so
the point of having this function
pointer is that the JVM used to mainly
be about Java right and Java has a
certain set of calling conventions a
certain way of orchestrating the
execution and when you new languages
come around the block that involve a lot
more dynamism like Ruby or closure or
things that just don't fit the mold
there needs to be a way to signal to the
virtual machine that this is sort of an
atomic operation that this should be
treated as if it was an instruction so
it's not only a function pointer per se
is it's it's really a strong signal to
the JVM so it helps when the semantics
of the language don't quite match the
semantics of the assembly code so all
right this is basically how an info guy
named McCall works you can imagine a
stream of instructions that as the
virtual machine executes them in
sequence it let's say it encounters this
invoke dynamic call the that instruction
encapsulate s' what's called a call
sight this is an actual Java method Java
class that has a few different
implementations but it's you can think
of it just as a container for this
method handle and the method handle is
the is what represents the function
pointer itself this is the method handle
represents the code the call slights
more more like a slot where the where
that pointer is going to be all right so
the this this allows you to change the
target of the call to decide at a later
date what
what that instructions going to do is
the dynamic part of it it allows you to
not write a series of instructions that
represent the same thing but to write it
in stone so the the other part is that
it's it's really about giving the the
virtual machine optimization opportunity
these sending a very strong hint that
this is an atomic thing please do what
you do but treat this as an atomic piece
so you can you can think of that in the
decompiled example of the var and how
you have to put the bar on the stack
then call get raw route to dereference
it that can maybe obscure optimizations
that the virtual machine can perform it
could it's saying the how instead of
just saying saying dereference the bar
right this also helps with the inlining
budget in the JVM there's certain
heuristics about when a function is
inlined into its caller invokedynamic
allows allows a little bit better
control over when things will be inlined
so the main object in invoke dynamic R
is called method handles and these are
low-level representations of function in
vacations there's basically one thing
you could do with them when you have
them in hand you can invoke them they're
just a real they're a real Java class
you can invoke them with arguments
there's two flavors of invoke you can
invoke it with sort of casting semantics
and in exact invoke then there's the
exact variety which will which will
throw an exception if you give it give
it non castable things there's a bunch
of different types of method handles
some to grab a handle on to your
run-of-the-mill virtual and static calls
there's some for field manipulations you
can get you can construct a method
handle out of a constant so these are
not just constants that are in the class
header on the on the on the class file
like strings and and numbers you can get
constants from a database and then make
a method handle out of that so you can I
mean
the database could be halfway across the
planet but you can get a method handle
to it install that in the call site and
it's it's treated as a you can get it
treated as a final variable by the the
JVM and there are some other things that
the method handles can do that we'll
talk about in a second but um the very
first time you invoke the instruction
the call site has nothing in it it's
just this empty empty instruction so it
has to be bootstrapped for the very
first time this happens only once on the
first crossing of the instruction and
the job of the VM will call you back
it'll call one of your bootstrap methods
and the signature of the bootstrap
method just says you have to return a
call site okay and you put a method
handle in the call site the call sites
usually mutable there's an immutable
variant but but that's how it gets wired
up initially other things that you need
to do with method handles are derived
them from each other you can get a raw
handle to an instance method but then
you can transform it in certain ways
mostly with argument manipulation and
you can compose method handles together
so argument manipulation you could
insert values into slots and then get a
method handle representing the the
original method handle but with slots
already pre-populated like like currying
you have some certain method handles
will will collect things into an array
and spread them kind of like apply some
of them will cast and there's all kinds
of arbitrary argument manipulation you
can do the other side of method handle
transformations are are composing them
together you can chain two of them
together I actually tried chaining
method handles to do to do closures a
function composition that's pretty
interesting there's I think there's some
some Headroom and performance there that
you can also do exception caching and
there are a few more method handle
transformations but you might be asking
alright why why not just encode the same
transformations but to encode them with
the normal bytecode
like why not just write out the manually
sort of expanded execution semantics
that you that you're trying to achieve
well it's a you don't want to be
rewriting class files willy-nilly it's
super hard it's expensive so you want to
have a little bit of indirection and and
and be but if you have a series of
instructions
it makes the VMS work harder in
determining what your actual intent was
so just just treat it as a logical
atomic handle all right so let's let's
zoom into guards because guards are some
of the the most important types of
method handles there's two basic forms
of guards the first one is called guard
with test and you can think of this as a
method handle that encapsulates an if
conditional so you give it three you
give it the test you give it the target
method handle if it's true or the
fallback method handle if it's false and
it gives you back a method handle that
does all that then the other type of
guard is a switch point switch points
are designed to be understood by the
virtual machine you think of them as a
hot bath and a cold bath
it will always call the hot bath until u
invalidate the switch point and then
it'll shift over and then it'll always
call the fallback the cold bath you can
only do this switch over one time after
that you have to read you have to
recreate the switch point so I'm these
two guards deserve special mention
because you can do sophisticated things
they're their composite method handles
but really guards are primitives when
you're doing language implementation
guards are everywhere so what can we use
them for we can take a look at the VAR
back to our function that takes two
arguments there's only one var in here
and that's the associate is almost never
redefined I hope you're not redefining
this so she'll have problems but um it's
effectively final so the only time you
would really redefine a var is at the
repple time we're going to
just about static bars not thread-local
dynamic bars so and the basic operation
right is to get the raw route the
dereference it so if we encode this in a
switch point what would that look like I
have a branch of closure that does this
for 4 VARs and it the performances is
pretty interesting
I'm the basic idea is your hot path is
gonna be a method handle to the value
inside the VAR you're gonna make a
constant you'll dereference the VAR grab
the value and make a constant method
handle and you're gonna install that as
this the hot path in the switch point
and whenever that var gets redefined
we're gonna invalidate the switch point
and we're gonna do some fallback path
the fallback path all it has to do is
return the new value of the bar and
relink this entire call site into with
with a new switch point so you get a
constant you switch it over and you have
to sort of relink at the at the end the
performance that i've experienced on
this was really really promising at
least on micro benchmarks it it allows
it allows as much performance as the
there's a there's a branch on closure or
github off the master now the called
direct and it's just about as I mean
it's it's the same performance as as
that branch that that's pretty
interesting so there's other possible
applications we talk about VARs there's
protocol invokes you can maybe use the
the spread and collect things to do
apply and varargs and closure that's
probably a more invasive change I
haven't had enough time to even begin
messing with that you could do it for
multi methods to when you're multi
methods sometimes they're just simple
switches between dispatch statements
sometimes you use the hierarchy features
too but it would be nice to have sort of
some some optimizations there I did
experiment last week with the reflection
to make a call site when you when you
don't type in a function and yet you
have to reflect and it warns
it would be nice if reflection only
happened once and I made a one of those
mutable call sites where it would
reflect the first time then when it
resolved the method handle it would just
install that as the as the as the method
handle for the future so that works up
pretty well so next let's play human
disassembler again and we're gonna look
at these keyword lookup sites a lot of
people don't know about this
optimization that's in the compiler
right now but basically when you have a
function and it calls a keyword as the
first parameter there's an optimization
that occurs and normally you just want
to map lookup but sometimes that map
sometimes the something and this
argument is a record and if the record
has a foo field why do a map lookup
right that doesn't make sense because
well if it has the field the Java
already has byte codes to get that field
by name directly that's what that's what
the JVM does so there's this
optimization that's there for for
records I don't expect you to read this
but this is this is from the wonderful
tools emitter JVM project this is a
representation the closure
representation of the byte code that is
emitted every time you do one of these
keyword lookup call sites any time that
there's a keyword at the very beginning
of the form so that's like 20 byte codes
there it's it's it's a lot it doesn't it
looks like a lot but it doesn't really
cost that much it gets optimized very
well but if we were to think about doing
this as call sites with invoke dynamic
how would that work well basically you
have two cases on the left hand side you
have the the map case where the argument
is just simple map on the right hand
side it's the record case so when you
have when you have the map case you want
to make your test check is this a record
okay if it's a record we're gonna switch
over we're gonna go to the go to the
right hand side but if it's not a record
we're just gonna call that middle handle
we're just gonna call the run times get
get
function and and we can encode that in a
method handle and we'll just return the
value but otherwise if it's a record
you'll have to call the records ask the
record for its proper value and relink
the call site to the right hand side now
so when you relink the call site you
treat it as you treat it as if the the
indication is going to be a record in
perpetuity but not only any record it
has to be the same class of record
because the Foo class the Foo field on
this class is going to be a completely
different field than the Foo field on a
different class so the guard in this
case is going to be are you the same
class as the previous thing that was
seen here but if you are let's just grab
your foo your Foo field and return that
and if you're not we have to relink the
the call site we're gonna call this son
we're gonna ask the call site to relink
back to the left hand side so it's not
all wonderful for invokedynamic there's
a lot of there's a lot of hype about it
it's a it's a wonderful technology i
think i think one of the the v8
engineers was saying it should be a
feature in all VMs it's a really nice
extension point you can think of it as
as like kind of like tag literals in
Eden and transit and fresh and it's the
same sort of concept it's an
extensibility point there are warm-up
problems initially when you install a
method handle it's interpreted but it
needs to get hot and sometimes sometimes
it takes a long time for it to get hot
and compiled there's no story on Android
still doesn't support it doesn't look
like Android will ever support invoke
dynamic and because it's interpreted the
stack traces are crazy if you think
stack traces are bad with invoke dynamic
it's I mean there's a lot you barely see
your code there so what else um so
another couple things about invoke
dynamic it could be possibly used for
lazy loading
when you load closure core there's been
some talk about it takes a long time to
load closure core but it's possible to
defer that to essentially defer loading
behind one of those bootstrap methods
and just only when the only when the
VARs dereferences do you actually load
the load the class itself and apart from
that there's some interesting work by
Zack Talman to unroll small collections
there's a there's a patch that is being
considered for the next version of
closure that sort of fast paths
different collection sizes and so it
would be really interesting to use
invoke dynamic to to encode these vector
creation sites in in the bytecode has
invoked dynamic and to encode them
symbolically that way that way future
versions of closure could maybe iterate
on iterate on the implementation but the
binary interface the instruction could
remain the same that that's interesting
that's a that's an approach that Java
itself is using in Java a the lambdas
are are actually invoked dynamic call
sites even though Java is a static
language but it allows the I mean the
abstraction allows you to iterate on on
either side of the instruction so the
biggest consumer of the actually the
biggest producer of invokedynamic
instructions is the NASS horn project
this is a crazy project from Oracle it's
part of JDK 8 it's it's a rethinking of
the Rhino engine so it's really a way to
make sure the invokedynamic
implementation is awesome it does all
kinds of compiler optimizations on
JavaScript it does optimistic typing it
actually pretends everything's an
integer instead of an boxed object it
has all kinds of sophisticated things
and it's because JavaScript is really
really hard to optimize so this function
to double something I want to say it's a
function to double an integer but it it
could be anything that that argument
could be an object it could be anything
so even though it looks definitely like
an integer to
to somebody reading it but JavaScript if
you want to make something from an
object into an integer you have to call
this value of method and you would think
if you're gonna encode this in byte code
let's just call the value of method and
then save it since we're gonna double
this integer Lee why don't why not just
cache the value well you could have
monkey patched the prototype to value of
and made it stateful so you can't even
that you you have nothing you have to
account for the worst
so it's interesting how NASA warren
approaches that they use an internal
representation an ir that's a sort of a
graph of how the language works
the idea is you do the optimizations
before you spit out bytecode when they
spit out the bytecode this is this is
really just an amazing piece of
engineering what they do is they just
pretend everything's a primitive they're
like they're like alright it's a
primitive until it's until it's proven
false and they omit by code that just
assumes primitives and we'll throw an
exception when it's not a primitive so
what they do is they wrap it in this try
catch method handle and when when it's
not a primitive the try catch handle
will will will catch that exception but
the exception could have occurred
anywhere in the middle of this function
so you might have work that you've
already done and the exceptions just in
the middle and you have to figure out
how much work has already been been been
accomplished when you throw an exception
the entire stack is blown away and
replaced with the actual exception so
they have to squirrel away all the
intermediate values into local variables
and so they throw this exception they
have to figure out how to get from the
middle of the function to the end they
do this with this rest of call and then
that that rest of call is like a
continuation it only happens once and
the next time through the function they
rewrite the function with wider types
just less conservative so this is nuts
and it's it works though it's achieved
incredible perform that's really
competitive with v8 and it's implemented
in in the JVM so that's just amazing
stuff so it's amazing engineering but
why waste it all on JavaScript right so
like why not make it reusable and that's
exactly what the NASA foreign team is
exploring right now they want to maybe
think of a dynamic bytecode and think of
a way to use the - horn infrastructure
for all kinds of languages so what what
can they extract for maybe like a
dynamic language runtime so we're gonna
switch with switch gears a little bit
and talk about a couple challenges
there's an interesting quote from TR
Crump a few years ago about higher level
higher higher-level languages with with
functions and combinators but call site
based optimizations like we saw with the
keyword lookup sites could be
fundamentally at odds with higher order
functions it's a it's an interesting
thought this is sort of solved by
tracing jets where a tracing JIT can can
sort of optimized through method
boundaries that really helps but we
don't have a tracing JIT on the on the
JVM
there's some interesting there
interesting research there so the idea
is for inlining we would want to
specialize a caller of a function sorry
we want to specialize a called function
differently depending on who's calling
it so if you're if you think about
reduce we want to not only specialize
the implementation of reduce but we want
to specialize the function that we're
using that we're reducing with we want
that all to be inlined
to the specific portion of the program
to portions of the program might call
reduce and they might call it in
different ways but in consistent ways
this part might always call it with a
vector this part always the map but the
actual implementation of reduce has to
account for all those different
implementations so that's that's the
sort of the challenge with with
languages so well shift gears a little
bit to an interesting project from
Oracle labs in Europe called growl and
its sister project truffle brawl is
basically the hotspot infrastructure
inverted and made useful in userspace
moving a lot of the reusable bits out of
C++ and into Java they have assemblers
for all kinds of backends even GPUs the
actual compiler does crazy inlining the
compilation units are very large in it
it does sophisticated escape analysis
which is the active realizing that an
object doesn't doesn't escape the scope
of the function and when it doesn't just
tear the object apart get rid of the
headers and just store the fields in
registers so that it it's really really
good at escape analysis so truffle is a
is a language framework that's
implemented on top of crawl it's a very
simple model so basically you write your
you write an AST interpreter in Java of
your language think of the tree as a
function the root node is entering into
the function each individual node and
the tree is an atomic operation in your
language alright and you encode your
language semantics directly in Java
using the truffle API and it takes care
of the rest it's a it's a really
interesting design so so far there have
been a bunch of different languages that
have been truffle eyes some of these
have been written with a super small
team sometimes even one person starting
it's really amazing and it's kind of a
testament to the simplicity of the model
let's zoom into a node alright we think
of a note an addition node the first
time truffle executes this addition node
it doesn't know what the types are so it
just punts ok it has two sub nodes which
are the arguments from the function
frame and the first time through its
when it tries to invoke it sees that the
type is an integer so the node rewrites
itself into an integer node that just
assumes it's going to be an integer in
the future
so this is optimistic this will
specialize the node optimistically and
if that's ever disproven by the the
types changing on one of the arguments
it'll rewrite the node into a generic
addition node which isn't
as fast okay so the nodes evolve nodes
can involve not only by getting more
type specialization they can also if
evolved by inlining other portions of
the tree so think of the the Asaka bar
that we're calling in that in that
sample function earlier why not just
grab the entire tree of nodes for a sock
and just Transplant it into the person
the the stack frame that's actually
calling a sock so you can do language
level inlining and truffle even can do
inlining for you so it's all about
moving these trees of nodes around so
what's the point it's still an ast
interpreter those are supposed to be
slow but what they do is they queue it
for compilation they keep once the tree
evolves and it gets stable enough it
gets it just gets fed into growl and
growl just me grinds it and gives you
back really really nice assembly it does
all the the compiler optimizations on it
and that's the basic model it leverages
growl similar to the way closure script
leverages the Google closure compiler I
think I got that right so if if
something's been compiled and some of
the assumptions about nodes get
invalidated it bounces back into the
interpreter the nodes will evolve
they'll get more appropriate and they'll
get queued for compilation again so it's
it's sort of a cycle JRuby is the most
sophisticated implementation of truffle
I think this is a representation of a
bunch of nodes in in a JRuby ast you can
see there's a check arity node in there
that's that's when you enter the
function there's writing and reading
from from local variables it's all
direct it's all really easy to implement
so the the point if this is the inlining
operations it's really you can think of
it as macro expansion for your code you
macro expand into more and more and more
nodes my inlining is the granddaddy of
all optimizations it enables the rest of
them to perform you have to figure out
when you want to inline you have to
figure out when to stop in lining and
those sort of
this are still sort of heuristic based
but different languages can do different
things so if you take this to its
logical conclusion you have this project
called truffle C which is an
implementation of the C language in
truffle I heard about this this summer
and I thought why like this doesn't make
any sense how are you gonna interpret C
and make it fast
right so what they do is they just
represent the entire ast a a C let's say
it's like a C extension in a ruby in a
ruby program you you implement the
entire ASD and what you can do is allow
truffle to inline trees of C into trees
of Ruby and likewise trees of Ruby into
trees of C so you can have inlining
across language boundaries and that's
super it's super amazing they can even
inline function pointers optimizations
that GCC can't perform because GCC has
to is ahead of time you have to account
for the the most pessimistic case but if
the node just sees hey I'm always called
with the same memory address why not
optimize that
so truffle is still research it's it's
still ongoing there's some it's already
proven to be extremely performant
there's a couple downsides you have to
wait for your language to warm up and
you also have to wait for growl since
growl is implemented in the JVM you have
to wait for that to warm up too so
you're kind of paying the warm-up cost
twice it's still single-threaded
they're fixing that currently but that's
just a that's just a current limitation
but it would be interesting to know what
ideas can we leverage directly without
even using truffle or growl are there is
there value in this model as a as an
actual framework itself could we call
growl directly like somebody calls LLVM
for their for their language
implementation there's some there's some
value there it's made a little bit more
difficult that closure is not a language
that
is trying to be the best Ruby or the
best implementation of something else it
really tries to interrupt with the host
so this is these are all the interfaces
that are implemented by a vector and
there's a lot of them so we I haven't
really dug into how you would model this
with truffle but that's an additional
challenge but the value prop for for
truffle is right the interpreter just
directly model your language don't even
worry about code generation let growl do
it right just leverage it as the
meat-grinder and it calls them to
question you know why even think about
byte code in general it seems it it
seems like there there could be a lot
more power if we if we think a higher
level so before I finished up I want to
just inject a little bit of personal
opinion this is my this is the personal
opinions section of the talk where are
we in the compiler it is fast it is
simple it's great I've been
experimenting a lot with invokedynamic
and in certain respects I found a lot of
performance improvement especially with
VARs
I haven't found much improvement with
changing the call sites of protocol
methods so I mean you can win some you
can lose some it's in general though I I
don't recommend yak shaving on the call
sites I've been really it's been
interesting it's been fruitful but it's
not really what what closure as a
community what we do best we really want
to leverage tools in a sophisticated
fashion so um we do have challenges we
have challenges with inlining we have
challenges with making fewer boxes more
primitives we also want any improvements
to still be deterministic performance we
don't want to have some some sort of
performance cliff that you know hits you
when you when you least expect it and we
we obviously want any compiler and
enclosure to remain simple right so um
these are challenges as I mean Java is
beginning to
faster and dotnet was open-source last
week so maybe Java will even move faster
than then it's already beginning to move
so also these opportunities invoke
dynamic growl truffled the amazing tools
analyzer framework there's so much value
to be had and I I just want to encourage
everybody who's interested in this
low-level stuff if if you ever want to
jump out of the the high-level
abstractions and and deal with low-level
stuff it's fun it's really really
interesting work so thank you everybody</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>