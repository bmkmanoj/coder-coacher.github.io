<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>spec loves data structures - Michał Marczyk | Coder Coacher - Coaching Coders</title><meta content="spec loves data structures - Michał Marczyk - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>spec loves data structures - Michał Marczyk</b></h2><h5 class="post__date">2017-08-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LGGV7nxDghg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi so today I'm going to talk about data
structures and various approaches to
making them robust and well I think what
I really like to say as production
worthy why how do you make sure that you
did success production where we went
implementing it and before I get to that
I just like to introduce some terms so
what are big detectors well data
structures are concrete realizations of
abstract data types
now abstract data types are basically
collections of operations that let you
construct and interact with instances of
those apps of those abstract data types
and axioms that describe the
relationships between the various
operations so for example for set you
could write down axiom like this one
which says that for any set s it is the
case that for any X for any Y the set
obtained by con joining X onto s
contains Y if and only if and only if s
already contains Y or Y is equal to X
and so any interesting ADT you'd
expected to write a number of these to
capture adequacy or what it's all about
so when when you implement a data
structure them then these axioms are a
form like the foundation of of the
contract that this data structure
presented to users but for it to
actually be useful for the data
structure to be useful it it tends to be
necessary for to make further guarantees
right certain complexity and performance
guarantees related to well how how
quickly operations
complete both in terms of their
simpatico and in terms of the
performance on real-world hardware and
also things like google use of memories
a structural saying in the case of
persistent data structures so so when
you publish the data structure you make
a certain promise you users and it's a
two-prong promise generally so so one
part is that okay listening here it's a
black box that that obeys this ABT
contract and then additionally it is
quite a foreman say and these are the
performance characteristics so it has in
the in the past few years become
received wisdom in the community I think
the black box generative tests are the
way to go when it comes to verifying
compliance with with a DD contract and I
think this is fantastic and this is
totally totally the way to go even if
you go to the trouble of formally
verifying correctness you still want
some tests and the generative tests are
best kind when it comes to data
structures in to do things like like the
axiom above and then obviously obviously
with the data structure in hand you
always need data you always use
benchmark say some some real world or or
reasonably close through your world
information how it actually performs on
actual Hardware on an actual JVM and so
on and if you have a robust and written
off suite of benchmarks then you can you
can get some information on whether the
the actual behavior that that data
structure matches the promised
asymptotic say it's a very
coarse-grained thing though and it makes
it less coarse grains while keeping so
the black box native if you have to make
it extremely expensive as I take ages to
run it's not very practical now in this
talk I'd like to make a case for white
box testing
generative testing of data structures as
a way to verify internal invariants that
vector form
scanties of data structures and I'd like
to suggest that that it is crucial that
in addition to our black box test we
also build this these white box tests
and they can provide
that's why good value and while I'm a
filter analysis at some points in the
presentation the suspect can be can be
useful when doing that but before we get
to that I like to just give you a
selection of interesting bugs that that
came up over the past several years that
I found particularly inspiring and that
kind of led to all this free interval
that two items here but one of the maxi
hides two bugs so okay so let's move on
the first one was reported in 2013 by
Zack bellman and well basically this is
how his collection Tech library burst
into the stage like screaming I found a
bug in your position hashmaps writer
that called my attention suddenly so the
story there is that when when which
first developed the system has map it
was a persistent on new data structure
nice transients later this into closure
and so so when it was first implemented
a persistent head map was free to make
certain assumptions about about the
internal structure of its nodes that it
standout the the late edition of
transient hashmap invalidated and the
thing is some of those cases actually
missed and we only discovered by a
generative test one once discovered this
is reasonably simple to diagnose because
you could get a an actual problematic
instance very quickly just by following
the the outfit of the generative test
and and so he says well to fix but well
it was very nice like you could
go
for several years I think with with bug
in place that is just let had the
property that you had to be somewhat
unlucky to run into it and I mean you
know if you've run into something with
once in a blue moon you might not even
think this is necessarily a bug so okay
so that made it clear that the
generative testing is the way to go and
it may be clear the collection check in
particular is a great library to use so
here's the commit message key stuff six
the dog so when I developed beta AVL in
2013 I didn't have this off this soft
test fit in place initially but in the
early days of January 2014 with this
early collection check success first in
my mind like I knew I wanted this kind
of thing in place I while it in actually
before before crystals messaging again
made it into a release version of
tourism and just to give you some
background on this library because I'll
be using is of those examples at the
dock what they tell you is is a
conceived library it in ferns drop-in
replacements for those clovers and
clover script sorted maps and sets with
a rich API right so they support the
transient API and they also support a
bunch of operations like empty and blank
off which is basically reversals and
nearest neighbor the Cubs and splits
which are like closer cosplay dead but
they return subsets or sub maps and and
sub range is a similar to sub seek but
again in sequence a sub set or sub map
and well with collection second place
and obviously those other tests size
using the reasons we help you grow
bus'ness of the library and it's it's
it's awesome ever use and the
so and well okay so so so so good to see
it as he's actually being used with
collection second place I selves as well
okay so surely at least a map API is
fine so yeah I think it'd be good about
this one until until August 2016 when a
bug report landed its what's submitted
by Dyck Weber now I'll quote is his
description when I split the map and
then try to split again a split again on
the right result the split phase to turn
we go well so so I conducted an
investigation and again well he was he
was kind enough to submit to submit a
patch with some generative testers are
now part of the test suite and will
hopefully prevent any inversions here
but with this generative test in place
is actually fairly simple to pinpoint
the problem and fix it I'll I'll quote
the post-mortem that I published after
pushing the changes the root cause is
that ourselves 0.0 13 no drawings get
miscalculated in one of the cases in
split ultimately this means it is
possible to construct a map that
actually holds the expected entities but
this count is less than it should be
well so so so that's that's really
really unfortunate and the reason it
took a while to discover perhaps that a
fossil it was possible to use they came
here in such a way that you'd get some
value out of it but never like never
observed this particular breakage
because of like oh I guess an into I
said no well the way it was various
features in fact it's so so big of
masked in some cases it wasn't relevant
to to certain types of users but still
well it was a case of off I mean
completely broken contracts rightful for
one operation so mmm
so well I I didn't get to it right away
but but at this point I started thinking
about and them distracting in various
ways eventually I got around to putting
together a new invariant test because I
didn't want any other so I decided okay
well it's time to reach into the
internals and verify that randomly
generated instances obey all the
invariants that I expect them to obey
cause well if I know that then surely it
will then be possible to just the
library to work correctly and well I was
kind of expecting to just put them in
and reassure myself that everything's
fine and move on right what happened
instead was that I put them in and
discover that everything was not fine
then fixed bug and then Sophia short and
moved on but the thing is that her that
the problem that their beasts tests
these new tests uncovered and is
something that there's well there's very
little chance of the user observing
because because the thing that has
broken was was well what I guess one of
the cases I'm not happy with this one
but there was a scenario in which he
could you get the form an operation an
update operation of the tree and a
social or this house and it would get be
performed correctly in the sense that
the binary search he would be would call
that the expected entries at the end but
the rebalancing step would actually not
be performed and so you could you could
find yourself in person over off every
purportedly AVL tree they've actually
actually no longer baked the AVL
invariance and if you happen to like to
make multiple modifications to to a
problematic segment of the tea or maybe
it could because observe some operations
behaving a little you know more slowly
than you'd expect
nothing invisibly break but still it's
so it's not something that should happen
and it's still compromised phones
grantees or certainly departments at
least mmm Sergei it's obviously
obviously these invariant oriented tests
are in place now and hopefully they will
prevent with your sympathy but but the
main point I want to make is this kind
of thing would not have been caught with
collection taken anything like that site
because give it the in no way did this
break the observable contract why if you
had to reach inside so I'm brand what if
it around the same time I was
implementing priorities as cues for
closure and I publish actually I
actually presented this library at last
year to go drive so it's called PS q CF
j SQ stencil priority set queues and to
give you some context they basically
sorted maps when you look at the keys
but then we respected values they behave
in a priority queue like fashion and
then there are some operations at bring
the two aspects together so when
developing this library I had a
satisfied and very implicit in place
right away right is it's been the
initial test suite and I still use
collection checks with that well I mean
I use collection check - to validate the
the black box contract but then I also I
also use some of the internals of
collection checks back to some some
functions that might private that that
allow me to construct instances nicely
vandalize instances of my priority set
queues that I can then subject to
further psq specific operations and
check whether the the results returned
satisfy satisfy the invariant I'm
interested in less a type of like I
think 50 for generative testing the
testing and 14 of those may be use
satellites invariant
and having that in place early on was
fantastic I didn't end up breaking the
invariant very often but when I did I
found out right away it's it was a great
development experience so at that point
I knew that okay well going forward
whenever I implemented data dr. this is
what I want to do the only question is
well can I can I do something better can
this be improved is it possible to build
better tools to facilitate this kind of
testing and so on so so this is able to
talk about oh and and the expression on
this slide I don't really recommend
reading it here but it's just the the
the main end expression in in that
satisfies invariant I guess so it's
basically a huge letter form and and
then this is its body so so the
situation now is that we have one two
data structures right whose invariants
are being tested in a white box fashion
and we reach inside and check that
everything's fine but but the instances
which we subject to these checks are
still black box generated in the sense
that we call functions in the public API
typically starting with an empty
instance and you know building up large
instances
well not the sliding census there's more
instances with more complex histories
right we might so some keys do so some
keys cond some entries and so and so
forth and then at the end maybe displace
or whatever a PS q coz supports the
entire behavior API for it's sorted map
aspect so there's number of operations
to then apply and test and for invariant
reservation and I would say that this is
actually quite good when it comes to
when it comes to providing guarantees
related to the to the AVP contact mercy
and and also some guarantees related to
the data structure contract
when it comes to the shrink-wrapped
package right now I put out this this
package this library over here to
library that does this with this kind of
test in place it's reasonable to feel
someone confidence particularly if you
actually read it and one is yourself
okay well it probably does work as
advertised right because it's it's all
being checked
but exactly what a at least one more
thing we could we could try and
accomplish using this kind of test
Suites and that is a deeper
understanding of the implementation
right suppose you want to evolve it
suppose you want to build a more complex
data structure taking an existing data
structure starting point right then it
is really necessary to understand the
thing that exists so that we can build
this other thing that you want and also
when designing tests for an
implementation you really do want to
have intimate knowledge of it well it'd
be like white box test for thee mmm so
okay so so when so maybe maybe you can
still do better so that we can offer
even better guarantee for the things out
package in terms of our ability to say
explain to the users exactly what the
date such a does and how it does it and
what it can be used for if you you know
people to make modifies and so on okay
so at this point finally it's like
respect to come on stage now I will I
will say up front that law it doesn't
seem at first glance to be useful for
validating low level invariance now it
is protocol based so I can imagine maybe
trying to make it directly useful but I
actually actually don't feel like doing
that so far it's because it's also
possible to just build math based
representations of the data structures
right like say if they tie vo has a
number of def types which which have
certain cues and then once you descend
into the views or some of them hold for
the instances of the best type
introduced classes well here we can we
can just have maps right and key
those maps that correspond to fuse and
then then with that map based
representation as a whole to do at least
two things one thing is that you can
actually implement all the relevant
operations using this representation and
this can sometimes be useful but the
other thing is that you can you can
provide some conversion functions that
take well actual say data your maps and
nodes and convert them to map these
representations of AVL maps and nodes
and then this there will be a secondary
function that converts them back right
so both of a particular make sense but
but particularly the letter that the
letter is is relevant when when testing
the actual implantation right so this
was I'm mostly going to focus on now
what you want to do with the map base of
limitations is you want to you want to
spec them and you want those back to
capture all invariants that you care
about so for example we'll get to some
examples a minute but things like like a
year invariants like by new searching
variances on you want to capture them
using specs and you want to make sure
that you can then generate instances
that satisfied the invariants using the
generation machinery in spec and test
check so to that end it is likely that
with them will be necessary so you want
to provide custom custom generators
because well well first of all you
likely to have to do with some classes
that expect doesn't know how to do a so
comparator is once this class but then
also if you have complex invariants that
span multiple views um lot of these
complexes aren't really then speckle
want to be able to understand them and
magically generate and precisely the
instances you need right it'll keep
trying and in principle it would
eventually four keys right if you gave
it in time but
but in practice it's ice under times and
then gives up so chicken you can start
with very naive generator that but often
often times it is necessary to take them
but what what's nice about this though
is that is that the fact that spec keeps
trying like when you register a
generator first back full and then
attempt to use it then it won't to give
you back whatever the generator
generates it'll give you back the things
that the generator generates it only if
they obey the spec right that means that
you can use over-broad generators that
do generate some malformed instances
because it sometimes it sometimes it's
easier right easier to accomplish good
cooperation this way so that's a
balancing act but but it is a very
useful facility mmm and finally what
what's nice about this all setup once
once you want to build it up is that
potentially it may be able to generate
unreachable instances meaning instances
of the data structure that obey all the
invariants that you thought was right
and that you expressed in your specs but
nothing else right and so so conceivably
could get instances that you couldn't
even reach using the public API right
and I think this is good I mean this is
amazing because once you reach such an
unreachable instance two things can
happen right shake you can you can apply
some some operations to it and discover
that okay well all the operations might
go crazy because this is not something
that the data structures people to work
with and that's good to know because
that means that you don't actually know
what invariants are right clearly you
rely on some invariants that you have
not yet made explicit and then the other
eventualities that everything's fine
right and then well if it's everything's
fine then that's also an interesting
thing to know because well maybe you
want to build something on top of the
data structure make these unreachable
instances will somehow become relevant
so the ability to make that possibility
explicit is great I think and just to
give you an example of what suspect beta
structure might look like well here's a
few things are built around beta AVL so
that to my specs there's a nodes back
and an AVL Maps back at the division of
responsibilities is that node checks
that checks height and banks and also
the AVL invariant where AVL map is
responsible for checking that count net
is the actual node count in the tree and
and also that the the tree is actually a
binary search tree now it might seem
like that the responsibility of node but
there are several problems with that one
is that well you have to provide the
compare your comparator to the nose back
first of all and no way to avoid that
which would be fine but it would mean
that that your math laser presentation
would be as when we asked close match to
the actual low level implementation so
so a bit of a trick of the but in any
case it is much more suitable to handle
generation at the top of the tree
because when trying to generated by new
city I well I guess I find at least that
it is easier to generate the safe of the
tea and the keys to be inserted into the
tree separately so you didn't leave the
safe and then you put the keys in the
right places in order right so so it's
safe or to do it once at the top and to
not worry about key order in in node I I
do have a separate spec for actual BST
node that's separate and they've
actually calls on the generator five
year map and
generator is useful a number of tests
and now I've experimented with a number
of specs for keys and values just to
keep the simple for this talk I included
like the simplest ones I used actually
good enough because key using just
integers for keys what kind of things
respective you want to do more in a
prophetess feed but but at the same time
just like with a black box test feet in
place you kind of know that the data
doctor basically works so so then it's
it's reasonable to use a very simple
domain for keys when on validating some
structural invariants and and what what
it also does is it eats things a little
shorter which makes it possible to just
about set them on slides which is also
important so so this is what node looks
like hmm and it isn't see necessary to
read this I'll just I'll just comment on
a few crucial details so first there's
an esky spec that checks that the right
keys are present and a left and right
just resolve to node again so so your
sub nodes are validated which means in
particular that you can rely on their
height and their rank being correct and
there's a bunch of predicates this
consistent high question mark consistent
rank this mark a base a vo and very
impressed to mark these all do what what
do you expect
and finally there's a there's a
generator the generator is a custom
function that actually I don't think
I'll go to the slide but what it does or
what this iteration of it does is it's
interpreted size parameter to mean the
height of the tree that you want to get
now at 3 an AVL fee of 100 million items
might have a height of 27 say so
so you can't really realistically
generate generate deep very deep esight
so so it is important to apply the right
kind of scaling this this may not yet be
perfect but but it is reasonable AGL map
is by expecting this way this is the
wrapper object in in data i/o so this is
this comparator which is just a compare
talk versa tree account and meta map I
left out has values for for this set of
examples we check that that we obeys the
BST invariant using the the comparator
in in behavior map object we check that
the actual node and entity method
account specified in the wrapper object
and and we done with the stack itself
the rest of it is is the generate of it
which does a number of things but but
you'll notice that it's possible to as
possible to reuse generators for for
various specs that are relevant here by
calling s10
so so that's that's quite nice and well
I think it keeps us in for
and finally what with these these things
in place what you can do is you can you
can make a custom property custom test a
property that well Miguel go through
this it generates a map based
representation of an angular map which
is well probably reachable I don't think
there are any unreachable instances in
date a via but if the world and
potentially you'd get one of those and
then vesicle to a collection check
internal private function the generates
math oriented operations and with these
two two things generated we we convert
the math days of presentations IVR map
into proper AVO map
we apply another private collection tech
function to build up a more interesting
AVL map and then we convert it back to a
map based representation and check
there's like this back meaning that it
actually always all those invariants
that we previously thought about and
obviously we do rely on on these
conversion functions for correctness but
well Bacon themselves obviously
generatively tested and that's obviously
fought so it they're also extremely
short and simple functions so it's
easily trust them yeah so this is
actually quite good already but it turns
out we can we can do better the way I
discover that we can do better that I
again before before I've done with this
I we implemented an experiment the key
teachers of data AVL using the map based
representation actually well to say that
I reinvented Emma Gerber selling what I
did very slightly because I basically I
took the existing implementations just
converted them to the math base of
plantations and then I started adding
specs function specs and using closures
back test text to to test them and it
turned out as well okay so I so what I
got was a bunch of test results most of
them successful to test yourself but
some of them some of them including some
failures because of a typo here or an
omission there or what have you
with like the core message equivalent to
what for all would tell me like okay
this thing broke right and this is the
input of the bookid but then then i'd
also get a full spec message pinpointing
exactly what broke right like this thing
poked and this is how like this is the
specific predicate that there's hidden
satisfy so enough of it
plastic so I then turned around and and
applied the same test basically to the
actual data of your functions using
conversion functions unwitting layers
and okay well I get same results
actually all passing wheels if I
remember correctly and now I have to say
that like I don't want to make a
statement that I don't fully believe in
so I'm not going to say that this is
this is something that can possibly be
done without specs but it's similar to I
think this year's close the West Daniel
Solano Gomez have an amazing sensation
about packing a legacy system with it
they wanted to place using spec I think
you made the point that ok well well
they use back because it seemed
interesting for this nice new tool and
they have happy with it obviously in a
different language you could not have
access to spec then maybe do something
else you can also compute lead your own
machinery but the thing is that that all
works and it has a number of features
that come together nicely so I think
this has also been my experience with
something like spec available out of the
box in closer
I don't feel terribly inclined to to
build my own thing because this actually
works very very well indeed now don t
want to do this right once you provide
check based tests or for all your
internal functions what becomes clear is
that is that function specs could
actually be used to improve on on this
thing and the way the way to do this is
while suppose I suppose we want to make
sure that the split key operation in
data VL which takes they save your map
will set enter key and returns a vector
of subsets or sub map
of the original settlement that includes
the keys less than yoki there's the
sizing the vector the third item in the
vector the same thing but on the right
side then the middle item is nil if the
key the split key is absent from the
collection and it is the act of the map
entity or the key itself in the case of
a set if it is present in the collection
so suppose you want to make sure that if
given an arbitrary data ideal map or set
that obeys all the invariants that we
know about split key produces correct
AVL Maps and sets there's also obey all
environments that we know about well you
can you can write a helper function that
takes takes as input the thing the
things that you expected generate for a
test that will check this and in this
case you want in a starting point so
basically starting like an S feed a V or
collection you want some actions to
apply to it using products in texture
halves or some other operation runner
and you want to split key and then you
you build a bunch of data structures I
to you while you actually apply split
key to an interesting a yellow
collection you also maybe take some
seeks of the relevant data structures
and then you return all these things in
things of interest in a vector or a map
or whatever some some sort of data
structure and then you then you provided
a spec for it that actually doesn't even
need to use the SN part of function
specs as it it ends up being the case
that the red part already captures the
relationships of inputs and outputs
because by the way the way that he
supports this the relevant inputs are
included again in the output
and your your axe back handles
generation obviously so ADL zero will be
an ideal map and initialized EMF split
key will be an arbitrary key and actions
are the spec I use for actions is called
CC editable sorted map actions which
means that it's a collection of well a
sequential collection of of actions
applicable to transient enables 40 laps
generated using collections area and
service working function takes and then
it outputs a task with a sequential data
structure that includes an AVL map
another ideal map of the nng a map ng
and then yet another idea map so this l
AVL equation mark and our AVL part these
are the outputs of blood key and a few
additional data that are useful for
validating things and it texts that
things behave as expected actually
hmm I think I put a shorter version like
a short initial version on this slide
the version that I can't use has one
more branch branch in the at the end so
if you actually read this and spot that
something missing or it's probably the
locally but the deficits on the side and
and to run the AXA to make this into an
actual test you do something like this
like this a success a successful check
predicate because because the tech
function returns a map that describes
the result and you have to fish out the
actual two or fourth or maybe it's no
but that tells you what the tests were
successful out of it so that's this
function that does that you run your
test 50 times and well if it breaks then
you get you get really nice description
of exactly why actually the way are the
way it's written here you probably you
probably don't fit the predicate max it
lets you if you run the check expression
for them then you do exactly I actually
covered all this and I would say that I
haven't experienced too many impedance
mismatches when working with back
applying it to the data structure
invariance there are some the main one
is that there's no way to parameterize
specs right so if you have a spec safer
recursive structure and you want to
validate your pant now based on also
your child nodes based on some
information that's explicitly available
in the plant node well what any
campsites you have to work around that
somehow and there's a number of ways to
work around this problem sometimes it
makes sense to just make it explicit
that would ordinarily be an implicit in
a be implicit in low-level implantation
and I found that the entirely
appropriate and even helpful with
vectors but not so much with by
necessities I and you can also validate
things closer to the root of the tree
and just validate the whole thing in one
go but trade away some of the benefits
but you still get to keep them out for
so it's it's mostly okay i i'm not
actually completely sure what i what i
think about this but this is just
something interesting that feels like if
each others would be nice to have but
then I am actually run into a case where
it would be strictly necessary so and
it's been stimulating having to do with
this in in a number of cases so it's
it's it's maybe it's blessing in
disguise but I don't know so at this
point well at this point what I'm
convinced is the case there's any time I
invented data structure again this is
the kind of test I want to put in place
addition to all the black box testing
that you'd expect and there's a number
of data structures that interesting size
the guns of cataloging various
invariance and that's the famous working
progress
I might someday put out an artifact
called invariant catalog say or maybe a
single one but but we'll see setting
when I interned my on basis active there
will be accompanied by tests like like
these and I have several in the pipeline
so seven I shall be it'll be interesting
developing something using this
methodology and but also tells me is
that I'm bait Ivo is County and version
zero the zero that's seventeen and now I
feel almost justified and believing it
to be correct and just done right so I
don't know if I care about the version
number but but I am told that the two
leading zeros maybe send the wrong
signal so I just might celebrate closest
tenth birthday by bumping the first
number all the way to zero that one as
you go so possibly expect this in
October so and yeah but for today that's
all I got thanks very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>