<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Alex Miller, David Nolen -  Clojure and ClojureScript Update | Coder Coacher - Coaching Coders</title><meta content="Alex Miller, David Nolen -  Clojure and ClojureScript Update - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Alex Miller, David Nolen -  Clojure and ClojureScript Update</b></h2><h5 class="post__date">2015-04-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NvF-GZI20L4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what's the state of closure script today
a lot of things have changed in the past
two or three months there's a lot of new
stuff unless you're read every single
post you might have missed a few of the
things so we're going to sort of cover
that today and then i think alex is
going to do the same for closure as well
so what's new there's a bunch of stuff
closure script is not small anymore i
think i remember i think the original
clojurescript compiler whenever's
release was like i don't know five
hundred thousand lines of code so close
your script the standard libraries now
10,000 lines the compilers and the
repple supports also 10,000 lines so
it's about 20 thousand lines of code
does a lot of stuff it's probably to do
more stuff in the near future what what
are the things that it does and why is
it you know why is it grown so much lots
of stuff to talk about one thing that's
huge is that you know I for a long time
for various reasons because we were
focused on just getting it things
working the compiler was probably not as
fast it could have been so if you've
messed around with the sea ljs jar which
is like the standalone thing that we
have now things are really fast and
eventually they'll also be fast if
you're using even lining in the main
problem is that since the compiler is
really 10,000 lines of closure every
time you run it you get reaction have to
compile 10,000 lines of closure every
single time so we want to stop doing
that so things that make quite a bit
faster today we have a lot of analysis
caching we cast the results of the
compiler we just skip analysis
completely on my work desktop now if I
compile hello world cold cold JVM build
it only takes about one and a half
seconds it's way faster than it's been
in the past we actually a big reason it
was slow is because we would also not
only when you when you load it up are
you compiling 10,000 lines to the Pilar
you would also compile 10,000 lines of
the standard library and we don't do
this anymore we in the jar at least we
ship both cases where we ship the entire
standard library precompiled so it's
really fast in or death and it includes
the source map as well as
cash analysis eventually even if you're
using lining in or boot and you're not
using the uber jar it will still be fast
because we're going to start shipping
basically a otd artifacts it's already
true for closure scripts dependencies so
if you're a tools reader and data JSON
are actually available as a ot closure
artifacts you could actually add a
classifier classifier aot and you'll get
that already precompiled jar okay CL
janice jar it's pretty cool um it's it's
you it's really not you probably won't
be using it if you're using boot or if
you're using line but if you're like
trying to show people that clojurescript
neat or interesting or fun it's a lot
simpler to get started you don't have to
explain line again or and choose them to
some other build tool you really can
take this one jar as long as you have
Java 7 or Java 8 it's probably better
with Java 8 because Java 8 has NASA form
but it does work with Java 7 that's all
somebody who actually needs again this
is great for beginners the entire Quick
Start which is the entry point for
people who have never really looked at
closure script before all the
instructions are around using the the
single jar as fewer moving parts but
it's also better for the broader
ecosystem so as as there's so many cool
tools that are coming out fig wheel
you've got am blue which we'll talk
about Bootsy ljs there's a lot of
interesting stuff happening but it makes
my life harder and the people that work
on the compiler harder because it
without this separation it's confusing
as to where's the problem is it
downstream or is actually include your
script itself and see ljs jar is a great
way to say i'm going to submit an issue
or a bug show that show that you can
reproduce it with this don't involve any
other a tooling it makes it much simpler
to find the source of the issue so
foreign limbs is brand-new then this is
a totally exploded and in a very short
amount of time in three months people
are really using this so it really
simplifies the story of there are a lot
of interesting libraries out there that
aren't written enclosure script right
react is awesome
developers love react but it's not
written enclosure script and there needs
to be a good way to include in your
build and this is what foreign lives was
designed to solve also for various
reasons you might be I want to use
jQuery I want to use jQuery UI and those
are dependencies they have to be put in
a certain order there are lots of
problems of solvent again this is what
foreign libs lets you do it also lets
you escape from externs hell because
with foreign libs you can produce a jar
that has all the foreign live
information including the externs so
that people that want to use a plain
JavaScript library they don't have to
define any X turns and then again this
allows the community to package useful
libraries that again just aren't
available for in pure clojurescript see
ljs chances probably the best way to
consume one because it's curated there's
a lot of support it has 33 packages now
Google Maps dimpled III pick a day
moment react react with extras and so on
it's great really really just solves
that problem of wanting to use a popular
JavaScript library that again can't
really be a part of the closure Google
closure pipe compilation pipeline clj
has tests is new for a long time the
community relied on Chazz's a pretty
nice clojurescript test oh the problem
with clojurescript test is that it was
oriented around simple or something
higher than none which is kind of not
that fun for having a really productive
fast development workflow so CL jazz
test is official it works with every
compiler a setting you throw at it it's
worth checking out we dog food did it on
our own tests so there's like 16,000
assertions that we run when we when we
test close your script and these are all
red in terms of C ljs test most of the
functionality from closure tests have
imported so it really is designed if
you're familiar with closure test it
just works again works under
optimizations none it has a sink testing
support which you've already dog food
encore async there there are a couple
bugs because it's relatively new stuff
but it works reasonably well
static vars so when when Rich first
announced clojurescript you is we're
getting rid of ours because we're just
going to generate code that makes sense
to Google closure and including reified
VARs really didn't make sense and serve
for a long time we didn't we didn't have
anything like bars but actually we do
now because when I put when imported
closure tests a closure test uses VARs
not in any dynamic way uses in a very
static way to get metadata about a
namespace like what are all the VARs
with tests attached to them and so we
support this now a subset of the VAR
abstraction is available specifically to
support testing but you can use it as
well if you want to do some sort of meta
programming it allows it's a very simple
way to really grab compiler information
without being a compiler expert right if
you want to get the source or a line or
the arg lists or what have you you can
do this now it just works and then the
static bars are in vocal same as they
are in enclosure macro usage has gotten
simpler and it's probably to get even
more more simple in the future but
basically there's new convenient
behavior if you if you consume ohm or
any of any of really the a lot of the
nice react rappers they did they do this
little trick where if the namespace and
the macro namespace are exactly the same
and the library namespace includes the
macro namespace downstream users can
just require the namespace they don't
have to talk about the macros they can
just say require ohm core and alias at
his own and that's going to pull in both
the macro NS and the librarian s and it
just works and that's that's pretty nice
tons of updates and fixes around
incremental compilation we always sort
of support incremental compilation but
it was easy to corrupt your build
specifically if you have a parent
namespace in a child namespace you
change the parent that wouldn't
necessarily trigger a recompile of the
child namespace so we have we recompile
dependence now it's awesome so if you
change a parent namespace we find all
the child namespaces and recompile them
this is huge for ten
sting so often you'll you'll have a
bunch of tests namespaces and the one
namespace that calls run tests and and
you really need that to be to get
recompiled because of the static var
thing right the VARs are static static
information you have to recompile the
run testing because that expands out
into all the VAR references so this is
great for testing you can change a test
and your test runner namespace will get
updated recompile and again this works
even under cold builds so if you're if
you're just running a cold build it
still works if you want to disable it if
you're a fan of fig wheel of this
behavior while it's great for
correctness may be kind of annoying if
you're if you're using fig wheel because
you kind of just want to sort of play
facile news because you're just diving
you can you can disable it there's that
there's a flag for it this is this is
big for this is mostly for people who
are shipping large clojurescript
applications which i have seen quite a
few now you and what you want to do is
you want to you have a single build but
you're but you're really really your
build is now quite large you're relying
on react and you're relying on ohm and
you have your own libraries and you have
you know fifteen thousand lines of
closures good you're like we really
divide this up so we only load what we
need on each page so Google Google
solved this problem back in 2011 it's
just never been exposed to close your
script in a reasonable way and I went
ahead and fixed that so if you do an
advanced build you can now code split it
and it's and it's actually really
awesome it's actually quite a bit more
sophisticated than anything that's
available for JavaScript I think this is
one of the neatest features for people
building large applications allows you
to build the product it's really one
build but lets you allows you to split
them into optimal pieces it has nothing
to do with es2015 modules or AMD modules
or common J's modules when people talk
about those modules are talking about
something that a human rights Google
closure modules are only about code
splitting so one thing that we tweaked
around this is that it used to be that
the top level was a little bit too
dynamic
and Google closure couldn't just
arbitrarily move functions so the
standard library is big right it's
10,000 lines of code and so what I did
is I change the top level so that when
we omit functions everything is static
the top level is always completely
static and this means that even though
we have a large standard library Google
closure can actually move code to where
it belongs so even though it's huge and
one big thing and monolithic Google
closure can say oh you only use say
partition it only is used in this
namespace it will actually move
partition into the namespace where it's
being used and this is amazing there's
nothing like it for JavaScript yet
besides Google closure so closure script
mission is optimized for this so you
don't have to do anything there's an
absolutely nothing for you to do you're
just getting this for free again f ends
will get moved to where they're needed
this is big so the only took three and a
half years to get to this conditional
reading Sam at I'd I didn't work on it
so you'll have to thank Alex me Alex
Miller Niccolo momento who's known as
bronze ax worked on it luc van der hart
worked on it Alan died pert and and Myka
I think they they're the ones that
really push this in the right direction
we would have ended up something that
was really not data oriented and I think
what we ended up with just actually
really really cool I like it quite a bit
you don't have to use CL JX basically
you can write your source files that
need to be shared you need to feed it
into the closure compiler of the closure
scrim compiler you just use a new
extension the CL JC it can be loaded by
both compilers we support three
platforms we need feedback try it out
and maybe it may be the case that we
need to extend it in some way but right
now out of the box it works for closure
CLR closure and clojurescript it also
works in ripples so if you're your
library library developer it's really
easy to use you can be in your sale GC
file and the repple will be configured
whether your enclosure enclosure script
and you can eval and all this stuff it's
just going to work
people I mean like when we shift it
within 24 hours p-put harpy ported their
CL Jack's usage to it so it works it's
quite useful the other big news is
rebels so for a long time because we're
focusing on basically allowing people to
ship really really production artifacts
we didn't spend as much time on rebels
as we should have they were really
woefully woefully just wrong they just
did not work at all and it's required a
lot of breakage and then you know I
apologize for that but i think in moving
in the next 2-3 months whether you're in
them or emacs using cider or your incur
civ ripples will work and they'll work
exactly the way you've come to expect
from closure itself there's a bunch of
new rebels which is really awesome and I
think you'll see more of this in the
near future we ship out of the box a
Nassau run repple the National is
interesting it's maybe not the one you
want to use unless there's a specific
reason for it but we're you know I'm
hopeful that by Java nine that a lot of
the load times issues will be fixed but
the nice thing about Nassau is that it's
comparable to modern JavaScript engines
like v8 and javascriptcore so that's
cool we have an odious repple so a lot
of people like this it works pretty well
it could be it could be made better so
people are interesting and enhance let
us know or submit a patch the nice thing
about the node repple it is actually
reflective of a browser JavaScript
performance so it's the node repple is
actually really great i use it for
example to dev test checks so when i
when i ported test check to closure
script it was real a really great way to
just fire up the node repple and confirm
that the behavior of tests check was the
same again the ripples got overhauled
like basically everything works whether
it's doc source der printstacktrace the
stack trace will always get remapped
back to close your script source Macker
expand works require works and s
Internet's works load file works
specifically load file is really
important because that's what allah
out of the tooling uses to trigger a
recompile and a reload so for example in
fear I you actually used when I minimax
I use inferior closure which is from the
the closure you max team you know and
its really it's the same mode right as
the closure mode and I can I can
interact with a a closure scruple in
exactly the same way it just works again
all rep will support stacktrace mapping
by a source map so it doesn't matter if
you're in node the node ripple or the
NASA ran ripple or javascriptcore or
whatever you'll always get a closure
script stacktrace not not a JavaScript
won the support that we did so not only
did we overhaul everything and all this
stuff works it's completely generic so I
highly recommend checking out fig wheels
so fig wheel is a custom repple that
supports all these really cool behaviors
and it's built on this reusable
architecture that we've set up another
one that's super exciting is the ambling
ripple for iOS and I'll talk a little
bit more that about that in a second the
ripples now conform to the same design
as closure main which is really good for
integrating with n ripple or cider it's
perhaps not the best design but it's
really again this is what n repple
expects piggy back to point 0 and then
ripple 0.9 which are you know just on
the verge of coming out there snapshots
but it's probably really soon will
deliver basically sightly new cider will
just work for closure script which is
huge so let's see you demo so I'm going
to show this with with IntelliJ but all
this will work with anything really so
here i am here i have a couple over in
the side fight you know I'm go control k
and here i can switch into this
namespace i can type foo and i'll see
the function you know type closure west
right that works this is it you should
notice up here does it does not say this
is actually i'm actually in a dot CL JC
file this is not a dot c ljs so a lot of
things that didn't work in the past
work now so I oops that work oh sorry so
I'm in the wrong name space for this
let's go back she'll just user so if I
want to get the doc the doc string for
first that works if I when I get the
source for first that works if i want to
find for example I want to find doc
anything that mentions this is a regex I
think you mentioned the word array right
so is it really now instead of feeling
like um you know second-class to the
closure of boats really exactly the same
and it pretty much everything works Oh
another cool one that I added so
debugging macros work was never that fun
in close your script but here I'm going
to macro expand that work yeah so macro
expansion also works that's pretty sweet
okay so other exciting stuff is that you
know when when Rich first announced
closure one of the big goals at the time
in 2011 the obvious target was the web
right it was just the web is that the
JavaScript runs in the web we want to
build web apps and we want to write
closure we don't want to write a
JavaScript and it's not there's anything
wrong with JavaScript but we like we
like closure we would prefer those
semantics and the benefits that we get
from closure for even if we're targeting
client-side stuff things have changed
quite a bit thanks to react so that the
nice thing about react is that a react
now has a developing story for native
and how it's going to work is basically
Apple itself has been improving the
javascriptcore bindings it's you can
even like create basically
multi-threaded JavaScript applications
so they haven't publicized this but the
the JavaScript core support is very very
good and what facebook said is ok what
we're going to do is we're going to make
a huge set of widgets that are standard
widgets and we're just going to write
the entire application in JavaScript
using the reactor rendering model it's
great but this means that foreclosure
script users you now have a story that's
going to be done pretty soon which is
that if you want to target the web you
want to target iOS you want to target
Android you can do this all in clojure
script and react and that this is huge
there's not been a way to do this
previously in the past so of huge step
in this is this replica Embley which is
by mike fikes he actually is already
shipping an application the App Store
written purely enclosure script doesn't
use react but it uses the same tricks
but here i totally recommend checking on
github it's called am bleep it on the
ohm organization and it basically lets
you dev live against your iOS device you
don't even need Xcode you can basically
boot the app with with the ripple and
you can actually compile java script
sources directly to it because you can
basically mount it as a a webdav volume
it works great and if you haven't tried
it i totally recommend like giving it
spin it's super super fun to be able to
interact with
an iOS device directly with Lisp so yeah
so keep your eyes out for this check it
out amelie again it just uses bonjour
and webdav and it audit you can
automatically connect your device it's
definitely a good foundation for react
native integration so what's next for
cloture script so that's sort of a bunch
of updates what are we what are we
planning on for the rest of the year a
couple things so we really want tooling
to be stable and be better I mean this
has been a problem because closure
script moved so quickly and often people
just tap into details that really we
never discuss or they're not public so
we want to fix this we want people to
have something that's stable that we run
tests on and that's where we meet people
will need to stop calling in to the
implementation namespaces so this is
already under development the two
namespaces that we have our CL GS build
a p.i and clas analyzer api so if you
want to build some really amazing tool
you'll want to go through these in the
future if there's something that's not
there you know ask us and we'll we'll
figure out what exactly is required and
needed but relying on this will
stabilize things for everybody these
namespaces will get dog fitted so so
we're going to actually use these
ourselves as well it's not just going to
be like oh we think this is what people
need we'll verify that and then
hopefully it'll get better over time as
as people describe what the gaps are
what's missing optional bootstrap is
also going to happen and its really
likely we won't actually this ourselves
we're not going to get in the way of it
so now that we have conditional reading
there's almost nothing left to do we
just need to port some macros somebody
needs to port tools reader to compile
the nodejs and that's it you can point
the compiler back at itself and if you
want to do that you can and there are
legitimate use cases for this there's
some interesting new targets right back
in 2011 these targets didn't exist that
would benefit from a bootstrap compiler
Adam shell is an obvious one so there's
a lot of people building desktop
applications portable desktop
applications
with Adam shell and this would be great
to just be able to stick the compiler
inside so that when you ship your thing
you don't need the person to install the
JVM first so this is a problem for light
table right so people have to have Java
to use light table with this model you
could just ship the thing you don't need
Java there's very little left to do as I
said port tools reader macros and some
conditional reading so no something
that's happened something I got
announced right before the conference is
the final draft for es2015 it's really
happening finally the explain but you
know it's it's actually some it's in
some sense it creates problems for us I
think it was Ricky once said he just
want Java to stop changing and I kind of
feel that way about JavaScript but we
have to deal with it it's happening and
people will start you'll you'll find
more and more quote code out in the wild
that uses es2015 modules it's already
the case that we have this problem with
react react ships these things this
thing called react tools and what people
often do is they'll have some really
cool widget that they haven't compiled
to be used in a normal way you need
react tools to build the thing and
that's a problem so react jas relies on
both a custom transform called jsx and
then on top of that it uses common j/s
the common J's module format so we can't
consume this stuff right you're in the
thing we want to avoid is a world in
which you have to run some other build
tool in order to get something that you
can load into clojurescript so we have a
solution coming for this it's you know
it's a joke system CLG ask if you've
heard of system j s similar idea there
are three popular module formats Google
closure already thought about this again
back in 2011 Google closure can actually
consume and process md and common j/s
they just haven't exposed good hooks for
it and I will be submitting some patches
to the closure compiler to make it
easier to work with and likely will
start leveraging JavaScript parsing and
analysis so one thing we don't do is we
don't often validate the way that you're
interacting with jas and that's going to
change and then likely this will also
lead to what
we're sort of calling externs inference
so we would actually be able to
automatically compute all your ex turns
for you so this is even better than the
existing behavior that you get from
forum libs you wouldn't have to package
externs at all this is important for
things like 3 j s right 3j s is massive
it's huge nobody's and the right
externals for it so this this would be a
way to automatically generate it based
on the code that you wrote so that's it
I it does anybody maybe there's time for
questions or maybe Alex needs to get on
I don't know quick questions go ahead
there's no runner we don't ship runners
yeah it's just outside it's completely
outside what the closure script compiler
is designed to do you can bring your own
runner though yeah I mean it something
to definitely to rely on some other tool
to launch for you other questions no
okay thanks so I'm gonna be talking a
little bit just about what's going on in
the closure world and company world and
community world and just try to catch
you all up in case you don't like like
David said he and I sort of serve
complementary roles and obsessively
watching things that are going on as so
sometimes it's hard for us to pull back
in and get into the headset of people
who are merely just using it as as
interested developers but not obsessive
people like us so closure 1 dot 7 is
coming real soon now we're currently at
17 beta 1 and there's been a number of
bugs reported on that and you know
aggressions and little things that we
forgot and and almost all of those have
been resolved already and have patches
ready to go and I expect that sort of
after the conference when things calm
down a little bit that will move rapidly
to release candidate one I I can't
really predict exactly when that will
happen but I would guess within the next
week or two that will probably be moving
into a release candidate mode
point when we release things like a
release candidate in particular it's
extremely helpful if you get if you can
sort of go to your internal project or
your library that you have and update it
to release candidate one and run it and
see if there's anything that you don't
expect that happens and then give us
that feedback so and that could be it
and you can give us a good and bad
feedback it's really really helpful to
hear from 20 people upgraded didn't see
any problems looks good you know that's
extremely helpful so we announce all
those in the mailing list the closure
mailing list so if you see that please
give it a shot and that helps
tremendously some of the big well I want
to mention these are current
contributors I think there's probably
some patches out there with new people
that are included in this but I went
through the commit logs for 17 and these
are all people that are included and
it's great to have all of their help
many of these people it's not the first
time they've contributed to closure I
would really do appreciate it I do want
to mention got a shaven hit but probably
doesn't have that many lines of code and
that were committed in this release but
he's been a tremendous help to me sort
of offline and thinking through
different issues and I really
appreciated that and also i want to
mention nicola momento who has done a
lot of the work on like tools reader and
tools analyzer and those kind of
libraries and he often Wade's in on the
nastiest gnarliest compiler aot related
things and helps me make progress there
and that's just been I it's been hugely
helpful for him to have him helping out
and so a big big thanks to him and
everybody else has contributed of course
so the there's kind of two big features
that I want to talk about it in 17 I'm
not going to talk about it very much
this is the entirety of the slides about
transducers I'm obviously skimming the
very thinnest bit of surface here but i
do want to give you a little taste of it
just in case somebody hasn't seen it yet
the big thing with transducers is that
they are composable algorithmic
transformations so that allow us to take
the kinds of operations that we
currently see in our sequence functions
that we use all the time and to create
what we call a transducer out of that so
when you see filter odd or map ink those
are just like the normal sequence
functions we have but they have one less
arity so we actually omit the input
source and it's just really represents
the pure operation of filtering odd over
each element in something or mapping ink
over each element in something and then
we can take those things and actually
compose them still completely distinct
from the input source or how they will
apply it and how the output will be
collected so transducers if you think of
sequence operations as really being
having three parts to them of traversing
some input performing some
transformation and then producing some
output transducers are really just the
middle part and so we can produce these
sort of algorithmic composable
transformations and then choose to
consume inputs in different ways and
produce outputs in different ways and it
with same transducer and so it gives us
this little reusable thing that we can
use in different ways so transducer is
because they actually form a stack they
actually the order that you compose them
will feel backwards so that's kind of
confusing it's kind of like middleware
have the same kind of a problem but we
can use cop and comport just fine to
compose things in a left-to-right manner
so when we say comp filter odd mapping
take five that means first take the
input and filter odd then map ink and
then take five so it's analogous to the
thread last macro or something like that
if you want to that's how I think about
it and that helps me so and then we can
there's a bunch of ways we can apply
that transducer there's a brand new
function called transduce which is
similar to reduce except that it takes
an initial argument which is a
transducer and so the final argument is
the incoming the input we apply the
transducer
to all of the elements of the input we
apply some final reducing function which
is exactly the same as the original
reducer function and then that 0 there
is just the initial value of the final
reducing step so that's how we use
transduce into now has an extra version
with an extra aritee so you'll see that
X F in the middle there we can take the
input sequence transform it and then
collect the results into some other data
structure so this allows us here I'm
using a range which is a sequence but
you could also use this on a vector and
so you start with a vector and you end
in a vector and that's something that
happens eagerly and so this allows us
more options in terms of how we apply
the kinds of transformations were used
to getting with lazy sequences things
like that we have new options now for
how we can apply those in some cases
doing that eagerly is going to be is
going to be what we want right we know
that we want to compare output at this
point and we can control that and the
benefit there is that because we're able
to build this compound transformation we
do that through a single pass over the
input and there are no intermediate lazy
sequences being created and that allows
us to have a greatly reduced allocation
costs through that and you can really
get if you combine that with a source
that knows how to reduce itself and
we've had a bunch of changes related to
that those two things can allow us to
avoid a significant amount of the object
allocation that we that we had before
and also do less sort of function
operations as well and so you really get
some significant benefits in that case
if you do still want to do things lazily
there's the existing sequence function
which probably most people have never
used but it's similar to seek except
that it will return instead of an ill it
actually will return an empty sequence
potentially but that function now also
takes a chance formation function and
you can consume the input apply the
transformation but receive those things
in a sort of incrementally computed away
a lazy way as you read elements off of
that adduction takes
that same idea it's something that's not
going to be computed at the time that
you define it but it will actually
recompute that Tramp that transformation
every time you use that adduction that's
useful in the case where for example you
don't want to hold on to the head and
then have all of the intermediate state
of that transformation in memory so if
you just want to do that once and then
consume it and let it let it go away but
then maybe do it again adduction is a is
a key tool for that and then finally
Cory a sink has been extended so that
you can create a channel that will
actually apply a transducer to two input
values that are flowing through the
channel and so you can use exactly the
same transducer in all these different
ways so that's the short pitch on
transducers there's a closer org slash
transducer transducers page now and
there's also several talks out there now
from rich and other people that are
useful to see how those things work and
and there will be some more i'll be
writing some more things about about
that as we get to the 17 release the
other big feature i think david probably
talked about this already but reader
conditionals and so again I've condensed
this entire months of feature work down
into a single slide so I would echo what
David said about thanking MIT the many
people who worked on this in different
parts and and in particular Alan amisha
in particular for sort of driving a
really useful design discussion around
what we should be doing so the big thing
here is that we have a new file
extension CL JC or the final see can
think of as common or some file that's
common across closure platforms inside
only CL JC files you can use these
reader conditional forms and I just put
two examples here the reader conditional
kind of should be reminiscent of a cond
so it has a condition at the beginning
which is really a match against the
platform feature so each platform has
its own feature and it's only only going
it's going to walk through those until
it find one finds one that matches the
current platform so it's going to try
clj and it's going to
I see ljs and at the point where it
finds one its going to read and emit the
expression immediately following in any
of the other branches will not be read
or or put out and it's possible to fall
through this and actually emit nothing
not nil but like literally as if you had
not read anything at all and that's an
important capability for some use cases
and there's also the splicing version
which is exactly the same except that
you're expected to turn something that
is you know some sort of list vectors
lists or other things like that and the
results will be spliced into the outer
context so you could produce on closure
in this case you'll produce ABCD on
closure script you'll produce a BEF and
on another platform you just produce a B
so that's a in a nutshell that's reader
conditionals and and again I think
there'll be more stuff coming out about
details of that another big focus and
this I've worked on a lot of these in
particular is performance and so we've
done a lot of things and there have been
a lot of sort of bugs and patches and an
enhancement work that's gone on some of
it is driven by transducers some of it
which just happen to come into scope for
this release symbol and keyword
construction is faster we've got
significantly reduced compile times in
particular on but by reducing class
lookups and this is particularly useful
in macro heavy projects and Zach Tillman
I think who's here somewhere was the
sort of the genesis of the ticket that
drove this change and so big thanks to
that it really makes a significant
difference in some projects like fifty
percent faster compiles in some cases it
will give you know faster c'mon so I'm
not saying that for everybody but in
some cases it helps the there's a number
of functions that are sort of generators
of sequences so repeat cycle iterate and
range or kind of the the main ones all
of those now have different
implementations that
that actually work faster as sequences
so if you're using the way you are using
them before you continue using them and
they get exact same way and that is now
faster they also now are reducible and
so those are used cases that work with
any of those contexts where we're doing
reduce like things so that includes
reduce and into and transduce and any of
those kinds of contexts can leverage
that behavior to do a faster to do a
faster reduce without allocating a
sequence and then having to throw that
away and so let's see and hash maps and
hash sets they now have direct iterators
before they would create a sequence and
then build an iterator over the top of
that sequence you can now iterate the
hash map in the hash set directly
without ever building that sequence and
this is again something that's being
taken we're taking advantage of this and
a lot of the low levels of reduce
underneath other things keys and vowels
used to if you think about what they
used to do if you went to a map it would
build a sequence of map entries first
and then walk through the sequence of
map entries and extract the keys from
the from each map injury and so what
happens now is that we're able to
actually build an iterator that walks
directly over the map and produces a
that iterates over the keys of the map
so it does not generate all of the
intermediate map entry objects because
we're not going to use them it also
doesn't generate any of the intermediate
sequence nodes because we don't
necessarily need to use those either and
that so that makes things like keys and
vowels significantly faster and these
reduce like cases iterator seek which is
used to wrap a sequence around an
iterator that's a case that now comes up
in some different places is now a chunk
sequence so that's faster vac and set
are now have been completely reworked
and are now significantly faster for
most inputs and in particular they used
to be some sort of you know conventional
wisdom about how you should use into
instead of a can set and in
2 is still really really fast because
it's based on reduce and it's gotten
faster for a lot of these reasons too
but vac and set in particular for the
use case where you're passing some some
collection in and you want to ensure
that it's a vector back in that case
we'll recognize that special case and be
able to basically avoid creating a new
vector to a large part so and the same
thing with set so that particular use
case now is something that can return in
nanoseconds instead of some linear time
related to the size of the vector or the
set so that's a huge win for that
particular use case and it also is
better for sequences and lots of other
cases as well we unroll did a little bit
more argument unrolling and partial
which is used by other things and and so
that helps in a few places and then we
also discover this is something I ran
into literally years ago before I was at
cognate echt and didn't understand what
was happening at that point and just
rewrote things until I've got past the
problem but somebody else ran into it
and posted something on Twitter and I
recognized it and now that that's my job
I said hey do you have a reproducible
use case for that he did and I very
quickly figured out that the default
value dispatch case for multi methods
was not being cached like every other
case so this was it's actually a pretty
common thing that happens and the cash
was basically not being utilized for
that particular use case so one place
where I've seen that come up a lot and
where it actually was reported was using
closure walk to walk a data structure
you tend to end up hitting the default
as you hit some of the intermediate
nodes so things like that that that
particular use case is now significantly
faster there's some other things that
I'm not listening these are kind of the
main ones all of these things combined
to make 17 really substantially faster
in a lot of real-world use cases without
changing any code if you want to use
transducers and and sort of go down that
route I think there are greater gains to
be had but even if you are not doing
those things we've seen some early these
are some tweets the captured from out
there
Tom Crayford was seeing fifty to seventy
percent performance improvement on some
of the benchmarks that they run in every
release his build went down from 32
seconds to 18 seconds so he saw a big
scene infinite jump there and then we've
seen these are some production timings
here where you can see that it's using
less CPU and less resources and then
I've got some other reports to what I'd
have any sort of good Twitter things for
them or anything but we're definitely
are seeing real real gains from some of
these changes that are in 17 and I also
saw a couple of these tweets recently
and I captured them because it's
something that most people don't talk
about but that I spend a lot of time
thinking about but we work really hard
to avoid breaking code between releases
to make it easy to upgrade and we're you
know following in javas stead there for
sure but we do really care about
regressions and we want to hear about
those if you see them and so we want you
to be able to upgrade without in the
majority of cases without having your
code break and we we do really spend a
lot of time on that ok so that's 17 we
will be moving into thinking about the
next release soon but rich and I haven't
had a chance to really had a top have a
talk about that so I'm not going to
predict predicted that I i we definitely
have talked about some things and
they'll be more coming on that so like I
can't talk about it he was supposed to
be here we maybe we might have had that
conversation today but we didn't have a
chance so I wanted to talk just briefly
about sort of companies in the you know
the fact that we all make our livelihood
out of this pretty much there's a new
page out new since the last time we had
this conference a page out on closure
the closure org slash companies page
I've been adding companies that are
using closure in some way out there if
you want to be added to it there's an
email at the top there and you know feel
free to ping me there's 148 companies on
there which is probably more than I
would have expected when i first started
putting this page up I would love to add
more companies
so please if you're not on here check
and let me know we also have a page out
on the cognate x site where we've been
trying to collect sort of a little more
success stories to give a little insight
into how people are using it and why
they're being successful with closure
there are a number of I just kind of
grabbed a screen grab of part of this
page there's a lot more to it so you
should go look at that it's really good
if you're trying to give that somebody
to use closure to show them that lots of
people are really using it and being
successful with it if you'd like to be
added to it that that would be fantastic
so please talk to somebody at the
cognitive tech booth jen helena is here
and she's been reaching out to a lot of
people she might you might have gotten
an email from her at some point and so
she's here and and and she's involved in
updating this page and we can add more
things to it that would be great I also
want to mention because I don't know
that everybody knows this but Todd
contect does a number of things in the
closure space besides just maintaining
the language we do consulting we also do
training so I will sometimes go out and
do training classes at companies if
you're trying to move towards closure
and train more people and and we also do
things like architecture code reviews
and we also sell support contracts for
closure as well as the other things that
we the other things that we produce at
cognate act like dey Tomic and other
things so if those things are useful to
you I just wanted to let people know
that they exist because what we're
finding is people don't know that we do
that stuff so those options exist moving
on to community the the closure
community is fantastic and awesome and
so I never get tired of talking about it
just a quick update on google Summer of
Code last summer we had nine slots that
were allocated to us by Google and we
had projects about core.typed and quill
and tools analyzer core matrix and some
compiler ideas and light table and so a
lot of interesting stuff and I think
there's two people here from
the google Summer of Code and a cup we
were able to use the funds that we can
request from google to get people to
conferences and so we spent summer at
the conch and there's some here today
we've been allocated five slots for this
year and those are sort of in the
process of getting decided I don't think
they've actually been decided or
finalized yet but there that should be
happening imminently opportunity grants
this was something we started last year
at the closure cons and the idea is to
remove obstacles for people of
underrepresented groups really with the
idea of improving diversity of the
closure community and I think it's been
one of the most rewarding things that
this and we have a similar program at
strange loop which I also run and it
this sort of thing has been one of the
most rewarding things that I've done in
my career and so I'm really proud of it
and we have raised we raised over ten
ten thousand dollars at the conch and
were able to bring 12 people in and at
closure West we raised about 14,000 this
has 19 on it but I know that we've had
at least four or five more that we've
been able that were here in town that we
were able to get into the conference
just in the last day or two so I suspect
that number is probably below at this
point but it is really making a
difference and I just want to thank
everybody who has sponsored one of the
opportunity grants that includes a bunch
of companies there's I think for
companies that sponsored in this
conference and that's been on the slide
rule that's been going through there
were more at the conch and then there's
also been many many individual
contributors both at closure West and
closure cons who have donated money as
they bought a ticket and it's just it's
hugely helpful and and we've been able
to I think really make a difference with
that stuff your closure has never done
anything like that oh
that your closure has never done
anything like that that we announced a
little bit back that we've taken over
the organization of the earth closure
conference and are working on that with
Marco who's run it in the past and we
expect to have an opportunity grant
program out there we just haven't we're
kind of waiting to get through this
conference before that's all that stuff
but will be definitely accepting
applications for that and and we're
already have some things out there for
sponsorship and we've already had some
sponsorship dollars come in or euros
actually come in so we're still still
adjusting it's really terrifying to run
a conference out in a different country
by the way but anyhow so that's a that's
an interesting thing your closure is
going to be jun 25th and 26 in barcelona
if anybody's interested in making a trip
should be a great sugary read conference
i want to mention some of the books that
are coming out I probably forgot some
and so I apologize for that off the top
of my head and there are I know a number
of the authors are here on the here in
the audience so I know Karen Myers here
with living closure and Colin Jones is
here who wrote the macros book I happen
to have a book that just came out and
pragmatic press and I don't know if
Danielle Higginbotham is here the author
of closure for the brave and true he
might be but I'm not sure and I don't
think any of the other authors are here
but there are I apologize and if I miss
any other books I apologize but these
are all books have come out since
closure West last year so that's awesome
and I know there are more sort of in the
pipeline so it's great to see lots of
interesting books coming out things to
read i also want to talk about closure
bridge closure bridge was just sort of
in its very it's in its infancy at
closure west last year there are some
meetings that happened here and it had
already been sort of underway and
planning was underway for the first one
which was in durham north carolina and
so just to give a little update on that
about the things have happened since
then
there's been I'm missing a couple of
them on here there were events in I
think one more event in Minneapolis and
one in San Francisco I think I'm
actually missing on this slide but
there's been about a dozen closure
bridge event since then including to
this past weekend one here in Portland
and one in London and so that's just
phenomenal to bring people into the
community again like the opportunity
grants i think it's it's really making a
difference could i ask anybody who here
who has helped organize a TA or attend
at closure bridge can you stand up I
don't know how many people are here but
probably a lot so yeah awesome
so if you're interested in holding a
closure bridge in your area please get
involved on the mailing list and and
there's lots of great resources now for
helping to organize and organize TAS and
teach and materials and all those things
all that stuff has really been pushed
forward by a lot of great people who
have done a lot of work so that's
awesome playing with keynote you know
and then I also wanted to mention some
of the closure bridge sponsors these are
all people are companies that have
sponsored closure bridge at some event
over the past year and so there's a huge
amount of people i'm sure there's lots
of people in this room that work for one
of these companies so thank you to all
of you for supporting these efforts it's
it's greatly appreciated and that's it
that's all I had so I am it's awesome to
be here and to see the growth in the
community and I think there's just
fantastic things ahead for closure
things are definitely on an upward
trajectory right now the one other thing
I wanted to I'm meant to do earlier
there forgot to do I want to see a show
of hands of everybody who's company is
currently hiring foreclosure developers
so there are tons of people looking for
closure people right now so I'm sure
there are also people nerve or are
looking for closure jobs so you have no
excuse there are plenty of people here
that was about a third of the people
here so talk to three people and one of
them probably is hiring ok and then
talked to nine people and you'll have
three interviews and then you can you
can find somebody good so let's match
you all up while we're here and then go
make awesome things so let's keep it
going</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>