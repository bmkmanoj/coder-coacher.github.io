<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Glenn Vanderburg - Cló: The Algorithms of TeX in Clojure | Coder Coacher - Coaching Coders</title><meta content="Glenn Vanderburg - Cló: The Algorithms of TeX in Clojure - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Glenn Vanderburg - Cló: The Algorithms of TeX in Clojure</b></h2><h5 class="post__date">2014-11-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/824yVKUPFjU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Thank You Stuart that was Wow
Esther mentioned I work for LivingSocial
and I just wanted to mention that we are
hiring closure developers we have about
eight full-time closure people and about
that many others who split time between
closure and Ruby and we're doing more
with that and looking to build that team
so please talk to us if you're
interested and I want to start with a
couple of disclaimers
I don't program for living anymore and
so I'm a closure dilettante
you're not going to see any advanced
techniques here or anything that'll blow
your mind
and I'm talking about a project that's a
currently kind of in a shambles because
it's in the middle of a redesign
redesigned because I changed the focus
of it but we'll talk about that a little
later so please forgive me for that I'll
begin and end with history Donald Knuth
learned to program in 1957 at the age of
19 at the IBM 650 computer that he's
shown within this picture I endure
introduced him this way because it will
provide important context for what is to
come
here's a more recent photo at age 74 at
the console of another machine that he
loves one of the things he's famous for
is the tech typesetting system which he
released at version 1.0 in 1982 32 years
later it is still in some ways the state
of the art for computerized typesetting
especially for books that are complex in
structure layout or content I had to
pick this example for a lispy audience
this is a table from volume 4 of the art
of computer programming that shows 8
different ways of representing the 14
distinct permutations of you know valid
nesting of four sets of parentheses
Knuth had three primary goals when he
was building tech utility discovery and
education the utility goal came about
that it was the genesis of the whole
project
when Knuth received the first page
proofs of the second edition of volume 2
of his magnum opus the art of computer
programming
they were disappointingly ugly and he
learned that the reason was because for
the first time the typesetting had been
done with the aid of a computer and like
any good hacker he said well I can do
something about that and thus began what
is arguably the greatest yak shave in
history as he took ten years off from
writing his life's work to write systems
that it would allow him to make them
look acceptable to him again so that was
the utility goal being an academic he
also wanted to discover new things he
wanted to advance the state of the art
and several important results came out
of his work on tech including its most
well known algorithm for optimally for
some definition of optimally breaking a
paragraph into lines but then there was
an education goal as well and this isn't
as well known in his second appearance
on this stage today Tony Hoare
encouraged Knuth to publish the source
code to tech and the reason he did that
is that at that time and this is hard
for us to believe today there were
really no good real programs available
in source code form for students of
programming to study you know today in
the age of git and almost everything
seemingly being open-source that's hard
to remember but you know in 1982
networks were starting to be places
where people could share files but just
starting
in that year this 250 page directory of
all of the 5000 people who had access to
the ARPANET which became the Internet
was published and also remember at that
time the ARPANET wasn't even on TCP yet
tcp/ip didn't take over the Internet
until the next year 1983 if you really
wanted to read a big real program and
study it you know something that wasn't
a toy written for a class if you knew
somebody who had a copy of John Lyons
commentary on unix and wanted to
photocopy 250 pages or so you could read
that but that was about it
so Knuth began considering how he might
publish the tech code thus began his
ideas on literate programming and tech
was published as a showpiece of that
style and in 1986 it was published as a
book for years probably until the late
90s or so when my guess is it was
surpassed by the Linux kernel tech was
the most widely read large program in
the world tech is a masterwork it's fast
portable produces excellent results and
is still in why do you use over 30 years
later with astonishingly few bugs having
been found during that period of time
and yet for reasons that I don't fully
understand I've always wanted to
re-implement it
this has been on my mind for a long time
over 25 years since probably not long
after I learned that Knuth could make
mistakes
I would love to claim that those were
for bugs in the art of computer
programming but they were actually for
typos in the tech book and but you know
I kept talking myself out of this for
various reasons you know a because it's
crazy and things and I made a couple of
false starts and always said you know
this this is ludicrous ludicrously
ambitious and has no practical use and
and this is pointless and I'm going to
do something that has a point but then
two years ago at rubyconf Yukihiro
Matsumoto in his keynote kind of gave me
permission to do this silly thing he
said nobody should laugh at motivation
everyone has different motivations and
motivation is very precious
who's the driving force behind great
works some may call it reinventing the
wheel but I say go ahead if you're
motivated he said that on November 1st
2012 and 8 days later on my birthday the
first non-trivial part of khlo was
working I should explain the name it's
an Irish word that means font or print
and also for some reason spike and that
seemed to appropriate so I went with
that I should also mention that it is
not the first time that people have
reimplemented all or part of tech
there's a long list of projects that
have reimplemented those things and and
they all had to re-implement the
algorithms from scratch and that's
telling in and of itself so I'll be
coming back to that later but you know
even though I took Matz's encouragement
of if you're motivated you know don't
laugh at that go do it it's still worth
asking where that motivation came from
my goals like Canute's were utility
discovery and education
but for me education came first mostly
because I didn't at first understand why
a reimplemented tech would be useful and
to explain why I thought it would have
educational value we need to return to
Canute's early pro your programming
experience at that IBM 650 in an article
related written in 1986
Knuth remembered the 650 and he wrote
things like this most of the commands in
the 650s repertoire accomplished several
things at once and it was frequently
possible to make good use of the side
effects that's a great quote for this
audience
for example this instruction meant load
the contents of location one two three
four into the upper accumulator and the
distributor set the lower accumulator to
zero and then go to location 1098 1009
for the next instruction all four of
these actions were often useful in the
subsequent program steps that that was
the state of programming when Knuth
first encountered it and because that
computer had only 2,000 words of memory
each of which was a ten digit decimal
word things have changed a lot
programmers were often forced to use
those kinds of tricks to do even
moderately complex or ambitious things
with such limited space and resources by
the time Tech was complete it was over
25 years later and a lot had changed but
it's now over 30 years since then and
looking back on it it's amazing to see
how primitive things still were in 1982
and how much has changed between then
and now Tech was a very ambitious
program for that time on that hardware
and once again Knuth found himself
having to exploit those old tricks and
habits and skills to make tech run
acceptable on common hardware of the
time Tech is written in Pascal a
pre-processed dialect of Pascal it is
full of global variables
lots of go twos it frequently he'll sort
of realize okay this variable isn't
being used for its intended named
purpose here
for a little bit so I'll just use that
variable for something else you know the
assumption of single-threaded
procedural programming and mutability is
just pervasive it's it's kind of
mind-boggling it's like a time capsule
reading the code is like visiting
another era he wrote it in Pascal
because it was you know receiving
plaudits at that time for being a good
language to teach programming in which
turned out not to be a good idea but
anyway and he wrote it in a style that
was already as he was writing the
program that style of programming was
already beginning to die on wards wiki a
few years ago a guy named David Brantley
called it the last hurrah of procedural
structured programming by the time the
book was published in 1986 the book
represented a sterling example of a way
of programming that it was already in
many respects obsolete let's go back to
canoe this article about his old IBM 650
experience in the conclusion he said
surely I wouldn't recommend that today's
software be produced as we did the job
then we would never advanced very far
past the rudimentary levels achieved in
those days if we remained rooted in that
methodology and similarly while I'm glad
that the source code to tech is still
available to study I sure wouldn't point
a new programmer toward it because we
should not be doing programs today the
way we did then but what might be really
valuable is to have a modern
reimplementation written in a modern
functional style to study alongside it
to see how much has changed and to
appreciate what we have and the value of
improved improved tools and techniques
and the trade-offs that have been made
we can illustrate what's changed
demonstrate the value of expressive code
provide real examples of how algorithms
changed when they're translated from
procedural difunctional style so just
how much easier functional programs are
to reason about show different styles of
optimization things
like that so my first goal was education
I started out in this vein aiming for a
faithful reimplementation of tech
top-to-bottom one of the first things I
wanted to illustrate was I get confused
so doing a bunch of stuff at once
multiprocessors were research projects
in 1982 now most of us have one in our
pocket so what can we do and so I looked
at tech in the way it worked and I
decided on a parallel dataflow
architecture I'm not very good at
drawing boxes in lines so I repurposed
an old diagram from a paper I read once
and you know at the the textual input
format format comes in at the top and
gets read to produce a stream of tokens
and the macro expander gets hold of that
and produces primitive tokens which gets
get interpreted to build what tech calls
vertical list elements things that can
appear stacked on top of each other on a
page if those are too long to fit within
the margins those get broken into
multiple lines and as a paragraph and
spliced back into that list and the page
breaker reads that and collects and
builds page bodies the page builder
sticks headers and footers and other
adornments on that and makes it the
right size and ships it to the DVI
output stage which spits it to Tech's
version of an output file I implemented
the last three stages and a simplified
version of the line breaking algorithm
so you know that that part of it works
not 100 percent feature complete but the
basics are there implementing this
architecture and I believe that in a
full version with this architecture we'd
see fairly significant parallel
execution and especially once the that
dataflow pipeline got filled up
this was really the first time that I I
really had my breath taken away by the
power of the seek abstraction and
enclosure this is the little driver bit
of code I wrote to link all those stages
together it threads the input stream
through the token scanner and then the
primitive interpreter or the the macro
expander and the primitive interpreter
that builds the lines the the line
breaker the paginate or the output
routine and finally the output routine
and it worked pretty well and this all
works in single threaded mode but by
just replacing the threading macro with
a different variant that I wrote I
linked all those together in different
threads with bounded buffers in between
them and it works in parallel with the
same code structure and that allowed me
to start doing like apples to apples
comparisons apples to apples benchmarks
against tech in single threaded mode and
then run it during the same thing in in
multi-threaded mode and see how much
benefit I was getting from the the
parallel architecture and that was
pretty cool and what I learned is you
know Chlo is much much much slower than
tech but we did get a substantial
benefit from the architecture or from
the from the parallelism there are some
gotchas to this architecture error
handling is going to be difficult things
in tech can be redefined here in the
page builder and that needs to take
effect farther upstream it's kind of a
dirty trick and you're not supposed to
do that in the page builder but you can
and so there are cases where just as in
the original appearance of this diagram
there needs to be feedback for further
of the stream and I had strategies
worked out for handling all those but I
started realizing that the quest for
end-to-end compatibility
was distorting otherwise lovely
abstractions that were appearing in
those later stages that I'd implemented
and this all raised some interesting
questions to make Clos 100% compatible
with Tec I would have to give up many of
the aspects of closure that make it an
interesting and worthwhile alternative
to more traditional languages does that
represent a failure of closure how much
of text interface that it presents to
the world is a product of the language
and paradigm in which it was written
that assumption of sequential execution
and pervasive mutability leaking through
into the the the language the the tech
input language and the the tech program
specification to what extent is that
true of all software more questions what
would anyone really need from a new tech
how much compatibility is enough or even
desirable and I finally had to face the
question of whether I'd prefer Clos to
be instructive or useful we'll get back
to that in a minute I also had a
secondary goal of discovery this is
where I'm gonna show some of the the
code on the inside and talk about it a
little bit more this wasn't my first
closure project but it was it was where
I really wanted to dig in and try to
explore it and learn everything I could
and learn to be a good closure
programmer I wanted to learn more about
tech and typesetting I wanted to learn
about expressing algorithms in a
functional style especially complex
algorithms
I don't wanted to learn how to optimize
closure and make it fast it's been a
struggle the gulf between the style of
programming the tech is written in and
the style of programming I want Clos to
be written in in closure is enormous and
it's been really difficult to understand
the original code and all of the things
it does in the style that it's written
and then figure out how to translate
that in
to a functional style I've been really
tempted to duplicate the existing
optimizations that are in the tech
source code within finally you know
having to talk myself out of that and
realize those are optimizations that are
appropriate and necessary for that era
in that language and that style but
there are other ways of doing things now
there's duplicate code everywhere and
it's been difficult to be patient as I
learned and studied and wait for the
underlying or the unifying strategy for
those things to become clear each
substantial part of tech that I tackled
followed the same pattern I would study
this text source code for an hour or so
I wouldn't want to get too deep in that
and infect my brain with with the the
mutability and everything and then I
would spend about three hours banging my
head against the desk trying in vain to
figure out a way to express that without
mutability and in a functional style and
eventually give up in despair and then
for about five days I would be literally
unable to think of anything else lying
in bed at night sitting at dinner with
my family watching TV late at night with
my wife sitting in meetings at work
thinking about this stuff and then after
about five days I'd have an aha moment
run to the the computer and bang out a
rough horrible version that worked and
you know was was arguably a closure
program and then spend a couple of days
refactoring it into something that that
I wasn't ashamed of and then I would
have to set the whole project aside for
like eight weeks because I have a life
and a family and a job and and I can't
afford to spend every week like this so
it's been difficult
I mentioned being distracted by text
optimizations Tech is aggressively hand
optimized using techniques that we would
really sneer at today but the ability to
turn our noses up at those techniques
are gifts from 30 years of Moore's law
and
not just Moore's law but language
implementation techniques and things
like that I mentioned that he wrote it
in a pre-processed dialect of Pascal he
makes heavy use of macros for inlining
and I've avoided you know doing anything
that kind of thing in closure so far so
here is a snippet of the tech source
code as he meant for us to read it in a
typeset form and this is the V package
routine I'll go into what that does in a
minute
note all of the single letter parameter
and local variable names pH ml r WD XS g
and oh this makes me sad not for the
reason you think but because it
remembers it causes me to remember my
dear departed friend Jim Wyrick who made
this observation last year
let's look Oh so I mentioned macros so
almost all of these things in this code
that look like procedure calls or
function calls are little macros that
that are basically just doing indexing
into a great big giant array of Records
there are also these other things that
are named sections that are larger
macros that are used to take long
routines and and you know decompose them
for purposes of exposition and to walk
through this the purpose of V package is
to take a list of vertical mode material
including fixed size things like lines
of text and rules and and stuff like
that and pictures and also separators
that that have some stretch and shrink
and give to them and and to set that to
a certain size so it might just happen
to be the perfect size already or you
might have to shrink the the spacers the
glue in between some to get it to that
size or you might have to stretch it out
and that's what this this routine does
and so looking at the parameters P
points to the list of vertical mode
material H&amp;amp;M together are a height goal
H is a height and M why it's called M I
have no idea is a flag that indicates
whether H is an absolute height or a
Delta relative to the natural height of
the box that you should aim for and L is
the maximum depth that the box is
allowed to the resulting box is allowed
to have below its baseline so the
routine starts off by building up
allocating and initializing a box node
to return then it initializes some
tallying dimensions to zero so that can
keep track of things it loops through
the vertical list accumulating height
than width and depth and various and
stretch ability and stuff various
dimensions goes ahead and records the
width at the end because it's not going
to do anything with that it only messes
with the the height and depth it adjusts
the maximum depth if necessary by simply
moving the the baseline of the box down
it determines the difference between the
boxes natural height and the height goal
and then sets the proportional stretch
or shrink of the glue to fix the box at
that height if it had to stretch or
shrink the glue too much so that it in
Tech's estimation is no longer a good or
suitable bit of typesetting issues a
warning about that and finally returns
that box it took me a long time to
understand this enough that I could
explain it that well once the tech macro
processor gets through with that routine
it looks like this raw Pascal routine
here and the point is not to read it the
point is to see what it is
that's one Pascal function 182 lines it
is far from the longest function in tech
and the point is oh my god is not oh my
gosh that's a great big huge function
inlining is a perfectly legitimate way
of optimizing God he talked about that
yesterday he's not in lining for the
same purpose to allow an optimizer to
get at it but to avoid procedure call
overhead but the point is just to show
how much work he did to eliminate that
kind of procedure call overhead the the
outline of that routine in terms of what
it does and how it calls procedures
looks like this get node which allocates
a new box node everything telling up the
box dimensions is all just you know raw
code grabbing stuff from memory and
manipulating it if the box is too tall
then it calls a badness warning and if
it's too short than something the same
thing if something went wrong then okay
we're in error handling mode and we
don't have to be as fast and a whole
bunch of other stuff if everything goes
okay this 182 line routine will call one
subroutine and if just a little bit is
wrong you know there's a little quality
problems but no real errors it'll call
two for comparison here is the closure
version of V package it takes V list a
height goal combine those two parameters
into one a max depth it starts with a
new box tally which is a map of all
those quantities that we want to keep
track of and threads that through a few
functions that tally the list dimensions
adjust the maximum depth determine the
height set the glue warned about badness
badness is Tex fitness function or I
guess unfitness function and then turns
that that map with all those dimensions
tallied and everything and the glue
setting and everything else into a V box
record
I like that I you know you know for my
initial goal of making this making
what's going on clear and making it easy
to understand I think this is a lot
better
so what's lower because it calls a bunch
of procedures and functions and things
like that another little bit part of
that Pascal version version is this big
38 line case statement that as its
looping through the different nodes in
the vertical list handles different
types of nodes differently and does the
right thing in the closure version that
case statement is replaced by
polymorphic dispatch of the add to V
list function as shown here in the merge
updates function up there and then tally
list dimensions is just you know
reducing that list into the map using
add to V list and there's a lot of this
kind of thing in how Tek operates and
what khlo does and I think transducers
will help in some of the more complex
cases another interesting problem I ran
into was stateful i/o the DVI output
format that tech rights to is inherently
stateful it it consists of each page
consists of you know a series of
commands in a little binary language
with operands and to keep those small
all the distances are relative to the
current point and so you have to keep
track of the current point as it goes
and if there was just one current point
you might be able to like represent that
by composing your decomposing it into
function calls properly and and you know
passing that state as parameters but
there are actually three complete
different sets of operators that have
three different current points that they
work with and they're used for different
purposes and it really doesn't map well
to any kind of functional decomposition
so I wrote the first version of the DVI
output code using a thread local var at
a conversation a couple months later
talking about this Mike Nygaard
suggested maybe is the statement add
just off the top of his head I did that
I wrote a community wrote the whole
thing using the statement add
here's what I learned nobody actually
uses the closure statement and I learned
that because it has a couple of really
bad surface bugs that you know I had to
get around before I could even get very
much to work at all and and it was much
slower and you know perhaps in a
language where like Haskell where Mon
hands were your only choice for that
kind of thing you know the effort would
have been done to optimize and and and
make that the fast path but you know I
came away from this thinking okay
closure is an impure functional language
and it's that way for a reason and
you're better off embracing that when
you have a problem that needs it then
sort of twisting things to be all pure
and stuff so that was kind of fun and I
went back to the the thread-local of our
version and I'm open to other
suggestions for that but I wanted to
move on up the the stack and so I stuck
with that for now
Javadoc niño has these elaborate
facilities for gathering rights and
scattering reads where like you you give
you have an array of buffers and you say
write these buffers out to a channel
just start with the first one and when
you're done move to the second one and
everything else and then scattering
reads are the opposite you give it an
array of buffers of certain sizes and
say you know read from this channel and
fill the first buffer and then fill the
second buffer and on and on and I've
always been skeptical of the like how
use how many people that would ever be
useful to but now I'm one of them the
the tech font font metric file format is
basically a header saying here's how
long the widths array is and here's how
long the heights array is and here's how
long the depths array is and so on for
like twelve different arrays and then
it's just those arrays in there
and using that that scattering read
facility saved me loads of trouble and
it's blazingly fast and I will say it's
the only time so far that that I was
like man being being hosted on the JVM
has really paid off with a huge amount
of leverage
that I wouldn't otherwise have when
Ellen's talk about utility how can Chloe
useful to people well as I was working
on this and remember I said that that I
was I was finding that that trying to
design for 100% end-to-end compatibility
was distorting things that would
otherwise be quite simple and nice I I
realized that that what would really be
useful was to have implementations of
Tex typesetting and for formatting
algorithms that were composable tech is
very highly integrated it's a it's it's
it's so tangled up and and I mentioned
that all those things that have had that
have reimplemented parts of tech I've
had to do it completely from scratch
it's impossible to extract any part and
use it in isolation so I think it'd be
cool if clover made of independent
composable pieces and I started thinking
maybe that would be useful in a lot of
ways you know typography on the web and
in ebooks is pretty abysmal and I see it
all the time here's some examples that
I've found in ebooks that were lying
around on my laptop yesterday here's a
case where there's a line break right
before an em-dash that should never
happen em dashes should be at the end of
the line here's a case with a line break
right before an ellipsis here's a really
horrible widow line right up at there at
the top of the page one little part of a
word hanging all by itself and the
opposite case here's a an orphan line
there at the bottom the first line of
paragraph without the rest of it here's
a more subtle one in this left-hand page
there there's a section break or a scene
break and usually at a break like that
it represents a change of time or
setting or characters and it's pretty
obvious there but if you worship we're
reading this on a device of a different
size or in a different font
or something like that it would appear
this way with that break occurring at a
page boundary and if you were reading it
in single page mode instead instead of
facing page mode or if it happened to
occur at the bottom of the right-hand
page you'd be very likely to miss that
that break ever happened because the the
gap is hidden in that page break and the
trend and then then you know you read
the next line and it's really jarring
because wait a minute how does this
relate to what came before the
traditional typesetting answer to this
is to if the if the break occurs at a
boundary at a page boundary put a little
ornament there I'm sure you've seen it
usually it's three asterisks or or some
other kind of a short rule or something
like that but ebook platforms and the
web simply don't support that and it's
really kind of shocking that they don't
yet so anyway I'm redesigning focusing
on only the back end of that of those
all those stages I showed working on
making things independent and composable
and I'm looking forward to is act
Hellmann's talk tomorrow maybe you'll
learn something and the idea is that if
you provide a list of objects that
implement the proper protocols you can
use closed formatting in arbitrary
contexts
I have a hunch that these protocols will
get simpler as I learn more but here's
kind of what they look like today
there's list element where you can add
two v lists add two h lists say whether
this is a valid break point or not or
whether it disappears after a break as
some things do elasticity is about the
way that that parts of a page can
stretch or shrink page element and line
element and finally kerf how many people
in here other than Timmy wold know what
a kerf is a few it's the the gap between
piece and two gap in a piece of wood its
how wide a saw gap is when you saw a
piece of wood and after tech was
finished his Knuth
grad student that worked with him on
line breaking Michael
published a generalized version of the
tech line braking algorithm that can
also be applied to choosing page breaks
for a long chapter and generalized some
of the breaking different types of nodes
and everything into something called a
kerf and I've incorporated that so
that's the current status I'm kind of
redesigning around this kind of thing
and and taking out some of the
distortions and complications in those
algorithms that I had put there to try
to make way for supporting all the front
end stuff and who knows maybe I'll get
around to supporting all the front end
stuff on top of the more composable
general back end and I'll have to make
decisions about how compatible it is and
that's fine
I'd like to close with a reflection I
frequently hear people say you know with
frustration and exasperation and I can't
believe it's 2014 and we're still using
I don't know what you know green screen
architecture on the web or MVC for
crying out loud or IDs that focus on
textual source code instead of you know
visualizing your program and things and
we use crappy debuggers and we debug
with logging instead of doing it the
right way and and we have in some
inconsistent command-line interfaces and
you know on and on and on and as someone
who's been spending a lot of time living
in code written in 1982 I have to invoke
louis c.k and say everything is amazing
and nobody's happy
so you know Stu introduced me by asking
you to take a journey to 1987 so let's
go five years farther back
it's 1982 and let's remember what this
was like
it's 1982 and computers are really damn
slow memory is tiny most programmers
have never seen a multiprocessor much
less have one in their pocket we have to
deal with different word sizes and
different bite sizes and you have to
worry about whether your machine or your
file or whatever is big-endian or
little-endian I Triple E standard
floating-point is still three years away
so different machines have different
semantics for floating-point operations
if you want to write something that's
widely used and portable you have to
support I don't know roughly thirty
eight different operating systems and
each of them has different file system
structures and different paths syntax
and different IO api's and different
memory allocation api's and you know on
and on that's just the beginning don't
forget that you have to support episodic
in addition to ascii you can't
dynamically load code optimizing
compilers are still research projects to
compile the Pascal compilers that Knuth
wrote tech for didn't even do constant
folding so there's a bunch of magic
numbers in the code there Oh while we're
on the topic of compilers compilers are
proprietary and they compete with each
other by supporting incompatible
features dynamic languages are too slow
for almost anything so is garbage
collection everybody you know writes
long procedures with go-to s and single
letter variable names and nobody
understands why you don't like global
variables as for two tools
well GUI max is still two years away you
can use VI not vim but only if you're on
Linux and you probably aren't you can
use something IDE like if you're at
parkour Tektronix and you definitely not
aren't let's face it
there's no open source there's not even
any free software yet source control
well let's see no no there and that's
only if you're on UNIX no there's not a
library for that right at yourself even
things we now consider incredibly basic
like common data structures and calendar
routines there were no standard or
reusable libraries for at this time this
will be some of you will recognize this
and laugh and others will you've got
jaws will fall open at this at this
point in time it was a part of the
working knowledge of most professional
programmers that January 1st of 1900 was
Monday why because there were no library
routines to tell you what day of the
week a particular day date fell on and
the easiest way was to calculate how
many days it had been since January 1st
1900 and used that to index into an
array modulo 7 and the first thing in
that array had to be Monday its 1982 and
TDD is still dead more seriously
automated testing of any kind is almost
unheard of so the ways that we can
program today are luxuries made possible
by decades of small advances
I'm not even beginning to suggest that
you don't just settle that you just
settle and and not try to improve things
if if I thought we should not try to
improve things I wouldn't be at a
closure conference but for crying out
loud enjoy it once in a while thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>