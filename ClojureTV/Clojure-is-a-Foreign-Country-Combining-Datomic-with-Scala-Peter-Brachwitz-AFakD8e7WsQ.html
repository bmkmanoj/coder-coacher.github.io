<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Clojure is a Foreign Country: Combining Datomic with Scala - Peter Brachwitz | Coder Coacher - Coaching Coders</title><meta content="Clojure is a Foreign Country: Combining Datomic with Scala - Peter Brachwitz - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Clojure is a Foreign Country: Combining Datomic with Scala - Peter Brachwitz</b></h2><h5 class="post__date">2016-11-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AFakD8e7WsQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hello everyone my name is Peter I'm
working for Cisco I'm going to talk
about our experience in using the atomic
from an application that's not written
in closer but it's written in Scala so
for some of us closure was a foreign
country and how can you say that the
atomic is not a closure database the
atomic is a JVM database if you will but
at some point you you come into contact
with its roots in closure and for a
scala team that can be perceived as
something foreign but before we discuss
this question why this is foreign a bit
further let me show you first what we
did and how we did it so the problem
domain in the problem space that we're
talking about is sort of configuration
management but not in the traditional
sense where you configure infrastructure
but on an application level where we
wanted to configure whole service
software as a service platforms from a
new application so from a database point
of view that's not a very right
intensive task like you'd as people
users setting up configuration maybe
testing it and then sending it to remote
systems to configure them the only other
requirement we had is that the whole
thing that we were building should be
deployed in a sort of cloudy environment
and which is something you can do with
the atomic but i think that was not the
only reason why we chose to do it there
are some other compelling reasons that
seemed to make it a good fit for this
problem for example the property that it
does know in place updates but sort of
retains all the history of your data
which is useful if you do configuration
management you want to go back to what
you had before the fact that it has
something
or what you could call reify
transactions and now going to show you
in a minute how we used it for auditing
purposes but more than anything else I
think what made it attractive to me is
that it has this interesting hybrid
nature where it combines some of the
things we appreciate in traditional
databases which is for example having a
schema or Essex acid semantics if you
need them with some of the properties
that sort of the newer no sequel stores
have which in the Atomics case is that
you can scale the reeds horizontally so
the stack we use to build this thing
look like that and we are using a think
of the play framework which probably
doesn't tell you very much if your
closure programmers but it's sort of a
very popular web and HTTP framework in
Scala we were using a lot of cues in
between these different components to
ship the configuration to its
destination and we're using a technology
called Apache artemis for that formerly
known as honored queue which happens to
be also one of the underpinnings of
diatomic and we used atomic in
combination with Apache Cassandra so
assume a general familiarity with the
atomic in this audience so you can you
have to choose a sort of storage service
when you use the atomic and cassandra is
one of the options you can also choose
react or amazon than ammo and others but
we already had patchy Cassandra
deployment is seemed to be a natural
choice so if you would like to visualize
the thing you could draw boxes like
these right so we have a we have some
sort of you I a browser users
interacting with you able to pay
application through a browser which we
are serving through our API server which
gets its data from at least three
Cassandra nodes that's how many you need
when you use the atomic as the minimum
presumably to mediate different
consistency sort of profit properties of
a eventual consistent data store with
Atomics consistency guarantees
and then I think the interesting thing
with the atomic does in order to achieve
these sort of hybrid properties is that
it breaks up the database into its
components and has them as separate
processes so that the Cassandra notes
are sort of the storage service then you
have this thing called the transactor
which is the single writer who writes
back into the storage from your
application the transactional data you
send to them and then the third power if
you zoom into your application process
there's a thing called to peer library
which does all the heavy lifting when it
comes to running your queries based on
cleverly cached index data so you have
to of course sighs your heap accordingly
in your application so with this sort of
setup we thought we would be well set up
to sort of handle also future demand so
if this application would become
tremendously successful we thought we
could just scale by adding more API
servers or maybe at used a high
availability option on the transactor
but how do you actually go about using
the atomic from from Scala well the
first thing is as I said the atomic is
not a a closure database so there is
it's a JVM database that there is a java
api and you can just use that with
interop there is similar good inter up
in Scala is there is good Java interop
enclosure but of course people start
building libraries around these Java API
is because it's not very emetic usually
to use a Java API from from its Carla
application so there are two libraries
that try to do that one is called data
miska the other one is called molecule I
mean theory there's also the REST API
but I haven't really explored how viable
that is to build anything on the top of
that and I want now to take a very quick
look at each of these libraries because
I think it's quite instructive to see
how they approach this problem of
adapting
and atomic to this other language so
this is I hope is it's readable is an
example that I've chosen from the data
miska library and I think I've chosen
that because in my mind it exemplifies
the philosophy behind this library quite
good because even if you don't know
anything about scala but you have
written a diatomic data log query you
recognize this immediately because this
is just a query right there now you
could say if you know something about
scala well that's a bit lame that's just
a string right it's actually a bit more
clever than that because this query
thing around is actually a scala macro
that parses this query and returns a
type representation of it that at least
tells you something about it how many
input see how many outputs it has but
keep that in mind that this is a scholar
matter i come back to that point later
when we talk about problems so i think
the philosophy behind this library is to
to represent today ideas or features of
diatomic as closely as possible in scala
without adding any conceptual overhead
just sort of wrapping type
representation about these sort of
untyped data structures and to take a
quick look at the other library molecule
with which is also very impressive in in
many ways but what you immediately
recognize is that you don't recognize
the atomic here so that there's a
there's a conceptual layer in between
they have chosen to build a I don't know
maybe object-oriented builder pattern
style dsl on top of it and these two
things that we just saw this one and
this one is the same query right so we
choose to use data miska also because i
wasn't aware of molecule when we started
out with this project but let's talk a
little bit about what i call the happy
path things that worked really well that
translated nicely from closure or java
into into scala and one thing is of
course and that follows from this
property of
not doing in place updates of retaining
all the history of your entity zing of
your attributes is that you have the
history of everything available for
queries and that is in itself very
interesting but what I sort of find
remarkable in retrospect is that this
that the simplicity and the same time
flexibility of the underlying data model
sort of has a lot of potential potential
that you're not aware of when you start
out so to illustrate that so we had we
didn't anticipate certain requirements
that we had to implement only model
doubt our our problem and at some point
a new requirement came up that we had to
implement sort of a corporate the
typical corporate password policy and
one of the constrains of that password
policy was that huge were not allowed to
reuse passwords you had used previously
so when we thought about how go how do
we go about implementing this we
realized oh hold on a second we don't
have to change anything in our data
because it's everything is there we just
need to write a query that and I've
translated that for your convenience to
closure that goes into the history of
this attribute of the password hash for
a particular user for that hour all the
historic values of that password hash
and compares it with what we what the
user proposes to use as its next
transport to answer that question is
this a valid new password and the other
thing that follows from that of is that
you can sort of time travel you can
retrieve a mutable version value of your
database from a from one instant in the
past and work with that and again this
is something that's on the sort of
conceptual level of day of diatomic that
translates nicely into any language you
use with it as long as the api's allow
you to to to retrieve it I guess so when
we had this requirement for example to
build an API that also gave you historic
views on this data that was trivial
threat because it's already there now
you can also to some extent travel into
the future with the atomic and it's
maybe not the future but one of many
possible futures sort of the Star Trek
kind of parallel universe future because
what you can do is you can use an API I
called with takes a database value and
some transactional data and you can in
your application process calculate a new
sort of speculative version of that
database how it would look like if you
were to transact that data so you don't
go to the trans actor who is the single
one that you do that in your application
process and we use this in I think two
ways one way was that when you have
relationships between entities let's say
you have an entity be that requires an
entity a to be present and let's further
assume that a has a unique constraint on
an attribute so what might happen is
that when you try to actually transact
that into the database that this
transaction made failure because there
is already an entity similar to a with
an attribute with that same value in the
database so you send all the data to
transact and comes back and says well
it's not possible but we did instead was
that we used this speculative version of
the database before actually going doing
the round trip to the transactor and
transact it or assert that the entity a
and catched in quartus this error early
and didn't even bother to calculate B
which might be expensive and didn't even
bother to go to the transactor now of
course they are some some pitfalls with
this approach because this speculative
version of the database is sort of a
local view but what I'm the point I'm
trying to make here is that it's sort of
again one of those concepts that you can
use no matter
where you come from which language you
use and the other thing I mentioned
earlier is that the atomic has this idea
or this concept of reify transactions so
if you think back to a traditional
relational database transactions are
essentially ephemeral right they exist
only while you execute them and what you
then have in your database is a sediment
of that transactions but a transaction
itself is gone and in the atomic the
transaction goes into the database is
just another entity and that opens up
possibilities for interesting
applications because you can now add a
tribute to this entities it attributes
like audit information this is what I
think many people do and what we did
also to record who triggered this
transaction and maybe why and where did
he come from and things like that and
here you see I mean this is is this
Scala code but here you see how the
library we used is similar in how it
treats this transaction data it's just
data structures and these two plus signs
we're just concatenating the transaction
data that the user wants to transact and
our additional audit information in a
similar way as you would concatenate to
closure lists or two to maps of maps or
something so this is the same concepts
the same sort of you work with data
structures also in the Scala library
that we used to interact with the atomic
so these are the things that I think are
worked really well and where we didn't
experience any any friction but I think
you might be interested in those cases
where we had to put in a bit more effort
where there was more work to be done and
and one of the aspects is where dynamic
query so if you remember what I said
earlier about how great is they to miska
library isn't that it passes query
strings with a macro into a type
representation then you have to know
that scala macros run at
pyle time and there is no Scala compiler
at one time usually available so that
means if you don't know the shape or
form of your query at compile time you
have a problem if you have flexible form
by a user can sort of build together a
complex query doesn't work as well but
queries in the atomic are just status
changes right you can just
programmatically build them up but I
think this is some of the areas where
the library use didn't offer anything
and we sort of didn't make the effort
because what we did here is we don't
build up a data structure if you look
closely we are concatenating strings
this is probably something you don't
show at a presentation normally it's not
very composable but you know things
happen another thing which I want to
talk about is this tendency to sort of
build something like an or M on top of
day Tommy and or answer the sort of a
bad reputation I think for a reason but
if you think about what they do they do
many many things and that's part of the
problem but I want to highlight two
things that they do one is that they
sort of reshape your data right you have
circles and you want squares you have
relations and you want objects or maybe
you don't want objects but that's what
you get and the other thing they do is
they force you to access your data in a
slightly different way if you use an RM
but instead of using maybe sequel if you
use a relational database to force you
to go through an interface that's maybe
a method or an object or maybe a dsl and
object-oriented dsl that almost looks
like sequel but has only a fraction of
its expressive power and I think this is
where a lot of the criticism comes from
so having said that I think there are
some legitimate concerns in this
approach right you we wanted to have I
think domain specific types we wanted to
transform the data that we got from the
atomic into something that's called case
in Scala and a case cars can look like
this is a person case clouser has a
first name and last name and email if
you into type theory I think you can
call this a cartesian product of three
components or enclosure there's a thing
called death records I think quite
similar so how did we get that um we got
us in this way and I promise is the last
bit of Scala code I'm going to show so
you see this is the way we defined our
diatomic schema for this fictional
person case guys ever just shown you so
we define a string attribute for the
first name and the last name and for the
email we want a unique index that you
can use the email only once and then
this implicit magic at the bottom of
this piece of code so if you don't know
anything about Scala you can think of it
approximately as a sort of prologue like
logic programming engine inside the
Scala compiler that answers questions
like I have a diatomic entity here and I
want to use it as a personal tight is
there anyway given the implicit
conversions in scope to transform one
into the other and this the system I
think worked really well it for us to
some extent once we had worked a head
around it and that it allowed us to
almost transparently use the atomic
entities and turn them into person case
gases in this example what we needed but
at the same time I always have this
reservation or Association of a bucket
brigade right so you you you transform
from diatomic entities to scholar case
classes and then you transform again
maybe into another representation that
you use then in your API maybe Jason
so you write a lot of code about buckets
when you're actually interested in the
water but of course this is just an
expression of trade-offs you have to
make it that you have to to always make
and once we had decided we wanted geez
idiomatic scala data structures I think
some things had to go and the things we
lost of course is first off laziness
once you tip one bucket into the other
you materialize the entity and atomic
entities are lazy but when you
materialized and we load all the
attributes that are modeled in Europe in
this case class and you're strict
suddenly the other thing we lost is the
ability to build I don't know how to
call it modular entities if you will so
in in diatomic you know this is best
practice to say an entity is essentially
a set of attributes that are grouped
together by a common ID and it's best
practice to use the same namespace for
the things that appear at the same time
but it's there's nothing that forces you
to do that you can actually have a nice
modularity how you model your problem by
adding attributes as you need them to
and from these entities because as long
as they have the same ID that they're
considered an entity and the way we did
this by tying our code to the data and
if you remember that piece of code I
showed you this is all one name space
where we build this schema we lost is
this capability and what we also made
much harder when doing that is working
with sparse data so the atomic in itself
can work great but sparse data so by
that I mean you have entities some
entities that have an email address and
some entities that don't have any no
dress
and an entity is just you know as I said
a group of a set of attributes bound
together banned by a common ID so
there's nothing that says an entity in
the atomic nut needs to have DS in these
attributes and that's sort of similar to
what I think what happens enclosures
back where you spec on the sort of
attribute level and you don't spec a
person respect the attributes of a
person maybe then you do another maps
back that defines the keys that you need
to have an adoption but with our
approach so having sparse later became
much more complicated because you have
to think now very carefully which of
these attributes are always there and
which ones are only sometimes there we
might say well of course you have to
think about how your data looks like in
advance but I think the problem is more
subtle because over time the way your
data looks might change right and when
you tie your code the way you did this
you need a very robust migration
mechanism if you introduce new required
attributes but don't have a default
value then you have to sort of take care
of that situation than migration
mechanism to add these to all the
entities that don't have it yet
otherwise your code breaks and there's
another implication of that sort of way
of doing things and that is that you
limit your ability to try and travel at
the same time I just told you earlier
how great it is and how nicely that
worked but in combination with dis
approach what we of course have is that
your code doesn't time travel with you
as you go back in your in with the
database through time and so you have to
take extra care if you want to use that
sort of time-traveling property you have
to build your code in such a way that
it's flexible enough to accommodate the
absence or presence of certain
attributes let's say
now there's more to be said I could I
think talk about how we solve the
problem that you cannot store large
binary objects in India Tomic or we
could talk about how we solve issues
around ordering things because what you
get back from the atomic is just sets so
when you are entities don't have a
natural ordering that you can apply
afterwards how do you go about that we
could talk about the how great it is to
get emacs out and write a transaction
functioning enclosure and how
anticlimactic it is then to copy that
code into your Scala IDE but I don't
want to do that now instead I sort of
want to zoom out a bit from the diatomic
Scala picnic and think a bit about the
broader implications of using a
technology like atomic and I I think
what I've observed is that it has a
certain effect on you and you and your
team that sort of goes beyond providing
you with a database solution it has this
where I would call a cross pollinating
effect because some of the idea is that
its core are so powerful like for
example that data is at the center of
what you do of how you solve your
problems that it sort of seeds into
other areas of the things you do and
influences solutions you find and design
decisions you make and one example I
want and want to give is this so
remember what I said earlier about the
application that we were building about
the problem we're solving right I said
we were doing configuration management
so we were sending chunks of
configurations maybe throughout you to a
remote system but it would be applied
now this has nothing to do with atomic
this is the part of the system where
atomic is not involved these are legacy
systems that are we configuring with
completely different data stores but
these data stores are not empty right
there is already data in there so how
does this new day
that's coming in relay to the existing
data so you need some sort of mount
point and the way we solve this is is
this so you could interpret this chunk
of Jason as follows by saying when this
reaches its destination then have a look
for a company called Acme incorporated
and if you find a unique result for that
then add a new person to that company
for been bit little now in this in
retrospect seems to me awfully similar
to what the atomic does with lookup
breaths where you want to work with an
entity but you don't know its ID so what
you what you can do is instead of using
the IDS you use a unique attribute of
the entity and its value and can use it
in every place where you usually use the
the ID and it's replaced and that's
nothing else what had what happens here
so we basically replace this inner
object is nested object with the ID of
the company they don't know because it's
somewhere else so I think the point I'm
trying to make you that you benefit in
unexpected ways from from using a
solution like the atomic and it sort of
has as an influence on what you do
beyond being a database but I want to
zoom out even even more now and come
back to the original question so why is
this if all I said is true about the
atomic and the way we adopted is why is
it then still that we can describe it as
far in our closure by association as
foreign and you can look at this this
problem from many perspectives and
angles i think but there i want to look
at it now is sort of inspired by a
German sociologist called Niklas Luhmann
and he described the horses whole of
society as systems of communication as
recursive cells referencing and
self-reproducing systems of
communication
and that's just an aside he has a very
interesting if you if you want to follow
up on this intellectual sort of
genealogy that points back to Spencer
Browns laws of form Alonzo Church and
what was back then called cybernetics
research so but if you take now his sort
of look at things than what we would be
discover what we observe is that this
tendency in our field of software
development to introduce more and more
distinctions to break it down in smaller
and smaller groups or communities or
ecosystems equals fear as many of them
any words for this illumine would
probably call them systems and there are
different kinds of reasons for that
there are economic interests at play
here but also if you look at the media
we use to communicate and they sort of
facilitate this this process just think
of of Twitter I think today is somewhat
unique and novel in its in its
properties in that it allows you to have
the impression you're talking to a
global audience but what you're actually
doing is you're selecting very carefully
who you want to listen to and which
parts of which information you want to
exclude so it has this it reinforces or
even creates its effect of sort of
breaking the field down into smaller and
smaller feet and almost can create the
impression of an alternate reality now
of course this observation is just it's
just specialization what's happening
here we're specializing their
specialized meetups foreclosure Scala I
don't know react GS conferences like
this one their mailing lists and other
ways and forms this is just a field
specializing itself but if you compare
this with the urinations ideal of the
warmer una batalla so this person who's
master of all disciplines then we know
that we cannot be that kind of person
anymore not a single scientist today can
be the master of all scientists sciences
not even of his own fear pure
sort of mast of a subset of your field
even as a scientist and I think the same
is more and more true with bits of the
development right so so what does that
mean I think it means that there is this
interesting tension between mastering
the tools that are close to you maybe
because they solve the problem for you
in the past or because they were
familiar to you in the first place and
processing this sort of irritating
amount of novelty around you and of
course learning new things is good fun
right but it's also expensive so and
even if an adoption of a technology like
the atomic works as smooth as it went
for us I think and I don't think we hit
any major roadblocks despite what I said
earlier then they're still the price to
pay yeah you have to invest in learning
this in convincing your team members to
use it may be convincing your boss to
use it today's there is no simple answer
for this problem how to deal with that
but I guess what you need is is an
additional skill so instead of just
mastering rug your craft of sort of just
being the best closer developer on the
planet you also need to still have a a
new sort of scientific skill which deals
with the complexity of options that you
have to choose from and that skill means
looking at those things that are not
close to you that are further away and
pulling them a bit closer to you to have
a better look and to decide whether you
want to pull them even closer and make
them part of what you do and I think
that's all I have and thanks for your
attention
I</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>