<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Save the Princess - Simon Belak | Coder Coacher - Coaching Coders</title><meta content="Save the Princess - Simon Belak - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Save the Princess - Simon Belak</b></h2><h5 class="post__date">2017-08-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SpLlsM2amuU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you
I'm Simon and I've just freshly became a
developer for mr. bass which is an
closure based open-source bi analytics
tools so if you're working with data
check it out but today I'm going to talk
about something completely different I
was originally I was looking back at the
previous series of conferences and think
about which books resonated the most
with me and it was quite clear the ones
I love the most
were those where people just went and
build something where they did something
for fun so and like actually my favorite
book of the last year was our very own
Karen Mayer speaking right here your
closure 2016 about the evolution and how
can we use spec and things like that and
that public Anna stay would be
especially her enthusiasm and sense of
playfulness so I'm hoping that I'll be
managed to channel some that today to
you as well so what we're going to do is
quite a bunch of things we're going to
build an AI I guess it is kind of server
the theme for this day and it's going to
play a silly little game saving the
princess and we're going to do we're
going to build this AI by employing
what's known as reinforcement learning
but we're twist we're going to Train it
we're using a completely new hot or this
very hyped algorithm and we're going to
implement that algorithm starting from
the paper and transferring it into a fur
coat using hands full which will be also
heard today but we're going to take it
one step further and try to make it kind
of massively parallel using onyx so it's
going to get a combination of
all my favorite technologies and some
Messing's on machine learning and stuff
like that so let's get started the game
is rather simple as and you can find out
the princess doesn't really saving but
whatever so what we're going to try to
do is have our hero code the princess
arm by the shortest path possible can
move up and down left and right and we
should be mindful that we don't fall off
the edge into the endless void so that's
again very very simple just something
that we have a small environment that
can plane so what will
whereas some kind of AI this figures out
that it needs to go up up up up up and
then left left left left pretty simple
but it turns out it kind of it does take
some time for computers to figure
dessert so how do computers can play
games this is sort of using computer
games for researching AI has kind of
came in vogue in the last couple of
years actually spearheaded by google's
deepmind and what the approach is the
kind of mostly using is what's known as
reinforcement learning which i think is
kind of one of the cooler deep learning
approaches or machine learning
approaches currently being present I
think overall in other ways if you look
at what kind of state of the art in
terms of machine learning it kind of I
think it kind of it found this local
optimum at the same time we don't we
aren't really progressing towards like a
proper general AI and if any person is
promising I think it's enforcement
learning is the one which holds the most
promise of being something actually
going to general or copying how we
function in the world at least from the
more well-known approaches up like the
dope we heard previously today was
something that seems very interesting
but hasn't gained the prominence yet um
so basically the idea with reinforcement
learning is that we have an agent
situated in the world and this agent is
interacting with this world and it's got
learnings bye-bye lapses can have some
feedback mechanism where the agent makes
various actions and then gets feedback
from the environment either immediately
or in some future point of time and it I
dia is that we aren't here looking for
one specific solution one specific class
or a predicament but rather what we're
looking for is a general approach of
policy of how to act when the
environment changes so again it does
seem to have the building blocks of what
we at this currently reckon also makes
us think and is kind of component for
general intelligence so we have embodied
cognition in the sense that the agent is
actually interacting with the world we
have the agent has to develop some
model of the world and of itself um to
kind of pick the best action for giving
circumstances one might even go star so
this is fundamentally different the
kernel of consciousness that you asked
both the that you're both simulating
yourself and your future actions as well
as kind of being able to step into
another shoes or you can in the shoes of
your environment and thinking from that
perspective so there is this kind of
kernel of that there and we also have
this going to a very classical
carrot-and-stick approach to learning so
as a kind of pretty exciting Knology
currently how most people go about doing
it is that they build a huge huge
general Network spend a lot of time lot
of money training it and but we have a
gallop twist that instead of doing any
sort of future engineering engineering
meaning that's like figuring out what
kind of data to feed your neural
networks they just usually take a huge
um just the screen all the pixels and
just send that and the network first
learns to kind of be certain various
things from the image like we were just
kind of watching what's happening in our
environment and then actually builds on
top of that understanding which
participate is obviously is very very
elegant because you don't have to spend
all the time thinking about feature
engineering that's also promised to be
quite generic arm but it is also rather
computation expensive as you can imagine
because we actually have solving two
problems at once this little bit of
machine vision and then also trying to
play our game there is however another
way to do this at least kind of in terms
of training and it's what we're going to
be talking about today arm the paper
I've kind of mentioned a couple of times
is this is called evolution strategies
as a scalable turns if to reinforcement
learning arm and the kind of idea is
rather a rehash of an old idea that is
to combine two of the main nature
inspired algorithms neural networks at
evolutionary algorithms and use
evolutionary algorithms to train a
neural network so kind of just some
background in the classical evolution
algorithm the ideas that you have our
population that kind of more or less
well solves your problem and then you
take that population
you some mutate some of the elements of
it and you cross over some of the others
meaning muted make a small change or
cross over just going to take two and
make them copulate and get a new version
of it and then with that create a new
bigger population and then sample from
that population weighted by how well
they're performing a new task and that
gives you a next-generation and so forth
at infinitum now the algorithm presented
here that we know today is just kind of
the idea is still the same but it kind
of I guess it comes more mathy and
instead of having this specific steps of
crossover and mutation what they just do
is just determining just introduce some
small amount of noise and then just
combine different versions of the same
we can wait it on obviously I mean you
never can have a population per set or
just invite is an intermediate step but
I just have a one solution then creating
very various different versions which
are slightly different noisy and
slightly different and then combine them
together to the next solution but we'll
go through because later so it's kind of
still the idea is the same but it's more
in the messy domain and also like in
some sense oh spec I have to say it is I
think more elegant right so when using
an evolutionary strategy to train a
neural network the kind of the core idea
is that instead of using back
propagation um we use evolutionary
strategy on the weight so kind of
normally how you'd pay a new network is
you it you'd have all them the weights
and then you'd send your data through
the network result and then look at the
error of that result and then it'll
slowly kind of propagate that error back
towards your network and this is called
back propagation but it does have
numerous problems the biggest one
problem like the two main ones are that
it is like it does require like it was
already mentioned today it does require
that your kind of fitness function is
more or less continuous and well-behaved
it was so like the deeper your network
the more problems you have because the
information gets more lost as you
traverse
that Rebecca so there's curve is
definitely room for improvement and
Aleutian cell just bring a couple of
very nice features to the leg round
first of all they are highly
parallelizable much more so than normal
new networks where usually arise them by
just sort of training batches and then
combining they are much more robust they
you have there's almost no hyper
parameters to tune it's much more stable
it doesn't care but that's much about
properties of the word function this is
very important because you can have like
very unevenly words or something like
that maybe just kind of very late in
time so the kind of it there's a lot of
lag between the actions being taken and
actually seeing what changed this
affected in the world and the evolution
Alison just doesn't really it doesn't
leak air about those things
um because like you aren't using ah
that's so much yarn propagating that so
it kind of it can have very discrete
jumps around and that makes your life
much easier and you don't actually going
to have to bend your problems to the
mathematics of the tools you're using
with work and solve it more directly um
it can also like if you want to make a
more advanced version it can also kind
of exploit structure because um instead
of kind of viewing the entire network is
this kind of continuous flow of data or
of errors going back you can actually
kind of do evolution on each individual
layer something that if you have some
well-defined structure you can use that
spectra in your training again because
you don't need this entire propagation
on and it is less computation expensive
it's because it's much much cheaper run
but this on their hand which if we move
the downside the problem is that it also
takes significantly longer to converge
so like it seems that it's in terms of
how fast it works it seems to be roughly
kind of unpair with what you'd get
planning a neural network because you
can it's faster but takes but it takes
more data or more steps um but still it
does because oh they are promising
properties and just because it's going
to be simple and it's always kind of
nice to have a simple building block
rather handsomely super-complex I do
think it has kind of a lot of potential
and garroting is it which sometimes
might trip you up is that it you do
because you can working with introducing
small amounts of noise and hoping for a
change is your network actually has to
be that's it can't be too stable because
if among some amount of noise doesn't
really change the output you have
nothing to go on and it's going to get
stuck so this is something to kind of
keep in mind right so this is kind of a
precursor theoretical about what we're
going on but now let's get our hands
dirty and try to build the main
components so first the Aleutians
retrospective this is going to be the
entirety of the algorithm so and as it's
written in the article nothing too super
complex but it does give us a nice
approach to that and rather
straightforward which is kind of nice so
um yeah as I can review the outline the
idea is that we start with some initial
solution and then we create a couple of
vectors of noise or basically just
sampling Gaussian noise um and then we
see what happens if we add that noise to
our solution we run it through our
fitness function and see what we get
back and then we're just going to wait
all those results and use them to update
our weight so it doesn't have a
selection for instance like the
classical GA has but rather always uses
old solutions and just where are all the
permutations and just uses them based on
what they contributed to the overall to
the overall performance okay so how
we're going to implement this is as
promised using an Drupal which you
already know is blazing fast matrix
algebra and linear algebra libraries arm
it runs both on CPUs and GPUs like when
I say chrome massively fast it's like at
least magnitude faster than what you can
get with vanilla Java and I'm nothing
not in this jar not even in closing
basically it because it does really go
mentally it's also like it's one of
those um simply fantastic closure
projects which I think that even if you
have if you don't have much interest in
the stuff I'm talking about today just
kind of go through the code because it's
an amazing study in how to make close
echoes performant rather have any JVM
code performance it's like it's an
amazing study in how to eke out every
last bit of problems although it's also
kind of carries some weight because it
is at the same time was like the API is
thirst to put it nicely it kind of off
sometimes it takes a while to wrap your
head around especially if you don't have
any experience with it can the
underlying libraries like Atlas or Lebec
but um once you get used to it it is
also it has immense expressive power can
sort of like reminiscence of something
like J or K language and it does also
have like a higher level library called
flow kittens which is kind of another
spin on the kind of bringing category
theory to closure so you get various
foods and metals and stuff like that
very optimized for working with the same
data structures the NFL is also using
right so um this is basically the
entirety of the algorithm and we're
going to walk through working them see
how it maps to what we're doing so um
it's kind of a common approach as I will
like this idiom arm when you're kind of
trying to do some form of machine
learning usually you want to iterate for
some steps and a primitive iterate or
just kind of obscure maybe but here is
this is what it was made for so a really
elegant solution will essentially kind
of generates infinite number of
iterations but just take however much we
want and take the last of those and
that's our solutions could also graph
instead of just take a fixed number
maybe have a predicate or something like
that okay so um first basically we just
we we sample from the Gaussian noise
okay we're just going to we we simplify
our life somewhat and just take a kind
of a matrix of those dimensions with
that noise so it's going to pre-stressed
word and then we need to go through all
the
of that matrix and calculate what our
new reworked is going to be so and this
is kind of here we encounter the first
actual Neanderthal that's the cryptic ax
by yby um so what this does is it's
going to get a family of functions which
can encode what they're doing so you
have these the general form is kind of
is going to be one of those either
you're kind of summing two vectors or
here we are multiplying one vector pass
by a number and then summing with the
other we can multiply first both and
then summing them up and the name feel
better kind of encodes this so we have a
for the first color and then we have X P
for plus and then Y and the end of the
optional B is not in the name and the
nose kind of comes in the version with
the bank sign where it actually mutates
the last argument and this is kind of um
what you note is going to be that's a
lot of things at once and it's kind of
cryptic but it's also blazingly fast um
and once kind of at first it almost
seems the day the options offered by
UMSL are too limited but once you start
going to using etiquette you get into
the groove and you figure out that you
can combine a couple of them and their
magic pulls out so um it is a gues also
kind of a nice complement to how
mathematical or machine learning artists
are usually written muchos currents tend
to be put eaters and use quite condensed
mathematical notation and here we were
just going to have probably like even
higher expressive power using that um
like I mean I guess the acronyms should
help although I'm pretty dyslexic so I'm
always kind of useless with what the
what the actual letters mean I have
either think or documentation but that's
kind of probably the only downside
honestly to me and this all is just that
but I think um it's kind of it I would
like I like that we also have another
option in Cole dot matrix which often
times like if you want to do some quick
prototyping some of that this what I
would turn to but once we talk about
actually kind of implementing an
algorithm for production near the for
all the way because of its go
performance analyst it's such a
well-written coded can it's easy to
crust it okay sir ah digression on the
interval but otherwise what we're doing
is going to be straightforward so as the
name implies we're multiplying our noise
by Sigma so is kind of making it
essentially kind of smaller in magnitude
because otherwise we have this kind of
normal distribution on where the
magnitude would be too high so we kind
of compress this and we added to the to
our initial weight and then we look at
what the rewards going to be for that
collect all the rewards in a new vector
code rewards and then we have the steps
actually one but where we deviate from
what's in the article and that's
additional step where we standardize
meaning that we are essentially Center
so we on subtract the mean of the data
and divided by standard deviation this
is kind of this is something that um
it's very often London Flickr in machine
learning maybe sometimes it was kind of
a bit of a cargo cult when you don't
know what we're just kind of let
standardize this or let's put some
randomization here but it does kind of
it tends to help with end of things
converging fast and so forth if you read
the paper they actually have our
discussion on this and kind of
theoretically it's a step that's not
needed but when I was kind of if you
look at their actual implementation
they're using it and also like when I
was going around with it does seem to
make convergence happen slightly faster
so yeah but it's one of those things
were it's a bit of a black art and then
we have the last step of our algorithm
where again we're kind of leveraging the
full potential of young before and what
we're doing is that we want to sum up
the contributions of all the slightly
perturbative weights and add them to our
initial weight and we're also going to
normalize this by a new learning
learning rate so we can we don't have
too big of a jumps and how much our
guess of the solution changes and get
the MV Bank
stands for matrix vector multiplication
bang meaning that we're going
to mutate the last arguments and so what
happens is it first we titled this
damping factor by taking the learning
rate and dividing it by population size
and Sigma again so this is just kind of
population size because we're going to
sum up many of them so this is sort of
like um doing the mean and then Sigma
because we multiplied there and to
remove that signal and learning rate is
the kind of damping force we said okay
we don't want to have very big steps and
I've written so that's kind of our
damping we multiply the damping by with
our nice matrix and then we multiply the
noise matrix with the rewards so that we
get kind of each then each row in the
matrix becomes weighted by its reward
and we add that to our initial weight
using the final solution here um like if
you look at the code up there it there
is also a more readable solution
available if you just kind of instead of
doing this or MVA things you could also
just first um do like the items such as
pairwise multiplication and then reduce
with vector summation you get the same
result probably kind of more readable
but I wanted to kind of highlight some
more on the inner force like to be
honest I would kind of if it weren't
super performance critical I'd be very
tempted to go with a more readable
version as you can see I'm not a huge
fan of various Greek letters and one
letter names so everything here nicely
written on this is something that I
wholeheartedly um appeal to you to do
the same because it just makes
everyone's life that much easier when
you're and we encode in trying to figure
out what's going on right so if you want
to make this paradise what now it's
already come as promised we're going to
be using onyx onyx is like a the closure
stream processing framework um one of my
favorite closure projects probably um
massively massive amount of features and
going to keep up surprising us with what
they're doing so we kind of things do
check it out even if you don't really
care about what I'm talking about here
and like the nice thing with onyx is
that
it really decouple those various things
that you do good like oftentimes setting
up something like thinking about setting
a to make a spark cluster that it's 3
TBS and then think sort of couple things
together and support and onyx it can
very nicely be complected and using just
closure data structures to describe your
entire computation so basically the
three main components being the work
flow which is the graph of how your data
moves through the system then you have
working on the work flow you have flow
conditions which determine what when to
flow values from one node to the other
so you can have kind of conditional
execution and so forth and then there's
the catalog where we can explain where
we define all the components were using
hey the other thing that I would kind of
draw your attention to is that we for
the extra computation we're using normal
closure functions the only kind of
protocol is that they need to accept a
map which is called a segment and they
need to return again a map or a vector
of maps and let's have the entirety of
being compliant with the onyx particle
protocol so it's it's a very
straightforward step from taking the
curve that we would previously and
change it to various um onyx nodes and
being processed like that so kind of and
really like and this is going to be
probably if there is going to be a
recurring theme really stroke is going
to be just take the power of describing
all your computations with data it kind
of just makes it so much easier to
reason about and what's going to benefit
and change maybe like one more thing
here um if you notice also you can do
things like bind parameters and things
like that which is again kind of useful
for in machine learning context for
various type of parameters and such like
if you remember like our code does have
some parameters it's going to is default
but if kind of one way where you can use
this parameter bind against to kind of
use different values or something like
that and we don't need to actually touch
our code for just business for instance
experimenting with various hyper
parameter configurations and such
right so um our entire turning will be
our algorithm into canonic jobs as best
as described by this topology so we're
going to we start with like a the Aryan
Nation solution coming in then we
populate the meaning and we generate the
entire population we deter each each of
them meaning we introduce the noise and
then we collect the move and update our
weight and then either recur back to
where we were or send define the
solution out and then this also the kind
of the monitor leaf which is something
that kind of it's like one of the
niceties if you're using kind of a
proper flexible system because you went
imagine it's going to be kind of a job
running for a couple of hours or in a
couple of days so you really want to
figure out what's going on as the job is
running and here what we do is just
going to attach another function which
gets data for instance every 100
iterations and output to the word save
is good database or maybe streams it to
some web app where you can see what's
going on so you you have immediately
kind of very in-depth monitoring where
you have access to all your data in just
something that's going to attach to your
code we will attach to your overall flow
workflow without introducing kind of
additional ballast into the code with
just going to like manual checking if a
box is visible by 20 then print line
whatever which is how these things are
usually done otherwise there's no one
small snag here though with this
topology in that it's kind of it's
illegal because onyx doesn't like
cycling graphs but this an easy trick we
can do this and that we introduce an
additional step and here a quality loop
which what does it kind of it's
essentially an output steps which writes
to a channel let's say an async channel
which is incidentally the same one that
we're reading from and we get this kind
of feedback loop again without onyx
complaining or like if you didn't do
this we're kind of more serious settings
probably makes sense to have some other
message bus where you can also inspect
what's going on and maybe serialize
things in between and so forth
there's like one kind of downside to
this kind of topology that our update
becomes kind of stateful because it
needs to accumulate state the entire
generation so let's say our progression
is a hundred means feel like a hundred
of those changes and then do the
calculation which as being fractional
programmers is not ideal but it's also
not as problematic as you might might
think because luckily onyx is rather
good at solving some problems um it does
a couple of things the window and
grouping functions are check pointed you
have various flux policies meaning if
like one of your nodes goes down you can
decide how like whether job is going to
continue or not and if any looking any
invariants are broken and those headed
this is a big one for machine learning
it has a concept of resume points so you
can actually transfer state from job to
job what this means is that I can have
my person running and then if I find
some bug or I figure out an improvement
I can actually kind of just update my
job and continue from the resume point
where I am without having to kind of go
from the beginning or dumping my current
state and kind of realizing you're
something that can just essentially hot
patch and continue from this resume
point which is rather nice and also add
a lot of in terms of this resilience
because even if parts of your class go
down you do have a really decent chance
that the whole thing is going to
continue and like here I would also say
like use this more and more I have said
that computational graphs just kind of
describing how you rate the flows is
such a good way of organizing your
processing code and I think it's
something that kind of should be used
more widely not just when you can doing
this heavy load heavy weight heavy
lifting but essential next at the moment
you don't have like I love writing
macros but like at the moment you have a
flow that's more complex than just luck
you can flow start thinking about having
some graph description of your job and
then work on that there or the couple of
closure approaches that um so for is
like the prismatic
has one and I think that I've seen one
that's going to trying to mimic the API
of Onix second there are some protests
but it was against something pretty
lightweight right if you have some
specific needs but do kind of I find
that they can massively simplify scale
especially if you can go all the way and
also do things like Onix does in terms
of then decoupling your air-handling and
so forth from the processing and then
have lesser concern at each step okay so
now the ER big part of the policy
network here we're going to use cortex
which is a relatively new comer to the
scenes on machine learning framework I
suppose mostly focused right now on
neural networks written entirely in
closure it has very nice and very
dramatic API they are they also act on
the computation cavities data been
draggin using it extensively and very
good effect um and kind of built using
call that matrix which on the one hand
is nice but also like in our compute
case it's going to mean that we're going
to have to kind of convert things back
and forth from the Neandertal formats to
correct matrix which is far from ideal
and still in just in terms of speed near
a file is much faster so would be happy
therefore but I do understand that just
because they would want to position
themselves as being playground for
experimenting with different algorithms
it does make also sense to just use core
matrix for it's nicer API so um and this
is basically the entire description of
the network we will be using arm which
first we're going to the speak to the
quality support expert also clamp like
our problem is relatively simple so the
idea is that we're going to encode their
whole breed as one huge vector so not
exactly doing machine vision but
sources.list kind of try to keep the
spirit of it and then encode princess's
one and here is -1 so we have basically
a vector with two very sparse vector
we're just going to values and it's
going to be our input
um and then we're you can have a single
hidden hidden layer of foot units arm
and then a final layer of four units
representing these four possible
dimensions
directions where our hero can move and
back we're using the bare-bones one
version here now like this is also like
one of the niceties of using yes is that
we like those this is something that
probably will need much more research
and much more thinking but it does seem
that you don't need some of the tricks
you're otherwise employing just to make
the new Network converge faster so the
overall topology can be simpler also
like if because like the depth a lot of
ways is just us trying to massage
networks into a form that's better to
learn or it's going to work around the
deficiencies of learning while the same
time like there is this Universal
approximation theorem theorem which says
that a neural network of limited size
with just one hidden layer can already
can approximate any function to an
arbitrary degree so like we don't need a
set of very deep topologies sometimes
they're useful if you want to kind of
use do what schools for learning so
maybe take just one chunk of the network
and use it somewhere else but oftentimes
it's just kind of a deficiency were
using to work around algorithms and here
it seems that it's kind of simpler it
also kind of brings me to this mini rant
that are often times it seems that a lot
of the secret of making machine learning
successful is just having enough
experience to know the magical
combination of different topologies and
parameters and but at the same time
because of how the publishing system is
set up it's not something is going to
get published and also like their
economic incentives to have this locked
up in your head and then get so through
tens of millions of dollars to things
it's also making a huge disservice to
the advancement of this because there's
so much progress just in terms of how
they actually kind of combine things
together rather than developing new
elements and such so and again
simplifications are also nice from this
perspective um but yeah like if our
problem would became much more complex
it wasn't even and like even this rather
small networks to has if you kind of
then go through because it's really
connected does have about 16,000 weights
so even here the learning problem is
kind of pretty big it's also like first
I was hoping to do an actual live demo
but you kind of takes way too long to
to converge in my computer and also like
here the other example just going to
show you this power of describing the
computations data because what we need
right now we have a couple of different
layers but we need to extract on all the
weights out of them so we can just kind
of train them as one big vector and
because it's just a closure to the
structure essentially it's going to will
be the component and then combine all
them together and we had one huge vector
that we can then feed you to our
evolutionary strategy okay so now the
last building block our game so it's
kind of a very straightforward just kind
of some ideas behind it like the cost I
kind of set so that you have three
different categories like first of all
you want to super pendant penalize a
falling of the edge of the world so it's
kind of the first thing we're hoping
that we're going to kind of get trained
in this one it's also pretty
straightforward explained about it
because it is like if I went the edges
like one of the directions shouldn't be
connected rather have a weight very
close to zero so this is something that
can be learned pretty quickly and then
we have the problem of just kind of
wandering around not finding the
princess so we do impose an artificial
limit of how many steps can done or if
not the game stops and then if the
princess pounds we want kind of the
shortest path so in that case we use the
actual economic distance of how many
steps to find the princess to versus the
optimal distance or the second this
turns - min turns so we'll get the most
aggressive the most direct solution and
then like we also going to plug this
into some more infrastructure I guess in
terms of our function we want to play
the entire game although here is going
to be strictly speaking it wouldn't be
necessary but it's kind of more
realistic example of if you want to do
planning where maybe the effects of your
decisions won't be entirely reflected in
the next step so we play the entire game
and also we collect actually multiple
playthroughs to lessen the effect of
randomness because it's things like
might be just kind of a lucky draw and
the game gets initialized with the hero
and the princess being adjacent spaces
and then it's kind of relatively simple
to find
so we wanted some robustness thing as
that so we'll do kind of batches of ten
runs this also means kind of that are it
plays words are paralyzation strategy
because this is going to get relatively
expensive it's going to pretty cheap
because it's a small silly game but
running this kind ten times or even 100
times would get actually expensive so it
will make sense to have those split and
run on different notes notes and with
that we have new again so I'm kind of
how to sum up all this kind of whirlwind
tour that we went through today as it
comes but it's kind of very simple just
explore and follow your fancy if you
find something enough that fascinates
you either as a concept of the
technology or just a library go have fun
and play with it and go to the ventures
um and now if have any questions let's
start an adventure of our own thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>