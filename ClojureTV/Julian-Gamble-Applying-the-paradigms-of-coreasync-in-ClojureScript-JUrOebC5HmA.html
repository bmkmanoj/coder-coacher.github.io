<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Julian Gamble - Applying the paradigms of core.async in ClojureScript | Coder Coacher - Coaching Coders</title><meta content="Julian Gamble - Applying the paradigms of core.async in ClojureScript - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Julian Gamble - Applying the paradigms of core.async in ClojureScript</b></h2><h5 class="post__date">2014-11-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JUrOebC5HmA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you as Alex mentioned my name is
Julian I'm gonna be speaking to you
today about how to get caught a sink in
your head how to wrap your mind around
it and what it can do I'd like to take a
moment to thank the Conger organizers
it's really special to be invited here
and I'd like to take it moment to take
my wife who's at home in Sydney with my
two little kids looking after them I'm
also writing a closure book it's going
to be called closure recipes and
hopefully it'll be up on safari rough
cuts in time for Christmas and it's
currently up on Amazon now now when I
give a talk at a user group back in
Sydney I like to have a protagonist and
the hero of our story today is Michael
Caine the theme I'm going to be
developing today relates to a movie from
1969 called The Italian Job now this is
the original one it's not the 2003
Charlie's three-on-one
now the summary of the movie is a
robbery to enable their getaway they
reprogram the traffic control computers
to create traffic chaos for the police
but leave a safe path for themselves out
of the city now what I want you to do is
listen carefully and see if you can see
the link from the Italian Job and Kasich
alright I saw in the show of hands
yesterday and Rich's talk about 1/3 the
audience of used core async before I'm
gonna be starting from first principles
to try and bring everyone up to the same
level so when do you use core ASIC now
there's this great talk where rich
Hickey introduces it and he says you
reach for core async whenever you use a
cue now you can also use core I think
when you want to make your program
simpler core async makes it easier to
fit the program in your head now there's
a whole lot of pieces of the puzzle for
core icing
we'll cover today I'm going to talk
about how you can send a block of code
to the NGO macro we're also going to
look at how you can do a queue in quarry
sink we look at timers and what they do
to your program we're gonna look at
listening on to queues simultaneously
using the odds macro we look at y cor
async enclosure and closure script are
similar and different we're gonna look
at a visual example of what core async
does to your program and how it looks
without it
I'm gonna have a look at how you can
convert a closure program to a closure
script program I'm going to look at some
tips for optimizing closure script
programs now you might have said well
that's a lot of stuff
what is this core icing thing sounds
like magic well quarry sink is about
queues it's about reading writing and
creating them the actual implementation
is a macro this macro is compiler like
in that it walks your code and splices
up into a state machine now you use core
async as the name suggests to do
asynchronous stuff it's about different
processes communicating with each other
now the other great thing about core
async is that the code runs on both
closure and closure script now when to
pause at this moment to make a
philosophical point now this is similar
functionality to core async in the go
language and also in c-sharp but they
shipped these features by modifying the
compiler you didn't get async/await in
c-sharp until Microsoft shipped a new
version of the compiler in closure we've
got this functionality when they release
the library this is one of the fantastic
things about closure you can extend the
compiler by shipping a library I'll say
it again closures fantastic because you
can extend the compiler by shipping a
library all right some background on
core async now it's based on this thing
called communicating sequential
processes the ideas behind core async
come from the academic world
in the 1960s and 70s there was a set of
ideas called the process calculi they're
trying to coordinate computation between
different processes using algebra the
coordination mechanism they came up with
was channels which we can think of as
queues there's this guy Tony Hoare whose
full name is Charles Anthony Hall who
wrote a book about this called
communicating sequential processes
alright so back to the movie now in this
movie they reprogram the traffic
computer to be able to make their
getaway with the stolen goods to do this
they call in their chief nerd played by
Benny Hill to come and do the nerdy
stuff in the movie he's a bit of an
outcast and this is 1969 so you can see
he's doing some refactoring with a
screwdriver it's pulling out the tape
and this is a little bit technical and
now you can get this slight feeling if
you haven't looked at core async maybe
it's a bit of a deep thing maybe it's a
bit nerdy maybe it's something you want
to steer clear of it's totally not like
that we're gonna jump into it now we're
gonna start with a really basic example
this is the hollow world of core a sink
it's all about producers and consumers
now I've drawn diagram before I show you
the code because I want you to have a
mental model in your head that you can
fit the code into this technique is
quite useful because as the code becomes
more and more complex we can quickly
communicate a high level understanding
of what's going on now on the Left we
have a go block on the right we have
another go block and in the middle we
have a Q joining the first go block to
the Q is a greater than an exclamation
mark symbol this is our function that
puts things on the Q then on the other
side of the Q we have a less than
exclamation mark symbol this is a
function that takes things off the Q now
this one's really important because this
is what we use to wake up go blocks that
have gone to sleep all right let's take
a look the code for what we just saw we
have your program with a couple of go
blocks and it prints finished when the
main thread is done so let's zoom in a
little closer
at the top we're defining a channel also
notice that we're taking hello world
were breaking it up into a sequence of
characters in the first go block we're
iterating over the sequence we just
defined each time we do a loop we put
one character onto the channel then we
timeout for one second this timeout is
critical it acts as asleep for our go
block in particular you'll notice that
timeout uses the function less than
exclamation mark for reading from a cue
I'm gonna have more on this later but
note for now we're modeling time as
reading from a cue now in the second go
block we know a second code block we set
up a while loop that will run for
infinity now this is okay because the
core ASIC macro will only wake up this
block of code when there's an item on
the cue the rest of the time this block
will sleep what we're going to do is
read a character off the cue and print
it on a new line in standard out so
let's look at the whole thing again we
define a channel and our hello world
sequence and a first go block would put
items on the cue in the second go block
would pull items off the cue and we
print them we also have a bit of code at
the end running in our main thread that
will print a - after 12 seconds also
note that the finished will print after
the main thread is completed but this is
going to be right away because
everything else is going to be
asynchronous alright let's have a look
at this running
now we've kicked this off and what we
can see is we're putting characters onto
the queue our main thread is finished
and we're still iterating through the
rest now we've finished our initial
sequence and our future with the dash is
printed and we're done
so that is hello world in chorusing
okay now let's make our example a little
bit more complicated we're going to a
second Q and a third go block we're also
going to read off both Q's using the
macro called alts all right well take a
look at the code it's quite similar to
before we've doubled the number of
channels and sequences and we have an
extra go block so let's zoom in at the
top we have two channels we have two
sequences now a second sequence is the
integers up to 10 now first go block is
doing the same thing as before putting
characters on a channel it's reading
from the channel to do time outs second
go block is a couple of differences
we're sticking our integers onto the
second channel in addition instead of
getting from a constant integer from our
time out or reading from a random
integer that means our time delay to put
things on a channel it's a random
interval up to one and a half seconds
now on a third go block are reading from
both channels using the alts macro this
comes in the form of a vector that we
destructor using a lip block from there
we can decide to do different things to
the item depending on which channel it's
come from now the important point here
is that we use one macro to get the next
item from either channel
so let's have a look at this running
now you can see here our hello is
reading through but our range of
integers is also coming through at non
predictable intervals due to the way
that we're reading off the the time out
with the random interval and we're done
so that's an example of us using our
alts let's bring that back
now we're gonna look at the code from
another example this is Tim Baldrige as
demo that he used to explain quarry sink
now the main thing we're gonna look at
here is it is the blue go block on the
right this represents a single colored
cell on the web browser we're going to
paint the browser canvas I'm going to
pause for a bit and I'm gonna paint it
again then we're gonna create a grid for
this go block ten thousand times one for
each cell of a hundred by a hundred grid
so let's look at the code now what's
cool about this is we're not looking
just at closure but a closure script but
everything we've learned so far applies
equally in this environment so let's
zoom in here we see down the bottom
we're calling our function with the
parameters hundred hundred which are the
dimensions for our grid and then above
we have two loops this means our make
cell function gets called ten thousand
times now in the middle you'll see our
one go block and you can see it's
setting colors and it's drawing
rectangles and you can see a function
that we saw before reading from a
channel less than exclamation mark and a
random integer function
this means this go block wakes up on a
random interval of up to one second and
in paints the cell given to it so let's
have a quick look at this one
so you can see how go blocks are all
running away they're updating
all right now what I looked at this I
was dubious I thought come on you can do
the animation with a for loop in Java
Script why do you need core async to do
that so I gave it a go we quickly
whipped one up and we're gonna take a
look at that now now up here you can see
there's four loops and you can see the
make cell function and it's it's kind of
doing roughly the same thing let's see
how it looks
all right what you notice is that this
is looking slightly different this is a
little bit more of a scanning effect
that the effect is less palsy and it's a
lot more blocky
in terms of what we're seeing up there
so you know maybe there's something else
going on there so we'll take one look at
the Tim Baldrige code again and I'm
going to ask a quick question for the
audience I'm not asking to answer but I
just want you to think about this in
your head and we know that closure
script runs in the JavaScript
environment we know that javascript in
the browser is single threaded now do
you think that all 10,000 go blocks have
the same random interval or do you think
they have different ones do they all
wake up the same time of paint or do
they wake up at different intervals
let's take another look
now what we see here is a really
pleasant pulsing effect coming from each
of the go blocks waking up and different
interval and doing their update in terms
of our understanding what this tells us
is that the program is maintaining the
state of each of the go blocks
individually the our go macro has
maintained the state of 10,000 light
weight processes and where they're up to
and what they're going to do
now David Nolan did quite a similar demo
but it turned out when you get into the
code he's actually exploring some more
sophisticated applications of Corre sync
now his version of the demo has the the
go blocks but it also has a render
pipeline now you'll see here there's to
go blocks on the left in the middle it's
a third block on the right this is not a
go block this means that while the first
channel between the first two blocks is
a core async queue the second is not now
the big idea of this of this arrangement
is a render pipeline we're separating
out our calculation logic from the
display logic now you might ask the
question what do you need two cues for
wouldn't one be enough well it turns out
that with core async you generally have
to be able to pull things off the queue
faster then you put them on now when
you're displaying things in JavaScript
this is not always possible now if you
put more onto the queue then you pull
off then eventually you'll get an error
now this means your channels full so the
way that David's designed guarantees
that the quarry sync queue doesn't get
full is to pull them off right away and
stick them on another queue this is how
you do a rendering pipeline in closure
script so let's look at the code here we
see this three code blocks there's a lot
of code here so we're going to zoom into
the detail the whole thing is kicked off
from the let block down the bottom this
calls the render loop function and it
gets something back which it puts in
render now if we look at the bottom line
of the code block above we see a value
in is being returned now if we look at
the top of the render loop function we
see the in value is being declared as a
channel so know that down the bottom
we're getting a channel back now looking
at the LED block we can see there's a go
block and a while true as we've seen
before
now the first channel reader function
reads from a random integer function and
this tells us the go block wakes up at a
time
love one second plus a range of up to
ten seconds the second channel operation
puts stuff on to the render Channel we
can see it's putting two integers and
the first represents the ID of the cell
on the grid
the second represents the value to put
on the cell now here's our go block
we're reading from two channels one's a
time out channel called refresh now
there's our in channel who have been
pushing coordinates on the alts macro
reads from both channels different items
come in from our cell ID channel we
stick it on the vector name queue of
items come in on our refresh channel
then we call our render function so we
can see the overall program and we see
our render function at the top sets the
cell to the value from the queue and
sets the cell CSS to the color so let's
take a look
now this is a copy of David's page where
he was demonstrating this and I think
this is quite powerful for a lot of
people when we were looking at core
async because it we could see that there
was lots going on on the page but that
we could see lightweight processes
running in the browser so this is an
example of our render pipeline
now there's one more point I want to
make about core async and applying it
now you can use core async in the
browser to go and read an event queue
this is a diagram that shows taking the
event stream with Dom object and
returning a core async channel this on
its own isn't that interesting but it
becomes more interesting when you're
trying to coordinate multiple queues of
event streams because you've got some
very powerful operators as we've seen
with the alts macro and also the ability
to filter on queues that makes things
able to scale up and be modified much
more easily than if you're using
callbacks so take a quick look at the
code for this you can see there's a
listener function it creates a channel
called out then listen function puts a
call back on the Dom object that puts
events onto the queue what we then do is
attach a listener down the bottom with a
go block and this go block wakes up each
time an event comes in and it dumps it
on the console ok so that's the theory
of core a sync so back to the Italian
job there's a scene where the bank
robbers have picked up the gold about to
get away in some classic mini coopers
right at this point they're about to
start running and this is where we're at
we've got the goods let's go run with it
now we can get easily tripped over in
our terminology so I'd like to clear up
one thing on parallelism and I'm sure
you've heard this phrase parallelism is
not concurrency but we're not asked
people I'd say well which way around is
it can you explain it to me they say oh
you know go watch that Rob Pike video
that makes it really clear and as
closure ends we really love our
Entomology so I'm going to take you back
to high school geometry and what I want
you to do is to imagine the streams of
execution in your program as lines on a
graph here's an illustration of
parallelism using geometry you can see
the processes in your application are
running at the same time but they're not
touching
each other now here we see a program
with shared state between processes
this is concurrency now there's a
problem with this analogy you can only
take an analogy so far in geometry a
line is straight and extends to a point
or to infinity but your program is
really more like a curved line it could
be parallel for a while and then a
conducive concurrency your program can
be both parallel and concurrent but it
doesn't have to be ok you want to take a
brief moment to talk about parallelism
in Cori sink because we're thinking
about them in a slightly different way
than you might have thought about it
when you might have done it done threads
in Java now in the demos above we've
been using a core async function to read
a time out channel to get sleep behavior
now this is not reading an actual cue
it's just blocking with a timer but
thinking of it as a cue is useful
there's still an implicit hue involved
now it's true the design goal of Cori
sink was lightweight threads now as it
turns out when you're doing a thread
back in your java days you were actually
implicitly listening to the ready queue
of the operating system so it becomes
useful to think of multi-process
programs in terms of queues because it
can relate to how it actually use them
when we go and bring our program into a
single threaded environment like the
browser ok let's recap
Cori I think it's all about queues we
can use Coar async for doing parallel
operations like with ourselves we can
use it to separate out the display code
from the calculation code with the
render pipeline and we can use chorusing
for regular JavaScript event handling
now we need to I want to take you back
to an example closure program we've seen
before and I think we all know it and
love it
this is rich hickeys original ants demo
you've probably seen it when Rich was
first introducing it I think it's in
closure for Java programmers now what's
amazing about this demo if you're
watching it back in 2008 and it might
have been coming from a Java background
was that there were multiple threads of
execution and they're all whacking away
at the one data structure in Java land
you knew that shared state between
different threads is really not a good
idea and yet here was rich Hickey
advocating it and this contrast this
change of thinking led you to start
thinking about persistent data
structures and about software
transactional memory okay so let's take
this demo
now the actual code consisted from three
main agents one for animation one for
the ant behavior and one for animation
you keep them all off and it'll act on
the one data structure so he was
creating an ant
he's kicking off the animation agent
he kicked off the vaporators where we
send off all the different processes
running in the program so what I want to
do is take this and run it in the
browser before we do anything fancy with
it we're gonna do the simplest possible
conversion just to get things running
now the original application relied on
structs we have got those enclosures
grouped so we're just gonna replace them
with maps and keywords we've got agents
so we're just gonna mutate to state with
swap now as we saw before everything
that JVM is running in agents don't have
agents in closure script and in the
browser lists we're running a single
threaded so the simplest version is
application we can do if we're just
going to make it all into one big for
loop we're just going to go through
around this simplicity gives us enough
room while we convert over all the
display functions so we'll take our
animation function we'll take our behave
ants function we'll take our evaporate
ants function we'll just call them each
one time as we look around so in closure
scripts the kind of the parent loop is
going to look like this we'll kick off
animate we're going to
requestanimationframe and we'll just do
a run loop each time that gets called so
can we do this can we get ants running
in the browser
alright let's unpause it and bang it's
working
got an initial version of apps running
in the browser now looking at this
there's a little bit smaller than the
demo we saw before unfortunately had to
shrink it down because it was running so
slow and this was about the only size of
the demo I could get that would kind of
run oK we've managed to bring a lot of
the code across and it seems to be
running okay but it's not really running
fast and I think even David Nolan would
and to his credit an amazing work on
closure but I think even he would admit
you know this probably some room for
optimization all right
okay now I don't want to use a big for
loop because then we lose the state of
our individual processes one of the
things that attracted us to closure in
the first place it was that we could
have processed level state and get away
from a single-threaded model of thinking
so how do we fix this now we've already
seen this before we can use go blocks to
simulate threads on the JavaScript VM
they're lightweight processes that run
on the core async scheduler I'm going to
show you a quick example of taking one
of our functions and bringing our
parallelism back here's our evaporate to
function in closure script and what
we're going to do is add a go block it's
got a while true in it at the top and
down the bottom bottom we've got our old
favorite the timeout function all right
and so we put the core I sink into our
code let's have a look at and see how
this is running
all right this is now running with core
async we've got several independent
processes running mutating the data
structure this is not bad but it's it's
not running that much faster than we saw
before we've gained an increased ability
to reason about that code and D couple
it but we haven't really gained any
performance so let's have a look at what
we can do about that now
now David Nolan's done some fantastic
work in this area and he did a port of a
Minecraft demo that was written in
JavaScript and he brought it across to
close your script and it's part of the
process of doing that he did a whole
bunch of profiling and that the project
he did was he called the port chambered
and they're a bunch of macros in there
for optimizing closure script animations
now this basically boiled down to
ripping out the persistent data
structures out of closure script and
replacing them with arrays we also
ripped out the higher-order functions
and replace them with for loops now as
kind of functional programmers and
closure programmers kind of have to hang
your head in shame but this is the kind
of things we need to do to get our
performance so here's an example of one
of these refactorings that we had to do
this is where we were creating our grid
vector vectors
we started with this and then when we
modify we go to this so you can see
we're replacing our vectors with arrays
there is a specific array maker I
haven't used it here for clarity and you
can see the map is gone you'll notice
we've used the for loop macro and it
turns out the JavaScript VM actually
understands this a whole lot better then
general closures group data structures
and higher order functions so we get
better optimizations and again I
apologize for turning this into a
function it's a little bit harder to
read and compare but it's a lot easier
to debug all right let's have a look at
this running did our optimizations work
bring this across and bang got a much
bigger grid now it's running a whole lot
faster we've managed to optimize our
closure script
cool so we got ants running in the
browser we've got it running fast back
to the Italian job and core async now at
the end of the movie the brave leader
Michael Cain leads the team to success
well kind of now maybe this is a
question for the bar later on we saw at
the beginning they reprogram the traffic
computer the traffic computer must be
modeling masses of concurrently running
processes this is not really a serious
question but I want to ask you did Benny
Hill when he did some refactoring on the
code and the traffic computer you're
gonna use process calculus that's the
grand grandfather of core a sink could
they've been using something similar to
core a sink back then well might save
that discussion for later so in summary
core a sink we're talking about cues
the primary benefit here is it makes
your application simpler to reason about
you could instead write your own locks
and call backs but that stuff when you
combine it together doesn't scale now in
some places you might consider slotting
core a sink to include event handling in
the browser or creating a display
pipeline or as a lightweight thread
that's like a pretend thread in the
browser and we took a look at the idea
of all you're threading being triggered
by the operating system ready queue and
naturally the JVM is multi thread in the
browser's not so if you're porting
across you need to consider if your
application will work in a single
threaded environment we also looked at
some closure script optimizations and
one last thing
Corre sync is not magic sauce you have
to use it judiciously it's definitely
not a replacement for your ASB it's more
about smaller sets of data where
processes need to communicate now if
you'd like to look at the demos there on
my github account and I thought I'd open
the floor to questions if we've got time
sorry there any questions in the crowd
it one day I'm here
yep
cool I'll repeat your question to make
sure I've got it and so everyone heard
it the question was what's the roadmap
for the future of their closure script
compiler is it going to get better
naturally I honestly can't speak to that
myself I'm going to direct your question
to David Nolan perhaps you can ask him
later at lunch but I think it's going
pretty well I'm hoping it's going in
that direction are there any more
questions
cool we're done thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>