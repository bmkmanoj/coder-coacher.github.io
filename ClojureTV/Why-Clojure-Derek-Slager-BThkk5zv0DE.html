<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Why Clojure? - Derek Slager | Coder Coacher - Coaching Coders</title><meta content="Why Clojure? - Derek Slager - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Why Clojure? - Derek Slager</b></h2><h5 class="post__date">2017-03-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BThkk5zv0DE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right welcome everybody why closure
why closure is probably striking use a
little bit of a strange topic to talk
about at a closure conference because
hopefully most people have an answer to
the question why closer that applies to
themselves in my case why closure is a
question that I'm asked a lot and why
are people always asking me why closure
so rewind a little bit more than a year
I co-founded the company I'm the CTO and
co-founder of a brand new company and
and so when you start a new company
you've got a bunch of really hard
decisions to make and one decision you
have to make is you have to choose the
technology stack and a major component
of that technology stack is a language
and there's a lot of perspectives on
what language you choose for a start-up
right there's there's a category of
languages that are sort of in your in
your startup friendly class right so if
I said we're going to use Ruby or Python
I probably wouldn't get why Ruby why
Python right those are sort of just
accepted like yeah also startup so of
course you're using something like Ruby
or Python
I could choose something like you know
job or Scala and I might I might get
that question like what job that's not
that's more like big company enterprise
stuff not really startup stuff but I
still think I would get that question
less often that if I chose something
like closure that's that's a little bit
off the menu right whether you're
thinking of thinking about it through
the lens of your starting a startup or
you've got a big company like oh there's
an unconventional choice so a lot of
people ask me this question and
everybody has a perspective right
there's there's different there's
different ways of looking at this
decision of what language to use when
you start your company but nobody
questions that it's an important one
right and and so some people will say
you know you start with the startup II
language and then like if you can get
the company working then maybe you've
earned the right to switch to a boring
language that'll actually work right and
this becomes this is like this is
something you hear right and like this
gets written up right
Twitter's like failing left and right
but they had to throw away their startup
move fast language and go to something
lame and boring but now the site works
cool and so you know this kind of
becomes part of people's thinking and so
there's there's almost you know this
just pull towards okay
that's what people do right they they
have the hacky founder code language and
then eventually they like you know
switch to something real and pouring in
their lame big company and nobody wants
to work there and everybody leaves I'm
not talking about Twitter so so I want
to talk a little bit about our company
called M parity we basically build a
large-scale data processing platform
that helps customers unify really large
amounts of consumer data even when it
doesn't fit together cleanly so it's a
pretty it's a pretty apt scale data
crunchy problem we are located in
Seattle where the weather is much nicer
than here in Portland you should all
know we are we are fortunate enough to
have a nice view of the Space Needle out
the out the door of our office we are VC
funded and I mentioned it's because
there are different categories of
startups and there is the category of
startup where we want to start a startup
because that's cool and fun we're going
to build a little lifestyle business and
you know our goal is kind of get enough
revenue that we can sustain and do
things our way and have a lot of fun and
that's that's a perfectly reasonable
choice our choice being a VC funded
company is we want to build the biggest
company that we possibly can right so
we're really going for it and and that
adds a lot of weight to the decision
about what technology we use we're not a
small company because we want to stay a
small company we're a small company
trying to become a very large company
there's a lot at stake and of course we
chose closure as the foundational
language for our company so why closure
I promise this is not going to be a
three minute long talk but I'm going to
actually answer this question right away
so why closure from our perspective this
is my thinking in starting the company
right why closure if I choose one of
those mainstream options I'm not going
to get questioned right people aren't
going to say why Python it'll be
accepted so I had to really be
thoughtful and sort of build a rationale
why closure so here's what was in my
head I thought to myself you know what
this is the best of both worlds why why
choose Ruby or Python so I can go really
fast
get dynamism and repple orientation and
all these wonderful things but then kind
of throw out the robustness and scale of
this other boring technology right with
closure you've got a little bit of a
knob you can tune right you can be
really dynamic on when you're using
closure but you can also orient more
towards performance and robustness and
scale that's a nice knob to have right
because as your startup you're shifting
from hack it out get it working mode to
something that needs to be really robust
at scale and of course the inherent
nature of our problem is one at very
large scale so it seemed to me like you
know kind of a cheat right I get I can
sort of get the benefits of both sides
if I use closure it's simple and it's
data oriented the problem our company's
trying to solve this data oriented I
have a pretty strong belief from a
couple decades of software development
experience that less code is better and
I think data orientation does correlate
with smaller code bases and I think if
you want to continue moving fast after
you sort of get out of that early stage
of the the startup phase you know you
need something that's that simple you
can't be you know pushing around
hundreds of thousands of lines of code
all the time and still stay agile and
the last piece is I was firmly firmly
convicted that smart people want to use
closure and I think you know creating an
opportunity for smart people to use
closure on a daily basis and get paid
for it seems like a pretty compelling
pitch for the company so that's it
that's why closure that's what was in my
head I'd like to spend the rest of this
talk talking about what happens next
right so we've been building the company
for more than a year we're a pretty
large company right so we've got more
than a dozen people full-time writing
writing closure which is which is larger
than average in the closure ecosystem so
I kind of want to talk to you about what
happens as you scale closure with this
sort of planted as our rationale then
you go out and try and build a company
what happens so the first category of
things you need to think about are of
course people right you need people to
build a company two people to write the
code and you know I sort of stated in my
rationale I I think smart people want to
use it
and that's definitely true smart people
do want to use closure but the reality
of smart people also want to use all of
those other languages and there's a lot
more people who are using those other
languages who already know those other
languages right so yeah smart people
want to use closure if you have a
smaller pool so there's a trade-off
there I think that people who are smart
want to use closure I do think that you
get a little bit more passion from
closure I think that's something that
kind of comes with closure being a
smaller community this person works at
our company they've literally got
closure permanently tattooed on their
body so I think there's there's a
certain level of passion around the
language and that's a great thing to be
able to capture right when you're
building a company having people who are
really enthusiastic about the tech that
you're using is an asset and that's
really good and I think you know the
other side of the of the of the
trade-off in terms of the overall pool
of people is there's a smaller pool of
companies who've decided to use closure
so you do get a little bit of benefit in
relative terms in the hiring market but
it's something to be aware of because
closure is a smaller community relative
to the more mainstream languages you
also have less opportunity to build an
entirely local startup right and there
are examples of closure companies that
are fully remote I've seen closer
companies that are fully local but when
you're a company like ours and you're
trying to build the scale pretty quickly
you have to be considered you have to
make that choice very early on are we
going to be remote only local only or
somewhere in between and there's many
different versions of somewhere in
between the answer is not always obvious
and the closer community this is sort of
the heat map of closure closure searches
from from Google Trends it's pretty
distributed around the world there's
kind of not oh well everyone who uses
closures in San Francisco and then you
know there's small communities or it's
very distributed so so we're in Seattle
closure developers are everywhere what
did we decide we went for the somewhere
in between and so we have a handful of
people on our team that work remotely
from a variety of different places and
it's worked pretty well
part of the reason it's worked pretty
well is because technology is better
for remote working than it has been in
the past I think you know this would've
been a little bit if you're even just 6
or 7 years ago I think there were there
were more just pure technology
challenges so you know improvements in
BC and and bandwidth and things like
slack have all been very helpful in
making it work so and by the way the
remote work investments you make to make
it nice for people who are always remote
to work in your company is also pretty
nice when there's a snow day in the
office because it gives people the
opportunity to have a close to first
class working experience when for one
reason or another they can't make it to
the office so great right it's all
upside you get access to all the talent
in the world you can still have your
headquarters well it's it's it's not
quite so straightforward right there's a
lot of downside there are there are
reasons that companies and frankly the
vast majority of companies are local
only or at least strongly local first
right there's something about building
that community right why why are you
here at this conference you know you
could go you could stay home and then
tonight all the videos are going to be
online right you don't have to be here
but you come here to engage and be part
of the community and it's you know a lot
of people say well I come for the
hallway conversation well in the office
that's where the hallway conversations
happen right so it's it's an important
thing to be aware of and we are very
vocal when we're hiring a remote
employee we say you're getting a second
class experience and you don't get to
like be in the office when all the
puppies show up or when we do a push-up
party or when we go out and have fun and
build community together and those
things are really important because
startups are hard they're really really
hard and those those chances to get to
know each other as people and bond
together I think are a really important
helping you get through it so there's a
lot of burden on the remote employee to
engage themselves and to and to kind of
understand I'm going to see a picture of
a bunch of people in Seattle who got
together and built these terrariums and
I didn't get to be a part of that right
so it's really important that both sides
be thoughtful about what the trade-offs
are there what about if you run out of
people right what if there aren't enough
people in market to hire you know what
are you left with well you know not all
smart developers
use closure exclusively right there's a
lot of smart people who are willing to
use closure but don't use closure yet
and we found that that's actually been
very effective for us is to find people
one of them is in this room who haven't
used closure before but we know they're
they're a great developer and just teach
closer to them
in fact it's worked so well we've done
it with about half of our team so this
is actually the distribution of closure
experience within sort of the the core
of our team and half of our team came
here without real world closure
experience maybe they dabble a little
bit but no actual like used it for a
company so this ratio has been very
effective I do want to highlight having
having you know two or three people on
your team that have a ton of closure
experience is really really valuable
right because you need you need people
who have kind of been way past the
honeymoon period and kind of seen seen
around some of those corners that you
have a little bit of trouble seeing when
you're taking on a technology that's
that's relatively new but if you have a
really good core of people who know
closure really well and they kind of
understand the responsibility that comes
with that you can absolutely train
people in closure and and the reality is
what we found time and time again is
that when we bring somebody in and teach
them closure that's a very tiny amount
of their onboard time right there's so
much to learn when you come to a new
company there's all kinds of new
technologies and ways of applying them
new pieces of architecture that you have
to understand it closer is a pretty
small part of that so I would not
discourage people from just looking for
great generalist developers and teaching
them closer it doesn't take that long
and most of the people we've had in the
company that we've talked closer end up
really liking it even some people who
might have initially been more excited
about the company in the space and the
technology so what happens when you
build a company and have a lot of people
creating a lot of closure right you get
a little bit beyond a lot of people
start with closure and they sort of
never get beyond like you know one
project where all their stuff is right
but what happens when you have a really
really really big codebase with lots and
lots and lots of closure code right this
is this is a this is our actual
screenshot from from github you can see
this is this is something at pretty
significant scale by the way I used to
get up for like two years before I
realized if you click that colored line
on the bottom it shows you the language
distribution so I'm sure everyone else
already knows that but but you can see
we're absolutely dominated by closure
that is that is our core language we
have a few kind of third-party shell
scripts that we've mirrored and there's
the actual number is probably well above
80% in terms of the overall code code
that we write this is a lot of closure
code and it's spread across about a
hundred projects so you might be
thinking to yourself wow there was this
one time I used this closure project
that had five or six different projects
connected and that was like the worst
thing ever because I had to constantly
like be jumping around projects and
version bumping in line installing and I
hated everything like I sort of lost all
my joy for closure trying trying to
manage that that's a pretty common
experience this doesn't work very well
right so in this model you can imagine
like each project has its own you know
say github repository and its own
project clj and so you have these kind
of like dependencies across these
different repositories that have
different version spaces and you have to
manage these sort of version steps on
top of them so you're constantly bumping
versions and and and it's really really
difficult to manage and closures tooling
is not awesome here right running line
install is usually not something you
expect to finish in one or two seconds
so one response to this is we could say
well let's let's just build a mono repo
let's take all the code that we would
normally put in its own individual
libraries and just like put it all in
one place so let's go from a hundred
project CL J's to one and that's all
part of your problem right there's a
simplifying effect there which is now I
don't need to like you know do all these
separate line installs and version buff
and all that kind of stuff but now like
everything depends on everything I've
just got this gigantic blob of code and
that's that's probably not better so we
wanted to have a mixture of both we
wanted to have the good parts of a mono
repo but with the you know with the
structure and the you know properly
dependent seed smaller versions of the
project so so we ended up actually
having to build a piece of
infrastructure here line monolith open
I'd encourage you all to check it out
and what line model is it allows us to
do is have a single monolithic repo but
within that repo to have all of the
different projects so so this kind of
gives you a little bit of the best of
both worlds but you need to Ling to make
that same the stuff that comes out of
the box with line again it's got some
nice features things like check out sand
and other things that some of you may
have used but managing that manually is
a real pain you end up writing lots of
shell scripts and those don't don't work
well as your project scales and you know
when you've got a hundred plus projects
it's really important to have good
tooling around that so we built it and
and this has been working
remarkably well for us so I imagine this
is going to continue being a technique
that we use for a long period of time so
so what is a project look like right and
don't panic by seeing the word snapshot
right like many people have programmed
to see snap snap shots are bad right
with snap shot we don't know what's
going on but because all of your code is
in the same repo you don't need this
sort of meta meta version set notion to
tie everything together
right because everything is version
together naturally anatomically in the
code repository itself so it's actually
perfectly fine and in fact this is our
best practice to have all of our code
inside that mono repo utilize snapshot
so you can read up a little bit more we
have an entire presentation on the line
monolith that you can that you can check
out offline but but I do encourage you
to use it if you have lots of projects
and you want to keep your sanity so what
tools are people using right you're a
big closure company with you know a
hundred plus projects like do these
tools work do these tools scale so most
of our company is using Emacs plus cider
or some other editor looks like it's
image is not loading sorry ok fine
a couple people are using cursive and
and I've got good news everybody is
happy so so no matter what tool set
people are choosing they're all really
happy and all this stuff works at scale
so you can just choose what you like you
don't need everybody to be using the
exact same tools and technologies
everything everything works together
harmoniously so you do have a big
decision to make when you start a
company around what language to use
arguably a bigger decision not unrelated
to the language the decision is what's
your Architects are going to be and
classically the decision you have to
make as a start-up is monolith or micro
services and again as with the sort of
ruby to java assumption some people
think oh yeah you start off with a big
pile of crap monolith and then you know
eventually when you're a real company
you switch to java and do a bunch of
microservices stuff and then you've got
a hundred people and you can you find a
way to make it work and I don't think
that's generically bad advice
right so so what if you choose micro
services instead of monolith right
you've got a lot of stuff that you now
have to figure out so first and foremost
what does that even mean
right micro service it's not like a
canonical dictionary entry for micro
services the micro service is a project
of this exact size that talks about like
what
how big is a micro service I don't know
because there's a lot of opinions on
that you have to figure that out right
if you're going to structure your
brand-new project is the micro services
project you better define micro and
pretty fast and you better get it right
- right does it 9:00 or some much larger
note I don't know you got to figure that
out how do they talk to each other right
you're going to build this big ball of
services and everything is going to talk
to ever like I don't know over the
network that's not I mean that's not
good enough right you have to you have
to answer a bunch of very specific
questions if you take any arrow
representing a communication from one
service to another
what is that arrow right you can't just
say network you can't just say rest you
can't just say HTTP like what's in the
payload like what format is that
specifically what happens when that
format changes you know how do you know
which version of us there's just all
these really really difficult problems -
so
and we're not like solving any
interesting problems here this is just
like plumbing this is very different
right when what's the answer to this
question in a monolithic architecture
the function call right that's that's
very straightforward so so this is an
explosion in complexity okay
so how am I going to deploy my stuff if
I'm deploying a monolith there's like
one thing to worry about I take the
monolith and I put it on that one thing
life is good you know if I decide that
based on my definite definition of
micro-service I have nine different
things to deploy like that's a big
multiplier like nine separate
deployments that means nine different
machines right like that's that's a
whole bunch of overhead operationally
that's that's not insignificant and
that's not even the whole story right
because as you scale a company you're
not going to just have a production
environment in somebody's laptop that
doesn't work at all right you're going
to have all these other environments for
testing and pre-production testing and
in development itself and it's going to
explode in complexity you're going to
have a much larger number of things to
manage than most people think when they
first start and you need to be an expert
in managing that many things if you want
to do that so if your pager goes off and
oh man there's a there's a urgent
software patch that needs to go out
across you know 50 different servers and
you don't have the expertise and the
tools in the infrastructure in place to
do that you're not being responsible in
choosing a micro services architecture
it's actually possible to do that when
you have four things across different
environment you can go and do that
manually and if that's if that's as far
as you can get in terms of your toolset
you should stop there management is not
just about applying configuration
changes it's also about understanding
the state of your infrastructure right
if my staging environment goes down like
in the monolithic architecture obvious
right well the staging environments down
everything's down so I don't know
restart it in a micro-sim starts like
everything's really spread out like
where's the problem
right why is the service not work I
don't know this service looks fine you
got to like sort of trace down so
so it's very difficult when you just
have a larger number of things to manage
and again nine is not a small multiplier
looks fairly clean on a slide but it's a
huge explosion in complexity and you
need a very different category of tools
and a very different caliber of of
administrative personnel inside and
outside of engineering to make that work
effectively and the cloud will not save
you and the vendors who say whiz-bang
platform-as-a-service will not save you
either failure tolerance this is really
important right if I go from four things
that can fail to 40 things that can fail
that's much more likely that I'm going
to see failure right there's more things
that could fail even if those are
smaller machines that doesn't change the
probability of failure in aggregate
right there's still different machines
so so your probability of failure goes
way way up right so you don't get to
take as much risk as you can in a
monolithic architecture or you can say
you know what I'm just going to hope
that that box that it's on doesn't fail
right you can actually get pretty far
with that one box but when there's all
those other boxes something's going to
fail and that means that much earlier
than you might want to you have to build
in failure tolerance right so when
you've got when you've got these
different services running on a machine
you're going to need a copy of them
running somewhere else so that when that
machine goes and machines go this
happens pretty frequently at large scale
even with with good cloud providers you
know you have to you have to be prepared
for that now what most people do is they
say oh man this is really bad I've got
to have multiple instances of things
running so I'd better find a way to pack
those together so that I'm not spending
tons and tons of money well the problem
is if I'm packing these arbitrary
workloads alongside each other what
happens when one thing starts
misbehaving right so if I put four
different services on a single machine
and serve as a start spinning out of
control
like that's all of a sudden going to
push off those other services to be
completely ineffective right so you need
to think of some isolation mechanism and
by the way this is usually what happens
next because all the traffic is
eventually going to going to spill the
other machine and back to that sort of
management burden like how do I know B's
misbehaving because a right this is
really hard so you need to really really
be thoughtful about isolation
and the answer to isolation is not you
know docker like it's more complicated
than that because you have to think
about the intricacies of how these
things work with each other and you
still need to do things like passively
planning all these other things that
that that vendors like to pretend you
don't have to do so if we solve all
those problems we still have we still
have more complication like how do I
find service a that's easy in in a
monolithic architecture I call service
ace functions here service a is kind of
a moving target like obviously at this
scale with things failing static
configuration isn't going to work I can
say oh it's like nine over and one down
right because then some administrator is
going to go patch the OS and oh man it's
somewhere else right so I'd have to go
and redeploy the static that's not going
to work at all some other version starts
failing and shows up somewhere else
that's a very dynamic thing right and
that's that's dynamic for a variety of
reasons from boring stuff like OS
patches to rolling upgrades and more
exciting things like that was nice to
figure out which service to talk to
right think back to that degraded
situation where I have a machine that's
that's not that's not working well like
I don't want to send traffic to the
machine that's not working well if the
other machine can service it well so you
can't just round-robin this like that's
not good enough
you actually given all the dynamism of
workloads and where they're running even
with great isolation there's going to be
different characteristics of a service
running on a different machine and
sometimes there's just slow machines
that's a thing that happens despite
trying to have consistency in your
architectures you need something much
more complicated than choose one at
random and add still more complexity
when something goes wrong again and the
monolith I don't know something's acting
bad looks like pop open our classic UNIX
tools and poke around oh this process
seems like it's weird let's go let's go
and fix that or restart easy not easy
when you have lots of lots of different
machines so you just you need a
completely different approach to
managing it so so obviously using micro
services of startup is a terrible idea
you definitely should not do it you have
to solve all those problems of course
that's exactly what we did and and
that's how I know about the problem so
well by the
just kidding so I do want to try to
factor closure because closure is not
going to save save you from anything I
just talked about either you know you
might make a choice of some closure
library that makes some of those choices
for you but you still get to deal with
all the implications of those choices
even if they're not choices you have to
make and one of the greatest things one
of the things I think people really love
about closures are amazing workflow and
as we talked about earlier right
startups got to move fast you want to
have things that are roughly and dynamic
and and when you split things apart you
end up with situations like this right
where you've got a whole bunch of
terminals and in order to run the system
I've got to run a raffle for each
service get everything where now man
I've got like some leader not available
thing up in the top left that doesn't
look like fun so I've got to get
everything working in my local
environment and that's too much right
that kind of breaks the benefit that you
get from workflow so so when we were
when we were building us we said look we
don't want to lose the value of closure
and dynamism and rep Laurie ended
development while we're building in a
microservices architecture so we went
through a few different waves of trying
to solve this problem so that we could
avoid people having lots and lots of
rebels the first thing we did is we said
okay let's buy everybody a really
expensive laptop with lots of RAM and
we'll cut that box in half half of it
will be for vagrant and we'll load that
vagrant image with exactly the same OS
image that we run in production right
because because you're running Linux and
and we use all the same configuration
management stuff that we do in
production to provision vagrant and
there's some really nice properties of
this right that means lots of people are
running your config management all the
time people kind of get used to adapting
and evolving that they're running
something that's very close to what
you're running a production of course a
much smaller version of that and then
because they're running what's in
production and all the infrastructure
there you can also deploy your services
just like you're in production right so
if I'm if I've got three services a B
and C I can deploy them on to vagrant
and then if I want to work on service a
I just fire up my repple on the host
machine and life is good right this
actually worked really really well
the problem is that you write more
services over time and eventually
there's just too much stuff for vagrant
to do and they don't
at some point they just don't sell a
good enough laptop to be able to solve
this problem or have enough memory so so
this didn't work at scale work worked
well initially so then we adapted this
we built something called the galaxy
rebel so basically what we did we we
kept the good parts of the vagrant stuff
so we still provision like the
underlying shared infrastructure stuff
with them let's not try and run the
services there because that's the thing
we keep adding more and more and more of
and a run vagrant of memory so we said
okay we'll use galaxy wrapper will bring
we'll bring the services back on to the
house as opposed to to deploying them
individually on the on the big road
infrastructure and we'll just kind of
run them all in one process and that'll
allow us to scale up right so life is
good now with those six services
everything's working in galaxy repple
and unfortunately the same thing happens
again
you write more and more services and
eventually run out of memory on the host
machine so these were both useful
stopgap measures they still you know
both of those tactics are used in you
know some cases but but they really
didn't scale completely so eventually
you end up at scale in a shared
development environment and this solves
your resource problems really really
well right now you've got lots of
machines that can run your workload but
that first word is a killer right this
is a shared development environment
which means when people are doing
development on services because it is a
development environment after all stuff
breaks all the time right so you're not
actually better just because you have
more resource now you're sort of dealing
with all the all the cost of a bunch of
people fighting over the same
infrastructure so this is not an easy
problem to solve by the way I don't have
sort of a exactly what you should do I
will tell you what we did and it's
working well but this was not
inexpensive to implement so the first
thing we did is we created a way of
doing side by side deploys so so the
goal is we want stable versions of the
core services so if I want H to stay
stable but I want to be able to develop
it I can make little shadow versions of
H and deploy them out onto the same
fleet now you might be thinking okay but
like how do you prevent stuff
I'm just calling the old age or like you
know if you change everything to point
to the new age here in just as bad a
shape so what we have and and this is
something that that we get as part of
one of the underlying technologies we're
using called finagle we're using you
know the the closure wrappers for fun
angles but basically it's protocol it's
arrow has a little request header and
this request header propagates through
the entire call graph and and because of
that for my request right so I am
working on service h1 I can make a
request to service a even though the
normal path of service a calls G called
H the stable version of age for my
request I can make a little override
that says instead of going to service h
for me and not for anyone else go to
service h1 and that's really powerful
because I can work on service h1 and
that works regardless of who's calling
service H because they're all going to
get rerouted wherever in the call graph
they are because that that override
propagates through the through the
request path so this is something you
have to kind of think about pretty early
on that would be a pretty difficult
thing to bolt on if you had just a
mixture of micro services written in
different languages
but it's really powerful this is
especially useful when you have multiple
people on a single service team working
together so typically we use this
pattern when you've got a bunch of
people who are all collaborating
together on h1 however this is closure
and we can do better right so if I'm
working on service fee I can actually
extend this and and and we've set things
up such that I can boot up service see
in my repple on my laptop and I can
override the request graph for the
shared development environment so that
it automatically routes no matter what
service is calling service C to my
laptop in my repple so that's really
powerful right this is sort of now I
kind of have the best of all worlds so I
get that that repple dynamism just for
the number of services that I'm working
on and I get all the benefits of the
shared infrastructure and my laptop not
running out of memory so this works
really really well it's super expensive
so it's something to consider like when
you when you're building building a
company deciding to use an architecture
of this complexity you've got to solve
these problems and if you don't you're
not going to get all the benefits
all the leverage of something like
closure right you have to solve these
problems other things that we've done
that are lots of fun we have
administrative repple so these are
ruffles that actually run inside the
infrastructure you know what happens a
lot of the times with people like spin
up a tools machine on the side of all
their infrastructure that they throw all
the ripples there right and then you've
got six developers firing up ripples and
that machine starts on fire running out
of memory so so what we did is we we
built a way of dynamically running
rebels over the same infrastructure
where we run our service workloads so
those can be dynamically scheduled and
we don't need the tools machine at all
and as things scale out right we can run
multiple rebels for multiple developers
we can you know sort of scale different
services so in this example service ii
now have four instances because maybe
that needed a little bit more weight and
we can design these things so that
they're preemptable so if i decide all
of a sudden because there's a customer
emergency i've got a spin up the
instance count'em service eetu eight
the rebels are preemptable so it can
boot those out understanding that those
are less valuable in other workloads so
this is great but remember that that
issue we talked about before with
isolation you know there's still the you
know everyone who's used to rebel has
eventually like gotten stuck in some
infinite loop right so if I do that and
my rebels running alongside my services
that's really really bad right so you
have to solve the isolation problem and
the way that we've done that is in the
simplest way possible so we use may sews
as our kind of underlying resource
manager a framework on top of that lets
us express the components of isolation
that are meaningful to us which are
mostly around resources like you can see
examples of disk and memory and JVM keys
and basically this gives us the ability
to sort of in an ad hoc way describe how
big a workload should be and so if my
rep will start spinning out of control I
have a fixed limit on how much CPU that
can take I have a fixed limit on how
much memory it can take and what happens
if something exceeds those limits we
kill it and and and we kill it
because we designed the system to be
robust to these things so notice this is
not an error this is an FYI something
got killed in production this is not
something that we want to happen a lot
but we've designed we've designed the
system so that
you know things are isolated well with
capacity plan we've done thoughtful
planning for each service about what if
actual workload requirements are so we
feel comfortable killing that and that
teaches us something about how to run
the infrastructure this is a very
difficult thing it takes time and you
have to build that robustness layer into
the into the underlying architecture
monitoring becomes really really hard
when you have a lot of things
fortunately in the closure universe we
have something called Riemann and
Riemann is sort of a power tool kit for
being able to do really advanced system
level monitoring focused around streams
of event so so basically in riemann your
monitoring is code and its closure code
that's pretty cool
so so basically you know to be able to
do even like relatively simple things
like notify when one of our containers
got got kicked in production that can
actually be pretty complicated so
riemann gives us very powerful tools to
tune alerts because when you have you
know a hundred machines and anything can
go wrong anywhere to prevent your alert
logs from just being constant you need a
lot of sophistication and how you
respond to these things you need code
and reminds a great great tool for this
we also feed metrics in through a couple
of other layers ending in griffin ax and
this gives us sort of big picture
visibility we have about a dozen
different dashboards that different
people in the organization use to kind
of get a very big picture look at the
infrastructure and this is something
that that requires a lot of investment
but it's necessary you have to be able
to see a hundred things at once to
manage to manage your service well and
have things be robust and reliable and
by the way you got to monitor the
monitoring infrastructure itself so we
actually have a dashboard where Rieman
monitors itself you can see here that
even on a very tiny machine it can
handle you know quite a lot of sustained
load almost 2,000 operations per second
on I think a micro micro instance so
it's actually a very efficient way of
doing complicated things with metrics
highly recommend so end by end the sort
of scaling closure section with this
talk by talking about closure script
because I've been an advocate for
closure script in the past and a lot of
people like a closure script like does
it
no sig we will still work you know the
vamps cop police work and all these
questions is yes closer script is boring
it just works and you don't have to like
rewrite your architecture every three or
six months to like be one of the cool
people in the JavaScript in the
JavaScript world so close the script is
so effective that you can it's easy to
just forget you're using it and in our
primary closure script developer had no
closure script experience coming in two
months and said I'm never going back so
it's just awesome so looking back right
I had a rationale you know I thought
closure was a good language to start a
company with and then we did a lot of
work to sort of scale it out we've got a
bunch of people using closure solving
really really hard problems at really
really large scale so you know did it
check out and and I believe it did I I
do think that we've it took some effort
right at side-effects of our
architecture to kind of get that dynamic
repple oriented workflow as well as kind
of all that large-scale and distributed
computing but it still works like that's
you don't throw that away as long as
you're willing to make those investments
it's simple and data oriented absolutely
I think our code base is definitely
simpler than it would be have we used
another technology we use macros
judiciously but it's a great tool to
have we probably have you know dozens of
them not hundreds or thousands of them
but but it's a very powerful tool for
simplification used well and smart
people want ease and again not just
smart people who already know closure
right smart people want to use it
because I think they can understand if
there's good ideas in closure and it's a
good fit to our problem so I asked
people on the team like what do you like
about closure because you know that's
something that might change right it's a
little bit difference we using closure
on the side versus I'm using closure
every day six or seven days a week and
in some cases given given startup pace
what do you like and I think the answers
were we're really in line with the
original rationale I love the repple
like everybody was like I love the
repple that dynamism of workflow matters
it's real you do get benefit from that
and the second thing almost everybody
said was the mutability right so I think
it's tracing that back to the rationale
suggests to me
it's been a good fit and we and we've
been on a good path and I think we're
seeing we're seeing benefits of that in
terms of the company fit I think it's
also been very good because closers
data-orientation fits our own company's
data oriented problem right we had a
case where because in the underlying
processing layers of our system we used
mutable versioning because that's a good
idea and the thing that makes sense we
had somebody use an API to delete some
data that they didn't intend to delete
and our recovery time was five minutes
right we just said okay well why don't
we hop back write verses a mute ative
thing where we that would have had to go
back to yesterday's backup and replay
from logs it was just it was almost a
non-event and and so there's some
powerful ideas and pin synergies another
thing I'd like to say is I think there's
a great fit in the culture one of the
things that I was excited about in
choosing closure and it's not all
dollars and cents I think the closure
community is a very welcoming group and
I think you know seeing the embrace of
diversity and it's a kindness from the
closure community that represented
something I wanted in my own company and
it's it's nice to be able to hire from
hire from a pool of people that have
already embraced that culture so that's
really powerful and something we've seen
we have a nice group of people at our
company and I think closures helped so
looking ahead what keeps me up at night
it's really important for me that for me
to look you know fast forward two years
from now if I'm going to look back and
say that was still a great decision
closures got to keep pace right we've
got to grow the community we've got to
get more companies using it we've got to
you know sell it inside companies that
are using it on the side and really get
it to be a first-class thing
this creates ecosystem effects that are
good for everyone right tools tools are
good right now they're keeping pace but
our problems are going to get bigger the
number of developers are going to get
bigger so we need to continue
development and continue growth so for
me again I founded a company so so I
have to take a business perspective this
can't be I like closer therefore it's
the right thing
I will change it if it ends up not being
the right thing for the company so it's
a fairly simple calculation for me in
terms of you know is this going to work
you know two or five years from now and
I think it will but we got to keep pace
right there's things that we have to do
to make clothes or work and there's
things that we get back from that
because it's powerful and it gives us
that flexibility and it gives us a
simpler and smaller code base we get
leverage from closure there's cost we've
got to make investments in closure as
well and that community growth over time
will allow us to stay on the right side
of that so I've gone a little bit over
time so I don't have time for questions
on stage but I'll be around I'm happy to
answer any questions after the fact
thanks everyone</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>