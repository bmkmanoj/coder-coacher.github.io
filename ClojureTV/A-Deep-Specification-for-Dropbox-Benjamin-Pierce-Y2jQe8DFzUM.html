<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Deep Specification for Dropbox - Benjamin Pierce | Coder Coacher - Coaching Coders</title><meta content="A Deep Specification for Dropbox - Benjamin Pierce - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Deep Specification for Dropbox - Benjamin Pierce</b></h2><h5 class="post__date">2015-11-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Y2jQe8DFzUM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you rich and thank you everybody
for being here it's really exciting to
have the chance to come and find out
everything that's happening in this
really exciting community before we get
too far let me check the sound is it
does it sound good all the way in that
corner and in the back here and way over
there
excellent I think we're good okay if
this were a standard talk about software
research it might begin with a little
sermon about how we have no idea how to
build software that actually works and I
would go on at length about huge
projects that are late and over-budget
and not working at all and security
vulnerabilities and malicious hacking
and medical devices that hurt people and
rockets that blow up but if you look
around sure there are plenty of problems
but the thing that's amazing is the
amount of software that does work we
build huge intricate software system we
distribute them across the globe they
handled vast amounts of data at
lightning speed so how did we manage
that of course there's no single answer
and some people including me probably
including many of you would point to the
better programming languages that we
have at our disposal nowadays compared
to 10 20 30 years ago
others would point to better ways of
thinking about organizing software teams
and getting things done other people
would point to the incredibly powerful
and stable and long-lived platforms
think about think about Windows if you
like that OS 10 Linux Apache the JVM on
and on and on and the we can stand a lot
higher than we used to be able to and
here's another one that you might not
have put on this list initially but but
it's actually the subject of the talk we
have gotten a lot better at specifying
that is to say rigorously thinking about
what software does
so why are specifications of software
useful well duh if you want to know what
the software if you want it to work then
you want to know what it does and and
it's useful to think about that we are
going to get past the Wilda stage in
this talk but here's a willed
specification so here is a specification
of the simplest possible piece of code
you could write it says the sort
function takes a list of things and it
returns the list of the same things in
increasing order couldn't be simpler
this is a useful thing already and
writing it down might have made you
think about some aspects of sorting that
that you could initially overlook but
there's a few things to criticize about
it first of all aren't we past sorting
functions now this is a pretty simple
thing also aren't we past writing down
specifications in English English is
hard to understand and ambiguous and and
you get into endless arguments here's
another criticism and and for me this is
maybe even the most important one this
specification has nothing to do with the
sort function that you wrote or maybe it
does if you sit with one on one hand and
the other on the other hand you can look
at them and see some correspondence but
as soon as you think about it and say oh
yes that that satisfies that
specification and then as soon as you
edit your sorting function all bets are
off so there's no the specification is
not live it's a it's an inert thing
that's disconnected from the code that
you're right and and that is less useful
okay so so here are three dimensions of
discontent and what we'd like is to move
to the other end I on each of these
dimensions and of course this is a
decade's old area of intensive effort
and people have moved to the other
and in some pretty amazing ways so we
have things like the C language
reference and 600 or so pages Java at
around 800 pages C++ anyway we have we
have architectural reference manuals
that are that are huge we have we have
specifications for things like
standardized architectures for the
innards of automobiles and those run to
thousands of pages so we are not anymore
just specifying the sort function we are
way past those days
we're also past the days of writing down
specifications in English some specs are
still in English but but people are
getting very good and there are decades
of experience in designing really great
languages for writing specifications in
and for writing large and complex
specifications in those languages so so
we have the development of lots of
environments for being precise about
specifications and we have decades of
research in tools for connecting
specifications to verification to to
code and the most obvious way to do that
is verification by which I mean writing
a mathematical proof that the code
satisfies the specification and better
yet writing it in a form that a machine
can check these are power tools they're
not super easy to use but with a little
bit of training people can use them to
do absolutely amazing things we'll see
some of those ok so we started out with
this cube and we're our sorting
specification is down in the simple
disconnected informal bottom corner and
we've seen that people are moving into
the other corners but of course where
we'd like to be is in the far corner so
we'd like to have specifications that
are simultaneously
integrated with the code rich and
describing very interesting properties
of the code and completely formal and I
like to call those deep specifications
specifications with those three
properties so this all sounds fine I
hope it does but you might be wondering
is this possible so we've seen people
moving along one dimension at a time but
could you possibly move along all three
dimensions and get to the to the far
corner is that is that a total pipe
dream even as recently as 15 years ago a
lot of people would have said yes that's
a pipe dream or we're never going to get
there we can keep trying because it's
important but we're not going to be
specifying we're not going to have live
specification of the real code of large
systems any time soon and they were
wrong so things started happening
amazing things started happening about
10 or 15 years ago one of the first that
people like to point out is the comp
surtsey compiler so concert is a
compiler for the bulk of ISO c99 so it
accepts most of the standard C language
it compiles code for power BCE arm and
x86 processors it is not quite as fast
as GCC but not too bad and it is 100%
fully verified into it totally amazing
to me
here's another in a way maybe even more
amazing sel 4 is an operating system a
microkernel operating system which is
nowadays deployed in cell phones which
comes with and end-to-end proof again
this is a nothing up my sleeve proof
that the actual machine code implements
a high-level logical specification the
specification is quite rich it describes
all of the behave
of an operating system it runs about 200
pages and there's a machine check proof
that the to correspond more over the
tools are getting better so we have on
the left hand side very powerful proof
assistance we have the development of
fancy new program logics that make it
easier to reason about about how code
behaves on the right hand side we have
the influence of SMT solvers which are
unbelievably powerful tools these days
and people are using them for for much
lighter weight verification efforts and
we have many more examples of real
software with with rich live and formal
proofs connecting it to specifications
so we have verified compilers concert is
a is a compiler for single threaded
programs we have concert TSO for
concurrent programs in C we have cake ml
for which is a verified ml compiler
bedrock is a another low-level language
we have verified operating systems now
several of them we have verified file
systems we have distributed systems
verified to verified in such a way that
the code meets the the actual running
code meets the spec we have verified
cryptography so what I take from this is
that deep specification and verification
of real software is shifting now we're
seeing the beginnings of a sea change
from a collection of heroic
tour-de-force point efforts to the
beginnings of an engineering discipline
so that sounds great where's it all
going
are we in particular headed for a world
where all software is formally verified
and and specified well no I don't think
so
verification will continue to be a
somewhat expensive activity we'll
continue to use it mostly for
are very critical components of the
software stack but a world where pretty
much all critical components are
verified and other components are
written in much safer high-level
languages than what we use now
like for example closure is no longer
science fiction in fact all of this is
something that I'm working on very
actively with some fine collaborators at
Panna del swear and one thing that we're
very interested in is trying to build
this zero vulnerability fully verified
software stack that I alluded to a
minute ago so we and many other people
are hard at work on every piece of this
picture and I expect to see the results
in widespread use in the next decade
I'll say going out on a limb so I will
sleep better when that happens but in
the meantime some of you may be asking
yourselves a question
I just want to write code that works I
don't want to write proofs about it I'm
just a I'm just a hacker I don't want to
go to graduate school and learn to do
logic and all that stuff so is this talk
really for me or should I read my email
or go outside well I hope you stick
around because what I want to show you
for the rest of the talk is that the
idea of deep specification can be used
in other ways than formal verification
so the first example is type systems
type systems used to be everybody's
favorite example of lightweight formal
verification what do I mean by that well
a type that you assigned to a program or
a collection of types that you assign to
a module is a kind of specification it's
not it doesn't qualify as a very deep
specification for me because the
properties that types describe are
generally quite shallow they talk about
the shapes of things so that they can be
verified statically whenever you compile
by a fairly straightforward algorithm
nevertheless type systems are a runaway
success in terms of improving software
quality because they're always on and
they give you some assurance and some
checking for very little cost nowadays
the things that people are doing with
type systems are becoming much more deep
so those of you that have dipped it to
the haskell world will know that the
type system of haskell is gradually
drifting toward being really a program
specification logic and a lot of the
developments in the haskell community
and the and the technology of Haskell
type checking have been pushing it in
that direction so Haskell programmers
right now can can shoehorn a lot of
information about what their program
does into the type that the type checker
checks so this is very cool but you
might have another question
we're at a closure cumference closure is
not a typed language and perhaps yet so
is there another way to use
specifications that you might find more
directly useful in your day-to-day work
yes there is so another way to use
specifications is for random testing and
and the idea here is again to to get
pretty good assurance to get some help
with debugging our code not to
completely verify it down to the last
iota but to get some assurance that that
we have understood what it's supposed to
do and that it does that and so the
let's go on so the idea is that we write
down our specification as a set of
executable properties so the the
specification is is written down as a
program we we generate many random
inputs and check whether the
specification holds for each one of
those inputs and if we generate enough
inputs and if they're well distributed
then we may find a lot of bugs and when
we start slowing down on finding bugs
this may give us a good degree of
confidence that the software is working
as intended the third idea that I won't
go into into much detail because there's
no time but but these specification
based random testing frameworks need to
pay a lot of attention to the issue of
shrinking so so I'll quickly tell you
what it is if you generate a lot of
random tests and wait for one to fail
you're probably going to come up with a
test that includes a whole lot of
garbage right because there's just a
random thing it's a it's it's probably
huge and only tiny pieces of it are
actually necessary to exhibit the
behavior so what random testing
frameworks of this sort do is once they
find a failing test they start re
running the test pulling out small
pieces of it so they say well let's
let's delete that bit and see if it
still fails if it does let's delete
another bit and see if it still fails so
the it or if it irately make the test
smaller until they can't find any bits
to delete that that yield the test that
still fails when you've done that you
have a test that is likely to be minimal
for illustrating a counter example so so
effectively what we're doing is moving
from unit test Suites to property Suites
plus generating random inputs and
shrinking counter examples so back to
our sorting function up on the top is
the unit test suite that you might write
so it says well if you sort the list 1 2
3 that should return 1 2 3 and if you
sort 3 2 1 that should return 1 2 3
again now this is fine in fact it's
pretty good so I'm a big fan of unit
testing it's good for a couple of
reasons it helps find bugs but also it
makes you think about what the program
is supposed to do and that is basically
a specification activity so it makes you
think about what the specification
should be and then generate test cases
from that the problem is the downside of
unit test suites is that you do all this
work you write down a bunch of tests you
have to think about the specification as
you're doing it and then you throw away
the specification or flush it from your
working memory and you just keep the
tests so that later on if somebody wants
to understand what the specification is
they either have no hope or they have to
read arrived it from the from the tests
that you wrote or maybe you wrote some
comments but wouldn't it be so much
nicer just to keep the specification and
generate the unit test from that so that
leads us to something more like the
bottom where we write down okay the
sorting function sure
take a list of things and return an
ordered list that's the first property
prop ordered and then the second list is
it should take a list of things and it
should it should always return a
permutation of the original list and
when you put those two together that's
what we mean by sorting oh this bottom
example isn't in closure is it I'm sorry
that's better okay so so this this
notion of specification based or often
called property based random testing was
first popularized in 1999 by Kuhn
Clausen and John Hughes their tool was
called quick check it was written in
Haskell but it was quickly ported to
every language that you can imagine
including of course closures so you can
view this whole talk is actually an
advertisement for tests on check in case
it needed one so you can find ports of
quick check to just about every language
that you might happen to be working in
there is a company it's called cubic
that that markets not only the air long
port of quick check but also consulting
services using quick check to to find
bugs in real software and it has been
used to find bugs for telecommunications
companies and volt and car manufacturers
and distributed databases and so on and
so on so what I would like to use the
end of the talk for is to give you a
little tour through a quick check
specification that I wrote along with
John Hughes co-developer of quick check
and Tomas art's co-founder of cubic and
the software that I'm going to specify
is Dropbox now you might ask why do we
want to specify Dropbox here's my answer
first of all it isn't just Dropbox there
are many servicing critias ation
services out there six percent of the
world's population uses Dropbox alone if
we add in the next-biggest - then it's
10 percent and all of these whatever it
is 1 billion people or so are entrusting
these services with all of their most
precious data including possibly their
closure code so I think I would like to
see a specification so the goals will be
we want to write down a precise
mathematically precise specification it
will be written down since it's a quick
Chek specification it will be written
down in the form of some air long code
that that can test the correspondence
between an input to synchronization
service and the observation that we make
of its behavior so we want the
specification to be phrased from the
point of view of users of a service for
two reasons one because we are users of
Dropbox we don't work for Dropbox so
we'd like to know how it behaves as
users and also because since Dropbox is
effectively implementing some kind of
distributed file system every other
synchronizer out there should probably
have more or less the same behavior so a
specification that we write for Dropbox
should be usable with maybe minor tweaks
- to test not only Dropbox but lots of
other tools that are out there ok so
we're going to write down a
specification and we're going to
validate it by comparing it by using
quick check - to test whether Dropbox
actually behaves that way so the setup
of our test is very simple for the
moment we can we
run our tests just on one laptop that
makes things easy on that laptop will be
an air long process it's the controller
of the tests so so it's the thing that
is distributing commands to the various
to the various nodes saying you know try
writing this file and now see what the
file system looks like and so on the
those different nodes are running as
virtual machines on the same laptop and
and in each of those virtual machines is
a little ere long stub that's
communicating with the with the master
and and executing the commands that it
says also on each of those VMs is a
Dropbox client we had nothing to do with
that we just installed the standard one
and and each of those is communicating
over the network with some servers that
Dropbox owns ok so this is the testing
setup and here's the idea of the test so
we have let's go back one alright so we
have the system under test that's what I
just showed you and we have a model of
the system under test that's the
specification that we're going to write
and a test is going to be a sequence of
operations things that we do to the file
system when we run the test we're going
to execute each of those operations by
really doing things to the file systems
of the different VMs and each time we do
that's going to give rise to an
observation what we see when we execute
the operation and now we're going to
define the model as a little state
machine so it's going to have
transitions corresponding to legal
observations and what we want to see is
that each of the observations that we
make when we run the test is allowed by
the state machine defined by the model
if we reach a state where the next
observation doesn't match
anything that the model can do then
that's a failing test is that a bug
notice I said I said failing test not
not necessarily bug is it a bug or is it
an error in the specification a priori
could be either one so you have to look
at the specification look at the
behavior and decide which one you like
so the basic form of the specification
I'll refine it in a minute but the basic
form of the specification looks like
this if if we have some sequence of
operations read this write that then we
execute it and it gives rise to some
sequence of operations of observations
excuse me
then what we want is that from the
initial state of the model the
transitions implied by those
observations are a valid sequence of
transitions for the model so this is the
specification written in English not air
long of of what a synchronization
service should do of course there are
some details to fill in so first of all
we need to think about what operations
do we need and what observations do they
give rise to where's first try so the
operations are read and write and the
observations are when we do a read okay
so read and write each annotated with
the node the the client node that we're
doing the read or write on so if we have
three VMs then we can do read from one
and then read from three and so on so so
read on a particular node is an
operation and write a new value on the
on a node is another operation the
observations that we make are when we
read from a node we observe the contents
of the file when we write to a node we
observe the previous contents of the
file so we're going to implement the
write operation by actually doing
read and then quickly writing the new
value and this is important because the
specification is going to want to know
what is the value is going to want to
talk about the value that was
overwritten by the right now you might
be wondering something
I'm not saying here which file I'm
reading or writing and for present
purposes for purposes of this talk I'm
going to make a small simplification
which is that there's only one file now
is that a ridiculously small
simplification does it make the
specification uninteresting no we can
still find bugs okay so so I'm just
gonna there will be one file and I'll be
reading its value and writing new values
into it and and I'll use a special value
so the value in the file will be a
string generally but if the file hasn't
been created yet if this is before the
first write in a test and we do a read
we'll get back a special value called
missing and and if I write the value
missing into the file what that means is
delete the file okay so really with the
operations are read write and delete but
I'm gonna squash them into two just for
brevity okay so this is the basic set of
operations but there are a couple of
challenges that we're gonna need to deal
with before we can get too far
the first challenge has to do with
conflicts I've been in the
synchronization business for a while
I wrote a synchronizer called unison
back in the 90s and and it for a long
time until we did this work it was the
only synchronizer that had a formal
specification now there are two
and from that experience what I can tell
you is that the hardest thing about
synchronization is conflicts everything
is pretty easy as long as nothing
happens as long as there are no
conflicting changes as soon as there are
conflicting changes you really have to
think hard and things get subtle so what
do I mean by conflicting changes so here
are two nodes and on the first node we
write the value a into the file and very
soon after before the second node has
had a chance to hear from the first node
via the server it writes the value B now
sometime later the second node gets the
message that the first node wrote a and
now we have a problem and we have to do
something so what do we do different
synchronizers do different things but a
reasonable answer and the answer that
Dropbox chooses is to say that the
earlier value wins
you could argue with that you could say
well why not have the later value win
but this is what they do so so the
earlier value wins that is the value
that the server heard about first wins
and the other value B in this case will
get moved to a conflict file in the same
directory so we get moved to a file
whose name is blah blah blah conflicting
version at such-and-such a time so it
sounds like we should write down it
sounds like maybe the right operation
should observe not only the value that
wound up in the file but also maybe some
conflict files no that's not what we
want and the reason is that Dropbox
actually has a kind of a funny behavior
here so these conflict files the file
containing B actually doesn't show up
for a little bit so when the when the
the second node hears about a it changes
the value in the file immediately to a
and B just disappears for a short time a
few seconds
assuming there
your connection to the server is good
and and so if we tried to observe the
effect on conflict files immediately
after the right as in fact an early
version of our specification did it
would look like the behavior is wrong
since we want to match Dropbox's actual
behavior we need to do it a different
way and the way we do it is by adding
one more operation we call it stabilized
and what it means is we wait for a
little bit until the same value is in
the file and the same set of values is
in conflict files on all of the nodes so
we wait for everything that's going to
happen to happen and then what we
observe is the value in the file and the
set of conflict conflict values okay so
this gets us going with dealing with
conflicts but there's one more challenge
and that is a non determinism so the
issue is that the Dropbox client is
looking at the file system and we're
effectively using the file system as the
API to indirectly communicate with the
Dropbox client so we're writing stuff
into the file system and it's noticing
pretty soon after but it's also
interacting with the Dropbox server at
times of its choosing and in ways that
we can't see
moreover the the timing really is
completely unpredictable so it isn't
that you know you write something in the
file and then after a certain fixed
length of time there's a communication
with the server and things happen it can
really be from very quickly to to a very
long time so we have this invisible
unpredictable activity in the background
that is to say the system that we're
testing is non-deterministic is
inherently deeply non-deterministic so
so we need some other approach we need
some we need to enrich our approach
there are different ways to do this and
we experimented with several and the way
that we wound up with as being
lightweight natural easy to understand
and possible to use for testing was
simply to model the the interactions
between the Dropbox clients on each node
and the Dropbox server as explicit
operations excuse me as explicit
observations not corresponding to
operations that we include in tests okay
so now things are getting a little bit
subtle but I've been hit stay with me so
the final version of our set of
operations and observations is this the
operations are as before the
observations include the three that we
talked about and two kind of pseudo
observations which we don't actually
observe we don't see the server
communicating with the client but we can
conjecture them so the final
specification looks like this it's we we
take the test which is a series of
operations we run them to gather
observations now between each pair of
actual observations we insert some
number of conjectured observations of
ups and down so up is the client saying
to the server here's what my state is
and and down is the server saying to
some client here's what your state
should be so we insert some sequence of
ups and downs and the important thing to
think about is there can only be
finitely many of them because it's only
interesting for each client to
communicate with the server twice one up
and one down so that's what makes
testing still work so inserting all of
these ups and downs gives us an
explanation a potential explanation for
what we saw and we run that explanation
against the state machine that's encoded
in the model to see if the model says
yes that's a valid explanation here's an
example
suppose this is our test so we we write
a on client 1 we write B on client 2
then we read on client 1 and then we
write C on client 2 and then we
stabilize and see what's happening okay
so that's the test sequence when we run
that test one sequence of observations
that we might make is when we write a we
see that the previous value on client 1
was the file wasn't there then when we
write B we see that the previous value
was a that means that there must have
been a communication from client 1 to
client two via the server in order for
that to happen
but we're not seeing it in the actual
observations that we made the
explanation that we can generate or an
explanation that we can generate one of
the valid explanations that explains
this sequence of observations is client
1 does a right then client 1 does the up
action then client 2 does down and then
we get the actual observation that we
made that that we see a and so on okay
so this is our specification this is our
real specification now how do we use it
for testing well we just have to turn it
on its head so the the specification
that I gave said this must be the case
to test it we just generate a lot of
test sequences and check for each one is
it the case and if it isn't so that is
to say if for every interleaving of ups
and downs with the observations that we
actually made the the model says no at
some point there's no transition from
from a state that we reach then that's a
failing test
all right I am running short on time so
I'm not going to tell you the details of
what the model looks like there's paper
about this if you're interested it's
pretty simple though so the states of
the model are we need to keep track of
the global stable state that is the one
that the server the value of the file
that the server knows we need to keep
track of the global conflict set so the
set of conflict values that the server
has heard about and then at each node we
need to keep the local value of the file
and two bits one saying whether that
node is fresh that is it's heard from
the server recently or stale that is the
server has something newer and whether
the node is clean or dirty dirty means
that it's been written since the server
heard from it and given all that stuff
we write down specifications of steps
that the model can take in the form of
preconditions and transformations on the
state so there's one for read one for
right one for stabilize one for down and
one for up and the one for up as you
might kind of expect is the most
complicated I won't go into detail but
but this was not our first specification
it required some refinement and and and
we refined it as a result of failing
tests that forced us to think about Oh
Dropbox is doing something a little bit
more subtle than what we realized in
particular two things that you could
read here if we if we took time to
unpack the notation are if two different
nodes without talking to each other at
more or less the same time write the
same value into the file no conflict
second if one node writes a value into
the file and the other node deletes the
file no conflict the deletion loses even
if it makes it to the server first
interesting a little bit interesting
here are some more interesting things so
here is an observation showing that
Dropbox can delete a file that was just
created so let's see what happens so we
create the file and client 1 we put the
value a we then delete it on client 1 by
putting the value of missing on client 2
we observe the creation so notice that
client 2 has not heard about the
deletion yet on client 1 we create the
file again and finally we read and
notice that it's gone ok well what
happened well don't worry it will be
back after a little more communicative
communication with the server to
stabilize things so is this a bug maybe
not probably not but but it certainly
surprised us when we found it one
interesting thing here just a footnote
is that the timing of the of the of the
operations here is very critical so if
you just blast out all these operations
as fast as you can you won't exhibit
this behavior you have to do it in a
fairly carefully timed way so the thing
that I'm not showing you is we actually
have one more operation it's called
sleep and so when we're generating
random tests were generating asleep for
random lengths of time when we're
shrinking tests we try to shrink the
sleeps away or make them as small as
possible and and that allows us to that
allows us to generate short tests we
didn't have sleep we could still get
this behavior but you might need a test
of 10,000 writes or something like that
to to wait the right amount of time so
sleep allows us to have short tests the
trigger timing the timing dependent
behaviors ok second surprise
Dropbox can permanently to recreate a
deleted file even if you're only doing
things on one client at a time okay so
there isn't there are other clients but
they're idle so so what do you do you
write be creating the file then you
delete the file at just the right time
and then you wait a little bit and read
the file and notice that it has come
back and this time it doesn't actually
stabilize to what you might think the
file is back for good and and the
deletion got overwritten
here's another surprise so what happens
here so we create the file on client -
we write BNE into it why is it client -
now instead of client one because we
created these randomly okay so we create
the file on client B we overwrite it on
client one and again the timing here is
very critical and notice that that the
the write sees the value B in fact the
timing that we need to use is we need to
overwrite the file as soon as it arrives
while the Dropbox client is still doing
some stuff okay so we so we wait for the
file to arrive and then immediately
overwrite it and then read it again and
notice that we have actually written we
read the value that we wrote but now we
try to stabilize so in the stable quote
unquote state so you wait for a long
time and and nothing changes and in the
stable State
the new value persists on client one and
the old value persists on client - so
why is that bad
further investigation reveals that
client one believes that it is fresh in
other words if we if we overwrite beyond
client two then a disappears without
going into a conflict file okay so
that's a data loss bunk
all right there are many details of all
of this in the paper that you can find
on my web page where are we going with
this specification effort well of course
we would like to we believe that there
are probably more bugs to be found and
and from experience with unison we
expect that adding directories will
flush some more out so so we're working
on now is adding directory structure and
generating generating tests involving
multiple files and directories and the
other thing that we'd like to do is test
lots more synchronizers this takes a
little bit of every particular
synchronizer that you pick up it takes a
few days of messing around with the test
harness because synchronizers are kind
of finicky beasts I'll tell you one
difficulty that we had with Dropbox when
you're trying to generate random tests
and you want to generate a lot of them
and execute them very quickly so what
kind of workload does that mean for the
for the Dropbox the machines that are
running Dropbox what they're seeing is
lots and lots and lots of changes to the
file system in as fast as we can
generate them what do you think Dropbox
does when the client sees that kind of
activity in the file system it backs off
it backs off and batches the
communications with the server so as not
to overload the link but that's exactly
wrong when you're testing it's exactly
what you don't want so there's a lot of
this kind of back-and-forth of you know
how can we could jewel the system that
we're testing into behaving in a way
that we can that we can follow
lots more as described in the paper but
for now let me just say that I hope I've
given you a sense of the excitement I
feel in some of the ideas that are now
becoming real both in the area of
specifying and verifying real software
systems and in the equally hot area of
of property-based specification based
random testing so thank you very much
for your attention and I'd be glad to
answer questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>