<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>It's Just Data - Bob Calco | Coder Coacher - Coaching Coders</title><meta content="It's Just Data - Bob Calco - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>It's Just Data - Bob Calco</b></h2><h5 class="post__date">2017-03-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wR2kYn-7ijQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon everyone I'm Bob calcio
I'm chief architect at Apex Data
Solutions the title of my talk today is
it's just data or everything your
database can do day Tomic can do meta
it's a it's an ideas talk today so no
code but it's one that I hope will help
you wrap your mind around the real value
of des tommix unconventional but
incredibly powerful information model
and all for other tidbits from our
experience in adopting it now that may
be enlightening to you as well the first
thing we're going to do is deconstruct
the title of this talk it's just data to
introduce the underlying themes and
we'll talk about some of the uses and
abuses of data generally that all of us
have encountered in our life experiences
in particular our professional
experiences
next we'll meditate a bit on the topic I
find really fascinating which is whether
and how far data models as we currently
build them really model anything real
does fidelity to reality even matter or
can we get by with less we certainly
seem to have been trying to get by with
less for a long time and I think des
Tomic teaches us that that's true or
does domain description asserting facts
about our domain hold out a better hope
for an approach to traditional data
modeling how you think about a problem
very often is the problem and you know
when we are modeling our domain right we
we really want to find the right
description so that the data that we
store in our in our databases is
relevant and timely and available to us
so I'd like to highlight how many of our
data modeling wounds that we've all
experienced are in retrospect
self-inflicted it's a natural outcome of
the way that we've been taught to think
about data our next topic will be we'll
touch on the Atomics Homo iconic nature
the whole schema is data mantra we can
know intuitively that this is a
profoundly important innovation it's
certainly the main one that caught my
attention early on in our consideration
of de Tomic but what does it mean prac
quickly for building real-world database
systems finally if there's still time
I'll talk briefly about the problem apex
is trying to tackle in the healthcare
space leveraging de tommix process
relational philosophy of data management
it's an easy problem perhaps you've
already solved it I called it pilots
dilemma or what is truth
in a world of conflicting authorities
about truth and there's no place where
that's more true in our experience than
in healthcare ok so our first task is to
deconstruct or unpack the phrase it's
just data bare with me I hope that this
will help us understand some important
things about atomic and why my company
is investing in de Tomic both
technologically and philosophically in
order to solve some vexing puzzles in
healthcare and other socially impactful
industries and why just maybe your
company should too so first we're going
to put emphasis on the word data the
first thing to note is that data is the
plural form of datum which happens to be
the fundamental unit of data storage in
de Tomic in philosophy it's any fact or
set of facts assumed to be a matter of
direct observation in epistemology the
study of how we know what we know it's
often defined as the object of knowledge
presented to the mind presumably for
ratiocination in civil engineering the
word datum has an interesting meaning it
means any level surface line or point
used as a reference in measuring
elevations a datum as a reference is an
interesting idea if you think about it
deeply but the bottom line is it's
something in the real world that we care
about something we want to think about
or maybe even something we want to do
something about or more radically maybe
it's something that we want to do
something and the good news is that de
Tomic is uniquely suited to diverse but
practical ways of thinking about and
getting the most out of our data so now
let's get some context around the word
just just in this context is used as an
adverb modifying the object which is
data the first adverbial meaning of just
is only or merely as in Jane was just a
Rubeus before she met closure
here homely or merely imply something
presumably inferior the good news for
Jane is that she met closure she became
a closure and transcended her previous
state as a mere rubyist but despite the
happy ending this sense of just implies
a negative inference the next adverbial
meaning of just is exactly or precisely
as in that's just what I meant
where the you know where the thing that
I meant and that whatever the antecedent
of that is are exactly the same thing
they're one in the same this is a
neutral objective statement of
equivalence the last adverbial meaning
of just I'll mention is actually really
positively it's meant to emphasize a
positive feeling or emotion about a
subject as in Portland weather is just
glorious
now I'm from Tampa Florida
so I'll just note parenthetically that
this adverbial sense of just can be hmm
a little less precise than the previous
one and might indicate sarcasm so what
I'm getting at is when we say it's just
data a listener who doesn't appreciate
the object which in our case is data
might take away from this expression
that whatever it is it's just data and
therefore something inferior because
data's inferior like it would be better
if it wasn't just data but we'd love
data right so we want to be able to say
this in the precise or ideally even the
positive sense we want to say yes it's
just data and this precisely is what's
so awesome about it so okay it's just
data and that's awesome but what is the
it we're talking about here precisely is
it a good thing that makes us smile and
laugh or a scary thing from which we'd
rather hide I would contend that this
depends on the database you're using
because as you probably have guessed the
it I'm talking about today is schema
okay so now we're firmly on topic in the
atomic schema is just data
so what's schema then one sense of the
word is a plan diagram or scheme when my
wife and I moved into our house last
year
among other things we got like the big
HOA agreement was the entire floor plan
of the house in in in architecture form
now my wife was trained as a real
architect I'm just a software architect
so I I was kind of nervous about a
decision we were making we get it
related to the stove to replace it we
needed to know what kind of socket was
behind it and since it didn't have a
keyboard I didn't know how to figure
that out but my wife was able to open up
the plan the schema and go to you know
all the different keys and legends and
discern that it was it was a 220 outlet
not a 110 so we were cool and that was a
good thing to be able to look at the
schema in real time the next sense come
from comes from Kant's philosophy and it
sounds pretty harmless at first blush a
rule or principle that enables the
understanding to apply its categories
and unify experience as if to make this
clearer he said for example Universal
succession is the schema of causality
and I'm not going to try to explain that
psychology provides a definition of
schema as a mental model of aspects of
the world or the self that is structured
in such a way as to facilitate processes
of cognition and perception so it's
basically con stuff in ition but with a
experiential or a posterior bias instead
of an a priori bias all we mean in data
science is metadata about data schemas
govern how our databases manage data or
not if we're foolish enough to buy into
the crazy idea of schema lessness
unfortunately Kant's ideas have
corrupted everything even data modeling
and I'm actually understating this the
issue is that too often we build models
that confirm our bias about the world
and thus collect data about it and
define it you know it gives us this
godlike power to define the world and
get data about it on our terms and that
therein lies the danger which is a nice
segue into my next topic my next topic
is how we use an abuse data for life
it's a play on the title of one in Ichi
smaller and lesser known rants entitled
on the use and abuse of history for life
where he talks about the then-current
obsession with historicism in the
pernicious ways hyper consciousness of
history usually tainted by the bias of
historians poisons our view both of the
past and therefore of the present now
here I'm quoting John Dewey instead who
said a similar thing but a bit more
subtly and a bit more charitably he said
time and memory are true artists they
remould reality nearer to the heart's
desire and that's really interesting to
think about before I elaborate on that
let's take a step back and consider what
are the good uses of data for life why
why do we need it what do we do with it
well we want to make well-informed
fact-based decisions in as much as we
collect data that provides good
actionable information data can save our
bacon in the clinical space where we've
been working you can even save lives
sometimes we have so much data that we
need to crunch it based on models called
simulations in order to comprehend how
different events or variables affect
outcomes if enough if we have enough
clean data these can even have
predictive value and that's kind of the
whole motive behind big data right often
we want to be warned when bad things are
about to happen so that we can take
preventative action a medication
reconciliation application that we built
for the VA in a recent contract had this
objective as its ulterior motive if you
will for an elaborate metrics capture
scheme that was intended at bottom to
help the VA identify among other things
at-risk veterans so that they could
intervene proactively instead of read
about more deaths in the news so this is
consequential stuff somewhat easier to
explain use of data these days is
visualization the quantity and
complexity of data knots is not
something our minds croc natively that
is to say in raw data form but if we can
picture it our minds can understand it
faster than the most powerful silicon
based computer in the world so this is a
particularly useful and valuable use of
data now the use of data we had apex are
particularly interested in storytelling
this is another modality that the human
mind graphs
more readily than raw data and this is
where de tommix lose nothing philosophy
of information management really shines
sometimes it's more important to know
how a patient situation got to be this
way than it is merely to know that what
the situation is I mean in an emergency
yeah we need to know what it is and
that's enough to kind of get started but
if you really want to bring healing
you've got to know the whole story and
good stories are what they're about
characters that evolve or change over
time the atomic is about identities
whose state changes over time seems a
good fit we're also interested in
filling gaps in correcting falsehoods in
that story and here again de tommix
fact-based information model combined
with its closed world schema provides a
solid foundation for reasoning about the
data that is known for that very purpose
to tell the patient's story and then to
fill in those knowledge gaps so now
let's talk about the abuses of data for
life if our data is incomplete and we
don't know or we don't care that it's so
we can make some really bad decisions
life ending decisions if our data is bad
or corrupt and complete our simulations
can convince us or others that were
right when in fact we're wrong about
something yeah I don't think I need to
comment on that one data can be used to
obfuscate rather than clarify an issue
is anybody hold enough to remember the
debate about smoking I happen to believe
you should be allowed to smoke if you
want to preferably outside but let's not
pretend it's good for you from a cancer
prevention point of view right now the
worst use of data arguably is to tell a
deliberate lie to modify or launder data
to tell the story we want to tell and
not the story that's true call it
alternate facts or whatever but this is
really bad so here's the problem in a
nutshell I'm gonna read from Charles
Sanders purse here it will sometimes
strike the scientific man that the
philosophers have been less intent on
finding out what the facts are then on
inquiring what belief is most in harmony
with their system charles sanders peirce
was a really important
her in a polymath and his works as one
of the founding fathers of semiotic the
study of signs had a huge unsung impact
in the 20th century which I had more
times to tell his story but getting back
to the matter at hand I contend that
modeling the world in sequel terms in
particular holds no hope of avoiding
this kind of danger systematizing the
atomic however allows us if and only if
we want to be to be driven entirely by
facts ie data even in the case of
modeling our domain because it's just
data so let's talk about what that means
with a really really simple example no
code I promise because I don't want to
the syntactic nuances of sequel and Eden
to get in the way of the important
concepts here so in sequel there's this
concept of like not null which is used
as a kind of business validation that
says if we don't have this value
associated with a given entity reject
the whole transaction for some new
record we're creating it's called a
required field and we're used to this in
pretty much every database we've ever
touched the atomic doesn't have such a
schema attribute to enforce the concept
of required for the same reason it
doesn't have a null value type the
granular nature of de tommix information
model expresses the non presence of an
attribute value in the simplest way
possible it simply isn't there after
beats aren't grouped into some arbitrary
tuple structure like in sequel so it's
actually quite easy to find that out now
let's consider a common example of this
right social security number I worked on
a financial planning practice management
app for so called FAL solo plaque
practitioners but many many moons ago
and in their requirements the social
security number was a required field for
the client entity why was it required
well obviously social security number is
a required field on various client
engagement and financial instrument
application forms fair enough you can't
do business without it so it seems
reasonable
a more troubling though Social Security
was also part of the composite unique ID
that was intended to be easy for the
planner to remember you know think like
calc nine nine nine nine for example so
a number that should be kept entirely
private in which you might not know when
you meet somebody for the first time our
second or third
was required just to add them to the
database that seemed to me a pretty bad
idea
so my mind did what it usually did back
when I was young and dumb and thought
sequel was all the bomb I started to
decompose the client entity to arrive at
an elegant ontology I did this because I
realized really quickly that key
entities in the data model I was asked
to create were in fact the same thing at
bottom person so a client relation which
is a relative of a client used mainly
for marketing purposes but also for
filling in beneficiaries and that kind
of thing adviser an employer could be a
person a solo practitioner could hire a
clerk or something to help them with
data entry so entities could be multiple
things it was a fascinating problem but
it got deeper it got deeper so person
wasn't the only thing with a unique
identifier from the IRS corporations so
sometimes a client will have a company
and you need to do business planning
with them and if you want to kind of
protect their assets in the most radical
way you'll put it in an irrevocable
trust because that has its own identity
right so all of these things and all of
their subclasses all of their
descendants are essentially legal
entities modeling this in sequel wasn't
so hard
but querying to obtain all the data for
a single legal entity with a tax ID that
might be in the system was really quite
painful after a baker's dozen left outer
joins you start to see where this breaks
down for example tax ID itself is called
something different for each concrete
entity subclass oh this is what I should
be dealing with when I just want to save
data before you know it you're you're
recreating a problem that has since been
called the impedance mismatch and I did
it with a vengeance on that project it
was it was a very very fun on a certain
intellectual level but in terms of
getting the code written quickly and you
know deployed that it was actually very
counterproductive so then you know you
start thinking because this was all the
rage back then hey I bet an ORM will
help an object relational mapper I have
one piece of advice about that
don't do it really painful I spent so
much time doting on the model and so
little time really getting you know
productive user interfaces going it just
didn't help right I was I was fighting a
problem with how the database thought I
needed to store my data and I was not
fighting the problem of the domain which
was to help planners compete with the
big guys with their clients you know in
some sort of you know technology enabled
way so there is a better way let's ask
the question you know what can and can't
I do with and without the tax ID why not
allow the system to store at least what
I do know and coincidentally in
healthcare you know some of the systems
that have been built and worked for many
many decades were way before there was
sequel and one of them with which we're
very familiar Vista runs on a language
called mumps which is even sounds bad
but it has a an amazing storage
capability built on something they call
Global's which is like this
n-dimensional sparse matrix and sparse
matrix was a good thing because it meant
you didn't have to fill in every blank
and you weren't overly concerned about
in all that there was a null or not you
just don't have any you know a patients
there at your door stop bleeding you
don't have their social what you're not
going to help them right that wasn't
feasible so they though that area kind
of evolved without all this nonsense for
many years before they started trying to
pull everything in the sequel so okay I
I need to have the social security by
the time I sit down and engage somebody
as a client to help them fill out
financial application forms mainly but
it shouldn't mean that I can't keep
information about them in the database
at all for any purpose so what's
happened here like how did we get to
that place where that's even a problem
well we've let business logic complex
the storage problem if you think about
it wouldn't it be much simpler to let
the business logic layer decide what to
do in those cases well this was at a
time when that clean separation of
layers was just kind of taking on you
know just taking taking on a life of its
own and the reason why you want to do
that is it might change over time and we
all know that in sequel for
or schema change is pretty painful or it
can be that was kind of the genius
behind rails for example which put
validation in the application logic
layer which also isn't by the way the
best place to put it but data validation
and business logic this is kind of what
I'm trying to get at here they're easy
to conflate in sequel based systems
because it's very tempting to use not in
all and stored procedures to provide a
homogeneous set of rules for all client
applications that might connect to your
server so again this is very
client-server mentality but good
architecture demands decoupling and
layering anyway and that's not hard
anymore there's lots of proven patterns
out there and we see them all the time
in in big enterprises so you know I
would argue a well-designed into your
system application the application layer
should also not worry about business and
validation rules as you get them from
the business logic layer and the good
thing is you can still have just one
place to manage all that so let's face
reality here like the deeper issue is
that objects and entities in fact they
in a fact-based world are total figments
of our imagination they are not they
don't exist they don't exist in the
database for sure they're just sort of
representations that help us maybe think
about them and often we project into a
domain in ways that subtly undermine the
usefulness of our systems and becomes
less expressive with respect to reality
as we become more deeply familiar with
what that reality is in the domain you
know when I first realized that a client
actually wasn't a single person it was
usually a family was really the the unit
that you were dealing with because you
had you know beneficiaries and all that
stuff going on so a client could be a
family which is usually two people in
the past that was as male and female and
how they could be both and they may or
may not be a second part of the family
it could be a single family home right
you start getting you start really
thinking through what this means in the
domain and how you apply this knowledge
to you know further the business
purposes of the domain and you realize
if you didn't start out with that
concept in sequel it's a painful haul to
change that but not so in DES Tomic you
just add attributes as those
facts about your domain emerge and then
you start adding data related to those
facts and it just grows organically and
you can always go back in time in query
as of the schema that was enforced at
that time that you're interested in and
that's that's an amazing mind-blowing
kind of meta capability the first time
you experience it you'll know what a
moment it is so so what is an entity and
atomic then in DES Tomic data accretes
in terms of attribute values as state
associated with identities and this is
this is the key point what we call an
entity and atomic is really an identity
the entity value of at atomic five tuple
is just the ID of some thing in the
database and that thing could be many
things in the domain the president's are
non presence of various attributes which
we can give names to which we can give
names that imply in any characteristics
for our mental convenience that's what
makes an identity and entity and atomic
so how do I know I have a client here
because when I asked atomic in one call
what we know what all we know about some
identity I get back all the attributes
associated with it at that point in time
some of these might be prefixed with
client right because that's what we we
gave attribute like client slash you
know date of engagement something like
that
and and if not then this identity is not
yet a client it's that simple
if it has some client attributes but
maybe social security is not one of them
well they're a client we've made some
kind of verbal agreement they want to
work with you but you're gonna need to
get that Social Security number before
you help them by a mutual fund right so
I mean that's the consequence of not
having it and and I can still have them
in the database and know about them so
you know this doesn't have to be hard
fault tolerance is a good thing in
complex systems and databases involving
complex domains where the very concept
of the entities are very tough to
disentangle that's a good thing and it
is a complex system just like any other
and no one layer in a distributed system
solves all of our problems right we're
really just trying to solve the storage
problem with DES Tomic here
storing data alright that that all made
sense let me just switch gears and look
at schema is data from a completely
different angle a year ago at the last
closure West I heard a talk by Luke van
der Hart from cognitive about a new web
framework called Arachne that he wanted
to embark upon like many folks
my first thought before I heard him
speak was oh just what the world needs
another web framework Arachne spider web
I get it
but almost as soon as he opened his
mouth and began to articulate his vision
I realized he was really talking about
something different something new and
the web framework pitch for Arachne was
really kind of a sizzle to sell a much
more radical and to my mind interesting
stake I was at that time ruminating and
how to take the work we were doing for
the VA on a generative programming
framework called Vista Services
assembler to the proverbial next level
in this context as I heard Luke describe
his vision for a totally data-driven
framework that used the atomic in memory
database to actuate real instances of
applications
I found myself unconsciously nodding you
know many years ago I want to say around
2003 someone gave me this book for my
birthday in it and I read it with great
interest because it was about generative
programming that's always been a niche I
wanted to scratch it's called generative
programming methods tools and
applications in its vision of totally
component based automated application
assembly really appealed to me books a
bit dated today most of the examples are
in C++ and a few in small talk but
nevertheless I always wanted to see the
software industry get beyond the hard
coding or even code generating to a more
reliable way to produce diverse
applications quickly make a long story
short we've invested in Luke's efforts
on Arachne and it's close to being
usable today in fact we have been
building much of our stack which we call
apex unify on Arachne or at least its
core principles I would encourage
everyone to check out where it's at
today just go to WWI rocky framework org
and try out the tutorials so Arachne
still has some really rough edges but as
Luke will almost - defensively protest
but it really pushes the boundary of
this schema as data concept I recently
had an epiphany about it myself one of
those moments when something you know
intuitively just sort of crystallizes
and suddenly you're actually able to
explain it to somebody else so I ran it
by Luke and logic goes something like
this if some data is code and we know
this because in lisps like closure all
code is data and if all schema is data
as is the case in DES Tomic then it
follows that some schema is or at least
can be code by which we mean use like
any other data to generate behavior at
runtime you know as with Lisp you have
to posit some runtime to make these
assertions operational for a day Tomic
schema is data there's the diatomic
runtime in the case of schema as code
that's what the Arachne runtime gives
you it's a deeply meta concept and that
I find frankly really exciting now in
its current form that schema is in fact
indistinguishable from code in that you
configure your Arachne system with
component provided domain-specific
languages or dsls so if you're a
component developer you follow a few
simple rules to you know basically
stuart sierra component and have a
parameterless constructor and then
somewhere you could define a dsl to
describe to the using system how to
configure this component and you know
when you think about it that's that's
pretty cool now if he's been panned a
little bit for this using a DSL is the
first way to do it but if you think
config and DSL is retro you're right but
you're missing the point it's just a
bootstrapping convenience for Arachne in
his early form the future is a
configuration that can be obtained
directly from a persistent database
Arachne could connect to the database
instance you tell it to go to find the
configuration specification you want and
then it does it's magic pulling down all
the required components and assembling
them together dynamically right then in
there how much easier it will be to mix
and match components in a completely
declarative and maybe even drag-and-drop
way you know and we're not just talking
about web applications
or any kind of application you can
conceive he's working right now on
something he calls chimera which is a
data abstraction layer for Arachne that
will unfetter your domain from tight
coupling to any one kind of storage and
you think about it that's sort of the
next step of what the Atomics doing it's
it's decoupling the peers who want to
query data from the concrete storage
well if that's good enough for peers
that need to execute queries why isn't
that good enough for your domain and
that's sort of where he's going with it
and it's kind of cool it means that I
have the convenience to choose whatever
back-end makes sense for that domain and
in this context we're talking about more
transactional systems maybe not
necessarily a de Tomic that instance
which which of course chimera also
supports so anyway just something things
to think about that's that's probably
one of the more interesting for me
anyway directions that this whole schema
has data as code is going okay how much
time we got here okay ten minutes all
right so now we got this far a few quick
words about problems that we apex we at
Apex are tackling with closure des Tomic
and Arachne a recent experience on a big
contract with the VA to implement a full
stack data Federation platform and in
particular to federate data across its
hundred and fifty plus instances of
vista that's its EHR electronic health
record has really helped us to refine a
vision for a new full stack platform
which we call apex unify Keita apex
unifies a new information management
capability that we're building on top of
des Tomic for long-term storage we're
using Iraq knees design principles and
in some cases early versions of the code
and this this new information management
capability we call apex forever DB for
use in highly regulated industries like
healthcare and finance for every DBS
addressing a really hard problem that
isn't going to get any easier as the
industry finally begins to work toward
the elusive goal of real data
interoperability I don't have enough
time to get into the details but suffice
to say that we're taking a very
pragmatic approach to a problem the
industry really hasn't grappled with yet
the problems what I call pilots dilemma
in a word what is truth specifically
what is truth in a world of conflicting
authorities of truth
and the reality with which people
haven't really quite grappled yet is
that in the quest for data
interoperability between disparate
electronic health records what we
consider a source of truth in the form
of any one EHR instance is in fact just
the source of belief about truth it's
like the old song you know two men say
they're Jesus one of them must be wrong
well they both can be wrong and with the
EHRs it's tragically all too often the
case local VA informatics is right here
in Portland one of our one of our best
sponsors on this project did a study to
discover what percentage of the time a
veteran walked in the door and the Med
list was incorrect shockingly it was 100
percent of the time that's pretty
staggering when you think about it and
they actually computed based on you know
the sheer number of encounters that
there are that that's 3,500 veterans
that have adverse reactions ranging from
you know a morbidity to mortality and we
need to run the numbers that's amazing
it's like horrible for many years the
industry has been obsessed with semantic
interoperability because they recognize
EHRs could be built on different
concepts they may be dealing with some
of the same kinds of data but they have
different concepts a real good example
there is uh our PMS and Vista which are
both written in mumps on a DBMS called
file man but they're very different our
PMS is based on the visit that's the
core semantic abstraction and the VA is
vistas based on departments which in the
VA are legion you know so they it's all
broken down by departments now even
within Vista I would contend there's
some some difference but it's a little
bit more negligible now the problem
nobody's really looking at even in the
case even in the case where as with the
VA there aren't many semantic
differences of a show-stopping
significance there's a the problem is
data reconciliation and this as much
about identity and access management as
it is about workflow or discrepancy
resolution it's a big bowl of problems
when you've got to say this VA instance
thinks that and this one thinks this
I'm a doctor right here with the patient
what's true well our object should be to
create new tools techniques and user
experiences for workers at the
point-of-care obsessing about systems
quote-unquote talking to each other
which is the kind of a common way they
talk about it I think is distracting
nonsense what matters is is getting what
is known in the hands of the provider in
the most relevant way for each and every
encounter so we need to empower not
enslave providers at the point of
service with a radically different user
experience one that allows them to solve
these hard problems and makes all the
backend data complexity just something
they don't have to think about it all
right
so to summarize it's just data is a
joyous fact about schema in day Tomic
and when you grok it you will love it
the Atomics information model gives the
real world of voice in our system
designs if we're careful to listen to it
rather than simply projecting our
illusions on it sequel entities are the
data what objects are to state a hot
mess
avoid them if you can think in terms of
identities with state that we can track
over time instead your application
developers will love you and so will
your customers schema is data means that
schema can also be code we may be on the
verge of a new era of generative
programming and Arachne might be part of
that check it out
finally truth is hard to know let's not
make it harder and if these are problems
you'd like to help us solve please visit
our table or catch me later
we're hiring</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>