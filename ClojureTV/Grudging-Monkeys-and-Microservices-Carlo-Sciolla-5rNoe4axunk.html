<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Grudging Monkeys and Microservices - Carlo Sciolla | Coder Coacher - Coaching Coders</title><meta content="Grudging Monkeys and Microservices - Carlo Sciolla - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Grudging Monkeys and Microservices - Carlo Sciolla</b></h2><h5 class="post__date">2015-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5rNoe4axunk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay here we go morning your closure are
you doing good so welcome to the second
talk of the second day which means after
the party and after Michael Marchak
which is a guarantee for me that your
cognitive budget is almost over for
today but I will try to be nice to your
brains and what I'm going to have with
you is hopefully a nice conversation
about microservices not so full of
technical details but what I try to do
is to explore the space of micro
services as a way to to produce our
software a few words about me I come
from a beautiful island that I know not
so many people know how to put on a map
so i did that for you a long time ago
almost seven years i went up north to
the netherlands where I currently work
as a as a CTO for a consultancy company
named SCI tech this year we started to
offer a closure courses and son every
now and then we are hosting the UMSL
inclusions meetup which is the community
that I am running since more or less
2010 so if you happen to be in the
Netherlands just have a look at meetup
com we are going to be there for you to
offer you a nice evening to talk about
closure stuff so microservices when I
first approached with microservices was
around one year ago not so long ago I
was working for a different company
company back then it was a product
company and our product was a typical
Java monolith so spring hibernate and
the likes and we had lots of problems
handling these applications so we
decided it was time to try innovate try
to do something new and we were looking
at micro services as an approach for us
to make development easier to make
upgrade easier and these sort of things
and lots of the thoughts that are going
to share doing this presentation they
come out of that initial experience so
yeah the the more I started to dive into
the details of micro services from an
architectural perspective it felt like
there was no some huge innovation it was
about distributed applications basically
the the problem scope of nitro services
is almost the same as distributed
applications and this is a recent blog
of Uncle Bob Martin's arguing that micro
services were already there in the 60s
where an IBM team developed 63 past
compiler and he claims they were
following a micro services approach
already while the comparison is
debatable I I do believe there's some
truth in there so that micro services
market might be more hype than they are
a formal specification of an
architectural pattern still there are
things that are good in approaching
microservices so for for you as a
development in you you try to focus on
packaging your features in dedicated
applications and the result of that is
that the code base has become very small
very easy to the reason about they're
very easy to manage when it comes to the
development lifecycle and especially if
you think of big enterprises big
development teams one of the side
benefits have seen is that a one team
can own an application top to bottom so
completely owning all the technical
decisions and all the steps of the life
cycle of the software which is very good
it allows you to take actually bigger
decisions and yes a polyglot a Trojan
horse so since you're splitting your
application in very tiny small pieces
those pieces that technology inside of
those pieces is relevant to the overall
organization so yes you can try out new
stuff that's what I've seen also in
other companies they are trying
microservices to have an easier way into
innovation so giving the team the
possibility to try out new stuff up
so what I did was to create a demo
application is a very tiny little
application that does almost nothing but
it's it's enabling me to discuss some of
the features some of the problematic
that you have to face when you're
approaching microservices and how to how
to solve potential issues or how to go
to how much overhead they might bring
into your normal development lifecycle I
got the idea from one of the best
technical blog in my opinion that there
are the guy in the middle is Thomasin
with it's the name and most likely
misspelling but the the blog is called
the Knobloch be found I am willing to
bet money that most of you guys already
know the blog so what he did was to take
an example from the southeast gene it's
a biology book where Richard Dawkins
describes how monkeys developed
different grooming behavior to counter
the problems given by bugs that can
cause a very nasty ish health issues and
what Thomas did was to try out this
sample to experiment on a reactive
programming and RX Java and what I did
is to take a similar example to try and
explore on on microservices so the idea
is again to develop different behaviors
for different monkeys the first behavior
we have is we call it the sucker so it's
it's a monkey that if it has bugs it
will ask another monkey to be groomed
and if there's another monkey asking him
to be groomed he will always say yes the
second character in the plot is the
cheater which is the bastard of the game
so of course he has if he has bugs he
needs to be groom then we ask another
monkey but it will consistently refuse
to groom anybody else and the cheetah is
countered by the Grutter which is the
hero of the game I guess so he will hold
a grudge if the
either refuses to grooming and that
means that if the cheater we'll ask the
groomer to be groomed the Graduate will
say no hopefully condemning the cheater
to a sting shin a the last bit of the
functional puzzle is the simulator which
is providing an environment where the
monkeys will leave and five hopefully
and it's basically providing a clock
signal to all the monkeys so that the
simulation is is a quantized so it goes
ahead one step at a time and it's also
keeping a track of the health status of
all the monkeys and showing it to you on
a on a UI on our closure script you I Oh
kiddo so then what I let's see the tiny
application I created them there we go
one thing that you can spot immediately
is that I should keep out of visual
designs as much as I can but yeah apart
from that that's pretty much it so what
you're looking right now at is the
simulator application again is a closure
script application and the the clock
signals are actually sent from the
browser so the user interaction is
triggering some actions on the backend
and I can control the clock with some
controls over here I can advance one
tick at a time and or I can continuously
play and I can be as can be a little bit
mean and i can add bugs to a monkey so
let's add the back to the monkey we know
that that monkey has the box and you see
that the the status becomes back to
green because somebody groomed the
monkey what I would like to see if we
are lucky enough no I want to kill a
monkey come on there you go I can stop
here another feature of the micro
monkeys is that ok so what happened here
is that the sucker got the bugs and Sin
City is going to randomly choose another
monkey to be groomed it consistently
chose the cheater unfortunately and the
cheater always said no and the sucker
that so said and you also see when the
monkey is that the application is still
up and running but it will refuse to to
synchronize the clock you know
simulating in my my experiments
simulating a partition in in the
application and we will see how what
that means for your application that's
pretty much the demo of it oh and what
the last maybe to be nice to the to the
sucker we can actually result ate it and
also interesting to see is that it will
resynchronize the clock okay so much for
the demo so if you zoom into the
application i created this is how it
looks like so we have those boxes at the
top where they are the functional bits
we have the three monkeys we have the
simulator we have one extra box which is
console we are going to see what role it
plays in the architecture at the bottom
of the of the application you have other
two things you have go to do continuous
integration continuous delivery and
terraform to automate the infrastructure
we are going to discuss about that later
okay first think about microservices
they're supposed to be micro but how
micro is micro and again there's no
general guideline the idea being that
your small application should be as
small as one feature no more than one
feature and possibly the transactional
boundary so if you have something that
has to have strict transactions AC
transactions they should be within the
boundary of one micro service
application in my implementation what I
did to encapsulate a single micro
service was to use docker doctor is
pretty popular it comes to micro
services it's not a requirement but it
looks like everybody that does
microservices really wants to use docker
the way I use docker is to to basically
build a ver jar with Lanigan and create
a docker container around it so that
when it is time to deploy the
application can be started with
just Java minus jar and I'm providing
the configuration options as a command
line arguments which is a practice
encouraged by the 12 factor app manifest
to the i call it immutable deployment
units because docker containers when you
are shipping dr. continues its not only
your app is also part of the operating
system and part of the operating system
is also the file system and when it
comes to docker they are using
copy-on-write strategy for changes in
the file system that means that
basically we will wipe out all of your
changes once you redeploy the same
Locker container and we will see later
on also how that you know it's
beneficial for your infrastructure when
you go for the docker you have to take
into account lots of problems I believe
because again you're not shipping on
your app your shipping part of the
operating system the moment you choose a
base box for dockery you're you're
basically choosing for a software stack
that you're going to ship along with
your application back when I was working
at that product company we were dealing
with banks so they were asking us okay
what are the security the guarantees of
this software you're going to ship to us
and that was a pretty you know heavy
question for us other issues that you
have is that when you start a docker
container the comment you use to start
the container is going to receive a PID
number one if you know how it works on a
unix environment that means that your
process in case especially you are going
to spawn multiple processes your
application ideal their closure
application has more responsibilities
that just you know serving web requests
it has to do clear zombie processes for
instance so there are hidden
complexities inherent to the choice of
docker only know it makes for a very
convenient packaging you can package
another in the docker container anything
so it's not a closure related to Java
related you can have quasi coexisting
technologies in the same deployment and
that's very very nice for for that
polyglot strategy was talking before
internally the applications in my
implementation at least they're using
REST API is to communicate either with
each other and they're using different
strategies to communicate I wanted to
experiment with different strategies
when when you know exploring
microservices and that the monkeys will
use synchronous point-to-point
communication strategy so they need to
receive an endpoint of the other monkey
they need to send an HTTP request and
we'll wait for the response in a
synchronous way whereas the simulator is
using an a synchronous strategy so the
simulator is communicating with many
monkeys at the same time and it's
basically sending requests to each and
every monkey and waiting as
synchronously for all the responses and
updating the state so the UI that we
have seen is updated in a nursing
Chronos fashion yeah i've used bd4 for
the HTTP routing because it's I found it
very convenient in my case because I
wanted to also experiment on how do you
grow how do you extend a base system to
to other systems and since BD is
treating HTTP routing with the data
structures it makes it trivial to
basically extend your HTTP set of
endpoints what we have seen is also
stated management so then the micro
monkeys have a piece of shared state and
that's the clock obviously we also have
seen that if the monkey dies it
simulates a partition in my case that
means that it will refuse to synchronize
the shared state and that means you need
to handle the situation especially for
the clock the clock is is trivial to
synchronize right it's it's a what's
called a convergent replicated data type
so basically I'm sending that the
simulator is sending the clock the new
clock value at every every time at every
tick and that makes it very easy for the
monkey once it comes back to life to
know am i receiving a new value of the
clock an old value what should i do and
it's going to eventually
with the new value and you can introduce
a counter in all of your HTTP requests
to provide the total ordering of your of
your communication when it comes to
state changes in a shared state but your
state might not be as trivial as a clock
so what if you have complex merger
strategies that you have to take into
account the moment you got microservices
you have to realize the cap theorem is
going to to bite you and you have to
prepare for that you need to know what
should state do you have and how you're
going to merge it after one partition is
resolved think of it for instance in my
case if the simulator was not one single
box but I had maybe I don't know a
cluster of five boxes to implement the
simulator and the partition is actually
happening between the simulator
application how would they reconcile the
number of the clock and you can use
techniques such as gossiping protocols
usually to make the synchronization
happen again but it's not trivial so you
need to take into account the extra
complexity in this case of distributed
application terraform so one of the
thing that I wanted to achieve in with
microservices is 22 yes have all the
benefits but pay as little of the price
as possible and much of the price did
you get with microservices is the
operational overhead that you have you
are not deploying one application
anymore you are deploying 20 to 30 50
different applications and you cannot do
that manually by any mean and also
managing the deployment once you have
everything up and running how do you
know what's running how do you know what
to update and how do you update that you
need tools for that there's no other way
and my tool of choice here has been a
terraform which is a local source
product developed by hachey corp the
same guys is a vagrant and it's actually
pretty cool i believe and it is again
enabling what I call him eternally I
call lots of people call immutable
infrastructure so the way telephone
works is that it you will write your
infrastructure your deployment
infrastructure in a configuration file a
configuration file that you can push to
get not only that
the when telephone runs so you have two
steps internal from you have a plan
phase and then apply phase the plan
phase will check ok let me see your
current environment and let me see my
current understanding of what should be
up and running right now and what do you
want me to actually deploy next and let
me make the plan of my following actions
do i need to replace the docker
container do i need to add two extra
nodes do i need to have a new load
balance or this kind of stuff and
whatever form does is to actually write
this plan into a text file that again
you can push to get you can dis over
time and you can basically keep track of
what you have deployed right now by just
looking at a good history and and that's
I think incredibly cool to do and what I
what I do also is I used the
continuation continuous integration
system to basically automate not only
the building of the new versions of the
doctor containers but were to use that
as a trigger to deploy new stuff you can
use this technique to I don't know
handle development environments where
you are continuously updating the
versions of your locker containers and
last last step is that any time I do
anything with telephone when my
contingent equation system what I do is
to also commit back the changes to the
main git branch where the terraform
state exists and yeah so we come to
continuous integration again most of
these presentation is about automation
and I believe that's very fundamental
for micro services because again you
don't want to pay the price of looking
at big monitoring tools ok go City how
many of you know go CD ok let's say two
percent ok it's actually a very old
continuous integration system it was
developed by by thought works at the
beginning and it's released as open
source heavily okay I think beginning
this year something like that it's I
think quite nice you can achieve the
same result with most of the continuous
integration systems you find on the
market right now what I think it's
it's unique in Ingo is that well maybe
not extremely unique but the what gives
the most value for me is the concept of
pipelines and materials so everything
can can be part of a bigger deployment
pipeline from your changes in a codebase
to the new creation of a docker
container new version of docker
container is created and everything can
be put as a chain of what go calls it is
is a value stream pipeline so everything
can contribute to a bigger pipeline and
this is not something i created is
actually a screenshot from go it's it's
the way it allows you to visualize how
your small pieces of the architecture
contribute to create final and goals in
as i mentioned before the the continuous
integration strategy follows it includes
everything from the building a new
version of the docker container to
applying the new they knew the new
versions to the infrastructure and it
works actually pretty well and I think
in India's it's trivial to extend these
to support multiple target deployment
infrastructure so that let's say that
you have a complex dtap street that can
have multiple approval steps then with
this with this strategy you can
basically you see the last step of the
of the pipeline you have you can have
multiple you know outputs and you can
deploy things to different to different
targets last bit of the puzzle is a
console console is another application
meant to support distributed
applications it's developed by Hoshi
curb the same guys a stand for n vagrant
and others and the way I use it is to
support continuous delivery sorry
service discovery so the way it works is
that them whenever any application in
the system starts up it will contact
console
one of the configuration parameters that
you give to the docker containers at
startup is where to find console so the
console HTTP endpoint is the only fix
that HTTP endpoint that you have in the
deployment and whenever any other
application we start up we'll get in
touch with console and say hey I am
Alive and this is my HTTP endpoint not
only that they will also say oh and by
the way to keep me to know that I am
Alive I want you to check me in this way
and that can be different things that
can be okay this is the HTTP end point
you have to contact to know if I am
alive or not or this is the shell
command that you can use to run the
health check or I'm going to contact you
every so many seconds to tell you that I
am still alive how does service
discovery works well console offers to
AP is to get this information out of it
you can use in a rich HTTP rest
interface where you can get everything
in the contrary of what console knows
about the world or you can use DNS which
is in you know I was dealing with banks
so it was a great selling point for me
to use low level protocols that we know
were easy to pass security scans and
actually the DNS interface is also so
basically you you point to console as
your DNS server and you say okay give me
the IP address for I don't know a grudge
or console and it will give you back an
IP address and yeah that works really
well so again both monkeys and and the
simulator they need to know the HTTP
endpoints that's how they do that they
asked console ok can you give me the
endpoints of all their live monkeys
right now and and console will give it
the information back and those will be
and that the applications will use the
HTTP endpoints to make a direct request
there is
a lot to say about console actually I
only used a fraction of the value that
it can provide I think the best feature
that I didn't explore is the watches so
you can place a watch on console for any
sort of event does a new service
register is a service going down is it
failing is it coming back to life all
these things is you can attach watches
on that and you can automatically
execute something what has europe
provides is you provides you is a
console template is basically a way to
attach configuration file production
from changes in the console state think
of instance okay IE i'm deploying i see
that my application needs a little bit
more power i need to scale up my
application so what I do is to deploy
new extra notes of my application and
when they come to live they will say to
console hey we are alive console will
know will send this event to the
registered watcher which will in turn
create a new configuration file for your
load balancer and you can automatically
scale up and down your application this
way it's it's extremely convenient I've
seen this pattern applied using well
mostly for load balancers actually 4-h a
proxy configuration but it works in all
sorts of different ways so you can you
can send emails if an application
Khandala Goes Down and and things like
that other features of console is for
instance that the key value store well
that's very trivial but it's also very
interesting if you're striving for
immutable infrastructure you don't want
state to be in your application you can
externalise configuration and put that
in console and we have seen how in the
micro monkeys are just contacting
console already and that can be the
endpoint to also fetch the configuration
another thing is that console is ready
for cross status data center so it can
scale very very
at a higher level for even big
organizations and that's also pretty
nice okay out here I am already done
explaining you what I've actually
implemented already in the micro monkey
so these are all the all the aspects
that I wanted to explore first how do i
deploy how do I keep them under control
and what do I deploy with docker and but
of course this it's not the end of the
story there are lots of more things that
you need to take into account when
you're dealing with distributed
applications I've been using for
instance hystrix in another environment
to great success to deal with some of
the problems of heavily distributed
application so i guess lots of you know
already history is developed by netflix
and what it offers you is the
implementation of a circuit breaker
pattern which means that if you have
external dependencies if you are
contacting an external system and of
course in a micro services deployment
you're going to contact pretty much a
lot of external assistance you can place
the secret bread ring breaker in the in
between so that if the failures happen
if the I don't know you have frequent
timeouts when receiving replies from
external services or the service is down
or these kind of things you put hystrix
in between and it will understand
immediately or immediately it will
follow some strategies to say is it
really the case that we we should try to
contact the external services or not and
it will provide you with a fail fast
approach to this sort of problems so for
instance timeouts do not propagate
across Europe lick your entire system
yes you have distributed applications
but if you are you know linearizing your
request you're you're you're making a
sequence of operations you don't want
timeouts to propagate in in your entire
system and hystrix can help you cutting
down this this problems in a fast way
together with also getting information
about this system so hystrix can also
give you a view of what services are
slow what are timing out
and and statistics about when the
circuit is open or closed for all of
those services another thing is about
auto scaling I already mention a little
bit about using console and watches to
perform auto scaling and that can be
done and also using the same tools that
I've been using for the micro monkeys so
using terraform to deploy infrastructure
and possibly console watches to deploy
configuration for your load balancer
there are other ways to to achieve
scaling and i'm looking at measures
which is a scheduler that you can use to
basically say ok Messrs these are my
this is my infrastructure this these are
my physical notes and this is the
resource you can manage and measures
will run a little agent in each and
every node and we'll know how much space
so to say is there to be used either you
can think of it as a resource allocator
something like a colonel for a
distributed application so in if you
were to use measures you would basically
push things like terraform at a lower
level provision the physical notes and
you would use measures to say okay and
now you can spawn three more new docker
containers in this in this physical node
one main thing I didn't touch with my
presentation so far is persistent
storage yes immutable is beautiful yes
stateless is beautiful but you know
you're going to have a state that you
have to persist during the time and it
is a big problem in that it's not a
solvent problem yet I would say so
depending on your on your situation you
would need to choose different
strategies one thing that I've seen a
useful to to my cases at least is Flocka
so it is part of the docker ecosystem
what it does is to allow you to
treat present persistent storage more or
less as the way the way you treat the
containers so you want state to also be
independent of the physical node where
you are running your application and
with docker containers is easy now they
are stateless that you can just kill
them on one node and start them up on
another note easy what about persistent
storage how do you copy all of that data
that's what Flocka does so provide you
with abstractions that you can use to
say okay I have my volume mounted on
this physical machine I want it
eventually to be mounted there and
Flocker will manage that for you the
copying and automatically mounting the
the volume for your container that's
very neat and it solves lots of problems
that's of course also taken into account
only taken into account persistent
storage not in memory store but that's
that's a different discussion last bit I
wanted to discuss is monitoring so okay
you can use a console for that I can
show you how it looks like so with
console you already have a minimal
monitoring application for your for your
system that works pretty well it tells
you you know what checks are succeeding
where checks are failing like like in
this case I know that the garage is not
working anymore and that's and that's
fine but it's not as advanced as you
would like them to be you want to know
everything about your application and I
think then heavily distributed is is
sort of adding complexity on that as
well and for instance logging all of
your applications will log separately of
course and you need a way to juggle that
that complexity how do i you follow the
trail of a mist of an error if the error
is spreading mana for services or yeah
that the process is involving more than
one node what i've been using previously
is the ALK stack elasticsearch log
session cabana to produce monitoring
dashboards so that logstash will collect
logs from all the different nodes put
them in a single location which is an
elastic search server and then you can
use cabana to create a dashboard to
visualize those logs in a night in a
nice way and that works really well for
your logs if you are outputting all the
information you want to know your logs
then it's pretty much enough if that's
not the case you know what about memory
consumption what about you know how much
traffic i have on how much load i have
on my cpu the best tool have been using
so far is New Relic you have
alternatives you have up dynamics for
instance but New Relic is is quite
awesome I could not use it at the
beginning because it's it's a SAS
service so you have to send your data to
the US which you probably are doing
already somehow but yeah again I was
dealing with banks so that was a tough
discussions as you can imagine in four
different clients have been using you
really pretty pretty well and yeah it's
great what it does it's it runs an agent
it you have to run your JDM with an
agent that will send information to to
New Relic and will collect and n
consolidated information in beautiful
dashboards and also curable dashboards
so part of New Relic is the inside
offering which allows you to use a
sequel like language to create your
custom dashboards and based on all the
information that me really ever
collected on top of which you can also
explore the deployment architecture so
you can follow a graph of nodes talking
to each other it's pretty pretty
complete okay I'm approaching the end of
the presentation so the techniques have
been using for for creating the micro
monkeys are heavily inspired by probably
two million sources but these are the
main ones so Cisco cloud provided these
micro services infrastructure
documentation which actually is a
framework along with a pretty extensive
documentation of how to bootstrap our
enterprise-grade microservices
architecture and
including lots of stuff it's incredible
it's including all of everything that I
ever mentioned in this dog so it is
using okay console terraform docker
measures H a proxy everything is
together in a git repository that you
can you know clone and get started with
a big microservices deployment and the
second inspiration is is a vacant it's a
retailer in the Netherlands they
basically followed the approach outlined
by Cisco cloud and they they are
actually up and running and in their
life with with their microservices
system they gave a presentation in one
of the doctor meetups in Amsterdam and
that was actually mind-blowing to me
okay done so any questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>