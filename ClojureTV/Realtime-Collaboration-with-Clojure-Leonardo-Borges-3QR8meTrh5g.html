<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Realtime Collaboration with Clojure - Leonardo Borges | Coder Coacher - Coaching Coders</title><meta content="Realtime Collaboration with Clojure - Leonardo Borges - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Realtime Collaboration with Clojure - Leonardo Borges</b></h2><h5 class="post__date">2015-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3QR8meTrh5g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hola when I started is quanta psyche
oblongata ya know see me pork eaters no
way no some be ended ah well it look I'm
your English hi everyone
that was missing a little high in
Spanish I live in Spain a few years back
and it feels kind of nostalgic to be
back here
but now the rest of the talk will be in
English so don't worry right so thanks
for came to talk about real-time
collaboration with closure about a week
ago I realized that this talk slot was
gonna be right before David's talk and
that kind of freaked me out because one
or two things was gonna happen either
this room was gonna be completely empty
because no one was interested in
anything but David's talk which is
possible and or the very opposite where
everyone is here because they don't want
to risk missing a good support for his
talk I'm both thankful and slightly
freaked out that it was the second case
I've been already thanks for coming just
before we get started I like to
introduce myself my name is Leonardo
Borges I work as a closure engineer at a
plus team I'm also a function a
programming advocate I run to Sydney
closure user group and I had the
pleasure to speak at irri closure in
Poland last year in Krakow that was an
amazing conference met a bunch of cool
people and I back then mentioned that I
was working on a book he was about half
done when I announced it so it feels
kind of really good to be here now and
say that the book is finally ready he
came out in March so I talked to some
people who have actually bought it so if
you have any kind of feedback anything
at all you'd like to tell me about the
book yeah just come find me after
beautiful right so what does this talk
about for several months now we have
been developing technology to enable
applications to provide real-time data
synchronization so what I mean by that
if you think of something like Google
Docs which is a good example you see you
can have multiple users collaborating
concurrently in in a single document so
that's kind of what we've been doing but
it's a slightly more general than that
and this turned out to be a distributed
system problem
and while developing the system we've
learned a few things so this talk is
essentially an experience report a few
things that we tried it didn't work and
what we ended up with Indiana this
problem also has a big focus on
performance and fault tolerance which
comes essentially from the fact that it
is a distributed system so this is about
this is a journey of how it got here and
I'm gonna start with statement that
might sound odd a bit first state Lewis
web servers are teddy bears I don't know
about you but you know if you're into
web development stateless web service
gives me this fuzzy warm feeling that I
know what I'm doing because we've been
doing web development for a long time
like this so the programming patterns
are well understood the scaling patterns
are well understood so business really
where you have the reason this is
possible and easy to reason about is
that where you usually keep state
elsewhere on an external database or a
third-party service or a cache what have
you and disk and gathers very far but at
some point will won't be able to handle
that many users so what do we do throw a
bunch of web servers behind a load
balancer and we're done for a really
long time a lot of high profile web
sites to run this way unfortunately that
is not the case for the system that
we're building it looks a little bit
more like this where each web server
keeps a little piece of State in memory
we sue half a database
could that service for some truth we can
replay our history that way but each
server keeps a piece of state and don't
let the colors fool you even though
there are very boxes that states
different between the servers and if you
take only one thing from the stock what
I'd like it to be is that when you talk
to people from other platforms like
scowl or airline they always have a very
interesting distributed system story and
tooling at the tip of their tongue such
as actors acha what-have-you what's very
interesting about closure is that it
gives you the foundation it's very
powerful foundations to build those
attribute systems yourself and hopefully
this will become one of those stories
that we can point to
so I mentioned I was working on real
time collaboration and what exactly do I
mean by that what we're building is
based on a research called operational
transforms so I'm gonna be referring to
that as Lt and in a nutshell what it
allows us to provide to users or to
appliance of the service is the ability
of doing concurrent undo and conflict
resolution when you have concurrent
users interacting the same document so
if you look it up there's a bunch of
different ot algorithms that you can use
each of which comes with their own set
of trade-offs as mentioned previously
Google Docs is one example but we have
others such as etherpad hackpad Google
Wave which was which failed as a product
but as an OT research playground it was
pretty impressive and you also have wiki
locks and what's interesting about this
is that over the years and specifically
in the past year or so a few companies
have realized the importance of the
technology and how it can be applied
more generally and you can see this is
the case be through acquisitions so
hackpad has been recently acquired by
Dropbox and wicked dogs has been
acquired last year by Atlassian which is
my employer and that's actually the
project I'm working on so for people in
the audience who don't have who have
never worked with ot this is a ot 101
just a very brief example to kind of
understand the type of problem ot solves
so let's say you have a user and a
server they start with the same text
which is says ello Barcelona which is
obviously incorrect it's supposed to be
hello Barcelona I have a single B which
is fine that's what collaboration is all
about let's fix it up so the user issues
a command an insert at position zero of
the character H now I have hello
Barcelona which you have the extra beat
while this is happening another user has
been currently committed a change to the
server that deletes the beat so it's a
delete at position six of that text the
text has diverged
but they are independent streams at the
moment they haven't ever attempted to
reconcile just yet so at some point is
operations will be replicated
and when do you do bad things will
happen so essentially the Texan has
diverged now and we don't really have
what we're expecting what we expect
expected what would rather happen is
that the OTA algorithm is supposed to
transform these operations based on a
set of rules and heuristics which best
approximate the users intention so in
this case enhance the name operation of
transformation so in this case the
algorithm would transform that delete
operation each one's elite seven because
all of the characters of that has been
you shifted and now we get to the to the
state that we expected in the beginning
many of these OTE algorithms they have a
common characteristic which is they
require a member state to work and that
is required for both performance reasons
and correctness that's essentially the
reason for which we ended up with this
or Hatcher and once we realize that this
is what we were building we had to
answer some big questions where do we
send requests you so as the one node I
can serve in theory I can serve any
request so I get this request but I
realized that I don't have the correct
States so now I need to somehow find
where that state is in route that
message to it so how do web knows talk
to each other normally in the stateless
world that I showed before
what you have is the communication
between the load balancer and the web
server maybe a database and back the
same way it came from this is no longer
the case the nodes are now able they
have to be able to sit and talk to each
other which poses some security
challenges as well what happened is when
web know to come up and down so in
distributed systems there are a number
of ways you can try and solve this one
of which being doing some type of data
and user migrations when your node the
other being just fail fast consider that
server completely out of the cluster
reinitialize and and off you go which is
actually the approach we took what
delivery guarantees do we need so when
we send a message is very important for
us to know that you know the disaster
message actually gets processed at all
so we need maybe some strong deliver
guarantees at that point and more
specifically we need at most once
guarantees so once we have that it's
very trivial to implement on top of that
at sorry we had we need at least once
once we have at least once we can easily
implement at most once by just ignoring
duplicate operations the next one what
about the order of messages so that's
important as well and especially in OT
we can definitely as a consumer you can
fix the order yourself because most
likely your messages will have a
sequence some sort of sequence number
that you can reorder yourself but if it
this happens a lot of the time you're
paying a price in terms of latency which
we didn't want to pay so what we ended
up with the solution that answers all
these questions for us evolved from both
using existing software reading about
what's available in other platforms and
then essentially writing a bunch of
custom code so we're gonna have a look
at how that happen so the first piece of
the puzzle was vertex so vertex is a
toolkit for building reactive
applications on the JVM that's how they
describe themselves which really that is
to say that they're an event-driven
non-blocking server very much like no
chess so the idea being that you can
handle a much higher throughput with
fewer actual physical resources in this
case OS threads the other reason we went
with vertex is our preferred transport
mechanism is WebSockets we want these
things to be as snappy as possible and
vertex gives us a JVM implementation of
such yes additionally on the client side
suggest implements first all the fall
backs that we need to make sure that
users even with the greater performance
can still use the system vertex also
comes with clustering built-in which is
very comfortable it's actually extremely
easy to deploy across route version of
vertex which yeah excited at first and
was using the conversion he also have
access to the distributed event bus so
essentially we can publish any message
in the spot
and any node in your cluster can then
receive that message so it sounds like
this fits the bill for most if not all
of our questions but this is actually
when things started going wrong for us
because the vertex event buzz doesn't
actually have very strong delivery
guarantees
once the sent a message that message
might be delivered at some point and
might isn't exactly the word we wanted
to use when building this it implements
some smarts around you know buffering if
a node comes down but if the actual
connections between nodes fail you will
most likely lose messages the other
problem with vertex is that there was a
lingering bug which seems to be fixed I
haven't tried I haven't attempted to try
to validate that there in certain
scenarios the order you would not be
guaranteed so that was also a bit of a
problem for us but it's ok we have other
approaches to look at if anyone in the
audience has experience with say Erlang
or Scala or you know actually in general
you probably think you hey all those
questions I think actors can solve that
for you and you'd be mostly right for a
lot of the problems that we had Xers
allow me to encapsulate stage that's the
whole point they exist you create an
actor you can capsulate some say you
send messages to it and it can operate
on that state that state being in our
case couldn't be a document or an entity
which is how we call it internally
actors also give us location
transparency so I don't actually need to
know where an actor is in the cluster I
sent a message as long as I know the
name of the actor and I know that that
message will be a relative properly and
it gives us at least once and ordering
guarantees which is exactly what we
wanted so a KERS that actors are
actually very strongly open ated about
this so actors are very very very close
match to our problem but you're on the
JVM so what can we use any specifically
we're in closure usually we have two
options we can go with akka or pulsar so
akka is an actor library for
Scala and Java and in pulsar is a closer
API for the quasar library which is an
actual library for Java as well for the
JVM the me problem with akka is that I'm
missing a cave there it is awkward to
use from closure especially if you try
to use the Scala API just the thought of
using the Scala guy from closure gives
me nightmares but we could go with the
Java API but even then it's still we
would be writing a lot of extra base
code and you would be a little bit
cumbersome to use
additionally you used to be the case of
the know if it's still the case that the
Java API and documentation would lag
behind the scala version so that would
leave us with closer posters great it's
it's it's very comfortable to use for
closure eight embraces closure idioms
it's essentially a very list px4 library
which is which is exactly what we wanted
however the clustering in Pulsar uses
the home drone in memory data grid
called galaxy which the authors
themselves consider to be alpha stage
and they have been very secretive about
their success stories in terms of
production use cases of galaxy which
there seems to exist but I they just
can't talk about them publicly so I
decided not to risk the other
requirement it is the requirement that
we're having housing ourselves is that
this is JVM only if you understand this
requirement is need to share a little
bit about architecture we have
essentially two that you probably guess
to have two components we have a
server-side web application written a
closure and then we have a client-side
library the interesting thing is that
the client-side library is actually
written in the closure script so we are
already sharing a lot of the OT
algorithms that we have things such as
Dafina plaintiffs calculating Delta et
cetera this is great because if we have
a bug in one of these things we fix it
once it's fixed everywhere as opposed to
having two languages even where you can
introduce the same bug twice or worse
different bugs in different places so
what we wanted to do is leverage the
same programming model that we'd have on
the server side also on the client side
specifically Google's core ISA we our
whole asynchronous API is based on
quarry sink
and we love programming of course Inc
it's a very comfortable way of building
a synchronous applications so our idea
was what if we could have an end-to-end
solution that allow us to leverage the
same programming model and spend and
lastly is the concept of fairness which
not many frameworks tackle fairness
wasn't immediately obvious I mean so
what it essentially means is that let's
say you have a group of green users
collaborating in a document which is why
it has the brief state over there on the
web server and they're not really
collaborating that much this document is
a document that has existed for a while
so you don't have that many changes now
but then you have a bunch of purple
users now if we have just traitor in
your document and in the beginning of
the life of any document that's where
the most changes happen so they're
differentially contributing there so if
you have a look at the stream of
messages get each our cluster it might
look something like this we have as
expected we have a lot more purple
messages and we need to be careful here
because there is a risk that a single
user or a group of users might hog the
the pipe to that particular node in
which case the other users would
experience a necessary delays so what
we're trying to do with fairness here is
optimizing for the average case we want
the average case to be as optimal as
possible so neither actors nor our
vertex actually fits the bill in all the
criteria we've set out for ourselves so
if you have a look at the summary akka
and pulser would fit most of the bill
akka actually gives you ordering there
is a obscure property that's not really
that document I think it's called
receive throughput in which you can we
can implement some fairness as well so
that the reason a lot of documentation
there and I haven't found anything post
the does that so the check there is on
fairness for akka not really for posture
on ordering for vertex I left to check
in and across because I haven't been
able to test about so I didn't want to
give the wrong information
so essentially what fits the bill there
is this wishful thinking distributed
query same framework which doesn't exist
or rather didn't and that's essentially
what we try to achieve so we didn't use
any of that what do we end up doing well
we wrote a lot of custom code and there
are two main components there are fairly
large components I guess it's it's
fairer to call them subsystems in a way
and that's what we're gonna be talking
about now as you know one of the big
problems in computer science is naming
things so we don't actually have yet
cool names for new things so I'm gonna
call them for what they are but names
might change if you have suggested by
then let's talk come talk to me please
the first one is what would be calling
the multiplexer and the reason to call
the multiplexer is because its sole
purpose is to multiplex multiple
chorusing channels through one channel
so if you think about it we have some
scarce resources in the browser are we
talking about WebSocket connections and
all the servers we're talking about TCP
connections between nodes themselves so
we want to be able to and that ties back
with fairness we want to be able to
share these resources appropriately for
each client connected to it it provides
a duplex channel through which you can
write and read messages it also
implements back pressure which is very
important in a distributed system and
the way does that is by using something
similar to TCP window we so essentially
the consumer sends your message say hey
I can handle X number of messages the
producer then commits itself to only
sending that number of messages and only
sitting further messages on the next
window message he also provides stroke
strong close semantics and this is very
closely related to the fail-fast
approach as soon as any of our
components fail we want to notify the
client as soon as possible we don't want
to wait as longer than what is
absolutely necessary to realize that
there is a failure so but what does it
look like so if you have this
multiplexer this gray box in the middle
screen and then you have an endpoint
connect to it it opens up the duplex
channel for that endpoint here an
endpoint is either a user in the browser
or a node in the cluster so you see
they're starting to reason about these
things as though they're the same and
the most blacks are going to take
the initial message and says thank you
I'm gonna wrap this message for a big
note and opens a duplex channel to that
note where the state lives if another
endpoint connects the same thing happens
again now what's interesting about this
is that the most flexor isn't this
special node that sits in a cluster only
handling this it actually lives in a
normal web server like any other so that
is to say that every single web server
we have has at least one most flexor and
that depends on how many in those we
actually have not clustered as well so
if you look at from a higher level we
have the user sending messages to our
cluster bounces through the load
balancer goes through the first web
server can't handle the message yet gets
routed to where the green state actually
is and then everything is happy which is
really cool because it's very powerful
to be able to reason about the system as
though you have a direct live wire to
any node in a server all the way from a
quarry sync channel on the client side
to any node which also allows us to
implement the strong phone close
semantics that I was talking about so if
that server fails the multiplexer
implements a acknowledge Rich fry
mechanism that will realize that failure
as soon as possible and propagated all
the way back to the client and what
happens at that point is that the client
was simply okay
there's nodes host retry everything all
the message that haven't been
acknowledged just yet so feel fast retry
this this is how we're building a
reliable system and the retry it happens
that node isn't there anymore he goes to
the first node where there was
absolutely no states that stay gets
loaded for the first time so that
essentially ends the bit about the
multiplexer there's quite a lot more to
it but is this component that you know
gives us fairness and back pressure and
allows us to share scarce resources what
we haven't talked about just yet is how
the nodes actually talk to each other
and this is the second component or
subsystem that we also have a
four so we're just gonna call it before
what it is and recalling the aleph
cluster so Aleph is a library for a
client-server Network program written in
bisect element and it gives you UDP TCP
an HTTP abstraction and api's well in
our particular case we chose to use TCP
Elif is built on nari which further
straight because net is asynchronous and
Alice is essentially synchronous as well
remember as I mentioned we're using
vertex which is an event-driven server
so for us this is perfect we don't want
to remain asynchronous for the duration
of all the requests and Alex gives you
this duplex stream abstraction through
which you can do exactly that for group
membership we have been using hazel cast
so we tied the elf cluster together with
hazel cast and this is also what we use
to update our and routing mechanism in
terms of the routing what we use from
the messages is something called a
consistent hashing ring and so we use
hazel cast membership events to update
the hashing ring there are few
references to that at the end of the
talk as well so putting these two
components or subsystems together we
were essentially able to effectively
implement a distributed end-to-end
equation channels essentially we can
think of our users as though their web
nodes and vice versa and it doesn't
really matter what the difference is
from a programmers perspective I mean
all of that is still keeping all of the
requirements that we needed such as
message delivery guarantees and ordering
guarantees we have four tours using this
strong close semantics so we know when
things fail as soon as possible and are
able to act accordingly we have fairness
so we can share scarce resources without
delay
unnecessarily delaying our users and we
have back pressure so things know about
up and expectedly
which is great like I honestly think
this is amazingly cool because now we we
effectively have
this would be the quarry sink and this
is a in my mind a very cool story for
distributed systems enclosure but this
very cold is essentially what we did
what would be next for us if people have
been into ot must also have have seen
see our duties before which our stands
for conflict-free replicated data types
so ot is essentially a precursor to see
our duties or some people say you can
actually think of ot is a special case
of a CR DT the big inside of CRE T's is
that it's mathematically impossible to
have conflicts so there's a whole bunch
of papers written about it and the
research is quite interesting
a good example that's been used in the
wild is reactive so if you've used to be
up before you most likely have used even
though you don't know it these
replicated data types so there's a few
references towards the end as well the
thing that she our disease is that they
come in two flavors so they have
state-based CR duties which came first
and then operation base CR duties the
problem with state-based CR duties is
that your document gets really bloated
because it requires the state to be
replicated essentially on on average
change so for a real-time collaboration
systems is this far from ideal
especially with the crappy connections
we have in Australia but then you have
the operation base your entities and
this is a lot more promising because you
start of replicating the data types you
replicate sorry instead of replicating
the state you replicates the operations
themselves in the operations they have
some restrictions for instance they have
to be commutative but other than that
you can solve conflicts you can
guarantee you will not have conflict by
using that so this is something that
we're moving we will eventually move
towards we're not going to completely
replace so T or T sue hasn't used but we
will perform some optimizations by using
CR duties I was hoping that we would
have a production beliefs of what we've
been building before the conference
actually happened it didn't happen do
you know as software delivery goes
sometimes they slip
we're always
I don't know why that is but we're
really close and what we're releasing
actually so our service itself is mostly
ready what we're releasing is a beater
circuit is a bit of product that uses
that service to provide a real-time data
synchronization and this is essentially
what we're going to be releasing this
will allow us to battle test our
backhand we've done low tests internally
and and we have been using that
internally but it's it's important for
us to try this out in a while and see
actually what people think about it the
next step what I've been talking about
this is the multiplexer and the and the
aleph cluster we strongly believe that
these things can generally help people
build in distributed system of
disclosure so we do want to open-source
these things we're not there yet mostly
because the documentation is virtually
non-existent
and we don't want to release something
that that we require too much effort
from us initially to teach people how to
use we want to have like a good
documentation story and good examples as
well
lastly the reason we've been doing this
is essentially to build real-time data
synchronization as a service so
real-time collaborative editing is all
fine which is your Google Docs approach
and it works great but that's the only
really a special case for for this so if
you can imagine a Google Docs like
application using the service and they
provide a real-time collaborative
editing perfect that's your normal use
case but I imagine you building a react
app with on for instance and that has
nothing to do with a real-time
collaborative editing what we're doing
instead is actually synchronizing the
application States in real-time and
suddenly there's application there's an
even a half a database anymore so these
two examples have actually happened
within Atlassian every three months we
have a hackathon and the past two
hackathons teams within the company have
built systems on top of this technology
so we're really extremely excited about
what this can bring to the table in
terms of different uses because whenever
it's all two people they use case it
comes to mind is Google Docs and that's
really just the tip of the iceberg
this is essentially all the content I
had what we have here there are a few
references of tools of nation in
particular a particularly interest there
is the Jupiter ot algorithm paper linked
there so this is essentially the paper
that started at all and even a Google
Wave was implemented on top of that it's
made some extensions and yeah you you
essentially gonna be found a bunch of
links there there is a link to a paper
about citizens hashing ring so that
essentially is how do we were out how do
you know where content lives in in a
cluster and how do you deal with network
partitions or things like that so that's
a crucial component to what we do in
terms of routing the messages from
within the multiplexer and finally
there's a link to the CR duties in react
there's a really great read because it
doesn't go into a lot of the gory
details so if you want to get a quick
rest of what sure if these are actually
about I highly recommend that link and
that was me I hope this was helpful and
will help people build distributed
systems with closure if you have any
ideas around in experiences there will
be building systems with similar
characteristics come talk to me I'd love
to have chat especially regarding the
components we were thinking about open
sourcing but that's me thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>