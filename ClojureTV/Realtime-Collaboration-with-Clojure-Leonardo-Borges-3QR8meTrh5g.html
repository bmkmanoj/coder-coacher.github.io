<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Realtime Collaboration with Clojure - Leonardo Borges | Coder Coacher - Coaching Coders</title><meta content="Realtime Collaboration with Clojure - Leonardo Borges - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Realtime Collaboration with Clojure - Leonardo Borges</b></h2><h5 class="post__date">2015-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3QR8meTrh5g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hola when I started cuantos ikea berlin
casa ya know simi poquitos no bueno some
viendra but it'll come here english hi
everyone that was just missing a little
high in Spanish I live in Spain a few
years back and it feels kind of
nostalgic to be back here but now the
rest of the talk will be in English so
don't worry right so thanks for hear me
to talk about real time collaboration
with closure about a week ago I realized
that this talks lot was going to be
right before David's talk and that kind
of freaked me out because one or two
things was going to happen either this
room was going to be completely empty
because no one was interested in
anything but David stop which is
possible or the very opposite where
everyone is here because they don't want
to risk missing a good support for his
talk I'm both thankful and slightly
freaked out that it was the second case
when already thanks for coming just
before we get started I like to
introduce myself my name is Leonardo
borgeous I work as a closure engineer at
opossum I'm also functional programming
advocate I run the Sydney closure user
group and I had the pleasure to speak at
ero closure in Poland last year in
Krakow that was an amazing conference
met a bunch of cool people and I back
then mentioned that I was working on a
book he was about half done when i
announced it so it feels kind of really
good to be here now and say that the
books finally ready he came out in March
so I talked to some people who have
actually bought it so if you have any
kind of feedback anything at all you'd
like to tell me about the book yeah just
come find me after beautiful right so
what does this talk about for several
months now we have been developing
technology to enable applications to
provide real-time data synchronization
so what I mean by that if you think of
something like Google Docs which is a
good example you see you can have
multiple users collaborating
concurrently in a single button so
that's kind of what we've been doing but
it's a slightly more general than that
and this turned out to be a distributed
system problem
and while developing the system we've
learned a few things so this talk is
essentially an experience report a few
things that we tried it into work and
what we ended up with Indiana this
problem also has a big focus on
performance and fault tolerance which
comes essentially from the fact that it
is a distributed system so this is about
this is a journey of how it got here and
I'm going to start with statement that
might sound odd a bit first stateless
web servers are teddy bears I don't know
about you but you know if you're into
web development stateless web service
give me this fuzzy warm feeling that I
know what I'm doing because we've been
doing web development for a long time
like this so the programming patterns
are well understood the scaling patterns
are well understood so visiting sure
where you have the reason this is
possible and easy to reason about is
that we usually keep state elsewhere on
an external database or a third party
service or cash what have you and this
can gather is very far but at some point
we won't be able to handle that many
users so what do we do throw a bunch of
web servers behind a load balancer and
we're done for a really long time a lot
of high-profile websites to run this way
unfortunately that is not the case for
the system that we're building it looks
a little bit more like this where each
web server keeps a little piece of state
in memory we see you have a database
that Sarah source of truth we can replay
our history that way but each server
keeps a piece of state and don't let the
colors fool you even though there are
very boxes that states different between
the servers and if you take only one
thing from the stock what would like it
to be is that when you talk to people
from other platforms like Scala airline
they always have a very interesting
distributed system story and tooling at
the tip of your tongue such as actors
acha what have you what's very
interesting about closure is that it
gives you the foundation is very
powerful foundations to build those
attributed systems yourself and
hopefully these will become one of those
stories that we can point to
so I mentioned I was working on
real-time collaboration and what exactly
do I mean by that what we're building is
based on research called operational
transforms so I'm going to be referring
to that as LT and in a nutshell what it
allows us to provide users or to
appliance of the service is the ability
of doing concurrent undo and conflict
resolution when you have concurrent
users interacting the same document so
if you look it up there's a bunch of
different OT algorithms that you can use
each of which comes with their own set
of trade-offs as mentioned previously
Google Docs is one example but we have
others such as etherpad hack pad google
wave which was which failed as a product
but as a no te research playground it
was pretty impressive and you also have
we keyed locks and what's interesting
about this is that over the years and is
specifically in the past year or so few
companies have realized the importance
of the psychology and how it can be
applied more generally and you can see
this is the case be through acquisitions
so hack pad has been recently acquired
by Dropbox and wicked dogs has been
acquired last year by atlassian which is
my employer and that's actually the
project I'm working on so for people in
the audience who don't have who have
never worked with OT this is a ot 101
just a very brief example to kind of
understand the type of problem OT solves
so let's say you have a user and a
server they start with the same text
which is says ello Barcelona which is
obviously incorrect it's supposed to be
hello barcelona i have a single b which
is fine that's where collaboration is
all about let's fix it up so the user
issues a command and insert at position
0 of the character h now i have hello
Barcelona which you have the extra beat
while this is happening another user has
been currently committed a change to the
server that deletes the beat so it's a
delete position 6 of that text the text
has diverged but they are independent
streams at the moment they have any
attempted to reconcile just yet so at
some point is operations will be
replicated and when
bad things would happen so essentially
the Texan has diverged now and we don't
really have what we're expecting what we
expect expected what would rather to
happen is that the OT algorithm is
supposed to transform these operations
based on a set of rules and heuristics
which best approximate the users
intention so in this case enhance the
name operational transformation so in
this case the algorithm would transform
that the lead operation each of the lead
seven because all of the characters of
stat has been you shifted and now we get
to the to the state that we expected in
the beginning many of these OTE
algorithms they have a common
characteristic which is they require a
member state to work and that is
required for both performance reasons
and correctness that's essentially the
reason for which we ended up with these
are Hatcher and once we realize that
this is what we were building we had to
answer some big questions where do we
send requests you so as a one node I can
serve inferior can serve any requests so
I get this request but i realize that i
don't have the correct state so now i
need to somehow find where that state is
in route that message to it so how do
web knows talk to each other normally in
this stateless world that i showed
before what you have is the
communication between the load balancer
and the web server maybe a database and
back the same way it came from this is
no longer case the nodes are now able
they have to be able to see and talk to
each other which poses some security
challenges as well what happens when web
know to come up and down so in
distributed system is there are number
of ways you can try and solve this one
of which being doing some type of data
and user migrations when your node the
other being just fail fast consider that
server completely out of the cluster
reinitialize and off you go which is
actually the approach we took what
delivery guarantees do we need so when
we send a message is very important for
us to know that you know the disaster
message actually gets processed at all
so we need me some strong
the guarantees at that point and more
specifically we need at most once
guarantees so once we have that it's
very trivial to implement on top of that
at sorry we had we need at least once
once we have at least once we can easily
implement at most once by just ignore
interpretations the next one what about
the order of messages so that's
important as well and especially in OT
we can definitely as a consumer you can
fix the order yourself because most
likely your messages will have a
sequence some sort of sequence number
that you can then reorder yourself but
if this happens a lot of the time you're
paying a price in terms of latency which
we didn't want to pay so what we ended
up with the solution that answers all
these questions for us evolved from both
using existing software reading about
what's available in other platforms and
then essentially writing a bunch of
custom code so we're going to have a
look at how that happen so the first
piece of the puzzle was vertex so vertex
is a toolkit for building reactive
applications on the JVM that's how they
describe themselves which really that is
to say that they're an event-driven
non-blocking server very much like know
Jess so the idea being that you can
handle a much higher throughput with
fewer actual physical resources in this
case OS threads the other reason we went
to vertex is our preferred transport
mechanism is web sockets we want these
things to be as snappy as possible and
vertex gives us a JVM implementation of
such as additionally on the client side
suggests implements for us all the fall
backs that we need to make sure that
users even with the greater performance
can still use the system vertex also
comes with clustering built in which is
very comfortable it's actually extremely
easy to deploy a crossword version of
vertex which yay excited is it first and
once using the quotient version you also
have access to the distributed event bus
so essentially you can publish any
message in this bus and any node in your
sir can then receive that message so it
sounds like this fits the bill for most
if not all of our questions but this is
actually when things started going wrong
for us because the vertex event buzz
doesn't actually have very strong
delivery guarantees what's the send a
message that message might be delivered
at some point and might isn't exactly
the word we wanted to use when building
this it implements some smarts around
you know buffering if a note comes down
but if the actual connections between
notes fail you will most likely lose
messages the other problem with vertex
is that there was a lingering bug which
seems to be fixed I haven't tried I
haven't attempted to try to validate
that there in certain scenarios the
ordinary would not be guaranteed so that
was also a bit of a problem for us but
it's okay we have other approaches to
look at if anyone in the audience has
experience with say Erlang or Scala or
you know actors in general you probably
think you hey all of those questions I
think actors can solve that for you and
you'd be mostly right for a lot of the
problems that we had extras allow me to
encapsulate state that's the whole point
they exist you create an actor you can
capsulate some say you send messages to
it and it can operate on that state that
state being in our case going to be a
document or an entity which is how we
call it internally actors also give us
location transparency so I don't
actually need to know where an actor is
in the cluster I sent a message as long
as I know the name of the actor and I
know that that message will be a
relative properly and it gives us at
least once and ordering guarantees which
is exactly what we wanted so ackers at
actors are actually very strongly
opinionated about this so actors are
very very very close match to our
problem but you're on the JVM so what
can we use any specifically we're
enclosure usually we have two options we
can go with akka or pulsar so akka is an
actor library for Scala and Java
and in pulsar is a closer API for the
quasar library which is an actual
library for java as well for the gvm the
me problem with aqua is that I'm missing
a cave there it is awkward to use from
closure especially if you try to use
this color API just the thought of using
the skylight guy from closure gives me
nightmares but we could go with the Java
API but even then it's still we would be
writing a lot of extra base code and you
would be a little bit cumbersome to to
use additionally you used to be the case
of the know if it still the case that
the Java API and documentation would lag
behind its color version so that would
leave us with pulsar poster is great
it's it's very comfortable to use for
closure it embraces closure idioms it's
essentially a very Lisp ex4 library
which which is exactly what we wanted
however the clustering pulsar uses a
home drown in memory data grid called
galaxy which the author's themselves
consider to be alpha stage and they have
been very secretive about their success
stories in terms of production use cases
of galaxies which there seems to exist
but I they just can't talk about them
publicly so we decided not to risk the
other requirement it is a requirement
that we're having housing ourselves is
that this is j VN only if you understand
this requirement isn't just share a
little bit about our architecture we
have essentially to that you've probably
guess to have two components we have a
server-side web application in britain
enclosure and then we have a client-side
library the interesting thing is that
the client-side library is actually
written enclosure script so we are
already sharing a lot of the OT
algorithms that we have things such as
differing applying deaths calculating
deltas etc this is great because if we
have a bug in one of these things we fix
it once it's fixed everywhere as opposed
to having two languages in where you can
introduce the same bug twice or worse
different bugs in different places so
what we wanted to do is leverage the
same programming model that we have on
the server side also on the client side
specifically which corey see we our hope
asynchronous API is based on Corey sink
and we love programming of chorusing
it's a
very comfortable way of building
synchronous applications so our idea was
what if we could have an end-to-end
solution that allow us to leverage the
same programming model and spend and
lastly is the concept of fairness which
not many frameworks tackle fairness
wasn't immediately obvious to me so what
essentially means is that let's say you
have a group of green users
collaborating in a document which is why
it has the grief state of their own web
server and they're not really
collaborating that much this document is
a document has existed for a while so
you don't have that many changes now but
then you have a bunch of purple users
now if we have just traitor in your
document and in the beginning of the
life of any document that's where the
most changes happen so they are
differentially contributing there so if
you have a look at the stream of
messages getting to our cluster it might
look something like this we have as
expected we have a lot more purple
messages and we need to be careful here
because there is a risk that a single
user or a group of users might hog the
the pipe to that particular node in
which case the other users would
experience a necessary delays so what
we're trying to do with fairness here is
optimizing for the average case we want
the average case to be as optimal as
possible so neither actors nor our
vertex actually fit the bill in all the
criteria we've set out for ourselves so
if you have a look at the summary acha
and pulser would fit most of the bill
akka actually gives you ordering there
is a obscure property that's not really
that document i think it's called
receive throughput in which you can we
can implement some fairness as well so
that the reason a lot of documentation
there and I haven't found anything
poster the does that so the check there
is unfairness for acha not really for
pulser on ordering for vertex I left to
check in and across because I haven't
been able to test about so I didn't want
to give the wrong information so
essentially what fits the bill there is
this wishful thinking distributed
quarries in framework which doesn't
exist or rather didn't and that's
essentially what which
I to achieve so we didn't use any of
that why do we end up doing well we
wrote a lot of custom code and there are
two main components there are fairly
large components i guess it's fairer to
call them subsystems in a way and that's
where we're going to be talking about
now as you know one of the big problems
in computer science is naming things so
we don't actually have yet cool names
for new things so i'm going to call them
for what they are but names might change
if you have suggested by there to talk
and talk to me please the first one is
what we've been calling the multiplexer
and the reasons call the multiplexer is
because its sole purpose is to multiplex
most precarious ink channels through one
channel so if you think about it we have
some scarce resources in the browser
we're talking about web socket
connections and all the servers we're
talking about TCP connections between
nodes themselves so we want to be able
to and that ties back with fairness we
want to be able to share these resources
appropriately for each client connected
to it it provides a duplex channel
through which you can write and read
messages it also implements back
pressure which is very important in a
distributed system and the way does that
is by using something similar to TCP
window we so essentially the consumer
sends your message say hey I can handle
X number of messages the producer then
commits itself to only sending that
number of messages and only sending
further messages on the next window
message he also provides stroke strong
closed semantics this is very closely
related to the fail fast approach as
soon as any of our components fail we
want to notify the client as soon as
possible we don't want to wait as longer
than what is absolutely necessary to
realize that there is a failure so but
what does it look like so if you have
this multiplexer this gray box in the
middle screen and then you have an
endpoint connect to it it opens up
duplex channel for that endpoint here an
endpoint is either a user in the browser
or a node in the cluster so you see
they're starting to reason about these
things as though they're the same and
the most blacks are then it takes that
initial mess
says thank you I'm going to wrap this
message to appropriate node and opens a
duplex channel to that node where the
state lives if another endpoint connects
the same thing happens again now what's
interesting about this is that the most
flexor isn't this special note that sits
a nut cluster only handling this it
actually lives in a normal web server
like any other so that is to say that
every single web server we have has at
least one multiplexer and that depends
on how many nodes we actually have not
closer as well so if you look at from a
higher level we have the user sending
messages to our cluster bounces through
the load balancer goes to the first web
server can't handle the message and get
gets routed to wear the green state
actually is and then everything is happy
which is really cool because it's very
powerful to be able to reason about the
system as though you have a direct live
wire to any node in a server all the way
from a quarry sink channel on the client
side to any node which also allows us to
implement the strong clone close
semantics that I was talking about so if
that server fails the multiplexer
implements a acknowledged rich fry
mechanism that will realize that failure
as soon as possible and propagated all
the way back to the client and what
happens at that point is that the client
who's simply okay there's no chosed
retry everything all the message that
haven't been acknowledged just yet so
fail fast retry this this is how we're
building a reliable system and the retry
happens that note isn't there anymore it
goes to the first node where there was
absolutely no states that stay gets
loaded for the first time so that
essentially ends the bit about the
multiplexer there's quite a lot more to
it but is this component that you know
gives us fairness back pressure and
allows us to share scarce resources what
we haven't talked about just yet is how
the nodes actually talk to each other
and this is the second component or
subsystem that we also don't have a cool
name
work so we're just going to call it
before what it is and recalling the
Aleph cluster so Aleph is a library for
a client and server network program
written by Zach Tillman and gives you
UDP TCP an HTTP abstraction api's well
in our particular case we chose to use
TCP Aleph is built on Nettie which
furthers great because net is
asynchronous and alice is essentially
synchronous as well remember as i
mentioned we're using vertex which is an
event-driven server so for us this is
perfect we want to remain asynchronous
for the duration of all the requests and
Alex gives you this duplex stream
abstraction through which you can do
exactly that for group membership we
have been using his o cast so we tied
the elf cluster together with hazel cast
and this is also what we use to update
our route tree mechanism in terms of the
browsing what we use from the messages
is something called a consistent hashing
ring and so we use hazel cast membership
events to update the hashing ring there
are few references to that at the end of
the top as well so putting these two
components or subsistence together we
were essentially able to effectively
implement a distributed end-to-end
equation channels essentially we can
think of our users as though their web
nodes and vice versa it doesn't really
matter what the difference is from a
programmers perspective then all that is
soo keeping all of the requirements that
we needed such as message delivery
guarantees and ordering guarantees we
have full tours using the strong closed
semantics so we know when things fail as
soon as possible and are able to act
accordingly we have fairness so we can
share scarce resources without delay
unnecessarily delaying other users and
we have back pressure so things low ball
up and expectedly which is great like I
honestly think this amazingly cool
because now we we're effectively have
this would be the quarry sink and this
is a in my mind a very cool story for
distributed systems enclosure but this
very cool dis is essentially what we did
what would be next for us if people have
been into OT must also have have seen
see our duties before which are stands
for conflict free replicated data types
so OT is essentially a precursor to see
our duties or some people say you can
actually think of OT is a special case
of a crdt the big inside of CR duties is
that it's mathematically impossible to
have conflicts so there's a whole bunch
of papers written about it and the
research is quite interesting good
example that's been used in the wild is
react so if you've used that before you
most likely have used even though you
don't know it these replicated data
types so there's a few references
towards the end as well the thing that
she our duties is that they come in two
flavors so we have state-based see our
duties which thinking first and then
operation based see our duties the
problem with state-based see our duties
is that your document gets really
bloated because it requires the state to
be replicated essentially on average
change so for a real-time collaboration
system this is far from ideal especially
with the traffic connections we have in
Australia but then you have the
operation base your duties and this is a
lot more promising because instead of
replicating the data types you replicate
sorry instead of replicating the state
you replicate the operations themselves
in the operations they have some
restrictions for instance they have to
be commutative but other than that you
can solve conflicts you can get you not
have conflicts by using that so this is
something that removing we will
eventually move towards we're not going
to completely replace ot ot so has its
used but we will perform some
optimizations by using see our duties I
was hoping that we would have a
production release of what we've been
building before the conference actually
happened I didn't what happen do you
know as software delivery goes sometimes
they'd slip we're always been
then I don't know why that is but we're
really close and what we're releasing
actually so our service itself is mostly
ready what we're releasing is a betta
circle is a bit of product that uses
that service to provide real-time data
synchronization and this is essentially
what we're going to be releasing this
will allow us to battle tasks are
backhand we've done low tests internally
and and we have been using that
internally but it's it's important for
us to try this out in a while and see
actually what people think about it the
next step what I've been talking about
this is the multiplexer and the and the
Aleph cluster We strongly believe that
these things can generally help people
build in distributed system disclosure
so we do want to open source these
things we're not very yet mostly because
the documentation is virtually
non-existent and we don't want to
release something that that we require
too much effort from us initially to
teach people how to use we want to have
like a good documentation story and in
good examples as well lastly the reason
we've been doing this is essentially to
build real-time data synchronization as
a service so real-time collaborative
editing is all fine which is your google
docs approach and it works great but
that's the only really a special case
for for this so if you can imagine a
google docs like application using the
service and they provide real-time
collaborative editing perfect that's
your normal use case but i imagine you
building a react app with on for
instance and that has nothing to do with
the real-time collaborative editing what
we're doing instead is actually
synchronizing the application state in
real time and suddenly this application
doesn't even have a database anymore so
these two examples have actually
happened within atlassian every three
months we have a hackathon in the past
to hackathons teams within the company
have built systems on top of this
technology so we're really extremely
excited about what this can bring to the
table in terms of different uses because
whenever it's all two people the use
case it comes to mind is Google Docs and
that's really just the tip of the
iceberg
this is essentially all the content I
had what we have here there are a few
references of tools of nation in
particular of particular interest there
is the Jupiter OT algorithm paper length
there so this is essentially the paper
just started at all and even a google
wave was implemented on top of that it's
made some extensions and yeah you
essentially going to be found a bunch of
links there there is a link to a paper
about citizens hashing ring so that
essentially is how do your route how do
you know where content lives in in a
cluster and how do you deal with network
partitions or things like that so that's
a crucial component to what we do in
terms of routing the messages from
within the multiplexer and finally
there's a link to the sea our duties in
react that's a really great read because
it doesn't go into a lot of the the gory
details so if you want to get a quick
rest of what series these are actually
about I highly recommend that link and
that was me I hope this was helpful and
will help people build distributed
systems with closure if you have any
ideas around in experiences it will be
building systems with similar
characteristics come talk to me I'd love
to have chat especially regarding the
components we were thinking about open
sourcing but that's me thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>