<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Predicate Dispatch - David Nolen | Coder Coacher - Coaching Coders</title><meta content="Predicate Dispatch - David Nolen - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Predicate Dispatch - David Nolen</b></h2><h5 class="post__date">2013-01-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iCl9rB1tyxo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">one of the interesting characteristics
of working in closure and being in the
closure community is that you'll start a
conversation with somebody who's
learning closure and you know explaining
some idea and by the end of the
conversation they will be expressing a
pain point about something that they
perceive that they're gonna do in
closure that's a pain point that they
never could have even gotten to before
right so you have to stop and say do you
realize that we just shot past all these
problems that you used to have and that
we're now on to you know a more
innovative space and I feel like I sort
of have this on a personal level that
you know I've shot past being impressed
with David to being disappointed in him
and I in in a totally I mean like you
know two days ago I would have said you
know wow if you know 48 hours from now I
would have met the reason schemer guys
out and and David's involvement in the
language is a key element to having had
that happen I'd have been like wow
that's really cool and now I'm just like
David I can't believe I only met two out
of the three guys I'm really
disappointed so if you could if you
could try to up your game in terms of
getting the people in the logic program
we were all excited about closure we'd
all appreciate it
thank you
it's working yes
is it working no closer okay hello hello
hello okay so I'm David Nolan I want to
talk a little bit about predicate
dispatch and if you don't know what that
is
you'll sort of have an idea by the end
of the taco plate I sort of a sub time
for this talk called incredible benefits
of wishful thinking and why so this is
an email the type is probably too small
to read but this was from January 7th
2009 which was like two and a half years
ago or more almost three years ago where
somebody is pointing out that it would
be really cool if multi methods worked
slightly different than they currently
do and rich Hickey respondent says this
seems like a halfway step towards this
this thing called predicate dispatch and
I remember thinking what is that I
haven't I've never heard of this term
before
and so we I'll get into what that is but
I also want to talk in another so the
talk is kind of like I heard about this
thing and now I'm thinking maybe I
shouldn't investigate it but also one
year ago I was here at the closure Cange
and I opened up the reason schemer for
the very first time and I recommend if
you guys haven't heard of it yet I
recommend picking it up and it's you
know and I also read William Byrd's
dissertation on Minnie Cameron which is
this logic programming system and so the
benefits of wishful thinking is like you
know maybe these people will actually
show up a year later you know so I I you
know built a version of their system and
it's really fantastic to have them here
so you know I implemented core logic
some of you may have heard of it and
said what is that logic program that's
kind of weird
it's a faithful implementation of their
system it adds a couple things it's
mostly made more idiomatic to closure
and has lots of performance enhancements
if you're familiar with Prolog it adds
sort of knowledge base facilities so you
can define FAQs and run queries on them
and ID those of you that were lucky
enough to see their presentation
yesterday was pretty amazing I'm looking
forward to adding some constraint logic
programming enhancement to as well so
I'm going to be moving back and forth
between the notion of predicate dispatch
and pattern matching again you don't
have to be familiar with these we'll get
into that so I got into pattern matching
because I was fascinated with wim Byrd's
dissertation he had a specific thing
called alpha camera which is exploring
this sort of topic called nominal logic
logic programming which is a bit too
esoteric for this time but what was
interesting is in his implementation he
had a version of pattern matching which
was sort of I didn't like in you know so
I was like oh maybe I should look into
the theory of pattern matching and maybe
come up with something better um so I
ended up going down the rabbit hole I
came across a there's another sort of Oh
camel a developer named Luke Moran J who
has been involved in the theory of
efficient pattern matching for you know
good 15 years he had this really great
paper that he published in 2008 called
compiling pattern matching to good
decision trees it's it's really amazing
because he sort of has taken the theory
of pattern matching and come up with a
much simpler compilation algorithm and
it takes this notion from this notion of
lazy pattern matching and the paper is
very readable the thing that really sort
of got me excited about it was not
because I you know the first time I
download I just sorted I tend to like
just download papers and just like you
know sort of peruse them and then
something to decide this paper
particularly jumped out at me because
there was this amazing sort of image of
what their algorithm was able to do by
sort of adopting lazy pattern matching
semantics they're able to guarantee that
the decision tree to find the matching
clause will be much shorter so on the
top part you see there's many paths to a
clod and a little bit hard to see but
there's the fourth clause or something
and there's many ways to get there by
applying lazy pattern matching you see
there's only one path and there's only
four tests whereas in the naive decision
tree you'll have up to six tests to get
to the match so I had read that paper
and I was like this seems oddly familiar
to another paper which was recommended
by rich Hickey and here's a bit of text
from there and it says our algorithm
first reduces methods written the
general predicate dispatching model
which generalizes single dispatching
multiple dispatching predicate classes
classifiers in pattern matching
I was like so this is from the Craig
chambers paper on efficient predicate
dispatch and this is sort of like whoa
so I read about pattern matching I read
about a sufficient predicate dispatch
maybe there's some way to bring these
things together so predicate dispatch
Craig chambers if you're not familiar
with him he worked on self at Sun which
is you know a very influential language
you know we use the JVM many of the
compilation techniques that the JVM uses
were innovated by Craig chambers and his
team women Chen I believe was also on
the efficient Kritika descents patch
paper so you read the paper and what's
great is that it does seem to do all
these amazing things what's fascinating
is a lot of the details are actually
hardwired so the way that it deals with
numerix is sort of it's sort of baked
into the system and you know so when you
read the paper you're sort of like well
can we get away from that can we get
away from these sort of baked in details
the the dispatching around classes and
and and fields and classes is really
great but other types can't really
belong into the system in a generic way
and then finally it's sort of like we'll
you know even if you come over something
and it's actually not too hard to
implement predicate dispatch but really
it's hard to do it well good enough that
you know us as closure programmers would
actually sort of employ this technique
in our own software and then there's all
these other challenges so you know I've
started down the pattern-matching route
and and if you're right strange live you
know you find out that rich icky doesn't
like pattern matching you know and then
I was on IRC and Sam Tobin hushed at who
actually worked on the pattern matching
compilation techniques in racket this is
like on multi on IRC saying multi
methods are scary you know so like this
is a bit discouraging but you know but
you know then why bother why do if
there's all these challenges why bother
and you know it it really is the case
that what's amazing about closure is
closure is not Java right so we you know
if you're willing to do a bit of
research the language is is malleable
enough for you to add these features
yourself regardless of what other people
think about these features and you know
a big inspiration for me is the art of
the meta object protocol
this was I think a very big step for the
list community in that you know
object-orientation had come along and
they said well let's think about that
what is interesting about objects what's
interesting about classes inheritance
and they were able to via macros but not
only implement object orientation but
also take in the next step with generic
methods which is sort of a predecessor
to what I'm talking about
so why predicate dispatch what's wrong
with multi methods how many people here
have used multi methods in closure this
is and how many people love multi
methods in closure so it's great it's
like this thing it's like you learn
about them and they're really they seem
really powerful you don't need them very
often but it's one of these things when
you do need them you're really happy
that they're there so the main thing
that's wrong with multi methods is that
you have this it seems cool but you have
this thing called The Dispatch FN you
know it creates the values which you're
going to use to match particular method
the problem with this is that so it
seems like you've got this great system
that's open but here we have a dispatch
method which returns a vector with two
values in it and then all methods can
match that the problem is that you're
sort of you can't really change the
behavior of that dispatch FN in the
future so what seemed like an open
system is actually not opening at all
right whatever use idea you had in your
dispatch FN all future extension is now
closed to your assumptions about what
that dispersed
dispatch FM was returning so the
dispatch FN is hardwired and the
question is can we do better and that's
what predicate dispatch is all about
before I get into that I want to talk a
little bit about Craig chambers did this
really fantastic presentation called
expressiveness simplicity and users and
what's great about this is he's talking
about his 20 years as a computer
scientist as a researcher as an
implementer and he says some really
fascinating things I might like to I
like to steal slides from people that
are smarter than me and so this these
are not my slides these are his flies
this is a great thing he says you know
simple ideas are easier to adopt
everybody knows this people prefer that
it wouldn't somebody present something
that it's easy to grasp and he just
makes this great point sophisticated
ideas need a simple story to be
impactful and I think closure has done
an amazing job in
specifically with persistent data
structures like you you know the theory
behind persistent data structures is
very sophisticated but what's fantastic
is we as close your users are presented
a very sort of simple interface to a
very sort of sophisticated idea so the
ideal is deceptively simple right even
if the implementation is actually quite
beyond most of our ability to comprehend
it as long as the print as long as it
presented as to a way that we can
leverage that sophistication without
thinking too much about it so again to
reiterate that idea you know
sophisticated ideas still need simple
interfaces and this and this is where
predicate dispatch is going in the
second point which is doing things
dynamically instead of statically can be
really liberating right there are
specific challenges that you're not
going to encounter when you do things
statically so is predicate dispatch
simple actually simple and I think that
can be sort of shifted a little bit say
is open dispatch simple or simpler then
close dispatch so here is I'm not
bragging on this code this is from
closure walk which is actually quite
useful but so you see it's a cond
expression and we have you know are we
testing its is the list is an instance
of a map entry is it is it a sequence is
it a collection else do something else
so this is a classic the con form is a
closed thing it's not open to future
extension this seems pretty strange
because you know object-oriented came
became an object orientation Kant came
along and said this is silly or you
really should have a generic method and
we can add types and the types just need
to implement those methods right so I'm
jointed orientation figured that out but
here's maybe perhaps a possible syntax
for a predicate dispatch way of doing
this right so I have a sort of this
wishful thinking of maybe def M existed
right and here we can say inner outer
for the first case and then form when it
is a list right and what's nice about
this is we have all the behavior that we
had before and but people can add new
cases as they come up with new types or
protocols or what have you
the only question here is that you know
it's again can we do this in a way that
it's as efficient as the con form right
so everybody knows the con form is just
going to expand out into into brain
primitive so if we're gonna do this we
would prefer that it not be any more
costly than doing it in the closed way
here's an example from William bird's
thesis this is the unification algorithm
so in logic program you often want to
take two tree like data structures and
attempt to make them equal and you see
the same sort of thing happening here in
The Dispatch you know U is are the two
terms equal M is one of them a variable
is the other one a variable are they
both lists and are the two things equal
in a different way right identical equal
and then a sort of deep sense of
equality and then otherwise do something
else so I ended up changing that in core
logic and you can see right here there's
no longer that dispatch there's no
longer a con statement we simply unify
the terms right so we're just using
polymorphic dispatch so this is allowed
to make the sort of unification
Alexander right so you know in core
logic we do a thing where we're you know
we extend the type and we say if that
type is being unified with a different
type do something and so this is kind of
nice so that people can actually at any
point if you won't have a new data
structure that you want to unify with
core logic you simply have to implement
a few methods and that's great right
it's open extension so you know you know
if we had predicate dispatch but maybe
we could write Italy you may be a little
bit even nicer so we could avoid the
whole protocol thing we don't have to
wouldn't have to define a protocol and
do all this extra work we could simply
start writing code which is what we
prefer to do thing you know unify and if
the first term is a var do something if
the second thing is a farm we don't care
what the first thing is do something if
they're ones of our and then once a map
you know and so on and this is kind of
nice right I don't have to have to stop
I no longer have to stop and think do I
have to create a protocol for this right
I can just think about what's the
logical thing that I'm trying to
describe so so much for predicate
dispatch so I'm going to discover to
describe the a roundabout way that I
think maybe is a good way to implement
this so let's talk about pattern
matching a bit pattern matching is quite
cool I think there's a rich history of
papers going back to the 80s you know
there's just an amazing goldmine of
ideas there about how to do this stuff
efficiently the key enhancements that
that Brett the predicate dispatch really
adds to this is open extension so if
you're used to pattern matching from you
know Oh camel standard ml Haskell you
know the patterns are closed you can't
really change it later so here is I
wrote a library called core match so
we're just sort of starting down the
predicate dispatch Road so here is a
sort of classic match expression so we
you're able to match so three locals XY
and Z somewhere they're defined outside
the scope of this code we're looking at
and we can see the cases right we don't
care the first Clause will match if we
don't care what the first thing is but Y
is false and Z is true in the second
case you know if X is false and why it's
true we don't care what the last thing
is and so on right so this is sort of
top-down matching based on the cases so
what happens in core match so I people
may have seen me present this before but
I'm gonna go and explain it in a little
bit more detail so what we do is we take
this code and we basically extract
what's called a pattern matrix so you
can sort of see we now have what's
called occurrences the variables at the
top and we have each row and we have the
values that we want to match with them
so what Lou Cronje did that's really
clever is that he says well we can we
can take this matrix and we can analyze
it for and see what's the best way to
produce the decision tree and he does
that by saying well once we hit a wild
card wild cards are relative relevant
basically so once we hit something
that's sort of a concrete value or a
constructor like a type or something we
want to see what's the what's the column
with the largest number of of concrete
constructors that we can sort of reach
and we can see here that Y is actually
has the most right the moment you'd a
wild card beneath you stop
so what's fascinating about the
algorithm this algorithm says well based
on our knowledge we know that that Y has
to be tested on the most paths Y has to
be tested on at least two so let's why
don't why don't we just shift that to
the front and we'll test it first and
this is exactly what Cora match does
core match will take your expression
find out which things have to be tested
first and REE
order the test and this is what produces
the compressed trees so it's also kind
of neat about the way a poor match work
is that itself it is extensible anybody
can actually add a new type of pattern
if they want the whole thing is designed
to be extended so what I actually do is
I say if you have a new pattern type
we're gonna pass you all the rows that
match so that means things like this so
we can match sequences so here's an
expression where we were matching
sequences so you know we had the
sequence 1 2 3 4 1 2 and we want to
capture the rest in our wine anymore to
capture the rest in our so what's
fascinating about sequences the
sequences you have to think about how
can you pull apart sequences you really
can only get the head and the tail you
really can't jump randomly into it in
without dealing with linear time so what
do we do we again we analyze the the
matrix and the only thing we're allowed
to do since since sequences don't give
us random access we can basically
extract out the front right and then we
put the rest in in a different variable
so that you see that we went from X to X
head an x TX tail right and so what's
what's great about this algorithm is now
we can actually share tests for X H
right we can use one test to see which
which Clause is going to match and that
will match one two and three and then we
can start testing the next sort of set
of sequences to see if they match so we
can also match maps so here's a case
where we're matching you know if we get
a map with a and the key B is to then do
Clause one if we have to keep B and it's
3 C 4 and so on again we we sort of had
a look at the matrix and we get these
maps so this is what's fascinating is
maps actually allow give us random
access we don't have to deal with
pulling off the head and then getting
getting that getting the rest right so
here we can actually immediately look at
all values in at once and we can
basically look at X you know the key the
X with the value at the key a X the
value at key B a C and D and again it's
we can we
see that we need to test to be first
right because there's the most sort of
valid constructors to look at
so here's we here's where it gets kind
of fun so this is a talk of getting into
the sort of extensibility of a core
match so we can add this constraint
called only and only is really easy to
do all we have to do with only is that
when we test it we simply pass in and
not found right so that those little
lightning symbols or the not found value
so if we if we if we get that we know we
fail right we can we can't meet we don't
want to see we don't we at we want to
see the not found value we don't want to
see anything else in that map so what's
cool about this is that we can use your
wrist extend up in a situation where we
actually testing be affecting the key be
and testing the key see actually end up
the same and this is actually what we
want we can pick heuristics to be which
ones we try first but we want to fail
fast if a does have the wrong key we
know we want to eliminate it from
further testing
so vectors provide similar opportunities
I'm going to this one's a little bit
different because we you have rest
patterns so that makes things a little
bit more complicated so again we put the
everything in the matrix and we say okay
however you analyze this so what do we
do we don't want to consider the rest
and so what happens is wherever there
were the most number of values before
the rest pattern starts we split we
split it right and we can analyze this
we can see that Excel needs to be tested
first it's a left and right half the
ours remember so those ours are
basically wildcards we're not testing
any of them for anything really so Excel
is more important and what do we do we
actually again we sort of break it apart
and bring it back together and now we
can analyze the pattern again and we
were able to test three columns to see
which ones most important and we can see
that this one is the one that needs to
be tested first and again and whenever
we term determines it means to be tested
first we move it to the front so this is
pretty interesting so so we were able to
this is an extensible system anybody can
add new patterns they can
choose to analyze those patterns however
they wish so so the question really here
is how do we go from closed to open so
while this algorithm is fascinating
it doesn't really buy us anything as far
as how do we make it possible to extend
new patterns after the fact so and going
from closed to open is very similar to
going static to dynamic so if you've
actually used core match you know that
what it does is it takes your pattern
and then it statically creates the very
deeply nested set of constants that
represent the matches so it gets really
challenging you know when we talk about
not hire or hardwiring so once we're
moving to dynamic we don't want to
hardwire anything so open extension so
pattern matching is top-down but this is
where it gets tricky if we're going to
have open extension so open extension is
not top-down right if somebody can add a
case later it might be that that case
needs to be for some reason tested
before a good example is even implies to
so somebody could come up with a a
predicate dispatch method that says oh I
want to test if the first argument is
even and then somebody might later
decide that well I want to test too now
the problem with that is if pattern
matching is top-down to will believe
will be below the even test its
unreachable so this is like a real
conundrum and this is the kind of thing
that Craig chambers and women Chen
punted on they were like we're gonna
hardwire the behavior of numbers so the
question is can we avoid that hardwiring
so you know it was proposed I think rich
had mentioned that he had created a
little prologue you know and tried this
earlier early on in closure and it was
cool it's really cool but it was like
you know pretty slow and it was all
happening at runtime so my idea was
maybe we can insert core logic and what
we can do is we can use core logic to
drive the behavior of core match so we
would actually use logic to control the
output that the core match compiler
generates but there again this brings up
real issues about reasoning about what's
gonna happen for example if somebody
adds the to case we don't want to
actually break anybody else's code right
somebody else's code might have
assumptions about the fact that
something won't get tested before them
so you know
solution might be namespace local
changes so this might look something
like this so you would say def pred
even-even so what this does is this this
is actually you're hooking into the
logic engine you're saying I now have a
logical predicate which can be involved
in other implication statements and
you're saying I want that predicate to
map to the even function that's defined
in closure so now when I go deaf and foo
I can go x1 even and that's great well
what's nice about when I add the next
case the logic engine will kick in
saying oh you defined a predicate called
even which points to the function even
before we try to insert this into unto
our matrix does this gets assumed by a
previous definition right the logic
engine says oh it does we move it up we
move it up we're going to test two
before we test even so there's lots of
challenges here so core match you know
being close is really simple it's
actually makes things a lot less
complicated to do this kind of thing
we're just generating the correct static
source you know once you start
supporting dynamism like Craig Chambers
said it's like it's really hard I mean
it does really fascinating challenges
there and you know the big trick here is
how do we have a performant
implementation and whatever it's gonna
be I know it's not going to be simple
one problem is that for example one
could say well why don't you change to a
runtime graph representation now that
kind of stinks because what's awesome
about core matches that it's really fast
I mean it's as fast as any pattern
matcher you use any functional languages
fast as pattern matches in Scala Haskell
oh camel it's really good
but if we change to a runtime graphic
representation then we lose all the
advantages of the you know primitive
branching forms you know so one thing we
could do in closure which which we could
consider as perhaps we could use lazy
compilations so what we would do there
is that you know we would because this
works you would define all your code and
only the first time that the predicate
gets called do we actually compile the
the dispatch tree and that's great and
we can do that in the JVM there's no
problem with that but there's a real
challenges that closure scripting is
really really great and core match
actually works right now today with with
closure script so it's really awesome I
can use core match with my and compile
that to JavaScript
so I don't want to lose that right like
there's something nice about being able
to have predicate dispatch work on on
any host JVM or JavaScript so if we have
if we use lazy compilation that JVM what
are we going to do
with closure script you know so the
really bad a bad solution would be you
know every time somebody extends we
could omit the entire dispatch and
that's that's not great code size will
suffer one thing that I thought about
that might be cool and I'm bringing
these points up because I'm hoping to
start the conversation so afterwards you
can bug me and say I think that's a
terrible idea or I think that's a great
idea or you have a better idea but one
thing we could do is like def types and
protocols you know the way they work is
that if you define your methods in a
group you get exactly the performance of
the hosts if you decide to use extend
type it's really fast but you know
there's no guarantee that's going to be
quite as fast as the host provides so
maybe we could do the same thing
perhaps we group our predicate dispatch
together and we get very optimized code
and open-open extension says well that's
great for expressivity but we don't make
as strong guarantees about the
performance
same thing with future extension perhaps
we again optimize the case well if you
decide to group your future extensions
then again those group to group
extensions will be performant and then
there's bigger deeper questions which
are like you know what about
redefinition so how do we somebody is
developing at the repo and they
redefined a method you know how do we
deal with that another thing is how does
one introspect on this stuff one thing
that's really great about multi methods
is that at any point you can get the
dispatch table and see which things are
gonna work how does that work in this
system is it open question so another
another issue is that you know so
extensions that have forced reordering
maybe that's maybe it's just we can't do
anything about that that's game over
right we may be closed your script again
we can maybe solve that with lazy
compilation on the JVM but maybe with
closure script if you force a reordering
and we just say we can't do anything
about that right you want that so we'll
just remit the entire decision tree a
real big idea which i think is really
was why closure is a good place to try
this stuff out is that closure doesn't
have
inheritance right closure doesn't sort
of bring that complexity into the system
and if you read the reason schemer has a
really I think important idea about you
know your clauses should not overlap and
if that is true then something like
predicate dispatch works really well
where you ran into trouble is where you
know something actually belongs to two
different possibilities and then we need
something like prefers method again
please bug me about other ideas
solutions approaches and wishful think
thinking is fun hopefully next year on
this time it won't be wishful thinking
questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>