<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lightning Talks - Rathore, Bockrath-Vandegrift, Miner, Dipert | Coder Coacher - Coaching Coders</title><meta content="Lightning Talks - Rathore, Bockrath-Vandegrift, Miner, Dipert - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Lightning Talks - Rathore, Bockrath-Vandegrift, Miner, Dipert</b></h2><h5 class="post__date">2014-01-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bmHTFo2Rf2w" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this
I think the story of how
does go from basically a 2 / 2 person
start up to you know helping some of the
largest e-commerce merchants do
interesting things and then being
acquired by staples so really quick my
name is a myth righto i've been using
closure for a while and written the
closure in action book as part of the
founding team of this little startup and
now thanks to the acquisition of eph
staples helping them do ecommerce stuff
and also run the innovation lab so this
story starts in 2008 and you know
ecommerce is a growing industry it's
growing by twenty percent a year of a
three trillion dollar market retail
market it's about two hundred billion
dollars a year in size in the US alone
but Amazon is absolutely killing
everybody in the space and conversion
rates are really really low and that
basically means you know if you're a
merchant 1% of the traffic that comes to
your store ends up buying something and
most people most merchants spend money
to get traffic they buy ads they buy you
know they spend on marketing campaigns
and ninety-nine percent of these dollars
are wasted ninety-nine percent of people
that come to us I don't buy anything and
retail 101 teaches many merchants how to
solve this problem you know lots of them
give away some form of price break in
order to help people buy more and of
course they leave money on the table
thanks to this because this is a very
old school way of doing things it's a
one size fits all you would lower prices
everyone gets the same load price you
know it's kind of what they had to do
for many many years but in the age of
big data today and personalization of
everything you know you can figure out
the individuals price sensitivity in
real time you can figure out where and
the buying cycle they are you can figure
out what their exact purchase intent is
so there is really no reason to do this
terribly you know non-discriminatory
approach to discounting and so this is
where runa comes in and you know what we
used to do was to use this big data
apply some machine learning algorithms
to it
you know predictive models that would
then in real time figure out what to
what to do with individual shoppers when
they're on the site provide this as an
API essentially and that's what would
lead to profit essentially so this is
sort of early two thousand innate we've
got a rails shop and in all set up in
the mid that doesn't any timeframe
started here but closure and you know
there's lots of things to like obviously
there was a lisp as functional is in the
JVM what's not to like but of course
they were at that time a lot of unknowns
is no one was using it in production you
know who was this rich guy things like
that and then of course Stu's book came
out and that made it production ready so
so thank you for that and we were in
production with closure later that here
I think we were probably over the first
few companies to do it and I remember
still that you know we star build used
to actually check out closure in a
distortion at this particular button or
tag or whatever they call it for a long
time and then in 2009 2008 continue to
do this a lot of success with it a small
team we build many more services on top
of you know using that ninety-five
percent of our code base was and still
is closure with some are in Python
thrown in for the machine learning bits
so at this point we're powering 350
small to medium retailers we had about
500 requests per second load thousands
of predictive models being around in
real time and all of this was done with
three engineers in one data scientist
browsing on a couple of servers so again
a huge testament in my mind to closure
pretty amazing results ten to thirty
percent sales lifts which incidentally
translates to a much higher lift in
profit and if you're interested in how
that works we can chat about that
offline these are all incremental sales
so everything basically forced the
bottom line so you know it was great and
then this story basically continues you
know couple years later we've bunch of
large merchants repowering stuff for
ebay group on overstock target and we
are doing about 10,000 requests
I can over a million predictive models
in real time but six engineers in one
data scientists also running still on
the same two servers again so now mid
2013 start to work with staples turns
out is the second largest e-commerce
play in the world after amazon and that
was an interesting opportunity we were
doing some good work for them and then
later that year this year last month we
got acquired and stable Innovation Lab
was born and I mean I really have to
thank everyone in the community
obviously rich and others too for all of
this awesomeness so it was an end of era
for us as Runa and we've been around in
the community for a while so you know
then you know Alice in Wonderland used
to be a sort of naming everything was
named after stuff in there so but a
start-up in errors all moved over to a
hitchhiker's guide as things should this
is our logo you know sort of named it
zillion and it's kind of a cycle that's
starting again this is early 2000 next
year and you know amazon is still
killing everyone and it's much worse the
bloodbath is just ridiculous I just to
give you some sense i mean walmart as a
company sold four hundred and eighty
billion dollars worth of stuff last year
and the US economy the gdp is portland
trillion this is a huge number an amazon
sold 150 billion dollars but here's the
thing Walmart's doing a two percent
Amazon's growing at thirty percent I
mean this is what they're doing and the
reason they're doing that is because
they're a technology company and they
know how to done Tim and Jeff Beezus is
there's a comes from a hedge fund
background is you know thinking long
term there is no way to compete with
these guys so that's where we fit in the
idea is to continue what we've kind of
tried to do at Runa just stay focused on
some very small key things within the
e-commerce landscape and basically build
out the this next generation set of
services and platforms for staples and
help them compete in this amazon world
they're already late quite frankly and
we have to now accelerate much more so
than we would have had to do so that's
kind of where we looking to closure to
help
they're also doing a massive ski product
expansion so they're going to go up
broad not just 35,000 office products
they sort so what are we gonna be doing
so lots of things that Amazon noses and
has been doing really well dynamic
pricing all the recommendations stuff
search whole new search for staples so
that's kind of the thing they've done
this for a long time our job is to you
know take that relevant bits of all the
learnings that they've had and sort of
do it in a really compressed timeline
know for a couple of years basically and
the tools are obvious and the people
that you know we want and that can do
this are also quite obviously go to
build the biggest baddest team of
closure engineers and data scientists
the world has ever seen that's the plan
here about 15 people when we got
acquired what about 25 right now 50
people by AQ 1 i'd say 300 over the next
two or three years this will be the
biggest hope the baddest closure team
and here's what we're up against but
this is amazon stock chart over the last
five years okay almost 10 x this is
staples over the same time period a high
to of 26 to 15 so the only way to go is
up this is an opportunity and i think
with the right people with the right you
know team we can help you know and
participate in the website so we're
again make no mistake you know this is a
brutalist ruthless fly you know enemy
and you know traditional warfare with
has and will continue to fail against
them and so this is again an experiment
this that continues in the power of
small teams and you know 300 is not a
very large number if you think about it
and the wave is structuring that is
multiple teams doing you know small
teams doing interesting work each of
them doing like a service or to
interoperability is and all of that and
that's kind of how we want to scale that
that human factor this is again 300
people smoke pretty small team and up
against this bad ass
full and so at this this we had people I
mean you know it's kind of this is the
300 but again I'm not under any illusion
because you know the Spartans all died
so I mean we may die too right i mean
this is I mean I startups a brutal I've
learnt that and this is like a start-up
but god damn it it's going to be one
hell of a fight so join us add this for
this thing thank you
thanks Matt I'm read also mention again
that staples Innovation Lab is a
platinum sponsor of the conference and
so we thank them for that their
commitment to the closure community so
thank you next up we're going to have a
marshal bockrath van van der grift
talking about parkour which is the
closure Hadoop stuff I'm sorry I don't
write you know that much about it so so
I'm looking forward to hearing more
about that Steve miner are you around
here somewhere yeah okay you'll be up
next
are you all right all right Marshall
okay so I'm here to talk about parkour
which is a library for writing MapReduce
jobs in idiomatic closure so my
motivation is primarily that I think
MapReduce is actually a really great
paradigm for writing certain programs if
you need to do bulk data processing that
is linearly scalable then MapReduce will
get you there I also think MapReduce is
actually an easy and comprehensible way
of thinking about programs a lot of
discussions of MapReduce talk about
functions over individual key value
tuples and gluing those together but
really at least in Hadoop's
implementation of MapReduce you have
functions that are transformations over
collections of tuples now closure has a
lot of really great functions for
transforming collections so what I'd
like to do is write my MapReduce
programs enclosure now if you were here
two hours ago at this point you're
thinking wait a minute doesn't ask a log
already exists okay so there's that but
really soak ask log is great i have used
and will continue to use Casca log but i
would contend casts clog is definitely
not MapReduce Casca log is its own
abstraction which then as we just saw
two hours ago compiles to a number of
different platforms but using a paradigm
which is distinct from MapReduce there
are things that you can do a MapReduce
that are not easily expressed in cask
log and vice versa and I think it's best
to use the best tool for the job so the
primary thing that her core provides is
Hadoop integration so i explicitly want
to contrast this against rappers there's
no like one-to-one here's a method in
Hadoop here's a function in parkour and
it's also not a framework parkour tries
to go out of its way to avoid
introducing new abstractions the idea is
to take the abstractions that are
already in Hadoop and the abstractions
that are in closure and bring them
together so that they work harmoniously
okay so parkour provides some basic
stuff to do things like integrate Hadoop
scio with closures I oh so Hadoop has
its own distributed file system using
park or you can use all the standard
closure io operations directly on things
on the distribute vile system there's
some other low level stuff like Hadoop
has these configuration mutable maps
that we have some nice functions to
access but that's all pretty low level
stuff more interestingly when you're
actually running a job Hadoop uses named
classes in order to implement what in a
you know a functional language like
closure we just have as functions so
parkour contains the necessary plumbing
to lift all that up so you do now just
write functions so this is the park or
version of the map and reduce functions
for the word count application that we
saw basically the same thing that Sam
ritchie showed earlier but so this
version is you know this runs as a
MapReduce job but it's just plain
functions no def special def map or no
def reducer you write functions that
then actually literally call the normal
closure collection operations actual map
cat actual map to perform the work of
that task now in Java Hadoop the classes
or two purposes they hold the you know
what you're executing but they also have
names so that you can find them when you
know your code is suddenly thrown across
the cluster in parkour we make this very
nice one to one mapping so that where
Hadoop wants a class you can provide a
bar and this is very nice for multiple
reasons one it's very I think very
seamless because there's this clear like
named thing class named thing VAR going
on but also it's completely obvious when
you are transitioning from code that is
running locally to code that's running
remotely like you pass a bar because it
needs to be able to find that handle to
run it remotely there's no magic or
confusion going on ok so configuration
steps this is the one thing where
parkour comes close to introducing a new
abstraction so in Hadoop you have
of a lot of these like static methods or
methods on the job class that do things
to modify a job and you just kind of
like glue a bunch of them together in
sequence and that sets up your job
configuration so what we do in parkour
instead is we define a thing called a
configuration step which is pretty much
literally just a function like any
function that takes one argument which
should be a job and then it modifies it
to apply parameters which are captured
through local variables in a closure
what this does is it now it means we
have a uniform abstraction for
describing things that we do to
configure a job and lets us invert the
control pattern so that we're able to
pass bits of configuration around in
order to build jobs as a composition of
things instead of having to have one
place that knows everything about what
goes into a job so then using that this
ability to describe a job is just a
sequence of configuration steps there's
an API which lets you describe in a nice
convenient functional dsl the
composition of the steps to form a
complete job it has helper functions for
setting up all the stuff that you need
for a complete job input mapper
partitioner etc but then it has this
nice big huge escape hatch where it's
like do anything you want to the job
conf so anything literally anything that
is possible in raha dupe you can do in
parkour without invoking any additional
magic ok so when I said that
configuration steps were just functions
earlier I slightly lied they're actually
in my current favorite trick there a
protocol which is extended to I FN so
any function of one argument is a
configuration step but you can actually
have additional kinds of configuration
steps to have slightly different
behavior so where this is exploited in
per core is inputs outputs so a
distributed sink is simply a function
which configures a Hadoop job in order
to output to a particular location using
a particular output format but it also
has with it its tandem of how to read
from that that location to configure a
job to then consume that output that was
just written so when you execute a job
what it returns is this
tandem the DC distributed sequence which
then reads from that same location and
then that is again what you pass here to
the input so if you have multiple jobs
you can actually just chain them
together through composition because the
output of a job is then the thing that
you feed as the input to another job but
by reifying distributed sequences as
their own thing not just having them be
purely these functions of configuration
steps we're also able to give them
additional behavior by allowing them us
to reduce them locally so here what
we're doing is we're actually taking
some collection of data that's on Hadoop
and we're just applying closure reduced
to it and then getting some local result
so you can apply exactly the same
functions locally to do local operations
on that data in your HDFS filesystem
that you do in your MapReduce task when
it runs remotely and I needed to close
that parenthesis you ate that ok and
that was all I wanted to communicate so
thank you very much thanks it'll take a
sec here to switch over but next up is
going to be Steve miner talking about
the way to Eden
I'll mention while we're get set up
tonight that the party is tonight so and
that is the party is here so any time I
think after seven you can show up and
we'll start the trivia some probably
somewhere around seven fifteen or
whenever a quorum arrives and that
should be an hour plus however long it
takes to get to do that and then we'll
be showing sneakers after that and there
will be beverages and a good camaraderie
and conversation so please come in and
have a good time ready to go you can use
the buddy mike if that'll work alright
I'm Steve miner I want to thank the
organizers putting on great conference
and forgiving me a few minutes to talk
here about a little project I've been
working on so you know closure community
often likes to read old paper academic
papers and get their inspiration from
the old work I feel that way about
science fiction so I watch old sci-fi
shows in this case this is an old Star
Trek episode the way to Eden now these
guys to me these guys look like closure
programmers okay they got the hair I
think that's a that's a harmonica guitar
so so they were in this episode they
were the space hippies we're looking for
Eden and you know they wanted to
communicate their values so so the Eden
format was perfect for them that and
then there's a quote yeah there's no
schemas in the Eden format that's a good
thing and Stewart how we talked to
yesterday about that but schemas are
useful and you know we had a really good
talk yesterday also about Chris Matic
schema and I'm very interested in the
schema stew so it's the hippies here are
looking for a way to describe the shape
of their data all right they're trying
to communicate with other people and not
everyone understands what's going on
with them so this is again the crew the
enterprise is kind of confused about
what these hippies are after what what
they're talking about so my projects
called Herbert that comes from an insult
that the space hippies had for Captain
Kirk but Herbert was a minor official
who's notorious for his rigid and
limited patterns of thought and so that
kind of I kind of was inspired to own
the insult there and I was designing a
little schema language for Eden so my
goal was that I wanted to be whiteboard
compatible and I was really starting
from a documentation point of view I
mean I was trying to just document for
myself what I was doing you know what
keys i was using what my data structures
looked like and i just wanted to have a
kind of a simple terse and readable
notation so this is all in my humble
opinion about what what is simple and
easy to read also once i got into this i
thought well we can make something
executable as well and actually test it
and I kind of set up for myself the
constraint that I wanted to do my
expressions about Eden in Eden so that's
just a nice property I know something
feels good when you can express your
system in your own system so i started
with patterns so my schema language is
kind of a pattern matching language the
literals all match themselves like you'd
expect
Bulls stand for something else that's
that some way of testing things and I i
use you know very short term so it
stands for integer and KW for keyword
and so on maps typically I had you know
literal key words and a value type for
the for the corresponding value vector
notation was for any kind of sequence
similar to D structuring and then I
added anything in a list is going to be
some other kind of expression some some
way of combining other patterns and then
the obvious kind of or and or not all
work there and I think this is fairly
readable this you can kind of take a
guess what things are done a match there
we also added quantifiers so this is
like regular expression quantifiers and
and they're typically in a list notation
but as a convenient shortcut allow
symbols with a suffix of one of those
quantifiers and it means the same thing
then this is my my usual example so I'm
taking a map and i'm specifying literal
key words and then types for the values
the be in the middle there has a
question mark at the end that means that
the b is optional so if the B key word
is in the map then it has to be
assembled the value has to be a symbol
but it might not be there at all and
then those are just some data values
that would match that pattern okay and
then for more complicated patterns I
have a grammar and the idea is you can
name kind of sub patterns and use those
names as as patterns in your main
pattern so that's the first one and the
last form on this slide here is Eden
describing itself in Eden so that's that
that's saying what a valid expression
would be for this grammar form so again
that's just a nice feeling that things
are expressible in Herbert that I wanted
to express we have a way of capturing
some of the match in bindings then you
can reuse those symbols to to help with
other constraints and
for tags you know I didn't want to match
exactly on classes because I think
that's a little I don't know too brittle
and eden has this nice idea of extending
the notation using tags so I adopted
tags as my way of kind of doing the
classmate Ike we can do class matching
as well but this idea here is that if if
you say tag and then some symbol we're
going to match anything that would have
printed say with that tag and and you
know closure defines a few tags already
for Eden and like any of these date
types all match to inst and i added a
convention for records so you can kind
of go from the record class name into an
appropriate tag and there's another
another library called tag that's used
for printing if you want to follow that
convention and at the base of it there's
a protocol so you can if you implement
this protocol any of your java classes
or special record classes can can
participate in this and match tags in
the Herbert so the API is pretty simple
there's one convenience function
conforms ? and give it a pattern of
value and it just returns a boolean the
second API call is conform with a
pattern and that returns a function that
will do the match for you and as with
that function a successful match
actually returns a map of the binding so
if you have any any bindings in your
expression you can extract those bits in
the map and then nil if it fails so
that's Herbert it's open source and on
github in on clothes ours now so you can
take a look if you're interested and I
intend to make some changes after seeing
that great talk about prismatic schema I
can already integrate with them I hadn't
heard about that before about a month
ago or so but we can integrate his
predicates but I think they might be a
good basis for doing my syntax on top of
their stuff and you know I kind of
leverage a lot of what they've done and
I want to thank Eric normand I uses
square peg parser library to
implement some of my tests and a few
other things there and finally thank you
to star trek for giving that episode and
aspiring the name that's it thank you
thanks Steve I think it's Alan or could
be up next I think it's really
interesting how many talks we've had at
the conference about schema schemas
describing data i should say we put that
way as someone who helped out with the
talk selection and scheduling it was not
obvious to me that that was a theme of
the conference so it's surprising how
often there is a theme that is emergent
alan is going to be talking about
something called gherkin I assume
everybody knows Allen diapered if not
this is Alan diapered
everybody sort of gurgaon as well it's
like little pickle
33
everybody see okay that's no right
nobody can hear okay how we doing yes
sure okay hello alright cool so thanks
everybody for coming and seeing my
little thing about you don't know what
yet so we have this continual problem
pretty much anybody who uses a computer
has this issue where we're on unix and
unix-like user myself i'm also kind of a
part-time linux administrator and at
least as grumpy so we have this issue
unix itself you know gives us powerful
primitives to work with that we leverage
usually through the JVM or c libraries
and it also gives us this less powerful
and incredibly annoying abstraction
called the shell which is a kind of
disgusting non-language that's glued
together from just garbage so but we use
it all the time it's everywhere you know
even our beautiful closure and haskell
programs are ultimately hypervisor l
script somewhere so so what's in shell
well it has good stuff i mean obviously
the syntax of shell is is optimized for
for command line interactive usage which
it's unfortunate though that there's
nothing behind the syntax or in front of
it there's no way to extend the syntax
there's no way to access the primitives
the syntax represents so in terms of a
programming language that's really
horrible but we often find ourselves in
positions where we need to write small
programs in bash because we can't count
on some dependency being there that we
need like the JVM or closure so even
enclosure projects you'll often see
startup scripts or set up scripts or
install scripts written and bash and
they're incredibly brittle and
error-prone at least any of the ones
I've written so how do we replace bash
so I brought a lisp called gherkin it's
a lisp 1a interpreter written in bash
for it's on github there and this
presentation software is actually
written in gherkin so we're celebrating
gherkin right now and yeah that's what
it is what's in it so it has string
integers and symbol scalars they're all
tagged types and it could easily support
big no more flow
point at the bottom everything is a
string representation so you know it's
two string is actually probably faster
than jaws just pointing that out so yeah
there you know we could do that kind of
stuff by shelling out to be see
unfortunately sub shelling and bash is
very expensive because it whenever you
sub shell or call a command and bash it
copies the environment over which is a
crap so it has garbage collection mark
sweep a garbage collector pretty vanilla
there it has dynamic binding facilities
similar to the way you create an update
and do things with closure bars as a
lexical binding facility with a fun
special form that does very addicts so
you can you know you can build d
structuring on top of this if you want
and I think we all want that it has you
know an on stack were consuming
recursion situation inside a fun
primitive you can call recur somewhere
in tail position and not consume stack
so you can do a form of TCO that way the
same way you can enclosure with the loop
and it has you know the beginnings of a
namespaces system I think for all you
budding gherkin programmers we're going
to want to have some kind of a you know
way to share a code I was thinking of
like a like a like a function you could
type at the repple to ship off your
whole worlds of gist or something like
hey check out my library and just you
know it sees a lot of free love in the
gherkin world so things that will have
so it's got a it has a def type
construct in there it's weird I when I
learned about def types and protocols
and closure they seemed like an add-on
thing but since then i realized having
used closure script that's there's a
tremendous value and having them at the
bottom and in fact in list was like
emacs lisp which don't have a way to
create a user type it that complexity
works its way all the way to the garbage
collector and you'll a lot of older
lisps have like separate heaps for the
different types and if you have this
user type mechanism then you don't need
to do that kind of stuff so it'll have
macros that doesn't currently but it's
pretty straightforward and they'll even
be first class so you can have like
write a little anonymous macro it's
pretty sweet it'll have a core async
like stuff built on top of the stuff
that she'll gives you like fee foes a
FIFO is really a blocking channel and
you can you can build CSP like stuff on
top of that which will
do and then it'll have save world and
load world the entire state of the
interpreter is in the bosch environment
so trivially you can save your entire
you know Conte Lisp interpreter state
everything loaded into a dot SH file
that you can then make executable so I
have a I have a vision for you know you
like I'm working on my little program
working working working i do save world
that gives me a dot SH file and then i
can send that to am is that are booting
as a user data script i don't know
because it's cool things that you might
consider doing i mean you could write a
closure interpreter for it Spencer
tipping who is this gentleman he's not
here he's a factual guy but he wrote
something similar for bash that has
actually concurrent garbage collector
which I want to seal it would be a fun
thing to do in racket using their
they're laying extension facilities if I
have aliases for closure syntax we could
actually statically try it type check
gradually type all the fancy type stuff
our bash scripts which is obviously
value in that and then I realized the
other day that make is kind of a
delimited form of prologue I mean it
unifies so I figure we can have a like a
high-performance embedded prologue that
uses make there are some things
unfortunately it can and will never have
it's impossible in bash and any shell
that I'm actually zsh has this but in
bash and any POSIX shell you can't have
any kind of associative data and you
don't even have the primitive you need
to do that which is a random access
array so it'll never have a real array
it's only linked list and bash
environment variables you'll never have
any numeric poor performance whatsoever
so it's not good for that and really is
not fast in any way but it will never
ever suck so this is you know obviously
built on a lot of prior art back to John
McCarthy but I think the number one help
was there's a guide arias bacon I think
he has a really interesting github repo
and he revived the implementation of
less Britain for awk it was actually on
the hit list mailing list in 1994 he did
like a pretty cool update of it in 2001
and it was a good reference Spencer
tipping he's like the most imaginative
programmer you've never heard of I
really recommend typing his name into
Google and staying up all night reading
his amazing stuff he's got some cool
stuff Aaron Brooks a co-worker of mine
gave me some early feedback on the
reader and Aaron Griffiths a friend of
Aaron the other errands who I've never
met give me more feedback and then joel
martin the other day you know so telling
my co-workers about this and you know
nobody believed me at first but then
eventually I started helping joel martin
he taught me a little bit about read
line so we have you know read line down
here so you can have history which is
actually better than the closure repple
was for a long time so and then actually
joel martin i was like well you know
wouldn't it be cool if we could write
read web servers and gherkin but the
problem is you can't bind to his socket
and bash so joel martin did something
completely unexpected which is he added
that to bash and sent a patch to them so
you know our platform is getting there
we're going pretty sweet so yeah I can
do a little i'm going to do a little
demo here we're going to switch over to
the repple and i'll switch microphones
okay maybe i won't switch microphones
but i'll just go over a little code oh
wow that's service
okay so there was a repple over here and
that's the the redline repple and you
can type stuff in like do stuff over
here that's cool but you know you can
also run it in an inferior Lisp and
actually just to show off the startup
time here boom gk repple boom lisping
and you know you can evaluate some stuff
so let me make some functions thanks man
wow that's that's true and you know we
have you have functions with lexical
scopes so you can do you know real legit
and functional programming reduce + 0 1
2 3 huh and then you know everything
else you'd expect so you know it has
this and of course jackson and sent an
essential like primitive so yeah that's
the whole thing it's on oh so i guess a
little bit if you want to contribute
good luck to you
so it's about a thousand lines of Bosch
I'm trying to keep it around a thousand
lines i think that's we can keep it
there but you know it's a lot of stuff
just kind of keeps going uh yeah but it
follows the pattern of awk Lisp so you
know how we evaluate a special how we
evaluate a primitive and all that stuff
it is fairly split out I'd say thirty
percent of the code is working around
like just weird bash stuff like you
can't have new line at the end of a
bachelor or you can't have white space
at the end of a bachelor but we'll get
truncated when you store that variable
so there are places where i have to like
maintain sentinels and of course the
star is unreadable because it expands
out to the like the current stuff in the
current directory so that was like a fun
little thing um but yeah it's all out
there you know how fun hopefully the
presentation serves as a little road map
if you're interested in contributing I
mean I definitely don't want to write
this would be the last big bash script I
ever write this probe this thing so you
know if we can if we can get it to a
point where the interop story is good
and it starts up reasonably quickly and
it generally rules then none of us will
hopefully ever have to write bash
scripts again so let's let's do that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>