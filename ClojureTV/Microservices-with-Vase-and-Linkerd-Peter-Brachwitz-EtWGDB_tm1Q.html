<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Microservices with Vase and Linkerd - Peter Brachwitz | Coder Coacher - Coaching Coders</title><meta content="Microservices with Vase and Linkerd - Peter Brachwitz - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Microservices with Vase and Linkerd - Peter Brachwitz</b></h2><h5 class="post__date">2017-08-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EtWGDB_tm1Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right can you hear me all right
great so I'm going to talk about micro
services building micro services with
VARs and linker D but before we get into
that I almost feel like I I need to
apologize for speaking about micro
services given the amount of inflated
expectations connected to this topic and
if you believe this Google glass it's
still going strong but I think many
people have become bit more cautious
about this approach and many people who
have been in the industry for a while
might say well isn't that just
service-oriented architecture in the
second coming and while I understand
where this sort of idea comes from and I
also think that it's sort of a new thing
in its own right to speak of micro
services and that's not only the coast
you know services oriented architectures
associated with maybe some problematic
technology choices that have been sold
in its name and have sort of blurred the
ideas behind it but also because I
believe that the foundations of what we
call micro services there is something
generally new there so there's starting
from sort of the the basic building
blocks in automated infrastructure to
sort of the ideas around sort of what I
could call technical scalability but the
one aspect that interests me most in the
context of this talk is sort of the
social aspect of of the de março
service systems and so whenever we write
code we communicate with machines of
course but I think to the same degree we
also communicate with other people
through that code or in the
establishment of writing that code and
that that's why sort of constraints that
apply to us communicating as humans in
social systems sort of bleed into the
technical systems we build and design
through code now this this insight is
nothing new and actually Logan Conway
has had
a bit of screen time already today so he
he wrote this paper and I think 1968
how do committees invent based of
formulated this idea that that the
organizational structure and the way to
communicate
he called it for lead to direct copies
of these structures in the systems that
are designed by these organizations and
this this idea from this paper has been
popularized under the name Conway's law
ever since then you've probably heard
about it already there is sort of a
trivialized example that's often cited
in this context and I'm going to repeat
it anyway if you have an organization
with four teams and you let them build a
compiler you end up with a full pass
compiler sort of to illustrate some of
the ideas behind it
and I think what this tries to say is
that the output of that design process
is is not necessarily optimal in a
technical sense and I think there's also
some good empirical evidence to support
this this idea of Conway's law and
there's also some good intuition why it
might be true I mean with all the
experience that how much easy it is to
communicate within a close-knit team of
developers and how much harder it is to
sort of go outside your comfort zone and
establish common interfaces api's or
something across a large organization
contracts design ideas things like that
now what I find interesting about
micro-service is that it sort of turns
this law upside down by saying let's
build systems composed of many many
small relatively independent components
that are loosely coupled and that sort
of is very well aligned maybe with an
organizational structure composed of
many many teams that work in relative
autonomy it may be even different speeds
so the design in some way the technical
design of the system in some way might
mirror the organizational structure you
as it doesn't say that that's
necessarily then the best technical
design yes but of that the disease
states with an alignment here and
there's one other sort of aspect that I
find important or interesting and that
sort of a matter of scale so in the same
way as concepts that work in the small
don't necessarily work well in the large
you can't scale an end to human size I
think in similar ways it is probably
true that concepts that work well in the
large don't necessarily translate into
the small so if you have a few just
three people building a system you
probably won't experience many of these
frictions all these these these
problematic situations that might drive
you towards such an architecture from
the social point of view so the question
is to the ways where's the boundary
where does it stand is it is the matter
of the size of the organization probably
not it's more sort of a combination of
maturity of processes and of also
technically of course needs do we
actually need that so what I'm trying to
say here is there's a good chance that
you don't need a microservice
architecture there's a good chance that
you I've totally fine with a well
structured monolith and that could be
the end of this talk and but let's
assume we had to the such a system for
the sake of the argument and just to
give you some background how I came to
this topic I recently switched jobs and
I was previously working for a company
we're joined in the last couple of
months while I was working with them a
team of developers who were building
what I would call a micro service
platform in disguise um basically data
transformation pipelines built up out of
small independent components that were
interacting and they were very ambitious
so they built everything themselves from
scratch including their own programming
language so when I joined them I was a
bit skeptical and I started evaluating
you know options or ways to fight the
not invented here in syndrome a bit
and so I was very curious than early
this year a beta version of of vassals
announced as an open source library
because it seemed to fit exactly that
that spot that we were working on now
I'm not going to go into too much detail
about about last here there are
excellent talks by its creators that I
recommend you watch or even better maybe
you try it out yourself it's very easy
to get started but I want I won't
mention a few points in case you don't
know the library and also sort of set up
the rest of the talk and I want to do
this in two parts I want to take apart
the tagline of Mars which is data driven
micro-services and look at the data
driven aspect first and then later at
the micro service part so what Lars does
in one sentence is allows you to build
very simple services fronted by an HTTP
API backed by the atomic and I'm tempted
to say crud services but I'm not
entirely sure if that's really true and
the idea is that you don't build them in
code primarily but that you define them
in data in an even file that you that
you construct and this is an example of
an empty service definition I've put it
up there because I think it illustrates
quite nicely the foundations of VARs as
a library because it's sort of built it
sits on three pillars if you will
there is pedestal routes to define the
entry point into your service you can
define as you would in in pedestal then
you have closest back to validate and
conform data let's transform through
these API endpoints and finally you have
the atomic schema to describe the shape
of your data in the atomic
and then Vance has this idea of
versioning so that you can have multiple
versions of api's in that same sort of
eden document and you can have multiple
versions of these api's active or you
can deactivate them as you see fit now
you have this Eden document and the next
question is how you turn this
description of your service this data
description of the service into a
running living thing and for that you
have to know that what has this idea of
a container and can roughly said it's
basically everything that pedestal runs
on and you somehow have to get it in
there and this is this error that I've
drawn on that slide and in the first
versions of ours and that's what got me
interested because it directly matched
our use case you were able to
dynamically spin up these services by
just posting your Eden document to a
sort of API of API is a mother of all
api's that would then instantiate your
service in the in the container and has
functionality has been removed I think
it can be reinstated if you needed that
and what you now typically do is you
sort of bake it into your jar file as
part of your build process and shipped
with that so to recap what Mars does I
think it's a good idea to have a look at
the mission statement the design
document of VAS in the github repo sort
of outlines that so the basic idea here
is to remove the incidental complexity
that you experience and you build these
very simple services with HTTP API so as
a fast way of building prototypes of
trying out new ideas so get to deliver
faster I think that's very emphasized
very strongly but at the same time being
flexible enough and open enough to
evolve this disservice into another
direction if it's necessary and in the
last point that's mentioned in that
design document is production quality
and I got a bit hung up on that because
I was wondering what what does that mean
how is that production quality or what
does production quality mean income in
the context of such a library and I
think you can approach this from from
various angles
you can think about the various
deployment options you have advanced so
being based on pedestal you can deploy
it inside a Tomcat the jetty mutant I
don't know what you can approach it from
sort of a security point of view that
you can say well we inherit all the
security features that exist in in
pedestal as well but I want to answer
this question right away I want to sort
of put a pin in that and come back to
the question later once we have looked
at the micro service part of it because
what does turn a library into a micro
service library I think there are many
ways to to think about that you can
stuff come from a domain driven design
perspective and talk about single
responsibilities and bounded contexts
and aggregate routes but if you look at
sort of the deployment sort of
architecture high-level view then you
can also deploy VARs in a very
conventional sense behind maybe some
kind of edge service maybe a reverse
proxy some TLS termination or
what-have-you
of course you have to keep in mind it's
based on it's based on the Atomics we
have to have a production quality atomic
deployment some in the background but
I'm leaving that question out for the
purposes of this talk but in my mind I
think so when we see what sort of to
makes it a micro service thing is that
you break up something that used to be
sort of in process function calls and
turn it into multiple components the
talk over network to each other and with
that we had some in the space of
distributed systems so when we're
talking about micro service libraries I
think we have to approach them as
building blocks for distributed systems
and then maybe that diagram changes a
bit to look maybe look like this so even
if you have a very simple system that
you want to build I think it's not
far-fetched to say there's at least
something in front of of our service
maybe that does event occasion or
authorization and then there's this big
question of whether you can get your
design with the main model down to
clean and isolated sort of a
responsibility point state that you can
avoid talking to other services but is
this really realistic can you really
expect your team's
build this architecture out of many many
components to not call into other
services I think probably not and then
is the next question is of course what
does Val offer here and the answer is
it's not really primarily built for
light so shelling out or integrating
with a third party and this is just a
listing of the Rida literals that are
built into vas so you can respond to a
request by calculating some kind of
response you can redirect to another URL
you can conform data using closure spec
you can query data that sits in the
atomic and you can transact new data
into the atomic and you can again
validate using closure spec and until
the next one intercept is sort of a
wild-card in a way it allows you to do
anything then to that sort of fact or
you can of course get in this
third-party service integration or
calling out to other services maybe not
in this way sort of by testing the
limits of what you can do in easy and
trying to squeeze in some Java interrupt
to shell out to a another service but
you don't have to do that you can simply
write a normal pedestal intercept some
some closure file somewhere in your
project and reference that in your
eating services and description um but
it's sort of one interesting consequence
of that because if you do that if you
sort of enrich what pedestal in this
case last us for you by writing own
interceptors you leave sort of the realm
of a self-contained service and
description you suddenly have now this
problem of dependencies you need to sort
of pull in that code somehow wherever
this service is going to be deployed you
cannot simply send this even file
somewhere and run it or turn it into a
service you have to somehow get that the
closure code there and that's typically
shipping a jar somewhere
unless we come up with a better more
flexible way of breaking down these
artifacts and smaller checks and of
course the other words you can extend
Vance itself we can add original
literals but I think it it's it comes
down to the same problem that you have
to ship some digital code and having
said all that I think we can now return
to that question of production quality
again now that we have sort of built a
lot of these last services or maybe
other services as well and for me then
to new sort of questions come up that
need to be answered and or concerns and
these are observability and resiliency
in a distributed system so with that I
mean as you all know probably
observability you want to see what's
going on in this sort of mesh of
components that interact by aggregating
any diagnostic output they produce in a
central location to see what's going on
by maybe distributed tracing to see as
requests go through this mesh of
services if something goes wrong that it
doesn't turn into sort of a forensic
investigation to find out where it went
wrong and why and maybe also just
regular telemetry data to see what's
happening before things go wrong and on
the other hand sort of in the resiliency
corner we need to deal with with failure
partial failure and easy we'll say if a
request doesn't work to another service
you just retry
how hard can it be and I've seen code
similar to that in productive scenarios
a couple of times and we all know that
it's not that easy right we need to
think about exponential back-off so that
we not make the problem worse
by hammering a service that's already
struggling and not even that is enough
you want to introduce jitter so I'm not
trying to educate you here about how to
do retries I think that the point I'm
trying to make is that these problems
are I would say non-trivial and need to
be addressed in a sort of production
quality manner and if retrying doesn't
help you know we have already had on the
first day of the conference
the mention of circuit breakers to
isolate at least temporarily a component
until it recovers again we need
production quality implementations of
these so what does Mars often that
respect and the answer is nothing and
that's not bad that's not a problem I
think it's completely out of the scope
of the library but when we think about
deploying that into the very productive
environment we need to address these
issues and there are many many ways to
address these issues and this is a bit
arbitrary sort of stream of
consciousness grass that I've made up a
Brandon technology names loader told
what our options so this problem these
problems have been solved in many in
many ways and of course we can now say
on the one hand let's just offload all
that for at least parts of that
responsibility to a to a vendor it's
just deployed at service in a platform
as a service we get done some of the
observability back or we might even use
one of the newer function as a service
things like Amazon lambda and as far as
I know the creators of ours are actually
working working on that sort of making
was a first-class citizen in a sort of a
lambda environment but even if you don't
want to do that they see if you go back
to the more traditional conundrum
between frameworks and services and I
think we can all get very excited about
how bad frameworks are in my mind it's
always there some people have thought
very hard about these problems that
these frameworks trying to address and
they have come up with very good answers
in most cases from their point of view
for all of these problems usually with
one answer to each of these problems and
the problem is that maybe these answers
don't match your use case or your needs
and then these frameworks can't and it
sort of a straightjacket but on the
other sort of implication is that
there's often a sort of they draw your
interest edible language environment as
well especially if you go down the road
of these frameworks as listed here which
might not be ideal so as a closure sort
of programmer you might more tempted to
use a library and there
quality libraries that address the
concerns that listed organizations like
Netflix have been doing this for years
that Stillings like history exit was
already mentioned yesterday the closure
bindings and stuff like that but I want
to remind you of what I said in the
beginning about the social implications
of building these kinds of micro service
environments that we want to have
independent teams have a relatively high
degree of freedom to build their systems
at their own speed maybe and I'll be
reintroducing a shared code base a
library and suddenly we have to maybe
upgrade that library because there is a
security issue and we have suddenly to
introduce with our coordination point
across all these teams that are sort of
theoretically fully independent or
relatively independent it's not
impossible of course it's perfectly
doable but it sort of wraps the whole
idea the wrong way a bit and so what
I've learned recently there is another
way and that's what I'm going to talk to
you about today and it has various names
and sometimes called a service mesh a
service proxy and one of the project in
that space that is linker D which is
what I'm going to talk to you about
today and there is more recently a thing
called
envoi has been released by lift it's
sort of in the same space and there are
similar concerns for this evaluation
event with linker D because it's sort of
integrated more closely with the
environment we were targeting which is
kubernetes but I'm not sort of
advocating one or the other
see this is an example for a class of
solution class product rather than is a
recommendation so linker D the name is a
bit inspired by the linker from your
compiler tool chain but instead of
linking object files and libraries it
links services talking of a network to
each other so it's a transparent proxy
and from a technology point of view it's
based on Twitter finagle so it's Carla
Nettie's in the mix and if that makes
you run for the hills for one reason or
another
don't worry it's out of process so the
deployment scenario here is similar to
that so as I said we were targeting
kubernetes so you would have some
containerized version of your service
somewhere and then link release it's
typically next to that application
wherever you're running it and because
you are that's basically a sidecar
container and because it's a JVM thing
it has some significant memory
requirements so the recommended way to
deploy this in kubernetes is what they
call a demon set we have just one
instance on each node and all the last
services in this example that need to do
Network I'll talk through this one
instance so you minimize the memory
footprint and trade in a bit of
availability here um and the idea is
that you have this across across the
board across all your services and the
link of the components or the router
traffic from these services coming in to
other services and back and also it can
also reduce to some extent ingress and
egress out of the whole cluster and the
information where to route and where to
find the other services comes from
another component called name early and
with a dynamic store for all the routing
information that integrates it's your
service discovery mechanism so what you
get by doing that is you get exactly
these things that listed that's why I
listed them get retries you get a
sensible and production proof and
implementation of slack off because
that's altered to find angle in the
background
you get routing that integrates with
your service discovery mechanism why
these rewriting rules or delegation
tables I think their calls and fine Adel
it's just a rewrite or function from
your host name to look up in the
community service discovery mechanism to
find a service with the same name and
then it routes traffic to one instance
of that so
and if you think that what I said about
sort of bars is a tool to rapidly
prototype to try out new things I think
that's it's quite well with linker D
because it has quite advanced
capabilities when it comes to traffic
shifting so you can do kenra deployments
where you're out like in this example
10% of your traffic to one version of
your service and 90% to another and you
can go even more dynamic but controlling
the traffic via individual headers or
special cookies if you want to expose a
new version on it to a very very limited
population so liquidy addresses the
concerns with regards to resilience we
get service discovery and it's not
because I mentioned kubernetes it's not
sort of limited to kubernetes its
integrates it's fairly neutral when it
comes to where and how to run it and
integrated various backgrounds you can
do nice things like transparent TLS
between your services without having to
integrate it into the service
implementation and you get also benefits
in tracing and telemetry I'll talk about
that in a little bit so on the practical
level how does let's work elitsa
transparent proxy and is actually a HTTP
proxy and why is it an HTTP proxy well
in order to implement a circuit breaker
that recognizes if something goes wrong
HTTP status codes are sort of good way
to find out if something goes wrong
unless you get no response at all of
course so that's why you have to
configure a HTTP proxy in your
application it's readable yes and there
are system properties in Java from that
to do that but you have to set and then
it depends on what kind of sort of
library you use to do your HTTP requests
from inside your service use things like
coj HTTP level that it will
transparently pick these properties up
if you use anything that uses n io the
new non-blocking i/o stuff it won't pick
up these properties and I think it
depends on the author of library whether
they integrate
support for proxies and that also means
you have to do a code change because the
other thing was just a starter parameter
and now you have to sort of pass these
proxy settings through when you create
the client it might be a knight or might
not be a problem but I think it's a
fairly limited sort of contact surface
between the two things and if that
doesn't work there are alternatives you
can do crazy things with IP tables and
stuff in kubernetes to sort of get
around the whole idea of setting up
these proxy in your application let's
look at the second aspect observability
where we get some immediate benefits
there to be without sort of implementing
any kind of metrics or application
metrics that's not not saying you
shouldn't do that but we get some basic
metrics across the board unified metrics
from these linked of the influences that
sit next to every service and you can
then feed them into whatever monitoring
solution you have for example a tenant
Prometheus so I think stats these also
supported and we get some insights into
the state of the system that go beyond
connection level sort of metrics because
as I said it's request level so we know
failure rates you know how many requests
go bad we see the latencies and things
like that and there's also a very basic
dashboard built in to lincolni itself to
get you started and on the front of
distributed tracing what we can do is we
can integrate with tracing tools like
Zipkin for example to see how your
requests go through the your services
again on the practical side of things
you have to pass through these placing
headers that link of the users
internally and bars actually has
explicit support to configure this is
again a snippet from that evening
service definition that I mentioned in
the beginning you can configure
explicitly to pass through certain
headers and that enables this
distributed tracing if you use it in
combination with linkage
so one implicit assumption that I've
made and I've not really made explicit
is that all the traffic we have in that
system is sort of synchronous HTTP based
traffic now if you listen around what
people are saying you will find quite
strong proponents of you know
event-driven methods passing
architectures asynchronous message
passing and they're good reasons I mean
if you do synchronous hcp between these
services I mean we introduced a temporal
coupling between services of course so a
and B a talking to be both have to be at
least in one instance of them has to be
alive we also use resources to maintain
if you do multiple requests and multiple
services you need to maintain these
resources network or not and of course
we have also this problem of sort of
accumulating latencies to build deeper
chains of these services service to
service call but I'm not going to to too
deep into this sort of question of
whether you should now switch from a
sort of synchronous HTTP approach and
redesign your whole system into a
synchronous message driven one I just
want to point out two things basically
first of course that the tooling I've
just program introduced or presented to
you doesn't work as well it's not as
expressive once you you go away from
from HTTP traffic because you don't have
the same insight into a binary wire
protocol you can still have some basic
metrics on the connection level of
course with TCP traffic for example and
the other thing I sort of want to
mention it that I believe is I think
it's not that black and white and my
experience at least there will be almost
all the time a mixture of both
at least as an external interface as the
least common denominator that everyone
understands and even if you want to sort
of give me in between that there's still
some some gray areas where you can say
yeah we can't even go into a sort of
more you event-driven asynchronous
architecture using HTTP so it shouldn't
conflate the connection protocol with
the way we do we design the sort of
general architecture of how net
communication works on the application
level we can we can send messages we can
listen to events even over HTTP traffic
but as I said I don't want to get too
deep into that because I think that's a
completely different talk and you
already might have see the impression
even without introducing now a
distinction between sort of outside
pressing through synchronous HTTP and
inside asynchronous event-driven you
already might have the impression we're
building a massive Rube Goldberg machine
here there's a lot of complexity a lot
of moving parts here and I would say
incidental complexity because you know
I've never mentioned any in use case any
domain any problem domain you if you if
you if you watch the examples they were
all really trivial hello world examples
so all this thing that beetles build up
is all the complexity visible that is
incidental but sort of required
incidental complexity if we want to have
these properties of destructuring the
system in the way I've described it but
I think all is not bad at the same time
I think we've discovered that there's an
interesting orthogonality between these
concerns that I've sort of flagged up
there's this ability to maintain the
properties we like about a library like
Mars to be able to iterate quickly to
prototype and still embedded into sort
of an environment that's
production-ready or has production
quality and we can do that because we
use a tool like the linker D it's sort
of
loosely coupled with the applications or
services it hosts through a well
understood protocol like HTTP so we can
we can actually you must not despair I
think it's it's a viable sort of way of
building things and I think that's more
or less all I've had so thank you very
much for your attention and if there any
questions I'm happy to take them</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>