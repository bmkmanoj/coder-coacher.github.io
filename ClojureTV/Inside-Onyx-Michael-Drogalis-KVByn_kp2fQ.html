<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Inside Onyx - Michael Drogalis | Coder Coacher - Coaching Coders</title><meta content="Inside Onyx - Michael Drogalis - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Inside Onyx - Michael Drogalis</b></h2><h5 class="post__date">2016-04-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KVByn_kp2fQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good cool so today today's talk is
called inside onyx we're gonna go and
take a look at the design and how all
this works this talk is gonna be based
on version 0.9 point form onyx and I
point that out because we're gonna
change some things in 1.0 but everything
I'm talking about today should remain
stable but it's good just as a reference
point in case you look at this later and
want to know my name is Mike de galis
and I'm the person who created onyx this
project is about two and a half years
old I'm also the co-founder of
distributed masonry a company that
officially backs and supports the onyx
platform and does distributed systems
consulting before I really get going
who here has heard of onyx before this
talk Wow is anyone running it in
production here we're gonna get there
cool most of you know what it is but if
you want the really quick summary before
we get moving
onyx is a scalable distributed fault
tolerant high performance data
processing platform written purely
enclosure primarily intended to be used
from closure
it has a batch and streaming hybrid
model so it's able to handle both of
these workloads relatively transparent
transparently and and the primary
objective for developing onyx was to to
produce a data processing platform whose
API was its information model we wanted
to get as close to data structures as we
could and in terms of communicating what
your computation is so this talk is
going to go pretty far in depth on the
distributed systems aspect and how it
all works but just to make sure we're on
the same page before I get rolling when
I say that it handles batch and
streaming workloads what I'm talking
about with a batch workload is that we
take a set of static bounded finite data
we apply a set of pure transformations
by using presumably multiple machines
which we call a cluster and we produce
immutable output datasets based on that
original corpus this is an immutable
transformation to more immutable data so
you probably do this for aggregation or
indexing or something like that it's
kind of offline computation but the
other thing that ox is really good at is
streaming workloads which is when your
data incrementals shows up a little
at a time you ingest it one piece it may
never all come it might be mobile data
so you're dealing with data of like an
infinite length and this is a harder
problem because you're gonna have
multiple machines still but you're only
going to be seeing incremental pieces of
your data so you're sort of reduced back
to using mutable state by necessity
because the problem is more about
accretion of data over time so this is a
harder problem but this is something
that we try to do really well on so onyx
is for batch and streaming workloads and
this is kind of what I'm talking about
when I say these are the problems that
we solve the payoff that onyx brings is
that it uniquely decomposes the
different computational aspects into a
set of data structures that
declaratively describe the work to be
performed because to be clear building a
distributed system is a really expensive
activity for a company in terms of its
development and it's its maintenance but
I know the one thing that you absolutely
cannot afford to do is to be confused
about what your cluster is doing and
executing at run time and that's why
onyx is the desirable thing and since
most of you in this room know what it is
already and we may have seen the Conch
talk about what the API provides and why
I think it's generally a good thing I
want to talk about how it actually works
so I'm gonna leave a lot of time at the
end of like ten minutes for questions to
talk about basically what's going on the
design is quite unique so I presume
there may be some misunderstandings here
and there so we're gonna try to clear it
up as much as we can so when we talk
about the design of these distributed
data processing platforms in my mind
there's two really big pieces you have a
messaging component and you have a
coordination component messaging is all
about the high performance fault
tolerant routing of data through your
cluster this is the thing that's taking
the data from s3 it's it's moving it
through your cluster and then it's
putting it onto like a Kafka topic that
stuff is really all about messaging and
that's not what I'm gonna be talking
about today primarily because this is
the thing that's gonna change quite
heavily in onyx 1.0 but probably more
than that it's because that the research
in this area is moving incredibly fast
just quickly to talk about what's coming
we're moving to a streaming engine
called async
barrier snapshotting which is the new
algorithm that came out of flink in the
paper that they produced so if you keep
up with that that's where we're going
just wanted to be transparent about
what's happening there coordination on
the other hand is about who is doing
what in terms of the nodes and your
computation and what's happening in your
cluster and this is what we're going to
talk about today because this is where
things got really unique in onyx so
coordination what is it who what's going
on around here who's doing what what's
supposed to be happening what do we mean
when we say coordination we're talking
about who is in the cluster who's
working on what did anything fail are
there new entities that are coming on
and offline and is there a change in
load these are the primary things that I
think about when we're designing a
coordination based system to to ingest
large amounts of data and you can take
these somewhat casual statements and
then nap them on to more serious don't
pieces in domain of distributed
computing so you know who's in the
cluster would correspond to you know the
topic of stage snapshotting who's
working on what is really a bin packing
problem failure detection is its own
well study topic in distributed systems
distributed reentrant algorithms are
quite difficult and then you have things
like elastic scaling so you can go and
you can find all the papers on these
things and and these are the things that
make up coordination and it's been a
tough problem to tackle here's why most
architectures for these kinds of
platforms follow roughly the same design
when it comes to coordination and know
it we call this sort of a design a
master workers architecture or like a
leader followers architecture and the
idea is that the master is the brain it
controls absolutely everything and the
workers are just the raw muscle they're
processing your data they're fairly done
they're just being told what to do and
they'll carry out your computation and
this is the way it's been for decades
quite a while there are a lot of pros to
this architecture the main one being
that you've concentrated all of the
coordination logic on a single machine
and so you get a more predictable
performance profile on the worker
machines and that's really good if you
don't have
whole lot of cores on your workers
because they can't afford to be doing
things that aren't related to the to the
task at hand but there are plenty of
cons to this architecture too you can
have excessive stress and overwhelm the
master if your nodes are doing too much
and your your your master needs to be
coordinating too many things at once can
you effectively end up with a single
temp in your design and it's managing
global mutable state which is basically
you know the value that represents the
cluster in terms of what the the master
is seen the master node in these
architectures progressively take on more
responsibility and they sort of devolve
into a dumping ground for other one-off
jobs you see this happens so many
different systems if you have this
little extra thing that needs to be done
done that's not related to the work at
hand they end up going on the master
node and things sort of degrade from
there but I think worst of all if
they're not designed properly it can
become a single point of failure if you
know even if it wasn't even designed to
be highly available in the first place
so it's tricky operationally you need to
worry about an extra program so while
the what messaging world is moving
really really fast the world round
coordination is like stagnant nothing
interesting is happening and in fact
mezzos was built on the idea that if you
built the distributed system it was
gonna look like this and it would
overtake the responsibility of the
master so that's really cool I think I
think that's a really good idea but I
wanted to explore what else could be
going on here I would onyx wasn't really
popular when I started tinkering around
with this sort of design and we started
out like this but I wanted to move
towards something with a different set
of trade-offs and just is just to see
what could happen could we could we get
new new properties if we tried something
else and so what we ended up with is
what I like to call the cluster as a
value onyx is now a masterless system
and everything is oriented around the
idea of an immutable append-only log
with a well-defined set of transition
semantics I want to be clear about what
exactly it does look like onyx is design
is composed of peers which are the
equivalent of workers and zookeeper that
is it unless you start bringing on this
the stateful
the stateful mechanisms to record
durable state over time and yet you know
exactly once semantics this is what
you're gonna have to deploy so there's
no master in onyx that being said there
there is a master in clustered zookeeper
so that's the point that I want to make
note of because it's a little nuanced
so it's not fair to say that onyx is
completely peer-to-peer but onyx itself
doesn't have a centralized coordinator
even if zookeeper does so just just to
hammer home that point ok so we started
off like this this is what onyx looked
like as a version 0.1 0.5 we did the
following basically we took out the
coordinator so we don't we don't want
that anymore I want to try something
with with no centralized coordinating
entity and when you move towards a
peer-to-peer ish design the canonical
way to do that is to represent your
topology as a ring and the reason for
that will become apparent and before I
keep going up something you might not
have noticed that before I did onyx my
background was in kind of like database
research I was really interested in what
was going on there and so the design
you're gonna see is quite similar to a
CP database actually so kind of keep
that in mind is there's a parallel
that's going on here anyways to switch
back to what we're talking about right
we got rid of the centralized entity we
don't have a centralized master anymore
we have a ring and so the emphasis now
isn't on centralized storage where peers
go to information for every time or
where they are you know being in the
active consensus with some other entity
instead we're gonna we're gonna replace
that with this notion of a replica which
is really meant to be the brain and in
fact we give every peer its own brain
and this is the same brain that you know
roughly used to be in the coordinator
and the replica is gonna consist of some
information of what's going on in your
cluster specifically it's going to be
the structural information that we
discussed before things like who's in
your cluster what are the other peers
where do I find them who's working on
what of note messages your user-defined
data things that are like in s3
never touch the replica I don't want
anyone to get confused about that
because this design would look horrible
if that's what happened this is strictly
about coordination and which you have
the properties of your cluster runtime
your messages never touch anything that
I'm about to talk about using the
replica Pierce can open up direct lines
of communication to one another there's
no centralized broker they can just
immediately look inside their own data
structure open up a connection channel
and start by travelling as fast as they
can so we're going to reframe this
reframe the discussion instead of a
master directly commanding workers I
want to conceptualize cluster activity
as a series of things that happen in a
linear append-only log such that every
worker every peer is gonna see every
event in the same order and in fact this
is atomic broadcast which is a
fundamental topic in distributed systems
but but the act of every process seeing
every event in the exact same order so
what happens is that when a peer or
another process wants to enact change on
the cluster it creates a little message
call it a log entry and it will append
it to the end of the log this log is
sitting in the zookeeper the log entry
is then asynchronously replicated to the
other peers in the cluster who are gonna
process the message and store it in
their replicas we'll talk in a minute
about what that means but it's gonna
take the message and then stick it in
it's a little local brain so we're
making a trade off here right there's no
centralized coordinator and acting
change peers are independently proposing
changes at the end of this log and then
other peers are finding out about it as
the asynchronous revell asynchronously
replicate so there's less coordination
than there was before because we
basically turned this into a reactive
architecture at the cost of using more
CPU CPU usage whereas before you'd have
a coordinator seeing every change and
then you know enacting and dishing out
commands to all of its workers now every
machine in your cluster is seeing every
change so there's obviously more CPU
power being being used this sounds not
good but the critical insight is that
the number of coordination related
events that happen in your cluster
is generally pretty small for for small
ish and medium-sized clusters that
operate on streaming workloads I'd say
we see like a few hundred to a few
thousand messages which is like nothing
we don't we don't need Kafka for a log
here we don't need anything
high-performance in fact we just use
uzuki per and sequential Z nodes to
represent this log that's far and away
enough so in effect what you get is a
durable change log of all events that
have happened in your cluster I don't
know of any other platform that does
this and it opens up a set of very
interesting features and so you can
actually subscribe to this change log
through the API and if your connection
breaks while you're subscribing for the
log you can go back in time and look at
changes that you lost and keep going
forward which is really nice because you
can build things like automatically
scaling up and down based on sort of
reactive approach if you see your
clusters being too busy you can send
warnings through page of duty just by
building on top of on top of the
changelog api this is quite unique and
really nice so let's talk about that log
it was a little big peers are gonna
reach from the log and they're gonna
apply entries to its replicas as it
moves forward and this log by nature of
it being in zookeeper as a set of
sequential Z nodes is going to be
monotonically increasingly ordered
starting at zero so that all peers will
know which log entry exactly they read
by nature of its identifier these
entries are going to be closure maps
that represent functions and arguments
to be applied to its local replicas the
replica is just the data structure that
sits inside the peer with well-defined
transition semantics and those semantics
are defined by the functions inside the
replicas we're going to look at the
keyword in the FN and resolve it to an
actual function inside of Onix and use
that to update the replicas these
functions are pure deterministic and
idempotent that is the critical thing
you have to get right because the
underlying property is that if any peer
reads up to the nth entry all peers who
have read up
the entry will have the exact same value
that's how you get that similar that the
exact same coordination mechanism and
you reliably know that all peers are on
the same page with what's going on
because they're reading the same values
getting the same replica at the same
login log entry does that make sense
there any questions so far because this
is like the really important part I'm
sorry a little bladder oh so how do you
know you're reading the same entries at
the same time to sit in the same work so
zookeepers sequential Z nodes will tag
every node that you append it's like a
little file system like 1 2 3 4 5 and
then you can get a watch on the
directory and zookeeper and be notified
every time there's a change and what's
happening is that the peer is keeping a
pointer into the log and every time it's
a there's a change it's gonna go back
and say I read the fifth entry now I
must be expecting the sixth so you know
that every entry is gonna get the next
identifier in
sure oh so you're talking about like
does this lead him to see rdt land yes
okay so yeah there's there's no
conflicts because they're only ever
reading forward in the same manner and
you know that they're just gonna apply a
function to a map which returns a new
map so you're never gonna have a case
where two peers are gonna conflict in
terms of their operational updates so
you always get the same value as you
move across yeah
I will get to that I'm gonna keep going
so cool good question I'm just
illustrating here that you were gonna go
ahead and point to every entry and just
keep reading left to right as fast as we
can go and again the the replica is just
a data structure that has structural
information like which piers are in the
cluster what jobs are active and things
like that okay so we have some bunch of
questions I think you guys understand
the notion of a replica but I'll just
blow through these slides quite quickly
repla is a data structure that's sort of
like a a journal or a trace of the real
world things happen in the real world
databases crash networks partition but
we do know what things we did to the
real world like we opened a socket we
opened a communication channel and I can
record those kinds of things in the
replicas and have a rough estimation
about what's going on out there and
that's essentially the purpose of the
replicas I like to think of this as a
vector of maps in closure and you can
kind of visualize yourself going from
one to the next and applying these
functions if you resolve them the actual
closure functions and then apply their
arguments so the log is built around
three three primitives that are going to
transition your replica from one state
to the next
the first one is apply log entry which
takes the replica applies the function
returns the new replica and advances it
forward so if we only have that nothing
would ever happen because these
functions are pure and deterministic the
critical thing that you need is a
function to fire side effects based on
the Delta between an old replica and a
new replica and the other thing that's
needed is that peers have their own
identifiers so they can identify
themselves in the diff and see if
they're related to any side effects that
should take place so in fire side
effects you're essentially taking taking
the diff seeing if this involves me and
if it does I'm gonna apply it I'm gonna
fire the side effects and so that's how
you don't get conflicting conflicting
operations and finally you can you can
have reactions based on seeing an entry
if it's applicable to you you think you
should do something else you can have a
reaction and append more entries on to
the tail of the log
this is just a simple example of an
implementation for turning on back
pressure internally we extend the multi
method and it's quite simple we have the
entries the first argument with its with
its arcs since we already know it's it's
the backpressure function we we only D
structure the arguments and then we take
a replica and basically we look in the
replica and we see is this pure active
is it doing anything and if so we we
flip on a switch in the replica that
says back pressures on for this person
we know that they're not gonna be
producing anymore messages in otherwise
we just return the replica so this is
pure deterministic item potent has
almost properties that we needed before
and it's it's a cyclic algorithm it just
keeps going iteratively we take an old
replica and a log entry we feed it into
the apply log entry to produce a new
replica and then we take the old and the
new fired into fire beat it into fire
side effects and then things actually do
begin happening and then we just recurse
and keep going and this is just the the
infinite iterative nature of a log based
design what's really awesome about this
is that debugging is fantastic because
we can take a pointer to a production
cluster if we know there's a problem
pointed in a specific log entry and then
move forwards and backwards and watch
our replicas grow and shrink and then
detect where there's a problem and then
a rewind and then patch the code and
then replay and make sure that we fix
the bug it's really cool to the point
that we actually built some tooling
around this we have like a replica
console viewer you can basically connect
a zookeeper and use the arrow keys to to
move across like your your log over time
and see what's going on so you can see
the log entry which one it is so this
one is accept join cluster with these
params you can get a diff of what
happened in the replicas for easy
examination and then you get the actual
replica itself at the bottom so we use
this for production diagnosis all the
time I would recommend if you're
building a system similar on this build
this early we waited like two years to
build it and oh my gosh it's amazing so
I just want to stress the point that
peers when they're reading this log are
never blocking each other they start the
beginning and they have independent
pointers into the log and this is why
coordination isn't crippled no one's
blocking everyone's always trying to
make progress moving left to right over
time they have their own independent
replicas and if they're all pointing to
entry
they're all gonna have the same value as
of entry three no matter which point in
time they actually get to entry three
okay so this assumes an infinite address
space and and as this person asked what
happens when it when appears gonna come
online later it didn't didn't catch this
third of the log so this is the topic of
really more overlapping into garbage
collection so I think I think the answer
will be a parent to your question after
I'm done but I'll just try to explain it
first and we'll see because this is
mainly targeted at GC so when you want
to have a GC you invoke a an API
function because this is user driven you
don't usually need to do a GC most
clusters we're seeing is like once a
week it's that it's not particularly
often but basically what's happening is
that there's an Origin address that is
constant and fixed and it's gonna point
to the head of the log and so when app
here comes in line it goes to the origin
and then it bounces to the first to the
first node so when you do a GC it's
gonna look for the origin and then it's
gonna set a marker to the last entry
that it can find since this is the new
start so that's marked and that's
recorded and then what the GC process is
gonna do is pretend to be an actual peer
which is basically what the the log
subscriber is gonna do it's gonna read
every entry and build up its own
replicas it will take that replica and
store it in the origin address so that
way when a new peer comes online it
could just take the whole replica pull
it down start reading from the beginning
again
it will then instruct the origin to
atomically point to the new start and at
this point you can safely just go ahead
and delete every entry before that now
if you had a reader behind you it's
gonna throw an error which we've we've
tested and we've made sure that it will
actually just hard crash and they go to
the new head so if you GC your peers
might go offline if they're like lately
reading behind but in general it's it's
not real problem really a problem
they'll just take up for a second and
then bounce back
so one of the problems with not having a
centralized coordinator is it does the
very important task of detecting
failures and without that your system is
in fault-tolerant and that's a problem
so I'm gonna describe failure detection
and adding in new machines at runtime
next and these were I think these were
two of the hardest things to do because
if we couldn't get these right there was
really no point in even doing it as I
said before we have a ring based
architecture and the idea is that every
peer is responsible for the peer - it's
right or conceptually left I like to
picture it this way and so it's suppose
we lose the machine just because it's
gone what's happens now is that the peer
to its left notices that it's gone it's
using zookeepers heartbeats and watches
to detect failure and it's going to look
into self code so it's gonna say oh that
peers crashed
I wonder which peer it was watching
right who is on it's right and it it
will broadcast a message to the log
notifying everyone that that peer is
dead and it's gonna establish a watch on
that pier so it just tighten the ring
into atomically because they could just
look in this replica know which way it
was because it has structural
information so you one of the problems
here is that you can lose a contiguous
set of the of the Ring all at once
simultaneously before any of the
recovery could have happened and the
algorithm interestingly enough remains
the same the only thing you need to do
is to be able to report failures as you
tighten the ring so if you go that
appear in the upper left tries to
recover to the the second peer to its
right it's gonna find that it's gone so
it just needs to continually
broadcast messages that disappears dead
this appears dead this appears dead and
eventually it can close over there are
special cases for when you have one peer
or you have concurrently joining peers
where things need to abort and back off
and try again but this is essentially a
safe process that we've Jefferson tested
and I'm happy to say that's working this
is a tough one
yes
you only have one circle B if you get
into a situation where there's about to
be like a ring split one of the peers is
gonna back off and the board yeah so we
always want exactly one ring if we ever
violate this this is really bad
hopefully we don't
you repeat that sorry
yeah
I think if we had a bug of that nature
that could definitely happen I I think
the reason we haven't seen that is
because the way that zookeeper
heartbeats work where if it was not able
for both of those to communicate the
original one was just gonna drop offline
and the one to its left was gonna kill
it right exactly but that's an
interesting question so that's how we
handle failures adding a new peer is the
more difficult one to do safely I should
say so if you have a new peer that wants
to join the cluster you need to do a
three phase process atomically to make
sure it's gonna work if you don't know
who's in the cluster ahead of time so
the first thing the new peer is gonna do
is gonna sign online and is this a knows
where zookeeper is it's gonna broadcast
out a message we call the prepare phase
say message number 42 and because of the
fact that we know every message ID that
we're recording and that it's coming in
through a monotonically increasing
increasing identifier we can use a hash
montt algorithm to determine asleep ick
appear for it to pair with so let's say
that top one it's gonna pair what's
going to read that entry and as a side
effect it's gonna establish a watch on
that peer it needs to be in this
direction because if if it was in the
other direction and the original peer
failed no one would be able to pick it
up and you could get your cluster into a
bad state so we first add a watch
outwards next that same here is gonna
write a message in the notification
phase say message number like 51 other
things could be happening concurrently
they can interleave just fine it's gonna
broadcast out that message all peers are
reading these messages but they're using
their own identifiers to pick out which
one should be doing what thing
so this peer knows it's looking for the
notification message it receives it and
as a reaction it's going to use its
replica to figure out who that original
peer was pointing to so we've actually
closed the ring again we have an
extraneous connection that we need to
clean up and so there's a third phase
which is the acceptance phase that same
peer I'm sorry is going to broadcast out
a message the original peer that helped
it stitch in reads it and fire side
effects by cleaning up and getting rid
of this extraneous link and after that
you have a fully closed cluster and you
converge back on the original ring so
widening takes more messages
than a departing node leaving does
resource allocation is a really
interesting part of this design because
as you're reading left to right left to
right in the log you can actually figure
out who's doing what as a pure function
based off of the replica value you take
all the peers all the work to be done
and all the work that's already
happening feed it through a peer
function and then get out a topology of
who should be working on what and if
there's a DIF in what you're doing all
you do is pivot from the last thing
you're doing to the thing that you
should be doing and I we've looked at so
many different third-party solutions for
this and like mezzos is a thing that you
can use there's lots of other heavier
tooling and all I wanted was the pure
function and like nobody had that and we
found a library called better place Java
based solution that has a very rich
constraint set and it's just perfect it
works like a charm it has declared of
properties to basically say given a set
of things to be done and people do it
and instead of constraints on that I'll
tell you who should be working on what
and this works great and gives there's a
really sophisticated scheduling
functions all right I just want to
finish out by talking about things that
are not awesome with this architecture
because I we didn't solve every problem
here we introduced new problems because
we have new guarantees and such as life
so there are a bottlenecks when we try
specifically to scale to really big
cluster sizes I don't think anyone in
this room if you're running it's
probably hit this this these are more
like you know 100 a couple hundred
thousand machine clusters that I know
are gonna break we just haven't done
them yet and things will need to change
when we get to it oh yeah like I said
like like five hundred machines you're
gonna see these things I think first of
all the replica size is gonna be a
problem because the replica is an
in-memory value that needs to fit on the
machine in every peer so if you have a
huge cluster you're gonna have the
structural information about the whole
cluster you're gonna need to know where
every peer is and I mean maybe using
bigger machines if you're using a large
cluster and the replicas value isn't
huge but if your clusters huge I mean I
think this is gonna start to be a
problem so we could one thing we can do
is take the replicas and put it on disk
and use a very lightweight database to
pull values in and out of it not a
priority but just something to think
about replica is sitting in memory and
that's that's that's pretty crucial
another thing that's tough is that the
the join process from scratch is three
phase three phases and that's kind of a
lot so if you try to converge four
thousand peers all at the same time it's
gonna take longer than it should it's
not awful but it's just it doesn't do it
up quite as quickly as I want it to so
one thing we could do is have like a
join direct function where you don't
need to know where zookeeper is off the
bat if you know the location of exactly
one other pier you can have a
bi-directional exchange with that pier
and then just do it locally really
quickly and then only send a message
when you're online then you're back to
one face and that's pretty good and that
does have the caveat that you need to
know the existence of one other pier
that's in your cluster already so this
might not be appropriate for like medium
sized clusters because it's a little bit
operation alee more difficult but it's
something that needs to be there
eventually log activity we count on it
not being heavy traffic but even if you
have you know only a little something
and then you scale up your cluster by a
hundredfold now that little something
becomes a lot of something just by
nature of the map and so this will be
the most difficult problem to conquer I
think because you're gonna have more
contention on zookeeper specifically on
reads and then sequentially ordered
writes I have an idea I just want to
throw it out there and and see if anyone
just I'm thinking on this I don't really
have time to work through this and this
is probably a design that's gonna happen
like you know two years up the road for
us I'm not trying to say that this is
happening next but it's in the back of
my mind and it was kind of kicking ideas
around suppose that this ring is
absolutely huge it's just you know tens
of thousands of machines one of the nice
properties of peer-to-peer and
nationalist architectures is that
they're actually more general than than
a master master master based
architecture and that you can elect
one-off leaders right we do that all the
time for instance picking which pier is
going to need to help new piers join in
we've essentially elected a master so
what you can do is pick masters in sub
sections of the Ring and have them
establish little zones so now you you
sort of have like a four-way sharded
cluster where these zones are basic
we the same architecture that I
described but communication Interzone is
gonna follow a more traditional approach
and and one thing that can come in handy
here that I've implemented before was
helpful was the court algorithm for
peer-to-peer communication and they you
would use the court algorithm when you
have you know massive numbers of
processes that don't all know about each
other but need to arbitrarily contact
each other the nice property of Accord
is that you could have log and based
communication to find any machine in
your cluster which means if you have a
million machines it will take at most
five messages to figure out where the
machine is you're looking for which is
pretty darn good for coordination
related messages given that they don't
need to be ultra high performance and so
the idea would be that you have up here
inside of a zone could contact it to
local master to figure out where appear
in a different zone is so that you can
actually just skip to a known master and
cut down on the communication overhead
thus reducing your replica size and
reducing the amount of log traffic the
last thing I wanted to just kind of
throw out there was we have centralized
storage and zookeeper to have every
entry of the log could we switch to a
gossip based protocol where you take
your entry and you put it on stable
storage but rather than everyone eagerly
pulling things down from storage you
know could you gossip to your neighbors
about the entry that you just put on the
log so that you reduce contention I
don't know if this is possible with the
design constraints that we have but I
think it's really interesting to think
about when I have some free time so if
anyone has an idea hammock time is
always appreciated that's all I have
about five minutes for questions I also
have laptop stickers up here so if you
want one come up when we're done happy
to take any questions now
they'd be different the exact once stuff
comes down to a a different log that we
keep in bookkeeper that does need to be
high-performance cuz that pertains the
messages that you're writing through
your cluster but this stuff is just the
coordination things so actually they
don't need to be exactly once because
they're just pure and item potent and
you can apply them as many times as you
want and it'll be fine ah there's an
interesting question okay so we take a
very different stance to deployment than
most other most other platforms that are
similar to this because usually you have
a master and you give it a jar like SCP
is the jars to your cluster onyx is
really a library you you implement your
stuff according to the data protocol and
then you call a function in your main
method which starts your peers for you
it'll start your threads up and your
head pool you you would block on your
main so your main stays up forever and
then you essentially take your jar
however you would like and then put it
on the target nodes in your cluster and
I like to do that with like docker and
kubernetes and and you're off they're
off and running the peer start and they
know where the zookeeper is they just
they continually enact that way any
other questions
um beyond batching streaming I mean I
have to think we work we do a lot of
consulting work I'm domain wise I the
reason it has Ennis who knew consulting
work it's kind of difficult to talk
about what exactly you're working on
unfortunately other companies can tell
you okay any other questions thanks
everyone</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>