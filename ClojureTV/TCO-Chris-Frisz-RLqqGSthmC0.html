<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>TCO - Chris Frisz | Coder Coacher - Coaching Coders</title><meta content="TCO - Chris Frisz - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>TCO - Chris Frisz</b></h2><h5 class="post__date">2013-02-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/RLqqGSthmC0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">has everybody done today three days of
closure cons we've seen a lot of really
cool modern systems to handle new big
problems facing the internet and what I
have for you today is some really old
computer science we have the problems of
the 1970s so this work somebody wanted
me to share the history of this work
this actually came out of closure conch
last year when when Dan Friedman and
will bird came for the first time and
Dan was having a conversation with rich
about closure as a language because he
didn't know anything about it I still
don't think he knows anything about it
today but he was asking about different
features of the language and asked if I
had tail call optimization and said rich
said now it doesn't have it and it's not
really possible because of the JVM dan
said you know I think there is a way to
do it so he came back and he recruited
me and so that's what we're talking
about today and so just to give you a
little outline for some reason why
clickers not working just a second there
we go okay so here's a little outline of
what we're going to talk about today
we're going to talk about the history of
tail call optimization and the idea is
behind constant space tail calls we're
going to talk about the built-in tail
call optimization support that closure
has because it's got just a little bit
and then we'll talk about the system
that i wrote which a very very
creatively named closure TCL and I call
it ctcl and we're going to spend the
bulk of the time talking about the
transformations that it does and the
three of them are listed there
continuation passing style yes we're
going to talk about cps today we've got
thunk ification and trampolining which
may be familiar to some of you at the
end if we get some time we're going to
talk about optimizations that I've been
working on the last couple of weeks to
make things a little faster little
peppier a little better and then the
very end we'll talk about work that I
hope to do related to this and directly
using this work so I've got a couple of
goals today and I want you to be kind of
in the same headspace what I want you to
know and what I don't care whether you
you retain after this so I want you to
have a high level understanding of what
goes on in ctc oh how it does these
transformations
in order to enable tail call
optimization in a language that doesn't
have tail call optimization I want when
somebody asks how can you get tail call
optimization out of closure it runs on
the JVM you don't have tail calls I want
you to be able to give two or three
sentences about why the three
transformations that CT CEO does enables
tail call optimization and I don't think
it's any secret to anybody who's talked
to me at cons very much that I think
about continuations like constantly I
want everybody to think about
continuations I want you all to
understand continuations and I think
that we've turned them into a monster
that's really scary and I hope to take
the monster out of them today and
hopefully give you a little bit more
understanding of continuations if you
don't already have a good one I was
going to say Dan's not going to learn
anything today and I've got a couple of
things oh excuse me sorry so I also
wanted to discuss how there are some
some benefits to using CT CEO like I
said you can write tail recursive
programs and they don't blow the stack
like they normally do enclosure but
there's also some costs associated with
the transformations that it's doing and
we'll kind of talk about those a little
bit for the end yes as I was saying
there are also some ongoing that I have
some things that I don't care if you
retain things that we'll talk about or
we might not talk about but I don't want
you to really think about these things
there's the internals of ctcl the
implementation we're not even going to
look at I don't care if you understand
the software engineering effort that
went into it at all we're not even going
to look at it and the other thing we're
going to see a fair amount of CPS today
now I said I want you to understand a
little bit about continuations but I
don't want you to be a CPS expert you
don't even have to understand the little
bits of CPS that I'm going to be showing
off today okay so we all on the same
page everybody good everybody ready okay
so the first thing that I need to do
it's good the doors are closed we're
going to imagine that this whole big
room is a time machine and we're going
back to nineteen seventy seven
so unfortunately I brought you back to a
time where everybody's using imperative
languages we got a lot of fortran we got
a lot of pl1 we got a lot of Kobol but
it's not all bad we've got lists
although it's for academics and nobody
would ever build any big web facing
database backed program and Lisp that's
just crazy that's not the real problem
the real issue we have right now is a
big debate we have the debate between
structured programming which you and I
and everybody in the room thinks of as
the right way to program it's using
procedures and function calls and
abstraction proper abstraction in your
code but the alternative that everybody
thinks is better is go to so there is
this horrible horrible awful rumor that
go to is inherently faster than
procedure calls that procedure calls are
stupidly slow and yeah sure if I write
my code using abstraction and function
calls and everything it's more modular
it's more readable but my manager would
kill me if I wrote a slow program with
procedures and procedure calls instead
of go to well it's also a good thing
that we came back to nineteen
seventy-seven because guy steal at MIT
has just published debunking the
expensive procedure called myth or
procedure call implementations
considered harmful or lambda the
ultimate go to he's truly a man after my
own heart in terms of ridiculous names
for things in the main point of this
whole paper was compiler writers you're
making procedure calls slow and it's
your own fault you're making people not
want to use procedure calls because
you're doing dumb things you're saving a
whole bunch of values whenever you do a
procedure call that you don't have to
and they can be a lot faster and so kind
of the keystone of his whole argument is
talking about tail calls and this is
very prevalent we're very relevant to
what we're talking about today so gives
us a little example and everybody can
see this right so it's this little Lisp
example he's defining a function bar
that takes two values x and y and it
does a call to G with X and a call to H
with Y and assumedly these are
to find somewhere else and then finally
notice I say finally you make a call to
F with the results of those values so if
you have any sort of background in
computer architecture then you're
familiar with the idea of a stack and if
you're not a stack is essentially the
place where we save values for the
current procedure that we're running so
we have our little stack off to the
right here and we come into a call for
bar and we've got x and y and we're
going to use this little space and we
get into the the body of the procedure
and we see that we need to make a call
to G to get the value out of it ok so
we're going to save our stack frame
we're going to call it a frame we save
our information and we make G work above
us geez up there he's going to do his
thing he's he's calculating a value it's
all cool he gets done and we've got a
value for him and we can erase his stack
frame and everything we come back down
we're back in our original stack frame
oh wait but we still have h to work on
ok so H goes up there and he spins
around he does is a little computation
thing comes back we've got a value and
now this is the key point we had values
that we had to save when we were
executing G and H because we had to come
back to bar we had some work to do in
bar but now all we have to do is make
the call to F so if we were silly we
would say ok f go do your thing up above
me in a new stack frame but what do we
have to do once we get back from the
call to ask what does bar have to do
when we get back from F think about it
for a second nothing there's no work to
be done why are we saving information
about bar so let's do just that let's
just reuse the stack frame and put F in
there let F work in there and then we
don't have to do the stack manipulations
all of a sudden we see we don't need a
new stack frame we don't need to do the
manipulations and all we've done is set
up for some arguments to go to the next
function and we jump it's just a go to
not only do procedure calls not have to
be slower than go to they can be go to
this is a really just awesome idea and
luckily it seems like most of the
compiler writing community at least for
the most part
procedure calls got the message and
procedure calls aren't painful anymore
and so we learned tale calls are super
awesome they're an efficient natural way
in languages that include constants
based tale calls to do iteration you can
do recursion on lists and all sorts of
fun things if you've ever written a
finite state machine or a parser you
know that writing it in terms of natural
recursion is awesome and it's still
great the guy Steele who is also working
on the scheme programming language and
Gerry Sussman at MIT they put it into
the scheme standard you're not a proper
scheme implementation unless you have
constant spaced tale calls and the
standard mo guys came along a little bit
later and they were like hey that's a
good idea let's do that too so we're
still in 1977 looks great for the future
everybody ever he's going to have
constant space tale calls right
everybody in the room 1977 everybody in
the future is going to have constants
bass tail calls right awesome wait not
every language ever uses constant space
tail calls and they're a whole bunch of
them but what we care about today is
that the Java security model makes it so
that we have to have a stack frame for
every single procedure call and
therefore our favorite little Lisp
implemented on the JVM doesn't have full
constant space tail calls sad days but
it's not all hopeless we do have a
little tiny bit of built-in tail call
optimization enclosure we have you're
probably familiar with the recur form we
can use this for self recursion and
function bodies or if you use the loop
form which if you squint and turn your
head kind of looks like a while loop
there's a reason for that or so I've
heard it uses the underlying mechanisms
for while loops to do that go to with
arguments that that guy Steele told us
about way back one and by the way we are
in 2012 again so it's sad times that we
don't have to i'll call optimization
everywhere but we we don't have to treat
the room like a like a time machine
anymore in addition to the recur form we
also have this function built in to
close your core called trampoline i've
personally never used it you have to do
some funky little code transformations
in order to get it to work
and actually if you were paying
attention to the very beginning of the
talk you would notice in the outline
we're going to talk about trampolining
is a transformation that CT CEO does and
so we'll get into it later it is
important it won't use the built-in
trampoline it actually rolls its own but
these are the things that we have to
play with so that brings us up to speed
we know about tail calls we know about
the story about tail calls enclosure and
so now we can get to the system that I
wrote called closure TCL and the idea is
that the way that closure stands now if
you want constant space tale calls you
have to roll it yourself you have to
know when to insert recur you have to
know when to do that funky trampoline
transformation that we're going to talk
about later and I'm a compiler hacker
and I like to write things that write
code for people so the whole idea behind
CT CEO is you just write your code the
way you want it let the compiler handle
it for you and of course the main idea
is that like with the go-to with
arguments the compiler transformation
will make that transformation as good or
better than you could do it if you were
an expert and how to do all these things
by hand so with that we're ready to
start talking about CT CEO
transformations which you know means
attenuation passing style so what in the
world is a continuation it's this weird
abstract math ii thing why are we
talking about it in terms of writing
real software well i hope to give you a
real software explanation of what it is
but first let's think about what a
continuation does you may not know this
it's fine it's a thing that takes a
value it does some work and we'll think
about it as some computation that's
waiting to happen and then it returns a
value if we were doing things in type
closure is actually thinking about this
with respect to Ambrose this would be an
arrow type it be value arrow value and
you can think of it as a function it's a
very convenient way to represent them in
fact that's how we're going to represent
them in ctc oh and you can even think of
the smallest continuation you can
possibly construct we call it the empty
continuation it's better known as the
identity function it
takes a value does no work and then
returns the value okay so we've got a
little bit of a picture of how of how
continuations do their job so now I want
to make a really big claim and it took
me a really long time to figure this out
and I think that this is the point that
helps you think about continuations with
respect to when real people not Matt the
abstract people write software
continuations are stacks it is just the
stack when we apply the CPS
transformation to code in C TCO what
we're doing is we're taking that stack
that the JVM handles for us and
sometimes we don't like the job that it
does because it creates stack frames
where we don't want stack frames we take
that stack and we turn it into a
function we've got it in our hot little
hands and so we don't care about the JVM
stack anymore we can clear it out
however we want because all the
information that was being recorded in
that JVM stack is now recorded in this
function that we have that's super cool
so from now on and literally even in the
middle of this talk if you hear me say
the word continuation you can yell stack
at me so I need some audience
participation right now when I say
continuation you say when I say
continuation continuation all right okay
so in order to illustrate this point you
know I'm just at this point I've just
said continuations or stacks I love you
guys okay apparently we've had a
technology failure you're going to have
to take my word for it okay well
unfortunately it doesn't look like i'm
going to be able to show you part of my
big claim i was going to take the
intuitive recursive version of factorial
Shakur's factorial is just factorial of
0 is 1 n factorial of n is n times
factorial of n minus 1 right and I had a
picture I had this wonderful picture of
the stack being built up where you see
these big multiplications coming out and
you have to save this information on the
JVM stack when you do it in the
intuitive recursive fashion and it blows
up it blows up in most systems because
it's a non tail call it's like f
not like ethics like G and H in our
original example from the guy steal
paper but what you see from the example
of CPS in it and now you'll just have to
come and ask me afterwards bumming me
out but then I get to CPS for you which
I really like doing you see that the
stack that gets built up on the JVM
becomes the actual continuation function
that we're passing around like I said we
don't have to worry about the JVM stack
it's not holding values for us anymore
we've taken all those values and we've
put them into our function and we use it
directly and the other illustration of
how this is awesome is we take a tail
recursive version of factorial and you
get to see doing CPS on it how every
iteration it doesn't manipulate the
continuation it doesn't manipulate the
stack you guys missed a continuation I
just said continuation I need two more
okay but the stack doesn't get
manipulated you see it's the same
continuation flowing through them thank
you the it's the same k stack flowing
through the program the whole time and
it it shows the point that guy Steele
was trying to make when you make a tail
call you don't need to record
information on the stack you can reuse
the stack frame you can reuse the
continuation awesome okay so
unfortunately back to my slides okay so
now we've done the continuation passing
style transformation on our code thank
you stack passing style and I can I've
committed now
so we we have the stack in our program
now and we can clear out the jvm stack
like I said so the next thing that we
need to do is this thunk ification
transformation and this was the weird
little transformation I was talking
about with the built-in trampoline
function the idea behind thunk ification
is that every time we make a function
call in our procedure we wrap it in a
function of no arguments a fun of no
arguments call that a thunk it suspends
computation the cool thing here is it
breaks the computation in two steps and
what I would love to show you if I could
get a terminal running would be in the
definition of factorial you just wrap
the the tail recursive call in a thunk
and then you can just run that
computation one step at a time and it
goes until it completes and because
factorial is a function that accepts the
number five and returns 120 you see that
that eventually happens I'm actually I'm
going to try this one more time oh hey
hey here we go okay so here we go this
was the point about factorial I was
trying to make we can take a step back
now so you can see we have our our
natural recursive version of factorial
here if you give it zero it returns 1
otherwise it takes n times factorial of
n minus 1 and this is our call trace
this is kind of our stack and like I
said you can see the stack kind of
building up through the multiplications
and so if I had time I would have shown
you the CPS version in detail but
instead you can take a look at it and
you see that instead of building up the
stack with a non tail call we have a
tail call now and we're passing along
this function that does the same thing
as the non tale called it before and so
you can see that weird thing that I said
about continuations that they perform
the part of the computation that's
waiting to happen that's what's going on
here this multiplication with n is the
computation that is waiting to happen
and so we've stuck it in a function
and we have it in our hot little hands
and we can we can run around with the
stack now and you can see that here if
you look at the call trace look at that
second argument to each call of
factorial it's getting bigger and bigger
with bigger and bigger multiplications
in the exact same way that the original
stack got bigger and bigger and bigger
so you guys kind of believe me that
right we're using the closure data
structure to hold the information that
the JVM stack was holding for us before
so kind of kind of get some some nodding
heads and yeah we got a stack or our
continuation is a stack and now
hopefully I can show you this is the
tail recursive version it's an
accumulator passing style which that's
just a big fancy name we don't need to
worry about it but it passes around the
final value that we're going to return
and so there's no work here to be done
when we finish the recursive call so we
should see here when we see PS it we
have this call trace where we've handed
in the original empty continuation
mm-hmm thank you and it just gets passed
along over and over and over again we
never change it because the stack never
changes so the continuation never
changes okay so this is the CPS
transformation on the tail recursive
version of factorial using accumulator
passing style like I said the next thing
we need to do is thunk a vacation and so
to do that all we've done is put this
little hash here now you know hash is a
little reader macro that turns the thing
into a function and because we don't use
any arguments and it's a function of no
arguments so now I should be able to
show you this is exciting now I can show
you things and one other thing to note
here I've left an entry point this
overload so that you can call factorial
with the original number of arguments
and it just sets up the the empty
continuation for you
so I can take this hold function
definition and i can paste it in here
and you can see when i call fact with
five and one well what's this we had a
function back what if i invoke it get
another function back well let's invoke
it some more times hey we got a value
out so each one of those sets of friends
that I just threw in there that's us
invoking one of those thunks that we did
now when you make a function call you
don't want to wrap it in a whole bunch
of friends you don't want to guess how
many steps it's going to take that's
annoying so that brings us to our last
transformation that we have to do in
ctcl Mac you're killing me
yes wrapping a thunk break the
computation in two steps you just saw
those steps and this prevents the
runaway stack growth because at each
point where we're returning a thunk we
would have made a function call which
would have made a new stack frame and if
that continued our stack would get huge
and we'd overflow and things would be
bad and we would be really unhappy so
this breaks it into the steps where
instead of making that function call we
return a value and that's the point
where you know how I said we could clear
out that JVM stack that's exactly where
we do it which lets us move on to
trampolining which is where we do the
running of that computation step by step
and in order to do it we need to have
some sort of looping construct in our
language that has constant space well
you remember toward the beginning I said
we have at least one we've got loop
recur so we're going to use that we're
going to run this little computation in
a loop recur and it's going to go and go
and go and go until it's done and an
important thing here is to figure out
when we dismount this trampoline now
there are a few ways to do it and I
actually have to give Alan diaper credit
wherever he is in the room for coming up
with a very clever way of doing it and I
can show it to you now now that I have
mastered my own computer okay that's not
what I moment there we go so now we can
look at trampolining and you can see
that you can see that all we've done is
we've taken our factorial function
definition and we've found it within the
scope of this trampoline function and
the trampoline function is simply asking
is there a piece of metadata attached to
the thing that we were past that says
it's a thunk of course we're not doing
that right now but
now we are and of course when we make
this entry point call here we need to
load ourselves onto the trampoline so I
should fingers crossed be able to just
grab this definition copy paste I saw
what it did there
oh man bumming me out you're going to
have to believe me so at this point we
understand all of the different
transformations that go on in ctcl and
just in summary like I said my my major
point that I wanted to make in this talk
was so that you understood the
transformations that are going on here
so somebody asks you how do you get tail
call optimization out of a language that
doesn't have it will you tell them we
CPS because that makes the stack an
explicit thing that we have in our hands
it's a function it's a continuation
which is a stack awesome we thunk if I
our expression so that we can run a we
can run it step by step and we keep the
stack from getting too big and then
finally we throw it on a trampoline so
it does that run it bit by bit by bit by
bit until it's done okay cool so
actually at this point although my
manual trampoline failed because of copy
paste errors I can show you how CTC Oh
does it directly so you may have noticed
i've loaded into a CTC oak or line or
Apple and we can just define our tail
recursive factorial
that's the same definition we had before
now actually before I do that let's take
a look at how this blows up so we like
to see out killing me there we go we're
like to see see things break right so
this is a normal call to factorial start
the accumulator off at 10 stack overflow
so let's go back to our original
definition let's just throw it through
ctcl and underneath it's doing all the
cps the thunk of occasion the
trampolining for you let's try that
again we got a big ol number
now one thing you may be thinking well I
could have done that with just using
recur because it's just calling back to
itself so a more interesting example to
look at is these mutually recursive even
and odd so the idea here is zero is even
and it's not odd so we have these little
functions that call each other asking
well if it's not zero when we pass it to
even we subtract one and pass it off to
odd and ask if it's odd so if i see here
because i don't trust anything i'm just
going to write it directly and i think i
still have time
yes I do want through there thank you
Dan
we have to change this to false because
0 is not even and our recursive call is
to even okay everybody think that's
pretty a pretty reasonable definition
for my even my odd we can ask my even of
12 this is going to be really
embarrassing if it doesn't work a 12 is
true if we save my odd 12 is odd well
let's say we crank this up a little bit
uh-oh stack overflow error let's go back
to our definitions let's throw your ctcl
let's do the same thing to my odd bad
things would happen if I forget to do it
with my odd let's try that again BAM
okay so now we're all good we all
understand the basics we have CPS we
have sunk ification we have trampolining
we can tell people why it does that but
it's not all roses there are some costs
associated with this because the code
transformations that we're making when
we do CPS we create continuations out of
functions and it takes some time to
build new functions and we have to pass
them around where we weren't passing
arguments around before we have all
these thunks that we created when we're
running the computation step by step the
idea is we're doing it in a really tight
loop and we're just invoking invoking
and poking and poking but that's still
something that we didn't have to do in
the original code so slows it down a
little bit plus there's this idea of
using stack versus heap memory if you
look real hard to the cps transformation
you see that every single function
definition whether or not its tail
recursive or not becomes tail recursive
once you see PS tit and so it looks like
i just got tail calls for free well no
you've traded the stack memory that you
were using for your non tail calls for
heap memory because you use heap memory
for your your functions and so
eventually instead of getting a stack
overflow you will get a heap overflow if
if your programs are written in a
primarily non tail-recursive style so
that's why CT co is intended for I wrote
something in a tail recursive manner and
you understand tail recursive manner if
you've read dan Friedman's books the
little schemer and the the season
schemer and all that and recursion is
awesome and you use tail recursion CT
CEO will be your friend but if you've
written a non tail recursive program
it'll help you out a little bit but it
will eventually blow up so some stuff
that I've been working on just go over
these kind of quickly so we can possibly
have some questions in the last couple
of weeks I added an auto recur if I pass
so like I said with the the version of
tail recursive factorial that we looked
at you could achieve the same thing by
just sticking a recur in there instead
of doing the thunk ification and
trampolining and so CTC oh now just
looks through and figures out oh you're
just calling back to yourself so I'll
insert or occur instead and I've seen a
fair amount of speed up from that there
was also this problem that I had for a
long time where you may have noticed
that when i did my function definition I
overloaded it because when you do the
CPS transformation you go from whatever
a number of arguments you were passing
around to that number plus one because
of your continuation that you're passing
around and so you had this clash between
the when you were trying to call into
the original version for say
frustratingly so let's take a look at
something really silly
the problem that we have here is that
when we see PS the first arity now we've
suddenly got two bodies one is trying to
take a continuation in the second spot
and the other one's trying to take an
actual value so the solution I came up
with was inspired by Alan diaper its
trick of attaching metadata at all the
thunks so every continuation that's
created in CT CEO is tagged as a
continuation and so what you end up
doing I heard one stack that's hilarious
so what you end up doing and I won't go
through this the full transformation you
essentially ask you ask is that second
argument a continuation and if so you do
the code for the CPS version of the body
preceding it and otherwise you call into
the original version and it took me a
little while to come up with this
solution but I was pretty proud of it
and like I said it was inspired by Alan
diaper so I think that's most of the
content that i have just finishing up we
have some future work that I want to
talk about I focused on getting the
correctness of this language and so
there are some some glaring omissions
and some of the the expressions that
it'll accept so that's a small piece of
work that I want to get done soon
there's also some talk of getting this
ported to closure script because people
would like to be able to play with it
there and there are some issues with the
current implementation that only work on
the JVM version of closure I'm also
signed up to write a tool CPS library
because apparently people think I'm the
CPS expert in the closure community so
that should be coming around sometime
early next year and finally I've got
some other ideas for optimizations to
try to make see TCO faster including
coming up with a way to do minimal thunk
ification which I don't really want to
get into now if you want to ask me about
it afterward that's fine so the basis
for a lot of this work was the first
order one pass CPS algorithm by Olivier
Don B and I've heard reports that if you
look at the ctc o code and you look at
the paper side by side you kind of see
how the CPS transformation falls out of
it
the other thing of course I pulled most
of this work from using parentheses to
transform scheme programs to see or how
to write interesting recursive programs
in a stack-based imperative inhospitable
host which was with written by Ron
Garcia and a whole bunch of people
including Dan Friedman and that was the
reason why he was able to say to rich
last year I think I know how to get
constant space tale calls out of closure
so just a few thank yous to thank you to
Dan Friedman for giving me all the ideas
and all the foundations for this thanks
to Alan diaper it for being the only
contributor thus far on CT CEO and
inspiring some really interesting
solutions in there thanks of course
David Nolan for helping shore up my
obstinate scheme earnest into the
closure realm and thanks to all the con
Jorgen I zehrs for letting me infect
your world with continuations
and what kind of compiler writer would I
be if I didn't have a slide full of
numbers at the end thank you guys for
listening</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>