<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Clojure DSL for defining CI/CD orchestrations at scale - Rohit Kumar, Viraj Purang | Coder Coacher - Coaching Coders</title><meta content="A Clojure DSL for defining CI/CD orchestrations at scale - Rohit Kumar, Viraj Purang - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Clojure DSL for defining CI/CD orchestrations at scale - Rohit Kumar, Viraj Purang</b></h2><h5 class="post__date">2016-12-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/T-3dPkdG_qc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Viraj Goran I I'm gonna give this
talk on a closure DSL for defining CI CD
orchestrations something we use at
Oracle where I work I have my colleague
Rohit Kumar who's gonna be helping me
with the second part of the presentation
and we work for a central engineering
team with an Oracle we do we do
basically services that improve
developer productivity and you know
enhance quality of a bunch of stuff that
we do as developers we quite centrally
focused on continuous integration and
delivery a lot of DevOps II stuff so
yeah so you know I'm a little nervous if
I do stuff that I'm not supposed to do
that I hope you guys are okay with it so
this is a safe harbor statement I just
have to show as a employee and I'll
quickly go through the introduction so
we go through the motivation of why we
did this particular thing there's a
detail about orchestration service for
defining the CI CD pipelines that we'll
go through we'll discuss the
architecture a little bit and then
Rohith will discuss the more specific
details about the DSL and what our
experience has been in terms of just
using closure in general you know we
started off at least I started off as a
Java developer he's one of the few I
guess in the world who started off on
closure so he's he's got a very
different perspective on closure so just
go to the next slide
so there's some history behind why we
did this particular product we have
diverse distributed systems with lot of
scale so when I'm talking about scale at
Oracle we're like we have an artifact
turi instance which is probably the
biggest one in the world at this point
of time we have about hundred terabytes
of installers and a bunch of other stuff
that's stored in it and that's just one
of the systems that we typically work on
there's like hundreds of other things
that typically get added as a part of
our development process so if we are
doing CI CD if we are doing any Jenkins
or Hudson or team site or team city jobs
they translate to pretty long pipe lines
and those pipelines they can span like I
don't even count the number of
development teams that are out there
they're pretty diverse there's stuff
that happens on node dot GS there's
stuff that happens on Java closure you
know pretty much any technology you can
think of and the development tools get
burden so you know like if you really
want to stress test any piece of
software that you made send it to us we
will break the hell out of it it's it's
that bad and the scale and the
visibility of any one of these pipelines
is a little hard to do because there's a
lot of things that a lot of like
heterogeneous things that you need to
look at and so visualizing them across
the board becomes a bit of an issue and
that those are the you know the four or
five basic points that we started off
when we started doing serious C ICD from
a corporate perspective at Oracle
so when we began CI CD you know the
biggest question we had was are we gonna
be able to scale we started off with one
Hudson instance we also have Jenkins in
those in the play and the answer was no
like there were about 100 teams on that
particular Hudson the problems were not
limited to what I'm going to talk about
but you know two different teams want a
different version of the Installer
someone wants to install something so
the Hudson has to be brought down and
now you have a hundred teams that are
not working at the same time so we took
our next logical step which was to
distribute it across different instances
of the CI CD or tool that we were using
and it was all good the only problem was
how do you link anything from one system
to the other system so if we have a
particular pipeline that goes from one
Hudson instance for the Blodgett server
and wants to do something for toppling
which is another product that they had
how do you make sure that you can
actually trace an issue that happened on
a tarp uplink server back to the logic
server that's out there and you know
even if you were to somehow figure out a
way of doing that you want them to be
able to visualize that not everyone is a
developer not everyone wants to actually
go on log onto a box see what's going on
so we had to come up with something that
would actually work
this is you know yet another slide that
describes the different things we you
know different stakeholders we typically
have so there's developers which is
fairly obvious there's darken
translation which is so if you have
manuals that we want to expose to a
bunch of customers for you know
different products that we sell we have
to make sure that they're available for
each and every different language so
that's what Dakin translation is there's
a patching framework that we have which
manages different kinds of patches that
we send out for different products and
they have a separate kind of requirement
where the servers that they're on need
to be more dependable they cannot be
done because if you are unable to
deliver a patch to one of our customers
it's you know it's money lost then
there's the problem of global scale so
our data centers are pretty much
everywhere in the world and we have to
make sure that whatever we have whatever
pieces of you know build pipelines or
testing pipelines we integrate they're
able to scale across different data
centers then there's obviously other
things like cloud that we deliver to
there's on-premise releases that we
needed to manage and then there's the
multiplicity of different CI CD products
so we we currently support jenkins we
support hudson we support different
versions of them and we also support
team city all of this you know the
combination the fact that we had diverse
set of stakeholders it created some
situation for us which was hard for us
to solve using you know direct like code
to code invocation and so we had to
switch to something that would allow us
to orchestrate across all these diverse
set of systems that were out there and
so we came up with this product called
carson and you might ask what carson
really stands for and it's a Downton
Abbey character
just supposed to be a butler of Butler's
and the play was that Jenkins and Hudson
have Butler's and this is like the
butler of Butler so Carson seemed like a
nice name to give it was actually done
by a colleague of mine who now works at
atomist his name is Jim Clark he was
also you know responsible for starting
this project initially and very quickly
it became an event-based Orchestrator
which allowed us to integrate all of
these different components that are out
there so if you were to just go
underneath the hood and look at what it
is it's an orchestration engine it
allows you to orchestrate workflows
across you know diverse distributed CI
CV systems it's even driven and the even
sources can be fairly dynamic and like
fairly diverse so we have at the last
count probably six different source
control management systems multiple you
know Jenkins Hudson instances test tools
the f-test farms mezzos kubernetes we're
using pretty much every one everything
that's out there and the events can be
consumed from messaging systems like
ActiveMQ or Kafka or rabbitmq or you
could just send them on web hooks that
are a part of garcin and what that
allows us to do is basically have
systems that would normally not be able
to send a message to a to a messaging
system like activemq could just send or
post a message to a HTTP endpoint and
that would be the end of it now there
are a couple of terms that I'm gonna
introduce right now which will be quite
useful when Rohit starts talking about
the DSL in more detail so orchestration
or a pipeline or a workflow will be used
interchangeably and
the instance or an orchestration
instance is the same as a single run of
a pipeline and the pipeline is you know
pretty much the same thing as what you
would expect on Jenkins or Hudson it's a
bunch of jobs that are strung together
the only difference here being that the
jobs can be from different systems it's
not limited to just one system so since
we are talking about events this is just
a simple event we don't enforce any
schema on the events and at least at
this point of time we down it's fairly
simple like if you look at a Jenkins
event
it contains or you route Qri which is
the URL of the Jenkins instance what
kind of an event it is so on finalized
is when the finalization happens on a
particular job
then there's job specific details like
job number status name and the
ordinality and then there is a map where
we have key value pairs now this can be
different for Hudson this can be
different for pretty much like whichever
job system we are planning to use
and the idea here is that we can curate
the event streams the job systems like
pretty much anything that is needed for
the for the pipeline
and here I'm gonna just talk a little
bit about the architecture so you can
see these different components each one
of them is an event stream so Hudson and
Jenkins are you know fairly obvious
these support measures and docker
artifactory events so anytime there is
there's an update or there's an addition
to artifactory we are able to emit
events from there and then we have more
internal tools like test farm and
thoughts and translations something that
I talked about in a previous slide
source control management systems all of
these act as event emitters and then
they send messages to the messaging
middleware and we currently support all
four of these actively I guess only you
rabbitmq and Kafka but Cupid in ActiveMQ
have been supported in the past and the
Carson Corps itself is it consists of
these six or seven different components
there's job systems so each one of these
components that you see on the left side
as even streams are available to Carson
as a job system and for you to be a job
system there's only two things that you
really need one is that you should be
either able to emit the event to us or
and you should also be able to provide
us an endpoint where we can actually
invoke you back there are variants of
this where you know there are some
things that are only vent emitters and
there are some things that are in that
particular sorry there are things that
are only event emitters and then there
are pieces that only have endpoints so
we just send specific calls to them but
general idea here is that if you're a
job system you should give us both the
capabilities otherwise we'll have to
pull or do something
similar the DSL which is the meat of
this engine is a combination of our
collection of handlers its event
handlers and orchestration server is
where these handlers are loaded from the
database the system started off as a
provisioning engine where we could
provision multiple masters or create the
integration between them so there's a
provisioning aspect that is available
and then we have a REST API and a UI
fairly basic but something that allows
us to do the job and then there are
value-added services like configs
visualization and analytics we store our
conflicts we've externalize them into a
HCD database the visualizations are
actually done using d3 and analytics is
done currently using angular there's a
bunch of web pages or screens that we
have which actually do that but there's
an additional element where we depend on
the BI services that are offered by
different Oracle bi products the simple
idea here is you send an event and it
could be sent either to a web book or
through an AMQP broker this animation
just shows the aspect and wherever there
is an endpoint we trigger jobs using the
REST API so for example if it's a Hudson
job there would be an endpoint which
would allow us to trigger a job on
Hudson similarly if you're
if you're sending the message to a
webhook the concept is still the same we
just send a JSON payload to that
particular endpoint and that triggers
the downstream workflow and just to give
you an idea about the scale there's a
significant volume that we typically
drive during the day there's about
100,000 events that that are triggered
during the day and these events can be
Hudson or Jenkins events there should be
tests or farm events well you know if
the tests get executed depending on the
life cycle of those tests each one of
them emits a different kind of an event
we share slaves between our Hudson and
Jenkins instances we use measures for
doing that but we have close to 600
slaves so you can imagine even if you
have 10 jobs per slave that's a fairly
high number and we run about 1,800
orchestration instances per day they're
500 different orchestration definitions
that are currently available and the
number is only going up so that's pretty
much it from you know my perspective I
think I've given a general idea about
the architecture of the two he's gonna
just go into the DSL specifics and a
little bit about closure why we chose
closure and what we are doing with it
right now
check so now that barrage has covered
most of the architecture and the
motivation behind you know why we
created the service I'll be
concentrating on the DSL itself and the
closure aspects of it
so the domain-specific language in our
case the domain was creating pipelines
that span these diverse CI CD systems so
to create the DSL we defined some of the
basic primitives for the DSL now what an
orchestration is is is just a namespace
so it's loaded it's a closure file you
use the DSL to to define your
orchestration and it's loaded into a
unique namespace using Create NS and
Jensen so it gets its own unique
namespace and all the constructs from
the DSL are available to it so an
orchestration essentially just to
reiterate is a set of event handler
definitions and the DSL is able to
create those event handler definitions
it is represented as a directed acyclic
graph and again an instance which is a
single run of the pipeline is a sequence
of transitions or handler executions now
what is the basic event handler
definition that we provide most of our
basic event handlers are composed of
three parameters the first is the event
or the event channel or a or a specific
job so every handler is activated when
an event arrives and matches the event
that you declare in your handler the
second element is predicates which are a
list of functions that are designed to
work on the events so they if you expect
them they are functions that take a map
as an input and they are designed to
work on specific as well as general
event types actions are where we further
dispatch you know dispatch tasks or
submit jobs
and that's how the orchestration of the
workflow proceeds forward so for example
submitting a Jenkins build or submitting
a message task so just a little bit
under the hood what happens all of these
handlers so when you create our
orchestration it results in a registry
of handlers for that specific
orchestration there's no memory
footprint whenever when an orchestration
instance is running the the handler only
gets activated when a particular event
arrives and it satisfies the predicate
for a specific handler so just just to
walk you through the workflow an event
arrives from the messaging layer the
engine finds all the handlers that are
that are correlated or waiting for that
specific event and then it runs the
predicate functions to check if they are
logically true and if it is then it
proceeds to the actions right now these
are the basic handler types that we
support now because an orchestration is
just loaded into its own unique
namespace with the entire DSL available
at its simplest it's just a closure
module and you know the simplest
orchestration that you can create is
just just a comment just noting anything
that can be loaded using load string you
can do that so these are the primitive
DSL handlers with which we build the
entire DSL you can compose all of these
together you can use these as templates
to create further DSL elements so just
it just to briefly give you the
signatures the the API signatures of all
of these DSL macros def start expects if
you look at each of them they expect in
in almost all of them they expect three
things the event or a particular job a
list of predicates and then finally a
body which corresponds to actions let me
briefly show you an example so def start
is a handler designed to
is designed as an entry point to your
orchestration so this is when you your
specific run of your oxidation can get
triggered so deaf start is a indirect
trigger an event arrives it ends up
triggering an instance of an
orchestration if you look at the botton
there's a deaf trigger as well which
which is a more targeted endpoint so
given an orchestration you wanted you
know you want to only trigger an
instance of the rock that orchestration
in that case this is what you use so in
that case there is no event channel it's
just the channel is the aux pacific
channel that means when i talk about
channels it's it's it's the event stream
so the channel all events correspond to
code or async channels and and that's
how they the handlers consume them so
deaf start is an entry point handler
that is more that is create that is that
is suitable for indirect triggers so for
example you you are getting events from
a github repository this this this is
the form you do so so if you look at it
from the first element the from defines
the event channel in this case it's a
channel called gate it corresponds to a
named code or async channel called gate
so an event comes in and then the second
element is the list of predicate so the
list that you see here is two different
DSL predicates predicate functions and
the first one is simply checking in like
if I just say it in words it's checking
whether the organization for that github
repository on the central gate repo is
my OGG and the second is checking
whether the project for in that SCM
event is for the gate project called
Terminator bail right so so if you look
at these predicates the you know again
as a previously mentioned the spec is
that it works on it's applied on the
event so we would apply get org is equal
to my org that results in a function
that expects just one argument which is
the event in the context so this returns
me a function I run it on
the event that came in on the gate on
the gate channel events again are maps
right so it's it's very easy to just
filter based on them get project again
does that it is applied on the same
event that came in and then we logically
and them together if all of that is
successful this you proceed to the
action so you you trigger the callback
in that sense and and yeah so the den
section is where the actions are this
one just has one form here most of the
the action block is an implicit do do
blocks so you can you can define
multiple actions you can trigger
multiple jobs you can dynamically
trigger jobs as well which I'll come to
in a bit but this is a very simple
example where an STM event comes in you
trigger the build the build CI job for
that particular project the key things
to notice which I'll show you here is
yeah just to reiterate the handler is
def start the the channel is the event
channel these are the predicates and the
action block is here right now now let's
take a look at one of the one of the
more common handlers that stitches the
pipeline together which is a deaf
transition so this this you usually end
up using once you all have already
defined a deaf start and a deaf start
has already been activated via in a via
an event or in a more targeted fashion
so so in the previous slide we
introduced you know the concept of
handlers but what I try to focus on here
is is some of the terminologies again so
if you look here in this case the from
is is is a label it's not an event
channel it's it's a more correlated job
label so so when you triggered a
particular job here you you added a
label call ID build for that job and
you're able to use it in in your house
as you as you know as you go through the
pipeline now
that's one of the things that we check
which is that these labels are unique in
the context of a specific oxidation
because they they correspond to node
names in your directed acyclic graph
right this this is the thing that is
used this is the glue that stitches the
whole pipeline together so we do
compiled time checks when the handler is
registered that these are valid now of
course some in because this is just a
closure module and we are not blocking
you from creating you know running
closure in here there are cases where
there needs to be at compile time we do
not know the job label or the
correlation IDs okay just again same
same handler same concept same concept
of three different requirements now now
our orchestration as I previously
mentioned is designed for directed
acyclic graphs so it's something that
proceeds forward so these are you know
these are possible like SS these are
possible expressions so we use closure
artwork to be able to you know construct
the graph at static time as well as for
a specific instance we are able to you
know based on the transitions that
happen we are able to construct the
graph so very simply if you look at this
handler in terms of what it corresponds
to as a graph so ID build happens and
then the then we start a job called test
job one we also start a job called test
job two both of them happen in parallel
and the DEF transition handler is the
one that ends up you know as defining
the edges between these two nodes if you
look here there is also this this thing
called in-group which you can use to
group add labels over groups of jobs
which which helps and in terms of like
dynamically dynamically starting jobs so
if you're not sure of the number of jobs
you'll start for a specific instance but
you want to respond to the whole set of
the jobs
that's what you'd use just proceeding
through quickly through some snippets
off the DSL just just so that you know
it it registers so this is another DSL
and when the first one where you're able
to trigger another trigger the an
instance of another orchestration in
that same oxidation server or or another
server all we all we require because
orchestrations are also generating their
own internal events you're able to use
cast and orchestrations themselves as
any other kind of charge system so same
thing the job label predicates action
block right so we triggered we we call
another orchestration as an embedded
orchestration in the main ox station
let's say you want to build the UI
pipeline right you want to test that and
then the second handler is when that
when that UI orchestration completes so
all this the the fact that we are able
to use the label in another handler that
is where the oxidation engine is working
it's it's doing the job of correlating
and even that comes in with with a
particular job label in a specific
instance and it's you know activating
the specific handler so in this case
yeah so once the UI orchestration is
complete promoted promote the original
artifacts into a different release
repository on artifacting so this
promote is a specific artifact reaction
so just just an example of the kind of
action helpers that are provided by the
DSL
again more components right more more of
the systems that you're able to dispatch
actions to so let's say after you
promoted your artifacts you want to you
know to start your docker container or
run your docker container on on a mesos
resource right so start containerized
task is one of the job dispatcher
functions that we provide again if you
if you've looked at any of these job
dispatcher functions they all the the
spec for them is simply they all end
with a job label so they all expect a
job label that you correlate that
particular action with and the other
thing is that it's designed for
asynchronous operations so if you're
calling an API that's that synchronous
it doesn't make sense to wait for
something to happen right so again here
a mesos task config is a dsl element
available to you to get configurational
elements given a key env is a dsl
element that's again very common which
is to access so every instance of your
pipeline has a map of metadata that is
available to it so you can attach
properties it's just a closure map or in
the database just a JSON so you can yeah
so a previously defined you know in so
just to be able to use the mesos cluster
you you get access to our mesos cluster
that you're authorized to using the
config dsl element and you you provided
a task info object the meso starsk in
for protocol that you that you've
previously defined in your orchestration
and and the Carson mesos module which
which is able to register all of these
frameworks given a particular task and
the missile's
cluster URL it's able to submit it to
that and it's able to generate the
events for you when the meso starsk is
complete right because it's it hack acts
as a registrar of mesos frameworks one
of the other common handlers that we
have which is def listener which is
designed to be at the same level as an
akka station which but but it involves
not having jobs in it so you it's just
handlers that don't end up triggering
jobs but for more synchronous operations
and things like that so for example if
an instance of your if your
orchestration fails which is arc fail is
a code or async channel that gets events
generated by orchestrations so in this
case failure events and then you check
whether for for that specific
orchestration you know JIRA is enabled
so you can create a JIRA issue if an
instance of your accusation is failed
right again yeah now just to reiterate
so these were simple examples you know
where we were able to dispatch actions
on some of these diverse systems but and
it involved CICE applications right but
you can imagine using this oxygen DSL to
create any kind of workflow you know
things like a workflow to grant
privileges to someone in an
authorization module but an ETL workflow
right so but it's it fundamentally makes
sense and it's useful when when you want
to create workflows that are comprised
of jobs like you know tasks that run
asynchronously on other systems right or
resource intensive tasks Carson itself
has an executor so you can dispatch
tasks and actions on the on the Carson
orchestration server but we try to you
know keep that as the domain of all of
these job systems right so so yeah just
to reiterate that orchestrations can can
you know can be anything not just C sed
pipelines of course some of the systems
have very complex state diagrams which
we are not able to map into a directed
acyclic graph so for example JIRA issues
you can go back you can go you know
close reopen close reopen closing open
things like that and that kind of MUX it
Allah okay
so just stepping back a little and why
we use closure right now this is this is
kind of like the elevator pitch for
closure
so I just you know cycle through that
it's Lisp and we know lisps are kind of
well-suited to create dsls some of the
key things that we found useful for
orchestration owners is you know Java
Interop is always available to you so
even if you know you you're not sure of
closure or if you you know if you think
the DSL is not a language to do
something you can can use that we use
protocols heavily the job systems that
we previously define there which are
integrated into Karsen are all protocols
so to be able to define and integrate a
job system into Carson as viraja had
previously mentioned we we all we need
is a REST API or an endpoint that we can
call to be able to dispatch jobs right
and we need a event schema so the
protocol has all of that what is the
event schema that we expect from a
particular job system and things like
that and we use macros and multi methods
heavily now I think all of these
elements were some of the like some of
the key advantages that we found in
using closure to create the server-side
we kept it in a language like closure
because we thought because the systems
were changing and because we didn't know
what what kind of systems would be
involved we would be involved with we
kept it in a language like closure so
that a DSL could it evolve easily as as
newer systems came in right so just just
just a brief like example of what is
what here so def transition is a macro
successful some macros are what we use
to create some of the basic DSL
syntactic constructs obviously all of
these macros can be composed on top of
features so you can create def
transition Myon right that that uses def
transition internally but it looks very
different right you can make make the
DSL you can compress the DSL so like so
that it's just one line instead of
so it's up to you an orchestration
developer can do that multi methods are
what you know keeps our DSL concise so
for example just looking at this multi
method which is successful now in words
just it's checking if a particular job
if it has a concept of success is
successful and we use multi method here
because we are able to use the same
predicate function across any type of
job any type of job or any type of event
that supports the concept of of a
success status right so because the
events are Maps we are able to dispatch
easily we are able to create the multi
method dispatch of functions easily and
so we use multi methods heavily to be
able to you know to be able to keep the
DSL very concise so a person who wants
to define the orchestration doesn't have
to know closure all that well
okay again this is a macro this is an
action helper that you know is
dispatches jobs and again the signature
of any job dispatcher is that it expects
a unique job label in that in the
context of that oxidation right and
these these are all the you know these
are the small number of event handlers
that DSL is composed of that's it's very
simple and then you can use all of these
as templates to you know build your own
bespoke DSL handlers as a sign some of
the capabilities that a DSL provides you
right right just functions that you can
use in your in York station or in the
action block of a specific handler so
you get a rich set of action helpers
things like you know repeat and resubmit
jobs until a certain condition is
satisfied right so what this would do is
the orchestration engine would submit
all the jobs and tasks that were started
within this rapper and if they failed it
would you know it would keep doing that
be submission based on the behavior
configuration you've configured so in
example here you can you know resubmit
in a seal more twice until it's
successful right things like that again
timeouts any any job started within this
rapper if they exceed the duration of
the timeout configuration you can time
they now tank them out
throttling protocols so you can throttle
your orchestration I'm just giving you
the basic protocol definition here but
you know upload a throttling is what
when do you throttle and when you
release the throttle right that's all
the protocol is comprised of so that's
what is available here so we provide
common implementations of that for
example run only one instance of an
orchestration given a condition function
right and things like that but you're an
oxygen developer is free to you know
create Rifai these protocols or create
implementations of these in his
orchestration module right so trivially
like you can provide an implementation
policy / orchestration or you can
provide a global one which is
inheritable by all of your
orchestrations this is one of the key
things that the oxygen we DSL that we
heavily use which is
parallel and dynamic job dispatching so
so when you have workflows where you
don't know what how many number of jobs
you're triggering in us for a certain
block right we are able to encapsulate
that into you know this concept that we
call a multi job which is you know which
is a set of jobs which which is only
instantiated at runtime so all the all
we are doing is we are giving a label to
that set and we are able to use that
label again because the label is the one
that allows us to create a deterministic
graph for the for the oxidation so in
this case for example we are you know
start jobs just looking at this you can
see the the you know what the definition
of star jobs would be it's like a let
it's like a sorry two sec so it takes a
list and over the list it it runs all of
the forms in it right so given a jobs
list we start each of the jobs in there
and then correlate that whole set with
an ID called jobs list right and we can
do skip jobs so given a certain
condition that happens only at the
instance run time we are able to skip
similarly you can do def sync so if
you've started three jobs and you want
to wait for all three of them to finish
that's what you do we have a vault which
which is an implementation that uses
ideas from the crypto world example in
the programming closure book that is
available to use for for any
orchestration so all your secrets can be
there and like I previously said you can
trigger other orchestrations as well now
since orchestration is code and you know
developers want to test their
orchestration and their workflow we
provide a test harness which you know
which allows you to create event mocks
so you don't have you don't even have to
have any jobs created or any systems
available to you or any resources
available to you but you can still test
the wiring of your workflow right so you
can still test that here and if an event
came in this handler should have been
activated
this happened just happen and finally
the pipeline ended at a certain point so
you're able to mock those events I
didn't mention it here but you're also
able to mock the dispatcher functions
because when you're testing you don't
want to actually trigger a Jenkins job
and things like
and obviously you can assert on all of
these we do provide a line engine
template as well as plugins so if you
put this in your profile start clj you
can you can import the Carson DSL as a
library as well as the orchestration
engine and you just do line new
orchestration your project it creates
orchestration template for you using the
line engine template and it creates a
test template for you as well to test
that specific orchestration right all
you need is probably a local DB but even
that is not needed because there's an
in-memory DB that's that's so that was
on the DSL itself now on the oxygen
service the application obviously you
want to see all the instances for your
pipeline you want to see all the jobs
that ran in them so we have rest APIs
for that we have dashboards that that
show you that yeah I just want to
quickly say what we are looking to do in
terms of the future of this this project
you want to open source it so we can get
more community health security and
reliability because the Carsen
orchestration is it is a closure module
there is sandboxing limitations someone
can do system / exit in there which we
want to avoid but you don't want to
blacklist too much because you is still
one the power power of closure to be
available there so yeah so inspection at
the load a compile time of the
orchestration runtime detection of
issues so that if someone ends up
creating an event handler that just
loops around you want to be able to
detect that we want to try out closure
to expect to to be able to specify all
of our handlers as well as job systems
so that it's more deterministic and we
are able to test these workflows
automatically as well and for closure
newbies we want to condense some of the
DSL constructs so it's for simple
pipelines you can do that as well as
provide like a UI drag-and-drop helper
yeah that's it I mean just to summarize
you know closure has been fun for us in
terms of creating the DSL and hopefully
we were able to convey
our enthusiasm using closure at Oracle
thank you so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>