<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Declarative Deep Learning In Clojure - | Coder Coacher - Coaching Coders</title><meta content="Declarative Deep Learning In Clojure - - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Declarative Deep Learning In Clojure -</b></h2><h5 class="post__date">2017-10-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1JWcyMag1e4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone my name is uh
willhoite and the title of my talk is
declarative deep learning in closure
we've had amazing deep learning talks so
far this cons and I really hope that
mine kind of contributes to your
understanding of the topic matter and
really is enlightening so just start you
know this is me kind of a nerd
I studied neuroscience in school I now
do data science and other science II and
data things at work and obviously my
tool of choice is closure
it makes my days go by really quickly
you know I have three points in my day
right when I wake up when I have lunch
and when I go home the rest of my time
has just spent in the world of closure
having a great time solving problems and
I get to solve those problems in an
amazing company called yet analytics
we're located here in Baltimore about
five to seven blocks away and in this
picture you might recognize Milt reader
who gave an amazing talk yesterday about
how day Tomic and the thoughts contained
within day Tomic really changed the way
we think about problems and how we solve
them so we're going to step into the
matrix because when we're talking about
deep learning there's no escaping
matrices right they are essentially
where the learning happens and how the
learning happens it's all matrix
multiplication when you're algebra all
those fun things and so the question is
then how do we how do we manipulate
these matrices in order to induce
learning and all it comes down to is an
optimization problem right we have some
error which is a measure of what our
network tells us is the answer and what
we know the answer is and we can kind of
think of that as creating this three
dimensional error space which we see in
the graph on the top and so all the
optimization algorithms do is they go
from the red peeks of airspace and they
try and climb down that hill and find
the blue valleys and so that happens
through optimization like I said and
linear algebra and that's not really
that interesting to be honest right it's
an iterative process we're just trying
to climb down a hill and make sure our
net our next step is not in the wrong
direction so let's get to a topic I find
more interesting which is you know how
does our brain actually learn and how do
we learn and in order to kind of get an
understanding or the necessary context
let's start with neurons the building
blocks of the brain so we can see here
that we've got two neurons one on the
left and one on the right that are
talking to each other
the one on the left is known as the
presynaptic cell whereas the one on the
right is known as the postsynaptic cell
the presynaptic cell sends an electrical
message through an axon which you can
see right here to its neighbor and that
is how they communicate and in order to
get into a little bit more detail what
actually happens is as that signal
passes from like here in the cell body
all the way to the end of the axon it'll
actually stimulate the end of the cell
and cause the cell membrane to change
and to release these chemicals called
neurotransmitters neurotransmitters come
in various shapes and sizes have various
effects and that's a rabbit hole I could
go down but I'm not going to the only
thing that you need to know is that
these neurotransmitters travel across
that little gap of space from the
presynaptic cell to the postsynaptic
cell where they then bind to dendrites
on the postsynaptic and cause a formal
reaction so what happens is as those
neurotransmitters bind we see this
effect where it changes the membrane
potential of the postsynaptic cell and
once that membrane potential gets to a
certain threshold we see this massive
increase in membrane potential
which is just that electrical signal the
action potential or the form of
communication between these cells after
the action potential fires off there's a
restabilization period in which the
membrane potential drops down before its
resting level and enters this period
called the refractory period this is
important because during this time no
other action potentials can be generated
and this kind of sets up the mechanics
of how communication actually happens
and so thinking of just two cells like
you can't really do much with that
there's not much that can be extracted
from that but when you network these
things all together with n different
connections right you now have a very
chaotic system where emergent behavior
starts to come out of it where that
emergent behavior you know is us right
that's our thoughts those are our
memories those are you know our
perceptions of the world and then the
question becomes well how do these
neural interactions how do they actually
lead to learning and this is a problem
we've been tackling for the last sixty
or so years and we still don't have it
fully right but we do have a decent
understanding of kind of the underlying
mechanics and there's two forms
there's associative learning and there's
non-associative learning associative
learning was first kind of proven in
1949 by this guy Donald Webb and he
basically set up and theorized and led
to the experiments known as classical
conditioning so during classical
conditioning two cells are two stimuli
are paired together and they're paired
to a certain reward so an experiment
that is referenced a lot is classical
conditioning in which a dog was trained
to salivate at the sound of a bell
because the experimenter ring a bell
every time it was feeding time and so
kind of the classic way that this is
usually described as cells that fire
together
wire together because when they fire
together there's an actual change at the
dendrites here were more added so that
way this interaction has a more
pronounced effect and to give some more
perspective on this we are going to go
and watch Jim and Dwight actually kind
of demonstrate this unless there's no
volume okay
well unfortunately I didn't get the
audio working properly
but Jim trains Dwight to expect an
Altoid every time he restarts his
computer so at the very end what ends up
happening is Jim you know restarts his
computer and Dwight just reaches out his
hand and she was like well you know what
are you doing and he goes up my mouth
feels weird yeah oh you know there's the
classic Jim smirk
but so that was associative learning but
then I said there is two types of
learning right
there's also non associative and this
was kind of proven in a very very simple
model it's the sea slug it's got a
scientific name that I can't pronounce
you're not going to care about so we're
just gonna call it the sea slug because
that's what we know if I cut essentially
what matters is it has this Gill which
is how it breeze right and whenever you
touch this part of the animal there will
be a reaction in which the Gill
contracts and so this only led to the
discovery of habituation which is where
repeated a single stimuli when it's
repeatedly presented the effective it
will actually get diminished over time
so you can see here in the top that you
know we we touch it there are some
action potentials that get fired off
there's a response by the neuron that
actually controls the muscle and we we
see a Gill retraction and then after her
bitching so after repeated you know
touching of that part of the animal the
siphon we actually see a decreased
response of the motor neuron and then no
retraction actually happens and so
that's one form of non-associative
learning habituation there's another
form of habitue excuse me of
non-associative learning and this is
called sensitization the way that this
was shown or experimented on or
experimented with to prove the existence
of the experiment consisted of the
experimenter applying a electrical shock
to the tail of the animal so what we see
at first is a little bit more pronounced
of a reaction just because you know the
animal is getting shocked right like
that's gonna trigger that same mechanism
but after repeated shocks what actually
happens is you know nothing about the
shock state are changed it was the same
shock every time but after being
presented with that shock enough time
there is actually an enhancement in the
response that we see and can measure and
so the interesting thing is these
properties can be combined and can work
together so we see from trial 1 to 13
you know as we touch the syphon the
actual magnitude of the gill contraction
or that response goes down but then a
trial 14 the shock of the tale and the
touch of the siphon get paired and we
see almost a exact response then when we
saw during trial 1 and so what this does
is this really kind of highlights the
basis for how or how our memory works so
associative plus non-associative
learning allows our brains to create a
stable representation of the world so
that way we can have expectations we can
predict what might be coming next and we
can react to things that don't meet our
expectations and so this is what allows
humans to continuously learn throughout
life without the cost of losing
information just because we learn a new
fact does not mean that we forget an old
one and that's known as the stability
plasticity dilemma and it's amazing
right because as we'll see in future
slides that's not always the case and
other learning models but kind of prove
my point about attention and stable
models the last slide this one did that
catch anyone's attention was anyone
expecting that you probably weren't and
that's why it kind of like grabbed you
at least for a second right and that
that is what's so powerful about how we
learn and how we can focus on some
information and leave some other
information out and in the mid 60's to
late 60s there was a model of memory
that was developed which basically
captures that right so we have sensory
information coming in we attend to the
parts of it that our novel or that are
worth paying attention
and that gets stored in short-term
memory which is also known as working
memory it's what you experience in in
than now right and the information that
we're storing there can be converted
into long-term memory for long-term
storage via rehearsal or you know
repeated exposure to it
and that long-term memory is then
queried for and used when we're trying
to think about things or remember them
and it's also used to identify and do
pattern recognition on incoming stimulus
so that way we can have we can recognize
things that come in and use our previous
knowledge to determine how we react to
them right so that way we can
continuously learn and build upon what
we have already learned or thinking
about this in another way we have the
part that works when you're at your desk
and a part that's happening when you're
in the hammock so this kind of brings me
back to traditional feed-forward neural
networks because feed-forward neural
networks suffer from massive forgetting
they once they're trained on something
they can be great at doing that one
thing but you cannot train it to then do
something else without it forgetting
what it already knew so I can't train
this model to identify cats and then say
okay well now analyze this time series
it just it's one or the other and that's
a limitation but that's fine right like
these models are still amazing can still
do amazing things the you just need to
be aware of the limitations when you're
using them but not all models suffer
from this problem back in the 70s and
since then there has been this model
called the adaptive resonance theory
model which was created by these two
people Steven Grossberg and Gail
carpenter out of the University of
Boston and it tries to mimic the way
that our our memory actually works and
so in brief what happens is we have in
four
that gets encoded here and that's like
our typical input at this f1 layer it
then gets compared to categories the
model has already learned in the f2
layer and if there's a matching we enter
into what's known as a resonance state
which means everything's good
there's nothing that we really need to
pay attention to here right we already
know it we can obviously refine our
understanding of it but that's kind of
that's the use of that but where it gets
interesting is when there's a mismatch
right because this system can then
stimulate the f2 layer in order to look
for a new category to match against or
if none of the categories actually match
to create a whole new category that
represents this incoming data and so
this is what kind of gets around that
massive forgetting problem which is
which is really cool because now you can
have an adaptive system that knows how
to respond given its context and you can
control the level or how fine-grain the
categories stored in f2 or via various
hyper parameters but at the end of the
day what it is is it's bottom-up and
top-down interactions being compared so
as we saw its f1 to f2 + f2 back to f1
and you can think of that in human
memory as what we already know versus
what's being presented to us right do we
expect it or doing to actually pay
attention to this and is this novel
information unfortunately these have not
gotten there this type of model has not
gotten all the hype that I think it
deserves it has been successfully
applied across various engineering
domains but its main application has
been within neural and cognitive
modeling and actually creating models of
real neuron interactions and whatnot but
there are some other types of networks
that kind of have this memory property
but
our buzzword compliant and had been very
successful and those are the long short
term memory recurrent neural network
models or LS TM for short it were
generated by these four gentlemen up
here and in order to kind of explain it
I'm going to lean on Chris Ola and his
amazing blog describing how these
systems actually work and it's
understanding LS TMS you can find it on
his Twitter page or you can just google
it it's usually the first thing that
comes up and so what we're seeing here
right is that the the output of one of
these cells or the cells labeled a right
is getting looped back through into
itself and then we can unravel that loop
to have it look something like this
where we're moving throughout time but
let's actually get into how these things
kind of work so the first thing we need
to know about is the self state the cell
state is just the flow of information
that describes what the current state of
the world is so though we need to
manipulate that self state and the first
thing that happens during that
manipulation process is the forget gate
which basically takes in the input and
what was previously known and says okay
given this new information what is in
what do I need to forget right what do I
not need to remember anymore and you
know there's there's some some black box
law that excuse me black box logic that
happens there then we're not really
going to get into the next step is we
need to figure out given this new input
what are our relevant features right
what do we need to pay attention to and
how much of it do we need to pay
attention to the final step is actually
determining what the cell is going to
output so given our new cell state which
got manipulated via the forget gate and
the feature extraction gets passed
through and we now figure out okay we
have our cell state how much of this are
we going to pass through to the next
iteration of the loop and so at a kind
of high level the way L STM's
process information as they decide well
what am I going to forget what new
information do I care about and what
part of our updated cell state do we
want to pass on where is a human memory
the way we think about things in the way
we learn is what about my environment
should I pay attention to is that
information worth remembering and then
if it is I'm going to store it so I can
identify it again and I really want to
highlight point to is that information
worth remembering because you know
there's a lot of information that would
get bombarded with every day right some
of it just we ignore some of it is just
not worth our time and speaking of
things that are not worth our time I
would like to talk to you about the Java
Builder pattern so as we saw if you were
at the recurrent neural network talk
yesterday we saw how ugly these can be
and how annoying they are to work with
and before we dive too much into the
Java Builder pattern I want to take a
step back and talk about constructors
they are a part of Java we have to deal
with them and in order to use a library
like DL for J we have to be ready to
work with them now Java Interop is never
really fun and I would recommend going
with a library like cortex if it solves
the issues you're trying to solve but if
it does not have the tools to do so
and if you need like in particular if
you need recurrent neural networks or LS
TMS to get the job done that's when I
would reach out into the Java ecosystem
and kind of find yourself in this deal
for J Interop land but getting back to
constructors so they use the position
the number and the type of arguments
that they get passed in order to try and
understand our intention and then to you
know perform some function and if the if
there was only like one set of these
like if there is only a single arity
right or not it is the wrong word but if
there's only a single set of conditions
that a constructor dispatched off of
that would be fine right we could we
could deal with that but that's not the
case right there's any different error
T's where the everything every little
thing matters and if you mess up any
little part of that you're not going to
get the result you expect so really what
we want to do is we want to tell we want
to declare what our arguments are and
have the constructor understand what
that means right without any additional
worrying on our part so if we look on
the right could you tell me which one of
those integers correlates to the batch
size I mean probably not right there's
no indication and at the end of the day
does it really matter which one it does
like at the end of the day we just want
to tell it okay this is the batch size
right or my labels are located here I
don't want to have to worry about well
the label comes before the batch size
and so on and so forth and so the
Builder pattern was kind of developed to
combat this right we wanted to make it
more declarative and have an easier more
readable way of working with these
constructors with crazy amounts of
configuration and this is a step in the
right direction right it's more
declarative we can kind of tell what's
going on right like a seed is getting
set here we're setting a learning rate
we're adding some layers but we still
have to deal with a lot of issues here
right we now need to know all the
different ways that these builders can
be configured we need to ensure that
when we're calling these methods that
were calling them in the correct order
for example if I was to call these
layers before I called list it would
break and the only way you can know that
is through playing with this stuff right
and going through the hassle of setting
it all up just to learn that something's
broken down chain so the way I handle
this is I just have I handle all that
logic for you behind the scenes and I
allow just keyword arts to be passed
so that way you can just tell the
Machine what you want in your model and
it figures out the rest for you you
should still be aware of what your
options are and how you can use them we
don't need to worry about in my mind
unimportant things like ordering and
whatnot you know this is all well and
great right
we've got declarative arguments they
they do something behind the scene and
they're supposed to evaluate to some
Java object right but how do I know that
I didn't how do you know that I didn't
mess up my mapping right how do you know
that what's actually going on behind the
scenes is right and typically you would
you know look to the tests right but
when we're testing in Java interrupts
land
I mean it's typically we just make sure
the return type is correct right because
we don't really have much much control
outside of that right like we can go
through testing getters and setters but
when we're working with constructors and
builders if we want to make sure that
it's properly configured we're kind of
limited in that and I saw that was a
huge issue right especially when you're
working in something with something as
complex as deep learning I want to know
that when I pass my arguments and I set
up my configuration that everything is
as I expected right I don't want to get
I don't want to shoot myself in the foot
and only realize it 10 to 15 steps later
and then I have to comb through
everything I've done in order to figure
out what went wrong so my solution to
this was they said you know what behind
the scenes what I'm gonna do is I'm
gonna have any function that creates a
constructor or a builder actually just
output a data structure that is my Java
Interop I now have pure functions which
create closure data structures that I
can now test against and be sure that
when I pass these set of of arguments I
know that this is coming out and I can
test against this right so if I'm going
through refactoring or if I'm doing any
other changes to the code base and my
tests start failing I know that it
failed for a reason
right because you can think of if it
wasn't done this way and we're just
checking on the return type given how
many different configurations these
things could have even if a typo found
its way in there your tests wouldn't
really kind of show that and so I think
this is this is a really powerful idea
and I've ported a lot of functionality
over from deal for J and made it work in
this way not everything is there but
kind of the core of what that library is
is ported over so we have data set
imports there's no real data
manipulation stuff because obviously we
would just use closure for that we have
the neural network DSL which is you know
all the predefined layers that deal 4j
defines for us we can train our networks
using standard back propagation training
and then we also have access to this
thing called early stopping training
where we can actually control at what
point and under what conditions we exit
training and can then tinker with our
model again we can also do training
within a cluster using spark and we have
network evaluations so we can actually
figure out how well our model is doing
now time for the dreaded live demo so
what we have here is just a ripple and
how easy is that to see yeah
how's that
it's cool alright so we're gonna bring
in some namespaces and first thing we're
gonna do is just kind of look at some
general data import so I've got a CSV
located my resources file and
unfortunately this is very Java esque
and I was very explicit and all the
steps here just to kind of illustrate
you know that this is this is still
being kind of true to the Java nature of
it but handling it in a closure a way so
we set up this thing called the file
split which actually looks at the file
itself we then have a record reader and
then we have an iterator right if we
were to actually look at this and we'll
do that in a second we'll see that it's
all just kind of it's a Java Interop
data structure behind the scenes so
we're going to normalize and now we're
actually going to look at some data so
there I've got an input and an output
that's in a form that's ready to be
passed to a neural network and we're
good to go now let's look at the
classical hello world example of deep
learning or training on the minced
handwritten digit set so we're gonna set
up our configuration and I mean there's
a bunch of stuff that kind goes into
this so it is a little scary in that way
but once you learn and if you have an
understanding of what these various
parameters are actually doing it makes
sense as to why you would want all of
them right because again we're doing
something that's very complex and needs
this level of hyper parameters so I'm
going to set up my actual data there and
we're actually going to train this using
early stopping and so in early stopping
I'm right now setting up the conditions
under which I've done a stop and so this
one's saying you know if my network
somehow produces an invalid store score
we're going to stop it and we're only
going to let it run for two epochs so
here is what it looks like altogether
and warning this is you know because all
of these things are
put together this is a pretty crazy data
structure right we have our actual like
whole thing there but let's kind of look
at some of these parts right so we've
got our data set so these are all
setting up various properties of the
early stopping and then here we can
actually see our network configuration
we've got our layer calls we've got the
setting up of various hyper parameters
and whatnot and if I was to evaluate
this list I would get back my my Java
object which represents this
configuration we're not going to go
through training because that would take
up a little bit too much of your time so
I'm just going to load in a model and
we're gonna evaluate it and see what we
get out so we set up an evaluator and
now we're gonna look at how well this
model was able to classify handwritten
digits and so we see an accuracy of 0.98
so you know that's that's pretty good
but what was how did it actually do and
we can see that how would actually label
different things that it was presented
with right so it got zero correct nine
hundred and sixty eight times I got one
correct or the label one correct eleven
hundred and twenty six times and so on
and so forth and you can see like it
still messes up sometimes right these
things are not perfect and we typically
don't want them to be perfect we want
them to be generalized and have good
recognition without just memorizing the
data set on which they were trained on
and we can see kind of an outline of the
various scores down here at the bottom
so now we're going to kind of look
through a lsdm example and so we're
gonna set up i've got again data located
at various places
we're going to go through the same basic
process right we're going to set up our
input splits we are going to and we
obviously have test sets and training
sets we're going to setup our record
readers for both the training and the
test and then we're going to create our
iterators right it's a very java ee
process and it can be you know these
steps can be combined into one right but
I wanted to be like I said I want to be
very explicit here here we're actually
going to normalize our data to be within
a range that the neural network can
actually expect and work with and so now
all of our data is ready to go and ready
to be fed to a model and now we
initialize our model and let's actually
look at what it looks like
so again it's just a data structure
right we're saying okay we've got this
class multi-layered network it's made
out of this neural network configuration
builder which has these methods called
on it and and it's specifically the
layers we can see that also the graves
LS TM are builders and you know the
layers are builders the models are
builders everything's a builder so I
know that what's going on behind the
scenes is what I expect and then again
I'm just going to pull in a training
model and create an evaluation guy for
it
and then figure out how well it did by
running it against the test set and so
we can see that this one didn't do as
well as our previous example but it did
a pretty good job and we see like about
95 percent accuracy where we see the
exact same information we saw before and
so I find this way of working with deal
forge a much more enjoyable and much
more manageable and so there's still
some things that are left to do right
besides just the basic neural network
DSL
there's also computational grass which
allow you to configure things in your
own way
there's reinforcement learning there's a
front-end for actually visualizing
what's happening during this training
there's Kafka support there's CUDA
support and of course I want to add in
specs so there's still a lot left on my
plate and a lot left to do but as it
stands right now as you saw we can we
can get data and we can train a model on
it and we can evaluate how well that
model performs so this talk was given in
memorial to Jason Lewis he was my mentor
and the only reason that I'm in closure
at all he recently passed away and I
remember you know year like about a year
and a half ago we were sitting down
watching closure College talks this was
my you know my first few months in
closure and he goes hey you know maybe
one day you'll be up there and now look
where I am so I hope I've made him proud
and I hope that uh you know he's in a
better place so thank you
that was my talking any questions or
welcome
yes I'm sorry I can't
so reinforcement learning is typically
used you see it in AI that learned to
play games right because they
essentially play the game against
themselves until they learn the optimal
strategy so in regards to applications
that kind of spans
a lot of different domains right this is
more like when you actually want an
adaptive AI that lives in some kind of
environment right that's where you would
combine things like reinforcement
learning and layer types and model types
that actually have adaptive memory
so a RT the model that I showed you the
limitation of that it was only on binary
classification I really find that there
is not as many limitations because we
don't suffer from that massive
forgetting problem and there's also a
lot more application within again
adaptive AI it's just that it hasn't
been you that model architecture has not
been used to go and win a bunch of
different deep learning modeling
competitions so it hasn't really gained
the hype that a model like LST M has and
I think both could be used to or
variants of art could be used to achieve
the same results as LST M it just hasn't
been a major focus within the community
so I think I didn't fully hear the
question but I I know that when it comes
to doing training in a distributed
manner that's what we kind of used spark
for and we can offload that that process
to a cluster which handles that for us
but the amazing thing is is those models
that I showed you I trained both of
those within 40 minutes right just using
my laptop which has no GPUs there's no
KU to support nothing like that
so the actual training speed at which
these things happen is not nearly as bad
as it used to be given the optimizations
at the JVM level that deal 4j has
implemented any other questions all
right thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>