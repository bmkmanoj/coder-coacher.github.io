<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Hacking the Human Genome Using Clojure and Similarity Search - Arnoldo Jose Muller-Molina | Coder Coacher - Coaching Coders</title><meta content="Hacking the Human Genome Using Clojure and Similarity Search - Arnoldo Jose Muller-Molina - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Hacking the Human Genome Using Clojure and Similarity Search - Arnoldo Jose Muller-Molina</b></h2><h5 class="post__date">2013-01-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ATTIe3GDM6I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">our next presenter is a postdoc research
fellow at the Max Planck Institute for
molecular biology that's a mouthful but
I've got to read the first sentence of
the proposal he sent me because it's
fantastic it says the study of
transcription factor binding patterns is
required to understand how genes are
regulated so I didn't really understand
it goes on like that for the whole first
paragraph and I thought it was fantastic
cuz I'd really get it but then he sums
up the first paragraph saying closure
makes it really easy to diverse many
gigabytes of information and I knew what
he meant by that as I knew I knew we had
to have his talk here I believe two
weeks from today he's going up to start
his own company on similarity search and
pattern recognition I assume you're
going to use enclosure yeah good all
right so here is Arnold molar Molina
with hacking the human genome with
closure and similarity search good
afternoon so this talk is more about an
application of the language i will be
showing you the things I was doing at
the Max Planck Institute with closure
the institute is located in minster
germany and we are a computational
biology group that is surrounded by many
biologists that are working on a stem
cell research i will give you a overview
of this type of research because it will
be very important in the future up in
the future years ok it's a bit all right
yeah I didn't realize I would move it on
getting home so is it better now okay so
it stem cell research um there are many
ways of defining it but I will give you
an example of the things that will be
possible in the future so or that they
are possible right now so let's say that
they are struck from your skiing a piece
a chunk of of something called
fibroblasts in this picture you see some
muscle here and then the fibroblast
cells that are these longish cells and
then by using some techniques we apply
for what is called transcription factors
they are proteins and this person that
you see here is called yamanaka this
researcher in 2006 created this method
and they think he will get the Nobel
Prize for this because it's a very
important advancement so what you get
after applying these four transcription
factors is an induced pluripotent stem
cells these cells can become any cell in
your body they are very powerful because
you can make them be part of your heart
or your eyes or whatever so they look
like this so once you have this these
cells ready then you go through a
process of differentiation and for
example here my colleague converted the
skin cell into hard tissue that is
actually beating so this stuff is what
they are doing over there so it's
important because in the future you will
be able to do tissue reconstruction you
will be able to reconstruct your heart
if it is damaged for some reason also
you can do organ generation you could
potentially grow an entire organ inside
a pig then you kill the pig extract the
organ and put it inside your body and
another important
asp against disease modeling for example
for parkinson's disease it's hard to to
analyze the the neurons of of living
patients but if used tractor asking and
then transform these cells into into
neurons then you can study the disease
in a better way the problem is that the
transcription factors i mentioned here
we know only ten or twenty percent of
them but what are these transcription
factors they are proteins and these
proteins here this blue thing is the
transcription factor they attach into
their DNA and and they start a process
that is really wonderful I didn't know
much about it before i went to the today
institution and i think it's a wonderful
machine so what happens is that you have
here two transcription factors this one
is off for and sox2 and they are very
important for this process that I
explained before of converting a cell
into an IPS cell so they will attach
into the DNA and then a lot of stuff
happens that is outside the scope of
this presentation but the final outcome
the final outcome is that another
transcription factor will be printed
other possible side effects can be can
happen but another transcription factor
will be printed to that will attach into
another section and this will create a
cycle you can create loops with this and
it can even attach unto itself and
continue its production so what we have
in each of our cells is like a like an
amazing 3d printers that is creating all
these proteins all the time and this is
how the cell reacts to the environment
so if you go closer where they are
attaching you see here the different
basis of the DNA and these transcription
factors
we'll attach to a specific sequences a
very specific ones and this is the focus
of this study try to understand which of
which sequences are going to be
potential docking areas for the
transcription factor so to summarize
there is a docking region where the
transcription factor will bind and then
a lot of stuff will happen and the
blueprint region that is called the
coding region is the one that has the
instructions necessary to create another
transcription factor that will continue
this process at the docking region is
called the promoter region okay so what
is a binding motif so once you have
experimentally studied these
transcription factors you can come up
with a set of binding sites a places
where the where the protein will attach
and people have used this type of
regular expression to represent this
it's called them the motives of the
motive what it means is that the long
sea is a place where there is a very
high probability that there will be a
sea and here in the middle where you see
a G and a teeth there it's like even it
will be a junior at E and there is a lot
of entropy there's a lot of noise too so
this is how people represent the
sequences where the transcription factor
can attach so again another
summarization you have several
transcription factors attaching a la the
transcription machinery will create
another transcription factor that can in
turn go recursively again or go to
another gene so the gene is basically
the docking area and the coding place
this is two things so if you know this
motive logo you know where it binds and
then you could predict which genes will
be switched on or off depending on
certain conditions so we want to reverse
engineer the cell and there are two
thousand six hundred transcription
factors in human this is a prediction
from a paper
but we know only 300 so we want to find
out the remaining ones and without this
there are no navigation to so we can
understand better how things workings
are inside our bodies so the objective
here is to find the missing 2300
transcription factor binding motives
find how they work together okay I don't
know if you read this book the gold-bug
from Edgar Allan Poe at a certain moment
in the book they will bring this message
that is encrypted they tell you that the
message is in English that each symbol
corresponds to a letter and there is no
punctuation used so what they want you
to do is due to find them the message
inside so you could for instance infer
that the column 48 is the most repeated
free gram in the message and then you
could infer for instance that because
English in English da is the most common
word then column four th is done and you
could start replacing words and trying
different permutations for this probably
corded logic could be very useful so
once you try a lot of different
approaches you can come up with a
message and this gold bugs book and this
message is very related to the to the
motive problem the only difference is
that in the motif finding problem you
only have ten percent of the
dictionaries you don't know how the
other ninety percent of the works words
look like there is no grammar available
and only very small sections of the
entire message are useful so probably
99.999% of the message is garbage and
then you just have to look at a very
specific place that you don't know where
this place is so this is how the
constraints are of the problem so a
definition may
be from two billion DNA words and by DNA
words I mean a sequence a string of actg
of size 4 to 24 let's say because it
could be even more but let's say just
for just went or not right now then
first you need to find a dictionary of X
DNA words you don't know how many DNA
words are there for your dictionary and
from this dictionary once you find it
you need to group it in two thousand six
hundred clusters and how they are
grouped is not known either so you don't
know how if there are patterns of to
accommodate this these groups so
basically this is the problem i was
using closure to tackle and i will tell
you a little bit about how I I try to
solve this this problem okay so we need
a Jess no function that is lies over the
genome and collect words that could
belong to the dictionary so that the
function will go and check every single
of the other sections of the genome and
you will try to find if there are words
of a certain size that that could be
part of the dictionary so the first task
is to develop this function and you have
to do it for all the genome so before I
go with this I will define what a
similarity search because it's a very
important tool that is used all over the
place basically you define a function
that computes the similarity of a and B
once you have this function that if a
and B are the same it will return 0 if I
am be are different you will return a
larger value and once you have these
functions similarity search based on a
query will find you the closest items or
another way of thinking about it is a
key values storage
where the key doesn't have to be exact
so it has it can have modifications in
any place and and then you can get keys
direct kinda close not exactly so for
example they having distance here you
have these two letters that are
different so the Hamming distance
returns one and here these are two
different sections of the strings so
they have in distance returns to this is
a well-known distance so I'm showing
here some some conceptual code it
doesn't have it's not meant to be
efficient or or maybe the best way of
writing meeting tell you but I thought
it was the best way to explain what it's
been similarity search or how to
calculate it so you will um I don't know
if you can see if it's too small or it's
too dark um like this better so it will
receive a database which is a sequence
of objects and a query and akay with
which tells you how many objects how
many closes objects you want and then
the function that you are planning to
use and what you will do is very simple
you will do a reduce over the database
and the accumulator will be in this case
I use the sorted map there are better
data structures for this but I just
wanted to do something that was ready to
readily available in the 80s so I use
the sorted map as a priority queue here
and I call this function update that
receives the function the distance
function value and the object that we
are analyzing and cake so how this
update looks like well it receives again
the priority queue the distance the
object that you're searching and
k and what he will do is basically if
the the priority queue is a smaller than
K that means our bags not full yet so we
just add the result that means the
distance and the object that we are
exploring in the database to our tour
resultset if our priority queue already
have K elements then we will take the
largest element of the sorted map and if
the largest element of the sorted map is
larger than the distance we are
receiving incoming distance then we will
remove these objects and add the closest
distance and this is how we get the
closest element yeah and this is could
be an implementation of the of the
Hamming this is what I wanted to say
here is that closure makes it so not
only nice to write fast code even though
this disinterment ation is not fast but
it's nice to explain how things work and
I just wanted to point this out so if
you do the sequential search over our
database I did an example here of 10
million objects and if you do it in a
sequential fashion it will you will have
to wait 27 thousand milliseconds but if
you use an appropriate data structure
you can take this down to 15 so this is
important i'm just showing the the code
here to explain the the output of the
method but sequential is not always the
best and i didn't use the code I showed
here to do this test I use something
faster okay so now we have we have our
similarity search tool and of course we
have closure to solve all these things
so we are using our function that is
lighting over the DNA here and now we
are looking at this window and also
because there have been many species
sequence in the past you have the monkey
the pores the panda everything people
align these dnas they put them together
so that they will match this call and
multiple alignment it's by itself a very
interesting problem and very hard to get
it right so the input of the other
process is this alignment is this set of
alignment and what I did here is that I
am comparing the current window against
all the windows of the other species
that are in this multiple alignment and
I am I'm not comparing i'm calculating
the Hamming distance here and then i am
sorting by Hamming distance and
therefore the closest elements are at
the top of the list and if you for one
moment forget about this is windows but
just look at the different species that
are here this becomes like a permutation
you can you can permute different
species based on how close they are to
the human if you take the known
transcription factors and you find the
size they have and you have the list of
the permutations that they possess you
can use this as a training set of course
you have to separate a training and
evaluation set which is what i did i
used a different different sets to try
to predict if a window is have the
possibility of belonging to our
dictionary based on this permutation
this is one of the things I'm doing the
other thing I'm doing is that when I
show you the motive here with this long
characters here that means that there is
a high probability that the teeth there
there will be a tea in the fourth
position here of the of the site and
this is the entropy profile so the
entropy is very low when where there is
very specific letters so these discs
is a different kind of fingerprint here
this green line is the conservation
which I calculate based on this
alignment again I take the number of of
letters that are different and I
normalize it and as you see here is
interesting because areas where there is
low entropy is highly conserved and what
it means is that it during evolution and
areas that are useful for something have
been preserved and places that are not
so useful have mutations and and here
they useful parts are highly conserved
between species because they I required
for the salsa function properly so once
we merge these two filters we have now a
dictionary of words and now it's or is
this the number one point and the number
two point was to group these these words
so you need similarity search now to
find clusters so what I did is I took
every element of the dictionary and i
created a cluster so every element of
the dictionary is a is a group that
could potentially be one of our
predictions so this is the first step
but then once you have all these
clusters not all these words belong
together we don't know exactly what are
the rules for the words to be together
so again i looked at training data are
the things we know about transcription
factors and i try to match the features
of the of the known transcription
factors with with these predictions I
try to make to refine every every one of
these predictions into something that
looks closely to the to the things we
know there are many ways of doing these
there is the Jeep sampling that is very
popular
you could do some genetic programming or
or some other optimization technique
once you have refined this this group's
now you have a lot of predictions you
can have millions of predictions you
don't need all of them you need to find
the predictions that are more useful for
what you want to do so this was a I'd
receive a lot of help from closure to
this because i was using one class
support vector machines for these and I
I had a lot of problems and then I
started to play with the repple and
finding a and a hybrid similarity search
approach and I I developed it with the
closure and it has been an instrumental
tool to to try ideas to to change things
easily it's it was a big help so i
created this this filter that projects
every of these predictions into a high
dimensional vector and again i have
previously learned how the known
transcription factors how these vectors
look like and i try to find predictions
that closely match the things we know
and then I I filter it with this so
which predictions are the best now you
have filters but still you need to sort
this prediction and there are many ways
of sorting them one way is to if you
recall the green line that i showed
before of conservation maybe you could
take those predictions that have very
high conservation lines or things like
this or you can combine it with
different approaches like entropy and
another thing so but the ranking is very
important in the process and because
they are overlapping predictions since
you did since every single word of the
dictionary becomes a prediction there is
a lot of overlap so you need to remove
overlapping predictions and and once you
have removed these overlaps then the
process
complete this might seem to related to
biology but this approach can be applied
to many domains and that's why I spend
some time introducing it because I think
it's useful for a variety of application
okay so the output of the program is
this and the left column there is a
known pattern and on the on the right
column any and on the left one it's them
the prediction the program is is coming
up with so as you see the predictions
are quite quite accurate and calculating
hear the person correlation and they're
returning high high values so I tried
all the known transcription factors
separating them with a training and
validation set and I repeated the
process several times and end result is
that the eighty-one percent of the known
things have been predicted by the
program without knowing anything about
them so at least we know that with the
things available the program works and
this gives us a hint that it might be
finding useful so I felt very happy I
felt like I was driving a fancy car
closure has made a programming fun again
and I really want to thank Rick on the
community for a tease it's been great I
used it in different parts of the
project first of all our file processing
and biology they have all these really
nasty file formats where for instance
this this is lashes lashes the beginning
of our record and all the records are
separate lines and then you will get
another slasher / and there will be
another record and you have to fire
every lab has a different file formats
so closure makes it very easy to parse
this is files with some partition by
filters it's it's so convenient
besides that and as I mentioned before
closure is like a thing now oratory like
a place where you can go and think I
started learning a scheme during the
first semester of of university and one
of the first or second homework i got
was to create an e memory database which
selects joints and believes himself like
this and at the time i didn't understand
why was so easy to do it with a scheming
and it's just that the simplicity and
generality of the language that gives
you a lot of power and I'm very happy to
find this again and also to have the
virtual machine to to be able to to use
existing libraries and it's really good
because before I was using a scheme just
to get the ideas but then I had to write
my programs in the language i was i was
using but now I can leave everything
already in closure because it will run
nice and and fast so i did also data
processing I did visualizations of the
output for example here I have my
predictions and these predictions are
associated with genes and genes have
oncologists ontologies will tell you
that a gene is related to to your eyes
or hair or whatever so we wanted to know
how these predictions related to these
ontologies and so I created a
programming closure that by using
similarity search and looking for for
close matches of oncologists then you
can create these maps using graph beans
and and you can create countries that
share similar anthologies and also you
can put the ontology together so it was
very nice to visualize all this complex
information closure made it possible so
this is another example and is the same
thing and furthermore once you have this
patterns this motive logos you can also
see how they work together in the
promoter regions in the docking area and
then you can infer syntax from them you
can you can see okay there are several
genes that share this guy at the
beginning and then there will be another
transcription factor binding and another
so I output all these things x rules
that that can that appear in in in the
in the genome so for instance these
rules it's applicable to 200 genes there
are 200 genes that that shared this is
topology so basically this is the entire
process um I discovered part of the
genomic codes with closure and
similarity search and the methods of
clustering refining filtering sourcing
and merging this combination was very
powerful and you might find it useful
for your data analysis project there is
a lot of work to do in biology Donald
Knuth said that biology easily has 500
years of exciting problems to work on
and there is a lot of things to do there
is there are many things we don't know
but with similarity tools which I think
they might be the next no sequel and and
with closure of course we have we have
nice tools to title this before
elliptical problem I would like to thank
hands shoulder for the support of this
research and Marcos are also for
guidance and carrying hÃ¼bner for
discussions in biology related topics
and vladimir for the pictures and also
to the amazing closure community and the
organizers and i would really like to
thank everybody for your attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>