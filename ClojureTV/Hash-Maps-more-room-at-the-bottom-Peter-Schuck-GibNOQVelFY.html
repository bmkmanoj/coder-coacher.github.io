<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Hash Maps: more room at the bottom - Peter Schuck | Coder Coacher - Coaching Coders</title><meta content="Hash Maps: more room at the bottom - Peter Schuck - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Hash Maps: more room at the bottom - Peter Schuck</b></h2><h5 class="post__date">2016-04-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GibNOQVelFY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello my name is Peter Cook nobody is
known as spinning tops of doom err on
the internet i work at Benny works doing
a software consulting and here I was
originally going to talk today about how
to build a a lien spaceship about how to
avoid the great GU situation when
building your own nanomachines what cup
of tea is best for powering your
infinite improbability Drive or look
very hot is the answer of course and how
to make your spaceship bigger on the
inside than on the outside but of course
these are all fictional technologies and
impossible to create in the world world
so let's talk about some real alien
technology this or more specifically
closure but recently a paper came out to
detailing some good improvements to
close your hatch maps that when the core
pieces of our globe a lien spaceship and
they made some really good performance
improvements and they claim that they
got like doubling performance for
iteration or an equality checking and
they called these new improved good hash
map data structure compressed has a map
prefix tree or champed for short and I
decided why not to see if this actually
works in the real world so I poured it
over to close your script the PostScript
implementation is under that github repo
of any works lean dash map and you're
going to go check it out want to and
when I implemented this I found that the
performance improvements did in fact
pulled out in the real world and that
not only that but the resulting a code
implementation was a lot simpler to boot
so what can chant do for your hash maps
well I can give them a lot of pep it can
give them you can prove the iterations
reports by doubling it for incineration
speed and not only doubling or tripling
or even quadrupling equal equality
checks but it can increase while
equality check speed by a mooring
magnitude about 10 to 100 times more
performance and also that trim to your
hands maps all while doing this that you
may have known your hash mats have been
growing a little bit pudgy around the
is that they may we be wearing more
relax it punctuation like the open
parenthesis and with champ we can go
from these relax it functions back to
the high school confirmations that they
wore nice and well I know but a lot of
people here may be thinking oh great I'm
going to need to be a wizard to do this
you need to have a Latin correspondence
course I'm going to need to look learn a
somatic components do do this and have a
degree in black magic bit twiddling and
also not know the special magic key
words like mo dad isomorphism or
burritos in order to do this but one of
the happiest coincidence that I found
while implementing this that champ makes
hash naps wieldy that makes them all up
makes them conceptually simpler and
easier to implement and like the
resulting code size was about two-thirds
the current implementation size that
just enclose your script when I'll all
said and done so before you dig into it
let's go to a overview of closure hash
map so that we're all on the same page
that's close your hash maps are a tree
of nose with the third to eighth
branching factor there's the root node
right there with as many as 32 subnodes
and inside a node there is an array with
up to 32 up to 30 size of 32 that has
key value pairs and references to nodes
at the lower levels which all call sub
no references for the remainder of this
talk and there's metadata on the node to
tell where a key is located inside of a
nodes array so in this example the
metadata it says that key foo is located
in the 0 at slot in the nodes array and
that the key 3 is located at the second
slot in the nodes array and finally
here's how the key finds a note inside
the tree that in this example we're
taking the hatch of foo and we then
partitioned the hash up into groups of
five bits each so we take this long big
number over here and divide it into
the first five bits are the 20 next bits
are 10 the next bits are 18 and these
represent the different levels of the
tree the first five bits are the root
nodes hash next 5 bits are the level
hash with a level below that and next 5
bits are the level below that and so on
and when we have a collision of two
hatchet of two keys having the same
patch for a level we simply go down a
level and then use the next slide this
of the hash extending the precision
needed for that so in this example that
we see the thief that for the first two
hashes of the key food twenty and ten
that there are other keys that have that
same hatch for those same levels so when
we finally get down to the 18 node that
we find that we have no keys that
collide with that so that is the correct
node for that are there any questions
about this all right so let's get to the
first major improvement that champ
brings that it removes a lot of the
problem with sub node references that
the perch major problems that subnet
reference is that a subnet reference is
a pseudo key value pair that they hit
has nail us a key that you can see here
that there's key value key value and
then their sub mode reference that looks
exactly like a key value only with nil
as the key so this of course has the
problem of like doubling the overhead
for each subnet reference that we're
wasting memory with this but in my
opinion a lot worse is that it has a
whole bunch of incidental complexity
that in work we can't store a lil keep
that we can't still a lower key and our
hash maps anymore so we have to have two
additional fields on our hash map data
structure one for a as a flag to say is
do we have an ill key or not and another
field to store the value for the nail
key if it exists and to get better
performance we have to have an optimized
node which is known as an array node
that just contains subnet references
and this array node is created whenever
a normal node has it gets full or has 32
elements then we take the normal node
and create an array node that and that
and there's a whole bunch of further
complications with the second problem
with seven addresses and that subnet
references are scattered throughout a
nodes array as you can see here that we
have key value then we have the subnet
reference then we have key value key
value and the layers of interference
there's no rhyme no reason to why to
where they are located so this means
that for every single operation for
association dissociation iteration and
look up that we have to keep this in
mind that when we look at a key value
pair this is a four realz key value pair
or is this a subnet reference and this
just adds a whole bunch of mental
overhead number one and it makes the
code a lot less clear that that you
don't really see the intent of what does
and if you want to add any other
operations that you have to always keep
this in mind and in addition having some
numbers has scattered throughout the sub
no differences scattered throughout the
array makes iteration a wiki walk for
these they don't know what wiki walk is
where you take it go to a page in
Wikipedia see something interesting
click on the link go then that next page
clicks a lot more links go to a lot more
pages and then like eight hours later
and 30 tabs later you're like looking at
hairstyles of the early Byzantine Empire
for a reason and have no idea how you
got back where you came from or I get
back and this is how it eration works
currently with attachment with a hash
maps that the instant they they they
walk through the array and then these
sins they see a sudden reference they
have to go follow that link down and
down and to give you an overview of why
this is bad let's go through a sample
wiki walk all right we're looking at the
Roman Empire and we see immediately we
need a vermin Republic let's click that
then we see the link of
ancient Romans this civilization so
let's click on that and we click on lots
more links links and links and we end up
at awareness finally at the bottom with
no more links so we're done and now we
have to go i'll be back up and i have
questioned for all of you what was the
next word after when were in public does
anybody know right no it was period and
this indicates why the wiki walk
iteration is very bad it has very very
bad locality that both temporally and
spatially you like divide up that your
array when you're going through it and
you just don't have the locality that is
good for like minor CPUs especially with
our caches what so what does champ
brings this a problem well here's the
chap knows improvements that first we
put make sure that key value pairs are
in front and sundry references are in
back this removes the need to have the
nail marker value so that we can save
space and we d complex with metadata
that we have the metadata right here and
then we divide it in the key value
metadata and two node metadata so that
we always know that we're pointing to
inside of the array let me know if we're
at pointing to a key value pair or for
pointing to a subnet reference and this
of course lowers the memory overhead for
because we can remove the nail market
values but that's like the most basic
improvement that I see that the bigger
one is that look at all this complexity
that we have moving that we no longer
need any flat any extra fields to hold a
nil key value pair and we don't need an
optimizer a note that we can just have
one node for all the map and we remove
the windows type thing where we ask are
you sure this is a sub node reference or
not every single operation that we can
just remove a lot of that complexity and
makes the intense of the operations on
our data structure a lot more clear as a
great bonus we get twice to perform
by changing integration for my wiki walk
where we go up and down up and down up
and down up and down the Zeta structure
that's basically a graph traversal of
the data structure and two linear scan
we were just can go straight through the
array and to show you like the best
simple like the simplification that
champ brings the iteration let's show
you the current hashmap iteration that
first we check the the hash map has a no
flag or not if it does then we return
the Milky value pair and then we go to
the tree proper and then we have two
flavors of nodes for Nomo nodes we
iterate through the key value pairs and
we lean say is this key nil or not if
it's not then we have a for real key
value pair and can return that to the
user if it's not then we have a sub
known reference so then we follow the
reference to the note below it and
repeat the algorithm and then for array
nodes we iterate through all the
elements if the element is no then we
continue through the iteration otherwise
we're at a subnet of reference and we
fall out reference and repeat the
algorithm again compare that to champps
iteration algorithm just go straight
through all the key value pairs then
iterate through the submount references
repeating the first step let's go
through comparison seven lines versus
two lines of high-level algorithm we
have three conditionals in current
include a chain versus none and we have
to have polymorphism in the current
implementation versus no polymorphism
needed in the champs plantation is there
any questions or clarifications you want
on the improvement two iterations and
notes of the sub node references right
all right now let's go on to the second
big improvement that champ brings that
quality check improvements I have a
close your puzzler that I like to call a
superficial cleaning but we'll have to
put on your thinking I know it's after
lunchtime but let's go through with it
anyway that we have a empty hash map
right here that we create then we go in
the next expression we associate and
then we discharge off of the hash map
and ended up with a empty lamp and then
we check that both of the maps are the
equal using as using the Equality check
so that they're equal in the eyes of
closure and then we each high some
Lawrence testing this so for the we do
an into empty hash map for the our first
hash map and that takes 140 microseconds
and my question for you all is how long
does it take for the next time thing
that is the exact same operation on as
far as culture you concern the exact
same map how many how many people think
it's a that they're the same map so they
should be roughly to say okay we got a
few hands for that how many thinks it'll
take double the speed for some unknown
reason do we see how many bees c 1b and
we say thinks it takes see ten times as
long alright a lot more hands how many
things it takes like almost a hundred
times as long I thinks it's d a few more
and finally e how many thinks it takes
about two hundred times longer to do
this exact same operation wow I see what
answer is e it takes two hundred times
as long to perform the exact same
operation for as far as culture is
concerned the exact same hash map that
they're both equal maps according the
closure and they're both empty so why is
it taking so long the problem lies in
the leash
algorithm it does a pretty superficial
delete that when we do the bleach an
algorithm where in this example we're
removing three from the hashmap that
heals and fights them know that three is
located under removes the three from the
array then makes a new a new node with
that array and does the path copying to
do all the immutability bookkeeping and
that's about it and superficial cleaning
leads to something horrifically is a
nice innocent hash map that has key
value pairs is all nice popping along
and before I go to the next slide I may
warn you this is quite perfect and those
are you weak constitutions may want to
look away oh sorry it's very very scary
you can see that these two maps have the
exact same structure the same nose and
you really could tell that they look
like the same thing at a glance that we
have the same exact number of nodes the
same subnet references and the same
structure that this is the problem with
the current deletion algorithm that you
can't remove empty nodes you can't
remove some no differences and that's
why we got the 200 times slow down in
our puzzler that was because that even
though we did the loop deletion of the
million elements all the nose all the
subtotal references were still there so
that when we had to do the into which
needs in duration that we had to go
through and check every single note
every single 710 reference to see hey do
you have any key value pairs or not and
that just leads to the horrible forwards
so what can we do about this will chant
has the solution for this it's a still
the same basic algorithm that we saw
before but there's two additional tweaks
to make it too much better than the
current one that we when we do a
deletion in this case we're deleting the
key three that and if we see that the
node array has just one key value pair
that instead of just deleting that
instead of just going through normal
approaching and being done that we
go and move the key value pair up to the
sub node reference replacing the 702
reference with the current keep with the
key value pair and if we have a chain of
those in this example that the deletion
that we're deleting three again and then
we end up with after moving out one
apparent reference that we still have a
array with one key value pair that we
keep on going up until we end up with
either at the root node or we have a
node with more than one key value pair
inside of it and this of course lowers
the memory overhead from the scioscia
and it's um minor memory overhead
improvements but really so what what
does this actually give us this like
close your puzzler only really happens
in the pathological case you're not
going to have like 10,000 100,000 or a
million elementa large cache maps that
you're just going to remove 99.9 or
ninety nine point five percent of them
and then use that your that is an
extreme edge case what does this really
bring us what's the payoff the payoff is
that equal chant maps are not only equal
in the eyes of closure they are
physically equal that they have the
exact same memory layout and this allows
us to allows us to up not only compare
on key values but we can now compare on
nodes and this means that that equality
checking goes from a order of linear
time algorithm to a logarithmic
algorithm leading to a hundred times
performance and crude improvements and
when I first implemented this I really
didn't believe what I was seeing when I
was doing in the micro benchmarks I like
saw it go from like 500 milliseconds
checks to 5 millisecond checks and was
really really like unsure like what did
I do wrong how is this less look just
right so I played around with it a
little bit and figured out that this is
only when the map share structure that
this is because if you have two maps
that share some structure like this that
here's like the first map that we're
playing with in the pinkish red and that
we make some changes to and have another
map that is the light blue that the
nodes that they share a lot of the same
nose which are exactly equal point the
point references are the same in memory
so that when we do we quality checks on
knows we can meet like we just had to
stop right here and don't have to
compare than those below there that
since this is physically equal memory
that all this below it will be equal
memory so that we only have to compare
the nodes that are not equal the light
pink and the blue is that we only have
to compare that so and the nodes that
are not equal that are not physically
equal in memory are very very small for
most operation for most maps especially
when you get into very very large maps
so this gives us the linear time speed
up but you may be asking what happens in
the worst case where we have two
physical two maps which are I have the
identical key list of key value pairs
but are separated in memory the good
news is that we still get a ten times
performance increase for match that
don't share structure that the reason
for this is that the current comparison
algorithm has a lot of overhead due to
using the closure abstractions of
sequences and lookups that the current
equality check generates a sequence for
the first map and then checks the key
value pairs for that sequence are equal
to the second map by doing a look up and
the sequence abstraction has a lot of
overhead due to the more allocate do the
allocation and put in a chasing and then
once we do find the key value pair that
we want to compare we have to do a
lookup which destroys any like temporal
or spatial locality that we possibly
have for these comparison but with the
champ comparison we can compare directly
on nodes so that we're directly
comparing two arrays and that's about
the fastest comparison can do for a
collection is just the only completely
let my overhead that is really added is
the closure equality check which is
incidental compared to the overhead that
have sequences and look up generate so
does anybody have any questions or out
some clarifications on this yes no it is
not actually the it's about the same for
the current algorithm it's probably like
within like margin of error I guess
source goes like up and down whether
it's the same because you're not for
that you're having like extra garbage
collection because you're having a room
of extra stuff anything to do the extra
steps but you're also removing all the
whole bunch of empty nodes and subnet
references so that what you're deleting
is getting smaller and smaller every
time it's not staying the same size so
that if we go back here like for example
if you want to go and leave something
here imagine this item like more key
value pairs that you have to go keep on
going down and down every single time
for the current implementation and that
would take slow things down there so
it's about a wash compared for dish oh
Sh any other questions all right
real and when I think that's like the
champ improvements pave the way for a
lot of future improvements that can be
made for hash maps that to the big
improvements I can think of top of my
head are like merging and dipping that
the current use they use closure
abstractions and think that that we can
get like at least double the performance
this by just using the champ
abstractions and that this will be
similar in the ideas to how r RB vectors
work for vectors but for and champ is
not as cool as working with nanobots but
I think it's a great addition to the
alien spaceship that we know I'm going
love called closure and it shows that
there is still plenty of room at the
bottom especially like for amitabh 'old
Atta structures that we still have a
long way to go that we can't get
doubling or even worth of magnitude of
performance on basic operations and
lower memory overhead to boot but for me
like the biggest win is this makes hash
maps so much more accessible and easier
to understand it implements that I like
read the code behind hash match before
and the bit twiddling was a bit of a
stomach Loboc but the bigger one was
like all the complexities that have to
deal with what champ cleans away that it
just makes it a lot simpler to
understand the intent of the code i
found when doing that and i think that
cloture hash maps are one of our best
exports that not only is our basic hash
map data structure that it's that day
structure for scala for Alexia and
that's been like Porter to even
imperative languages like Ruby and
JavaScript via hamster and immutable Jas
and I think that we can with the champ
improvements the complexity over it like
the overhead and the conceptual weight
is a lot lowered so that more and more
people can pick it up and implement it
and that for like future functional
programming languages that this should
should be and can be the data structure
of choice to go on
pick it up so I think that this these
improvements make it a lot easier to do
I'd like to give a lot of thanks I like
to give thanks to my employer bendy
works for supporting my work on doing
the clojurescript port on this and
helping with talk like to thank Michael
Steinem Darfur and her convened you for
writing the champ paper Zack telman for
writing collection check which I use
extensively for testing out that my map
and location was correct very property
based testing and Martin clutch for
pouring it over to co your script there
was a lot of tricky macros that
collection checked used that I tried to
implement and failed and Martin just did
that for me and Nicholas Bridger helped
me set up the test harness so that I
could actually run the test and finally
David Nolan helped me out with some poor
flying and performance tuning
suggestions I'd like to give special
thanks to my coworker cliff Rogers for
letting me talk for hours on end about
this and helping me go through this talk
and that is it
any questions I talked with Alex Miller
yesterday about that he said that
according to rich that it looked cool
but they had to be proved this out that
they want also to like tested against
like major like clay would close your
chord bases and see that was actually
working in there and so far I've like
had trouble getting assoc to be quite as
fast as a the current implementation of
a social I fifteen percent slow down in
there and that the transients assoc is
also a very tricky problem fortunately
like when I flew in here like oh there
may be something dude the reason that
it's a slower at least well i think and
i think is proven out that the this
implementation has can you can expand
the array up to 64 elements whereas with
the current implementation it's only up
to 32 so that gets in the cpu caching
and also when you want to copy the array
for immutability that that takes longer
to copy so what my idea was to get that
fifteen percent down is to instead of
having the key value pairs directly on
the array create a key value of data
type and then store that the data type
on the right instead of directly
compared directly and that got it down
to like about six percent overhead and
hopefully the transient assoc will be
implementable and want a lot more easily
than it would have been but it's up to
someone in the community to prove that
this works and is a reasonably part okay
yeah I didn't really know I think that
it's a obvious when you see it type of
thing that that at least it was to me is
like wow this makes law it took me a
while to understand what they were
actually saying when I read the paper
and then like pouring it over there was
a java implementation for that the
rascal language uses for this thing that
is correct but yeah I just saw like wow
this why didn't people think of this for
it but it's like a lot of stuff like a
like the best thing that I can think of
is like relativity like why didn't
people think that I mean the equations
for relativity are really really simple
but it took an Einstein they were think
of them that there's a lot of stuff that
you can say oh this looks why didn't
people think of this before but it's
really really hard to make that
conceptual leap and I mean it's been
like rich and David Nolan I know all
whole bunch of other people have looked
at this and not made this leap so I
think it still shows that there's a lot
of things that are easy and will be like
conceptual leaves that will be possible
in the future
oh that was a David Nolan tweak and I
just looked at it so I just looked at in
like oh that would be really neat that
were actually true impossible so close
your script is a lot easier to implement
coordinator structures in then closure
so figured why not give it a try and
like was very pleasantly surprised
especially like two-thirds the size of
the code whoo yeah yeah I have an
enclosure script right here yeah you can
sit I'll get to that that there I have
an operation which sets maps to be lean
maps so that you can have like do a
comparison stay luck for now i want all
maps to be lean maps and set up the chat
maps instead of a normal maps and you
can set it back to close your script
maps go that back and forth and like is
it a lean map is a ling nap sequence as
a hashmap etc implement it that it I did
this enclosure script because it was I
know JavaScript enclosure script a lot
better than Java so and that is a lot
easier to get the global implementations
inside of closure script than it is in
closure so I think the person who is
presenting like khda I I don't wanna
miss pronounce his name is looking into
it and the closure dev list and there
has been like some talk on that but it's
up to the community as far as I have
been told to implement this so this is
only available for closure script if you
want to discuss how to port to closure
and
java be happy to discuss it yes
no I just been like working on this and
then like got accepted for the talk is
like oh my god I had to prepare talk so
misty more chest is making sure that it
was a good explanation for what the
actual structure was but yeah come and
talk with me later and I'll just do it
did not know that thank you how am I
you're doing on time good alright we
have five more minutes so you like one
more question if anybody has one all
right and if you want to talk to me more
about this don't be afraid to approach
me I'm probably much higher and more of
introverted than you are so don't worry
about this i'll be happy to talk with
you about it I'll any time thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>