<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sequence and Concurrent Processing for Huge Genomic Data - Toshiki Takeuchi | Coder Coacher - Coaching Coders</title><meta content="Sequence and Concurrent Processing for Huge Genomic Data - Toshiki Takeuchi - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sequence and Concurrent Processing for Huge Genomic Data - Toshiki Takeuchi</b></h2><h5 class="post__date">2017-10-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ipNru1QSeWc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning okay canisters the present
presentation hi everyone my name is
Tasha Takeuchi from thank you in Japan
so first thank you for coming
I was so I'm so happy to see so many
people coming to my talk because I was
afraid everyone might go there the talk
in the next room so I couldn't sleep
well last night
I'm glad today I will talk about
sequence and complex processing for huge
genomic data using closure first for my
I am a researcher and software engineer
at thank you I have been using corrosion
and across a script to implement a
practical software for over four years
and make some closure library episodes
see my github if you are interested I
interned thank you
unload closure since I am a university
student last year I heard a PhD from the
University of Tokyo after that I
actually joined in thank you well about
Tinku has this local shows x0 is
pronounced dead thank you thank you is a
Japanese startup company providing
genomic integer integer installation our
company creates a services always three
policies and intuitive design for women
knowledge of advanced computing and high
ability of implementation of software of
course we're using closure on the
closure script the main programming
language also using some what
Java and Python Beto JavaScript on
tsipras process and so on
this is outline of today's talk first I
will introduce genomic analysis and by
animatics after that I've explained the
main topic of my talk why we decided to
use closure in by a Maddux field in
addition I with touching how closure is
used in our entire solution so before
starting the contents I'd like to know
how many people who know somewhat by
pneumatic saw so many more than I
expected
so some byproducts words will appear in
much lies but you don't have to
understand the detail of the word and
the main topic is closure and our
experience using closure for our
solution I start my talk from brief
introduction of genomic analysis genome
is genetic materials of an organism like
DNA or RNA in the case of human human
genome includes 3 billion letters of ATG
genome information is very useful for
understanding organism research for
genetic disorders and useful medical
treatment recent regional can be led by
a machine called sequencer easily and
quickly so manually search institution
his world conduct janam genome analysis
well why did genomic analysis become so
popular because of low cost and speed
this just shows changing cost needed for
DNA sequencing the green lines in
sequencing cost and the white lines
Moore's law so as you can see the cost
reduction is much faster somewhat low on
sequencing speed is also getting faster
so in practical case partial genome can
be leading a few hours this chart shows
fustian future accumulation of genomic
data your line is the determinant
estimation alumina is one of the biggest
company of biotechnology from this
church you can understand genome data is
laboratory accumulating and post process
of sequencing is serious issue
so such post processes in PI of Matt's
field studies analyzing process of
sequence genome data that is informatics
and data analysis domain in such biotics
field we mainly use closure next I talk
about while we use closure and my
closure is good at buying models with
actual examples these days genome data
is led by next-generation sequencer the
genome data generated by angeas is huge
the output format is different by
Angie's machines so but the fact
standard format is fast key format most
queue is a text-based format including
both
sequence letters like a DTC and the
corgis course basically
this file is a starting point of unit
analysis the first key page size is very
very large as much as from gigabyte to
terabyte per specimen this is one
specimen size
so for example a fortune on first Q is
366 gigabyte its size and includes 115
Giga bases this base means 1 calculate
EDG so even exome sequencing this is a
faster genomic data so even 35 gigabytes
21 Giga bases so performance is very
important factor when hunting such huge
files so in fact most of the 5 max tools
are developed in C or C++ or Java it's
for performance so though these tools
are very popular in mathematics so for
example bwa is written in c and body 2
in c++ some tools in C and C++
covering Java Python is written in
Python but it is just some suit lopper
so when did this tool very fast but we
felt code base is too complicated
performance is important it's true so
but we feel simplicity is also important
because algorithm or logic for analysis
he frequently changes in bio modest
field so to follow the cutting edge
method and repeat trials and errors both
performance and sapristi should be
realized simultaneously so that we
decided to use closure by closure
performance is achieved by concurrent
processing and simplicity is achieved by
sequence processing
I will show details of this processing
using one above source libraries its
Crozier rhodium is DNA sequence
alignment map library for closure
the crew gem is open source on github
and its latest version is 0.5 to 0 we
also publish the academic paper of crew
jam in the academic journal source code
for biology and medicine so part of this
talk is written in people so please if
we were interested well I explained from
sequence processing so why chickens
processing important in genomic analysis
that is because genomic data is actually
character sequence so as many of you
know DNA and RNA consists of four
nucleotides 80eec
so attaining and signing for DNA and
Yoshi for Eleni and guanine and cytosine
so genome data is crack the sequence
including such a digital letters to be
accurate sequence including a lot of
segments that is ATG she chickens like
the right figure because energies
machine cannot lead entire genome
sequence once so obviously its partial
segments of genome sequence that is
called leading so there are some lead
letters in the light figure a and T and
C and C a different base from different
sequence we can know they might be a
genetic power instrument so Lisp is good
at least processing so once you know
Roger is also good at
chickens processing especially in
genomic analysis it is because of
higher-order functions and ladies
sequence so higher-order functions
enable the sequence processing simple
intuitive and easy to change and lady
sequence neighbors processing with huge
genomic files higher-order functions
functions like map and filter and
enclosure threading macros are very
convenient for sequence processing it
seems obvious for CRO cherien's but it
is truly useful for genomic analysis
because genome data is actually sequence
data and sequence processing like a
filtering sorting is very common process
the bureau code is an example of leading
and passing some format file using
corrosion some form of this one of the
format's genomic data some leader opened
the sound file and some lead alignments
with segments of genomic sequence from
the Sun reader so filtering by our name
is very common so if you want to get
only she hl7 segments add field like
this CTR seven means seventh Kelantan so
if you want to get only frog in sixteen
at this filter so sorting by our name or
position is also popular process if we
want to sort by position our sort by
force
so these easy adding and removing such
sequence functions are very important so
these quick trials and fixes are needed
at practical scenes in genomic data
analysis so because basically genomic
analysis is still somewhat experimental
and unstable so by humans trying to find
better filtering our parameters night
and day so the combination of closures
chicest factions and leopard accelerate
this process and also Mary T's latest
sequence the most of closures secant
function return' logistic in genomic
analysis lady sequences so useful in
point of memory because huge genomic
data cannot be held in memory so ladies
chickens from firing input like line
sheik make sequence processing waste far
too simple so like the left code nine
seek returns lasik from breeder
similarly the master bleeding functions
of occlusion also written ladyship from
large gem files so like the light code
this course works on terabyte size files
this course style is quite readable and
intuitive I have introduced a rival
recursion but said another by
Aeronautics library in Crozier GOG bio
sequence it is not our library but
syllabus frequencies across a library
designed to make the manipulation of
biological sequence data each year
this is has a similar motivation indeed
MIOSHA bio sequence it it is written
that mechanisms for already processing
sequences from the large file that is
say motivational Croton one so from that
you in Noack Rogers ladies chickens is
suited to genomic analysis next is about
concurrent processing sometimes
Crozier's performance becomes a hot
topic this is a few example a sled of
wise closures Ostrow in Haqqanis NASA is
is Crozier performance theory that but
let it I think that not not against
usual answers for these questions are
that closure has extremely good
performance for dynamic language in
comparison with spicen or dobby but
crucially is much slower than C or C++
so it seems light but I think not so so
it's not always true in practical cases
it's because concurrency so as in known
Crozier provides very easy and strong
concurrency mechanisms so basically
closure has four types of compresses the
first is agent functions including send
and send off the second is future
functions team applied functions also
internally used futures or FEMA because
people it is a what is a kind of future
also concurrency mechanisms there are
equations and reducers so in these
features which is appropriate for
shickens processing so for seconds
processing PIM map and lead users seem
well-suited
P map is extremely simple to change
shield sequence processing to mass
leaded one so it just depressing map
with pin up so but in such cases simple
replacement may not be so good
performance because of context switching
so we usually remember a partition wall
or a schema pattern so that's pretty
sauce thickens with fixed chunk size and
evaluated a chunks concurrently pin up
is best in the point of simplicity but
we cannot control parallelism like the
number of slits so pin up always use CPU
processor slits so we don't use pin up
inclusion so about reduces the uses uses
Javas function and framework and has
great performance
it uses looks like good choice but it
cannot be used in our case so there are
two reasons for that the first reason is
the reduces fold only allows persistent
pictures and maps so in other words all
analyzing data needs to be in memory so
but as I mentioned before genome data is
so huge so that cannot be heard in
memory
another reason is IO bones for leading
becomes a bottleneck when increasing
number of slits so if comparing two ways
above way is leaning for fast and
processing concurrently after that
another way is processing while leading
file so if comparing these two ways just
below way is faster in your case so of
course that depends on machine specs or
analysis algorithm but we don't use
reduces for these reasons so what do we
use currently B is great pool ever be
repo is not our library but it is very
convenient so we have a we use it
crippled provides a flexible Pima and
other parallel functions such as beam up
be called p4p du chic cripples pinup
receives a threat to was the first
argument so we can control parallelism
like the number of sled kinds of sleds
and sled lifetime
in addition grapples functions similar
to logical functions except for the
first statement so it is easy to make
the sequence processing concurrent
so in the block code CP will shut down
controls read through lifetime and CP
thread to creates a new thread provost
specified numbers LEDs and CPU Pima
excuse the function color controlling
tree like closure coop image so per team
all-pro schema patterns also appeared
such calls are frequently find in rock
rhodium source code let's see actual
performance and simplicity of our code
this execution time under change number
of sleds
the Left Church is one indexing process
and the lightest one the pilot process
so it so why not explains a detail of
the process but there are such process
in genomic analysis with starting point
two gigabyte size genome data of the
1,000 genomes project and measured d
soon these 12 cores machines the blue
line is changeable our library corrosion
the green level green lines some third
one
let Lyons : dispersion Sun Tzu's and
Cora did not support much leading
execution sauce the time under once
ladies only drawn from these lizards
education times for cruising getting
better until four slit indexing and
three in pilot times of a concurrent
crew Jamar near ones for other two so
indexing almost same as curve and twice
longer than some toes and in pile up one
point three times longer than some two
we think these results are enough for
practical use
so this measurement is at the time of
our Journal paper so using somewhat old
version of Crozier manga that soon so if
you want to check the latest performance
try measuring it inclusion project it is
probably much much better chance than
that Benjamin I created a simple
benchmarking framework called library so
for easily checking performance the
library provides a closure test like
benchmarking features like def bench and
also lining improving and build tasks
and optional criterium interrelation so
after preparing a benchmark code in
bench directory and you just input
command line library so it's very easy
okay I think continuous Mitch marking is
so important to avoid performance
degradation in the project that
performance is a critical issue
well how about simplicity
unlike performance it is hard to measure
simplicity because it is subjective so
this is lines of code comparison between
corrosion some tools analytical light
most column shows a number of effective
lines to the roshi approach honest about
quarters out of Santos and 1/9 data
picker of course this result may not
show actual simplicity but we feel the
code base of Chrome is more than simple
from these lizards in bioinformatics we
found closure satisfied both performance
and simplicity so that's why we decided
to use closure so I think performance
should be considered from the point of
total cost of implementation and
thinking on that point closure has a
marvelous balance of them so and it is a
most important
lust are you touching how closure is
used for a wide range of our salvation
we provide a total genomics region
called Corvis the name of curve is comes
from chromosome and visualization Clovis
supports full range of data analysis
including genomic biological medical and
clinical data the Clovis consists of
four modules Clovis analysis for genome
data analysis and club's database for
connecting general information and
academic knowledge snippet for reporting
medical leaders Phoenicians and expert
panels and Clovis browser for
visualizing analyze information for
researchers the Clovis is actually used
in the Sun field for example in the
project used in the University of Tokyo
Kirby C is basically a web-based product
so using K axis an Isis lizard through a
web browser for example genome browser
is fast and seamless lending and
knowledge so changing and clinically put
these are all built on modern web
browser so of course we also use closure
in the spots for example all Co N Sync
and so on
so now I I shows demo of Crabbie's
and difficult to the on this piece from
this angle
okay I prepare the movie this is a demo
of the Clovis visualization this is a
Clovis browser demo so once the four
modules so this demo site is open to the
public so anyone can try the demo from
the provost website so let's write on
the top toolbar you can choose a
chromosome position scale and search
engine name and the left pane list of
difference and genomic files so in some
mapping histogram of genomic data
segments data are shown so we use a own
and equation for the top toolbar or left
pane and in maintain we use a WebGL ones
webworkers for management managing local
data or for for high-performance land
ring
hmm
this is overview of our system so the
genome data led by NGS is spreaded by
pre-process so under normal ones to more
data pass-through is reprocesses and
they integrated and the bryant
information is analyzed so the notation
modules are no teachers such as
knowledge about relation between pillai
ins and clinical information from public
databases like TB snip cream bar
clinical trials and academic journal
papers database like a PubMed oh so and
an teacher such an information to
Brian's data and in this port we use
somewhat AI technologies like natural
language processing and deep learning
then in deporting modules reporter LNG's
does information and life law data and
submit them to uses the three kinds of
users can access these reports so
researcher can access untreated
information and analyze raw data so
using for academic research expert
panels can see the reports through
website clinicians can see the paper
report this is a LOF data flow so where
is closure
used in this role
this opera is show related libraries
used in each pot can you see green names
closure libraries for example I will
generic and Co Inc used for quality
control and as I mentioned before
corrosion and cripple used for salt
indexing duplication and the alignment
process and crater also used a Bryant
core process and in sanitation module
until to use less dpi to communicate to
knowledge such engines wanted to use a
coj HTTP and knowledge search engine
uses link or body or so providing for
providing a less dps harbor and using a
Java JDBC yes yes care log time for
managing MySQL and crew she and I need
to use AI technologies and then it is
Python libraries in reporting modules
Nelly Putin uses a pie de closure script
on saffron and for rendering web
lipids and our original datastore for
states to follow
data is also used for cache and data
codec she shall and Sabri like this like
this we is closure and kocha script
everywhere in oscillation so by the way
this is my abstract so according to my
was locked
nineteen ninety percent of our solution
is written in closure nineteen ninety
percent is very high
so some of you may feel it is
overstatement this is a maybe line so I
think so too but to tell the truth it is
overstatement a liquid this is real
statistics
this shows a rosy distribution of
programming language which does not
include comment lines and hot lines so
pro-german clojurescript code accounts
for 80% of our salvation so I'm afraid
that it is less than 99 percent job
accounts for 12% and pison for 7% that
is because we use Java for some
low-level IO and Python for a later
calls so but nineteen ninety percent I
said is not all together lie so because
we feel making a tea person disclosure
because culture code tends to be short
for s expression and high-level coffee
cheese so s expression makes code
definition called Direction somewhat
horizon - so line road so besides
closure coffee features are very high
level and I was plucked so it's easy to
express logic with short code okay I
summarize my talk as I close your prose
for genomic analysis both simplicity and
performance are realized by features of
signal processing and concrete
processing this enables us to
concentrate and accelerates
essential logic so another process that
Crozier Crozier script and the existing
very general so our solution curve is
use disclosure everywhere
from analysis module reasons park and
and to serve visualizations away front
end sub outcomes have not so talked
about weak points of closure but from
our experience I feel Crozier is not so
good at some two means so the first is
low level I own so as I mentioned some
process I abounds so there is a limit to
improvement by concurrent processing so
he is pure Java for such ports for
example we load bi z4j library in pure
Java busy ZFS rock music format which is
commonly used in bioinformatics and
another week to me is early dated
domains such as natural language
processing and machine learning or deep
learning
so today person is a major interface of
these technologies so and we actually
use Python libraries but I had great
talks about AI in disclosure kanji so
about cortex deep running forging and so
on so I feel these domains of closure
are getting better so we might change
our implicit code with using closure so
if so is a near future truly nineteen
ninety percent of our system might be
little enclosure that it all thank you
for listening</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>