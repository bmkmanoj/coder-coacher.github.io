<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>In situ model-based learning in PAMELA - Paul Robertson, Tom Marble | Coder Coacher - Coaching Coders</title><meta content="In situ model-based learning in PAMELA - Paul Robertson, Tom Marble - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>In situ model-based learning in PAMELA - Paul Robertson, Tom Marble</b></h2><h5 class="post__date">2016-12-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/i84i1X9k8_g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning I'm going to pick up from
where I left off closure west back in
April talking about the developments in
our Pamela system and language this is
approximately what I'm going to do I'm
going to start off by trying to situate
what we're doing I know I've run into a
lot of people here already who were at
closure West but not everyone so I want
to make sure everyone knows what we're
doing and why and what the Philosopher's
losophy is then I'm going to talk about
part of the learning that involves
transitions and then I'm going to pass
the baton over to one of my colleagues
and we will have a short demonstration
the the primary team consists of five of
us four of whom are here today the one
who's missing dr. Hoffman has been doing
a lot of work in deep learning and maybe
we'll come back to another closure
conference to show some of those results
so I wanted to start off by giving a
little history of the of the idea Pamela
is a descendant of a long string of
languages and we've we've taken things
from these listed antecedents
particularly the MPL are NP l train of
languages these date back quite a way to
Xerox PARC and then to to NASA where
they were actually deployed in lisp on a
spacecraft in 2001 in the Deep Space 1
experiment in which the spacecraft ran
for a period of time autonomously using
this technology written in Lisp and was
able to among other things diagnose
faults that were injected into the
system
since then the technology has largely
disappeared into academia where there
are various groups around the world
continuing these ideas but the the tools
all belong to these little isolated
groups and there's really nothing
available to anyone who wanted to try
and deploy these ideas so part of our
goal here for which we obtained our
funding was to take this set of ideas
not as is though we added a the
dimension of machine learning into the
equation and to make this an open source
project so that these capabilities are
available to the world because it's time
to start deploying them here on earth
not not only in space so those of you
who don't know are MPL or MPL it's a
modeling language it lets you model
systems cyber physical systems for
example like a spacecraft the the
primary thing that we're bringing to the
table is adding in support for machine
learning machine learning has now become
essential the the way we build
applications today involve interacting
with the real world i'm talking about
robots i'm talking about the amazon echo
i'm talking about all of these
applications that deal interact with
human beings or with the the world at
large and these kind of systems need to
be able to deal with unexpected
circumstances need to deal with vision
and human language and all of these
applications the key to success and
these kind of interface with reality is
machine learning and there's a great
amount of work done on machine learning
it's not that well used outside of
research groups because it requires a
fair amount of expertise so part of the
philosophy here is that we should make
machine learning so that you don't have
to be a machine learning expert to use
it what you need to be an expert in is
modeling describing your sister
for which machine learning is necessary
and that if the modeling language has
sufficient expressivity we can integrate
the machine learning automatically the
second idea is that machine learning has
often been a side project the machine
learning pieces done on the side they
collect some data you turn around for a
few hours maybe for a few days to learn
it and then you extract the magic
numbers and put them into your program
which you then ship that doesn't have
any machine learning in it whatsoever
part of philosophy here is that machine
learning belongs in the application and
it should continue to learn while it's
an operation they want to show you a
little bit about one of the aspects that
is working quite well right now and we
have a long list of things I already
mentioned deep learning which I'm not
going to speak much about today I'm
going to focus on a simpler form of
learning though I hope it makes the
point so the rectangle depicts what a
Pamela program is it's divided into two
parts there's the part that models the
plot and when I'm talking about the
plants the plants sometimes is a piece
of hardware it might be a spacecraft
might be a robot it might be a it might
be a power station some physics either
physical system that we want to have
some control over and have some
observability of we need to describe
what that plant is at the level of
abstraction suitable for our goals the
Pamela control program allows us to make
that plant do something rather than just
watch it we can actually cause it to do
things like for a robot we might want it
to go from A to B for example so we can
divide the Pamela model into these two
basic parts the control program goes
through a a system that can
manage the unrolling of a control
program with the real plant the red line
here depicts the barrier between the
pamela program and the plant whether
that plant can be a robot a real
physical thing or it can actually be
another software thing there's not that
much difference these days if you're
communicating with something over the
network it takes on many of the forms of
a cyber physical system even though it
doesn't have any physical counterpart on
the other side the the Pamela model
enables us to interpret the state of
observations that come from the plant
it's in the context of its model that
the observations from the plant makes
sense and those can be used in
conjunction with a control program to
appropriately control the robot so if
the robot has to be at a particular
place and observations that we're
getting from the robot or where it is
then that makes part of the control of
moving the robot to the right place that
was all that I described a closure West
but as I said the key magic sauce here
is learning algorithms so if we add on
to that learning algorithms given the
model of the plant we can automatically
extract from that what it is that is
learnable and invoke the appropriate
learning algorithms which have been
integrated in a way to detect their
applicability to two things in the model
of make this I'll give a clear example
in a moment observations that come from
the plant now not only go into the state
estimation box but also streamed they
they get stored in a database we happen
to be using MongoDB here but we could
use any database suitable of storing of
JSON and those observations are then
available for the
learning algorithms the learning
algorithms then don't have to be
separated from the application the
application is continuously generating
these observations the learning
algorithm is by virtue of the plant
model know how to interpret the
observations and can do the apply to
learning algorithms as needed and they
can put back into the database what it
is that they've learned and those things
can be fed into the plant state
interpretation books so that's that's
essentially the vision of what a pamela
enabled application looks like there's
whatever it is below the red line which
we have some amount of control over and
some amount of observability of but much
of that is hidden as a black box except
for a well-defined interface and we have
a model that encapsulates what our
knowledge is about the correct operation
of that plant all right to start off
give a very simple example of a very
typical example it's simple but also
hard it's hard in the sense that in real
life things tend to be easier than this
because there are more constraints
examples that are very simple tend to be
less constrained and therefore are good
examples of tests for machine learning
in this case we consider the the idea of
coin tossing when I toss a coin it's
considered to be fair because there are
two sides and the likelihood of one or
the other is even but we all know that
we can replace the coin with one that
has two heads and then suddenly it's
decidedly not fair and with die we can
we can similarly wait to die so the
probability of certain numbers is higher
than others and if you know how it's
weighted and you you bet on it you can
win in this case we consider the
possibility of a weighted coin one in
which the probability of it giving a
head is different from the probability
of giving it a tail and we imagine a
coin a coin toss our and the rules of
this game I put the text in here
for the benefit of the reader but that's
not you that's for someone else in the
future who wants to read the slide I'm
going to prefer to describe it this way
the the coin toss er has two coins a
fair coin and a biased coin and
occasionally he changes which coin he's
using so you come up to his table he
wants he wants to bet he costs tosses
the fair coin a few times and you see
that it's fair and then while you're not
looking he switches it for the biased
coin and then that's when he takes you
to the cleaners in this case we
represent that as this state transition
the coin is either biased or unbiased
and in using these numbers point 9 is
the probability of remaining with either
the biased or the unbiased coin but one
time out of 10 it he will switch coin to
the other coin so we these numbers in
cups Utley transitions between these two
states encapsulate the idea of the
probability of switching the coin and in
the the emission probabilities are shown
at the bottom in the case of the
unbiased coin the probabilities are even
it's a fair coin and in the case of the
biased coin there's something else and
we can change what those something
else's are where they should add up to 1
so it's a standard problem and very
simple the idea here of course is that
the person playing the game can see the
heads and the tails that get flipped but
here's no idea which coin is being
tossed and part of what we are trying to
do here is to estimate what the hidden
state is the hidden state here is which
coin is being used so if you see a
sequence is a sequence of heads or tails
can you determine approximately when he
switched the coin the answer is yes and
there are machine learning algorithms to
do that and here's how we can model that
those of you who didn't
see my excruciating explanation of the
syntax in april i think this shouldn't
be too hard to to follow anyway def p
class introduces a pamela class here we
have a class that represents the values
head and tail this is what can be face
up after a toss and then we have the
coin class which might have been called
the the tosser or the player because
he's either tossing with the bias coin
or the unbiased coin so he has these two
modes the fair coin tossing or the
unfair coin tossing now what
observations do we get as I said the
only observation we get is is a face up
we get to see what faces up after he's
tossed the coin but we certainly don't
see him switch the coin that's what
we're trying to estimate here so the the
diagram here that showed the transitions
between biased and unbiased represented
straightforwardly in transitions here
these are names biased unbiased the
precondition that it's biased and the
postcondition is that it's unbiased and
the question is what is the probability
of that switch we don't know because we
haven't learned it yet but we can
estimate that if it's biased it's
probably going to switch about Oh point
one five of the time the probability of
a switch is about point one five these
numbers don't have to be correct their
their input from the engineer from the
the person who wrote the program a lot
of learning algorithms work well if you
concede them in approximately the right
region and then they can be learning
converges faster so we have these for
these numbers aren't the same ones used
in the in the diagram but they will
converge to whatever is real as it
learns in this case the plant that we
built was in software it's
uses a random number generator and the
program has real numbers fixed in it for
what the transition probabilities are on
what the emission probabilities are and
by using their call to a random number
generator it respects those and then the
learning part has to learn those the
emissions are dealt with like this we
have a method called flip now flip is
implemented in the plant so it's a
primitive method so primitive true means
that this method is implemented in the
plant but we have a body for it and the
body describes our model of that thing
that's in the plant and the model is
that the first choice if if it's in
biased mode then it's going to choose a
head with probability point eight to
this is the emission from biased of
ahead and this again is a is a
guesstimate of what that number would be
and the elva indicates that this is a
learning variable so the the code that
invokes automatically learning
algorithms searches for where the
learning variables are and based on the
structure of the problem decides what
learning algorithms are appropriate hit
similarly we have the probability of a
tail if we're biased and the and the
same things for the unbiased case
so then we need it to train we don't
actually have to do anything for it to
train if the thing just runs by itself
if we had a human who was doing the
tossing and we were just monitoring it
then we would get the observations of
heads heads tails tails at so on those
observations would get dumped into the
database when there were enough of them
the bomb Welsh learning algorithm in
this case would be invoked it would
learn the probabilities and then it
would be able to indicate when it thinks
the coin has been switched based on
those learned probabilities using the
Viterbi algorithm in this case what
algorithms are involved depends on the
structure of course of the model in this
case in order to force the plant to flip
the coins we have this this simple
control program the flip sequence which
a thousand flips the coin a thousand
times that simply flips it with the
flipping observations come in they get
stored and then the learning
automatically takes place and later on
it will be able to tell us when it
thinks the coin has been exchanged there
would be a useful thing to know if we
were betting that we think that he's
changed the coin because the last few
ones were last few flips were rather
improbable for a for a fair coin so this
is a this is a output of our test in the
the top graph shows the ground truth
this is the plant actually telling us
after the fact when it switched the coin
and the two graphs beneath it are when
the learned version decided that the
coins were fair or unfair they're not
identical obviously and of course
because it's it's random it's it's not
impossible to to flip ten heads in a row
with a fair coin it happens so that's
why I said this is this is a
particularly hard problem however it
does amazingly well
and the first the middle graph shows
using a sequence of a thousand flips to
be able to say when these transitions
occur and the bottom one is where we're
only looking at a hundred data points we
can try it with different numbers of
data points and there's a good point
there because depending on how many
points you use for training and how many
points you use for observation to decide
when eclipses occur affect parameters
like timeliness of the observation or
the accuracy with which the
probabilities are learned these are
things that the designer might care
about and be able to put in the program
and then the learning algorithm can
attempt to achieve those levels of
accuracy or levels of timeliness or make
the appropriate trade-offs so our goal
here is to make it possible to write
models to specify what your requirements
are and to let the learning algorithms
be selected and parameterised in order
to meet those goals as best as as
possible perhaps with some hints here on
that the first this set was where the
probability was point nine four heads
and point one four tails for the biased
case and this second one is where its
point eight four heads and point two
four tails as the probabilities come
closer to being a fair coin it becomes
progressively more difficult but a point
8.2 it still works well enough to make
money on in a bit and but when you drop
below point eight the results start to
deteriorate but that's not our fault
because we are we're not magicians we're
just integrating machine learning here
and making it available to you so
something that's much simpler than that
is the notion of temporal bounds often
when we do something we want to specify
how long it's going to take if we a
typical one in a in the space scenario
is if you want to
do an orbital insertion of a space probe
you need to fire the engines to reduce
its speed as it gets to orbit and that
requires that you heat up the catalyst
bed perhaps many hours ahead of reaching
the orbit so any plan that involves an
orbital insertion has to involve turning
on the catalyst bed heater hours before
arrival at the planet in question
otherwise are going to fly straight by
it so time durations are essential in
cyber physical systems not all of them
but in many of them and often it's
essential in software systems to how
long is too long if you're trying to
connect to a server somewhere in the
cloud how long is too long to wait for
response for your a database query there
are answers in there and typically
people make them up here's an example
here where we're turning something on
the bounds you see for the method the
method has a precondition and a post
condition which were not interested in
right now but the bounds between one and
three milliseconds that's how long the
engineer thinks that this turn on we'll
take this this is pretty much the way
these numbers generally come about
people have a notion of when is an
appropriate amount of time it turns out
that if you know the real numbers the
programs are a lot more robust and a lot
more useful so we want to learn those
numbers rather than have engineer simply
make them up so rather than just putting
these numbers in here which we can still
do by the way if you insist on making
your numbers up but we can replace them
with these learning variables that we
showed in the previous example here we
say that we're guessing that the myth
the lower bound for the turn on to be
effective is one millisecond and the
upper bound is three but we can learn
these two variables how do we do that we
we simply record every time this turn on
is performed when it was started and
when it is completed
and after we have collected up enough of
those we can do statistics on it we can
find the mean and we can define upper
bound and lower bound as being plus or
minus two standard deviations for
example so these are these are things
where we can specify how we want to
define upper and lower bound and have
the system collected data magically by
itself continued to retrain because
sometimes over the life of a switch it
might it might slow down from age and we
can have these numbers track the reality
of this I'm a physical system as it goes
this is very easy with with the
observation catching and databasing
architecture that I described at the
beginning I want to briefly talk a
little bit about transitions because
transitions or what this is all about
and transitions are amazing things and
in fact they're they're largely
underappreciated and we can do a lot
with them so consider this example this
is an example of a a car rolling down a
hill and slightly back up the other hill
it could be formulated with an engine or
without an engine it's defined in terms
of three differential equations this is
a most simple imaginable rendering of
these equations possible with a non
engine case but we have a forward
movement when DX by DT is greater than
zero back with movers when it's less
than zero and when it's stationary at
the bottom its first and second
derivatives are zero but some point we
have to transition between these and
interesting things happen when when you
transition when you when you go from
moving forward to standstill like when
you come to a stop at a traffic light
there's not just a simple switch between
forward and stationary weird stuff
happens you will notice if you drive up
to a traffic light and you put on your
break the
just at that point where you're about to
stop weird stuff starts to happen the
parts of your car are still moving
forward but the wheels have stopped so
there's this there's this little
vibration that occurs in the car and
that's really exciting stuff because we
can we can measure that if we had
accelerometers in the car they wouldn't
measure that the car is stationary even
though the car is because the wheels
have now come to a standstill but as
vibration occurring and and the
accelerometers will register those
movements back and forth and we can do
interesting stuff with that so for
example here's an interesting transition
a 25 volt battery connected up to
connect it up to ya tour to say a motor
at the point of disconnection there is a
reverse EMF this huge spike that goes
down to in excess of minus 250 volts
which is very short-lived and then there
is the the playing out of this which
goes on for about seven milliseconds so
once the motor is disconnected thanks to
the reverse EMF there's seven
milliseconds of interesting stuff going
on and there's other take a switch if
you disconnect a if you push a button
there's physical bounce as a physical
process that the the connector actually
makes and breaks contacts a large number
of times before it settles down I think
this is around 5 milliseconds duration
in which where there's this noise that's
pretty cool stuff usually we try to hide
these things make them go away we can
put a capacitor over it you can use
various damping things we can choose not
to sample it until a period has passed
where we can safely ignore it all but
I'm claiming that ignoring it is the
wrong thing and then of course there's
crosstalk if you have one of these big
spikes on one of your wires that that's
200 more than 250 volts bike
that can be induced into nearby wires
and before you know it you have you your
your effect is no longer localized to
one particular thing but it spreads out
in particular when you're making a
transition you don't necessarily know
what you're transitioning to but you
might this the answer might be hidden in
this in this waveform so it turns out
that using our observation capturing
mechanism we can capture this waveform
because every transition goes across the
the interface as an observation we don't
damp it out we can learn how long it
takes to die down so we can learn what
the bands are when when does this period
of weird stuff and because that's what
the bound is for that that button when
we say when when I said that it was
between one and three milliseconds maybe
five milliseconds in this case that's
between when it's stable e0 when it's
stable e1 we can yeah we can we can
learn those things and we can use deep
learning to recognize these waveforms so
that when a button press is happening we
can detect early on that the transition
is happening and and which one in
particular now I want to pass over to my
colleague to talk about the interface
between the Pamela system and the plants
that it's controlling well so I'll give
a brief introduction to what the plant
interface is and essentially a plant
interface connects the smart components
like dispatcher planner to the physical
components which you'll see in a minute
the cyber physical systems essentially
it's a set of messages that go back and
forth between the software components
and the physical components you could
view it as a remote procedure call but
there is a little bit more to it there
is a subtle difference that I'll cover
shortly so there are few messages
no I briefly describe the start message
is sent by the software system to send a
command to the physical system and the
physical system acts it back as I
started and when the command is finished
or failed the messages come back
likewise when when the command is in
progress the planner could come in and
say well I want you to cancel this one
and that's where the plant would come
back and say ok cancel or whatever and
while also while the system is going on
the plant has an opportunity to send
status updates so for example if you
might have a big file transfer going on
from point A to point B and you don't
have enough bandwidth you would want to
know how long will it take and so that's
where the support for status updates
comes in and observations as Paul talked
about is for sending observations about
itself to the planner I will skip this
part but this is the definition of the
plant interface enclosure and we have
implementations for the plants and you
could implement it in any language but i
hope you will implement your plants and
closure ok ok those of you who are with
us at closure West I gave an example of
modeling the simple circuit with a a
power supply a controllable power supply
and a light with a light sensor since
then we've built a physical
instantiation of this using a raspberry
pi 3 it's here with us today in this box
and we can we can see it in operation
and you can see the back and forth of
messages between the plant and the
running Pamela program so with that
you get in the cup
okay so what you're seeing here is the
physical plant in the lower left and in
the upper left is the hierarchical task
network that was defined in Pamela and
then Pamela built the hierarchical task
network file as JSON or Eden and the
temporal Planning network which is in
the upper right and now in the lower
right you see the dispatcher dispatching
the events / RabbitMQ and the physical
plant is listening to those events the
commands for example to turn on and turn
off and then the plant is also sending
its observations to RabbitMQ and that is
being monitored by the system so Pamela
is used to actually generate the plans
and what you see in the top is two
instances of plan viz which is our
closure script application to actually
visualize particle task networks and
temporal planning networks and this is a
a lot of fun because it's allowed us to
take the modeling language that we've
designed enclosure and actually use
closure tools on the back end as well as
on the front end and because our
interface is abstract 'add through
RabbitMQ it you know the language on the
other side and the plant is completely
independent of this and and can respond
accordingly so Paul I think you said
that you were thinking about publishing
the plans for how you constructed this
box and the software you installed in
the Raspberry Pi so people could
reproduce this at home yeah we're going
to put all the details on the website or
into the distribution so those of you
who feel inclined to build one can do so
in this in this example we were sending
commands from the from the control
program to turn the light on and off but
this button here also responds as a
normal button with so we can turn it on
and you can
see in the ago
they agathi the the button presses are
coming across the RabbitMQ interface the
plant interface so whether we're turning
it on and off manually or whether it's
being controlled that information is
coming across into the database and we
can learn from it so it's a very simple
example there's an implementation of the
example that we work through laborious
ly at tozhe west's at the beginning of
the year and
so just a couple of words about the open
source project after listening to riches
talk last night I've for some reason I'm
less enthusiastic about semantic
versioning on one thing that rich didn't
mention about semantic versioning is the
importance of the major version going
from 0 to 1 you know and 0 up you know
it's it's considered ok that the API is
changing because it's not solid yet and
then 1 point 0 it you know then then you
have an API and then to your you're
breaking the world and that's bad so I'm
especially sensitive about not breaking
any one with with Pamela I'm really
excited to say that this is a great
project it's a fun project because it's
a DARPA project we get to code and
closure and we get to work in the open
so you get to see our work in real time
and all the pretty things and maybe not
so pretty things but it's available on
github under the permissive patchy
license and no contributor agreement is
required we're quite enthusiastic about
getting support for it it still is early
days for Pamela for those of you that
were a closure west we've done some
significant changes to the Pamela
grammar in particular we're now
supporting a hierarchical task Network
representation we have this sort of idea
of I'm saying in air quotes macros Paul
showed you a code snippet earlier where
to do the machine learning we were
flipping the coin a thousand times so
that the thing that said do times a
thousand is sort of a Pamela macro the
thing to remember about Pamela as a
language is it's a DSL it's a
declarative language to describe a model
it's not an imperative programming
language so that's that's one important
distinction about when you're thinking
about Pamela the parser is reimplemented
with insta parse and there were a number
of things that we did in the UI side
with plan biz to make it better in
particular I'm really excited about the
fact that we can take the graphs that
you saw that are really pretty and
rendered in SVG in their browser and you
can export that to SVG to a standalone
SVG file now we're
mining for a q1 next year to do a
release which will hit one point oh very
important we're going to be very
sensitive to your needs that will
include the details of the plant
interface the Prakash described to you
also we're going to have at least one
planner a Monte Carlo temporal planner
to go along with it and belief state
estimation module which is part of the
larger plant diagram that Paul described
and some facility for machine learning
so I think that that's one of the things
that sets Pamela apart from other
modeling tools like prism that you might
be familiar with in prison the developer
has to hard-code these numbers in and
it's sort of a static thing Pamela is
different in that we want to declare the
model without having the domain model or
be an expert in various machine learning
algorithms or plant actual designs and
because those things are separate we can
actually and because we have this idea
of learning variables we can run
learning on the model and then use the
learned values in place of those
learning variables the next time that we
run without changing the model and
without having to hunt and type them in
again so we'll be around for the
conference today there's actually a
pamela channel in slack and you can get
us on github and we're really
enthusiastic to talk to you more about
pamela and your thoughts about it and
how we can help so thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>