<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>John Hughes - Testing the Hard Stuff and Staying Sane | Coder Coacher - Coaching Coders</title><meta content="John Hughes - Testing the Hard Stuff and Staying Sane - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>John Hughes - Testing the Hard Stuff and Staying Sane</b></h2><h5 class="post__date">2014-03-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zi0rHwfiX1Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay well thank you very much for the
invitation that's been a great pleasure
to be here
and I want to start by asking you all a
question
who really really loves testing oh well
a few but but not very many so I didn't
really used to enjoy it very much either
but then I co invented quick check so so
why is testing hard fundamentally well
suppose you're you're writing automated
tests for a system and you've got say n
features that you want to test what
you're going to do you're going to write
maybe three or four tests per feature
right that's okay that's a linear amount
of work but we all know that you won't
catch all the bugs that way because
there are some bugs that only appear
when you use two features together oh
well if you want to test for all of
those possibilities then you've got to
write a quadratic number of test cases
that's starting to sound not so much fun
and actually some bugs don't appear just
when you use two things together
sometimes you need to use three things
together to provoke them if you want to
test for all of those you're going to be
writing a cubic number of test cases and
this is really starting to ramp sound
like a lot of work and what about race
conditions they're the worst of the lot
because by definition the race condition
involves an interaction between at least
two features and what's worse it doesn't
even strike every time you run the same
test so you know ah this is horrible so
this is why testing is hard you can't
test everything you can't test enough so
when you're going to stop what's the
answer
don't write tests
generate them and that's what I'm going
to talk about it's what I've been doing
for quite a few years now
the original Haskell quick check which
perhaps many of you have come across as
something that tool passed when I came
up with fifteen years ago in 2006 then I
started cubic marking ting a version in
ED lang and since then we've added many
many extensions and we found a lot of
very fun bugs for Ericsson and Volvo
cars and Bosch show and many others so
what is quick check well it's a random
testing tool and the most common way
that we use it is we take an API under
test and often the API is that we want
to test are not purely functional sadly
but there we are so in order to test the
API it's not enough just to make one
call we generate a random sequence of
calls and then maybe that test will
passed if so we generate another and we
keep doing that until we generate a
sequence that fails now when a sequence
of calls fails a test it turns out that
it's almost always because of just a few
calls in that sequence so when you
generate your sequence at random you
have a whole lot of irrelevant stuff
that is mixed in with the few calls that
actually provoke the bug so the next
thing that we do is the shrinking
process that you might have seen re
Draper talk about we search for those
calls that are really necessary to
provoke the failure and we generate a
minimal failing example and that's then
what we report the user for debugging
I'm going to show you an example of
using quick check I'm going to test a
little bit of C code it's a very simple
example but it illustrates testing code
with side effects it's going to be a
circularbuffer so
there's going to be a call to create a
new one here's a circularbuffer with
three slots and it's going to have an
input pointer and an output pointer and
then they'll be an operation to put
something in which just increments the
input pointer and there'll be an
operation to ask how many elements are
in the buffer right now and of course
they'll be an operation to take things
out again so standard circular buffer
and of course when we reach the end of
the buffer then each of these pointers
is going to wrap around so you can
imagine that it's quite simple to write
this code but maybe the size operation
is a little trickier than the other two
and here's the code I wrote for it I
think it's it obviously works I just
take the difference between the input
and the output pointers that's what the
cue arrow imp and Q arrow out are and
that I take that difference modulo the
size of the buffer found to work so how
do we test this kind of code well the
approach we found works well is to use a
state machine model what do I mean by
that we generate test cases as I said
there are sequences of API calls but
then we also model the state of the
system in some simple way and for each
API call we define a state transition
function that tells us how the model
state changes and then we write post
conditions that compare the results of
the real API calls to the state of the
model okay that's a bit abstract oh I
should say all of this stuff by
specification is always written in ad
Lang not closure I'm afraid but you
can't have everything
but this is a little abstract let's see
how it applies to this circularbuffer
example well I might generate a test
case that looks like this put 1 you put
2 you get something out you put 3 you
get something else out hmm how can i
model declaratively the state of that
buffer let's see maybe the list of
integers that I think should be in the
state so my green model is going to
start off as the empty list after I put
1 it'll be the list containing 1 after I
put 2 it's list containing 1 and 2 and
so on and now my post conditions will
just compare the result well the result
of get is the only interesting one in
this case and check that get actually
returns the head of the list here's a
specification of get we write
specifications by defining a number of
callbacks callback functions that are
then invoked by quick check as we run
tests so get has a precondition s there
is the model state and it's slightly
more complex than my diagram the state
is a record and that s hashed state
putter
that's Airlines notation for accessing a
record field so what the precondition
says is that the pointer must not be
undefined that means you've got to call
new before you can call get make sense
right and also the contents of the queue
must not be empty you shouldn't call
gate if it is the next definition is the
state transition function it says when
you call get then the model state
afterwards just has the contents equal
to the tail of the model contents before
and the last bit is the post condition
it just says that the actual result that
is returned from get should be equal to
the head of the list of contents so as
you can see they're very very simple
pure functions that form the
specification of get and the other
operations are specified equally simply
so
let's run some tests oops
what has happened the right thing good
so I have a I'll show you the C code in
a minute but in order to run these tests
I will need to compile my C code I'm
running this in the airline repple and
this is I've just invoked GCC in the
background I'll need to compile my
specification and now I can run quick
check and I can give it the property
that is in my specification as an
argument and oh ok there's something
wrong my C code now what you see here is
you get my pen whole lot of output first
of all oh this was this was the random
test that initially failed and then it
got shrunk down a bit to this and what I
want you to look at is this bit this is
the kind of pretty printed trace of the
test that lets us see what actually
happened so I called Q new to create a
queue of size 1 and that returned a
pointer to a queue with that address and
then I call put to put 0 into it and
then I asked for the size and the size
was zero that's not consistent with my
model the post condition says that zero
what I actually got was not equal to one
so what happened there well I just put
something into the queue right there
should be one thing in it but sighs
return zero that can't be right
let's look at my code
here's the size function so you saw the
test case the Q is of size one so I took
I took the difference between the input
and output pointers modulo 1 but
everything modulo 1 is zero so when the
Q's of size 1 this size function always
returns zero oh dear that well that
can't be right
ok um let me just demonstrate the the QT
with a little example I'll create a
queue of size 3 just to show you that
normally behaves as we'd expect we've
got a pointer back oops
let's put 1 into the queue let's get
something out with the queue
we've got 1 let's get something else you
see it behaves just as you expect
there's the 1 again ok but obviously the
size function wasn't right ok so what if
you think about it this isn't a problem
just the Q's of size 1 my input and
output pointer wrap around when they
reach the end of the buffer so if I've
got a queue of size N and I fill it full
the input pointer is going to wrap
around back to 0 and now my input and
output pointers are both going to be 0
just as in an empty queue this is the
problem
I can't tell an empty queue apart from a
full queue what should I do
any ideas
well I could for example here's my
representation this is a strut that
represents queues there's the input and
output pointer and the size and the
pointer to where I keep the data I could
put a bullion in here it couldn't die to
keep track of whether it's full or empty
but that would be horrible special case
code no no let me show you a beautiful
hack the only problem is when the queue
gets full so when I'm asked to create a
queue of size n do you know what I'm
going to do I'm going to create one on
size n plus one okay this is where I
locate the data this is where I
initialize the size field just put M
plus one in both those places and now if
anybody puts actually fills my queue and
put M plus one things in it's their
fault
because they asked for a cue of size n
so I can avoid blame and this is of
course the true purpose of all good
software engineering ok
so I fixed that let me recompile and now
I will just rerun the last test that
failed which I can do if I just read
take away the quick check that will
rerun the last test and it passes ok so
that's good
by the way that hack it's the standard
textbook fix for this problem I only
found that out after I started showing
it to people that's and that's it so now
I fixed the bargain surely it now works
but let's just run some more tests oh
darn it failed again ok what happened
I created a queue of size one okay one
that's really - don't tell anybody I put
a zero into it that's alright I called
get to take a zero out I put another
zero into it so how many things are in
the queue one and size returned - one
what went wrong could anybody debug that
there's my code
yeah the size is now really - I put two
things in so I incremented the input
pointer twice it wrapped around to zero
I took one thing out so the output
pointer is now one so I've said zero
minus 1 modulo the size which is 2 but
what is minus 1 modulo 2 it's plus 1
right obviously it's just try to
deadline
oh darn Ellen doesn't implement modulo
it implements remainder and see does the
same so the problem here is that if this
expression is ever negative that I'm
going to get the wrong answer I'm going
to get a negative result so what I have
to do to fix this is I have to make sure
that this expression is never negative
how could I do that I'm sorry well we
yeah maybe I do that I I dread to think
what would happen but absolute value
sure ok so let's do that I fixed my C
code let's compile the C and I'll just
rerun that last test and it passes ok so
now I found a bug a tricky bug I created
a test case that exhibited my bug I fix
the code my test passes all my tests are
green I'm done right shall I just run a
few more random ones let's see what
happens
oh no it still doesn't work
look what happened here I created a
queue of sighs - sighs - that's better
this is progress now it works the queues
of size one I put three things into it
remember it's really three three slots
in the queue I called get once so the
input pointer wrapped around again the
output pointer is one I taken zero minus
1 modulo or zero minus 1 modulo 3 that's
- really
but what is my cold compute the absolute
value of minus one is plus one so
absolute value is the wrong thing to do
not the right fix what I can do is might
just add on another two sighs here
whoops if I type the right thing that'll
be enough to ensure that that's always
possible but positive and it doesn't
change the absolute value so if I
compile this
now it's all to work yep that test
passes I've learned my lesson
let's run round the ones oh yes there we
are 500 tests say it works now Danna
okay so there was a demo of debugging
imperative code in this manner what can
we learn from this well one thing which
I hope I've convinced you of is that the
same property the same specification can
find many different bugs and this is
something that we see happening again
and again and again and secondly I hope
you agree that those minimal failing
test cases were quite easy to debug this
is something that we experienced
repeatedly also and that we believe very
strongly so when you do random testing
then you get test cases containing a lot
of noise that is the purpose of random
tests but when you try and diagnose a
fault the last thing you want is a test
case with 100 calls in of which seven
are relevant so this process of
shrinking we think of it as extracting
the signal from the noise presenting you
with something where every call matters
for the failure and this is this
transforms the usefulness a random
testing okay that was a tiny tiny
example you might be wondering does it
work on in any larger programs well
we've spent a lot of time over the last
few years doing exactly this for real
using the same kind of specifications
the same interface to see to test out as
our software which runs in cars and
we've been doing this for Volvo cars so
one is out of source software well you
probably know that a car contains a lot
of processors nowadays 50 to 100 and of
course they all need to be able to talk
to each other so the software that runs
on them it's going to be running
different applications depending on what
the processor is for but they all need
to talk to each other
in order to do that they all run what's
called the antis our basic software and
this is a diagram of a large part of it
so you can see here maybe on the right
there's an Ethernet stack because you
might need these Anette in a car the can
bus is a very commonly used bus in
vehicles Lin and flex Rio other protocol
stacks the com services up the top that
does kind of routing between one
protocol and at another and the
diagnostic cluster that's the thing that
remembers fault code 27 one of your
cylinders didn't fire or whatever so
that when you take your car to the
dealer they can figure out what went
wrong so all of this stuff runs on every
processor but there's quite a lot of it
each of those little colored boxes is a
module and is specified by a PDF
document so there are what how many are
there there must be 20 or 30 just on
this diagram now you might think since
all these processes have to talk to each
other and they're all going to run this
software that the right thing to do
would be to develop a single open source
implementation that the entire industry
would collaborate on wouldn't you expect
that but no this is not what has
happened instead there are many
competing suppliers but there are
standards documents that specify
precisely how each of those colored
document boxes should behave and thanks
for the standard car manufacturers can
buy code from different providers on
different processors and they'll all
work together seamlessly and if they
don't then the car manufacturer of the
system integrator who's bought
subsystems from lots of different
suppliers has a huge problem because you
put this stuff together it doesn't work
the processors can't talk to each other
and then what's who is Volvo going to
blame they have they need to know who's
following the standard and who isn't and
so they contracted us
develop quick check specifications of
all of those boxes and use them for
acceptance testing of the code that they
were taking delivery of so we've had a
lot of bugs in this code let me show you
what on this a bug in a can stack so you
need to know to understand this that
when you send a message on the canvas
its message ID is also its priority so
every message has a priority lower
numbers are higher priority in this test
case we sent a message with priority one
that was sent out on the bus now the bus
is busy it can only send one message at
a time and then we quickly send two more
messages with priority two and three
they had to be queued up of course and
then we called the transmission
confirmation function which basically
tells the stack okay now the buses
finished setting sending message number
one which message should it sent next
message number two which message did it
send next message number three I can
show you why so this can protocol is
quite old and when it was first designed
then can ids were only allowed 11 bits
but remember this the message type that
meant only 2000 different types of
message in the entire car it's just not
enough for the modern car so there's a
new version of the protocol that allows
expanded extended can IDs of 29 bits
which is 1/2 million it'll keep them
going for a while but of course you may
end up putting together processors that
make use of the standard IDs also so you
have to know which kind of ID
each message type is using and you have
to use the correct representation in
this particular stack the can ID was
always stored in an unsigned 32-bit
integer but look the most they can be is
29 bits so the top bits were spare and
so the very top bit was you
to record an extended can ID unsigned
integer what that means is that when you
compare to message IDs to decide which
measures to send you have to mask off
that top bit what you couldn't see in
the test case before was that message
priority to used an extended can ID so
the stack treated it as priority two to
the 31 plus two and that's why it was
sent last so you might ask does this
matter
well the priorities are there for a
reason everything talks on the canvas
the stereo the brakes everything so so
if you're in an emergency situation
don't fiddle with the volume on your
stereo so it's important that the
priorities are respected so what I like
about this example is that although it
was a very low level error in C code
failing to mask off a bit deep inside
this code there was still a short
sequence that could provoke it which was
quite easy to debug and we could find
that short sequence by random generation
with quick check
followed by shrinking so what I showed
you working on that tiny example of the
cue also works for real and has worked
again and again and again for finding
real deep bugs in automotive C code so
this was a quite a big project we read
3,000 pages of PDFs which turned into
20,000 lines of quick check that might
sound like quite a bit of specification
but a simple code like the code I showed
you it's just a lot of it and we use
that to test a million lines of C code
from six different suppliers okay so we
had six suppliers so you might say maybe
each supplier send us 160,000 lines so
our our test code is one-eighth the size
of the real code
that's a pretty good ratio we found 200
problems of which more than 100 were in
the standard itself
I found one where there was a
requirement stated in the standard
little box and then an explanation in
the paragraph following which directly
contradicted the requirement one of the
poor implementers to do so don't believe
something is right just because it's
called a standard so this was a very
successful project and we're very proud
of it but I want to tell you about one
more great story and this story begins
with a message to the ad Lang mailing
list back in 2007 we know there's a
lurking bug somewhere in the debts code
we got bad object and premature end of
file every other month the last year but
we haven't been able to track it down
because the debts file is repaired
automatically next time it's opened and
this was a message from a guy called
took the turn fist who works at Clara
and Sweden so I'm sure we all feel took
less pain but what's the context here so
cloner are a company that started in the
mid-2000s to provide invoicing services
for web shops maybe it doesn't sound
very exciting but it was a great
business idea
lots of people apparently don't want to
give their credit card number to a
webshop and Clara allows you to avoid
that you get an invoice instead you
don't pay til you get the goods they
have been growing like a rocket they
built their system in err lang and they
used a database called Venezia to store
all their data this is a database that
is distributed together with their like
it's used in many airline applications
you get transactions replication lots of
good stuff
but it needs a back-end to store its
data and if you store the data on disk
the back-end that's used is called debts
that provides tuple storage in files
debts is the component that turbo was
talking about and when you have a bulk
that appears every couple of months
doesn't that just smell race condition
to you he did to me and I was interested
in them at the time so I thought oh
let's see whether we can find this bug
using quick check so in order to explain
how we did that I'm going to have to go
from the sublime to the ridiculous and
talk about testing one of these do you
recognize this
it's my drawing good enough so it's a
kind of de stickit dispenser you have at
a bakery counter and if I were to
simulate that and add line I'd need an
operation to take a ticket every now and
then the roll of tickets runs out and
somebody has to come along and replace
them so let's have a reset as well okay
so it's very easy to imagine how to
implement those and it's very easy to
write a unit test here would be an
example unit test in ED Lang here test
dispenser just calls reset and take
ticket and I'm using Airlines pattern
matching to check that the result in
each case is equal to the red thing on
the left so we're just comparing against
expected results so this is the standard
way of writing unit tests right you you
call the API under test and you compare
the result against what you expect and
it's easy to model in quick check as
well there is a sample test case I might
generate hmm how can i model the state
of a ticket dispenser perhaps an integer
sure enough let's take it integers that
may be reset sets it to zero and it's
incremented by every take and then the
post condition for take we'll just check
that take returns one more than the
model state when it's called so it's
easy to do this testing but these tests
miss a very important part of the
dispensers behavior what is the purpose
of the ticket dispenser it's to regulate
the flow of a lot of concurrent
customers to one bakery counter
so if I only test it sequentially that
I'm missing an important part of its
behavior what I really want to do is to
run tests that look more like this so
this test is supposed to represent
first of all resetting the ticket
dispenser and then two customers come
along and in parallel while it takes one
ticket and the one on the left
for some reason takes two tickets okay
so now let's think what are the expected
results well the one on the Left might
get tickets one and two and the one on
the right ticket number three that would
be okay right but it's not the only okay
behavior we might also see that the one
on the right gets ticket number two
maybe he kind of leaps in in between the
left customers two attempts to get a
ticket but that's alright if the ticket
dispenser does that I'm happy what it
must not do is this we're both customers
get ticket number one so this is the
problem with testing an API like this
that is intended to be used in parallel
there's more than one possible correct
outcome so if your strategy of writing
tests is to compare actual results to
expected ones you have a problem now
here you could of course enumerate the
three possible correct results the three
results aware that one on the right gets
tickets one two or three and you could
record the actual results and check that
you've got one of these possible correct
ones but this is a really tiny test I
don't want to just run tests like this I
would run tests like this here I've got
three customers and two of them take two
tickets oh look at this third one isn't
a customer it's the service guy
replacing that the tape at the same time
how many correct results are there for
this I've worked it out for you there's
30 correct outcomes so
the whole idea of comparing against
known expected results just doesn't
scale to this kind of test nobody in
their right mind would try to predict
all 30 correct outcomes and anybody who
did would get at least one of them wrong
so you just can't decide this kind of
test in the usual way however what can
we do instead so here I have the first
parallel test I showed you but I've
drawn it on its side instead I think
this is a correct result
if this happens I'll be happy with the
dispenser but why is it correct well I
say it's correct because there's an
order in which I could have done those
calls that would have generated the
results that we see so if I can take a
parallel test and find a way of
interleaving the calls so that the
result is consistent with a model I'm
going to say that the test has passed if
there's no such interleaving then I've
seen some behavior that can't happen in
any sequential test and I'm going to say
that that's wrong okay let's go back for
another quick demo I have the
implementation of the dispenser here
let's compile it now the first thing I'm
going to do is run quick check and I'm
going to run sequential tests of the
dispenser and they all pass so what does
that show
that shows that the model life made
corresponds to the sequential behavior
and there's no point trying to use a
model that does not correspond to this
quencher behavior in parallel tests put
it this way it's as a bulky confined
with a sequential test why would you run
parallel tests to look for it it would
just be crazy
so this crenshaw behavior and the model
agree now let me run parallel tests and
the thing that I really like about this
is that I'm using exactly the same model
exactly the same specification just with
a different property
oh no it doesn't work and here you can
see what happened we did two things in
parallel two customers took a ticket and
they both got to get number one now up
here you can see the more complicated
behavior that happened in the test I
originally generated so that is the
unshrunk test case which I think you
know there's enough going on that you
probably don't want to try and debug
that so this is the shrunked result and
shrinking is equally valuable for
parallel tests let me just run this
again same result same result you may
see this no possible interleaving this
is quick check saying that there's no
way of interleaving these two calls to
get these results let's run it again so
what I'm showing you here is that
although this is non-deterministic
behavior it's a race condition
nevertheless we can find it quickly
every time and we can shrink it to the
correct minimal example every time and I
really like that okay
that's the failed test case that we just
saw here's the code I wrote for take
ticket Adlon doesn't have global
variables but I simulated a global
variable and read and write read reads
it right writes it wait a minute that's
a critical section where's the
synchronization there isn't any so of
course there's a race condition in this
code and my point here is not that this
this bug is hard to find but that the
technology works to find it very nicely
let's talk about debts debts as a tuple
store airline tuples have curly brackets
around them and the tuples that you
store in the file have a key in the
first component and then a collection of
values
and there are operations to insert a
list of tuples into a table to delete
all the tuples with a given key insert
new is like insert except that if any of
the keys is already present then it's
Anor and that's atomic so that's kind of
nice and there's some more stuff none of
that will surprise you so how can i
model a debt table well it's almost as
simple as just saying let's keep a list
of the tuples that should be in there
that's going to enable me to predict how
these calls should behave so my model is
very simple in fact my model for the
core of the dets api is less than 100
lines of our land as simple stuff the
implementation is in four different
modules and it's more than 6,000 lines
it's keeping hash tables on the disk and
handling legacy formats and all kinds of
stuff so it's much more cold but its
intended behavior is very simple so this
hundred lines of code took me a few
sessions of maybe an hour at a time to
develop and I had to I had to debug my
spec a little I didn't initially
understand exactly what the operations
were supposed to do but quite soon I was
able to run sequential tests and they
all passed so I knew my model was
correct and then I ran a race condition
test and again was exactly the same
model the work of moments to convert it
into a race condition test and here's
what happened okay so here in the in the
sequential prefix we opened the file
that seems reasonable and then in
parallel I inserted an empty list of
tuples that's enough of that returned
okay and another process called insert
new to insert an empty list of tuples
that's all to inoa and that returned
okay but quick check says there's no
possible interleaving of these two
results that can explain the values we
see that's odd isn't it
what on earth is wrong with returning
okay in each case well sometimes there's
no alternative you just have to read the
manual here's what it says about insert
new look at the result type even in air
lang a bool is either true or false
it's never okay and in thousands of
sequential tests insert new return true
or false every single time and runs in
parallel suddenly returns okay where did
that come from so I hope let's see what
else we can find ran some more tests
this happened okay so I open the file in
the prefix and that I started two
processes each one of them inserted the
same tuple zero zero but one used insert
and the other one used insert new at the
test timed out that seemed a little odd
really and this message appeared I
wanted to see was a bug in my code but
when I got this error report dets
bug was found when accessing get stable
I thought how huh okay maybe this is a
bug in debts so I found these two bugs
very quickly and then I decided that
insert new just doesn't work so I
changed my model to exclude insert new
from the testing and I found this one
okay what happened here in the prefix I
opened the file and then in parallel I
did two things now the first thing I did
was open the file again you might think
that's a bit odd
but remember airline is designed for
highly concurrent systems we expect
thousands of processes to be using the
table at the same time and all of them
will have to make sure it's open so we
expect one process to be opening the
file while others are using it so
there's another process which is opening
the file obviously that shouldn't affect
anything while the second process
inserts zero zero into the table and
then gets the entire contents and it's
the empty list
but I just put zero zero in there how
could it be gone and indeed I found this
bug in several forms where if one
process is opening the table another
process can see it sequentially
inconsistent view of the table contents
well so that wasn't good so what I found
these bugs
I sent them off to the guy who was
maintaining the code who worked at
Ericsson and he said oh thank you very
much next day he sent me back a fixed
version so that's very nice but I don't
think these are the race conditions that
are occurring at clarinha at clarinha
the database is being corrupted so hmm
maybe the file is being corrupted with
his help I added one line to my property
that just checked to see whether the
file was corrupt after performing a
parallel test and then I started running
random tests I had to run tests for
several minutes to find this well okay
what's happened here in the prefix I
opened the file I closed it I opened it
again and then I did three things in
parallel a lookup of the key that wasn't
there and I at the same time I did two
insertions of the tuple zero zero and
everything said okay all those results
they're consistent with the model but
when I checked if the file was corrupt
I got premature end of file oh now what
emphasize this is the smallest test case
that provokes this bug I saw it I
thought open closed open come on that
can't be necessary and so I took out the
first opening closed manually and I ran
the test was just the four calls tens of
thousands of times they passed every
single time and today I know why it's
because at the beginning of the test
case the file does not exist that first
open creates the file then we close it
the second open opens an existing file
it's very slightly different we get into
a very slightly different state and that
is essential to provoking the race
commission now I ask you to imagine any
tester writing unit tests by hand who
would include this one in his test suite
it's just impossible so I thought this
was really great and then I was due to
give a talk at a developer conference in
Denmark about something else and I
thought no no this is a much better
story so I rewrote my talk to talk about
this but I hadn't saved the output from
quick check when I'd run the tests so I
had to rerun it and so that I could copy
and paste the output onto my slides and
as I did that what did I find but this
one okay so in the prefix we open the
file we insert a tuple into it with key
one and then in parallel ok the second
process there is reopening the file
again we know that's a bit dodgy but the
first word looks up something that's not
there and then deletes the key that is
and all those results they're consistent
with the model but when I check for
corruption I got a bad object exception
here's the quote from the mailing list
the symptoms seem to be the same I sent
these examples after the maintainer in
each case next day he sent me a fixed
version and that fixed code has been in
service at Kleiner for more than a year
now during all that time there's been
one bad object exception when reading
the file that was last touched before
the new code went into service so it
looks as though those bugs really we're
the ones which which by the time this
was fixed they were causing their main
server to crash every week so they were
getting really pretty fed up with it so
what I really like about this story is
that it illustrates the tremendous power
of finding race conditions this way and
minimizing the test cases before I did
this work the guy responsible for the
code had spent more than six weeks at
clarinha trying to figure out what on
earth was going on and at the end of
that time he and the other people
working on this thought it seems to
happen when the database is about one
gigabyte maybe it's something to do with
rehashing when we finally found the bugs
you needed a database with at most one
record and either five or six calls to
reproduce it and in each case given that
tiny example it took less than a day to
find and fix the race condition so what
does this show I mean it doesn't it
doesn't reflect at all on the very
competent people who have been looking
for this bug previously what it shows is
that trying to find this kind of race
condition from failures in production
where billions of irrelevant things have
happened as well as the five or six that
are actually responsible it's just a
hopeless task okay well those were a
number of stories about successes that
we've had with quick check what would I
claim I think the property base testing
finds more bugs with less effort built
like tests generate them</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>