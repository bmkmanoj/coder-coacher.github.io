<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Striving to Make Things Simple and Fast - Phil Bagwell | Coder Coacher - Coaching Coders</title><meta content="Striving to Make Things Simple and Fast - Phil Bagwell - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Striving to Make Things Simple and Fast - Phil Bagwell</b></h2><h5 class="post__date">2013-01-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/K2NYwP90bNs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's my pleasure to introduce Phil
Bagwell before before I say anything
else about Phil I just want everybody to
repeat after me
Scala is cool we can all get along now
in case you weren't thinking that Scala
was cool I'm gonna give you an
opportunity I thought I thought you know
the way that we could sort of establish
you know we could pretend to be nice and
establish closure superiority is is
bring in somebody who was a you know
intellectually underpowered to represent
the Scala side of the equation and so we
have Phil here Phil
understand that Phil is a marketing guy
that's actually his job so as you watch
this presentation ask yourself what kind
of technical presentation the marketing
guy in your organization could give
thanks Chris well you know coming over
here and talking this group it really
antastic to be here and I'm happy he
gave me a nice introduction and didn't
tell you actually you know as I'm up
here skinned me alive you start you know
it's a really nice way to start but at
the same time I've got a couple of
things I've got to do because obviously
over the time I've had a lot of respect
for the things that Richie's done and
we've seen together we've actually
brought some data structures to the
world so you know I love that so thanks
a lot really because I think without you
we wouldn't have got this stuff on the
on the table and therefore you know
closure is very important to us cuz we
steal anything you do good so I hope you
steal anything back that we do good so
we'll keep that relationship going I
think the big important thing is to
actual Factor get the world moving on
immutable in getting things working with
I'm gonna throw some things out and I'm
gonna ask you not to eat them but catch
them right these are Swiss chocolates so
not to eat them yet let's start up here
see over there yes you realize that when
you do a presentation if you don't give
things away everybody hates you anyway
so but this is this is the problem you
see because once I go in these those
people back there you can see the
sadness right the pie right this is the
last of the hand hold so here we go so
I'm just going to do one more thing and
the question I'd like you to do because
this is all about concurrency and since
we're doing I want now all of you who've
got the chocolate I guess you just hold
them up so the people who got them right
now you're allowed to eat them when and
only when you've agreed the order in
sequence which each one of you is
allowed to eat them in now I believe
that's a small subtle problem in
concurrency synchronization but at least
you know in this auditorium here you've
got so many different threads going on
couldn't write so anyway I'll by all
means go ahead and eat the chocolate so
I mean do what every developer does you
know when when the boss tells you to
complete the task in one way do it
whichever way works I mean so you know
being a guy who's sort of come out of
and they're sort of pseudo since the
academic side which is a lot of rubbish
actually I start as an engineer I spent
26 27 years in marketing and then I
ended up doing the worst probable thing
of all
I became an organizational consultant
for about three or four years so you
know this is a bit of a dire thing to be
up here staff talking to you guys but
nonetheless when you put up the first
slide with so you know the Blaise Pascal
yeah you've got a bit of intellectual
weight behind it this was one I liked a
lot better because it came from a group
I was talking through up in Dublin group
called their work day and they said you
know make sure you tell all the closure
guys the best place to be working is in
Dublin alright because up there they
guarantee you the Irish coffee comes
with everything you need to be a good
programmer because everybody lives on
caffeine alcohol fat and all those good
things so everything lots of that stuff
it was also a lie because they said they
forgot to put on the end of it of course
they all drink Guinness copiously so
after I'd done the president
we went down to local pub and want
copious amounts of Guinness I don't
remember much of what happened after
that I really am I'm gonna talk about
some other things but you know being the
marketing guy I've got to talk a little
bit about yes are things to do with
companies and businesses and all that
stuff because all the ways you know I
haven't earned my stripes as being the
marketing guy so one of the questions I
do this when I go and I talk to my S
companies as well
oh they hat is for you and Rick on the
basis that I'm hoping you'll come back
and join us in their Europe and come to
those Scala days which is our equivalent
shindig and come and give a talk because
we love the talks you go we learn a lot
from them and therefore you know please
come over and share with us um
the thing here is that when you so look
at different companies are going to ask
the same question of the audience is
there and say okay guys how many you
guys are Java programmers basically
right I'll give me some hands a lot of
people are doing dumb but it's quite
lejeune you later programming Java okay
now for the things you're doing now how
many people have got closure code
actually in production doing business
critical work yeah right okay so now the
rest of you right the rest of you are
missing an opportunity because the
people who can explain how you can get
your favorite closure project actually
pass the boss pass the big boss and pass
the colleagues it's go and talk these
guys were really working so one of the
things you should do while you're here
is to actually get around and find out
why the guys who an actual fact already
Otakon production did it because you
would like to be there too
how many of the people who are not got
stuff in production would like to
actually have a real job during the day
programming in closure see so no can we
have the guys are doing it already
already got in how come all those
production guys again right so the guys
who haven't look for the closest one and
go and say how the hell did you do this
alright so you gotta learn from the
people who win and one of the things
that comes up and this is why I put this
slide up here is we tend as engineers to
think of the world as being engineering
problems and think of things in that
sort of system and I try and tell people
well actually getting a language in it's
like backing up one level of abstraction
and so looking at the organization as
the system not just the
current development problem and
therefore if you're trying to get
closure into your organization you
should very thinking about what I have
to do to convince an individual that you
will allow me if you might manager to go
and play with closure all right the
things that allow you to convince say a
colleague who's actually there who's
also interested in doing the things he's
doing but you want to say why'd he come
to culture you've got to have some good
arguments so one of the things I would
really talk do about all the time is
what comes where this presentation comes
from is you have the bottom curve here
is very simply the time it takes for
somebody to learn something oops
and then the time they get the payback
of course the perceived risk is what
people perceive they say okay
of course the snake oil works and when
you get to the end of the line here
either lines flat on the dial it's a
classic sort of hockey stick you know it
goes bad and he gets better outdoors
marketeers know about this we explain
this all days to get good budgets but
the same thing is true for the
development side you know you got to
learn a lot and you get a lot back where
you gotta do things a little and then
you get a little bit back the most
important thing is during the whole of
this cycle is to work out when
convincing somebody why it's easy to do
not hard alright and why there is a big
payback and make the message is credible
you know we can walk on water not really
a credible message so it doesn't go too
well so one of the things I talked to a
lot of the guys who I meet who are
trying to introduce new technology is to
say think about the person you're
meeting with think what they need to
know to make the next step towards
adoption because people rarely go
through the sort of st. Paul sort of
light and insight they can only go
through a series of incremental steps
until they finally go AHA I think I'll
try it at home and then when she got to
how many people have done that you know
Oh closure and then you started trying
it at home yeah this is what you call
closeted closure programmers all right
we have closeted and I'm not allowed to
use the word you know the other type of
programmers and so consequently when
you've done that for a while you get a
bit confidence in what you're doing so
then you can go back and you can start
presenting the idea of a pill as a
little project in the organization I
wonder if I can do this enclosure and
away you go you start an incremental
process where you start in vince people
to move
the track if you don't win straight away
you go solo I'd like to do this thing in
a little closure he says no oh right so
one weekend you go away in that little
test suite that doesn't work too well
for people in Java you go away hack it
up and closure it might take you two or
three weekends you come back on the
Monday you say look I'm not this out
this morning perhaps you'd like just to
see how it worries you know it doesn't
say you have to tell the truth or you're
trying to get to an objective after all
it must be clear I'm not going to linger
on here too long all I'd like to
encourage you to do is not to think
about just the development part of your
problem
think bigger think about the system that
you're in think about your managers
think about your colleagues think about
the way that your organization is
developed and see if you can why find
the way to actually get your projects to
go a little bit further try and reduce
the imagery of risk all the time
okay so much for the marketing crap
let's go on and talk about some other
stuff and okay I'd done it again I keep
swearing on camera so if I sort of stop
that like this is the only piece of
Scour I'm gonna put up for the talk so
it's alright you can mentally turn off
during this piece so one of the things
that we were doing what Wyatt what have
I been doing well as a couple of guys in
the group there's a guy called Tia
trough if you're definitely gonna hear a
lot more in the future about this is a
very sharp guy
there's also another guy called Alex
Paco Peck who's also a very sharp guy he
and I and Martin Antioch worked on doing
the parallel collections and the
proposition we're here was we want to
make it very simple
we've only basically going to write a
vector in this case you know what
vectors are okay rich okay so we have a
vector and obviously this is a silly
short vector which we're actually
sticking some stuff in and then
underneath we're going to do a filter
and then we're gonna do a map so there's
nothing particularly brill here and we
end up with a result but the nice thing
about parallel collection is by adding
just three letters dot par four letters
I include the dot you can turn that into
a parallel collection and it's constant
time thing to happen so it doesn't cost
anything in terms of doing it
and from now onwards the rest of the
code down below will run as a collection
which is now paralyzed
so whatever number of threads are
available for it to paralyze on and it
will then run and you will then get back
the assemble results so under the bonnet
what's happening is using the fort joint
which we know is a fairly well and using
thing called work-stealing
we're breaking the collection up to go
all the collection to go up across the
end threads and then when the filter
starts it does the filter now pass down
to the end threads when it's finished it
reassembles the results and you go on to
the next day's map and then you go down
and there is some technique by which we
can chain these things through so you
don't have to reassemble things but
basically it means that programmer who's
got something which is not running too
well they've programmed using
comprehensions will actually come out
that much faster and in fact it scales
very well the results of it so that in
fact roughly up to about about 16
threads but it almost is linear on the
number of threads right so is this a get
a get out of jail free card well let's
let's just look at it and see how it
goes I just talked a little bit about
what goes on and if because one of the
issues that was raised this morning is G
when you do scheduling you've got to
worry a lot about this and the way the
scheduling is done inside this is that
each thread will convince your way you
can do it is you could break the task up
consists of a sub task break the
subtasks up further down so you get down
to nice granularity if you do that you
lose all the time in the scheduler
instead what we do is we basically break
the tasks up into the n threads then for
this thread over here we've split it in
half and then we keep one half on the
cue set the other piece of it going home
running and then if one of the other
threads finishes it comes in steals this
that is left over takes it splits e and
a half puts it onto the queue and then
these one for somebody else to steal if
they're and you basically go this thing
shuffle down I'm very low overhead in
terms of scheduling so it works very
quickly and you get a very nice result
okay so it works pretty good it's easy
to program three characters PA R plus a
dot and you've got the thing implemented
so it means if you've written your
program and you've thought about it
there's a set of comprehensions you can
push the get-out-of-jail-free car which
is the dot par and away you go
it's easy to program speeds up public or
good load balancing but I would tell you
it's not a fix for everything it reads
got a couple of problems and I think one
of the ones I think was alluded to this
morning
is that if in actual fact you look at
what the computational problem is in
power collection is your doing pure
computation but threads are being
competed for in the i/o area so you can
end up with one of the threads that's
trying to do this stuff totally blocked
while something else is going on in the
i/o string so there's not a total fix
right there however we've recognized
that this is one of the things that
needs to be fixed so what we're now
looking at is a super shed you know it's
it's over this and says okay we'll
allocate X threads to the computational
load and these other threads to deal
with the potentially sort of
interactable or blocking load okay so so
it's not a fix for all problems but from
a simplicity point of view if you're
writing a program which works nicely we
call comprehensions you can hit the dot
par and you can speed it up so it's sort
of yeah well if it works let's go with
it if it doesn't well if you lost
because the cost programming wise is
very low so the learning curve is very
small potential return very good so we
go back to the curve okay okay the next
thing that's on the block but I'm not
going to talk about today in any detail
but it was interesting because of the
conversation that came up is that we
have just developed a thing called I was
a long name non-blocking resizable
concurrent hash tries the model today
that people use is actually the
concurrent hash table which is got a few
problems with it then when you realize
that once you allocate the table as it
grows it sticks and sticks of that size
so it doesn't reduce in size so you have
a memory consumption problem so we
wanted to fix that issue also most of
the implementations at the moment our
blocking namely to control access to the
top part of the hash tables they
actually do some blocking and locking so
I can allocate buckets oh we didn't that
to happen so what we've done is we've
implemented what is the hash map that
tree map and basically we live that now
to run in concurrent mode so you can put
things into it you can take things out
of it from multi-threading environment
and you don't have any problems with
locks so it's a lot free way of doing
that perfectly nice for doing caches
dictionaries time varying analysis
analytics and scales very well in
multi-core in fact so it scales better
than any of the others we're now putting
into most of the stuff that we use this
very heavily in
and allows a snapshot which is totally
unique
so it actually alluded to a problem
which is the baseball problem which you
talked about I think some time ago rich
in the what was it are we there yet talk
if I remember my my background so let's
just see what it is we're doing here
because of this particular data
structure what we can do is to actually
take what is a concurrent hash try which
already exists and is having stuff put
into it and we can do called snap which
is to take a snapshot and it creates an
immutable copy of it so the original cxt
is carrying on you can start stacking
stuff into it but the SN the new version
of it the snapshot version is actually
now fixed it's immutable so you've got
this nice transition between mutable it
allows you to do lots of changes
immutable because you can use that in
some calculations using functional style
programming ok and the other thing is
it's still non-blocking and it's non
locking and it really runs quite nicely
so can we talk about a typical use case
just so you can get the idea what it
does we imagine that you've got some set
of threads here the busy correcting all
this stuff from the sensor points in the
baseball example it's like taking a
picture or it's trying to assemble all
the things that are going on in the
baseball is taking all your faces and
all the things that were there and
you're assembling it into this mutable
hash table that you can actually just
carry a hash table you can put things
into and then what you want to do an
actual fact you want to kick off a
process there's going to recognize
something that you want to see like me
now how many faces are facing me now you
realize the problem because the problem
is in the original data structure faces
are turning away and turning back and
turning away and turning back so how can
I statistically come up with a good
number because as soon as I start the
very first problem is how many people
are in the room
well I start counting and before I
finish people have gone and come so
classical problem the snapshot says take
a snapshot what is there now is what I'm
gonna work on so I freeze like taking a
picture all the faces in the room I can
now Karen do the processing so in this
example here the notion is at this point
I'm taking a snapshot
I'm now gonna start some processing
which lasts more than the time periods
that I really want to be taking
snapshots and doing analysis work on so
I take a snapshot at this point a little
bit later I take another snapshot a
little bit later I take another snapshot
and these are all independent this and
once they're taken each one of the
snapshots is immutable all of the
processing work down here can be
functional or can be immutable data
structures meaning to all the nice
things and you've got consistency in
what unit produces a set of results so
it really handles nicely this problem
where you've got things in the outside
world like recognizing all the people
who are baseball stadium oh yeah looking
up I'm a glider pilot by the way I play
fly gliders and claims are very
important to me so when Rich was talking
about you know recognizing plays in the
sky and saying yeah this is a problem I
can identify with so you think the same
thing you're doing cloud recognition you
get all the sensors that are taking
different pixel sets popping it into
this mutable down here and then the
actual code that does the recognition of
the clouds is the popping off down here
after snapshot so you can say all the
clouds there now how the clouds changed
you have this them very nice little late
instructions Villa quite an interesting
structure I think you'll see a lot more
from it in the future
okay but why don't I go talked about
today I'm gonna talk to you about any of
that stuff that's all just background
we've already done if you want to look
at that there's some stuff on the web I
did a presentation over it skills matter
in London and you can sort of go play
with it and get very bored trying to
work out how the blocking and
non-working blocks so here's the next
problem and Daniel why I have to
apologize roads Daniel is hi Daniel
the reason I have to apologize because
he said I've been trying to look at this
problem he said and I haven't found a
solution for it damn it
and no sorry so the basic job here is
you've got two vectors and you want to
concatenate them so how long does it
take to concatenate two vectors come on
help me
lilius time in be something bullet
thanks a lot so it is linear time B
which is a bit of a nasty real issue
because there's a lot of things you'd
like to do with vectors I mean
personally I can't I can't say this
outside the room because it gets totally
embarrassing I really believe vectors
are really the next list I think yeah
there's nothing you really need lists
for other than the fact that there's a
few small list shapes that are really
quite useful because you can reverse
vectors you can do all sorts of nice
stuff so in fact I think the you never
use reverse you only use back iteration
in this group but the problem here then
is - can I do a concatenation right I
can catenate two vectors together I can
do that in your time can I take a slice
you know take a middle of something or
take the end of something or take the
beginning of something and can I do
something like this sort of pseudo code
that at the bottom can I do a concatfile
of in the middle and bit something else
yeah and then we go back to the parallel
things that were doing
you know I split all this stuff up when
I did a filter I got the vector results
I have to put that to get back together
again so I need to be able to
concatenate these partial results in
linear time
so I paralyze it put it out to these
nice thread that beaver away and they
stole everything why sort of then you
leave assemble it so it's clear that
what we really like is something which
can do this a little better
would you not agree you don't agree on
stop now and you can go home and I'm
glad you agree yes basically the face
will be getting up and walking I'm just
gonna do a two-minute recap of what
vectors are about and I'm sure you're
all pretty well aware I'm only showing
it in four wide rather than thirty-two
wide you can generalize this for 32 why
you know the basic principle is if you
want to do an index down through the
data structure you start up there at the
top you pick off the first two bits
which tells you how far to index into
the top level you pick off the next two
bits that tells you how far to index
into here you take off the next couple
of bits and tells you how to index into
the item at this level and away you go
and this is the sort of performance you
get and it works very well so well next
when you want to in fact write it and
you want to change it
which rich worked out very nicely and
implemented beautifully that was the
second contention for Daniel was the
fact that we took riches code rather
than his so again apologies I don't know
what the reason was I was apologizing
the last night he thought it was just
pure hate but it wasn't anyway less at
this rhetoric so if you want to actually
change this value here you know already
that what you do is you rewrite the path
following the red path down here and you
write this here you point to all the
other things back to the existing stuff
and lo and behold you've got a new
immutable version of the old right the
updates run at that sort of value which
is if you look at the actual numbers
that's you can see the speeds the log N
and for M 32 it's roughly six point two
times because Y time you divided 32 by
five and that were that and the index we
had before was pretty nicely one over
150 log n so the one question that
people often ask me is how did you
choose the size why was it 32 bits you
hear lots of things bandied around like
well you know 32 bit words it's a
natural length of things well actually
it wasn't in fact this thing this
structures been implemented because if
you map out a new time the time to do an
update and the time to do the indexing
you notice there's a and that's why we
chose 32 okay if you carry all up to 64
you notice that the update starts to go
up quite steeply okay although the index
actually drops down okay so the problem
is is that you're now making this
trade-off and you're now going to the
stage where we went to 128 here this
will actually really take off okay
so what's the secret here there's two
secrets the secret one is that the
number of bits in here is obviously the
number of things you copy
and they sit in cache lines and actually
coming up to here at 16 you've got one
cache line typical on a modern Intel or
if you're looking at the future Intel
you actually got nice room just for 32
because the next one's going a fine 128
bytes so if you put the l1 is open
caches
these sort of mean that they fit quite
nicely into cache so when you're doing
copies where you trying to copy from one
place to another
you've got the knowledge that one thing
is sitting nice in a cache
the second thing about the whole thing
is that when you're looking at the index
times the index times are basically the
time you get from the top of the try all
the way down to the bottom okay
well statistically there's a few things
that are taught like one and at the
bottom there's lots so if you've got
another task that's going away somewhere
else and hammering the cache the
probability is is that the top items in
the try will be there when you come back
next time well as the bottom items in
the try will disappear so really what
happens and why we get such good times
out of this thing is because when you
come into the top it's in the cash off
you drop down and through the cash is
like a thousand times faster than doing
a cash exception I'm picking this stuff
up
odds are at the second level you're
probably going to have the stuff in the
cash as well it's only the last two
levels were things slow down because
those the ones you have to have the cash
outage and the things I have to work and
that's why the indexes work surprisingly
fast now you get an index into vector
which is around about 30 nanoseconds
which isn't really quite bad you can
really go quite well so we've got this
lovely structure that works like this
and now we want to do vectors that all
actually concatenate so this is a
summary of all the good things about
them okay so we've got a no end
challenge and we'd like to turn it into
an old wagon challenge is that one good
ideal it's a simple problem it's a bit
hard to solve
but it's economically interesting if we
can crack it it actually gives us access
to core number of problems so we started
off and say well you know and well the
linear one is that you basically take
all the items over here and you get them
over here and you rearrange all things
on the bottom and that's why you end up
with a linear arrangement because you've
got actually move all of the things copy
across so everything sits in the correct
place okay turns out some guys have had
a go at this and one of the earliest
attempts or thing called ropes right
which is by bone so ropes is a very
simple concept what you do is when you
want to do the concatenation if you bang
in a node which is a binary node and you
mark hyman you're on the left of it how
many of them are in total so you use it
so you've got 47 and then when you come
to do the index you come in to that node
then you say is my
index greater than 27 okay I'll go to
the right is my index less than 27 right
so now we've got the structure in salt
so what's the problem
button I guess deeper and deeper and
deeper and deeper and deeper it goes on
and on and after for Khun Kats it looks
like that because it's a right one it's
not a balanced one so say we could
balance it yeah think about that and
then of course we want to do splits as
well
well splits are easy do you stick
another note on the top and say well
nothing be like to the left of 12 exists
and nothing to the right of 41 exists
piece of cake you know we just rebalance
a bit we've got this thing but then
what's happened to the memory that's
held onto on the left-hand side of the
12 it's still in the structure and
you've got a memory leak so there's also
leaks memory like hell well okay back to
the drawing board let's have another go
rope indexing updates tons linear in
time it's proportional to log of C and s
which is number of can cats the number
of splits memory leaks without any
reason and this linear in sub vectors
now so any of the sub vectors which are
up to a given size you still have to
shuffle the sub vectors because if you
do a copy or anything else all the sub
vectors have to be code so we said well
hey we've been around a long time in the
computer science world we know this
stuff let's use B trees well the B trees
are pretty good you know you've got a
nice flat structure Wow indexing is
going to be pretty good all right here
we go I'm just done it for 16 in this
case cuz it's hard when just you 32 but
you can see sort of the problem that's
going on you see when you're coming to
the top you basically work out that the
thing that you want is down here and
you're gonna just come down through a
couple levels and the whole thing works
out here because the B tree rule is that
the smallest node is only half of the
biggest node so that's how you get beat
rebalancing because the longest path is
going to be proportional to the shortest
node and the highest path is going to be
proportional so longer note so you end
up with this number of levels and you
tree you get slightly higher but it's
still balanced and if you make n which
is the width large you'll find that that
particular number gets to be quite
attractive it ends up the onion that
one potential level of a difference it's
simple to balance if you actually try
and balance a b-tree very easy through
it's a piece of cake so what happens ah
damn the index that I was doing relied
on the fact that I had exactly the right
number of things in the tree below what
you see happens here as I go up here
when I index into this item up here
right
I should have have 256 items there but
if you add them up you see that I don't
have enough right so what happens is my
index will lie me short of where I want
to be so the index doesn't work anymore
I can't do radix indexing Oh
you know that's a real you know part of
the reason for doing all this is to get
as fast indexing how these vectors do
good okay okay well yeah that's the end
of the presentation there because were
stuffed but my little fellow here came
up with another idea you have to realize
there was t a trial for myself we were
beating this thing about it for over the
last 18 months so that I'm trying to
compress into a half an hour so we get
the wrong slot right what do we do then
well go back to the computer from friend
we add another node on at the top and
then lo do we stick on at the top it
actually contains the values of the
number of items so now we can index into
this No all right and we can find which
one which part we should go down but
this now you see the variation is up
here is such the only way you can do
this is to use a binary search at this
level which is not a radix search okay
but otherwise it does quite the right
things you know if you want to get to
the 29th item you basically start off in
the thing up there you go across until
you find the 29th place and then you've
tracked down the appropriate path and
you can find it's pretty good
you can do a linear search or you can do
a binary search concatenation is still
cheap it works very well okay it's
simple the balance we're pretty much on
track here except the indexes go on to
hell again okay so in fact when you do
the measurements it's seven time
longer to do an index in that structure
than it is with inside the vectors okay
we go back to our guy against it come on
another idea well what should we do well
you know the problem was that we had
this variation in the length and it was
giving us too much hack so why don't we
make them all n or n minus 1 right so
they're close to the right number but
perhaps I'll give us an flexibility that
balancing isn't too bad and away we go
so then we'll now change each one of the
items such it's 31 or 32 long because
now we're talking about vectors that
we're so familiar with the big change
now is if you think about it the
accumulation of error across here is
never more than 1 okay in this
arrangement ah it's only one out so I
know I can either land in the correct
one or one before it
okay I'm gonna land in the correct one
or the one before it then the natural
answer is why do a linear search but
what's the answer to linear search where
is all this stuff sitting in a cache
when I pick up this thing to actually do
this linear search into in fact the odds
are that if I look at item number two
then items three four five and six are
already in the cache and already easily
access so in fact the linear search is
dead cheap as long as you want to go one
or two places right so it turns out
using this actually things go quite well
in fact we get back to the indexing
speed is very close to the standard
vector we've now got a structure that
can be balanced good right but it's 60%
slower in terms of indexing but it's
costly to balance so we now looked
another process and we said let's do a
thing called rrb trees we've started off
with this thing here to do this
balancing which is what we call one of
these trees which is a 31 33 and you say
well how do I actually end up balancing
it and the way you end up balancing it
is you take the bottom two levels to
start with and you look at the things
that have to be brought together at this
place here
I knew balance such that these meet the
criteria so here we're doing it on four
so these are we all three four is when
we finished up here you notice there's
one this is the one finisher written
gets combined into here because we go
through in search for the ones that
don't meet the criteria and then we
construct the set which is a replacement
set for the criteria so there's the
first piece of my solution okay and the
bit left over I'm going to carry up to
the next stage so it gets combined with
the bit that's left over here okay got
the idea because this is a touchy verb
nod your heads or I'm gonna go back and
repeat myself so for the ones who are
not nodding your heads look sideways see
the ones who are nodding their heads and
quietly ask what the hell's your honor
backs alright so we know back to the
next level and we notice that we don't
meet the criteria cuz we've got two twos
so we have to know take the two twos and
combine them let me take them into the
four and we now ended up with this
structure and we've now got C okay so
that's my concatenation all over so the
concatenation isn't too bad works quite
well and it really goes those are what
we call the principles of 31:32 or our B
trees our R stands for relaxed radix
meaning it's running exact reading so
there's a little bit of slop so you can
actually go on with the next one
you see it's try ones there was a hint
that this doesn't work quite and what
happens well it all works pretty good
right index speed as a constant 40 or 50
percent slower
you've got the extra attributes in the
structure you've got these things that
tell you how wide these thing is memory
overhead is still really good because
it's only overhead on all of the upper
tree items that are not standard vectors
so you've got less than three percent
possible max overhead updates and
iterations everything worked just as
before because they don't need to look
at this stuff if you wanted to write
across the bottom of the tree you can do
it nicely ah the concatenation cost
about 30 times more than updates
that's not bad by the way 30 times
updates it's a hell of a lot better than
linear
all right so that's a constant times log
so I've got this thing down to a
constant time log why is it a constant
time log well the reason it's a constant
times log do you think about it when I'm
balancing down here I'm looking at two
levels
which is M squared right so at M Squared
that's all I have to look at when I move
next level I'm looking at M Squared
again alright so the actual cost in the
table is basically M squared log
something-or-other
well then we went back Chuck and I were
sort of we've been down to the pub we'd
had a couple of liters of left at that
point in time we you start say no probs
we'll make it a bit more sloppy is the
sort of thing you think about when
you're drinking beer and well actually
when you think about it oh we're trying
to constrain was that the last ones that
you get to one or other out so why I'm
trying to make all of them individually
correct when all I'm really trying to do
is to make the one on the end correct
all right so that's what we did we said
let's have a go at so this one in this
case what I do exactly the same notion
as before except I do something
different you notice up here I got these
things together and I say the only thing
I want to arrive at is that the total
number of items across here is such that
if I do a radix search I never have more
than one left over okay so here I could
do the computation you finally got one
too many I've got two left over and
there's computation over there time you
got two left over so I have to reduce
this thing until I get only one left
over and the algorithm we use is we look
for the first one that's small and then
we look forward and combine enough
together to be able to reduce it by one
now what you'll notice is in actual fact
the constraint is very nicely loose we
actually have to actually do this over a
fairly short range in the M Squared
items that we have to deal with so it
suddenly drops down from M Squared to a
lot less than N squared in terms of the
averages worst possible case it still
turns out the M squares if you end up
with small one right at the beginning
all the other ones are filled up and the
last ones the small one you can end up
with the worst case is still M screwed
but the average case oh now that gets a
lot better that was the case of how we
do it at the bottom you combine things
again at the top and you end up with the
vector no nicely concatenated okay and
here we go the vectors
dated so the index still works as before
exactly we're only never gonna be one
out so it goes very fast and now we've
got the concatenation so how does it go
well the answer is this it turns out
that and the 60 to 70 percent slower
than standard index it's still good but
that's when it's you've gotta work in
catenation so when you start off with a
few concatenations it's better standing
back to it right memory overhead is
still pretty good updates and iterations
or what good as before concatenation now
is only two times four six times worst
case the update an update cost by the
way just waiting one path in all
practical purposes we use this statement
very times that's constant right that's
not bad
so in constant time you can do
concatenation one your vectors which i
think is really cool all right
it's a standard unit concat and splits
all right oh we haven't every time
you're getting yourself really sort out
and you think you've got things going
well yeah well so at the top end then
using our RB trees with this sort of RB
relaxation method you can get down to
the point where you can catenate ins are
in constant time Grosso modo right and
the vector performance stays exactly as
it before if you don't do any
concatenation you have the exact
structure you have today which is 32
bits wide with perfect radix fixing so
you only pay this price when you decide
to concatenate so if you use the vectors
with no concatenation you get the
existing standard performance which is
also cool cuz it means that unless you
use the feature you don't pay the price
which is rather nice okay so negative
definite right splits
well splits are cool actually because
you can be lazy in splits what a
splitter is doing is basically shaving
off one side or the other right and all
you do is you rewrite the path okay and
if you noticed you say well you know if
I rewrite this path them I don't worry
be a small one over here in which case
I've broken the constraint that I had
before and we basically ignore it
because the very next concatenation that
will get fixed so we do the splits lazy
a split is exactly an update because all
you do is rewrite the left-hand path the
only thing we do is we move the things
from
to the other side or where there's three
there they get shuffled across so they
start roll them being in but that's the
only minor adjustment you do and you
have to write it are these actual
counting ages as well and that's what it
is if you want to do a take out of mid
in the middle that's two slits down at
either side and you retain a little bit
if you want to shave off the ends it's a
split where you take the piece off the
end all right so you can do all those
types of chopping and cutting that
you've ever imagined to do on a vector
in constant time well in our constant
time that is which means this one
one-fifth log n so that's good enough
for me all right that's cool for me you
can do splits you can do mid so you can
do concatenation you can do all this
stuff and everything stays happy and
nice right so seeing is believing here's
the performance time another take
through the numbers all it basically
tells you is it's good and you know
we've put this in the paper so you have
to say it's good but you have to show
everybody if you use binary search at
the intermediary levels this is the
column we put in that shows you what the
using binary and you can see it's fairly
heavy cost to do the binary search I was
doing this radius reduction one columns
the column over this side what we're
doing was we're generating random
concatenated vectors so how much so
we've produced a vector of a million
items and to produce that back to what
we do we start at the top and randomly
split it down into pieces right and then
took the pieces that we had and then
randomly split those down to pieces
until you're all way down at the bottom
and then we concatenate them all back
together again come up contaminate that
together again
okay fascinating so the whole thing is
really complete complex or our b-tree so
if you're on this side it's the messiest
possible set of concatenations you could
ever do right on this side it's the
least well this one is there's two
standard vectors which you put together
so the two standard vectors of this side
alright and the ones that heavily
concatenated on this side what you
notice is the degradation between
heavily concatenated and not
concatenated or kcassaro ones is only a
few tens of percent which is really nice
where you remember with the
ropes that you will have a progressive
degradation as you did more and more
concatenation well this one you need a
little help here you've got all the
different sizes a concatenation by the
way cost you at this level 150 item 12
you've got three levels to go you've got
basically 32 items at each level so
that's a minimum of 96 copies and you
can see you've only got 152 copies to do
a concatenation which you see 2x right
for example everything is very messy
this goes up a little bit higher so they
concatenation to take a little bit
longer so the Messier they get the more
you actually have to do a little bit of
assembly as you go up through ok so
there we go
right so the implementation now this was
important because this is where Daniel
comes in and we just sort of he came up
with a really neat way of making sure
that things go fast when you work and
drill down through a try um the way it
works is that if you actually do
concatenation the upper node somewhere
contains a structure like this ok
it's a array with a pointer in the
bottom which an any referee which goes
there this points to the actual decision
for how many items you have in each cell
below it you can have standard vectors
because if you concatenated some stuff
over here all right which has some more
of these arbitrary stuff here actually
is a standard vector and that's why it
goes very fast if you don't do very much
concatenation because most of the
structure is the standard vector
structure so you zip down through it but
we and the numbers I've shown you
actually release it we actually sort of
use this one here as the flag to tell us
whether we had the right structure and
what we carried that value down here as
well so it was an overhead on every node
and we realized Curtis has you Daniel we
know the type up here we actually know
the type of everything down through the
tree right and therefore at the top all
we need to do is to look at the type of
the next item we can decide whether this
level is in fact another one of the rrb
nodes or in actual factors of X to know
is the vector node then we go to a very
quick dump down through the vector we go
back to standard vector speed so we
believe all the times we've got we've
got about another 15 20 percent to pick
back up from the x using
approach so Daniel thank you very much
so see ya we learned something from the
closure people well actually I think
he's also Scylla person okay now what
does that mean
oh we're now a demo yeah right
oh okay okay now for some cool
stuff they say in the trade I wonder if
it'll work so there we go there's a
vector its base eight so M equals eight
in this case and you can see the vector
standard form right okay so we'll slide
the vector back the this on the top is a
vector the a vector here down here is
the result and now I'm going to start
sliding up here the right vector and
you're actually gonna see things going
together all right so the thing the
important thing to notice is in the
bottom here it's how little the previous
structure changes in showing you that
you're not doing any extra work all the
work is actually being done at this
level and most of the stuff that's
actually coming down here is also coming
down absolutely unchanged unchanged
means no work means low-cost
concatenation so as I slide this thing
up here you start to see the same thing
goes on okay now what happens if we do a
slice right well I can do a slice left
I'm gonna be slicing the vector that you
see on the right okay so I'm slicing
left on the right hand vector keep my
head straight here okay what's happening
you can see that where it started a
hungry before I now reduced it down to
109 is being the first one I don't know
where you can see them above in the
screen well let me I can't blow it up
too far can I try you guys you can see
down here that now we have the vector up
here started at 100 and we've sliced off
the first eight and it starts at 109 you
know side this vector hasn't changed an
iota so in actual fact the cost has only
been to actually put this bit in here
and slicing up the vector was very cheap
I don't think take a different approach
myself now you say that's all very good
but what does that look like if I
actually snow smack this up and I
randomized my vectors alright so I have
a button convenient
and that means all the vectors I've got
worried had lots of concatenation going
on already okay so then you get a little
more idea what's going to look like
because the vectors don't have a nice
regular structure they have these
oddities in their ones and twos and
stuff like that which is really why this
all works and you have that slop that a
will should put things together and now
if we play around with the sizes again
if I grow this from down here or I
shrink it as the case may be right you
don't need to look at the numbers let me
shrink the sizing back you're on the
zoom okay and there we go we can now
start to change the sizes and okay and
you see how and the levels only go up
when the level should go up all right
and we can keep increasing left hand
vector and you notice how stable the
right-hand side is for the added vector
on the right you see the complete set
and if I know slide this one back so we
can look at the right-hand side a little
bit I'm now gonna slice this vector up
here the one that was coming
it was also randomized let's make it
something that looks a bit more messy
okay
the randomization is done based on its
size so that every time I change the
size I get a different random set of
vectors out that makes it and now if I
actually start slicing here we go
slice slice slice and you can see how
stable the left-hand side is and now all
of the action is really happening around
just the middle part of the structure
okay or if I go and slice off the left
hand on the right hand side you can see
exactly the same thing and then it's pre
slicing the vector that's on the right
and then it's concatenate Indianapolis
okay so that's sort of demo in terms of
it really does work and this by the way
was a very useful diagnostic tool
because the number of odd trees I could
have shown you a descendant s code so
that's the
we go on them to say right now for them
and then we say gee thanks a lot</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>