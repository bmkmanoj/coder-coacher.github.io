<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>+ Loom years 2 - Aysylu Greenberg | Coder Coacher - Coaching Coders</title><meta content="+ Loom years 2 - Aysylu Greenberg - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>+ Loom years 2 - Aysylu Greenberg</b></h2><h5 class="post__date">2016-04-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eadPwx-bVS8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi it's good to be back at closure West
I was here I was a closure was in 2014
also good to be back in seattle last
time i was in seattle was six years ago
in august and i fell in love with the
city when i told everyone about it
they're like oh yeah it's only the three
months that it's so sunny and beautiful
well it's April now and it's also sunny
so as far as I know it's always sunny in
Seattle so let's talk about loom and how
to vote in the past two years dimension
I spoke at closure West 2014 about loom
and it looms protocols and algorithms
and since then there have been amazing
contributions to the library so I'm
going to talk more about what happened
in the past two years a little bit about
myself I work at Google on the
distributed build system so how many of
you use Travis CI for your development
or know what it is a yes ok cool so
basically the distributed system I work
on is the infrastructure in which travis
CI would be running so we are all the
releases or the testing of that goes
through the through the distributed
build system that I'm working on and
actually I'm happy to say a couple of
weeks ago we launched the big projects
like and the code is running all around
the world and data centers where we re
architecture our build system to serve
like to make it scale better and I'm
still in denial that one so smoothly so
I'm just like I keep checking my phone
hoping that something will happen in
production but it's been good so so
there's a lot of intersection between in
the closure community as well as papers
will love community and I'm proud to say
that I organize papers will love at
Google internal community and their
meetups all over the world if you're
interested in that in reading academic
papers and discussing them with other
people who care about the for passion
about computer science research and you
know i'm online so cool so today the
talk will be in three parts and and you
can follow along and like the bottom
there will be the three people three a
band made of nirvana how many of our
lives in the members in the audience
members have
affected by Nirvana in some way yeah
okay cool they certainly the whole
grants Ian affected my life and that was
great so um so you can follow along if
you get confused which section we're in
so first we'll talk about what luma is
just in brief details to make sure
everyone is on the same page I'm curious
how many people have heard of them
already okay how many have you used it
like okay I see if your hands how many
use it for production or like at your
jobs or research ok cool so um then
we'll talk about loom and how will make
vote in the past couple years but also
how its API is about how what algorithms
were added what kinds of things were
done and I'm finally we'll talk about
just what it entails to maintain an open
source project I've been asked many
times how many hours are spent on this
and so on and how do i balance it with
my life and other responsibilities and
it doesn't get talked often so I wanted
to also cover this ok so first let's
talk about what loom is so long Joe's
with graphs graphs are data structures
which represents a collection of nodes
and edges so nodes are connected by
edges so here we see 5 nodes a b c d e
and then they are connected by edges now
graphs are used very commonly to you
solve all kinds of real-life problems
for instance if you for routing problems
here we see map a subway map so stations
would be the nodes and then the lines
that connect the two stations will be
their edges and you can figure out how
to get from point A to point B also
graphs are commonly used in any kind of
social networking problems for instance
you know who knows who who's related to
whom and so on also graphs are used to
describe dependency graphs which is much
closer to what I do in my day-to-day in
my day job so a project here project one
for instance might have like three
different dependencies and those
libraries might have other dependencies
and so graphs are used to describe what
we need to
built-in compile and Link before we can
build our own project animare are many
types of graphs so there's the simple
graph also known as undirected graph
just nodes connected with edges then we
can assign costs on those edges so
friends with how long does it take to
get from point A to point B for Traverse
this route there is directed graphs and
we're now to get from point A to point B
you need to have the edge to be in the
right direction and of course you can
assign weights to those edges as well
now the more advanced types of graphs
are mucha graphs were now you can have
more than one edge between any two nodes
so this is useful ferences in game
development in describing more complex
problems for instance it takes like six
hours to fly from New York to Seattle
but it takes I don't know maybe a week
to drive from New York to Seattle and
you probably never want to walk that
distance but maybe by kids so it would
allow us to describe different things
about the the same two nodes and how
they're connected and finally there's
also mixed grass which basically have
mix up directed and undirected edges
okay so what is loom do so loom is a
graph algorithms and visualization
library so it supports numerous types of
graphs such as undirected graph the
simple graph that we saw directed graph
weighted graph where do I sign weights
on the edges multi graphs that I
mentioned and then also fly graphs which
are really only an ad-hoc graphs so
there allow a student for some
information about the graph from the
given information for instance if we
specify note what the nodes are in the
graph and how to retrieve the successors
we can infer what the edges are in the
graph similarly if we know successors in
a start node then we can infer nodes and
edges in the graph there's a variety of
algorithms that loan supports such as a
depth-first search and breadth first
search
including the bi-directional
breadth-first search so that first
search is basically for what reverse day
they know that the original node is
connected to and then you know keep on
following the successors until we reach
the end and then we backtrack and start
covering other adjacent vertices the
siblings vertices and breadth first
search is we'll look at all the adjacent
nodes and then we go into the next level
of their adjacent nodes and so on so so
like tier by tier exploration and there
is a topological sort algorithm which
basically guarantees that it provides an
ordering of nodes in the graph such that
every success of a vertex comes after it
in the ordering there is a lot of
different types of shortest path
algorithms which are very useful we're
figuring out how to get somewhere in
least amount of time and there's the
single source shortest paths like you
specify one sort of vertex oh there is
also a pair shortest path so figuring
out how to get fastest to everywhere in
the available map in your graph ok so
there's also a couple algorithms for
finding clicks and strongly connected
components so on the left side you see
there are click is 125 so click is
defined basically by the following each
vertex in the clip has to be adjacent to
every other vertex in the clicks so we
have 125 there are Jason to each other
now strongly connected components say
something a little bit more powerful on
each vertex in the strongly connected
component needs to be reachable from
every other vertex it needs to have a
path so on the right graph you see for
instance a B and E are strongly
connected components and there is a way
for a to reach E even though there's no
director edge going into it through be
there's also ability to determine the
density which is defined as the ratio of
edges over notes Lona knows which i just
notes that are not connected to any
other nodes in the graph different types
of colorings and
is Orion familiar with a coloring
problem okay yes if you're not so
basically the problem is you want to
color the graph such that no two
adjacent vertices a color the same color
so the greedy coloring basically just
takes a new color whenever it can
satisfy this property and then to
coloring is used to determine whether
the graph is bipartite which is helpful
and some problem that means finally
there's max flow algorithm so basically
what we have is we have a source vertex
and a sink vertex and then edges have
capacities defiant on them and then we
want to find the flow across the
directed edges such that the flow that
we computers the maximum so this
algorithm is commonly used in logistics
and routing like if you want to ship
things between your different water
houses and then the minimum spanning
tree algorithm is basically given the
graph we want to turn that into a tree
such that all the edges that will live
in this tree the weights of those edges
are minimum possible ok and finally
there is alone does grab translations
using gratis so this is one of the
examples of the type of graph it could
output for you all right so now we
discuss in general with Loomis let's see
where were loom stands in the general
closure ecosystem so closure toolbox I
think a lot of you might be familiar
with it I find it super useful it's a
categorized directory basically of
libraries and tools that I available
there in the closure ecosystem so if you
have a problem you're wondering which
tools which library should I use they
have a very pretty comprehensive list
and tells you exactly the different
things you could use so you can just
take a look at it and figure out what is
the right solution for you there are
many projects out there that either use
loom or related saloon such as Mark
Engelberg subha graph which basically it
implements loans product codes and goes
above and beyond for
or the problems that loom didn't solve
for mark specifically and many other
people will find it also very useful
especially in game development work we
want to have mixed graphs and multi
graphs and multiple waits for any given
edge and so on and maybe we also we want
to have changeable with so I highly
recommend you check this out and I see
if that fits a purpose and eventually I
would love to see the great ideas from
uber graph also adopted by loom and
maybe who knows maybe at some point
they'll solve all their graph problems
that you might have there's lots of
different ways are implemented to
visualize loans graphs besides just a
you know they already available graph is
so there's the prototype or chart and
then there's the gorilla ripple I people
familiar with like the worksheet style
computing development you may be
familiar with covers for good test
session so gorilla repo is basically
that so for instance here we see an
example from the gorilla repose
worksheet or we call loom view which is
how you can render the graph and then it
shows you just the graph right there now
line boom too I use this loon line boom
was presented a closure was 2014 by
Aaron Brooks and so will lets you I
depend on code and github rather than on
a released library so if you found
something that really solves your
solution but they haven't released any
kind of you know closures or anything
like boom line room allows you to
actually do that and the most also
mentions in a book closure for data
science I am NOT a data scientist myself
but I browse through it and it looks
pretty awesome and it shows how you can
use loom to solve social network
problems so it's very very cool I
recommend you check it out and finally I
know that aloma has been used in a
variety of research projects and
production workflows there was a team at
Berkeley
that was implementing a compile and used
loom for their to represent their
programs and people have told me that
they use it for their workflows in
production cool so let's talk about
evolution of loom now and how it came to
be where it's at now so in 2010 loan was
started by Justin Kramer and there's a
great library she worked on it for a
while but then got busy with other
projects so in 2013 I picked up
maintenance of loom and in 2013 3 2016 I
gave a bunch of tags on loom and how to
do functional graphs enclosure and so on
after the closure was 2014 they have
been many more contributors to the
project which is really exciting because
that's when we were able to get even
more features in Tulum and finally in
2016 as I realized that I had less and
less time to contribute to maintenance
of loom post Niner stepped in to cool
maintain loan so I'm very happy to have
him on board and I'm very much looking
forward to long getting all the
fantastic contributions faster and
faster into its releases so in the past
two years there have been several
algorithms added such as a star which
allows which is commonly used by AI game
a is for pathfinding which specifies
basically heuristics and then allows the
game yeah it's a fine um its path and
then pre edge traverse and post edge
traverse algorithm which basically
defines given a node n its successors in
which order there should be output in
the ordering there is the maximal
cliques we discussed which basically
clicks are when all the adjacent when
the vertices in a clique are adjacent to
each other the greeting coloring was
added the dad ancestry I algorithm was
added by Aaron rope which is used now by
line room including generative testing
how many of us use our are familiar with
generative test
like technical test check okay cool i
see a lot of hands great so i was very
excited when we added that to loom as
well some of the other algorithms that
were at is bi-directional brute force
search prims minimal spanning tree and
data flow analysis framework so data
flow analysis framework it basically
allows you to run flow algorithms on
your graph representation find out
things like for instance how does the
constant get propagated through my
program if i were to visualize my
program as a graph another example of
this is tint analysis like information
flow analysis so like if a secret gets
leaked and only this circle of people
knew the secret how could it be that
this other person outside of that circle
found out the secret so it allows you to
do this kind of analysis on the graphs
there were lots of performance
improvements which was really great so
some of the performance improvements in
loom basically bow down to at the
algorithmic improvement could we stop
doing some of the unnecessary operations
if we don't need to by taking a hard
look at the implementation of colorism
and comparing it to what the theoretical
time-bound are and trying to figure out
where are we wasting too much time and
where are we doing much worse than their
theoretical bounds in addition there
were many memory usage improvements for
instance like if we want to store lots
of nodes we might be in viewing them
into queueing them into this our
collection of nodes but then we might
realize that we don't actually need to
keep track of all of them and want me to
reduce this set and finally we started
using transients so I've been asked a
lot what about closures data structures
and whether I needed to write my own
more sophisticated data structure to
make it more performance the bottom line
is no the classic closure data
structures that all the available have
served really really well and just use
of train
and adding the specific points of
mutability were a necessary to speed it
up and we knew something about this
instead of doing you know the immutable
structural sharing approach to having
our in-memory intermediate data
structures for its really well now API
as you might imagine also involved in
the past two years so before 2014 there
was the editable graph like the whole
idea of editing graphs was kind of
sprinkled around the graph protocols and
then Steven cocoon kid and I had long
discussions about what graphs should be
represented as and whether we should be
mixing this mutable and immutable ways
of dealing with graphs and we decided
that edible graph should be sub in a
separate protocol which allows you to
add nodes at edges and so on and if
you're not interested in actually
editing it then we should have just like
immutable view into the graph immutable
way of dealing mothered finally they say
well so a multi graphs were added by
Mark and Goldberg which was really
really cool he had a very interesting
way of actually adding it to the
existing protocols where he previously I
just was defined by just the two
vertices source and destination vertex
and he created a way to refer to an edge
either by its vertices or by an edge
itself as an entity and the way he
implemented a tad is very interesting he
basically extended the persistent mad
persistent vector thing and was able to
do it like that and finally we did a lot
of the protocol cleanup so for instance
it was pointed out that partial
functions shouldn't really be part of
the protocol because it requires the
author of the graph which ones to port
it to loom to have to define lots of
boilerplate and you know we're writing
closure here if we wants to write a lot
of boilerplate would write in a
different Jamie I'm language
so so those who are removed and and now
we have just much cleaner much better
protocol definitions and there's a just
many more things that happen like it's
basically a big mixed bag of things so
they have been improvements the testing
as I mentioned for generative testing
was added matraville added the
compliance tester which basically
extracts all the different tests that we
had for grass to confirm that the
undirected graph or the directed graph
was correctly implemented and all the
different invariants about it are
correctly asserted and he moved that
into its own test suite which is really
cool because now anybody coming in as I
using had a third-party implementation
of loom protocols can verify that the
graph is appointed to the specification
we had a closure script support as of
0.6 bono release which was released
couple of days ago with so Daniel
accountant provided reject conditionals
by moving loan to a closure 1.7 and then
all day file extensions were switched to
sell JC and he added a trigger
conditions for us to live in in the in
the methods and in the functions that
were we had to pick whether to go with
closure or closure script implementation
we had to increase one more dependence
so used to be that bloom only depended
on closure and I was presented with this
interesting choice when we were adding
prims minimum spanning tree algorithm so
the trade-off was and then we add
additional dependencies which is
priority map and ideally would like to
keep the dependencies to a minimum
because somebody else depending on loom
may not want to depend on all these
other crazy a number of dependencies on
the other hand the trade-off was that
someone would have to roll out by hand a
a dealer structure that's similar to
priority map but then they overheard of
testing maintaining that if you're
applying its correctness increases so
seemed like a reasonable choice to add
dependence on priority map so that this
could be solved in a clean way and we
can separate the concerns of the data
structure correctness implementation as
well as the algorithms correctness I
made another choice after closure was
2014 which was to no longer require
closure contrib and I've been asked
about this several times so let me
clarify why I did this so a lot of us
may be playing with a different open
source projects and like me maybe
working in companies were sometimes
there are certain processes the one
needs to go through to get the code
submitted to open source things so on
the idea was to lower the barrier the
entrance bear so that people could start
contributing to loom even while it's
taking them some time to get the correct
approvals for closure contrib and it was
interesting because actually most people
who ended up contributing to whom still
have the closure contribs signed but I'd
like to believe that for some people
that was the helpful bit were they were
able to see their contributions as part
of loon now let's talk about the all the
traders we do when we maintain open
source projects I feel like this whole
topic doesn't get discussed as much or
at least I haven't been in as many
conversations I would like about all the
different things that it entails but a
lot of people who are interested in open
source are interested in what it ends up
costing them what it ends up taking it
so first of course you know for pork was
after closure West I started getting
more and more pull requests coming in
and before when I was pretty much the
only contributor it was very easy right
I just write code i tested and then it's
part of them now and now release it soon
now the lots of work was coming in and
so I needed to make the trade off
between development time and the time
that time spent
Stan on reviewing pull requests and I
ended up making the choice of preferring
to review pull request because those
however many hours I could have spent
writing the features those same hours
spend by many other people and all that
effort I could get that in tulum much
sooner by reviewing many more pull
requests in that amount of time so that
just allowed loom to have more different
features have better design and have
more good contributions another
important consideration was the quality
and the quantity of contributions and
I'd like to clarify the quality of
contribution was always good what I'm
talking about here is whether it was you
know had an appropriate coverage of
testing even if it was correct was it
consistent within the rest of the code
base what is it idiomatic closure I
started working alone because I wanted
to learn enclosure and so I was learning
as i went about all these idioms that
closure community uses and also when i
get to the pull request the person may
not already may not have enough free
time left to address all these things so
striking the balance between accepting
maybe not the most perfect form of a
pull request and then just myself
addressing couple issues we're waiting
for someone else to come in and help out
with the code cleanliness or rewriting
some code to be more idiomatic enclosure
was very important and speaking of
consistency of code base um a lot of
there are a lot of tools out there like
lint or toes like line is food line bike
shed which basically catch all these
little issues for us already
automatically so we can just you know
save those brain cycles instead on
implementing new things instead of
worrying about being extra clean extra
precise extra consistent and I don't
know maybe it was surprising to me but
the time spent on everything else beyond
pull request actually took up more than
reviewing for request it all centered I
being just like many different types of
work or protocol review
you know so much fun just like reading
code through it and trying to figure out
what their code does so one of them was
releasing your closures maybe just my
bad luck and there's nothing wrong with
the lining and toe but it said that it
would work out of the box i followed so
many blog posts and there was always
something how there was like
authentication things like I battled for
that so many times but the important
part is that work is important because
it's important to get out the
contributions of people and to get bloom
used by other people by releasing those
things another thing was creating the
auto-generated API documentation using
code ox so if somebody comes in and
thinks that Lou might be able to solve
that problem so they can have a quick
look to see if loom has the necessary
algorithm for them instead of having to
dig through the source code by the way
if anybody knows about a tool that deals
with reader conditioners for autodoc
generation which is talk afterwards
because I ran into some problems with
contacts after day 0.6 bernal was
released now sitting on continuous
integration tests the travesty I was
also very important it gave that extra
bit of confidence for people who lie
down alone for their research projects
or their production work to verify that
loom actually worked its passing tests
so to the best of our knowledge there's
no issues another useful thing is
there's an integration of Travis CI and
what github so when Porter cross came in
both me and the contributor could
immediately see and address the issues
because they would run the tests for
them at their poor request and figure
out if there's anything that is breaking
then there was all this you know
community management stuff so there is a
mailing list to get people up to date
about what's going on with loom and
people asking questions and over time
community started helping each other if
figure out issues before I could even
get to respond which was really cool and
also you know having a twitter account
allowed me to keep people informed about
the releases coming up
now the attacks on design structure and
content have also been incredibly useful
because it helped keep all the
contributors and to be contributors on
the same page about what the vision
behind loomis but the philosophy of
loomis so that the contributions could
be in line with word we want a loom to
go for instance there are many questions
about oh is low for visualizing graphs
what is but that's not what it does it's
specifically to run graph algorithms and
visualization is just a way to look into
the grass but it doesn't try to you know
figure out the layout of your graphs and
so on so making sure that the
distinction in concerns is well address
was very important so this is me at
closure was in 2014 talking about them
and also backwards compatibility of
release is very important I loomis not
yet one porno I hope you'll get there
soon but so I used a minor version
increment increment to signal that it
may have breaking ipi changes whereas
the micro increments were for any kind
of new fixes bug fixes and so on once we
get one point no I expected it will
follow much more rigidly with the
semantic versioning um there's the non
zero cost to context switching when
using different languages so in my
day-to-day job I write C++ and when I
worked a lot of them which was like most
weeknights and weekends they over had
seemed negligible because I could just
write a dive right into it whereas as my
responsibilities became bigger and
bigger in my day job I couldn't
necessarily get to write closure so
frequently so every time I had to sit
down there was that extra overhead where
I needed to remember what the idioms are
and how to express these things in
closure and also i'm sure my c++ code
was very much affected by the closure
code ask my co erection again
and of course you know we're all have
different life responsibilities it's
important to balance to find the right
balance and it was just one of the many
considerations when I was maintaining
low um there's some list of references
that I used a specific like too potent
one which I didn't actually mention so
there was opposed by Nathan Mars on
history for patches tournament lessons
learned which to me was the first blog
post i read about what it's like like
what the process is like of i do an open
source work and actually inspired me to
share my experiences whether you're here
today I had a recommend that if you're
curious about how you know storm got
from a passion project to an Apache
project with lots of commuters and
contributors to it now this is the
moment for you know like after all these
many many days months years of work it's
good to you know pat yourself on the
head right about the job well done so
there was opposed by Adam board on where
he is the offer of leader for reddit
which is basically this tool that allows
you to post post to sup reddit and
figure out the best timing the most
optimal timing to get there awesome you
know instant internet karma points
because yeah that's lucky not the
priority here and it also republish
system for you if you didn't get enough
points you know because huh if you
wouldn't want someone else to get that
was credits right for you so I so here
so he used lum for something else so he
used them to figure out so he's business
the says he didn't track any private
data about the users who used later
later for reddit but what he did is he
could say if you're interested in
cooking then you might also interested
in baking and then figure out which kind
of like you know clusters of interest
and he used long to analyze this and he
wrote up about how easy it was to use
loam to actually Porky's internal
representation in Tulum and so thank you
for the post he found it easy so
hopefully you will too if you decide to
use loom and I'd like to thank all the
contributors I really hope I didn't miss
anyone there's like twenty six of them
and I went
very carefully so thank you all for your
hard work and thank you all for just
being amazing community and something
that I mentioned at closure West in 2014
which still holds is looms vision I
would love to see loom being part of the
closure country Porter it is the
solution for graphs graph algorithms it
is the graph library enclosure it's well
under way on its way to become that
people had very easy times it's evolved
and it's becoming more mature what it
needs now is just more battle testing
proved it that it actually works for the
use cases that is it for today and thank
you very much and I'll take any
questions
Nick so sorry did everyone hear the
question should I repeat okay so the
question was instead of adding the
dependency it correct me if I
misinterpret your question instead of
adding priority map instead of creating
the shading of okay so the point would
be to make sure that the consumers don't
pick it up as well and so prims a
minimum spanning tree is a very useful
rhythm for a lot of people so we have
not considered that or looked into this
because the idea was to get it out there
and get it used by as many people and
see how many people actually need it one
thing that we did do is when discussing
for instance there was a namespace i
added a loom derives which allows you to
derive graphs from any given graph using
maps and filter and so on and the
trade-off that we made a's wanted to be
part of them but we wanted to be in a
different name space because we don't
need to be part of the Loom graph like
that's not part of like they the core
package of you know how graphs are
represented and similarly with data flow
analysis it was actually put into its
own namespace so we use some of that
work now you can lock filter on the
namespaces that you're actually
interested in using and but we have not
done that yet yes
so the question is have I connected loan
to other graph databases such as neo4j
or other ones so not neo4j specifically
but in 2014 I talked about integrating
with titanium which is the closure
wrapper for Tizen TV so yes I have done
that and I didn't talk about it here
today but it was very easy and like I
showed some you know snippets of how I
actually imported the view in in Titans
world and titanium to convert that into
your loom graph so that was successful
any other questions who wants to
contribute to look oh yes
I see ya so the question is what are the
limits that I reach with loom um
personally I didn't have the graphs the
size of graphs that would push its limit
guru giovanna was a great contributor
who did a lot of performance
optimizations because he actually had
the graphs and available to him that he
could test on and verify that he saw the
speed-up said he wanted to see I think
it was like and off the top of my head
something like 10,000 know it comes to
mind but you know it all depends on like
what your nodes actually are underneath
rights because when you put it too long
they're just note just did I but uh so
you know good if we were to talk about
limitations of lung I would say that I
because of my day job doesn't muslem my
personal limitation was that I no
surprise again my personal limitation
was that I didn't have the huge graphs
available at my disposal so I could play
with them and actually push his limits
and do more performance optimization so
so that would be it is what keeps loan
from one point oh um I would say we want
to one thing important thing would be to
take a very hard look again at the
protocol definitions and to make sure
that it's really what we believe how
graphs should be represented in loan
then to take a hard look at what uber
graph does and the types of problems it
solves and figure out if we can take
some of those fantastic ideas from uber
graph and move them to loon and another
would be just getting it used as many
times as possible to where we can say
okay great people enough people have
used it word they haven't had it solve
the problems the way they wanted them
solved and now we can say that if you
were to use in your production thing
then luann will probably work great for
you and that also implies that
performance is reasonable it's not too
slow which is something that people
found you know two years ago for their
problems but but you know we can always
do performance
provements again and again so it would
just be you know i guess i will need all
your help if you have a graph problem
try using it tell us about it if we
would love to know post night and i
would love to know how you using it so
we can make the best library because the
point of loom is to be as general as
flexible as possible solution for graph
problems graph algorithms
so the question is how do we get from
you know just the unit test driving it
running the travesty I to actually
releasing the closures and deploying and
trying that and having integration tests
so we don't have integration tests we so
when a pull request gets submitted we
try to do the best job we can we're
working with a contributor to get the
test coverage to have the confidence in
the implementation of the algorithm and
then once it's a travesty I green who
basically published that to closures and
cut the thing it would be great if we
had something where we could integrate
with many different other types of grass
but right now we don't have that so
somebody is interested in writing that
it has sweet integration tests with that
would also be very helpful to get loan
to the orchard zillow of 14 no yes
so the question is like how how much
more can we add to loom before we can
actually feel confident releasing it is
that a fair summarization of yeah like
what does it mean for it to be ready so
that's a good question like a lot of the
a lot of the most useful grass I roads
there a lot of the most widely use graph
algorithms are all did there so at some
point I imagined in my just being a
judgment call where we say looks ready
enough and then you know getting other
people to agree that it's ready enough
for usage I've used loom but all my data
was basically fit very nicely into you
know laptop memory so if there and it's
possible that a lot of use cases for
long we will just be you know throw your
problem at it it fits very nicely into a
ram and then you know don't worry about
the optimizing it and we might end up
doing that but if people try using one
algorithm for their seemingly
straightforward problem and they run
into such a slow run of an algorithm
which is what happens with one of the
algorithms and then like nobody can use
it and it doesn't really make sense to
promise and at some point also you know
if and when it becomes well hopefully it
will become part of their closure
control it will still be more
development doesn't mean that it will be
you know just the perfect thing that
nobody will ever touch again because
it's so perfect yeah so I imagine that I
was just at some point it would just be
you know a judgment call that the
maintenance will make and the community
will agree that it's ready to become
part of the closure country yes
mhm
you
so the question is like if we were to
use loan for some of the you know AI
problems could we add some timing
constraints or some like you know depth
explores constraints so that we can make
it usable so right now there is no such
way but you know the goal of lung was me
to sort of like be as flexible as
possible of a solution for many
different use cases so I were very much
welcome that contribution assuming that
you know it would also be helpful and
present a solution that doesn't take
away from other types of solutions like
it doesn't you know steer it towards
only one direction of loons use cases
okay I think we're out of time but I'll
be here I'm just curious how many of you
are now interested in contributing to
loom or may consider interview ok I see
if your hands so looking forward to our
contributions thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>