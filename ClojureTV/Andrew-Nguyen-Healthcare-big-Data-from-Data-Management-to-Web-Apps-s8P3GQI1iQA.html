<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Andrew Nguyen - Healthcare &quot;big&quot; Data from Data Management to Web Apps | Coder Coacher - Coaching Coders</title><meta content="Andrew Nguyen - Healthcare &quot;big&quot; Data from Data Management to Web Apps - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/ClojureTV/">ClojureTV</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Andrew Nguyen - Healthcare &quot;big&quot; Data from Data Management to Web Apps</b></h2><h5 class="post__date">2014-03-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/s8P3GQI1iQA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Andrew nuyen and this is my
first closure was so hopefully this is
somewhat in line with what you guys are
expecting to hear and I think the
schedule says body data systems for the
company we recently went through a name
change and so that's what you see on the
screen is Clara health and then first
just thanks to alex lynn and everybody
at kona tech for putting on a great
event so far and happy to be here
basically i'm here to talk about kind of
how we're using closure and closure
script in health care big data but i put
big really in a really small font
because to us big data and health care
is really a thousand little data
problems i haven't been able to find the
source of it but i was told that the
average patient electronic medical
records only about one to three
megabytes and so discounting images and
videos and whatnot there's really not a
lot of data it's just a variety of it
and so a little bit about myself I
recently finished a PhD and medical
informatics at UC San Francisco and my
thesis was on biometric and
physiological sensor data analytics and
mostly waveform data in the intensive
care environment and then kind of
through that process and through that
work became acutely aware of the need to
normalize and harmonize healthcare data
and whatever's coming out an electronic
medical record just quickly in terms of
the audience how many people here have a
background in health care or have done
health care okay and then in terms of
the software side I spent a lot of time
in embedded software and defense
aerospace wireless semiconductors and
then in terms of the health care and
informatics I of it did a lot of work in
Hadoop and semantic computing in general
and web application development and
quickly brought the company kind of the
startup our goal is to bring clarity to
health care and pretty much through the
data and our lead product right now is
the my view electronic medical record
interface and the idea behind it is to
make it really easy for physicians
nurses administrators anybody in health
care to have access to relevant patient
data and customize the view of patient
data from any patient within our network
and the goal is to make electronic
medical records better we
overlay any EMR systems or not intending
to replace them and then make health
information exchanges unnecessary and so
what's the problem that we're solving
really for us it's it's just it's
difficult to to access relevant patient
information from electronic electronic
medical record systems even within a
single organization so a doctor sits
down and says what did I do to my
patient last week and what do I need to
be thinking about to treat them today
and that's not as easy as it should be
and then if you're trying to pull data
from different sources so the hospital
down the street or clinic across the
country it's virtually impossible right
now to do so at scale and and in a way
where you're getting what you want
instead of them to hunt in fact for
everything and so why is it so hard the
problem that we see in health care it's
for kind of four fold we're trying to
communicate the same thing in different
ways and so simple example a lot of
times we just call it a heart attack
doctors call it a myocardial infarction
you look in the notes and there's a
bunch of abbreviations am I and these
all encompass the same concept most of
the time and when you look through it
though it just looks a bunch of
different ways and how do we tell
computers what this means and then if we
look at it we're also trying to
communicate different things the same
way and so something as simple as a
patient encounter you know a doctor and
a patient's in a room together there's
an encounter but is it really an
outpatient visit is a hospital admission
where you got admitted one day and
discharged two weeks later or is it a
procedure where a surgical procedure
sometimes is referred to as an encounter
and then we're trying to do the same
things with different data so something
that's common right now in the industry
is looking at hospital readmissions so
did you come back to the hospital for
something that should have been treated
or could have been treated and if you
look at it from the hospital perspective
they're usually trying to answer this by
looking at electronic medical record
data but insurance companies who don't
have access to that data they're asking
the same questions but they're only
looking at claims and there's that's
just one simple example and then we're
trying to do different things with the
same data and so there's a lot of
electronic medical records out there
there's a bunch of patient data sitting
in there and one doctor may look in it
and say you know what I want to set up a
trigger a report of some
sort that lets me send out notices to
parents and reminding them that their
kids should come in for a booster shot
for immunizations or something and at
the same time we're trying to use that
data to do resource management and
supply chain make sure that we have an
effect scenes on order and so we're all
trying to use the same data but we're
doing very different things with it and
so back to this example of an encounter
let's say you're patient you get them
into a hospital for two weeks and
there's three surgical procedures during
that timeframe simple question to ask is
how many encounters is this and this
forms sort of a it's an example of a
basic query that we want to ask of the
data it forms a unit of measure right
and if you talk to a hospital is there
an inpatient doc they'll say it's one
encounter patient got admitted on one
day got discharged two weeks later you
talked to a surgeon and they say well as
three encounters because they came into
my or three times and to make it a
little bit more complicated what if the
second and third surgeries were just
extensions of the first and so are those
separate encounters is it one encounters
at one episode of care and so up until
now how did the industry approach this
basically was let's build custom
solutions for everything every hospital
out there gets its own little system and
within a department sometimes you have
different systems for the ER for the o.r
for psychiatry for I mean pretty much
everything and then clinics if you look
at outpatient clinics versus hospitals
and we've gotten into a habit of
basically just building custom solutions
for every possible use case out there
even within a single Department you
oftentimes see multiple competing
systems that's like dude slightly
different things and it's pretty much
the reason why there's a ton of data
silos there were a lot to begin with and
we keep making more of them as we try to
actually leverage you use this data and
one of the stats that I surprised me the
first time I learned about is if you
look at a medium to large Hospital so
this is like 600 to 1000 beds there's
upwards of 400 different data systems
and I was talking to a guy at one of the
hospital systems in California and
across all their hospitals they have
over 2,500 different databases and
vendor
that they're trying to aggregate data
from and so how are we trying to handle
this now that they're all these silos
and basically let's push
interoperability and let's get everyone
to agree on how to capture store
exchange and interpret healthcare data
and as engineers I'm sure you're all
aware how you capture in how you store
data is often times depending on how
you're going to use that data and so
then it comes down to interpretation and
one of the things that we're focused on
as a company is that that part of the
process how do we interpret healthcare
data and from an interoperability
standpoint if we look at kind of hims
definition there's a major trade
organization that encompasses healthcare
IT they break it down into three steps
the first is foundational so the ability
to communicate between systems and so at
this point in the game we have things
like XML JSON rest and a handful of
others that allow us to physically send
data back and forth and then on top of
this you can build some sort of
structural interoperability and in
health care there's the hl7 standard it
allows us to at least know what we're
sending there's an API coming out of
Harvard that's called smart and that
provides some sort of uniform access to
healthcare data and then on top of all
this is the semantic side of it so the
National Library of Medicine carried
this umls which is a collection of
vocabularies terminologies and and
whatnot and this is sort of where I've
always been focused on where my
interests have been and the definition i
like to use for semantics and the the
sub part of that is the interpretation
of the meaning of a word or in this case
a medical concept or a clinical note or
a data element of some sort within a
database and so that interpretation ends
up becoming a highly contextual process
it depends on who's asking that you have
doctors or a cardiologist probably not
going to interpret data the same way
nobody gon would and then you have
patients and their caregivers parents
and whatnot that are trying to look at
this data and then what are you looking
at are you looking at patient records
are you looking at stuff out of
electronic medical record or is it
claims information or something coming
out of a bedside monitor an EKG or some
sort of sensor and then now there's a
whole lot more patient generated data
between wearables and fitbit's and just
people tracking a lot of stuff on their
own
and how do you interpret that and then
why are you looking at that data the
most obvious one is patient care all
right doctors nurses pharmacists and
whatnot are always looking at this data
to treat patients better but as an
organization or as an industry there's a
move towards population health where
you're trying to aggregate data across
multiple patient populations to target
the sickest or the most expensive and
see what we can do to drive down costs
or just improve health overall and then
there's always predictive analytics it'd
be nice to know if we can predict when
something bad is going to happen and
prevent that and then how are you
looking at this data is it a clinical
workstation that I don't know if you've
been to the doctor recently but pretty
much the person sets at a computer the
entire time while you're talking to them
and then you have analytics algorithms
where normalization is really important
and then generating reports for the
administrative administrative level or
trying to exchange data between
hospitals or different organizations
within the healthcare continuum and then
where is this happening is it in the
hospital is an outpatient clinic
insurance companies the big 12 is
geographic or the difference between
urban and rural medical centers the
environment plays a big factor in health
and so do demographics and so how does
this affect the interpretation of data
and so how do we get everyone to agree
on semantics it shouldn't be too
difficult until you look at the numbers
there's 300 million patients there's
anywhere from two and a half to three
million nurses out there and over
800,000 physicians and they're spread
over 6,000 hospitals if you look at the
electronic medical record vendor
industry there's a federal mandate to
certify EMRs and as a stage one there
were over 900 certified EMRs and part of
stage two that numbers drop to about 70
or 80 and it's an ongoing process so
they're probably going to be more but
you have almost a thousand different
vendors providing centralized electronic
medical records and then you have
thousands of other vendors providing our
scheduling systems ER management labs
pharmacy billing and come the list goes
on forever and then you have insurance
company mechana everybody else in
healthcare outside of the hospital you
have insurance companies medical device
companies pride
practices my parents were in the dental
field and pretty much not a lot of
people are looking at dentistry from the
data standpoint in health care and our
perspective on this is you can't really
get everybody to agree so don't try but
can we design a system that embraces
that inherent dissonance and somehow
enable a mass customization on top of
that and somewhat synonymous with
building a customizable and dynamic
system but standardized enough that we
can repeat it in scale it across the
industry and so our approach this is to
leave data in its native form we don't
want to alter the data because a lot of
times you change data you want to go
back you learn something new about the
patient or or something better on how to
interpret that data and you've already
changed it and so with that basically
this contextual on-demand translation of
the data so can we do what we need with
the data without changing the the raw
source form of it and can we deploy this
as an on-premise solution a lot of
hospitals want to be able to control the
data or for those that don't have the
resources to do so can we deploy into a
HIPAA compliant club but the key you
regardless is to manage everything from
the cloud and what this does it allows
us to make it repeatable and scalable
and especially given that we're just a
start-up trying to tap into the
enterprise healthcare market and so this
is a quick screenshot of our my view
interface right now it's just there to
to show that we can group all the data
together and kind of provide a concrete
example of one example of what we want
to do with that data so the big question
is how do we make that a highly
customizable and dynamic system but make
it repeatable and scalable and so we
discovered closure about six months ago
and had been using a lot of Java before
that and it's become an important part
of our toolkit and just some quick
background basically we're doing a lot
of Java and then we started doing some
groovy and mostly because the existing
ecosystem has a lot of Java a lot of it
runs on the JVM and about six to seven
months ago we started to play with
closure mostly just experimentation
futzing around with it and then five
months ago we started using it pretty
exclusively and then closure script
about the last two months
we've ported quite a bit of our code
pretty much all of the Java and groovy
has been ported over and that was way
faster and more painless than we had
expected it to be the CoffeeScript and
closure script side of it we're still
learning and I have some questions about
that later and so how do we get there we
started with Java as I said went to Guru
because we didn't really like Java and
then we started experimenting with
closure when we started playing around
with Hadoop in casco log we do a lot of
Hadoop on the backend and cass god
looked interesting and so I figured this
may be a good time to start learning and
once we started playing around closure
we realized we were really liked it and
liked what we could accomplish with it
mostly and so we decided to take a stab
and see if we can commit to it and see
what that would look like and so one of
the kind of the the three main reasons
we went to it was dynamic development
and the repple and being able to
interface with and it sounded really
cool but we kind of had doubts in terms
of background we came from assembly C
C++ Java and so this was a very foreign
workflow for us it was fundamentally
different and we had to learn how to
work with it and how to move away from
kind of the traditional mechanisms of
testing in iteration that we were used
to but what it did was it enabled really
fast prototyping and experimentation for
us we could futz around try something
see what happened add to it and keep on
adding to it and the next thing you know
you have a functional part of your your
project done and that also made it
really easy for us to learn and
experiment with new EP is I don't have
any numbers on it but in terms of how
how many more libraries I've
experimented with in the past six months
has gone up quite a bit and I think
that's largely due to the fact that it's
okay to experiment and it doesn't cost a
lot of time or take a lot of effort to
pull in a new library and see what what
happens when we can do with it and some
things that we noticed in terms of
trying to keep an eye on it basically
these are things that bit us in the ass
and it was really easy to create complex
one-liners and if somebody kind of goes
off and does something and comes back a
couple weeks later it all works it looks
really cool then you forget
about three weeks later you go back and
try to fix something and you spend a lot
of time just trying to figure out what
went on and when we looked into it it
was a lot of experimentation you try
something out you add a little bit to it
you keep adding little bits to it the
next thing you know you have two lines
of code that do a whole lot and part of
that also was it's easy to get away with
not documenting because developers
should say well if you need to look at
the code and it's all there for you and
my code is self documenting because I
chose really good names for everything
but it's not always the case and they're
not really a dynamic development issue
but one thing we noticed was macros are
tempting but risky because they create
time bombs especially when interacting
with other api's or other people's code
unless you spend a lot of time vetting
all of the code you're bringing in the
end up getting unknown interactions and
those interactions create really weird
effects and then I heard this a lot at
first it seemed whatever but I've come
to appreciate a lot in terms of code is
data and data is code and for us
specifically because we have a system
where we're trying to pull in these
semantic rules or even syntactic in
nature of how do we massage data how do
we pull it together and and be able to
compare different data sets we needed to
deploy what we call data rules that are
a runtime thing we deploy our system and
then we need to go in and change them
these rules around and this idea of code
is data is just very helpful for us as
an abstraction or as a way to think
about what we're doing and functionally
it's great to and everything is a
function and so we can test these
functions pretty easily outside of the
system have a high confidence that
they're not going to break anything and
be able to deploy them and manage this
process and so it really simplifies how
we deploy our data rules and how we're
able to basically blur the lines between
what's being done traditionally as a
compile-time task and what's being
pushed out to run time or you know we'll
deal with it later and then the other
cool thing for us was the close
integration on the JVM
we pretty much didn't have any trouble
calling job or groovy stuff from closure
we didn't have any major problems and
since the original attempts at closure
we ported all of our groovy code and all
that's remaining now is Java code that
were interfacing with in terms of
third-party stuff one of the things
we're still learning though is how do we
translate kind of from this object
oriented approach to a more functional
one and this is true with a lot of
existing libraries that expect you to
create this one instance of an up class
and then you just keep doing stuff to it
over time and then sometime down the
line you call this run or do it function
of some sort and all this magic happens
and how do we encapsulate that into a
more functional approach and something
we're still learning and experimenting
with just to find out what the best way
to do that is one thing we have not
tried at all is to go the other way is
to call closure code from Java or groovy
and we do notice that we have a lot of
hyphens in our namespaces and so maybe
that's one of the reasons why we're
trying to commit to closure completely
and then for whatever reason it was just
a lot of fun and I don't know if it's
just a combination of all of the above
but it didn't feel as difficult or as
tedious to learn new API there to
integrate or to take on bigger and
bigger challenges and I as a result it's
just a lot more fun for me to develop in
terms of the stack I'm not going to go
through all these libraries but
generally it's what we're using we have
a graph database that we're using with
the blueprints API we have a Mongo
instance we're using RabbitMQ underneath
a lot of it and then we're starting to
look at de Tomic but we haven't done
anything with it and then kind of your
standard web stack and then associated
libraries to make the coding life a
little easier and how we test and so in
terms of looking at what libraries were
using the first the most important thing
for us was how easy is it to use there's
so many options out there and there's
always the do we get one especially if
we're trying to wrap an existing Java
project of some sort
do we use one of these rappers somebody
else created do we create our own
wrapper because it's really not that
much work or do we just not wrap it at
all and try to interact with the Java
directly and so the first thing was is
it easy to use and then second is it
easy to maintain projects come and go
and if need be how much effort would it
take for us to take over that project
internally and then it'd be nice if it
was an active project that we didn't
have to worry about adding features and
what not to overall we had a couple
other things we considered which was how
many dependencies were there in the
project that we were pulling in however
Bose was at API two things we learned is
a lot of projects out there so there's
there's always that balance between do
you reinvent the wheel or do you pull in
an existing project and sometimes we
found these really simple libraries I
pulled in like 20 or 30 other projects
and it just became a big nightmare to
maintain and make sure that we had all
the library set up so that we knew what
was going on and what was happening
especially once we start deploying these
in large-scale production and then did
it make sense overall Oh some of the
api's we found I don't know if it's
because we're new to closure and kind of
what's idiomatic and what's not but it
seemed like a really weird way or really
convoluted way to accomplish something
simple and so that made us stay away
from some projects and then overall that
it fit with our general coding
philosophy this was not as important to
us because we know we're still learning
and what we think is best now may not be
in vice versa and then one thing we
really disliked was hidden dynamic
bindings or state kind of in the
background that was just hiding there
some of the comparisons I'll go over is
so we started with closure tests and
then we ended up migrating away from
that and partially because the fail your
output was easier to understand for us
and auto test surprisingly increase our
developer productivity more than we
expected and especially when trying to
convince people to add all the other
test cases to round out your test suite
and the ability to just keep adding that
and watch the little auto test say all
your tests are succeeding I think was
a positive feedback loop that people
were able to to really add all the tests
they should and then one thing that we
noticed with closure test was that the
fixture seemed to be a little bit less
verbose and this could just be that we
don't fully understand our tools yet but
we do a lot of testing where we're
interacting with databases and so being
able to set up and take down that
process was important to us and the
migration away from closure that test
was sort of difficult when we're trying
to learn that initially and so we're
using core type coming from the sea
world we wanted some sort of type system
in place because it made us feel safer
and kurta type seem to be exactly what
we wanted but we noticed once we started
using it we started sprinkling these no
Czechs everywhere and it seemed like we
were doing that more often than not and
so the big question was why are we doing
type checking or what do we want out of
that and really it came down to we
wanted to ensure that the maps and
vectors were passing around had a
certain structure to it and so once we
thought about it that way schema seemed
to fit our current needs and be less
verbose and easier to to integrate in
tour our workflow and our our code base
but one of the cool things is if and
when we need a stronger typing system of
some sort there's no reason why we
couldn't integrate the two together and
then on the web stack side we chose to
use and live instead of hiccup or close
dash or any of the other templating
libraries and it came down to a matter
of coding philosophy and style we wanted
to be able to have a hundred percent
HTML templates that looked real even
when you were using these are
interacting with them outside of the
rest of the stack and part of that was
because we were working closely with
physicians nourishes other domain
experts who are non technical and being
able to just have something that looked
real and work through that process
really quickly and then hand that off
and not have to do anything else to
actually get it to run was was very
powerful for us basically providing for
our workflow a cleaner abstraction
between the how it looks and how it
works
of the coin and it happened to fit well
with how we were using knock out from
when we were doing a lot of this in a
previous iteration of the product and
that's not to say that other things
wouldn't agree well it's sort of an
observation for us and then in terms of
the closure script side background we're
about a 7030 split right now we're
starting to do new stuff enclosure
script and we have a lot of existing
coffeescript that were afraid to port
over just yet and in terms of prior
experience we have a smattering of
experience with various frameworks and
toolkits and whatnot and so we started
with JavaScript moved to coffee script
and then went on to closure script
mostly because we really liked what we
could do with closure on the backend and
wanted to see you know if it carried
through with the front end stuff and
then we discovered a CL JX or close x or
however you pronounce it in order to be
able to share code between the front end
and back end pretty easily in terms of
our stack on this side it's a lot
smaller pretty much we're just wrapping
a lot of jQuery and then we're using
corto de sync and then your same schema
and tests and whatnot and so we're using
a sync on both the front and the back
end both enclosure enclosure script and
it's really just to simplify the
messaging and job coordination and being
able to do so in a way that we think is
easier to maintain in the code it's
easier to understand which in my opinion
translates to easier to fix bugs and
then on the the front end basically just
simplifying that communication with the
back end whether it's Ajax or not and
overall it gave us a huge simplification
of the code base and as a result the
overall logic and we really want to like
closure script because it's nice to have
one language for everything if it's
possible and then testing for us seems
easier that's not necessarily a
technical reason for that but it's
easier to convince people to to round
out the test suite and make sure that
we're actually testing everything we're
writing and being able to share code
between the front and the back end like
the schemas as we're validating
becomes very useful to us instead of
having to try to duplicate any of this
but we've had difficulties and like I
said this is very new to us and we're
not one hundred percent sure on what
that development model should look like
whether it's a coding style issue
workflow and with the idiomatic way to
to accomplish various tasks is and
sometimes it feels like we're trying to
fit a square peg into a round hole and
that comes down to how do we keep things
idiomatic while at the same time still
feeling relatively natural when it comes
to UI development and as you can tell by
my background UI is not something I've
really thought about much except for an
internship back in college and so this
could just be a lack of understanding on
our part as a development team and what
it comes down to is we're using a lot of
JavaScript objects to hold state and
we're just sprinkling them all over the
place and maybe thats related to how
we're using knock out also and there may
be a better approach that I don't know
so if anybody has any comments feel free
and so using them together as i
mentioned we're using schema on both the
front and the back end just to validate
our are just the data the maps and
whatnot and when we were doing with
CoffeeScript there was another piece of
code to maintain and by combining him it
became pretty simple to to manage
updates basically we didn't have to do
anything anymore and so now that I
understand kind of our workflow better
there's no reason why we couldn't call
the validation functions from
CoffeeScript or JavaScript or whatnot
and then from a development standpoint
kind of a more management perspective on
this by having the closure and
clojurescript intersection it gives us
the ability to move engineers around you
have a lot of stuff we're on the on the
back end you need a lot of particular
knowledge or on the front and the same
thing but there are a lot of tasks in
the middle that you can move people
around as you need and as the your
resource needs change and so basically
the language in this case provides a
common abstraction for us for four more
effective resource management and being
able to do more with less and one of the
the problems that we're assuming exists
I guess is that there's fewer developers
generally to to draw from especially
relative to Java and JavaScript and
we'll be hiring in the next six to nine
months so if anybody's interested feel
free to ping me so what and basically
this come to conclusions we had in this
sort of six-month journey enclosure is
that we were able to increase our code
density quite a bit whether it's good or
bad we don't know but from a lines of
code standpoint we have about a four to
five x reduction and one of the things
here it's a very rough estimate and
we're also adding in comments and
because we were new to closure we felt
we should add the comments because
without the comments sometimes
developers wouldn't understand what was
actually going on in the code and so if
we're going to require comments then we
might as well add those because it's
extra work but as we get more experience
and develop more institutional knowledge
around this we do expect this number to
increase one interesting thing we notice
was if you write a little bit of code
it's you know you're using a couple
closure functions and then you go away
you don't think about it for a couple
weeks or you hand it off to another
developer you have to relearn what
happened why you did why you made a
certain decision why did you do things a
certain way versus actually making the
change that you're you're looking to
make whether it's a bug fix or adding a
feature of some sort and we did notice
that at least perception-wise it felt
like it took longer to relearn code than
with the more traditional
object-oriented approach we had but in
totality the time was reduced in terms
of actually making the change adding the
test case for it and then moving on and
so is an interesting dynamic where it
feels slower at first but we think it's
probably faster in the long run and then
that comes down to just as i said
earlier doing more with less and with
fewer people we seem to be able to do
more I joke that we'd still be creating
or maintaining Java interfaces and a
bunch of getting set functions and then
all the factories associated with that
and especially since at this stage in
the game were moving pretty rapidly and
constantly changing and learning better
ways to to capture the EPI and so
it for us that was really helpful and
then being able to lower this temptation
to just do it in four go test this is
again it's not a technical issue but one
thing I noticed was that developers or
happier creating test cases or they're
not they're not as resistant to creating
tests and maybe it's because it doesn't
feel as onerous because if you're
sticking to this functional programming
kind of paradigm your functions are very
simple so you know what your inputs are
you know what your outputs are and it's
really easy to create a test case around
that and you don't have to worry about
creating these massive test Suites just
to test one function or one
functionality in terms of the more
traditional object-oriented approach and
so as a result testing is much easier
now this is again not a technical
comment but a an overall software
engineering one that if you can get
people to create the tests and not get
as much pushback then I think that's a
win and so basically we're committing to
closure we're on the fence about closure
script as a primary development language
and there are a lot of interesting
projects out there for us to experiment
with still you know kind of keep an eye
on all these different projects but we
haven't spent any time looking at them
and we're very interested in some of the
DevOps stuff out there and so far the
community experience has been really
good and we're excited to be a part of
it and there's just a lot of options out
there in terms of libraries there's a
lot of rappers for existing Java stuff
there's completely native closure
implementations of various functions and
the beauty is you use what you need you
ignore what you don't and it seems
easier to integrate bits and pieces of
different closure libraries than in the
Java world at least in my experience and
we like the flexibility that we get with
closure now obviously with that you get
time bombs or you get you end up cutting
yourself and that's just a learning
curve for us to figure out how to to
head off problems and prevent them
before they happen and
and it's unlikely that as a company we
would have made as much progress as we
did without closure and so that's sort
of one of the reasons why I'm really
excited about the language in general
and kind of where the ecosystem is
moving is that we see making a
tremendous amount of progress in a short
amount of time with few resources and
basically focusing on our time on what's
hard what matters as opposed to just
making sure everything plays nice
together from an interface or an epi
standpoint so it's all I have if anybody
has questions or comments my contact
info is there if you want to reach out
for any reason</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>