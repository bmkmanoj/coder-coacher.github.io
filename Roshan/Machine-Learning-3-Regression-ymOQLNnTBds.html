<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning 3 - Regression | Coder Coacher - Coaching Coders</title><meta content="Machine Learning 3 - Regression - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Roshan/">Roshan</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning 3 - Regression</b></h2><h5 class="post__date">2014-07-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ymOQLNnTBds" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone and welcome to the third
part of this series about machine
learning this tutorial will be about
regression and the previous lesson we
have talked about prediction types
features parameter tuning we talked
about cannon algorithm classification
and testing accuracy it's a very
interesting tutorial and you can access
it by clicking here we're actually
building their a predictive model that
can classify and predict if someone
makes more or less than $50,000 a year
so let's start the third lesson by going
to Amazon Web Services you can access
that by going to aws.amazon.com and got
a call and go to your console then go to
ec2 this is the service that we're using
I will be going over this fairly quickly
because we have shown this process twice
so far and previous lessons so if you're
not familiar with every step you can see
a much detailed description the previous
citizens so we'll be launching an
instance community Mis ipython notebook
server and that's the public one make
sure if you don't find this if you don't
find this ami make sure you choose
Oregon in here u.s. West Oregon select
that
our view on launch
finally go to our security groups is
added security groups open to looks
reports for ports 8080 and 8000 review
on launch launch choose existing because
I have an existing one choose an
existing keep here yes
acknowledged launch now we're launching
our instance we can view our running
instances from here or from here this is
our new instance let's name it first
lesson 3 M let's access this let's
access it will copy them the IP and then
we'll go to column 8000
that should that should open the ipython
notebook server sometimes you have to
wait a little bit until it finishes
initialization
I think it's still boating so let's
retry
it's taking longer than usual let's
check this one to Haiti
yeah I think it started working anyway
sorry actually to access to the ipython
network server you use your IP colon
8080 not 8,000 8,000 days for the agente
administration that we'll see in a
second now
the password is Russian are oh Sh a.m.
that's the default password I have to
remember that would access the third
listen that might take a second to load
so and this listen we'll talk about why
do we use regression we'll look at
temperature data we will see how can we
load and analyze this data talk about
linear regression and finally sfm SVM a
regression support vector machine
regression I made this little script to
generate this so you can run the script
by hitting shift and enter and you will
get this out but it's a link to the
agente administration interface and
these are the default username password
for them so let's do that
understand confirm
the username is root and password is
admin so let's do that
we will have to keep an eye on our
memory usage we're using we're using a
low specs instance which is within the
free tier of Amazon Web Services so it
can replicate everything we're doing in
this lesson without going into any paid
services from Amazon no service you can
get a better instance and do this with
the more memory to do any real work but
for the purposes of this lesson that
will be enough so let's get back to our
ipython notebook and so why do we use
regression and classification within a
predictive model to produce a class or a
category so in the previous lesson we're
predicting whether someone makes more or
less than $50,000 a year that's a that's
a class or a category with regression we
regression is used when you need to when
you need a predictive model that
produces a numeric value instead of a
class or instead of classes so it will
this predictive model will produce a
number instead of class so if we can
train it with them enough income data
like the previous lesson we can have it
actually predict how much someone is
making instead of just a class of more
or less than $50,000 fortunately I don't
have this data will will be using
temperature data and the citizen the
data the data that we'll using is from
Climate Research Unit from the
University of East Anglia I am
very tortured the name you can find the
that's it on their website that's their
website and that's a link to the actual
data set that we used this is sample of
their data it's a fixed distance
separated file which is a text file
it has a year repeated twice for each
year and it reads every month is change
from the anomaly that they have set so
we can see January February March until
December and the last field in here is
the coverage of a global surface that
they have from to construct this number
so they they are using three percent you
can see it's becoming four percent and
it's the number is actually increasing
through the years this is from 1851
until 2014 so the columns we've talked
about the columns we have months
basically there and rows we have all
drawers change from not from previous
months actually this is change from
anomaly and even rows it's a percentage
of coverage globally will lab will be
processing this data and Excel or Cal
Cal actually I used calc to process this
data you can download the file and save
it you can you will have to add a new
column and average all the monthly
anomalies to create an annual average
and you have to
clear out those coverage lines basically
all the even lines this is how I did it
actually I filtered out all the odd rows
and I added and I added an average
basically and the final file is actually
available on your instance the one that
you're using now it's in data the temp
data we can see that in here from
magenta administration file manager I go
to home bond to data and you can see
temp underscore data that CSV comma
separated value so that's the file that
has this data in it we know how did we
acquire the statin what kind of
processing we did on it so far so we'll
let's start the programming part of this
let's start by importing the required
libraries and importing numpy pandas a
scalar and matplotlib which is our
plotting library and we can load this
data by reading the camera separated the
value of one file and we will store this
data in a variable called csv underscore
data so let's execute that shift and
enter first will visualize the head just
to see what we're looking at so in here
I'm scattering all the annual averages
of the anomaly on the y-axis
the years and the x-axis then I'm
plotting the same number just to show
just to give this effect I'm using the
the average as the color so you can see
a color bar in here that shows you that
shows which color represent positive and
negative numbers we can see we can see
kind of a trend in here but we will be
studying this a little further so let's
do this with a bar chart we're coloring
all negative numbers with the blue and
positive numbers with red so that's what
we get we can see we can see definitely
a trend in here but most importantly we
can visualize our data better too
to further analyze it let's look at the
final record the final record doesn't
have all the months it has until April 4
2014
so we cannot really use months in a
reliable way to analyze this data
so first let's calculate some variables
we're basically dropping average this
ico to seach for we'll talk about those
further later but basically i'm
serializing all the month numbers so I
get a long list of numbers for each
month of each year so this is what I
have in here and I'm calculating this
monthly index which will show the year
with a point representing every month so
let's visualize that I'm doing the same
scattering technique in here this is
this is representing every month in our
data set this is the zero line and we
can see something going like this almost
in the monthly but will less they'll be
visualizing this further to see if there
are any visual clues that we um can use
and this is plotting the monthly data
using bar chart we can we can still
visualize a more interesting pattern in
here than the one we had with annual so
first let's see what we can do with this
data
if visually you look at this data and
try to predict where is it going
just with a straight line you will draw
something like this for example so this
is what this algorithm does it will try
to fit a linear model to represent this
so I'm doing the same thing now with the
annual numbers which are the yearly
averages and this is a linear regression
for this period from 1851 and till 2014
we can definitely see this is going up
actually now this is not the most
impressive thing that regression can do
it can be fit to do more interesting
things but not with the simple algorithm
like a linear regression algorithm so
let's do the same thing for monthly data
this will take a few seconds to process
because we have more numbers for months
we can still see the same pattern going
on with the monthly data with the linear
regression you can see this is going up
in over our monthly data too so we will
now look at SVM regression SVM
regression is very interesting to say
the least of an algorithm we'll be
looking at one kernel now we will be
looking at RBF kernel the thing about
SVM you have to tune its parameters to
give you good predictive models so you
can tune it to give you a long term
prediction or short term prediction you
can tune it to give you a more accurate
number over
for any predictive purpose that you have
for regression
so we're training three predictive
models here we're fitting them with our
data but they all have different
parameters we're printing their accuracy
and finally we are plotting them on the
same chart so let's execute this block
and see what we have and here we can see
our first linear regression the green
one we can see that we have three RBF
predictions red the yellow and blue we
can see the blue is a very responsive
one that's a more of a short-term
prediction and we can see we have two
long-term predictions RBF two and three
one is going almost exponential and the
other one is going to more of a sign a
big sign wave we we have a way to test
many parameters to find the best fit the
the best fit for our predictive model we
do that using grid search a grid search
will attest many parameters for each
many values for each parameter and
figure out which gives the best results
according to any scoring criteria that
you want use and here we're using R to
it because it's regression so oh I
executed that already so it's returning
our visits estimator and it's telling us
the best estimator has C value of 1
and epsilon of the 0.01 I was looking
for a gamma where is gamma and gamma of
0.001 so we had few values in here and
this is the way to even further refine
your numbers by basically looking or 10%
around the numbers so I'm looking from
10% list to 10% more and refining our
values so instead of 1 it's 0.9 3 and
gamma is even more refined in here with
the 0.009 so let's visualize this one to
see our best predictive model our best
predictive model shows that that
temperatures are at best stabilizing
then the next few years
it's still going way higher than the
anomaly but more or less it's
stabilizing which is not a bad thing
actually so this is basically creating a
prediction from a single point of data
at least for the short term this
predictive model is predicting a short
at doing a short term prediction and
Sharon gets stabilizing we can build
other models that show more of a long
term prediction and it will show one of
the predictive models that we had in
here like the yellow or red one these
are more of long term
Asians but this is just doing regression
with one feature we were just looking at
temperatures and trying to predict we
are they going usually you need you need
more features so if you know of anything
that can affect temperature you can add
it into your predictive model to have a
more informed predictive model so for
the purposes of this I will be doing
forecast for three more features or
three more series of numbers I'll be
looking at co2 level ch4 level and
totals and radiance set ESI this data is
from the following sources co2 and ch4
dataset are from NO Double A it's a
federal agency that provides
environmental data sets and for total
center audience we get this dataset from
the University of Colorado and it's one
of their projects it's called source and
they're basically collecting the
information about Sun activity in here
I'm defining a function that returns
correlation basically between two series
of numbers I will be using this function
later to major what's more correlated to
what we want to predict which is
temperatures so let's start with the TSI
totals and radians and here we can see
our totals and radius data I added the
I added different axis for that so the
one on the right is the TSI axis and the
one on the left is for the temperature
anomaly we can see some interesting
pattern going on here
you can see a short-term pattern and you
can see kind of a long-term pattern the
correlation between this data and the
temperature data is 35.2% this is not
really a high correlation but we know
most of the temperature most of the heat
on earth is coming from the Sun it's I
think it was like a mostly Sun activity
and barely any nuclear or nuclear decay
activity from heavier metal heavier
metals and earth basically so we can see
the general trend in this data going
going to some level with the temperature
anomaly but it's kind of a moving away
somewhere around 1970 in here would
listed this more in a minute let's look
at our other two features first we have
co2 levels this is in parts parts per
million so we can see almost an
exponential line in here if it's fairly
exponential the correlation between co2
and oh sorry
this is co2 action
so to the correlation between co2 and
temperature anomaly is fairly high it's
91% actually the the other feature that
we'll be looking at is ch4 which is
methane we can see also the correlation
between between ch4 sorry
search for between ch4 and temperature
anomaly is 80.6% which is also fairly
high you can see little bumps in here
with matching little bumps in there you
can see this is almost going with that
as it stabilizes temperatures go down as
it stabilizes temperature go down this
is fairly correlated to temperatures we
know ch4 and co2 are both greenhouse
gases so this is why we're studying them
when we are looking at temperatures so
we'll be forecasting all of those will
be forecasting TSI co2 levels and ch4
levels one last thing about ch4 this is
parts per billion not parts per million
like co2 so the numbers might look
higher in here but it's actually much
lower than this this is fair almost two
actually or 1.9 and parts per million
anyway I will live will be forecasting
all of that so we'll start by doing a
couple of grid searches for TSI to find
the long term and the short term
FET or our predictive model for this and
now will visualize both of those this is
our TSI data and - the gray and we can
see our short-term model in green I'm
going doing the same wave and predicting
basically the wave to keep going the way
it is so and we have our long-term trend
or long-term prediction and it has a
much longer wavelength if you want to
call it that
so we'll be looking at those wavelengths
we have our long-term wavelengths
equaling 182 years so the Sun goes from
high to low to high again in hundred and
eighty-two years and it goes and this
shorter cycle every fourteen years from
high - from high peak to the second high
peak it takes 14 years to do that
that's all approximately because I don't
have enough data to get a more accurate
number so this is why it's approximately
and those numbers then will be
predicting co2 levels we have more
testing long range of gamma numbers to
see what is the best predictive model
for that and this is our best predictive
model so by sometime
the 18 that 2024 it will be very fairly
close to 420 parts per million
it might go beyond that if we looked at
a shorter a longer time frame for
prediction but it's clearly not a linear
I think it's it's going a little bit
exponential if I can just judge it
visually which is totally wrong but
anyway finally we'll be doing a
predictive model for ch4 we're studying
also a variety of parameters to see the
best fit for that and finally we're
plotting that and we can see our data
and - the gray and our prediction and
blue and it's predicting that it will
still go up for the next few years then
stabilize then kind of stabilize and
maybe go out from lower which is which
is a good thing actually but it's still
going up for the next few years just
based on this prediction and thank you
for watching this is the end of lesson 3
for any questions please leave them on
YouTube as a comment you can tweet at me
or you can leave it in Google+ you'll
find the links to those in the
description box below this is a link to
the previous lesson and twas an
introduction to machine learning and it
covered also classification and the next
lesson we'll be talking about clustering
and so we will be talking about why do
we use a clustering finding centroid and
k-means algorithm thank you for watching
and see you next time
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>