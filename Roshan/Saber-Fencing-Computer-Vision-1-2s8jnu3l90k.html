<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Saber Fencing - Computer Vision #1 | Coder Coacher - Coaching Coders</title><meta content="Saber Fencing - Computer Vision #1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Roshan/">Roshan</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Saber Fencing - Computer Vision #1</b></h2><h5 class="post__date">2015-02-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2s8jnu3l90k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone I've been working on this
contest for a computer vision and it's a
contest to create Sabre fencing
analytics system basically that uses
computer vision to do that so it uses
data from camera to analyze the game
basically I took permission from the
contest order to share my some of my
work with you on the channel and I get
permission from him to do that so here
we go we're creating an automated
referring gas system for sale
referencing if you're like me and you
didn't know what Sabre fencing before
today it's like sword game where you
basically touch the other player on
their upper body so waist up basically
whenever you touch the other player you
have a light that will shine basically
and you will can tell that you scored
the point if your light is on but in
this case it's complicated because both
of their lights are on so let's look at
the basic rules you score a point once
your Sabre touches the other players
upper body if both players hit within
120 milliseconds of each other the
player with the right of way gets the
point the right way is a very
complicated concept but in simpler terms
it's the attacker gets the point
basically deciding who has the
right-of-way severe complicated process
and I don't completely understand it but
if both players at the attack at the
same time and hit each other within 120
milliseconds nope
point is awarded tonight neither of the
neither of them so basically if they
just if they attack together at the same
time they started the attack at the same
time and they hit each other at the same
time no one gets a point there are more
rules this is a long list of rules for
referees basically you can find more
information about it then you'll find
links to fit singando kapadia facing
roads on wikipedia international facing
federation and finally seen the sydney
saber the goal here is to create a
system that can detect scoring points
and keep track of them so it will keep
track of the result and detect scoring
points basically so what are we doing in
here exactly we're building a proof
concept not the final system so we're
building we shouldn't care much about
how it looks now but it should do enough
well job so does our knowledge of Sabre
fencing could could that affect our
ability to do the system in the mortal
war is actually of true Conway I present
data science Venn diagram it's a simple
diagram for that science to explain to
you where are you from on your project
basically so hacking skills these are
programming skills these are data mining
skills knowing about where to get the
data how to process it things like that
mathematical and sign
statistical knowledge and that's what
you learn in the math class versus a
statistics class basically and so if you
have both of these you have you have the
machine learning skills but if you have
a substantive experience so let's assume
for example your doctor if you learn
some hacking skills like computer skills
programming at things like this you're
in a danger zone because you don't have
mathematical and statistical knowledge
it's a danger zone because you might do
really you might get wrong results
basically and you want know it if you
don't have mathematical statistical
knowledge so where are we on this
project we have mathematical skill
knowledge and we have hacking skills so
we're in the machine learning and the
more we will learn about sigh Sabre
fencing throughout the project I hope
we'll get closer and closer to that
assigns doing that science of this
project so what's the approach will
start by feature extraction will track
the lights the two lights on the players
the red light and the green light in
some situations the lights are fixed
they're not on the player we will do
some OC our optical character
recognition so basically we'll be
reading the names of the player and the
score and the round things like that
we'll be tracking player location over
time so we know where is the player over
time then we have some pre-processing
we'll be splitting the game in two
rounds using OCR on the score so never
the score changes it will split the
video there because these are rounds
then it will split these rounds into
bouts or segments so sometimes two
players will attack and none of them
will get a point and they will go back
to their
original place and they would have a
second bout so these of both of these
bouts will be detected as a single round
in here but then we would have to split
these rounds into doubts if they if they
have multiple abouts they might have
just a one about in there would be doing
image processing a computer vision will
do US air for the scoring player name
will be doing motion tracking for
location of red and left players and
we'll be doing template matching to
detect red light and green light we'll
be doing some machine learning features
from player players motion and and
features from the light which fight his
own and if its owner of the results of
each segment or about is the result that
we want to predict basically and our
machine learning predictive model with
the computer vision and image processing
will be working mainly with the opencv
and socket image opencv is a computer
vision library and it has capabilities
process video and extract frames socket
image on the other hand is an image
processing library that might come in
handy for some advanced image processing
i'm importing all kinds of libraries in
here numpy pandas matlab cv2 is this is
opencv library that will be mainly
working with and this is socket image
scale image so let's let's run this
actually so we'll import all the
libraries and then we'll open the video
open the video with them a video capture
creating a video capture object and we
will pass this
video to it I have this video here
locally and they will not be sharing it
but you can feel free to get any other
with you that you have in your machine
to practice with we will check after
that if the if it's if it loaded the
video using is open a function that
returns true or false if the video is
open or not and the did not print unable
to prefer to open reduced that means the
video is working so let's start by
retrieving one frame from this video we
can do that with the function read so we
get our video capture object the treat
and it returns two variables the image
and a boolean telling us if it worked or
not if they're if it's red the frame or
not and finally we'll be using
matplotlib that I am show to display
that image and it did display this white
image because the video has some intro
with white screen so we can do this few
more times just to check that you can
and you can see things moving into the
screen by the way I'm executing the same
field without moving to the next one
with with ctrl + Enter so in here I'll
just read 30 frames basically in a loop
then I will show the next frame and we
can see that we loaded this image of the
actual game the first thing we can
notice the image the colors are off and
this is because opencv uses
BGR blue green red color scheme as
default but almost every other library
including Matlock lab uses RGB as
default so opencv can convert to many
many color schemes including to RGB so
we'll be doing that with the CV to that
CVT color convert color you pass your
image to it and a converter basically
here i'm using the b pgr to RGB
converter and i'm storing my result in
damage underscore RGB so let's do that
and we can see the colors are correct
now and will be inspecting the
properties of the video capture object
to do that we use get function then we
pass a property ID these properties are
represented by integers so this is 0 1 2
3 and you can pass any of these numbers
but in here I define the small
dictionary so we can find our objects in
an easier way so let's execute this did
I yeah and i will use cap that get to
get POS frames so the position of our
current frame and it tells us that we're
in frame 140 we can display all of these
values and you can see posm milliseconds
that shows us how many milliseconds for
our current position POS frames this is
our current frame POS avi ratio
and this is our ratio from the total so
0 is the beginning and one is the end
and so we're at four percent basically
frame width and frame height so it's 720
x 1280 friends per second 25 for cc
that's code it's a four letter code for
our encoding or codec frame count this
is the complete frame count of this
video we have other things but they did
not they're not threaten basically in
the header of this file so we don't have
results for them so for CC this is that
all this four digit identifier for the
codec so let's this is a little function
i wrote in here that reads basically
this number converts it into hexadecimal
and converts it back into the four
letters that represent this psychotic so
it's every c1 which is basically mp4
format from Apple so will we want to see
the video length and current position I
wrote this little function here that
does that it gets the frames per second
and gets our current position and total
length of the video and it shows us
where we are so we are at five seconds
and point six and if we say in here
false not correct position that will
shows the complete length of the video
which is five minutes 44 seconds so to
show this image in a better way I
I will be configuring matplotlib a
little bit more to show the show a
better image basically i'm getting the
heightened and width of video adjusting
the figure size then i'm reading a frame
and converting the color it's all things
that we already covered then i'm showing
the frame basically the one thing that
you did not see before is instead of
looping over the frames with read and
here i'm using set so I'm sitting frame
position to the frame past and
dysfunction so to get frame 130 I just
pass frame 130 and I get the frame I can
change this frame to another one but
let's do something even nicer in here
i'm calculating the total number of
frames and i'm using a widget in here to
browse through frames from 130 to 500 so
i can just slide this and it will
show us the video so basically in here
both of them they touch at the same time
you can just scroll back view frames to
show that and here they both hit at the
same time and no one scored a point
because of that so you can see the both
of their lights are on at the same time
let me get the first yeah they hit each
other so the right player hit first 245
just two major a single frame just to
tell you how long a single frame
represent that represents in this video
for 40 milliseconds so we can see that
that's basically between them is only 40
milliseconds between the first light was
on on the second light so so this light
is on then this is 40 milliseconds 80
milliseconds and the other light was on
so that's less than 120 milliseconds I
hope you like this and it's available on
github and it's viewable on mb viewer
feel free to use this source code for
any computer vision work that you might
be doing I hope if you like this you
will subscribe to this channel and if
you're feeling a little left behind
because of the programming you can go
and watch a series about ipython where I
cover a lot of the basics or you can
watch the next part of this series where
we will be building and OCR basically to
read the score thank you for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>