<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Web Scraping - Data Mining #1 | Coder Coacher - Coaching Coders</title><meta content="Web Scraping - Data Mining #1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Roshan/">Roshan</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Web Scraping - Data Mining #1</b></h2><h5 class="post__date">2014-10-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wT66i7jeyL8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone and welcome to the series
about data mining this is part one and
it's about web scraping web scraping is
one of the most common methods of
collecting data although most people
consider it a last resort it's still one
of them most commonly used methods of
data mining actually I will be using
Alexia metal library this is the link to
it where you can find more information
about this library I'll be importing
this library pandas numpy and Matt lost
Lipe finally I'm configuring pandas for
maximum of 50 columns the data and data
source that we'll be working with that
would be working with the Nobel Prize
the data I'll be getting this data from
Wikipedia this is the page that we'll be
working with
that's the page and this is the table
that we want to scrape and get
information from
so before you use web scraping read the
Terms of Service of that website some
websites don't allow any web scraping
some allow moderate use only for
Wikipedia I've looked up their terms of
services and generally they don't allow
automated use if it's abusive or
destructive of their service so I would
argue web scraping a single page
wouldn't be a problem this a very clear
disclaimer I'm not a lawyer but some
basic rules of the web scraping check if
there is an API and use it it will make
your life easier
don't use web scraping too much in a
short time so don't make a lot of
requests to a single server in a very
short time it will slow down that server
it might get you banned from the web
site and never scrape anything that is
not public so if you reach a document
that's not supposed to be public you're
not supposed to get any data from there
I think that's clear but lastly check
robots.txt II usually it it guides you
to how to use their website in an
automated fashion and so let's start by
fixing our HTML page and building and
building the HTML tree and here I'm
defining a function that just previews a
HTML element so I fetched my URL and I
converted that into an HTML tree and
this is my first element which is the
main HTML tag of the page these are the
tributes of that tag and itch in here it
just shows the first 200 letters from
the page the first thing we want to do
is locate that table so if you will go
down in here you will see this table
that we want to a scrape and if you're
using Firefox right click on it and
inspect element and you will be able to
interactively check your code and you
can go back to your table tag and we can
see that there is no ID so it's not easy
to identify the table but it has class
wiki table sortable and jquery table
sorter so that is what we know about
this table so let's start by getting all
the tables in that page to get tables
I'm referring to I'm using XPath
function and requesting all tables the
two forward slashes means look
everywhere in the document so not only
children or so if you're anywhere in the
document this will look even in parent
nodes and child nodes so I'm finding I'm
printing get all the tables that I found
so I have one two three four five six
tables yes sorry
three two five tables this is a long
table actually I have five tables in
here and I can see that the first one is
disabled that I want obviously the
others are just styling or something
like this so we can get the first table
in this list
but let's see how can we locate it using
a class imagine if we have if we had
more tables with the similar multiple
tables with the same classes this is an
easy way to get one of them or all of
them so in here I'm selecting table
again and I'm selecting attribute class
equals week table and sortable which is
what's written here there is an
important thing to notice this table has
two classes and this table had three
classes and this table had three classes
jQuery two table sorter and this last if
you selected this and searched for it
you wouldn't find it in the code because
this last table is added on the
client-side using javascript so web
scraping doesn't execute any JavaScript
within the code it receives so it will
not add that extra CSS class so this is
one thing you have to watch out for if
you want to disable JavaScript to see
the page as your web scrubber will see
it if you're using Firefox go to about
colon config scroll down to script
JavaScript that enabled and toggle it if
you toggle that and go back to your page
and refresh you will see that you lost a
lot of JavaScript things but if you
inspect your code now you will find only
the two classes that were enabled that
existed in the code that we get from web
scraping so let's toggle that back and
let's close this
so that's that's an important note about
classes or sometimes they will be added
on client side so you will have to check
the code some other page sometimes
without JavaScript enabled so let's get
that and in here I'm referring to the
first one even if you have only one
result coming back from XPath it would
always return as a list so in here I
just want the first item which is this
table first I'll start by extracting
gears so in here I'm looking for XPath
TR which is which are the rows and then
I'm getting the text content of these
rows so I'm extracting all these
subjects of the first row except for the
first column if you will look in here
this is the first row that we want to
scrape now we don't want the first
column we just want physics chemistry
and the rest of them so and here I'm I'm
skipping the first one and going through
the first row and if I execute that I
get all the subjects in here I'm
replacing n with space because I have I
have a line breaker between those two
words so I had to replace that line
breaker with a space so it looks like
this and then I will get all the years
I'm using XPath TR I'm skipping the
first and last rows and I'm getting all
the
other roles basically I'm getting the
first column of all rows except the
first one and the last one and this is
why I want to get the first column of
all rows except the first one the one
with the title and in this special table
if you look down you'll find the last
column also has the same titles so you'd
have to skip the first and last one and
I will execute that now I will be
extracting winners data and so I'm going
over the same table with the expert and
TR that's four rows and I'm just looking
at the first row so with the first year
they distributed prizes so I'm looking
at this row now so I'm extracting the
subject sorry I'm getting the subject so
I know which column um and then in each
cell I'm extracting a class in here so
let me just show you how does that look
I will inspect one of the winners and
you can see inside that row starting
from the second column we have a a span
called
the cart with a class v card then there
is another span inside it then there is
a link inside that so what we are
reading we reading the title as the name
of the winner and the the link to his
page so we can maybe extract more
information about him later
so this is exactly what I'm doing here
I'm getting spam Vick vCard as a class
then spanned an a and I'm extracting the
attribute title and the attribute href
which is the link let me execute that
and this is only for the first year this
is just to demonstrate it so I'm
printing everything in physics in
chemistry and it can shows me that who
get prizes and each different subject
that here so I will be doing that over
the complete table and here I'm a
numerating over years and the inside
table is the inside loop is exactly the
same as this one so let me do that and
for post-processing will be using pandas
I will be I'm defining a data frame in
here I'm passing the winners names and
calling the column winner name then I'm
adding the subject they get the prize in
the year and then I'm converting the
year into an integer because it's a
string because it came from an HTML page
that's a string then I'm adding a column
for they are finally I'm showing just
the top five records in here so I can
see the winner's name subject here and
relative URL to his page on Wikipedia
looking at the data so in here I'm using
values value counts to get how many
prizes
how many people get prizes in different
ears so I have another series in here
now with years and how many prizes were
distributed every year or given every
year or how many people actually want
prizes that here the number of prizes
per year
I'm just plotting the number of prizes
per year
so we can see it went a little down and
then it went up after that overall they
have given 853 prizes and here we can
see that only few years they gave one or
two prizes most of the years are in here
between five and seven and we can see
there is like a shift in here so this is
how many prizes they gave over the years
now I will be analyzing that by subject
so in here I'm using cumulative sum for
the values so for each subject I'm
plotting a line with cumulative sum so
this is the amount of prizes giving for
Physiology or medicine since the prize
started and this is the case for all
other lines in here we can see the old
started kinda together and there is a
little diversion in here where Peace
Prizes are less given literature is
almost linear chemistry is trailing
behind physics and
on the top Physiology or medicine we can
see there is a little shift in here
actually also I think it physics prizes
who are giving more than anything else
and there is a little switch around 1945
checking the effect of World War one and
World War two I'm plotting the same
chart but I'm plotting everything only
before 1950 and I'm adding two
rectangles in here to cover the area of
World War one and two and I'm annotating
this text in here WWI and WWII for World
War two so we can see that they're all
going the same piece no Peace Prizes
during the war going up again no Peace
Prizes during the Second World War you
can see a spike in Physiology or
medicine
by almost the second half of the war so
that's the tutorial this is available
open source on github and it's viewable
on mb viewer the link to this isn't that
description below and I hope if you
would like this you will subscribe to
this channel and you can watch another
series about ipython notebooks and this
is the first part of it or you can watch
the next part of this series and it will
be about YouTube data API thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>