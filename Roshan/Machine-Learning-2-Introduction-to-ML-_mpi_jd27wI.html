<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning 2 - Introduction to ML | Coder Coacher - Coaching Coders</title><meta content="Machine Learning 2 - Introduction to ML - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Roshan/">Roshan</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning 2 - Introduction to ML</b></h2><h5 class="post__date">2017-01-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_mpi_jd27wI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone I will start this listen
with a quick prediction I'm defining a
person in here who's 25 years old
bachelor degree studies for 14 years
works 40 hours a week never married from
the United States works in sales white
nothing family is a male and works in
private sector this is based on data
from 1994 so this might not reflect the
marketplace today but I will try to make
a prediction whether he makes more or
less than $50,000 a year it tells us
that he makes less than $50,000 a year
let's look at the same guy ten years
later when he was 35 he still works the
same 40 hours bachelor degree same
occupation same everything let's see
what happens in 10 years now he makes
more than $50,000 a year if we changed
the race his race to black we can see
that he makes less than $50,000 a year
what if he was working 45 hours a week
now he makes more than $50,000 a year
but if there was a female makes less
than $50,000 a year
let's try to make that 50 hours still
less than fifty thousand let's make that
fifty five hours a week now she can make
more than $50,000 this might look like
very bad results or might not sound like
good results to everyone but this is
just based on census data from 1994 so
this is lesson 2 of machine learning
series and it's an introduction to
machine learning
you have not seen part 1 we discuss
Python ipython notebooks matplotlib
numpy pandas and Amazon Web Services in
this lesson we'll be replicating the
results that we have just seen in our
quick prediction system we will
machine-learning uses regression
clustering and classification as basic
tools to emulate learning and do
predictions so let's go to Amazon Web
Services and let's go to our management
console you can go to Amazon Web
Services AWS that amazon.com if you
don't have an account open one that's
three and everything that we will be
using this lesson will be free so it can
replicate everything we do without
paying anything to Amazon Web Services
will be using services from the free
tier for the purposes of this lesson
let's go to AC to the service that we'll
be using
we will launch a new instance choose
your ami from community aim eyes look
for the one I left public it's called
ipython notebook server actually you can
just go with ipython and hopefully you
won't find anything
besides my public am I select that and
that's taking the Sabbats a lot
that's taking more than usual to go to
actually let's go okay okay
select again choose the micro instance
this is within the freight here you can
choose something bigger if you want that
will make your system a little faster
next we can just go to review on launch
once you're in review and launch go down
to security groups edit security groups
and open the extra reports that we need
to manage the system 8080 and 8000
review on launch
then click launch if you don't have a
key
create a new one and save it somewhere
safe I will use the key I already
created before
it's launching my instance now
you can see that I have tried to record
this lesson earlier that did not go well
so the first thing we do we name our
instance I will just call it listen 0 2
so I can tell it from the other one and
it's initializing now we can access it
from the public IP so we'll clap with
the public IP and we'll go to it colon
8080 that will take us to a Python
notebook server once we're there we'll
put the password the default password is
our Oh sha and Russia and our Oh sha and
go to listen to introduction to machine
learning this might take few seconds to
load it's a big not work so and this
lesson we will learn about scikit-learn
we will learn how to choose which type
of algorithm to use and we will learn
about some public data sets that you can
use to experiment and learn with then we
will be talking will be replicating the
classification example that we have seen
in the beginning of this lesson
one important tool that we always need
is urgently it's our administration
interface we will open this link and we
will paste our IP in the place of the
word IP
it will tell us that it's not signed
certificate that's okay
we're not verified certificate because
that's self signed user name and
password the user name is wrote and the
password is a dmin
admin don't want it to remember thank
you thank you okay we will be using this
tool mainly to monitor our memory usage
during this lesson so we want to keep an
eye on memory usage we want to make sure
we don't go beyond our memory if we
exceeded the memory we'll start using
swap and that would be a very big no-no
and any machine learning application you
always want to use only memory so let's
go back to the listen scikit-learn
scikit-learn it's a machine learning
library written in Python at simple
efficient that has tools for data mining
and data analysis so machine learning
uses three types of algorithms depending
on the problem that you have in hand we
have clustering clustering is used to
group data into groups according to
their similarities so in here we had
black dots all over the place and a
clustering algorithm and decide
predicted that these orange points
belong to one group red points belong to
another group and red and green points
too and green points belong to a third
one it could not cluster the rest of
those black
the screen classification and here we
have black data points and white data
points and the algorithm made a decision
function that will tell if a new that
point will be considered black or white
without knowing if it's black or white
just depending on where does it fall on
this chart so if it came anywhere in
here it's a black data point anywhere in
here it will be a white data point
that's that's another way to do the same
problem to classify the same problem
with different weights for the algorithm
the third thing that we'll be dealing
with is regression and here we have a
few data points the red data points the
algorithm will try to fit a line that
goes through them and it will predict
where does this word where it does it
think this might go and it will show you
according to the algorithm that you're
using an area of confidence so this is
an area of confidence that it might
proceed to anything within this area
this is a little chart that shows us
which algorithm to use it doesn't have
every algorithm and scikit-learn but
it's a very good place to start if you
don't know if you don't know which
algorithm to use so it will ask you
first you have more than 50 samples no
go get more data figure predicting
category or a quantity if you're just
looking at data if it's labeled data or
not you will it will lead you to some
algorithm that you can use if it's text
data or not
and it will help you choose an algorithm
again it doesn't have every algorithm in
the system but it's a very good place to
start data sets you need data sets to
work with the machine learning this is
these are some data sets to get you
started this is an archive it's a public
archive for machine learning and this is
the scikit-learn data sets that's public
so inside each data set you will find
samples which represent records so if
data sample is about people each sample
will be one person and it will have
features or attributes and those
features represent a feature about that
person might be age it might be income
or something else so let's examine some
data we will be working with this data
set from from UCI and this data set is
40,000 48,000 records more than 48,000
records it has 14 attributes here is
some information about it these are
papers that cited this data set you can
see a very long list of papers that
cited this data set and we can go to
data folder and and here we will see the
file that has the actual data this is
the file that has the actual data that
we'll be dealing with and we can either
download this file into our machine and
upload it through a gentie to our data
folder or we can fetch it directly over
the internet so let's go back to our
lesson this data I I copied the
description of each column and the data
set this is small sample of the data set
so you can see for example this person
is 39 years old works for state
government
this is his weighted demographic number
Bachelor degree studies 48 13 years
never married admin clerk oh nothing
family white male this is capital gain
capital loss works for 40 hours a week
from United States he makes less than 50
thousand dollars a year so we will start
to build that example that we have just
seen the predictive model for
classification that classifies if people
make more or less than $50,000 so we
will execute the first pod sell to and
port our libraries to execute any sell
any code sell click in the cell and hit
shift and enter and once you see the
number appears in here
this means it finished processing this
data so second thing we will do will
load data so we can fetch it directly
from the URL or use the path for this
file you can upload the file download it
to your system and upload it to the data
folder and using agent e and here I just
named the columns because in the data
set it doesn't mention the columns the
column names within the data set so I
have the column names in here and I'm
using pandas to read comma separated
value this is the method that reads come
separated value files to know how does
this method work or works you can go
inside the method and hit
shift tab and this will show us this
little interesting hit again that will
show us this little interesting help box
we can expand it and see these are all
parameters that you can pass to rate
comma separated value and it will help
you read the file in the right format so
we will be fetching it directly from the
URL second thing we notice about file
the separator is not just comma it's
comma then space so we will use the
parameter for separator to do that I
will pause the video and I will be back
the second parameter is names and here
we pass a list with column names for the
comma separated value file because this
comma separated value file doesn't come
with headers in the file the last
parameter we're using is in rows which
is number of rows we're limiting that to
20,000 because of the limited amount of
memory we have in our instance so let's
run that again to execute shift and
enter we will do some math statistical
analysis of our American features we
have aged between 18 and 90s as a
weighted identifier of demographic or
something like this I read the
description I couldn't get exactly what
does it do
education numbers the number number of
years people studied so around the 50%
is 10 years capital gain almost no one
made any money and capital lost almost
no one lost any money hours per week
this is how many hours per week people
work and we can see very clearly that
almost everyone is working around 40 to
45 hours a week so this is how we can
describe our data
always remember that your data is stored
in this variable CSV underscore data
visual inspection
this is scatter matrix of all the
features
i pre excuse code cell say so you don't
have to do that it will take a few
minutes if you try to do it again so I
executed that before I started the
citizen and in your instance you will
find the executed version with the chart
the chart basically lists all numerical
features age weighted demographic
education number capital gain capital
loss and hours per week and it plots all
of that or scatters all of that against
the same features and whenever the
features the feature is scattered
against itself so how is per week with
hours per week it gives a histogram of
that feature so it can very clearly tell
that everyone works 40 hours a week
there is a little bump around 50 and a
smaller one around 60 capital gain and
loss we can see that it's there is no
there is no data there because almost
everyone made 0 this is education number
so how many years people studied we can
tell that almost everyone studied 9
years then 10 those are the highest
values then we have a little bump around
here which is 13 years so 13 years 14 15
and 16 finally and here
I don't understand this feature so I
wouldn't try to explain it this is age
this is just a histogram of age we can
tell that almost everyone is in this
range and it drops rapidly after that
which is around 45 years of age so we
will visualize some data we will scatter
again to get the little help box for any
method like scatter method we hit Shift
+ tab and we get this help box or help
undo we can see that we should pass an x
and y then we can put colors their
markers color map with there are a lot
of features that we will be using alpha
will be using that too
this is transparency level for colors so
we'll be using that too so we're
scattering X which is the education
number which is how many years that
someone study against age so our Y will
be age and our X will be numbers number
of education years and here we're doing
get little filter so whenever we want to
filter our data we pass one of our
columns so we pass income and equals
equals to any value which is more than
50k that will filter only people with
more than fifty thousand in annual
income
we're using elf of two percent so it's
only showing two percent of the color
which is 98 percent transparent we're
putting a label there so we can identify
it and using red color for people with
higher than fifty thousand we're doing
the same thing for people with income
less than fifty thousand and were
scattering them in blue color we're
showing legend and finder method which
shows actually the chart and this is our
chart we can tell that more people have
studied like sixteen years or most
probably will be making money since the
beginning of their career people of the
fifteen years around the same time but
maybe a little later people around
fourteen years well there is a still a
very high chance that they would be
making more than fifty thousand thirteen
years around their end of their career
they would most probably be making more
than that we can tell that there aren't
much people who studied eleven or twelve
years
mmm ten nine we can see that people who
stayed until they're well around sixty
when they actually made more than fifty
thousand and we can tell that almost no
one before that time is making good
money but there aren't much people in
that bracket anyway you can see the
faint colors which tell us the density
of people in here the problem with this
chart everything is scattered on one
line because no one studied like nine
and a half years or nine point three or
nine point one or eight point nine so
everything is scattered on one line so
to take care of that
we add a random value of 0.5 minus 0.5
to 0.5 which scatters this line within a
range and it never goes to the next
range because it scatters only between
minus 5 and plus 5 so to do that we add
numpy random uniform minus 5 to minus
0.5 to plus 0.5 and we will generate an
array that's similar in length to our
data set so we're getting the length of
our data set and passing that as a
parameter so it will generate random
lists of numbers between minus 0.5 to
0.5 and the length of that array will be
our list will be the length of our data
and we're adding that to education num
which is the number of years they
studied and we're storing the result of
that in education num underscore R and D
for random to differentiate this feature
we're plotting on a bigger chart that's
12 by 8 that's a big chart we're doing
basically the same thing in here and in
here but we are changing the Alpha value
to 2 in / - 10 % so points will be more
clear in here we can see in the legend
we can barely see anything if you don't
have the very good contrast in your
screen you want to be even seeing the
faintest dots because it's only because
it's not yet percent transparent and
here it will be 90% transparent so it
will be fairly visible after that I'm
adjusting x-axis and y-axis by adding
labels to them and adjusting takes and
limit and finally I'm putting a grid and
title on the chart and after that I'm
dropping the feature that we calculated
the random number so we get back to our
original that is it let's plot this and
see what we get
that might take few seconds to process
because it's a big chart and we can see
way more information than our original
chart we can see the trend in here where
the more people spend in studying the
letter they enter the market where we
see people entering the market around
their thirties who studied around 16
years we can see a dense area in here
which shows that some people are
actually working part-time at a very
young age around let's say 18 or 17 and
we can see this very large blue area
which is around nine years where no one
almost no one is making more than fifty
thousand ten years people above fifty
are they do have a good chance of making
more than fifty thousand there isn't
much people in this area we can clearly
see that now and we can see a dense area
around thirteen years or more people are
making more than fifty thousand after a
few years of their career after almost
less than ten years of their career they
have a good chance of making more than
fifty thousand fourteen fifteen or
sixteen we can see it getting redder and
redder and the the threshold for where
they can start making more than fifty
thousand is down to their the beginning
of their career basically we can see the
dense area going like this
almost where this area is the high
income
area of our chart processing Jetix
features you can process text features
to convert them to numbers and this is
what we our binary like 0 and 1 which
are still numbers but you need to
process your text features and convert
them to number somehow to make them
machine learning compatible the way to
do that you can you can vectorize 0 data
which says for example if you have three
people if you have 3 cities like London
New York Toronto and this will this is
would be there your users location you
can vectorize those features to a
feature with true or false and it just
says for example he lives in London so
if someone lives in London they would
have one there and a second feature will
be lives in New York a third feature
will be lives in Toronto for someone who
lives in London he will get four the
first feature 1 0 4 second feature and 0
for the third feature if you have there
another way is to convert it to a series
of number representing their original
value so sometimes you'll get results
like excellent good average bad terrible
you can easily convert that to 5 4 3 2 1
which would still keep the original
meaning of data with the text document
use count vectorizer it's a way to
process big documents big text documents
we will go through that in a later
lesson and finally have special values
sometimes you have emails URL phone
number username
and you have to process some of those
with special treatment for example for a
URL you want to fetch that page and
process the content of that page using
text processing but you still want to
see if there is an image there it might
be a link to an image it might be a link
to a social media page where you want to
know who owns that page and store that
information too and so depending on what
do you want to do with the data you
might need to do special treatment for
those special values we will we'll
proceed with this data now we'll have
vectorizer our data but we will the
first thing we will do we will drop an A
which drops not available to record so
and record with nulls or blank data it
will be dropped
then it's dropping few columns capital
gain capital loss income income because
it's the result that we want to predict
and the weighted demographic and we're
dropping those three features because
they are not machine learning useful to
us
because there is almost no data on those
two and this one is it has a very large
range and I'm not really sure that it
represent anything that can be related
to the result that we want to calculate
finally I'm converting that to a dict
which is a dictionary and the output
type is record so it will create a list
of dictionaries each dictionary has all
the values in a single
and finally it's converting that to an
array I'm adding an extra column sorry
I'm adding a new value called results
and it equals two comma separated value
of income which is this column of comma
separated value data equals equals more
than 50k so to compare more than 50k to
each value in here and if it's equal to
it it will return true if it's not it
will return false and it will store this
list of truths and false true and false
results in a variable called results
actually now we split data into training
and testing set so we have 20,000
records we will be training with all our
records except the first except for the
first thousand so we go thousand column
and if you leave that empty it will use
the rest of that list for features which
is the vectorized features from our
comma separated value data a second we
have results and we're getting all the
results except the first 1000 for our
test data were using the first 1000 so
we go empty : 1000 so it will start from
the beginning and stops at 1000 and the
same thing with results let's see just
one of the records just to which to
visualize that and understand how this
look it's a dictionary with all the
features inside it and that is what's
passed to the vectorizer that
converts all those text text or string
features and two numbers basically into
binary numbers will track a
classification model using KNN instead
of trying to learn what does this
algorithm do exactly it's much better
just to see the results learn other
algorithms and try to basically develop
experience in choosing the right
algorithm with time it's oh sorry we did
not process this one yet
we should execute this one first then we
go back to this one and execute it so we
have a variable called KN n now that has
a an on neighbor classifier and it's
fitted with the extraneous and white
training sets which are which is the
complete data set except the first
thousand records now we want to do a
prediction so will predict our X test
then compare our prediction to whitest
and that would be our accuracy so let's
test that find it I'm printing just the
first ten predictions and I'm printing
the prediction itself and I'm prediction
predicting the printing the prediction
equals the actual data so it will tell
us if it's correct prediction or not so
we can visualize at least ten of the
results and see how do they look and
here we have a loop I promised to
explain things as we go so for counter
that's how we do loops in Python for
counter in range of ten
that will range of 10 is a method that
would create a list that's like this it
will be 0 1 2 3 4 5 6 7 8 9 and that
would be equal to range 10 but instead
of doing that it's much easier to write
to wrench them so this is done our
accuracy is 81 percent sample data it
predicted that this guy doesn't make
more than 50 that was correct
false correct false correct false
correct true false it predicted this guy
made more than 50 thousand but he didn't
this guy made more than 50 but he didn't
and here it predicted he didn't make
more than 50 and it was true and more it
predicted more than 50 and it's true
less than 50 and it was false he
actually made more than 50 true and it's
true so him prediction is more than 50
and the actual was more than 50 we will
see better reports now once we're trying
to improve our accuracy so and to
improve our accuracy there are a couple
of the parameters inside this classifier
one of them is the number of neighbors
that it will use so in neighbors and the
other one is the weights method so it
has two weights method one called
uniform and the others called distance
and we will so we will be looping over
range from 1 to 15 and we will be
looping inside of that with uniform and
distance and we are passing the value of
the first loop and the value from second
loop to the parameter to test different
values so we'll be testing all values
from 1 to 15 for N and we'll be testing
all values
for uniform and distance for each of
those values so let's run that that
might take a little bit of time to run
so that's the first one
neighbors one weight uniform precision
recall if one score and support this is
the standard report that we use to test
the accuracy of classifier support is
the number of samples for each class we
have so the number of samples for less
than 50,000 was 768 and for more than
50,000 was 232 so we can see that we
have way more people making less than
50,000 in this sample the total number
is 1,000
precision is 1 one of our metrics for
measuring the accuracy of classifier and
it's showing the precision for each
class recall is very important we want
to make sure we have high recalled
values that will ensure high accuracy
because recall is not just getting the
correct answer because recall is
calculated by calculating all a true
positives which is like correct
detections divided by correct detections
plus false negatives which is values
that it did not did not it messed
basically so this is recall value want
to make sure we have good recall values
f1 score is another metric all of them
the highest value for all of them is 1
and the last is 0 so we're looking for
values higher
and closer to one this is our first one
it has 79 overall accuracy but this is
the report that we will be looking at
from now on so one uniform good values
we have distance with one it doesn't
really matter but with the more than one
neighbor it will start making a
difference between uniform distance
waiting methods and here we can see
really low recoil value that's still not
really good we can see that we have so
many this is actually this is fairly
good actually the results that we have
for five neighbors is fairly accurate
81% is a good number in here even if
it's a even though it's 83 overall the
actual numbers we have for recall is
really bad so that's not that's not a
model that you want to be working with
well this one's still not really good
that's a good one that's a good prospect
seven with the uniform I think the best
one I found was number 11
yes this is it it's 11 the neighbors
with the uniform weights you can see the
rest of the results you can go through
them you can use a specific one of them
to do some testing some further testing
so we will use this one with 11 and
uniform and we will keep our trained
model using those parameter and care
usually want to put the predictions back
into the original data set if you want
to save that as a file to send it back
to your client or something so that's
how you do that you just then you column
and you put your predictions in there as
planned a series and this is the example
that we started with in the beginning of
this lesson let's run that one last time
just to see more than 50,000 these are
all the values you can use those values
in here to define different people and
see how a changes affect their income
this is a little chart I get from
Wikipedia that will help you if you did
not study in the US to identify how many
years do you need to have different
levels of education so this is education
number this is the end of lesson two if
you have any questions leave them on
this video as a comment or on Twitter or
Google+ thank you for watching and hope
to see you next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>