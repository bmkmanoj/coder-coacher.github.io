<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>G1 Garbage Collector Performance Tuning | Coder Coacher - Coaching Coders</title><meta content="G1 Garbage Collector Performance Tuning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>G1 Garbage Collector Performance Tuning</b></h2><h5 class="post__date">2013-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bhVzCIk3-Q4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well good morning everybody and welcome
to Wednesday morning at JavaOne it's
encouraging to see a good turnout here
this morning for a geeky talk on g1 GC
I'm Charley hunt I'm the performance
architect at salesforce.com I'm also the
lead author of the Java performance book
and on stage with me here is Monica
Beckwith Monica is a JVM performance
engineer at Oracle and Monica is largely
leading the performance effort related
to G 1 GC so I think you're going to
find out over the next 50 to 60 minutes
you're going to get jammed with a lot of
information and we're going to move
pretty quickly we got a lot of slides
here but I think you're going to enjoy
you're going to find useful what you're
going to see hopefully you walk away
from here with enough information and
arm to go back to your offices and be
known as the G 1 GC expert so the
standard safe harbor slide now that I'm
not an Oracle employee you can believe
every word I say just kidding a sort of
course basically what this thing means
to me is if you're making some
purchasing decisions don't make those
purchasing decisions based on what you
hear today okay enough of that stuff so
the program agenda here the first part
of this first half of this session
you're going to hear me talk about
laying the groundwork for why would we
want to use G 1 and give you an overview
how this thing works so we need this
background to understand how do we go
about evaluating G 1 as a GC which is
going to be the second part that Monica
is going to cover and then she's going
to move into how do we do this analysis
of G 1 in other words how do we take
this information that's coming out of
the GC logs figure out what it means and
then if we need to do some tuning what
is that tuning that we need to do so
here's the second part here that Monica
will present so when should we consider
G 1 or Y G 1 what we're looking for a GC
that has a couple of really good
attributes one of those is that it can
operate concurrently with application
threads kind of like what we see in CMS
so CMS
as old generation collection that
operates concurrently and we'd like to
build a compact free space without these
lengthy induce GC pauses so in CMS in
order to compact that old generation
space we have to go through this painful
full GC so we'd like something that
freezes of that sort of issue we'd also
like some more predictable GC pauses and
we'd not like to sacrifice an awful lot
of application performance throughput in
addition to that we'd also not like to
have to throw in an enormous amount of
Java heap at this in order to achieve
our either our throughput goals or our
latency requirements okay so G 1 is open
JDK slow pause low latency garbage
collector it's intended to be the long
place for replacement for CMS was
officially supported in southern update
4 that continuously are making
improvements and updating to it so if
you start an evaluation of of g1 start
with the latest update release because
there's been a lot of changes that
continually being made and you're also
probably seeing a lot of updates coming
recently out of Oracle these days don't
know if that means you're making a lot
of updates to do you want or maybe it's
something else what if you're following
the news you get an idea what that is
anyway so g1 is concurrent so it's got
some concurrent phases to it so
refinement marking and cleanup those
phases in g1 are concurrent so in other
words they run in parallel I should say
at the same time as your application
it's also multi-threaded in other words
it's parallel so the stop the world
pauses in g1 or multi-threaded the one
piece of g1 that's not multi-threaded is
if you get in this edge case where you
need to do a full GC it is currently
single threaded but it is designed in a
sense to avoid full GCS if you're
getting to a full GC you should be doing
some tuning and hopefully that tuning is
very minimal there is an RF e to multi
thread full garbage collections in g1 at
this point it hasn't been implemented
because we haven't seen enough evidence
so
or JVM engineers or Monica hasn't seen
enough evidence to justify it
so the general recommendations of today
as a Java 7 update 6 you know I wrote
this slide about a week ago and I see we
got another update release so it's
actually update seven so you should
consider using G 1 you have a full GC
that's either too long and duration or
they're occurring too frequently and
this is going to be true for both or
whether you're using CMS or whether
you're using parallel GC now if you're
using CMS today and you can run your
application loud experience can full GC
I would suggest you to stay with CMS
because your minor GCS or your uncle GC
times will probably be faster today with
CMS than it would be with g1 the focus
today is BAM thus far with g1 has been
to reduce or eliminate the need for full
GCS as g1 continues to evolve and the
focus starts to shift you'll see that
they will start to address how do we
achieve minor GC times that are
equivalent or better than what we can
see with CMS likewise if you use in
parallel GC today if you're able to
avoid full GCS I would continue to use
parallel GC however in the future as g1
continues to evolve you will expect to
see as I mentioned earlier g1 will
replace CMS it's also likely that the g1
GC framework will eventually replace the
parallel GC so there will be a parallel
GC version or type of implementation
that's built on top of the g1 framework
a little bit of dirty laundry here in
open JDK there's currently three
different GC frameworks and hotspot
wouldn't it be nice if there was only
one so here you can kind understand the
motivation of why g1 is and the g1 GC
framework is is the future for open JDK
SGC ok so what do we need to know about
g1 in order to start our evaluation so
what I'm going to do here over the next
several slides is
I'm going to do a little comparison with
how CMS works and how g1 works I think
most everybody has a sense of how CMS
generally works and we'll see how that
contrasts with what g1 does so
everybody's probably familiar with this
diagram that's on the left-hand side of
the hotspot GCS have this layout of an
Eden and two survivor spaces and a
larger old generation typically so you
have these young generation and old
generation and they're split up the
young generation is split up into Eden
and survivor spaces an old generation is
generally one larger space and in the
case of CMS objects are collected in
place there's no compaction that's not
unless there's a full GC likewise with
parallel GC collections an old
generation don't occur unless there's a
full GC now if we take a look at G 1
essentially G 1 allocates this huge
large area as a Java heap that is then
split up into chunks or regions and the
JVM picks how many regions is going to
be and it tends to target around 2,000
regions in reality what ends up
happening is these regions are then
mapped to a logical notion of Eden and
survivor and old generation so in this
diagram you can see that there's
different colored squares here so what
I've done here is anything that's
colored a light green is a region that's
logically mapped to an Eden space
likewise something that's yellow here is
is mapped to a survivor space and that
blue here mapping to an old generation
space so you still have this notion of
an Eden and a survivor in a literal
generation and they're just a logical
set of regions and the way that g1 works
here is when a collection occurs what
you're doing is you're evacuating or
copying / moving objects from a given
region into another region either you're
copying objects from say an Eden into a
survivor space or you may be moving them
from a survivor space into old
generation or you may be moving
I'm promoting them into a new unused
region so essentially what you're doing
is you're evacuating and releasing this
reach and you're saying okay this is
free to be used for something else so
these regions are designed to be
collected in parallel or with or without
stopping the application threads so
there's portions of these regions that
can be collected while the application
is running when when you are evacuating
you're going to be doing a stop the
world pause so as I mentioned earlier
these regions can be allocated or mapped
to an Eden space a survivor space an old
gen space one I haven't talked about yet
it's a humongous region and an unused
one in other words is currently not
being used by one of these other areas
so humongous regions are basically set
aside and are allocated to hold
humongous objects now humongous object
is basically something that's an object
that's larger than half the region's
eyes and it's a set of contiguous
regions so this is how we deal with very
large object allocations that might be
larger than say your region's eyes an
important point here is collecting
humongous regions to this point has not
been optimized so you should be having
this aha moment that says aha if I got
large objects in my application and I'm
expecting those to be collected in a
timely manner not a good idea
okay so let's see how CMS works and
compare that with how GC works in g1 so
I've got a diagram here it's colored now
from what we saw earlier so a light
green color here is young generation
space and you can see that split between
the eden and the two survivor spaces and
then you see a bunch of this blue color
in this old generation area so this
would be a snapshot of what CMS might
look like as your applications been
running for a while things have been
promoted into old gem things have been
collected you see the sort of scattering
of objects that are sitting around in
this old generation area so a key thing
to understand here again is this D
allocation with CMS in other words the
way objects
collected an old generation is there
de-allocated in place there's no notion
of compacting the space together unless
you're getting this full GC okay so
during a young GC any of these live
objects that are in Eden and survivor
space or then copy to the other survivor
space and there may be some objects that
are promoted into old generation so if I
move to this next slide so this would be
a snapshot of maybe what this heap looks
like after a minor GC or our young GC so
the darker blue color here in old
generation where objects that have been
promoted and the darker green here is
objects that were still live and the
miners after the minor GC and they've
been copied into the two survivor space
okay so let's take a look at how a young
GC works in g1 so again our Java heap is
divided into regions you can see this
designated by the little squares here so
again the blue colored ones here or old
generation regions the light green ones
here are young generation regions so
both the young Jen and the old gen are
merely a set of regions as I mentioned
earlier and they're not required to be
contiguous okay so I've got a couple of
young generation regions here that are
circled and we're going to do a minor GC
so what happens we take any of these
live objects and young generation and we
evacuate those to one or more survivor
regions and some of them may get
promoted into an old generation region
the other thing that happens is we
calculate the size of the Eden size and
survivor size that we're going to use on
the next GC pause so one thing that you
might be thinking about here is well how
do we do that well there's some
accounting information that we keep for
each region and I'll talk a little bit
about that a little bit later so based
on this accounting information we can
get a sense of based on a pause time
target that we've set we think it's
going to take about this much time to do
the next
- ICI or the next youngji see that's how
we determine to figure out how to size
the Eden and survivor space so one thing
to think about here one of these nights
attributes of these regions is it's very
easy to add regions to a given space and
it's very easy to remove them so it's
very easy to do resizing so of course
youngji CSRA stopped the world pause
okay so at the end of a young GC you can
see here that I've changed some coloring
here we've evacuated some of these live
objects into a survivor space so this is
the dark green area and we've also had
some promotions into an old generation
region so that is the dark blue here and
then the thing that's not really shown
here is we don't really have a sense of
whether the Eden or survivors sizes have
been resized I couldn't really figure
out how to do that in this example but
that's a possibility that could occur
so to summarize that a youngji see in g1
we have the single physical heat that
split into regions we have this notion
of humongous regions to deal with these
large objects we don't have this
separate young generation like we saw in
in CMS it's also very easy to resize we
could add or remove regions as we need
them young GCS are multi-threaded
they're a stop the world type of pause
and we evacuate anything that's live
into some other regions okay so now
we're going to shift the saying how do
we collect old generation so we're going
to take a look at CMS here and refresh
ourselves as to how this works in CMS so
the mostly concurrent marking marking
phase and CMS has to stop the world
pauses in it and that is the initial
mark and then a remark so just real
briefly in the way that this works is
you reach some heap occupancy of old
generation it kicks off a concurrent
marking phase this is the initial mark
so it does a short little pause it then
goes into this concurrent marking it
goes through old generation it says okay
this is all of the live stuff and then
it says okay what has changed in between
now and when I kicked off the initial
mark so this is the remark phase and it
goes back and
that and that's a again they stopped the
world pause so after this marking is
done it goes into this concurrent
sweeping phase and it sweeps over the
entire old generation area and it D
allocates in place the unmarked or the
dead objects so at the end of this so
you can see on this slide I've got a
bunch of this stuff that's been marked
and now that the sweeping has been
completed I've freed up a bunch of space
so you can see here that there's no
compaction of old generation that's gone
on here so let's take a look at this how
this works in g1 so the concurrent
marking phase there's a one stop the
world pause remark and you would see
this in the GC logs as GC remark the
initial mark is actually piggybacked and
what I mean by piggyback that's done at
the same time as a young GC and what you
would see in the GC logs is you'll see
this indication that it's a young GC and
immediately after that you'll see this
thing that says initial mark that tells
you that on that young GC it also did an
initial mark at the same time so there's
no separate notion of the initial mark
like what you saw on CMS so during this
concurrent marking phase if we happen to
find a region that has no live objects
in it these are denoted here with the
large X so these are regions an old
generation we found that there's nothing
live in at the end of remark we can
reclaim those regions immediately so the
other thing that happens here as we're
going through this concurrent marking
phase we do this accounting information
that give us an idea of the liveness and
we also get information about who has
object references into our region so
that gives us an idea of how long it
takes to do a collection of that region
so there as I mentioned at the end of
this remark phase you can see here these
two regions that were marked with the
red X are now gone they've been
reclaimed and we know this liveness
information or we have a sense of how
costly it's going to be to evacuate or
collect another old generation region
so the way that we go about reclaiming
old generation regions is we choose the
regions that have the lowest liveness
maybe it's better way to say this is
those that have the least cost
associated with it from a duration a
time perspective and then we collect
some of those at the same time as we do
the next youngji see so there's no
separate motion of a separate pause to
do a collection for old generation we do
that at the same time as a minor GC so
what you'll see in the GC logs when this
of type of event is occurring rather
than saying GC pause young its GC pause
mixed so what that mixed means is we're
doing a mix of collecting young
generation and a portion of old
generation so here I've got identified
some young gen and old generation
regions have been identified as
candidates to collect
so after this marking has been completed
and the next minor GC occurs next young
GC occurs we get this mixed GC and we've
collected both old generation regions
and young generations at the same time
so you can see here with the dark blue
this was the amount of stuff that was
still live in the old generation regions
that we collected likewise the things
that are still live in young generation
or the dark green so to summarize this
in g1 the current marking phase gives us
this accounting information that gives
us a sense of how much it's going to
cost to collect those old generation
regions it identifies those best
candidate regions to collect on the next
minor GCS there's no corresponding
sweeping phase like we saw in CMS and
the remark algorithm that's used in g1
is different from what we saw in CMS
remark an initial marks at times could
be rather painful from the standpoint of
duration of time in CMS g1 uses this
thing called snapshot at the beginning
sa TB and it's a very very fast remark I
have seen very very few applications
that have a lengthy remark phase very
very few soul generation regions are
collected by evacuation pauses these are
stopped the world pauses because they're
being done at the same time as minor GCS
and the ones that are completely empty B
can can be collected
at the end of the remark phase by
reality is most reclamation happens in
the evacuation clauses so if we look at
the differences between CMS and g1 CMS
is very hard to tune
I hate tuning CMS I don't know about you
guys but you look at a command-line
option for CMS this is probably about a
smaller one as you'll ever see
contrast that with g1g ones goal is to
require only a min and max heap size and
a GC pause time target you might decide
to tune at which Heath topic occupancy
you want that concurrent collection to
start off so as an example you can see
there's quite a bit of difference here
in the set of command-line options that
you might use here I would suggest that
if you have a sense of what your GC
induced pause times you're looking for
going to be go ahead and set that and
use that as a starting place and then
based on what you're seeing with GC logs
then do the tuning of when you want the
concurrent marking to start one of the
key differences here with the heap
occupancy of when you want that marking
to start is different between CMS and G
1 and G 1 it's the occupancy of the
entire Java heap in CMS it was the
occupancy of old generation only
so that's one thing to pay attention to
there's some consequences to further
fine-tuning young generation or survivor
spaces with g1 essentially what g1 does
when you give it a young generation
sizing it basically says to g1 you
believe you can do better than g1 can at
pause times are you basically telling g1
ignore the pause time target because I
think I can do better
likewise if you do something like
setting Survivor ratio it's going to
have that same interpretation
okay in the area of footprint if you
take CMS or parallel GC with the same
Java keep size and you migrate the g1
you can expect to see a slightly larger
JVM process size and that has to do with
these accounting data structures largely
related to what's called remembered sets
and collection sets remembered sets or
are sets for short track object
references into a given region and
there's one of these per region and what
this enables is the parallel and
independent collection of a region and
its footprint impact is usually less
than 5% the collection sets or C sets
for short is the set of regions that are
going to be collected on a given GC so
all of the live data in a collection set
in other words that set of regions
that's identified to be collected is
that set of regions that's going to be
collected on that GC minimal impact here
on the footprint size usually less than
1% here is an example G 1 GC log so you
can see here some things of young GCS
here the first couple and here you see
on that third line you see this initial
mark that's happening at the same time
as that young DC you can see this
concurrent cycle being started you see
that remark you see the clean up and
then you see a young GC and then you see
a mixed so mixed again is we're seeing
old generation regions being collected
with young generation regions ok I'm
going to turn it over to Monica and she
can educate us on G 1 and give us all
the gory details Thank You charlie
all right so again I have a lot of sorry
again I have a lot of slides and I'll
try not to go fast but there are some
things that we can look at a you will
get all have the slides so I put as much
information on these slides as possible
and B we have some links to a to a blog
by Poonam Bajaj and and what I'm going
to cover some of them some of that
information is already on the blog so so
I may go fast during that so how do you
evaluate dg1 I keep on saying this over
and over again understand g1 defaults
right what what are the defaults how
they impact your applications behavior
basically what what default contributes
to what behavior and why are they
necessary first of all they're necessary
to address your goal and set priority so
what are the goals throughput latency
and minimal footprint right so for g1
the goal is low latency right so these
are the defaults max past time target
defaults to 200 milliseconds and the
automatic resizing of the young-shin is
between 20% which is a minimum and 80%
which is a maximum of the Java heap okay
sorry
understand the defaults again what
happens when you set xmn explicitly on
the command line you know it metals with
your default right g1 does it remember
g1 has a spaz time target as its main
goal and it's trying to resize the
nursery to achieve that goal and when
you set xmn which is a nursery Max and
min equal on the command line g1 will no
longer respect the past time target it
will respect the fixed nursery size that
you just set it set it to and when the
heap is expanded guess what you have
explicitly set your nursery to a value
and so that will not change
when your heap expands or even shrinks
so how do you evaluate g1 you should
know your performance requirement so we
often observed folks that want to
improve their response time throughput
and footprint right but response time be
careful just using average response time
is not enough and I'll talk about that
right now
so I know we all know SL A's have this
response time criteria right but but
what is that response time right it's
it's it's basically adding a ball your
sample set and then dividing by the
number of samples right so do you think
what happens when you have a
significantly varying or different
values over a large samples in are you
capturing them all not with average
response time right so there are other
response time metrics that you should
consider
worst case response time 95th percentile
99th percentile 90th percentile so our
recommendation is consider 99 teeth plus
percentile so what does that mean that
only 10% of your response time response
times are worse than that 98th
percentile number so so please do that
because imagine so so in a web server
again only 10% of your people are going
to experience worse response times and
what's your number so if you want better
than go what 99 or the worst case you
know tune like that so let's say we're
targeting with low latency so you should
know this flag you defaults to 200
milliseconds you want lower or higher
but set it on the command line it
provides a hint to 2g1 to the collector
that you need less than or equal to
those that many milliseconds right and
g1 will do its best to meet the past
angle how will it do that it'll adjust
its Eden the end nursery and survivors
are eaten and survivors and the heap
size and other related parameter Charlie
spoke about that earlier and to start to
stay within that goal
and then check your logs right I mean
your logs that will talk to you they
will tell you if there H if you actually
meet in your past and goal or not so I'm
going to provide lots of examples on
this so now if you want what if you want
to evaluate g14 throughput a you should
know that g1 is low latency is designed
for low latency right so it's new to the
tupid game
so first let's define throughput what is
throughput it's a percentage of time not
spent in GC right so so since g1 is new
guess what we're saying that we're okay
with the GC time ratios that is the true
put goal right it default it's a log
scale so it defaults to nine for g1 that
equates to a throughput goal of 90% so
you want you're okay with 90% of
application time and 10% of GC time
imagine are the true put collector that
we have hotspot stupid collector
parallel GC that is 99% throughput goal
99% application 1% GC so there is a
starting difference right there
so my number one comment to you is if
you want to evaluate g14 throughput
relax your past time goals aggressive
pastime gold indicates to g1 that you're
willing to sacrifice are you willing to
sacrifice your throughput because you're
willing to increase the bear and
increase in GC overhead so again so how
would you do it how would you tune it
for throughput you would do something
similar what you've done in the past
with parallel GC use new ratio new size
magnet max new size xmn whatever to your
advantage
note again fixing your young generation
size indicates that you're not concerned
about meeting a low pass time goal so
again evaluating g1 replication of
production environment is very important
it's important to understand what you
what environment you're working with
what are the issues fragmentation spikes
and allocation are you are you
replicating that lows
shoes you need to know the phases and
how long those phases run in your
production environment and also the
worst-case behavior and how often does
the worst-case behavior the frequency or
the likelihood of the worst-case
behavior you need to understand all that
and make sure the new benchmarking you
are capturing all that okay collection
of important data the GC logs right we
need the GC lungs and what how do the GC
logs help us they help you help provide
you just directly just in the GC lance
itself you have the past times you have
the GC frequency the type of GC Young
mixed what not the heap utilization
Chelsea Eden
you know occupancy before occupancy
after etcetera and then you can plot the
heap utilization you can calculate the
real response time stats you can
identify contributors like say mix GC
was the contributor or the last mix you
see the last of the three mix g4 mix
Jesus was the contributor to the through
the worst case past time so yeah so you
can look at that and you can identify
all these things you can calculate your
GC overhead and look at your pawns
distribution you can feed it to GC you
know you have to write a parser script
feed it to GC histo J feature what you
haven't
what else do you need g1 is new you need
a baseline configuration that you have
used in the past and and we understand
that we know d1 is new and we know that
your past configurations were highly
tuned right and that's fine
don't worry about that but you need to
understand you need that for comparison
and we need that for comparison because
we would want to know what works you
should you want to know what works what
has worked in the past what doesn't work
with in the past why do you need g1 you
have to ask the question to yourself and
and and then comparisons will help you
and us come with a baseline
configuration for g1 and then an
experiment plan you know we'll go this
direction or if that works and
experiment a B C and and so on and so
forth what else what are the data you
need you need the application statistics
you need the response time not just the
air do you remember we spoke about that
earlier footprint throughput metric your
CPU utilization and another CPU related
statistics are advise to use investigate
any unexpected behavior check your
configuration more often than not it's
operator error it's happened you know
sometimes you bring a stale command-line
option with you and you don't remember
what happened why you used it some so
you just remember it worked it gave you
some 5% benefit you carry it forward to
g1 probably messes up everything that's
happened I look at logs every day so I
know ok so I'm going to dive into g1 GC
analysis we have 25 minutes so I may go
a little faster with what I'm going to
show you next so Charlie has already
covered this most of it in his in his
section and we do have this information
and on the blog that I was talking about
so I'm just going to talk quickly about
the g1 phases what are the concurrent
mark but what is a concurrent marking
cycle phase it involves the initial mark
which is piggybacked on a normal young
GC it stopped the world because it's
piggybacked on to the young GC marks the
roots then comes a root region scanning
it runs while the application continues
to run it must complete the
you have to you have to scan all your
roots the references into into the old
generation you have to scan that before
the next GC can happen
concurrent marking it finds reachable
live objects over the entire heap it
runs while the application is running
can it can be interrupted one another by
a young GC remark it stopped the world
charlie already mentioned that he
mentioned about SAT B the snapshot at
the beginning stuff and then reference
processing it is a part of remark
cleanup it which is partly sub the world
and partly concurrent what is top the
world the lightness accounting
identifying the completed free regions
or stop the world remembered set
scrubbing cleaning up of that and stop
the world and then resetting the empty
regions and returning them to the free
lists are concurrent part of the clean
up cycle what's the evacuation pause in
in g1 it's the copying pause it's both
young in mix GC they're both stopped the
world events GC induce pause if it's a
young collection copies all live objects
into the in young regions into the
available unused regions if it's a mix
GC if event it copies on live objects in
younger regions into new regions and
some old because now it has the markers
remember a mix GC cannot happen until
you have the marking information so now
you have the marking information so you
know what old regions you can you can
collect
what-what-what-what live objects you can
move right from the old regions so you
move them into unused regions what
diagnostic flags can you use you can use
word bows GC which is similar to print
GC the output looks like that you can
use print GC time to stamp which
prefixes the last time since the start
of the jvm process it looks like that
print GC date stamps again adds time of
day prefix to it looks just like that
diagnostic flags again this is what I
use I use print GC details and I use
print GC time stamps what is what is
prim GC tell you and I'll show you I'll
walk through the one thing you need to
know about G ones Jiwon lawns it gives
you a lot of information and it's
because it wants to be transparent it
wants you to understand what are we
spending those time those times right so
if something is like really out of the
ordinary you know exactly oh look I'm
clearing my cart in Wolens taking too
much time something like that right so
it gives you all that information it
gives you whatever I've said over there
and I'm not going to read that and just
going to move on very quickly also it
shows you the Eden survivors just like
you would see in parallel GC and and CMS
and it's much more readable though it
shows you the occupancy before the total
size of Eden after the collection Eden
is of course zero what is the total size
of predictor Eden so the predicted size
is less and in this case survivors were
zero before now you have a 104 Meg
that's survived and then the total heap
which it's much more readable I like it
okay
understanding the logs this is how a log
looks it's a big log so I'm going to put
a ticket part by part and piece by piece
and I'm going to talk about it very
quickly federal time it's the overall
elapsed time of the main peril part of
the pause so you see this was a young
pause it tells you right in the first
line the parallel time is right there
and then there's in the net starts so
what these logs are basically ordered on
thread ID the GC work with DC thread ID
and are not consistent on each entry so
whenever you see them you will see that
the same thread ID corresponds to the
next entry all from the workers start to
whatever next right so the first entry
you will see the workers start which is
a timestamp at which the GC workers stop
you know started and it shows you
average min max difference it is a seven
update for format of the log so it'll
tell you how much on average and whatnot
so
the next entry you would see let me just
make sure I didn't skip through anything
okay
the next entry you would see route
scanning remember I defined that earlier
so it's a time taken to scan the
external routes for example system
dictionary that points into the heap and
it shows again shows per thread it
corresponds to the previous entry of the
thread and then it has average min max
and difference the update RSS update
remembered said any buffers that are
completed but have not yet been
processed by the concurrent refinement
thread before the start of the pause
have to be updated right so the time
depends on the density so it is a coarse
or fine or whatever so it depends on the
density if it's coarser guess what it
will take more time to update those
remembered sets so yeah that's what it
says here and then the number of process
buffers are right there I kind of like
use a mouse right there yay right there
scanners so we updated the RS scanning
the remembered set
looking for pointers that point into the
collection set again average min max
difference object copy times again so
it's a so this is the object copy time
which is what you would see in a young
collection right the copying time in the
young collection pause so this is what
corresponds to that remember so object
copy time is the time that each
individual thread spent copying and
evacuating again its average min max
difference termination so what is
termination time what do you mean by
termination time in termination
basically when a worker thread gets done
with us work so it's done done scanning
and copying objects and whatnot it
enters something called a termination
protocol so in that protocol it often
enters the protocol it looks for work to
steal from others and once and if it
does get the work and once it finishes
the work guess what it again enters a
protocol and again looks for stealing
work and stuff like that so the number
of attempts that it tries to steal work
that's counted in the termination
attempt so that's another thing to look
for if you have more time you know so
just number more number of counts for
one thread than the other maybe it's not
balanced for some reason so
again it has average min max difference
and then finally we have in the parallel
phase we have the worker end which is
again time-stamped individual GC worker
stops and then the worker time total the
time taken by individual GC worker again
average min Max difference and then
something something called GC worker
other so basically just means just what
it says it's the time that cannot be
attributed to whatever I mentioned
earlier so it should be quite low again
if it's high and we've seen cases where
it was high and it was because it was a
increase in the code cache occupancy
because of tiered compilation was
enabled so it was not a part of g1 it
was basically a bottleneck in the JVM
itself so this was high clear card table
time taken to clear the card table of
our sense scanning metadata other time
time taken for other various other
sequential GC phases choosing C sets so
you know you want to finalize the set of
collection she sets the set of regions
to collect basically it should be
usually very small and if you have old
regions in the mix color in the mix GCS
basically if you have marking
information already available guess what
it may take slightly longer because now
you have all regions to collect as well
reference processing time spent in
processing references reference in
queueing trying to place them on the
pending list freeing see set time
spending freeing the set of regions that
have just been collected you just
collected a bunch of regions guess what
you need to feed see sets including the
remembered sets of the see sets now
there's a diagnostic flag of that's
called print adaptive size promising
what it does is it so first thing to
note we did not support use adaptive
size policy the flag itself it's only
supported for parallel GC but we do use
that flag to find out ergonomic
information right here as you can see it
shows you it was it was the pause was
doing see set construction
it starts choosing C sets right there it
predicts a base time it knows because it
because the target past time was 200
milliseconds so the remaining time is
still 155 so then it does
it's another calculation so it adds
young regions to it edan sizes survivor
sizes and now the new predictor time is
1:30 inch because it knows we have 200
milliseconds and you know guess what we
were really quick so we have enough time
to you know add more regions and
whatever do more work basically
finishing choosing the collection sets
and stuff like that so it's very useful
information at least for me I understand
where things go wrong I can look at that
and figure it out so post seven year
four so I know 74 had these amazing logs
but sometimes you know it's too much
information so what we decided is then
people who don't want that much
information can actually go choose what
they want so you can choose fine finer
finest fine is similar to print GC but
now it has a cause so for example that
first one was a young you see with
initial mark and it has G one humongous
allocation for that then the next one
was evacuation pause so that's a cause
of the of the of the GC right finer is
similar to print GC but this time you
don't have that individual thread times
you just have say for example route good
scanning happened and what was the
average min max and difference so not
those individual threads member and the
finest is what exactly what I just told
you about it has all the information
that you need so so have at it before I
go into the tuning knobs I want to talk
about evacuation failure because we all
need to know that what is an evacuation
failure it's like it's a promotion
failure that happens when you run out of
he pigeons so it can happen for both you
know or survivors or promoted objects
heap cannot expand it's already at its
max and how do you know you are having
evacuation failures you look at your log
and it shows
by this indicator to space overflow it's
very expensive
GC still has to continue just can't say
oh oh gosh I don't know what to do you
know it has to continue it has tons you
know whatever objects one successfully
copied they have to be tenured in place
any updates to our set of the regions in
the cset have to be regenerated how do
you avoid it so increase the heap we
have something called the g1 reserve
percent which is ten defaults to ten
basically it's the reserve memory for in
case you need more to space so so right
there if you have a packaging failure
because of to space overflow or whatever
try to increase that start the marking
cycle early increase the number of
marking threads you can use something
called concurrent GC threads right there
to increase the number of marketing
threads alright moving to tuning knobs
so I'm going to talk about initiating
marking cycle and timing mix GCS and
these are the three free knobs that you
need to learn one is called the
initiating keep occupancy percent it
defaults to 45
it's the occupancy percentage of the
entire Java heap again difference from
CMS it's not the just the old generation
it's the entire Java heap that triggers
a market cycle there's something called
g1 old C said region live threshold
percent which is actually when do you
consider region to be a good candidate
for inclusion in a mix GC so basic base
it tries to look at the threshold
percent of how much life live occupancy
is for that region and it tries to
include that the default is 90 so if you
have 90 percent of live data in your own
in your collection in your own regions
guess what it will be included 90
percent or less g1 makes GC count target
it defaults to 4 that is the maximum
number of mix GCS that will happen after
a marking cycle so let's go with the
first one initiating heap occupancy
percent
so how do you tune it like I said the
default is 45% of the total heap
occupancy so what do you do you observe
at 100g an occupancy initial mark phase
phases begin you don't want the marking
cycle to start it's similar to what we
do for CMS right you don't want a
marking cycle to start too early or too
late you will either spin or you'll have
a no to space overflow which eventually
will lead to a full GC which is single
threaded like Charlie pointed out
earlier observe how much is reclaimed by
viewing heap occupancy at initial mark
and after marking and mixed GCS you just
want you want a reasonable amount of
object reclamation very tricky okay so
so so if you observe that your your
maximum keep that you're utilizing is is
below your actual maximum heat that you
specified and you have that room and you
don't and you you want it you want the
athlete that you see to use that you
know you don't have anything else in
mind for that particular route into
space I will show an example but if you
want to you want to use that guess what
you can set your initiating he occupancy
percent higher to to push that maximum
heap utilize occupancy higher right
that's what it means
so but be careful not to set it too high
guess what you said it too high then you
have end up with the to space overflow
so in the example I'm gonna show on the
next slide what we did is that we asked
them ask them to increase the initiating
heap occupancy percent to 70 to reduce
throughput and reduce the concurrent
overhead right here so what happens when
we ask them to increase that so they
were working with a 3.2 gigs almost of
heap and the default value of 45 was was
what would it would do we'll start a
marking cycle earlier so when the heap
occupancy would be 1 point 4 gigs or so
it would start a marking cycle and now
we have this much room that we are not
using the marking cycle starts it does
all everything and comes down so we're
doing more mix mix GCS and they're
expensive so we asked them to raise the
it to 70 and look at the difference so
again the turquoise color is mixed GC
the red is young jeezy and stuff like
that
Oh see said live threshold percent we'll
talk about that next so I'm going to
show you some GC pause distribution the
graph on the top I'm going to show you
next is basically or generated when we
dropped the cset line so remember see
said live threshold percent defaults to
90 we asked the people to drop it to 65
and the graph below is expanded to match
the scale like this so see that it
directly so you see how it shifted the
posited abuse in step shifted I know you
cannot tell the number so I have written
it down here so because I cannot tell it
clearly either it so the but on the
bottom you will see it ranging from 250
milliseconds to 325 or little over 325
milliseconds on the top we need to go
when we did the we said only include
live fresh or regions that have live
threshold don't cross the threshold of
65 basically it draw the distribution
moved into 160 milliseconds 2 to 35
milliseconds range so this area is what
moved over here so we saw our past times
got produced drastically because we did
not include as many live right more
expensive we kind of produce the expense
of the region's basically the next one
is g1 mix GC count target I have eight
minutes so so what do you need to do is
you need to first check your GC pauses
and see all the defaults working for you
in this case the default for g1 mix GC
count argot was 4 which did not turn out
to be optimal so what happens is that
we're trying to collect one basically by
default of four we trying to collect
one-fourth of the old regions at every
mix GC collection right and that could
give us at a very large collection set
so look at that so again the red is
young collection times which is almost
averaging to 200 or less the default is
200 and and then those turquoise colors
are mix GCS and you see how over time so
I'm going
start with your right here and then it
goes higher and then goes higher and
then goes higher and see how the last
collection is so expensive right it's
taking about 850 or more milliseconds
just for the last one so see number one
number two number three and number four
and that's what our maximum was number
four so what we told them is increase
your mix GC Tarkan target and another
thing we could have asked them to try
was to work with the GC heap gcg waste
person yesterday that is exactly how it
looks it's like questioning so so we
asked another thing we could have tried
was to ask them to increase in g1 heap
based percent basically g1 will revert
back to Young Jeezy's if the amount of
state space reclaimed is less than that
value so we're saying that we okay with
five five percent he wastes but if you
say increase it to ten percent so we're
saying oh well we're okay with ten
percent way so just go back to young mg
see earlier so that could have also
helped them alright so this probably is
the last one that I'm going to cover and
and I wanted to mention this because the
defaults clearly were not working in
this case so this application had 36
gigs of of your heap size and because of
that remember g1 defaults its nursery to
20% of the heap size which in this case
was 7.2 gigs the object allocation rate
and the lightness of the was such that
g1 was not able to meet its ponce time
target goal which was set to 350
milliseconds so a recommendation guess
what was simple drop your minimum
nursery size and I'll show you why look
at that
so the first young collection itself
took more than one second and you can
see and then I applaud also plotted the
that that's how I got to know what was a
problem I plotted it over here this is
my G this is JP chart this is GC histo
so the JP chart shows you that the the
it starts at the Eden starts at little
over its little around 7.2 gigs so the
first collection itself was getting
expensive so there
no way that they would what because of
the way the application was that they
were going to meet their pastime gold so
we asked him to drop it drop it lower to
this somewhere here and the minimum
nursery and guess what they were able to
meet the opossum blow with that we have
five minutes these are the aliases that
I would like everybody to at least
monitor and then then start using you
know ask questions and you will get
answers and this was the web blog that I
was talking about it
Poonam sweat blog so we have about five
minutes for questions but before we do
that I'm going to kick off a little bit
I kick this little section off with a
little funny story about g1 so it took
quite a while for a hot spot to support
g1 I'll share with you a funny little
story or a joke that has gone around
inside of hot spot as to why that
occurred so you heard us use this term
evacuation what we were seeing for quite
a long time is we saw that it was
evacuating before spaces where regions
were full we promptly called that the
premature evacuation
so g1 and his adolescence days had a
little problem hopefully this isn't the
one thing that you remember from this
talk today okay so go ahead with your
questions go ahead
that's a very good question tooling for
g1 so what what I've used and what
Monica tends to use is a combination of
two things one of them is GC histah
which you kind of have to do a little
finagling here so when GC has still
currently supports C MSM and parallel GC
it also turns out that GC histo has a
mode called simple log format so what
you end up doing is you write a little
parser in Perl or something of that
nature and you have space delimited
fields and that you load that inside of
of GC histo and then you see this
distribution of pause times the other
critical piece with understanding in and
seeing how g1 is behaving in and driving
your analysis efforts is having
something that can plot the heap
occupancies and the actual sizes of the
young generations and old generations
what we did is somewhat similar in that
case so we developed something that is
based on J free chart we parse the logs
that pulls out this data of heap
occupancies
and then we also you know you as a
x-axis we use time so we can see what
these heap occupancies are doing at a
given time and then it will also tail a
over top of that the pause times so
those are the two things the unfortunate
thing is there isn't a at least I
haven't seen a really good off-the-shelf
tool just yet that can do this that's
always was one of my main motivations is
to drive this tooling side of it because
that's always one of the big challenges
a very common engineering problem you
put out this great technology but then
you always have to ask this question
where's the tools you got something
there Curt what is that one of your
tools ok so talk to Kirk afterwards if
you're interested in tools
yes
the number of GC threats
there's been some changes that have been
made to that I don't recall the update
releases I don't know if monarchy
remember the exact formula but I think
it's based on the number of underlying
Hardware threads and I think when you
exceed a certain number it takes 5/8 of
that number this is one of the things
maybe to keep in mind if you're running
multiple JVM instances that you may end
up tuning the number of GC threads is it
5/16 now okay other questions Kirk
everything seems to be focused on pause
time does one of these calculations
actually take into account the
concurrent time because it's still
stealing
awaiting your application
that's a good question that's all part
of the prediction model so the question
is that thanks for asking me to repeat
that Liz so the question is basically a
lot of the focus with g1 is on pause
time so this is a prediction model that
predicts how long a given GC pause is
going to take does that take into
account the amount of concurrency that
you have because when you have the
concurrent sort of collection activity
going on you're stealing CPU cycles and
that's all part of this prediction model
that g1 uses to my knowledge I don't
think that it does there are
improvements of being made through folks
and Oracle labs to help us with better
prediction models another question so
I'm wondering if the adaptive sizing
whatever that's happening in g1 is
taking into account the Farber space
flooding or does seem that provides
survivor space flooding actually matters
in the Jie
okay so the question is are we is g1 and
is prediction model taking into account
the notion of overflowing survivors so
Kirk is using the notion of survivor
flooding which I'm interpreting as
survivor space is overflowing or you get
very rapid promotions and old generation
we call promotion so does it okay so
it's really driven by the pause time
target so the lower you set a pause time
target what you expect to see happening
is young generation gets size smaller
and smaller to accommodate the young
generation pause time so depending on
how how long your your objects stay life
is going to dictate how quickly they get
promoted the thing to keep in mind is
the amount of time it takes to collect
an old generation region is essentially
about the same as what is going to take
the to collect the young generation
assuming the same level of occupancy
there's a few edge cases there to deal
with because you have to deal with
references in to that region but you can
generally think of it that way it's not
as critical because you have this
ability to compact old Jim and then you
because you don't have this you don't
have this huge expensive cost of doing a
compaction so you don't have to do this
full GC so you now have this ability to
do essentially incremental or partial
compaction via the mix GCS so the next
audience question is going on survivors
days
that is a good question is a good
question I don't know the answer that
question is why have a survivor space
what are the worst what are the sort of
things that lead to the worst case
scenarios some of the biggest challenges
I would say for g1 and in particular
with an application so if you start on
from the simple standpoint and move to
something that's a more complex sort of
situation and probably less likely so
the most common situation and challenge
you'd probably have with g1 is you start
this concurrent marketing cycles too
late or it starts too late and you don't
have enough Headroom and you run out of
space and you have what's called a to
space overflow to space overflow
basically means you're trying to
evacuate some region or sets of regions
to some unoccupied or some other region
and the to space that you're copying to
runs out of space and that's what's
called a to space overflow that in order
to recover from that you have to do a
full GC and then you have to undo a
bunch of this accounting stuff with
references that you're keeping to
recover from it things go they go
the circumstances are the number of
circumstances and I'd say the
probability that something bad occurs is
much less likely with g1 than it is with
CMS
we're being screamed at being out of
time thank you everybody for coming I
hope you've learned at least one thing
out of this today</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>