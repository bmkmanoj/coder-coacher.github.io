<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Leveraging W3C Linked Data for Loosely Coupled Application Integrations | Coder Coacher - Coaching Coders</title><meta content="Leveraging W3C Linked Data for Loosely Coupled Application Integrations - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Leveraging W3C Linked Data for Loosely Coupled Application Integrations</b></h2><h5 class="post__date">2013-02-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CnEdt-jpaIo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's a little bit about myself Steve
spire actually worked for IBM have been
with IBM for shoe a number of years
guess since 96 predate the the rational
acquisition but I still work for the
rational brand my title is I work on
integrations between tools and so focus
on different integration technologies
and and linked data is one of the things
we've we've explored and actually
implemented some background on me beyond
that is is my first Java one so it's
been good so far of course I haven't
spoken at javaone before so of I'm a the
co-lead for open source project called
Eclipse Leo I'm also a member of the w3c
of standardization effort and get into
some of those things in a bit so I have
a fair amount of material and we'll show
some little bit of source code because
it felt like I should in Java won by a
lot of other resource descriptions if
you will what resources look like on the
web in some ways of of modeling and
showing those so I want to break it down
exploring leaked data so just go find
some some motivation use cases what
really a look at our problem if you are
being rational we looked at to
integration not just integrating our own
tools which was a mess for for a period
of time but also with our partners and
others and some other use cases where it
works well then get into what is it so
what do I mean by linked data and then
talking about the standardization
efforts going on and a little bit of
open source that's available to help and
I'll try not to trip so we look at our
background within tools so I'll take a
step back in time and these the year is
it really important it could be 1995
whatever just showing that in the past
way we typically built tools was really
focused on the features and making those
point products better for those end
users so the specialized modeling tool
specialized a source and configuration
management tool for those working in
embedded systems and really the focus at
the time was really just making that
tool as good as
could be no one really cared much about
integration there was someone offs but
there was a need that it would be nice
as they they work together he would
often manage the data information
between the two via spreadsheets or some
other you know pencil and paper and how
the information between the two
different tools work together especially
we were talking about things like why
this test case and why can't make any
progress until this bugs fix but this
bug as you know i don't i don't know if
a bill devale yet for me to actually
rerun that test and all that stuff was a
very manual process so the way we solved
that was we got a big bucket of glue and
started patching things together based
on the api's that were available to us
so a lot of these tools in whatever
native language they were built in you
would they would expose a public API
some private api's these api's were
often bolted on the end of the tools and
only expose certain data and process
these and configurations on these tools
and it was a really thought of well we
won't integrate this tool in the
beginning so will design it that way and
also these were done often by third
parties so they'd come in glue these
things together and then you'd have to
buy this one product by this other
product by this piece of glue and now
you're you're you're tangled together we
can never upgrade the one end without
upgrading the integration software
without integrating the other end of the
piece and then own it be even terrible
if you've repeated that and you had that
occurring on the other end which
everyone typically does and so now you
can't upgrade anything because
everything's tied together without
shutting down for three months to make
it happen to putting on your you're
sighs mature so you saw this by wrapping
everything together in an alm sleep
sweet so rational had one of these you
know you everything everything be good
if you come into our world you buy our
products will give you the sweet and and
it'll all work well together it did for
a number of weeks maybe until you need
to upgrade something or you want to
adjust things so is a bit clumsy so we
we say well let's move away from
at let's go to an approach where we
instead think about exposing our data
upfront using open protocols to do that
such as HTTP trying to focus on the
smallest thing that will work so a lot
of times we kept getting into these well
the customer needs us and he says and
this is we need these tight coupling
between these applications and when I
change a stake here it's got to change
Aaron's got changed Aaron's got changed
Aaron the reality of that ever really
happening was zero so instead of looking
at well we just need to be able to
expose the data from the tools and some
rules around how we manipulate the data
may be some rules around or some
conventions on how we expose user
interfaces on the data and so we did
this experiment out in the open at open
debt services net and I have been part
of this I guess since near the beginning
where we got together with whoever was
willing to come work with us and say we
want to work on this integration problem
and then the way our one vice president
with an rational describes it is you
know we have such a hard time with in
rational getting our three products that
do essentially the same thing so we have
the problem of there's this product
we've had say from legacy we have this
other product we have because of
acquisition and then we have this other
product which is our next generation one
so now we have these three things that
roughly do the same thing but they
really don't integrate well with our our
quality management tool and then again
we have two or three of those because of
the same reasons and so we we really
need to flip that on its head and say we
need to do this out in the open we need
to talk about it we need to get our
partners involved we need to get our
customers involved and let's get our
competitors involved you know it's all
it's all get together and so and there
we we define to set of specifications
and I'll talk a little bit about how
that works as well
so taking a completely different use
case looking at a the field of
healthcare and life sciences so if you
look at one of the challenges that often
had around collecting data for drug
usage either if it's the the you know
trials are just regular fda-approved
type pharmaceutical is that we
especially the drug trial you in the
past I remember someone and then in the
field would always show this picture it
was horrible it was just stacks of
computers and and I wish I could pull
the picture out and it was so any time a
medical office or facility or somebody
wanted to participate in the study the
the drug company would hand them a
computer system to say here enter the
data in there so that's terrible it
could imagine how many trials they were
involved with not only that is the
employee of the patient information is
also track somewhere else and then on
top of that regulatory wants to know
about these problems too so you and they
don't want to trust the the drug company
to know about they want the physician's
office to report it back the medical
facility and so these have all kinds of
challenges and problems so there's a lot
of interesting data there the method by
which it's collected is is varying
across each one of the different drug
manufacturers so they have their own
custom way that they want to receive
their data of course the different
regulatory agencies just in the US and
others and there's a lot of
standardization work going on between
all these to improve this but just
showing if we had a common way that they
could actually expose their data right
their data doing in a loosely coupled
way this could really solve a lot of
interesting problems in the field so one
would really lower the cost for let's
say that the drug manufacturer to
actually see if out all these different
drugs by it being able to leverage an
open platform a simple way of collecting
and reporting that data and then the
regulatory is
it would have that same data but on top
of that the patient would benefit
because I would have a lower cost to it
but now that data could be available
within the employees there's an employee
and patient information and health
record to say you know as I data comes
available somebody else's taking that
prescription drug or drug trial then the
problem with it becomes available almost
immediately because as you share this
data and a standard format in a easy way
then that becomes available into the to
the physician or who is evaluating the
patient to say oh these common problems
occur and is not say months of getting
that data scrubbed and published and
then pull back into the system so
there's many other use cases I could go
on about I mean there's some
standardization work going on around
just library data you think it's a nice
interesting web of data and interesting
relationships and you need to just do
simple things of updating you know what
books are available maybe who owns a
book and and transfer status and things
like that but I'm gonna go through
hopefully a simple example of what
linked data is so first I have to ask if
if anyone's knows w3c's definitional
linked data and sort of a semantic web
stuff okay
so this this introduction is supposed to
help with that so I won't get it so
there's there's a I'll get into it so
those are no no Tim berners-lee he's
credited with the inventor of the web I
guess he invented the a tag in HTML
essentially so that the ability to link
across a different documents on the web
and he's the director at w3c so he's a
he's a big thinker he was even on stage
for the Olympics Opening Ceremonies I
know if anyone saw him on there tweeting
the so he came up with this this model
this definition for linked data in 2006
in your basic things so use your eyes to
name things that seems pretty obvious we
need a universal naming standard or
something your eyes work boy when you
make them your eyes it would be good to
make them HTTP URI so when you do a HTTP
GET on them you get back something and
then of course would be good if you get
back something it would be something a
bit more meaningful so you could look at
it to do some type of facts from it so
use some existing standards we have
today such as RDF which is a resource
description framework and sparkle which
is a query language language over RT up
stores so then the fourth thing was of
course then when you get these things
would you know provide interesting
information about other things so you
can go look up those other things as
well so as he said it was that's simple
of course when you put in RDF and
sparkle that probably doesn't qualify as
simple funeral asst technologies
so that's Tim's definition so let's take
a simple example and walk through if you
look at the I think we've heard the
story before if we look at this this
statement here you'll learn because it's
written and you can process English
English and understand that test case
for is blocked by issue 973 so the webs
in a number of ways is built this way
where it's unstructured text it's you
know just out there available we learn
it by we can learn this information from
you know I may be a tester I'm
responsible for testing some product I
have written down maybe in my notepad
what my test cases are and then I have a
column that the right down anywho
pass/fail and and why they failed what's
going to happen and this also could be
you know defined in a computer system
somewhere also and I can learn other
faxes on my tester I'm at the water
cooler I run into my friend Joe happen
to have a conversation and learn he's a
committer on some Apache project and so
that that's again an interesting fact
but then again it's you know it's hard
for a computer to understand these
things so using rule one of tim
berners-lee we're going to identify
these things by giving them all you are
eyes and this is probably the part where
if you're sitting far away it's hard to
read or even close so the URI it may be
something to my internal homegrown test
system that I you know either yeah
required through a friend or wrote
myself or it's a commercial software
application I have so so that it's
system that identifies a local item some
some statements about the relationship
so it's a block by and then I just
picked some random and shortened the URL
out of the the HTTP client repository
there jo repository and then Joe he has
his own your ISO Joe coder dot me which
is not registered so
and then he's a he's a committer and on
the the Apache project so that helps a
computer and also helps that we've
organized these things into the
statement so this is where there are DF
resource description framework comes in
it defines things in threes subject
predicate object so this this Triple D
statement so or facts and you can
collect up a bunch of these and they're
interesting so there's really no
relationship between these two things
are just two independent facts that I
learned about now I actually have a way
to tell the computer I know about it so
this is where rule number two comes in
I'm going to go fetch something and I'm
going to then enroll three learn
something interesting because I give it
an RDF so if I look up issue 973 by
doing a kid on it I could see the
subject of this they're the same I could
see in this case it depends on some
other bugs so now I have something else
to chase down in that bug I I picked on
it's looking in the Oracle bug
repository for fun and then I can see
you there's a contributor the owner of
this bug is actually Joe I happen to
just run into Joe so that's good so the
example here is really trying to show ya
obviously the how the full rules work
but also shows how if if I didn't happen
to run into Joe at the watercooler I
wouldn't have known he's on Patchi
project but if I had to chase down this
thing and try to get it resolved I would
I could use this structured data the
computer could understand it and and
this is a model that we're doing within
our tools to help it to integrate
between them by just simply following
these rules to learn about the
relationship and dependencies across
them and also you know not just like a
get mechanism and I'll get into it as
more of a post and update so how we can
insert this information in the other
tool
and I figured pictures help so when it
provides some interesting visualization
so it's the same thing that was written
in all the the URI triple Gorp is he can
simply show a directed graph may be
centered around issue 973 I'll not the
Penn's relationship a test case is
blocked by that the contributor is Joe
and the commuters Apache so this has
some nice scaling qualities too because
this information is stored with issue
973 so this bug can evolve independently
the system that's running this
information can be upgraded this is just
a simple UI to the system like the web
works today I put a link in my web page
that leaks out to something I don't need
to tell that something over there when I
change or likewise I just have to go
fetch it whenever I'm interested in it
so that was like a three inch view of
link data so this is like a 30,000 foot
view of link data so there's a website
out there to linked open data cloud that
collects RDF data dumps from different
sites Oh while I didn't look great so it
is supposed to highlight based on the
size of it the amount of data from that
that site were published it the color
indicates the the the base industry so
you can see publication data over there
in the green life sciences in the pink
and so the the communities linked data
commute is actually using this model at
a pretty large scale so it's just back
to maybe a thousand foot view so this is
what it looks like when we're we're
looking at a model based on the two
integration I don't want to get into
much detail about this other than when
we use linked data we define some basic
rules on top of you know Timms for rules
are good but you can't call that a
specification you can't really go right
test suite to that you really can't go
right a compliant server to that I mean
you can do certain things so we went off
and did some exploration or and helped
refine those rules and then also build
some interesting capabilities on top
that just use the accessibility of HTTP
and rdf and also in cases HTML so so the
key thing is you got to define what your
resources look like so look at scenarios
look at what's important what type of
resources are key what type of
properties on those are resources and
key and really focus as this is what
we've preached out there something
minimal that will work so we're not
trying to solve the world's problems in
version one we're actually trying to
solve this problem this year and then
actually learn and build off of that so
we've we've got quite a bit of success
than that and this is you know just
using our example but this is a repeated
example other words so we got a bug that
has a bug resource type if you will a
bug report and a requirement and there's
certain properties we define predicates
that define the relationships between
the two just using and also defining a
way to preview that link so it's often
if you're in a web application you see a
hyperlink and some tool to provide a way
to hover make show some information we
provide a way if you have a link from of
those to fetch a minimal representation
to present that and another thing is he
is getting at that information so often
time it's hard to search a repository
for data it's hard to learn all the
rules are to create data in that
repository but most of those tools
you're interviewing with already have
those dialogues that do that so why not
provide a model around that that I can
embed that into my application so we've
defined some simple guidelines on how to
do that in some html5 mechanisms to
conventions to use to do that so that
was a quick view into linked data what
is it I'm going to talk about
standardization now checking my time so
doing okay I'm going to talk about some
of the need for standardization what's
going on and then I'm going to actually
drill into a little bit of what's going
on with the standardization so
so the problem with the using this
technology i would say problem it has
its benefits and its downfalls one of
the one of the big usages of it today as
you saw in that big linked open data
cloud is it's this open data perspective
where it's about publishing data on the
web and making it open and available for
people to consume so that's more of a
consumer-oriented way not interacting
with the data more and so use a lot of
the things you see today are focused on
that dumping out of the data so data gov
David IgE co uk Drupal other places
dbpedia so when you have to update to
update that data you have to then go
look at or who gave you the data then I
have to go contact them some mechanism
maybe they give me their public API and
then push it into their or somewhat page
to enter it and then eventually I'll get
a new dump of that data so I just more
or less replace or merge the data I had
and that doesn't work but so well now
you look across the web now some of the
feedback we got on why we think it's
interesting to standardize it people so
others there's a lot of there's a best
practice out there just look at that and
a problem with that is it somebody's
blog you know it's not a standard and by
the way I can go find nine more blogs
that say similar things but yet
different so who's really right and
that's where we come to the point where
well it's be good to get together really
smart people who have some experience
and let's let's do something better and
because of all these variations in these
best practices in different ways you can
interpret certain specifications you
find allies implementations go to this
least common denominator way so they're
not be able to really leverage some of
the power of the web and and these
different technologies because of their
limited by what a lot of these big data
sites do and these best practices that
people follow so taking on w3c's linked
data
you know those things say the only thing
we have is at w3c as tumors Lee's
definition of linked data we said well
let's the standardized that in a sense
you could say it so we we got together
we meaning IBM talked with the w3c and
the way things work there to figure out
if enough people are interested to
standardize as you hold a workshop so
held a workshop in December had a number
of people there oracle EMC yet nokia
very various others that are in a linked
data space the ones that published a lot
eases we even were blessed with the
presence of Tim berners-lee there so a
good discussion out of that people more
or less a lot of head nodding for that
two-day session which is a good thing
when everyone's agreeing that there's
the problem in green roughly on a
solution so we said well the way to go
for it is if you've anyone's ever worked
in a standardization group before it's
often hard to show up with a group of
people and say an open whiteboard and
say what are we going to do so it takes
a long time to get to something that's
aspects often it's best to have
something to start with so we agreed at
this that we would group of us would go
off and write a start of this based on
some of the things we learned with our
experience and rational and we published
this link data basic profile Co
submitted with a number of folks and
then led to the creation of a working
group that working group fired up in May
of this year we have now up to 45
participants from 27 organization so
that's quite a few people the large say
half of those are from academia and I
don't know if say this carefully had
limited participation so far so the main
goal of the group is as I mentioned is
to build HTT based applications that
follow restful principles to provide a
read/write linked data
so really looking at that sort of a
finite are really narrow in on web
resources how you operate with them and
providing a lot of the best practices
we've learned about we're on target to
deliver a what's called a candidate
recommendation a few know the w3c
process I feel sorry for you but that's
where that's more or less the end
specification as far as the working
group agrees and general community
agrees that this is what it should look
like and then it matures through
implementation another implementation
feedback from there no one thing I
realize in sessions yesterday is if I
would have put a rest in my title I
probably would have filled the room
website yeah well I don't have anything
about WebSocket so
so I'm going to get into a bit of the
gory detail now of what that what's in
that member submission that members
submissions now been transformed in the
working group into a call it editor's
draft and so in and working through
coming up with the working group
consensus of what it should look like so
the the model we took when we looked at
well what should we say how should we
say it how should we break things down
we broke things down and I say three
basic things those so there's a type of
resource we call it a link data platform
resource just to give it a name it's a
little different than your typical web
resource your web resources anything
like a you you know a URI you do a get
and it comes back and it could be a
screenshot it could be a PowerPoint it
could be number of things but the
problem that those things have their
there as a regular resource in there and
there say they don't have a problem but
when if you're looking to model things
like test cases requirements their state
is actually fully represented by the
representation you get back so like a
power point is maybe somewhat limited
there you may publish it and it has
information in it but you don't have
things about who really created that
finalist system when it was a last
modified all this other data that might
be with it so we look to define the type
of resources that we work with where
we're actually modeling something and we
want to expose it on the web so its
state is fully represented by its
representation so we use RDF is a good
way to do that so the problem with RDF
if anyone's ever looked at rdf XML and I
don't know if I'll offend anyone but
it's not very popular so there's
different text formats that are out
there and there's often a question which
once you use so you can sterilize
already up data model into rdf XML text
turtle JSON etc you look at the data
that you use so when you try to really
build an open system to
be able to update this data and create
it well the problems you have is
everyone has custom types to their data
so I'll define my own custom type system
on the literal values but really there's
already standards out there let's just
adopt one so xml schema definition data
type seems like a good one or whatever
the right things are we use some typical
vocabularies that we see there so you
some discrepancy cross different
vocabularies that are used Oh what do we
do when things change and and how do we
represent that data what should we make
sure our servers do HTTP leaves things a
bit optional you know you can do this if
you do this but doesn't say you have to
give the appropriate conditional headers
when you submit and properly handle
etags but we're saying you should always
do this and always have any tag and
always submit on a put or some type of
write operation or the appropriate
conditional headers to to avoid writing
over somebody else's changes the second
last bowl it's kind of an interesting
one and it's hard to standardize is
basically saying it showed my example if
I'm depending on this other system when
I do a get one day and I get back this
description of something that is a bug
the way the web works it's at the end of
that other system and it could change so
i might do it tomorrow that thing maybe
it will be a bug into requirement so it
might have multiple types that might
change it might actually change to be a
something called a feature or some other
thing you know it depends on how its
modeled so as a client or as someone
who's consuming this data how do we
write the rules to to make sure clients
are don't break all the time you know
that they they handle the flexibility of
the web that way
oh and also this is a thing we pride
ourselves on developing tools at IBM is
we may think so complex to or give
customers the ability to make things so
complex that they can never actually
create data in the repository so the
rules around what's a valid defect
report well then you try to do that
through a REST API on how do you you
know what you post to and as like oh no
you forgot to you know that field which
depend on that field being this value
those say what that's that's just crazy
we need to stop that so trying to make
you know some rules in place to keep
things simple minimizes constraints so
let's take a look at an example here so
if you don't know that the the text
description which it sounds like people
are don't so let's it's a real simple
model right we've seen this all before
you do it get your asking for the
representation i'm using text turtle
because it is easy to understand and it
fits nicely on the slide and taken
chopping the HTTP headers normal
namespace prefixes we've all seen XML
before but this is more the subject of
the statement that I've mentioned before
so we're doing a get of number one and
so that's the the URL number one so this
is the predicate a it means basically is
a type of a so it's a it's cash
basically so I'm saying it's a
representing some type of asset and then
it also has that in this in this bottle
is if you continue another statement for
that subject using a semicolon so this
number one has a title of this again
some I colon means it continues and this
subject as a value of 45 you know period
end of state so a pretty simple syntax
pretty simple to understand and
represent things so that's that's what a
simple resource in this model looks like
it's a I think it's intended to be a
complete representation of what's in the
repository it's possible to transform us
in a repository to match this it's
possible to actually implement this with
a native rdf store whatever whatever
makes sense to you so that's the base
of what the resource is and how its
representation looks and rdf terms so i
mentioned there was these resources so
the problem we also have and this is a
common pattern you see in and rest and
you see in and publishing protocol it's
it's not necessarily a new concept but
you know everyone's using it over and
over again and no one's standardizing
some of the ways it's working so we so
what you said well we'll look at this
this thing that you collect these
resources in we'll give it a name will
call it a container we could have called
in a bucket a collection but there's a
lot of reasons we didn't listen Oh
answers those questions where well what
you or I do i post to to create things
when and if I forget about that your eye
where do I go to to get and then learn
about you know the things that were
either i created or were created before
or existed before the normal questions
we get on i think that was the pact
presentation I I attended yesterday on
how restful is your rest api or
something like that so a lot of the
things apply in a similar model here in
the discussion of some of the patterns
that were defined and then and we'll see
the importance of maybe the fourth one
if you don't have the background is the
when you get a representation back often
in like the atom syndication format it
will include the entries and all the
data about the entries in there so a
similar problem you have there with how
do i get all the data back without
having to get a list of your eyes and
then go each one get get get get which
is we all know is is not good maybe
there's a where place to explore web
sockets there so you know paging is
important a lot of things there that
drive this these things in this is
actually around query requirements and
it's not just about update and read but
there's a lot of cool interesting
powerful Semantic Web things you can do
to say this thing's a type of that thing
and that has these properties and it has
those properties and I'm really one of
those things all this inference enrolls
you can do which is all interesting and
good but you need to have a system that
can process all that and you need people
to properly describe everything in that
way but if you look at just simple query
you can say well I just want to search
if it's one of those things I don't need
to infer to one of those things it says
it no it's just a real simple statement
so container no magic here you do a get
on the container we call it a container
so one of our best practices so you
don't have to infer what what this thing
is we just tell you what it is it has a
number of members and using a standard
term here based on one of our best
practices is here the list of members
and as a set of your ISO a real real
simple model so that the key was to keep
it as simple as possible so let's make
it more complex so how do we had things
to this container so we just take a
description what we want the resource to
look like we say it's a stock it's got a
title it's got some value and this is
the URL of the thing we're creating so
there's another one bits of guidance
this is saying the server assigns the
URI for it I don't as a client tell the
server what to do I don't I don't
necessarily care and then it you know
converts that stores it send it back i
think this sort of a standard create on
the web so I'm not talking anything new
other than a small rule around
assignment of that you're I controlled
by the server and how its communicated
and again all these these your eyes are
opaque it doesn't matter what they look
like from a client's point of view it's
just going to use them create server is
going to communicate it back so it
doesn't have to do any any math to
figure it out so you do a get on the
container it looks the same it now has a
new member
so that's a that's a good sample simple
sample so let's take a slightly more
complicated one it's looking at the net
worth of someone so of course that net
worth has somebody who's the owner of it
there's a number of aspects associated
with it there's subclass of course have
a value we've already seen some of these
examples and I feel necessary to put a
disclaimer on that even though this
picture is uml it doesn't follow uml
constraints so that's probably the eye
test chart so the the idea is it's
really a simple example that was before
so if you look at what we have here now
it's it's the net worth your ISO network
/ and w1 it's a net worth it's got a
list of assets so you can see a list of
things but the thing the problem with
these type of models i would say you
maybe not strong problem is what you or
I do i use to post you to add to this I
guess I could get this I could I could
add another triple that adds another
asset to it and I could post it back and
that's how it would add the the net
worth one but I i would still would have
to do a post somewhere to create that
asset I would just you know what I just
described would just add another URI to
this list it wouldn't create the
resource so we say well there's actually
a container out there some other your
eye well like we did before we call it a
container it's got a name these names
are maybe a bit more or file RDF
specific but it's basically saying it's
for this resource this it belongs to
that membership so it defines this
membership or defines the things that
are in the container so quite simple so
now as i get one of these things i can
understand if i do a post on this
container uri i can then add things
automatically to that to the asset
into the example I mentioned before on
well that in the previous example and
these colors didn't come out well so in
the same get it just adds this
information so on the response for asset
one asset one here's the information by
asset to asset to his their information
so in the the representation of the net
worth when I fetch that I not only
learned about the container information
but I can supply also the data about
those assets so saving the multiple
fetches if I don't have web sockets the
common problem is containers contain a
lot of things so unlike my LinkedIn for
know my Facebook friends it's not a big
list the you might have a hundreds and
hundreds of things we all dealt with big
collections so but we want to learn
about them so we don't want to fetch the
whole thing and all its members to learn
about it so oh this is was a interesting
debate on what's the best way and the
web to fetch data about something HTTP
headers query parameters save you that
discussion but we came up with this as a
simple way to take from a container
attack on something and ask for the
metadata if you will about the container
paging again we tack on first page
similar same example same example now we
have a new resource so as we know in the
web resources are identified by the URI
so this has a unique URI from everything
else so it's a first page resource we
know it's a page because we say it's a
page we also say what's the page of so
it's the page of this container and we
give it the next page so and again this
is an opaque you or I it doesn't matter
what this is I'd here that's
non-standard it could be a date range it
could be a whatever you know whatever
the server wants to give you for that
you're
right so it follows a similar model that
you would see in Adam pub feed and
paging but that deals with a couple
other things that we don't put in here
around previous or number or I'm all set
we found that some challenges maybe
eliminate some challenges from servers
that they're the ones who really dictate
what they should send back and how much
so we try to simplify it and just say
the server is going to give back what
makes the most sense in this case and if
you need more than ask for the next page
so we're testing that theory and we'll
see how what works oh so how do you know
it's the last page because we say it's
the last page so RTF mill tells you in
the web it's especially defining things
in this way it's uh you know if you omit
something then you're kind of left
guessing well did it leave it off
because it's not said or did they leave
it up because it doesn't you know
satisfy the condition so just just tell
me it's the last one ordering is
important and so instead of putting a
rdf has some interesting way say some
some constructs to define ordered list
but their popularity is falling and not
everyone uses is getting back to this
what we've seen is a least common
supported item so and we also look at a
again back to her what's the smallest
thing that can work so often that the
data itself has the order information in
it so we're just going to tell you here
that the data we're giving you is
actually ordered by you know whatever
the value is so we're not adding
anything into your model we're not
adding a construct around it to say this
is list item one also you can't
guarantee the ordering of the things in
that representation again a simple model
where we're trying to test to see how
far we can go so that's what's going on
around standardization
as I mentioned that's part of our
current working draft we have some some
implementation work going on with it
validating it both from IBM and those
involved in the working group in their
own separate exploration so it's been
interesting so and I'll enough they
don't they're not represented I guess
some are representing these projects so
I think most people are aware of some of
these projects but I'll build them up so
a wink as we know is is very useful
maybe it's the wrong audience to talk
about wink vs now I'm going to forget
the name of the Oracle implementation it
was the jax-rs implementation so it
provides a real simple way to bind those
HTTP request to your your Java
implementation at G Jenna Java API and
storage for and sparkle implementation
and an HTTP interface to that sparkle
endpoint so valuable and providing you
know some some good tools to do some
linked data applications and the folks
there actually involved with this
working group in I'm doing some
experimentation claw Reza is a is a like
what we're talking about dido have much
experience with it but I figured put it
out there's a as an interesting one
Stables showing that how you can take
some of these technologies applying to
different domains content management and
then the last one is what we've done
around ano slc and around our linked
lifecycle data and higher to integration
we've built a project that Eclipse to to
help those implement those tools and so
it's a non-traditional Eclipse project
in a way that it's not any ID he plug-in
or anything it's actually just SDKs to
help build web applications or just
general OSLC implementations so I want
to explore how we can use so the
technology looked up before so this is
your your jax-rs example
so real simple how do I get a change
request you know it get you have an ID
for it or have your eyes spliced
produces a number of formats so this is
your accept header so this is very
valuable if you ever written a tool to
parse accept headers are actually can be
a somewhat complex format because it has
qualifiers and other things built into
it so you can you know rate or wild
cards so anyways I've seen enough but
those bad implementation that my days
and know that you should leverage a
toolkit that does it for you real simple
right so then I just get my
representation from wherever i sterilize
it I send it back over the wire it then
fills it then the 200 ok and the
response back so our post a container
sample there's a similar I'm starting to
give a hint here above what's coming
next so we add some annotations here to
say what kind of thing that you can
actually create here so given a hint
similar thing here is the you can give
it any one of these already affects some
lxml abbreviated format of rdf or JSON
and of course create magic happens here
well it's actually not much stuff but I
just didn't put it here and again a nice
mechanism here and jax-rs use it you
don't have to build up all your response
headers and all that stuff it just does
it nicely for you so that was a simple
get of a resource simple put post to a
collection oh now let's look at well
what could we do this is borrowing off
sort of the jacks be model we tried to
use Jack's be annotation but it it fell
down with somehow i already have
constructs in couple places so we've
this is a art book done in clubs leo
projects i think we're looking at what
can we do broader with it and not
limited to just our OSLC world but i'll
use as an example so a change request
for a better term
as a bug report you know we can see that
whatever namespace most of things come
from a resource shape if you will is the
type of it so we identify the type you
know simple things this is the as you
see it's your along with your your java
model project model and just annotate it
with Jack's be like annotations but this
is the URI for this predicate and that's
the UI for the title predicate so and
then the nice thing is is we've found
that to the jax-rs implementation so
when someone's asking for rdf XML we can
then look up the mapping here and auto
produce from using apache Jenna the rdf
definition without the Java code or
having to do more than just extend an
interface and tagged a few things and
then we have our RDF representation from
our Java object model and then likewise
when the post comes in and it's already
effects Mel and it looks up the the type
associated with the data that's coming
in and then finds the right Cyril Iser
to our yes the opposite reader to to
build up that change request model and
then hand it to the to the application
to work with it so it's similar to the
the model that you get with jack's b and
jax-rs
so whether you're happy or not that's
that's all the slides I had today so i
think i'm at the right amount of time
too so the i guess some of the key
messages here is is this area is pretty
active and evolving even though if you
saw some of the statements in the
Semantic Web world how long it's been
around it's been mostly an academic
initiative with some commercial value
we're seeing more and more commercial
value out of it and broad adoption not
only are we doing it within our and in
the same IBM's software division and the
rational brand does tooling and if you
look across all our brands we have you
know would say rationals not the biggest
but we have our tivity friends now who
deal in the system management space are
starting to adopt this model as well and
had started to ship products and will
continue to and they're actively
involved in the OSLC community and
linked data standardization work as
we've proven with our own shipping
products like this for three years now
and supporting them they have benefits
like anything that relies on your eyes
stability you have to rethink the way
you deploy things in the past so some
people have built applications let's say
that depend heavily on the current
hostname or IP address or things like
that and and then try to roll it into
production and then also need to rewrite
the repository so the thing people have
to rethink how they're building things
it's not completely broken but you just
have to think up front it's just like
Google doesn't plan on changing its name
on a daily basis and have everyone have
to learn about it has a lot of good
alignment with with what you've done
already with rest applications in fact I
would say it improves on it so it gives
you the rest patterns plus a consistent
data model to apply behind it so now you
can work with the data in a consistent
way that represents the full resource
in like I guess I've probably said let
me seven times I don't know the
standardization will help here so by
being able to get together agree on it
will leveled him to make some progress
so with that I hope hope you've learned
something hope I don't think I saw
anyone fall asleep so and I didn't serve
coffee beforehand so that was
challenging so I appreciate your time
I'm available for questions I'm around
for next couple days to so yes funny
with it Vicki
Oh
because I don't see they often
conflicting ok so I'll repeat that for
those it in here so oftentimes a
standardization efforts are focused
around the protocol and formats but not
much around the the vocabulary
terminology are ontology and what's
going on with that I think that's a good
point i think that's where people are
learning about you can go to a couple
different sites and learn and get a huge
catalogue of ok ontologies that exists
but then you're left wondering well
which one should i use what's this
maturity status sometimes I like one I
was amazed at you know with some
research are some macadamia site and it
was down for multiple days you could
even get to it so I think there's a
thing that's an area we're looking to
improve i think the you see some of that
coming out of w3c now because they have
the Providence ontology that they're
publishing there and so I think that the
I don't know of any other group that is
dealing with this problem head on other
than w3c right I noticed a lot in
right right so the the statement was
that there was the there's a
microformats group that took and
embedded some of these concepts of
vocabularies and rdf a into HTML and
then the google yahoo formed schema.org
which define their own vocabulary format
that that does a lot of similar things
so no they're not involved in that yet
so I can't speak for them yes yeah
questions winding back to when the other
side you have showed how you plan to use
link basis wins great applications yep
and then the second office was really
about a model for being opposed to get
important and get
from stores what's your plan in terms of
those multiplications EP you expecting
those application providers to provide
are you going to use their api's to
extract data prominent application and
and coalescence aggravatin into a
central big data store how you actually
going to okay so the question is uh
who's going to expose this link data and
then how's it going to be used to these
epic for the applications to be linked
to get together so I think both cases
are so the first and how they expose it
so within our products we have a couple
different patterns we see some of them
it's how it works the product is built
that way so there is no other way to get
the data other than by this model so the
other is some have been traditional and
have some relational model and then they
have some persistent logic over it and
then we expose some application logic
that exposes it that way so it's a bit
more direct so you're still getting live
data but it's going through if you will
a couple transforms to get to the rdf
but that's and then the other end of it
the application is just consuming that
link directly so it's not going through
enter any middleman if you will to the
house that data to then provide it to me
so there's a point-to-point integration
okay so if you go an application an
application a providing then then it
would use the phone Scott's establish
right yep the asian a device provide yep
yep so images of your stock
so the price is always changed so do you
keep on history's as you go
so the question was and we talked about
the net worth and the in that example
when you look at certain assets those
values change a lot so how do you keep
track of the history and notification so
from I guess that's depends on how you
want to do it we're just showing you how
to expose the data we we haven't I don't
know if you know there's a need to
express at that level from the protocol
in the format you know what what you
should expose their I think that is how
you model that application so you might
want to say here's the history
associated with it and maybe add a new
term to the to the current one and say
you know here's the that you know a
pointer to the history resource then you
can do a get on that and then you can
learn about all the transaction history
and that might be its own collection or
container for that information you know
that asset history so it can be modeled
I guess however you want to do it you
know whether an application just wants
to keep the latest or a link to the
history
any other questions
thank you enjoy the conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>