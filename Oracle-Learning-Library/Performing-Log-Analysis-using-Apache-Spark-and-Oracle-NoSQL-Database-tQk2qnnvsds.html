<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Performing Log Analysis using Apache Spark and Oracle NoSQL Database | Coder Coacher - Coaching Coders</title><meta content="Performing Log Analysis using Apache Spark and Oracle NoSQL Database - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Performing Log Analysis using Apache Spark and Oracle NoSQL Database</b></h2><h5 class="post__date">2016-08-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/tQk2qnnvsds" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi
in this demo you're going to learn how
to perform log analysis using Apache
spark and Oracle no sequel database for
the purpose of this demo we've already
installed Oracle no sequel database and
Apache spark Oracle no sequel database
is running on port 5000 and has a store
named KB store these are the steps that
we will be following to perform log
analysis step 1 viewing the contents of
a log file to perform analysis we'll be
using the log files generated from a
performance test in one of the no sequel
machines
let us open a log file and look at its
contents
each of these log files have five fields
log ID which is the unique ID generated
for each log file the timestamp in the
form of number of milliseconds this
allows for filtering of logs based on
time periods such as since last our day
and week log level are the severity of
the log which is info severe a warning
the host in which the data is stored and
the message saved into the database
we'll be pushing this data into the no
sequel database in the form of a table
using the push lock dot Java file step 2
pushing the log data into Oracle no
sequel database before we push the log
data into the database let us set the
Java class path to specify the location
of spark and no sequel packages we set
the class path using the set C P dot SH
file this file specifies the location of
all the spark packages and no sequel
packages to the Java compiler
now we are ready to push the data into
the Oracle no sequel database for this
we use the push logs the Java file
let us open this program in the VI
editor and understand the flow of steps
this program stores the log files into
the no sequel database and reads data to
Apache spark we use the create table
statement to store the data from log
files log files from all nodes are
collected into a single place before
processing and then for each file the
log entries are passed into fields and
pushed into the Oracle no sequel
database let us scroll down to the main
class here we create an object called KB
config and Link this object to the store
named Cavey store that we have created
in the OR key no sequel database let us
exit from the VI editor and compile this
program the program is compiled
successfully now let us run the program
using the Java command and providing the
location of the log files from where
push locks takes the data to be inserted
into the database
the screen displays a total number of
log entries being processed
step3 reading the log data from Oracle
no sequel database into Apache spark the
log analyzer program is used to read log
data from the no sequel database and
perform analysis in spark
let us open this program in VR editor
and understand the flow of the program
now that the log entries are in the
database we create a spark context
object named spark conf as highlighted
on the screen then we read the log data
from Oracle no sequel database into
spark using this code snippet the class
is primary key row and table input
format are provided by Oracle no sequel
database primary key and row are the
classes for keys and values respectively
and table input format is the class to
integrate spark with Oracle no sequel
database it handles the read access from
Oracle no sequel database it reached the
configuration parameters such as kV
store table name and hosts to connect to
the database
a successful execution of this method
returns an RDD next we specify filters
to the tool from the command line a
filtering is requested the filter method
is used on this oddity by passing an
appropriate filter function for example
if the entries need to be filtered based
on LOC level the highlighted code would
do the needful the Col method takes a
row as an argument and returns true if
the log level matches the required level
this method gets executed on all the
rows and finally the filter method
returns a new RDD containing only the
required rows
step four categorizing the locks for
easier comprehension while doing log
analysis you may want to know
information such as how many processes
crashed or transaction failures occurred
without caring about the process IDs
this code allows you to perform simple
categorization by replacing the numeric
values in the log messages and makes the
log comprehension easier now let us
compile this program the program
compiles successfully step 5
specifying filters - the tool from the
command-line let us run the log analyze
a program this allows you to use filters
to the tool and perform analysis in
SPARC let us search the log data for the
word name time there are 212 log entries
containing the word time in the message
field now let us look at all the data
that was created in the past week
the results shows that there was no log
data created for the past week lastly
let us find all the log entries with a
warning message there is one entry for
the search these filters are required to
find out how many processes crash - how
many transaction failures occurred to
perform further analysis
note that the log analyzer program is
written to perform simple analysis in
the real application it is possible for
you to do a more complex analysis this
brings us to the end of this
demonstration thank you for watching
this demo to learn more visit us online
at cloud.oracle.com</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>