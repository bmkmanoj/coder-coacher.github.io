<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deploying Oracle NoSQL Database on AWS in 10 minutes | Coder Coacher - Coaching Coders</title><meta content="Deploying Oracle NoSQL Database on AWS in 10 minutes - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deploying Oracle NoSQL Database on AWS in 10 minutes</b></h2><h5 class="post__date">2014-03-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zNocq8EFBgc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone my name is Abbi
Dube I'm a Hadoop and no sequel
architect in Oracle and today we will
look at deploying oracle or sequel
database on AWS
we will setup a three machine cluster
it's a very simple process you will see
that you can setup this cluster in less
than five minutes so what is Oracle no
sequel database it is an advanced key
value database the reason I say it is an
advanced key value database is that we
have added certain features certain
sophistications over a basic key value
interface so the basic key value api you
don't really care about the value thank
you when you have to read or write a
record you use the key now in our key
the key is segmented into major and
minor key which gives you certain
advantages such as data locality we only
use the major key when distributing data
and we also support transactions so as
long as the transactions are over the
keys that share the same major key it is
fully supported then we have a JSON API
okay this is another way of describing
the value so remember I'm the basic key
value API you the database is not aware
of what is in the value with the JSON
API we can describe the value with a
JSON document and in this case not only
are the fields visible to the database
so you can query the field directly you
can do aggregations inside the fields
but we also support scheme evolution so
if your JSON document changes in
structure you still continue to read and
write the data that was written with the
older format then we also have a table
level API this makes the design of your
database easier in certain use cases
with this API you will create a table
these tables are a little different than
than relational remember that you know
the table definition is just a metadata
it's something that we store as a
metadata it's not tied to the actual
data which is stored in your database so
just as we talked about schema evolution
with the JSON API similarly we have
schema evolution with the table API you
can change things like column names you
can add more columns delete columns and
and that will not affect the data that
is sitting in the database but with
table level API you can very easily do
design very complicated data structures
such as nested tables tables with arrays
tables with a parent and child
relationship and other things so with
that introduction let's get into the
tutorial for today and for this
installation and deployment the key
concepts that are relevant are topology
shards replication nodes and storage
nodes let's go through these one-by-one
shards are non-overlapping subsets of
your data okay for example you know if
you have if your data has hundred
records and you have two shards then
each of those shards will contain 50
records number of shards is set
automatically by the database so this is
what what called Auto sharding you don't
have to specify how you want to char the
data or how many shards you want to have
it's something that the database chooses
automatically based on the number of
machines you have in the cluster and in
doing so in setting the number of shards
the goal is to maximize your write
throughput the driver in our case Oracle
no sequel database driver
as a partition map okay so before we get
to partitions the driver uses an md5
hash function to determine the hash
bucket for your major key okay
we call these hash pop buckets as
partitions it's a static hashing so the
number of partitions is fixed and we
will see when we deploy the database we
will set a number for the number of
partitions and then this number cannot
change and it's a two-stage algorithm
well what this means is the the first
stage is mapping the keys to hash
buckets or to partitions so in this
example we have hundred partitions okay
so your keys will be distributed across
these hundred partitions the second
stage is mapping the partitions to the
physical storage okay so in this case on
shard one we have partitions one to
fifty and on shard - we have partitions
fifty one to hundred
the advantage of using a two-stage
algorithm here is if you change your
storage you add another shard you remove
a shard it does not require us to remap
your keys okay that mapping can stay as
is now each shard has at least three
replication nodes replication nodes are
logical and they are Java processes they
are responsible for reading and writing
data okay one of these nodes will be a
master so for each shard there will be
one master node and two replicas nodes
master nodes are responsible for rights
to that shard all the three nodes are
responsible for reads to that shard
now the next term is storage node
storage node is equivalent to a physical
or virtual machine and in a production
environment this will usually be a
physical machine with the CPU and disk
the number of this can be specified in a
parameter we call capacity okay so in
this example this is one shard we are
using two machines for this shard
machine one has two disks attached to it
so the capacity of machine one is two so
storage node one has a capacity of two
storage node two has a capacity of one
and therefore when the database is
placed the replication nodes it
automatically places two replication
nodes on storage node one and one
replication node one storage node 2 the
next term is topology and topology is
the overall layout of your cluster ok of
your deployment it includes data centers
so in this example there is one data
center which is called West it includes
all the storage nodes and remember so as
note of the physical machines so in this
case there are three physical machines
it will tell you the replication node
processes running on each machine so
each machine in this case is running
three replication node and then you can
also see the number of shards number of
shards here is is denoted by this rep
group or RG or G is equal to 1 RG is
equal to 2 RG is equal to 3 it means
there you have three shards three
subsets of the data okay so with this
terminology let's look at the steps
required deploy Oracle no sequel
database the first step is to create a
configuration file and this
configuration file has has various
information such as the host
a capacity of the storage node memory
requirements this configuration file is
used by the storage node whenever it
started okay so after we have defined
the configuration file we start the
storage node okay so remember stories
known as the machine right so this is
the basic machine so each of these
storage nodes is running a storage node
agent process and that is our second
step we start the storage node agent now
on this storage node agent we configure
the name of our kami store this is like
the name of the database then we deploy
one or more data centers then we add the
storage node to the data center we
deploy the administrative service which
gives us a web GUI to monitor our store
and we create something called storage
node pool and this pool is for resource
management okay once this is done our
first storage node is up and running is
fully functional at this point we add
the other storage node agents to the
data center okay so in our example with
Amazon will be adding three machines so
in this step we'll I'll be adding
machine two and machine 3 to the data
center the last step is creating and
deploying this topology so this is
basically the layout of our cluster so
in this in this step we will be saying
that this topology has three shards each
shard has three replication nodes let's
deploy it at this point the data store
becomes functional okay so let's look at
this in Amazon
these are the three machines the three
instances I have on Amazon these are
micro instances very low memory 600 MB
memory and 8 GB storage ok so if you
have set up a Amazon instance before you
you will know that this public IP
changes every time you stop and restart
your machine and then these machines
also have a private IP this private IP
remains constant
ok so once I am logged into one of these
machines I can ping the other machines
and using the private IP so the only
configuration here which is which is
relevant to AWS is if you go to your
security groups this is my security
group that I'm using for my instances or
in DB and for the inbound communication
I have to open all the traffic ok so so
that's what I have done here I've opened
up all the traffic ok
so with that let's login to our machine
1 ok so a dot p.m. file is the the
security the key file that that a blue s
sends to you when you set up your
cluster my AMI machines are our Ubuntu
so that's why I have the username as a
boon to this username can be different
depending on which which instance you
chose on AWS ok so now we are logged in
ok I have already installed so I have
downloaded the kV store file which you
can do from
from Oracle's OTN page you see if we
Google protein an Oracle or sequel you
go to this nice page on ot an Oracle on
sequel database this is a very
informative page you have comparisons
against almost all or no sequel
databases here go to the download
section and then there's these zip files
right so I downloaded my dot tired or GZ
file on these AWS instances and I
unzipped them and that's that's
basically where we are starting ok so
let me log into all the three machines
okay so you can see here like I have in
my profile in my dog profile I have
actually entered the internal IPS
because these don't change so you can
see like the three machines have 64 65
66
okay so 64 65 66 here okay so now we are
logged in d again I'm in my dog profile
I have two other variables which are KB
rude and KB home okay so KB loot is
where the database settings are stored
okay so when when we create a store and
you create a database insert records the
configuration file goes in KB root and
then all your data files go under KB
root KB home is the location of the
binary of the install okay so you can
you can set this up accordingly for me
when I downloaded this database KBC 2.1
dot 57 so i unzipped it in this folder
under home bun too and that is why my kv
home is in this folder you you know you
you can have some some different paths
as you want okay so now going back to
our steps here right so first step is
create a configuration file so i have a
hyper script and it's a one line command
but i've just put it in a you know in a
simple shell script which which I call
reset kV so let me just show you what is
in the script here okay so because you
know I have this cluster set up and
running this this has already a three by
three a three shard install of no signal
running I will remove everything so I
will remove the database folders just to
start from scratch okay so we can do
these settings from the scratch so you
can see that I am removing this KB root
folder altogether okay so once I have
removed this folder I again create these
directories KB root
then three directories for for three
different storage areas on this on the
storage node agent and then this is the
command to create this configuration
file
you remember create a configuration file
so the command is make boot config ok
the utility is make boot config and then
we pass certain parameters we we pass
the location of the root folder here we
pass the hostname so this is the IP of
this machine we pass a port where we
want to run no sequel database we pass
administrative port this is to to see
the web interface for monitoring this is
high range
fetch a range means high availability
range capacity so I'm telling this
storage node agent that the capacity is
3 so that the database can place 3
replicas on this machine memory and
these storage directories ok so it's a
straightforward command utility is
called make boot config once we run this
utility okay so let's run it once we run
this utility see this configure XML this
is the file that got created because of
this command ok so if you run if you see
what's in this file ok so all the
parameters that we just passed in host
admin HTTP port storage node ID memory
they just got put in this XML file ok so
that's what make boot config does so
let's do the same thing here on node 2
and node 3 ok so right now on all the 3
nodes nothing is running and we have
just created the configuration file okay
we have deleted all the previous
configuration files in fact that we have
deleted the previous database
altogether and we just created the
configuration file now the next step is
start the store in your agent so again
this is a one line command
it's just start KB stored or jar start
that's so that's the whole command I
have I have put that command again in a
shell script so that's easier to run and
let's let's look at that script before
we run it so the script is called start
SNA ok so as I said you know this is
just one line command and what we are
doing is we are starting the we are
running the the program can be stored or
char with the utility start and I said
ok so this command will start the
storage node agent ok so we do it on on
on each of the 3 machines that we have
ok alright so now we can we can see we
can check right what happened so we can
look at the Java processes so as you
know when we start the storage node
agent some Java processes should be
running so we can see here that this
start process is running and there's a
managed service which is running ok so
this the storage node agent now gives us
this capability of logging into the
machine and and doing some some more
interesting things ok the same thing
here you will see the same processes
running on all the three all the three
machines ok this is the one which we are
interested in my managed service this
means that now I can go and log in and
do something else I'd create a cluster
start a service things like that ok so
now we come to step 3 alright so now we
will be doing the bulk of the work where
we'll be naming our KB store deploying a
data center adding the storage node so
starting admin service so again I have
I've put it in this
file here deploy one okay and these are
just one line commands for for each of
these these sub steps it's just a one
line command nothing a nothing
complicated here so the first thing is I
am telling the name of the store I'm I'm
setting the name of the store okay and
just to make it easier I I'm actually
setting the name in this KB profile file
that I have and just passing the
variable here okay but you can you can
hard-coded here so you can say name of
this story is customer data for example
the next step is deploying the data
center ok so again I'm the command is
plan deploy data center and then you
pass a name name of the data center and
then the replication factor okay the
replication factor means how many copies
of data you want so in the slides that
we saw the default is 3 and that's why
there were three replication nodes in
each of the shards ok so once we have
the data center up we deploy the storage
nodes to the data center ok so here is
the command again deploy SN this means
deploy storage node to this data center
this is the data centers ID TC 1 and the
host name and port ok the next step is
we start the admin service ok because of
this admin service I'll be able to go on
a web page and look at the the store ok
and then for resource management we have
these two extra steps where we create a
pool ok this is a pool of the storage
node agents so I create a pool and then
I add my storage node storage node 1 to
this pool ok so let's let's run this
deploy ok so I had some echo commands in
there so we know everything is deployed
so we can see that this
tor was configured the name I chose is
my store then we the first plan was to
deploy the data center so it says
executed plan one plan one successful
and this plan is data center West was
deployed then the second plan was to add
the storage node to the data center
the third plan was to start the admin
service okay and then lastly we have
those two resource management tasks
where we I created a pool and added this
to the pool ok so now the important
thing here is the admin service is is
now running so I can actually go in a
browser ok now remember I can I have
started the admin service on this first
node right this is the first node so so
therefore I have to go to this IP right
in a production scenario ok so in a
production scenario we will have admin
services running on on all the 3 3
machines so that in the case this
machine is down you still have a access
to these this web GUI ok so you so this
is the web GUI right so I had the
private IP and then a port the HTTP port
right me set this port when we created
the make boot config file 5 0 0 1 and so
you can see here right away
that there is a data center which is
called West and there is a storage node
and this is the IP of this machine so
remember storage node is a machine and
the admin service is running on this
machine that's all ok we have not
started any replication node processes
right these are the master node and
replica node services this is the actual
service so we have not deployed anything
else we have just deployed this first
storage node ok so let's let's deploy
the other nodes ok so if we go back to
our steps we have completed these so far
ok now the other step is just adding
other storage node agent to this data
center ok
so I have it written here in clust
Sh okay so again you know one line
commands the only reason why I've added
it in a script is it's easier for me to
walk through rather than typing it
online okay so here is so first command
is it this is exactly same as the as the
command in the foot in the previous step
when I deployed this when I added
storage node to the data center right so
I'm saying deploy storage node to this
data center do Center one where the host
is now node two so this machine I'm
going to add this machine okay I'm going
to add the third machine here in this
command node three okay and then I add
these nodes node 2 and node 3 to the
storage node pool ok so that's what
these commands are doing pool join s
into s in 3 ok now once I have done all
this I will I will deploy the topology
okay so final step create and deploy
topology so in the topology so as you
know right topologies the is the layout
topology is this layout so you can have
multiple topologies right today you can
have 3 machines on tomorrow you can have
4 machines so whenever we create a
topology we give it a name so I can
refer back to the older topology you can
hear every word back to the older
topology so that's what I am doing here
I'm saying topology create with a name
with the pool right so that this is
where the resource management comes in I
am saying that use all the machines use
this pool which basically means use all
the machines in this topology and then
partitions so this is the number of
partitions okay so remember static
hashing we cannot change the the number
of partitions these are the hash buckets
so I'm saying that for this topology the
number of partitions is this variable ok
whatever I have said it and you should
you set it to a large enough number 100
or 200 is a good choice usually this
will create the topology ok so running
this command is going to create this
topology and then
running this final command which is
deployed is going to make it functional
it's going to activate it okay so let's
run this thing okay so the first thing
is the node two it has is deployed now
it's it's deploying node 3 node 3 is
deployed storage pools added topology
created with 150 partitions ok so I use
the number of partitions as 150 ok and
now it is activating the topology now in
fact we can even see this in real time
so see you see this so once when we saw
this before
the only thing that was available here
was this storage node 1 and as the
topology is getting deployed we see that
the the the topology browser is changing
in real time ok it's still getting
deployed boom perfect ok so it deployed
and you can see right this updated on
its own and now it is giving me the
whole picture now your database is
functional so it is saying that you have
3 machines in your data center one data
center we could set up multiple data
centers in this case we have one data
center West we have three machines each
machine has 3 replication nodes ok one
of those machines is running an admin
service so that's why we are able to see
this here ok and then this part here
tells you about the shards okay so our G
is our internal development terminology
for shards our G is replication group
which means shard so this is saying that
you have shard one shot two shot 3 ok
now another cool thing is is when you
come here you can see where on which
machine this this replication node is
placed so notice that the three copies
of this shard right these are the three
copies of this
three replication nodes inside the shard
each of them is placed on a different
machine to maximize high availability
okay and I did not have to set this up
right when we were setting this up I
never told it specifically to put this
replication over on this one this
replication or on the other machine
right it it does it automatically it
automatically maximizes the high
availability of your cluster so when I
told the utility that I have three
machines each of the machine has
capacity of three it will automatically
take care of this distribution so there
is no chance of a manual error where by
mistake you place two copies on the
single machine we have made it very easy
okay so now the cluster is up and
running right so five minutes that's all
it takes now we can look in the cluster
notice that it doesn't tell you where is
the master so it doesn't say which one
of these replication nodes is the master
so we can we can look at it here so if
we can go to the admin shell okay so
this is this is our admin shell right
this is this is where we we run all
these commands to setup the topology and
everything the shell in the admin shell
if I do a ping it pings each of the
machine and it tells me what is running
on that machine okay so it says here
that machine one has one master machine
two has another master and machine three
has the third master okay now remember
in this example right in this case when
it's saying master replicas replicas
these do not belong to the same shard we
can see it here master is from shard 1
our g1 replica is from shark 2 and this
replica is from shard 3 so it mixes it
up to maximize the availability okay now
let's let's do some fun fun activities
I'm going to shut down part of the
cluster and see what happens ok so you
have this cluster running ok let's say
we lost
machine three so the whole machine goes
down okay
so you know one of the one of the common
questions people ask is oh this is a
master slave so that means that if the
master goes down then then you know you
lose high-availability
right but that is not true right when
the master goes down the other two
replicas are going to elect a new master
and this election happens in in
milliseconds
okay so practically speaking there will
be no almost no effect on the
application so let's let's try that okay
so I am here on machine two and machine
three so let's let's shutdown machine
three so again to shutdown I I have
already created a script I will just
show you what it is it's called stop SNA
but someone line command is nothing
complicated it's just stopped that's it
utilities stop and it will stop the
storage node agent okay so let's run it
alright so the process is gone now this
will automatically update so let's let's
wait for a few seconds and this this is
going to be updated in case you have
load on the database where you're making
calls you're making read and write
request then we pass this information
piggybacking on those read and write
requests okay so it's not like an extra
call to the application driver right so
see I I'm now getting error messages
storage node three is unreachable okay
wrap node three is unreachable okay so
basically this the whole thing became
unreachable right the store is no it
became unreachable and the three
replication nodes became became
unreachable okay now let's go back right
and let's do another thing let's see
what happens because now I'm worried
right this master was on this third
machine so this means that my RG one
master is now unavailable right that's
what you will think so my your first
charge you cannot write anything to your
first shot okay but that is not true
let's see what happened
so now write this this became
unreachable okay but see what happened
here right here this guy from the RG one
group form from the first shard became
the master okay so now you have a master
now two masters are running on the same
machine and then one master is here you
can still do your reads and writes and
everything even though you just lost 33%
of your cluster are you lost a full
machine lost 33% of the cluster you're
still you're still up and running no no
problems now just for fun let's also
stop this one okay so I'm going to stop
this second machine as well I'll just
see what happens okay
this browser should update in a few
seconds as I said if you're if you know
it's a real scenario where you are
actually reading and writing data then
the the topology information the cluster
status is passed on with every request
as part of the metadata of that request
so this is this is a this is taking a
second but just because I don't have any
any load on this database okay so so
boom okay now now we get it right this
thing is down like this thing is down
all right the whole thing is down stairs
no.2 is down the three duplication or
the down okay now let's see what
happened what happened to the processes
okay now notice 67% of your cluster is
down okay this is a you know this is a
calamity even then you still have sort
of a functional database right the older
master in the master which was on the
first machine this belonged to our g3
which means this was the master for
shard 3
this is still running this is still
running so you can still do region right
on your chart three the other two
machines here right notice that they did
not become the master okay when we shut
down this machine then we saw that the
other machine became the master by
itself in this case the other two
machines did not become the master the
reason is we need a majority to elect
the master okay so when we so in our
shard there are three nodes which means
majority is 2 okay so we go back here
right so in this shard there are three
nodes majority is two shard three nodes
okay so when we shut down the the one of
the machines right the other two nodes
were still alive okay and this is
because of the placement the way we have
placed these replicas is this goes here
this goes here this goes here so even
when this went down right in our first
scenario when our and three is down our
n1 and our and two are still alive and
so they are able to elect a new master
and as we saw the master was on the
second machine so our and two became the
master okay in this scenario what
happened is now two machines are down
okay so now for our and one even though
I have a node which is alive here right
this you see this this are g1 are and
one is still alive but this cannot
become the master because it doesn't
have the majority to other nodes are
dead okay
what this means is you cannot do rights
you know even in this catastrophic
scenario all it means is you cannot do
right you can still do reads from this
so you can still you can still do reads
from from your shard one and even on
short - okay from this machine this
machine is still unknown because as I
said it's it's it's not is it cannot be
the master without majority or you can
they will still service read read
request okay so that's it
this
this is the end of the tutorial this is
all I wanted to cover today you saw how
you know how straightforward it is to
install and deploy the database on AWS
basically these are the steps 1 2 3 4 5
5 simple steps and your database is up
and running we also saw a little bit of
a che in play right so we shut down we
shut down one machine and we were still
fine
the master relocated and then we shut
down another machine and and then we see
that only one machine is alive and and
we have one master and two nodes which
cannot be the master right in fact if
you start the service again you can you
can start the service again ok so if you
start the service again you really don't
have to do anything it just
automatically joins the cluster it
already knows that it has to join the
cluster ok so you will see that you know
this this thing gets updated
automatically so you just started the
machine again right no recovery or
nothing like that and boom boom boom
starting starting starting everything is
back back to normal ok ok this alright
you do the ping again and see so
automatically everything is back ok
back to back to where it was alright and
in fact what has happened is because
because in one of our scenarios we fail
this machine and there were two masters
on this machine this machine still has
two masters so this this again the
database takes care of it so the
database notices it will notice that
there are two masters here and it will
do a rebalancing and the master will
actually move to this machine ok
see see what I'm saying right here okay
so it ought it will notice automatically
so we don't I didn't have as an
administrator I didn't have to fix
anything to move this master okay
automatically in in a matter of seconds
the master relocated to the new machine
okay and that's that's really the power
of Oracle no sequel database fee we try
to make it really simple to administer
okay so thank you guys that's all I had
today check out other videos of Oracle
no sequel database we have some really
nice videos on data modelling and other
other videos on deployment as well thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>