<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Java Batch for Cost-Optimized Business Efficiency | Coder Coacher - Coaching Coders</title><meta content="Java Batch for Cost-Optimized Business Efficiency - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Java Batch for Cost-Optimized Business Efficiency</b></h2><h5 class="post__date">2013-02-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TIelF3j760M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the session my name is
sridhar sue larson and i'm with IBM i am
actually a part of the watts and i don't
know how many guys are familiar with
Watson here if you guys watch jeopardy
it was a computer that we built last
year an expert system that actually
played jeopardy against the two
champions ken rudder and bread jennings
and one so we're now trying to apply it
on cognitive systems so we're using a
lot of java there as well so i just
moved to that group but prior to that
for a while i was and i still hold some
of that responsibility I was the chief
architect for IBM's batch processing
strategy so like a few years ago we
realized the importance of Java
importance of batch in enterprise system
continuing to grow and expand so as a
result of that I kind of took this
position to look across our technologies
and portfolios and system z and
distributed platforms to see how we can
enable modern batch or what what kind of
things we can do to enable batch systems
right and also work with a lot of
customers so we'll we'll spend some time
today talking about why we're going to
be you know what's the IC this works it
did when I tried it earlier ok there you
go so what we'll talk about today is you
know just a very little time on why you
know batches relevant or important and
continuing to grow I'm sure a lot of you
how many of you guys work on on batch
using any kind of Java today oh very
good a lot of you excellent so obviously
you guys probably realize why you know
how why it's important and why it's
continuing to be important I'll touch
upon a couple things and and you know
you may or may not already be doing that
but if you're not hopefully it'll open
up you know some some more ways for you
guys to think about how we've seen you
know a lot of customers using batch and
how we've seen the trends across
industries here so I'll spend very
little time
that and I'll talk a little bit about
your badge platform in a solution like
why do we need a platform for doing
batch right and for the longest time
we've been doing bad solutions for what
40 years now iBM has been a big player
key player that obviously now there's a
lot of technology changes in innovation
that we want to bring in to the to the
pictures we'll talk a little bit about
that and what that entails just from a
reference model perspective right and
and and then we'll talk a little bit
about Java and batch and I don't know if
you guys are familiar with the fact that
there is a GSR currently under in place
for batch so that's something that I'll
spend a little bit time talking about
that our interview guys active
contributors and in the GSR okay so
we'll spend a little bit time talking
about that and kind of how that came
about and what we'll spend a few minutes
on the concepts are on that and then
we'll talk about some of the offerings
that we have from IBM around batch I
don't know if you guys use or are
familiar with the WebSphere application
server which is basically a GE server
and you guys use web strap server ok
good so essentially we have batch
capability in the WebSphere application
server now so i'll talk a little bit
about what that what that is and and how
it looks like and how you can actually
leverage it and then I don't know if
you'll have time you only have an hour
but depending on how it goes i'll see if
i can quickly cover a couple of
scenarios that we've actually used at
customers doing batch and what what
they've what that entails and talked a
couple bit a little bit about some best
practices right and the charger should
be there up uploaded so you should be
able to get to it I did put some charts
in the back up so that you know more
information on the jsr because we may
not have time to go into all of that all
right so um in in in general you know
sometimes when when I when I've gone
into enterprise solutions with customers
one of the things that comes across is
well
why don't we just use real time why do
we even need back so let's just move all
badge to real time unfortunately it's
it's cool if you could do it but it's
it's not scalable it's very very
expensive to do things real time right
the economy the reason you do batch is
so that you get the economies of scale
and the fact that you can actually
optimize and make things more efficient
right that's that's the big biggest
driver for doing things in batch right
and that that's continuing to continuing
to be the case now especially going
forward as you know more and more as we
support and build more and more products
right whether in your bank or you're in
an insurance company or retail shop
manufacturing shop more and more
products that you build more and more
channels that you support more ways of
accessing your customers right growing
customer base essentially what that
means is a lot of data right the data
amount of data is growing exponentially
and in order to be able to process that
in various ways you know batch becomes a
key component because again like I said
it's it's processing things in bulk so
that you get the efficiencies right the
economy of scale now the picture is
actually I don't know if you've you know
it's and it's an interesting trend that
we've observed over the last few years
here you know generally we be view batch
as sort of being an end of day
processing right something that you do
where you have a fixed time or a
scheduled time that it starts and a
scheduled time that it needs to end by
so that you know further processing
online processing can happen things are
all updated you know balances are
updated inventory is updated etc so that
you can continue processing you know
more like online cut transactions right
whether it's reconciliation and so on
now what we have been seeing right and
again this is a this is something that
is being driven by your end customers is
that the need to have access to
information in a more real-time basis
right so what that has been what that
has been trans
waiting to in the in the back end in the
enterprise is that your your end of day
batch now you still need to do end of
day in some cases right but but more and
more there are opportunities for looking
at that batch window right and I said
earlier that the amount of data that you
need to process is growing significantly
the window that you have to process at
night is shrinking right because your
clients are now becoming more global so
there's really no no time that you can
actually shut down or slow down your
online and or shut down your online and
just run your batch right dedicate all
your resources for running your bat
systems so essentially what that is
doing is that and this is a classic
problem that you know when I was talking
with with a Swiss bank you know they
said yeah we have this shrinking
shrinking time problem right how do we
process more and more data within a
shorter amount of time right so one of
the solutions I mean obviously there's a
lot of ways you can address that but one
of the things that we've seen as a trend
in general is to kind of do this elastic
batch concept right where I take that in
whatever was at night and I may still
need to do work at night but what I'm
doing now is I'm kind of trying to
trickle my badge throughout the day as
well so this whole notion of being able
to run a batch along with my real time
along with my best message based you
know any kind all of these different
processing in a 24-7 basis without
affecting each other's or one another's
SL ace right I think that's the key and
and we're continuing to see more and
more of that growing right so what that
translates to is is an intelligent use
of the resources the hardware resources
being able to share your your your logic
your business logic right being able to
share your people that are building
these systems you're not building
disparate batch and real-time systems
right and one in certain using a certain
technical technology another one using a
different set of technologies and so on
just the optimization is different right
so if you're processing a claim as an
insurance company the way you process a
claim is is exactly the same whether you
do it for a single
West and wait for a response or whether
you do it for you know million of these
that come in from you know various
agents that you have right so the actual
process that uses the business process
or the business logic is the same so
this is different ways of optimizing the
two what that does I mean there's
there's significant benefits that you
can see out of these right and and they
involve different degrees of changes so
when we were talking to a core banking
come banging company you know one of
their core banking applications their
retail bank guys you know he was like
well if we can do this this makes this
kind of changes our whole perspective on
how we do our back-end banking
processing for example today what they
do is all of their core banking
reconciliation of the accounts and the
payments and postings and interest
calculations they do that at the end of
the day because you know once the branch
is closed they send files and then these
files are then processed and then
they're ready for the next day right now
instead if we could do apply something
like this what that does is now I can
obviously the other extreme of the
spectrum is to send these every single
time which is very expensive so this is
kind of meet in the middle scenario
where you're doing this throughout the
day but you're doing it in smaller
batches if you will right so as soon as
you and these could be determined by
business rules like once I reach you
know million dollars of processing I
want to send it over or one side you
know every two hours or it could change
right and if depending on how your your
activity is you could change that and
optimize it accordingly right so you're
essentially putting the control of when
and how these are invoked in the hands
of your an expert and SME like a branch
manager or somebody at the bank branch
now what that what's what that is doing
is now in the back end what we're doing
is we're continuously processing these
and as technical people you know one of
the some of the red flags that will come
up is well what about concurrency what
are you doing about you know database
contention what if you're trying to
access the same kind of records so
there's that done that's kind of where
we started recognizing
these challenges and we started building
some solutions so we have several ways
and obviously it's not a one size fit
all right so we have several different
ways that you can actually address those
kinds of challenges right at the data
level at the application level at the
scheduling of these jobs level at the
run time in terms of how you prioritize
one request versus the other what you
don't want is running some of these
batch jobs on the same resources and
then you have a glut of online requests
that come in and you have you know a
smaller small amount of processing for
that right so there's ways that you can
actually control that right if there's a
peak activity that comes in from our
online you can actually suspend your
batch slow down your badge and that's
why you see these varying levels of of
batches that you're running throughout
the day right but essentially the point
is that you're you're you need the
ability to be able to split a large job
in two smaller ones stop them pause them
resume them you know collapse them
together there's there's all these
things that you want to do at the data
level you want to be able to vary the
amount of time you acquire the locks on
the tables for right if you're accessing
relational databases so there's there's
some things that we do with
checkpointing in terms of how you
dynamically change your checkpoint sizes
depending on what kind of workload you
have right so essentially all of these
kinds of things is what we have we kind
of consider when we built this the Java
batch solution if you will right or the
platform and we'll talk through a lot of
these things but I just wanted to lay
down the premise for this before we move
off of this I want to talk about one
more thing right there's so so I talked
earlier about how people want to move
all batch to real time there's the other
end if if you want to think about it
from the other side right if you
approach it from the other side it is I
want to move what I'm doing real time
today but it's expensive to batch right
so so what does that mean so think about
an example where let's say you're you're
reserving
um reserving a ticket on on for for an
airline or or or for for for some
concert or whatever right now when you
do that essentially what you're doing is
you walk through a bunch of screens and
you know you you pick whatever you need
to pick all your options and at the end
of it you kind of submit and make a
payment now typically what you expect is
an email sort of comes to you within you
know a few seconds right now if that
you're not instantly expecting an email
to come so it's technically not real
time right but sometimes there are these
processes which do treat that request as
a real time request and an email does
come to come through to you now if you
batch up now at anything given time you
know if you're on on an airline website
or travel company website there's
probably you know hundreds or thousands
or millions of people that are doing the
same kinds of things right especially if
you think about like concert tickets and
stuff like that so what if I batch these
up into very very small intervals like
10 seconds I collect these requests that
come within 10 seconds and I send these
all all at the same time right so I
batch them up and I send the email for a
consumer if I'm waiting 10 seconds for a
confirmation email is that really
affecting my perception of this this
website or this application perhaps not
and 10 seconds is just something that
I've used maybe it's five seconds maybe
it's two seconds maybe it's 25 seconds
but the point is that I'm really trying
to what I'm trying to make a point on
here is that the key is where we're
looking where we were looking at things
as being a continuous real-time sort of
process now we're looking at
opportunities where we can bulk them up
and then gain efficiencies now sometimes
they actually can translate to real
business value as well right so for
example even in that ticket or account
opening scenario for example if you're
opening an account through a bunch of
screens that you pass through there's an
address validation that happens you know
there's income validation there's credit
score calculation there's a lot of
things that go on in the background
every time you click through those
screens right if from an online
application now
imagine and obviously you pay a third
party to do that kind of stuff right so
you pay some third party to do an
address validation now you do that for
every single request what if you're if
you as a business person could could
have a contract with them saying look
I'm going to send you 50 of these at a
time or 100 of these at a time it's
going to be easier for them to process
right a hundred at a time which is one
at a time so and and and these hundred
maybe you know every two seconds or
every five seconds right depending on
how your what kind of business you're in
but what that effectively does for your
business is to say is to negotiate a
better contract saying hey you know if
I'm paying you a dollar for every
address that you're validating for me
now that i'm going to give you 100 at a
time maybe I don't pay you a dollar for
a hundred but I'm also not going to pay
you 100 dollars let's talk about
something in between because it's better
for them they're getting it more
efficiently done and and you can get you
know better business value out of that
so I mean again the point here is that
you you can think about the other
extreme and some of these technologies
start letting you do some of that right
so the previously the reason we didn't
do it is because we didn't really have
any technology to enable us to do that
so so that's essentially what the what
the purpose is right now some of the
common batch patterns I already talked
about some of these be you know
especially when you're doing service
oriented architecture when you're doing
services transformation there's a lot of
neat about what do you do with all your
batch jobs right do you leave all your
batch jobs as is and you do service if
occasionally if you're you know whatever
is your real time or online type
applications perhaps in some cases but
maybe not in many cases right there is a
need like I said in some cases to pull
your batch jobs as well into your
service oriented architecture so that
you know what does that mean you can
invoke a job as a service a batch as a
service and you can have all of the
batch participate basically as a
first-class workload in any process that
you're creating any choreography that
you're doing of a process right so
essentially that's what the
course the the big thing is from a SOA
perspective it allows reuse right you're
reusing your your work you're reusing
you know people resources you're reusing
you know reducing maintenance costs you
know you're doing a common build you're
doing common deployment and and so on
right so essentially that's what you're
getting here is is is not only just a
better run time but you're also getting
a better sort of a full life cycle model
there from a you know mainframe I don't
know if some of you guys use mainframe
here or work on z/os well great okay a
lot of you so on mainframe you know
that's another thing that we've seen
quite a bit where you know as you as
some of you know batch has been running
on main frame for four decades now right
and and one of the questions that come
up comes up is how do I modernize what
I've got right i mean as my skills are
dwindling about people who have written
these things you know 30 years ago 15
years ago how do i how do i start
leveraging modern technology i still
want to stay on the mainframe on z/os
but how do i leverage that and start
being able to you know optimize what
I've got reduced the MIPS reduce the
cost of MIPS that I'm using today right
which is basically the processor speed
on on the mainframe and that's how
people are charged right so so Java
allows you to take advantage of some of
the specially priced engines that IBM
has got which allows you to do it you
know a lot cheaper and and the
performance actually in some in many
cases is on par with what COBOL does as
well right the what I'm not suggesting
is that every COBOL has to be
transformed to Java but there are
opportunities in many cases and and a
lot of customers are doing that as well
right there's actually the biggest
reinsurance company in in the world
Swiss Sri which is based out of
Switzerland there is actually embarked
on this a few years ago about four years
ago where they're running moving there
cobol into java but running on the z/os
and they're seeing an excellent benefit
from a price as well as from
a performance perspective right ee the
shrinking batch windows we already
talked about that from an agility
standpoint again you know the the whole
purpose like I said is from a reuse and
being able to use Java as a framework it
allows you to component eyes your your
your business logic separate from how
you need to optimize for batch separate
from how you're invoking your batch and
when we talked a little bit here about
the about the reference model kind of
show you how you can obviously the more
componentized your solution is the more
the more aged all it is the quicker you
can make changes to it and so on right
so here's here's a reference model that
that we created a few years ago when we
started talking to customers about you
know some of this these concepts one of
the things was well what what do you
consider in batch right and what what
are the different parts that we need to
think about so again and again by
intention this is a reference model what
that means is you know you don't need to
have every single layer here but when
you're when you're looking at your own
batch applications or your bad solutions
whether it is a new one or migrating one
or or using an existing one that you
have it's good kind of good to think
about all of these different components
right in the model so for example if the
way to look at it and again given that
we only have an hour I can probably
speak for half a day on this but given
that we only have an hour I've just got
this one chart on this page in this deck
and and I'll quickly talk about it but
the way to read this is what you have
here on the left is is the development
right what is for what do you need from
a batch application development and
deployment perspective so that includes
you know your tooling your collaborative
development how do you do how do you do
your you know team development what kind
of tooling use for doing unit testing
how do you do you know debugging builds
my and so on right and essentially what
that is is it covers a lot of different
you know best practices around doing
that you know what kind of tools you
have available how you can go about
doing that what are some methodologies
that you can adopt that you're probably
already familiar with if you work in
Java just on a regular you know Java
online or je je tu seÃ±or je kind of
applications how you can apply similar
principles for building batch
applications right so the the motivation
really as we started doing all this was
me as a Java developer I want to treat
all applications alike batch is just one
way of invoking the same application
that i right right and online is another
way of invoking the same application so
as a Java developer I should really be
abstracted from the things that are
really specific for for batch as a
business domain application developer as
now there's certainly like I said
there's optimizations you need to do for
for batch and so you know that's why
we've got a programming model we've got
we've got the extensions the API is the
SP is that need to be extended and and
you can build these fairly
straightforward way right using pojos
basically and the other thing that we've
done so so that's that's your
development piece what you see on the
right here is his system management and
operations this once you have a batch
job or a set of batch jobs or
applications deployed in your
environment right and along with your
your other applications that you're
running then the question what what this
area covers is you know how do you
manage these what kind of operations do
you need now chances are you know if
you're running a lot of batch
applications in your environment today
you already have some operations and
procedures and and run books and so on
in place so this this talks about if if
that is the case then how can you keep
the number of changes required the
amount of skills the learning curve for
the operators to be a minimal right the
kind of the kind of change that they
need to go through to be minimal and
replicate the same experience in in this
new environment that we're coming
through so that's kind of what that
talks but also talks about you know
monitoring scheduling from an enterprise
perspective security you know how do you
handle all of that roles and
responsibilities and authorization and
so on and so forth right so that's what
the that's what it means by you need to
think about and cover all of those
pieces the center here is all of the
center is around specifically your
runtime and your applications that
you're building right so if you look at
it from top down essentially so given
you know if you think back to that
picture that I showed a couple pages ago
where you have your twenty-four-seven
you know real-time and batch or online
and batch all running at the same time
what that does now is it kind of makes
the notion of my batch jobs being
scheduled and starting at a scheduled
time kind of become you know less
significant right or or not less
significant but but less prevalent if
you will right because now what I'm
doing is I'm running these batch jobs
throughout the day they're still or jobs
that may be scheduled which means they
either start at a certain time or they
start after a certain number of
precondition jobs are completed and so
on but so there's there's the scheduled
services but there's also these ad hoc
kind of jobs that now come in right
which means they start because you know
you you are doing some aggregation and
you reached a million dollars of
aggregates so you kick off this batch
job you know files come in and and
something else you know basically they
reached a certain a file size limit and
then you kick off another batch job so I
mean there's there's a number of
different things you can think about
right i mean like i said whitney in the
address validation either when i reached
10 addresses or if i reach five seconds
or 10 seconds kick off a bad job at the
time so there's a number of different
triggers or invocation triggers that
that essentially kick off these bad job
so you want a way to manage all of those
services right and even if you're doing
it as a part of a beep out process
you're kicking off a bad job then you
you want to know what that invocation
service looks like
what because now that now that you're
running these jobs along with you know
other workloads you're sharing the same
system resources that opens up you know
other challenges right what what I
talked about earlier how do I manage the
SAS across these workloads in a real
time in a in a real-time transaction if
a user is clicking submit he or she is
actually just waiting for a response you
can't let that you know go beyond
whatever your SL azar whether it's
ninety percent of these users have to
you know have a response time less than
a second or so so you cannot violate
those essays for batch it's more around
you know it's not response time it's
really throughput driven right or its
deadline driven sometimes it is I need
to do this as soon as possible but I
cannot exceed beyond six a.m. or 6pm a
certain time right because if I do that
then I'm going to start you know
affecting my my downstream applications
or I'm going to meet I'm going to miss
my deadline people you know 15,000
people are not going to get their
paychecks and me as a CIO I'm going to
get fired right or I'm going to pay
penalties which is even worse so so
batch has their own s la's right and and
and essentially what that optimization
layer does is it kind of looks at all
these different parameters right so how
do you look at all these policies and
manage the resources that you have
available across all of that so so like
for example in the WebSphere solution
there are ways where you can actually
set up these kind of policies by an
administrator an administrator can set
up some of these policies and underlying
applications then are running
accordingly right priorities are
provided a crow appropriately you know
notifications are sent appropriately if
you're at a risk of meeting a deadline
and so on so for example if you're
nearing your your deadline for
completing your batch jobs then your
online kind of end you're at risk of
completion then maybe it's okay to kind
of exceed that online SLA s within still
staying within your policies so maybe
your policy said ninety percent have to
have one second or less but you know so
and you're running a ninety-eight
percent you know at one second or less
maybe you kind of slow that down a
little bit to give a little more
capacity for your batch which is on the
other side if you get an unexpected you
know some market event occurs and
there's a lot of trading that happens
right people are trading or people are
buying stuff or selling stuff in a
retail type scenario then in that
scenario I want to make sure that i
satisfy all of my you know online
customers and so I slow down my batch
right I trickle my batch now sometimes I
actually joke about but it's actually
true if you think about it that a batch
applic or a wreath if you optimize your
applications for batch you technically
can optimize them for real time
automatically in in some ways right
suits because if you think about it your
your online app is or an online request
is nothing but a batch of size one with
zero latency right I mean if you treat
it that way then it's really all bad
right man I'm talking about a trickling
down of badge the the the other extreme
of how you actually manifest itself is
that you know I have just one one one
record that I'm processing and I'm not
doing any latency so I'm not preventing
when I'm actually storing it I'm just
passing it straight through so I'm again
one way to think about right the
container is what will spend you know
some of our time here on in the next 10
or 15 minutes essentially the notion of
needing a container for bath just like
you have in Java is or in online for
java je e and so on is that your you're
basically pushing down a lot of the the
repetitive work the qualities of
services that you need down into the
container and let it handle stuff right
so the transaction services the check
pointing the security pieces the thread
management priority management all of
that you the notion the idea is I mean
it's centrally the same kind of I
Yeah right mean 15 18 years ago 15 years
or 18 years ago whenever Java came out
you know we were all building thread
pools and web containers and you know
Java containers and transaction managers
and all that good stuff right but then
you know once we decided that well we're
all doing kind of the same things until
we formed you know like the j ee specs
for example right and the reason for
doing that was you know a lot of these a
lot of these qualities of services
services we could push down and and
that's how we have you know these
different containers right like the app
servers essentially that implement these
batch i think was a few years behind but
we caught up right same thing we were
all building we're on a lot of you guys
are doing batch i'm sure a lot of you
are doing very similar things so when we
realize that a few years ago we started
pushing these things down into the into
a container right so that's what the
container does it kind of does the same
thing if you think about it from from a
you know each a bezoar web containers
think about this like a batch container
which basically does there's all those
common functionalities provides you
those quality services and then you
build your applications on top of that
right so that that and well I think I
have a chart on that as well what you're
doing with the data now by definition
you're running a lot of data when you do
batch a lot or a little but you're
working on data and and so the data
access management services is really
just your standard notion of separating
your data frame your application and
your data could be in any form right
could be barbecues in memory etc it
could be your your cobalt copy books and
so on right and the reason you separate
it from an information storage again
that's optional but the reason you want
to separate it is because there's
opportunities in a batch to do different
kinds of caching to optimize your
applications like you're different from
doing in-memory caching and so on right
so for example in a batch if you know
that you're operating on on accounts
that are from a particular branch right
in a file it's a you get a million of
these and they're all sorted by account
numbers that all start with certain
in a certain way that the accounts have
been defined where they are all belong
to the same you know either type or the
same location or the same zip code or
whatever it is the way you can group it
in a way of caching is to preload you
know whatever information you need to
process rights or transaction data etc
for that kind of that category of
accounts and then the life of that cash
is just till you finish that batch
process so once you finish that you
flush it out and you're done so it's a
more shot lip cash right so there's
there's again a number of opportunities
that you start getting around how you
can cash some of the information for
batch jobs and that's why we kind of
separate the two right and there's
various strategies you can apply in
terms of how you do it the
infrastructure services is really
depending on you know where you deploy
right because it's all Java we we want
it to be behaving similarly but there
still no matter how much we say that
there's still differences depending on
how you deploy it and where you deploy
it and so on right so for example like
if you deploy it on on a-z system
there's there's some inherent advantages
you get from using the Z workload
manager and all these capabilities that
are already built into the operating
system versus if you deploy it on a
Linux distributed server you get a more
you know you get a different kind of you
know performance price ability to
partition your your data partitioning
your applications and so on so so that's
just what it is is when we when we do
all of that we build it in a way that
knowing what target we're going to
deploy it on you can take advantage of
some of the underlying capabilities that
exist analytics and not autonomic it's
not like predictive analytics or
anything it's really around how do we
analyze the jobs that I'm running as a
whole look at the resources that I have
look at the data that I'm processing
look at the applications that I've got
the application server instances I've
got and how do i optimize it across all
of that so there's a lot of things like
at least in the Webster case the because
you layer it in this way and you create
that separation of responsibilities
there's opportunities for doing this
kind of optimization and like and the
way the minutes it's pretty clear
because in websphere bad for example we
have built in a lot of these and we
continue to do that right as we learn
more as we deploy more app in more
environments we continue to build in
these kind of automation these kind of
autonomic so that you essentially been
as an operator it makes your life
simpler as a developer from a tooling
standpoint makes your life simpler and
you don't have to program as much as you
would if you didn't have these kind of
optimizations and so on right so
essentially it's about you know making
things abstracting things out and
providing the right kind of controls or
tuning parameters to the right to the
right role if you will right and like I
said there's a lot of work behind this
maybe I took a little longer than I
wanted to but but I think it's important
to understand that right here's an
here's a page so we talked about we
talked about how we have these different
layers right and so essentially you have
your application and when I talk about
these qualities of services and what you
have within a container essentially it's
everything that you see that is not in
yellow right except that batch
application which is what you want to
write based on the requirements you have
the needs that you have you know
whatever your your design team is giving
you or whatever you're designing
yourself that's your application you
really want sorry you really want to
push down everything else not from a
processing perspective processing as
well but even from a development
perspective into the container as
possible right so you have your runtime
engine you need to have some way of
managing your jobs that's your job
control language right and it's
decorative you want it to be where I
don't have to modify any code so it's
imagined and so think about it as being
configurable but being standardized some
of you that are familiar with with z OS
and and the mainframe are probably also
familiar with JCL which is your job
control language so it's kind of similar
our model right i mean there is a reason
why that's still so successful right
it's been it's very solid it works we're
trying to adopt something very similar
here as well right so that's well the
whole decorative job definition comes up
and and of course now it's xml-based
this is also there in the specs by the
way right and for example in the
WebSphere batch in mind when we call it
an X JCL which is an XML form of
providing that decorative job definition
the batch container like I said is think
about it like you're you know any other
app server container basically it's
doing all that work optimized for batch
you know that then there's a dispatcher
or scheduler which really manages how
you dispatch the workload how you manage
you know different limits that you have
so you know you don't just bombard your
system with with requests as they come
in with job requests as they come in and
then and then cause you know unplanned
outages and system downtime and so on
right logging in archival the PGM is
really parallel job manager so it's
around how you manage paralyze your job
remember i talked about how you can
split your job in two parallel streams
combine the results all of that kind of
stuff right workload management high
availability and so on okay so a couple
minutes a few minutes on on the GSR so I
think we started this sometime last year
we've tried this a few times in the last
few years but but last year we we
actually started this you can see some
of the expert membership in the in the
in this community IBM Oracle VM ware
Credit Suisse red hat and some others
Chris vignola who is actually also a
good friend of mine who is the architect
for 10 far up for the Webster batch
platform is also the spec lead for this
jsr and essentially the the idea is that
we took a lot of the concepts that we
had that spring batch had if you
familiar with spring batch and and we
try to build the standards out of that
right so what is a job what is a job
step how do we do checkpointing what do
you do how do you do parallel job
management what's an execution container
all of that that's what these spec
really focuses on right and essentially
that's what we that's why we have the
programming model the target is to bj
java ee or SC I think we we're delayed a
little bit the plan the intent was to
close the spec by the summer but I think
we've delayed it to the to the end of
the year now but there's a there's a
link oh did I do that there's a link on
that on the charge that you can see to
the community itself to the to the
homepage of the community and there's
also mailing list that you can subscribe
to right so it's it's one of those where
the proceedings are transparent you can
actually even not only to subscribe to
but I think you can also contribute to
it ok so I'll spend like I said a couple
charged on our slides on what these
concepts are so you can read the text
but essentially it is the job repository
consists of you know a number of jobs
where each job consists of a number of
step or can consist of one or more steps
and and there's definitions for each of
these I think you can read them they're
right and what what you're what you're
doing is a job can comprise of multiple
steps that always go together right in a
certain order they can be sequential
they can be running in parallel but the
notion of having a job in a step is that
they always go together right so that's
why you don't you call one job and that
has like three steps or four steps or
five steps sometimes you may have just
one step the the way the step is
processing is essentially you have then
you execute your step there's an item
reader so if you think about the
simplest of batch jobs what you're doing
is you're reading data you're processing
data you know and then you're writing
something out right in the reading and
writing
probably optional but the writing
certainly is optional but you're reading
you're processing and your writing and
you do this in a loop till you run out
of records that you need to read or to
Lu come up with an exception where you
can't proceed any further so that's the
the note the simplest of batch now
there's there's complexities when you
start needing to do check pointing in
between right you don't want to commit
only at the end of all your record
processing because then if you have a
failure you have to start from the
beginning you don't want to commit after
every single record because committing
is very expensive and committing at the
end of every record makes it an online
transaction right so then there's no
difference what you're doing in a batch
is you're doing a checkpoint which means
you're doing something that is between 1
and mm and and typically that has been
done as a you know you do it every five
seconds you check point on a time-based
based on time or you check point based
on some records every time a process you
know 500 records I do a checkpoint or
five thousand records I do a checkpoint
what we also do now is we do like I said
dynamic checkpoint so I want to do you
know or I want to have my own algorithm
I want to do a time-based but I also
want to do it every time I do some kind
of aggregation some business logic
triggers a checkpoint as well so there's
that but then the dynamic is that I keep
changing it for the same job for the
same set of records that are coming in I
want to change the way i do checkpoints
so if you think back to that picture
that I showed where you run your your
real time and your batch jobs throughout
the day right would be pink in the blue
arrows essentially the dynamic
checkpointing there is if I'm if I'm
approaching and now and if you think
about what that what the implications of
doing your back your check pointing at
different intervals if you check point
add larger intervals then you're holding
locks for a longer time to checkpoint at
shorter intervals you're you're you know
you're obviously going to slow down your
processing but here your concurrency is
not as affected so there's there's pros
and cons for each but that's where we
can actually play around with some of
these to see how you can you know
depending on what you need to process
quicker or who you need to get more
prior
to the whole meaning the online versus
badge you know we can actually manage
some of that right we can do some of
that dynamically we can do that
programmatically etc right and so
essentially you have your item reader
your item processor and then your your
item writer and your prot end and this
basically happens in a loop like I said
right so the operator of course is
essentially your interface that manages
all aspects of how you run your job when
you run it you know when you stop it
when you suspend it what you do how do
you manage your life cycle and so on
sorry about these white I don't know if
you guys can see it all the way from the
back but I should have probably made
these black inside the lighter colors
here but it says job step job instance
job execution step execution chunk and
Bachelet right if you guys can't read it
from there and essentially what it is is
it's showing that when you run a job
you're you're what you're actually
running itself is a job instance right
that's your logical run and what you're
doing is as a result of that you're
essentially executing the steps that are
within that job now the chunk and the
bachelor comes in where where it's
really very partitioning your job you're
splitting up your job you're running
these in parallels you're taking a chunk
of your of your job step and you're
executing it right and what you build as
that processor that you execute in a
chunk is your Bachelet essentially right
and like I said I'm trying to cover some
of these quickly i I'm sorry because of
the time but but i really want to
introduce these notions to you so when
you actually go back and read this back
to you know it'll start making a lot
more sense in terms of what the context
is chunk oriented processing is
essentially you know the notion that i
just talked about right you read an item
at a time you process it and then you
write to you collect all these processed
information and then write it out as a
chunk right instead of writing it out
one at time you write it out
chunk and and essentially it allows you
to start again beginning to do your
optimizations right when you're when
you're writing every single time you're
increasing the i/o if you collect them
in memory till you can afford in the
memory and then you write it all down
push it all out in a chunk allows you to
do more optimizations you can do some
similar things in the reading as well
right you can read it a chunk process it
and then write it out as a chunk the job
specification language is the job
control language right so for those that
are familiar with JC else it's similar
to that right so the notion is it's it's
a definition language written in XML to
describe the job the job the job step
you know the data streams that you're
reading from writing to how you're doing
your check pointing your partitioning
your parallelization so on and so forth
so there's a number of things you can
actually describe given the schema that
we have for for the job definition
language or job specification language
we talked about paralyzation so there's
two main concepts here one is
partitioning and one is concurrent so
when you partition a job essentially
what you're doing is you're taking if
you're processing a hundred records
you're taking each of those hundred
records and maybe you're splitting it up
through two ways so you're processing 15
1 and 15 the other partition and you're
essentially running the same step right
so instead of running it all in one
stream you're now splitting it up and
you're running the same step for all
these partition jobs concurrently
running is where you're running two
different kinds of processes but or two
different kinds of jobs but you're
running them at the same time so that's
slight difference between what the
concurrency and partition means right so
how you're splitting up these jobs ah
correct that is right that is a that is
a that is another way of saying that is
correct yes thank you we talked a little
bit about this already so how you how
your batch programming model flows you
have your batch controller beam which is
essentially I mean don't don't don't
look at the beam part right it's
centrally it so it's batch controller
which is part of the container right and
now we're getting into how this works in
an implementation from a web server
perspective by the way for the GSR I
think IBM is responsible for the
reference implementation for that so
we're we're working on that and I think
it should be out when when the spec gets
completed as well correct that is
correct so the question is is GSR 352
recommending that you run it run batch
jobs within a container when you write
in Java right so so the idea and the
notion for being able to have a standard
like jsr so earlier we had our own
programming model so if you wrote you
know your Java bad jobs then you run it
optimized for the IBM's batch container
versus if you wrote a spring batch then
you're you know running it as a spring
batch not necessarily directly running
it in the container the idea here is
it's certainly a recommendation the spec
really focuses more on how you would
actually have your batch job broken down
how do you best write your batch jobs
but yes that is correct and that is the
same regardless so the idea the whole
purpose of doing the spec is to be able
to standardize on some of those
programming model concept concepts and
specify what the container shouldn't
shouldn't have right so it's the same
thing as you would do for your for your
online apps right I mean technically you
can write your own if you want to then
nothing there's nothing that prevents
you from doing that it's just that it's
a it's a trade-off between more more
work that you do as a program error as a
developer because you're building in
some of these services that don't exist
versus you know building something
targeted for a batch server like
websphere so yeah
exactly complex pajama pants almost
seems to it becomes too heavy that good
becomes too tacky so actually not yeah
you'll be surprised I mean if you take a
look at the specs and how the
applications have been written they're
not necessarily tied to a container at
all I mean so you're not you're you're
barely there's a very loose coupling
between and that's why the whole as the
way the SP eyes are written the way the
api's are written their intended to to
make record code not tied so much to
your app server right absolutely true so
it depends i mean off all you're doing
is just processing you know something
that is a script that you're using today
and you're writing a Java program to do
that great right i mean more power and
just run it as that and that's all you
care about is running it really
lightweight and so do that yeah yeah
absolutely but but if the if the idea is
that you want to build something that is
robust that takes advantage of you know
the transaction services that is is a
lot more reliable where you don't want
to build all that framework yourself
that's when you use the container right
that's when you use a batch container
like this so so it's it's a difference
it's a standard argument that you would
do even from your online perspective
right i mean if it's something you can
do on your own great but if you don't
want to be in the business of building
all those underlying batch
infrastructure type things the
optimizations and if you build it it's
something you build very custom to what
your app is then you have to start
working on how you reuse it across your
enterprise and so on so I mean it's the
standard set of arguments that go with
you know using a container where it says
can I do it on my own right so I I mean
I don't see anything that's different
here from a batch perspective
there's tooling support that that exists
in the in the Eclipse so in the rational
application developer if you guys use
that we have built in a lot of tooling
so if you if you used Eclipse and you
know how you say like new Java project
and basically walk through a bunch of
screens in our wizards and it builds out
the project skeleton for you and then
you go in and code similarly now you can
do a new batch project it walks you
through all these artifacts as wizard
and then builds out the batch project
for you right so so again what you what
you're what you're adding in terms of an
additional if you're not already using
an app server and app server you're
you're gaining more than that from you
know the tooling from the time that you
can use to build your application
quickly and so on and so forth now again
like I said I'm not always saying that
that's that's what how it's always
should be but this is what it does for
you right so it makes life of you as a
developer administrator man operator
simpler right so that's what that is
that's this is just I just have a couple
pages on the web store batch container
so just like you have your web and EJB
container you have your batch container
as well which like I said carries all
this programming model jars and
libraries and all that for you so you
can you can essentially use it just like
you build your other applications you
can share your business logic you can
share your your your actual application
modules between batch and your online
applications right I don't think I'm
going to have enough time to run through
this but I'll just keep it for about a
minute or so the flow of a batch job is
where you have multiple of these
interfaces that can invoke a batch job
or call a bad job command window another
another application and other service
the web server is called a job
management console which is a tool that
is provided here to manage your jobs and
so on or WS great
interface which is basically your job
operator interface that can allow you to
interface with any of your you know
Enterprise schedulers like tivoli
enterprise scheduler to a workload
scheduler control em or ca7 or whatever
it is that you guys use you use you
submit the job with the ex JCL which is
the job control language dispatcher is a
component within the Oise batch its
purpose is to manage the life cycle of
the job we persist all of that
information so that's how you recover
jobs if there's failures or if you need
to restart a job we restart from the
last checkpoints you're not restarting
it from the beginning the container
basically is another instance of your
app server it's an app server instance
where you're essentially deploying a
number of your applications and and you
know managing your your jobs across a
cluster of servers and and you're
running it against you and your own apps
data store obviously these two can
reside in the same place as well you
know again like I said I think I have
sometimes I'll spend like two hours on
this chart but I I know I have to rush
through here the same the same picture
as the previous one the only difference
is what we've added here is the parallel
job manager so think about the parallel
job managers being a batch job which has
a special characteristic of being able
to split up an existing job that you
submitted to into chunks and then run
those chunks in parallel right so run
those so if you're processing like a
thousand requests enough in in one that
came in as one job what this chunking
can do and again you can be either have
out-of-the-box parameterize errs or you
can write your own right how you want to
chunk it because a lot of times you
don't want to just chunk it based on
size or number of Records or anything
you you have you know boundary cases
that you need to take care of and so on
so you essentially you chunk it and then
you submit the job over to a cluster of
your containers and what we do right and
again going back to
some of the discussions about whether I
can build it myself or use something
that exists here a lot of the management
of the job across these chunks is kind
of handled for you so you know there's a
lot of conditions around what if you
know one job one record failed in one
situation and and the rest of the job
chunks complete and how do i recover
from that and do I have to do a lot of
manual work the short answer is a lot of
that is what we take care of right using
logical transactions and we have this
running in real financial institutions
with real you know actual process
payments processing and so on happening
so so it's fairly reliable it's been
around for a few years as well so again
you need something you can build
yourself absolutely okay can you build
something like that yourself absolutely
but this kind of allows you to take
advantage of all of those things out of
the box right there's a lot of cool
things you can do as well round
aggregating across sub jobs aggregating
within sub job summarize summary
information being able to provide
customized status back to the caller you
know manually suspending some of these
chunks resuming some of these chunks
again you know to get that 24-7 allows
you to do a lot of those kinds of things
so I'm going to skip that I'm going to
just breeze through for charge here just
to show you what all you can do so you
can write these apps as an osgi bundle
there's some interesting multithreading
capabilities that we've added terms of
how you can optimize within a JVM and
across jvms different kinds of job steps
that you can marry together within the
same job right transactional
non-transactional script based and so on
overload memory protection which is
basically you don't want to kick off
more jobs if you're reaching a certain
heap threshold you know so we have ways
of preventing that you can set those
again goes back to the policies that you
can set right just one example of that
so based on that you don't really
overshoot the
amount of memory that is available on
that JVM and so you can manage that
proactively this is the tooling again
there's a link at the bottom so
hopefully you can go out and check it
out there I'm going to skip through
these best practices let you stare at
these customers scenarios and I think
that's my last chart yeah but you know
the customer scenarios are basically
we've deployed it at you know mainframe
customers distributed customers you know
different industries sharing batch in
real-time helped manage costs being able
to make reuse a reality and and you know
we've seen some pretty good success
there so I'll stop there and take
questions
so so essentially the spec is something
that is just started right but we have
had the Webster batch around for last
five years right so there's some parts
of the spec that are that are already in
there but but because the spec is not
complete i can't say any part of the
spec is really running in production
right okay all right so i'll take one
more question and then and then i'll be
here I've been told that the session is
over so I really want to thank you all
very much and I'll be around for a few
minutes so if you have any more
questions yeah the presentation has been
uploaded to the Java one site where you
know I think where you can get all the
prom loads so you can get it from there
yes
if you should ever miss the ball
here's the whole yourself
attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>