<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Overview of an Embedded Platform for Big Data in Manufacturing | Coder Coacher - Coaching Coders</title><meta content="Overview of an Embedded Platform for Big Data in Manufacturing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Overview of an Embedded Platform for Big Data in Manufacturing</b></h2><h5 class="post__date">2013-01-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Bixdbv6p1kg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">today's topic is building an embedded
platform for big data in manufacturing
and I'm ranbir Mazumdar I work for
Oracle I am a principal sales consultant
for the worldwide Java sales my interest
areas are industrial automation
manufacturing and the whole emerging
architectures which most of the people
are dealing with so I will be Co
speaking with my friend and partner
ethelyn vijayaraghavan who is the CTO of
system insights a company we are
partnering with and essentially what we
will try to do is give you guys a flavor
of what is cold and what how to make
sense of big data especially in the
manufacturing space so this is a code
which I found on the human face of Big
Data project it essentially is a project
by Rick Smolin who is a photographer and
who is trying to create the human face
he's trying to capture in the human face
of big data because big data is
different for different people so what
this says is during the first day of a
baby's life the amount of data generated
by the entire humanity is equivalent to
70 times the information which is
contained in the library of congress
this kind of gives us the scale of data
which we are talking about so which
brings me to the question what is big
data is big data something which is
really big is it something which needs
specific architectures concepts
platforms to deal with or is it
something more where I stand big data
essentially is a convergence story we as
human beings we are creating tremendous
amount of data today and I was giving an
example in my previous talk where
overlaying weather patterns with the GPS
locations or coordinates for taxis in
Singapore are telling people that
drivers in Singapore don't necessarily
like picking up customers or rides when
it's raining a reason they found out
when they did this analytics was because
somewhere in Singapore it's always
raining and there is a bond which these
guys have to fulfill if they get into an
accident so essentially the amount of
analytics which is involved in getting
to these simple solutions is
mind-boggling and and we look at this
whole big data as something of a
convergent story so it's a convergence
of the compute the compute which happens
at the back end data center and the
compute which is happening now in the
nodes in the edge devices so essentially
it's a nodal versus the infinite compute
possibilities of the cloud that's
essentially what a big data architecture
should address so what what do we mean
by this convergence and how is data
being generated if you see this is kind
of more more like a feedback loop but
you have human beings us we have these
different touch points so we have cell
phones for our personal lives we go work
we work with desktops laptops iPads when
we are in a manufacturing floor we are
interacting with all these shop floor
machines cnc machines which are cutting
things up slicing and dicing them
creating something meaningful and
essentially the interaction is human
beings are interacting with devices
which essentially have a lot of compute
already built into them and that compute
provides us a mechanism of correcting
the course so if something is going
wrong we want to find that out early if
something has gone wrong we want to find
out why so this is essentially a big
feedback loop and that's that's what is
essentially the crux of the big data now
of course we are talking about Java in
all this and I want to give you a
snapshot of why Java and what is the
Java Internet of Things so these are all
passwords be here essentially 31
devices and this is projected to be
around 50 billion by 2025 we have four
wheel four billion people out of six and
a half billion in the world already
connected in some way form or fashion
what we are predicting is all these edge
devices sort of the leaves in a tree
these are exploding these are exploding
because we have on us now at least three
or four devices which vu so we have an
iPhone or an iPad we have a laptop we
have a desktop back at home and we are
interacting with smart set-top boxes TVs
Apple TVs whatnot so we already are
talking in terms of data being generated
consumed and all of this data has to
make sense so the traditional view of
the edge to enterprise was have these
edge devices which you see here are
personal devices inner phones you have
industrial controls you have meters all
of these spilling out enormous chunks of
data and then the compute happening at
the back end so you have these cloud
based strategies you have oracle has a
whole platform which deals with our
cloud-based aspect of doing big data so
we have analytics we have intelligence
built in and this is essentially what we
have so Oracle has the most strategies
covered for the Internet of Things so we
have a complete stack which is the
Oracle Java devices in data centers off
data centers we have solutions which are
n to n which are best of breed and all
of this is built on Java which is an
open standard we put in a lot of effort
in creating that vertical integration
points you know we make sure that these
things are bulletproof so essentially
what a consumer or customer gets is an
on-premise or a private public cloud
offering or a hybrid so you you today
can have oracle provide you with that
snapshot view of the backend cloud and
provide you the big eye on the bay
analytics to go with that now what we
wanted to do in this session by the way
this whole embedded cloud and device to
data center architecture is probably
worth three or four sessions so what we
wanted to do was we want to introduce
you guys to a more narrower focused view
where we think an important use case of
this whole H to enterprise architecture
is how to push back or stream some of
the analytics or create some of the
analytics on these node devices so we
all know there is a latency issue there
are issues by which if we send
information back to the cloud and the
cloud does the compute and comes back we
waste cycle so essentially what we want
to show you guys in this session is how
can be embed some analytics on these
edge devices on the leaves on the nodes
and why to do that and of course athlon
will go in more details specifically
from the manufacturing perspective
before I do that let me give you the
value proposition of Java so why are we
so upbeat about Java because essentially
if you talk to a CT or a CEO of a
company what essentially we are trying
to do is they are trying to do is
they're trying to grow the ROI and
reduce costs and Java essentially
delivers on that promise so we have a
product life cycle which is updated
which has roadmaps you have comparative
advantage we have business focus we have
a developer ecosystem which is matured
which is there for the last 15 years we
have increased market reach we have the
best partner ecosystems and all of us
know that we didn't create the world
alone we all came together some people
have specific niche talents and we need
to build that ecosystem work through
that ecosystem to create a solution
which is cost-effective and make sense
and how do you do that how do you reduce
costs you
costs by making things portable so you
have different architectures which makes
sense for different technology so you
have guys who are working on powerpc
technologies other people are working on
arm so there are these different
business challenges which we always face
and how can we have a technology which
essentially is write once run anywhere
and that's what Java is so what we
wanted to do was I requested a student
to kind of give us a deep dive business
exposure to what manufacturing domain is
doing in terms of event processing and
edge analytics as we call it so this is
what we have so what Oracle is doing is
we are working to create a model where
we can have a notion of an architecture
which is actually doing edge analytics
for us so which is so we've currently
have a product which is called the
Oracle event processor which essentially
streams events through the cycles so you
have these edge devices you have the
gateways and you have the backend
servers all these devices are
communicating with each other events are
being generated and these events are
captured and there is analytics which is
done on them and we are we are creating
solutions so this is the stack view of
the OE p which is a oracle event
processor and what we are showing here
is essentially javab a stack we have the
java embedded stack which gives you
security management different kinds of
you I or HMI libraries we have standard
networking I or which comes baked into
the product we are providing an embedded
database which sits on top of it and
then we also have announced our new
product is Java embedded suite which is
called jazz which essentially builds a
glass fish or a scaled down glass fish
on top of the embedded stack and of
course the oep is an event processing
mechanic
them which is this is basically set of
API is which allow you to do or EP the
complex event style processing which
sits on top of it so that's basically
what our vision is for the edge
analytics so what we believe is there is
a time and place for doing compute at
the backend cloud but they are use cases
where it makes sense to have a near
real-time decision-making capabilities
and push the analytics to the edge
devices and a thorn in his presentation
will go more detain or deep into those
but this is basically the Java value
proposition so what we are doing is we
are enabling edge processing so what we
do is these devices are doing data
reduction filtration aggregation pattern
matching and doing all sorts of all
sorts of combinations to make sense of
the data which is being captured we are
doing things like reducing network load
distributing and processing pushing all
these different devices which are
spitting out data and kind of trying to
make sense both at the backend data data
center which can be an Oracle or which
can be some other cloud offering and
also now we are providing you in an
architecture which allows you to do that
on the device
so with that this is some more
information about the embedded Java some
some links to get you started I will
invite you learn to come up and set set
up his talk so this is our grand vision
of big data so we have big data big
analytics which talks about different
domains we have the smart grid
healthcare automotive and we have
manufacturing and each of these domains
have their own challenges their own
issues and what we wanted to do was give
you a flavor of what are some of the
challenges the manufacturing domain is
facing and how a specific company which
is system insights is solving those
problems so with that I would introduce
up to London vijayaraghavan who is the
CTO of system insights and utter lon
okay great so thank you Ranbir ok my
name is a thornridge arreguin I'm the
CTO and co-founder of system insights
and he there was a very nice
introduction and I think it's set the
theme well for what we have so just a
really quick introduction to what we do
at system insights we're a startup we're
based in berkeley california we were
started about three and a half years
back in early two thousand nine and we
build software tools for manufacturing
big data analytics so our primary
product is an analytics platform called
vimana this provides both real-time and
historical information to drive
productivity improvement at the shop
floor we will talk about that a little
bit later so what we do in system
insights is we we build software and
some hardware to help transition
manufacturing decision-making from
monitoring the manufacturing process to
detecting challenges issues failure is
happening in the manufacturing system to
ultimately be able to predict how the
system is going to behave in order to do
this we apply complex event processing
for rapid decision making we apply
machine learning to understand the
behavior of manufacturing systems in
order to make these predictions so we
bring a lot of technologies both in the
cloud to perform analysis on large
volumes of data from the shop floor and
we also look at how do we collect data
at the lowest level from the shop floor
so we're interested in putting it in in
in rem beers words we're interested both
in the device and in the data center
because we need to connect we need to
control and connect both of them in
order to provide you know value to our
customers okay so I want to talk a
little bit about why we care about
manufacturing right both us as a company
and why does it even make sense to care
about manufacturing think one of the
interesting takeaways from Judson's
keynote yesterday that kicked off jalan
embedded was
how manufacturing was not mentioned as
an area where embedded solutions could
help in a big way and part of that is
because it's been very challenging to
tap data from manufacturing and
manufacturing has also been an industry
which has not been very open to a lot of
innovation especially in terms of
connectivity and that's one of the
things which we are trying to change and
we're motivated by very traditional
concerns of how do we make more money so
you know I think from a from a business
standpoint manufacturing gives
tremendous potential for improvement
which you know the technologies that
we're talking about today can bring so
manufacturing itself is is big and it's
really big there is this very common
perception that American manufacturing
is is losing its place in the world for
a variety of political reasons but if
you look at just the numbers America is
still the world's biggest manufacturing
market so it's a two trillion dollar
sector and when we talk about discrete
manufacturing or manufacturing that
makes things part by part discrete
manufacturing ends up making parts that
are directly sold to a consumer like
something you know it would be a turbine
blade it would be a gear that goes in a
car which would buy and discrete
manufacturing also contributes tooling
and other kinds of equipment that goes
into the supply chain so if you have an
ipod the plastic mold the plastic parts
that go to the ipod was probably made on
a mall that was manufactured in a
discrete manufacturing facility and
these facilities they give tremendous
opportunity for productivity improvement
now one analysis said that metal cutting
equipment equipment that make features
and make parts by removing material
these equipment spend less than
twenty-five percent of the day doing
useful work so if you look at the
overall productivity of the
manufacturing sector this just this one
statistic says that we have about four
times the capacity that we're currently
using so there is a
opportunity to make manufacturing more
productive and one way of doing that is
by harnessing the data that
manufacturing equipment can provide and
this is this is a lot now it's not that
these machines themselves aren't
sophisticated it's just that the data
they generate is not collected centrally
and a lot of that data falls on the
floor so that's that's really the
opportunity we have and an interesting
question and you know getting deeper
into the process right what are we
trying to do why do we care about
manufacturing right what are the
questions we care about in manufacturing
so one way to look at it is let's say we
have a big hull curve titanium right I
take a piece of titanium and I put it on
a machine and I make it into something
that goes inside a jet engine obviously
the part has to be made within certain
specifications the part has to meet
certain design criteria in order for it
to perform in that jet engine so we care
about many things related to how
effectively are we making this
transformation so we start with the
business questions how productive mi how
much time is my machine running how
profitable are mine what is the overall
profitability of this piece of equipment
what is the profit profitability of this
part I'm making on the equipment then we
might care about larger term things like
what's my return on asset right how
effectively am I using my assets then we
can zoom in on the part am I making the
part correctly is it a quality part is
it fitting all my requirements are the
people making the part are they in a
safe environment is the product itself
reliable and then we get into concerns
that are beyond just our plant is it
sustainable right am I making the
product in an energy efficient manner am
i creating toxins and by polluting so
there are a lot of questions that come
up as we make this transformation from
this big Hulk of material to a finished
part and these questions have been
answered over and over again using many
techniques and they're continuing to be
answered today in manufacturing using
you know the business as you
methods but the opportunity we have here
with data is we make answering these
questions a lot easier we make our
answers more accurate and we make the
cost of getting these answers a whole
lot lower so the interesting thing about
manufacturing is that we're not applying
big data in coming up with new questions
to ask in manufacturing we're applying
big data in coming up with better
answers for questions we already know so
in one sense we kind of a we've made a
lot of progress in this industry because
we already know what we care about so
then build some discussions on the
potential for big data and discrete
manufacturing this is from a report from
McKinsey the Global Institute the
mckinsey global institute in a recent
analysis they talked about the potential
of big data in various sectors and right
up the top of the list based on the
total stored data in the United States
was discrete manufacturing so this says
that discrete manufacturing has about
one extra byte or in this case 966
petabytes or petabytes of data that's
been stored and they said now what are
the levers right how can we apply this
data in making you know in improving
manufacturing and they identified
several levers across the manufacturing
supply chain and there are a couple
which I think are really pertinent based
on what we're doing is actually on and
that ties to implementing lean
manufacturing model production digital
factory systems to create process
transparency develop dashboards and
visualize bottlenecks so here the idea
is to apply all this data in finding out
is my overall manufacturing system
behaving more efficiently the second is
implementing sensor data driven
operations to improve throughput and
enable mass customization and this is
interesting because manufacturing has
transformed over the last 100 years from
being very very low mix and very very
high volume you know the Ford Model T
you can have it in any
color as long as it was black so that's
where manufacturing started and now we
have a whole lot more customization and
configuration going inside the
manufacturing process because everybody
wants to have it in a different way in
order to enable that you need much
tighter control over the process and
that's where getting data from these
sensors and harnessing that information
comes in so we are focusing specifically
on discrete manufacturing now these are
discrete manufacturing is when you're
working on individual parts as opposed
to continuous or process manufacturing
so food processing oil and gas making
paint for instance that would be a
process manufacturing or continuous
process manufacturing discrete
manufacturing is when you're dealing
with metal or many doing injection
molding things like that so these
facilities they tend to be large they
have disparate types of equipment so
you're not talking about one huge
integrated system in your plan you're
talking about a facility with multiple
with multiple types of equipment and
these facilities have limited automation
you don't have one cohesive all
intelligent you know all intelligent
integrated system that's running the
plant and a lot of the machines are
human driven and humid control the
equipment themselves don't have a lot of
computational power of the equipment is
old and they generally have a life of
about ten years or more so what we have
is a case of unintegrated islands of
excellence now when an outsider comes
into a manufacturing shop everything
seems kind of old and falling apart and
they say about these pieces of equipment
they really don't have any capabilities
in them but that's that's not the right
view it's just that they have a lot of
capabilities in doing just the few
things they're supposed to do so they
are islands of excellence but they are
islands they have no way of exchanging
information and getting integrated
easily to form a larger system and
that's where data can help us so what
kind of data are we talking about so
here is a machine tool so what you see
is you have a big hunk of metal and
removing material away to create a part
in this case it looks like some kind of
a complicated gear on a shaft so we can
get a lot of data out of a machine like
this we can get position speaking at
alarms we can get the design of the part
we can get sensor information like the
vibrations the acoustic the temperature
we can get things like tribal knowledge
so we can get information pertaining to
how an operator a human being reacted as
the spark was being made so there is a
lot of data that can be collected and
depending on the kind of data the
resolution the scope and the input you
have to put in to get this data can vary
now some of this is very straightforward
right acoustics of vibration you have
the right kind of senses other kind of
data can be quite complicated especially
data pertaining to tribal knowledge now
this is data that a skilled operator
would have and how he or she comes in to
control the manufacturing process so we
are talking about very very different
types of data and we're talking about
many many different types of data that
even a single piece of equipment can
generate and this data also varies in
terms so so this data also varies in
different levels of analysis so we have
the actual manufacturing process right
and there's all the science and the
technology that goes into the process
all the way up to the manufacturing
supply chain so if i had to zoom in I
have my manufacturing process and then I
have the equipment then I have you know
a factory or an enterprise making the
part and then i have my supply chain
that could be across multiple continents
so that we have that on the y-axis and
on the x-axis we have decision scales so
with all of these with with data with
data from all of these different scales
when do we make decisions so we can have
analysis in the microseconds or
subseconds all the way to analysis
happening in a matter of days so I like
to think of this as real-time analysis
and real-time decisions near time
decisions and anytime decisions and the
distinction is
time is usually in what we call the
command and control loop so we have to
make this decision because it will
affect the quality of the part it will
affect the manufacturing process it'll
affect the machine it'll affect
somebody's health any time are decisions
that are primarily managerial decisions
and this is these are decisions that are
taken by an ERP system these are
decisions that are taken by you know a
an MRP system so these are not decisions
that have to happen at the shop floor
itself in the middle you have this vast
gulf and this is where you have mere
time decisions these are decisions that
you can take to actually improve the
process and these decisions you can have
you can take them in seconds you can
take them in hours you can take them in
base and this is the space where we
don't have a lot we don't have a lot of
tools and this is the place where we are
missing the most amount of data because
to manage a manufacturing process
financial information is generally
enough if you're doing high-level
management at an enterprise level and
individual machines controller sensors
do a really good job managing data at
the low level of process control so in
between when you have mere time
precision making that's where you have
the biggest gap okay so given these
temporal scales how much data are we
actually talking now we need some
estimates and we estimated that the
American manufacturing of the American
machine tool sector can potentially
generate anywhere from 200 petabytes to
950 petabytes of data per year so that's
almost an exabyte if you turn on all of
the machine tools in America today and
you you you were pumping out the maximum
possible data from them again a lot of
these machines don't have capabilities
to communicate this which is what we're
trying to address but the potential
exists to collect about an exabyte of
data per year just from machine tools in
the u.s. today and on a global scale
you're talking 30 to 50 times more than
that and depending on the kind of
facility you are if you're a small shop
with just about 10 machines you could be
generating up
do you know 10 terabytes of data all the
way to a large enterprise if you're
buying or lockheed martin or
curtiss-wright you could be generating
you know a few petabytes of data just by
yourself per year so there is a huge
potential and what's interesting is that
if you take this 950 number McKenzie
points out that that is the amount of
stored data that this sector has all put
together but now if you turn on
real-time data capture real-time
streaming analysis you basically create
that much data every year so this is
truly a big data challenge because you
have to deal with this information you
may not want to store all of this you
may want to just dump some of this
information so now you're dealing with a
much more interesting much more critical
problem which we're trying to solve so
what do you do with all this why do you
need all of this data right we don't
want it just for the sake that we have
it so what are some of the grand
challenges of manufacturing that this
data can solve so one is enterprise
traceability so instead of the boxes
let's try and work this out with an
actual example so a couple years back
there was a an Airbus a380 in one of its
first flights the plane developed an
engine malfunction and it had to land in
singapore now it turned out that the
plane had to land because one component
in the engine had had blown out and so
there was a big malfunction and it was
unexpected it was a new engine it hadn't
gone through a lot of testing and
basically they did a bunch of evaluation
that they found out that it was a
specific component that had failed now
that component was made in a discrete
manufacturing facility and if we had
traceability data if we had data that
could trace what exactly had happened to
that part when it got manufactured if we
knew who had made the part when the part
was made which machine made the part
what were the environmental conditions
was the part made in a very humid
environment was was the part made when
it was really hot outside what was the
machine doing when the park was made was
that excessive vibration was that
excessive noise what was the operator
doing when the party was made
have any way of telling if the if it was
done at 2am in the night when the
operator was tired and there was there
is a greater chance that a mistake was
made so with traceability information we
have a complete record of how this part
was made so now if you're Airbus and you
have this traceability information you
could say here is it effective part that
almost brought a plane down now let me
look at the data and find out if there's
anything funny with it are there any
anomalies do I have any deviations from
the plan and then if we go back to our
better bite storage right sitting
sitting in a big database somewhere we
can now say let me look inside this
database and let me find out all of the
other parts that hopefully are not in
the air that are probably in a warehouse
somewhere that demonstrate the exact
same flaw or that were manufactured
under exactly similar flawed conditions
and then we can isolate them so
traceability gives us a way of
controlling the manufacturing process
and not just control but capture
everything that went into that process
so that we can make effective long-term
decisions based on how the process
happened and this involves capturing
data from the part as it moves across
the manufacturing process through
transfer stations and sharing that
information across the entire supply
chain so if you're but you know if
you're an OEM you're buying this from a
vendor the OEM wants to have it you want
to have this information flow through
the supply chain and if this is an
airline part you want the FAA wants to
have access to that data if for example
this is a hip replacement the FDA wants
to have access to the data so there are
also regulatory requirements that this
kind of data can address so another
grand challenge is how do we improve the
energy efficiency and how do we manage
the energy consumption of manufacturing
processes in a better way and here we
have a classic you know loop problem
right we want to measure the 90
fracturing process we want to find out
what's happening in the machine we want
to find out what is the energy
consumption
we want to find out what is the impact
of the process on the environment and
then we want to and we do that by
monitoring the process and then with
enough data we can say okay here is how
I should be manufacturing the part here
is the options you know here is the
approach I should take and manufacturing
the part such that I decrease my energy
consumption and then the only way I can
validate it is I try it out in the field
and we go down we go down that loop
again so this is a classic continuous
improvement cycle so we can't fix this
in one shot because we have too many
variables in the system so the effective
way of doing this is you keep making
these small improvements and you make
sure that overall you're improving
you're improving energy efficiency so
this is another challenge because energy
management is not something that we care
about just in one plan but this is truly
global because when you have
manufacturing processes moving from site
to site or from country to country the
ramifications of energy consumption
could be different so with with these
grand challenges right how would how
would a big data stack look for
manufacturing so we would need three
pieces and these are very big chunky
pieces so one piece is data collection
we need ways of efficiently capturing
data from manufacturing equipment the
second is we need ways of collecting
storing and having that data available
for an appt for analysis and the third
is we need technologies such as complex
event processing statistical machine
learning in actually acting upon this
data and provide value to the customer
and our stack our software stack is
based on this kind of a platform so this
is the architecture of our vimana
product this is a software-as-a-service
product that is its we hosted and we
collect data from our customer
facilities in real time so we have data
flowing in its captured we have a data
bus and then we send the data away for
complex event processing for real-time
pattern matching we send it into a
machine learning service to find
historical analysis article analysis and
we store all the data so that we have a
very very high density wreck
of everything that happened in the
manufacturing system and based on that
we build our user interfaces reports and
we tell the customer how the shop is
behaving and they use this data in
improving their manufacturing processes
and in addressing some of these grand
challenges that I talked about so so
vimana provides this information this is
just a screenshot just to give you a
sense of what the application itself
looks like so Ramon are tries to answer
questions that people have about
manufacturing the monitor edge to answer
why am I not doing the right thing so a
common problem in manufacturing is you
know something is wrong because you're
not you know your machines aren't
producing anything but you don't know
why and most manufacturing approaches
look at just telling you that your
machine is up or your machine is down
you don't have context to help you go
solve the problem so what we try to do
with the Big Data approach what we try
to do with all of this information from
the machine is to answer the more
interesting question of why is the
machine down or why is the machine not
producing parts or why is the machine
producing bad parts and the data for all
of this for this auto classification as
we like to call it comes from various
sources including sensors controllers
the user and other and other entities in
the manufacturing system so this
information is available real-time it's
available on dashboards and you have it
in a reporting system that pulls data
over historical periods so the idea is
as a customer right as an end user as
somebody in a manufacturing shop who
cares about its current performance its
historical performance and with an eye
on you know keeping it performing into
the future this gives you a pretty
holistic view so you have real-time
access to the system you have historical
analysis and you also get to customize
what kind of data you seeing because we
can integrate with a lot of type of
equipment and a lot of type of data
sources so this is all good right we
have you know we have a stack we have
software we have
I challenges so you know why are we here
right it's we don't have any problems
well we actually do um there is a big
gap in big data and that gap is in data
collection so we still do not have as
much data as we can potentially get from
the manufacturing shop floor again there
is a ton of potential there are a ton of
applications to the data there is very
proven business value in what you can do
with this information but because of a
variety of historical reasons there is a
very very large gap and data collection
so if we walk around you know oracle
openworld we can see many many
instantiations off the stack i talked
about right there are tools for that you
know there are tools for databases there
are tools for analysis you know Ranbir
talked about oep in the cloud you know
we have OE p on the embedded all of this
is great right but the big gap is in the
actual collection of the data from the
manufacturing shop so this is how we'd
like it to be right we have you know we
have devices we have the data center and
there's a really tiny gap between them
and it's easy to get them together well
that's not the case what is actually the
case is that we are missing a very big
piece of getting information from the
device into the data center and part of
that is because we lack effective
standards and we lack effective tools to
apply these standards to get data from
these edges into the cloud or into the
enterprise so a lack of standardized
data sources because the shop floor has
complex disparate types of equipment
equipment with you know proprietary
interfaces this has turned out to be the
biggest gap in having the kind of
end-to-end connectivity that we've
always wanted in the manufacturing word
okay so one way of addressing that um
one way of addressing then was proposed
by AMD a few years back and this became
the mt connect standard and there is now
an institute called the empty connect
institute that supports the development
of
standard an empty connect is an open
standard that defines a protocol and an
exchange format to facilitate
communication between devices in a
manufacturing system so empty connect is
is a data exchange standard it's based
on XML and tcp/ip it's extensible it's
lightweight it's really easy to
implement and the problems that empty
connect addresses is that in
manufacturing we've had an abundance of
protocols we have had an abundance of
data formats we've had every type of
machine in a discrete manufacturing
setup shipping with its own proprietary
interfaces and AP ice and setting up any
kind of communication or integration
between these interfaces has been very
challenging so empty can it has gives a
very lightweight solution to solving
this problem of inter device
communication or interoperability in the
shop floor an empty correct also plays
very nicely with other standards so
empty connect integrates very well with
existing approaches like OPC and other
more for other standards in the
manufacturing world okay so given the
fact that we now have some standards
which can help manufacturing let's get a
pivot back to the focus of the stock is
how do we how do we make this connection
right how do we bridge the device to the
data center and this is where some of
the technologies that Java has can play
a pretty a pretty major role so we
believe that with java SE and better
technology we have a very compelling way
of connecting up the shop floor to the
cloud and the big gap we see is the big
gap which we have seen which i've talked
about is how do we get information from
all of these devices into the data
center so what we're looking at is can
we're looking at developing devices
using java SE embedded technology to
help in collecting data from the shop
floor so these devices can interact can
get information from a variety of shop
floor data sources including CNCs plc
sensors power meters barcode scanners
you know tablet PCs if you know where an
operator
interesting some values you name it and
we envision these hardware devices as
being powered using the empty connect
standard that they can exchange
information in a standard format and on
top of that right so this gives you a
nice fat pipe of empty connect data and
now you can have applications like
vimana sitting on top of that which now
have access to a whole lot more a whole
lot more data from the shop floor that
this kind of a device will enable so and
this is a pretty compelling use case for
java SE embedded i think some of the
applications that when we talked about
like jess and oep they fit really well
because some of the things we need this
device to be is firstly it needs to be
pervasive it should be pretty easy to
take this to any kind of a manufacturing
environment and ubiquitously get it
working with different types of
equipment and do it in a cost-effective
fashion it has to be device agnostic so
you should be able to work with all
systems new systems sensor systems and
the like it should be based on standards
empty connect is perfect for this but
obviously it should support other
standards as well and the solution
should be scalable so you should have
capabilities of going into a shop with
five machines and hooking it up in the
same way you would hook up or shop with
a thousand machines so we see the java
SE embedded sweet and other products
that we've been speaking about as a very
nice fit here and we see this as forming
a very critical piece of the you know
off the integration from the device of
the data center in the manufacturing
world so with that I'm done arm and I
think we have about 15 minutes for
questions yes
question about the two against the OE t
be used so I understand with ed you go
back and read when you start moving it
closer to the edge what do you think
would be the most critical factors or
using you there we process one less we
mention is featuring right listen to the
best for in the context of therapy it is
your body pushing the lead-up to the
park and tenant so I didn't feel your
aura and we stopped in statistical
analysis and machine learning or matter
of the most actually no
users seen that are more pertinent that
free time in creation so first wanted to
understand what using out the best age
should actually filtering is an
interesting example because um I I agree
with the point you make about how you
don't want filtering per se because you
want to collect as much data as possible
in the cloud but filtering in in our
opinion is a good candidate to do in the
edge not because you want to restrict
data to the cloud but because you want
to take decisions in different time
frames so if you want to have instant
decisions you can do some low-level
processing a low-level filtering in the
edge and stream the high bandwidth data
at the same time so exactly so that
that's so one nice case of IEP is that
it allows us to select you know it
allows us to filter and send the full
pipe another example would be
correlations the thing is and this is
where having I mean that's why in our
stack we use both CEP and machine
learning so machine learning is more the
classic big data problem right so we
have the huge trove of data to say here
is a correlation right here is a
correlation between temperature and
failure so one we instantiate a pattern
saying I have a certain temperature
trend now that will become a pattern in
CP so that is I think that's another
common pattern which we see is basically
some kind of thresholding so comparing a
stream of data over a window of mtor
function so from simple things like are
you above or below value to more complex
things like I going up a slope by
hitting a waveform things like that
no no we the machine learning is not
being done on the edges the machine
learning is being done on the cloud and
the patterns could be implemented on the
edges
so that's the that's the architecture we
are proposing so correctly we have a
product which is a sweet and so Jay Jay
Suey is the senior principal what if you
stand up yet he's a senior principal
product manager and I stole most of his
slides to create this dog by the way to
thank jay so Jenna has so the product
team has a vision of creating a stack
which lets you to edge and abacus you
don't need to do that if you defeat make
sense for you to have that round trip
back to the data center to the big and
the cloud and do that analytics and all
the other things which you mentioned we
are okay to do that but in cases where
now the devices the nodes can have that
intelligence and should make that
decision currently we didn't have
anything so the IEP and the staff and
what his vision is is to create that
availability of analytics on the edge
devices so if your use case finds that I
can save that round trip by doing
analytics on this edge device we from
our can we have a product stack and it
fits right in his scheme so these are
the domain experts so what you see here
is a validation from a manufacturing
perspective Warren J and other guys
basically spend sleepless nights doing
in architecting that project so what we
try to show was the perfect marriage and
by taking an example of manufacturing
but there are complex decisions to be
made there are various different use
cases which govern how you would
architect your systems but we just
wanted to give a snapshot of of this
particular narrow view of edge analogous
and and I think specially to your point
of persistence right now we don't use
the the Jess stack and that's what one
of the things that's going to come out
of this is we are looking at picking
chow
you know embedded as as our platform of
choice you know on the embedded site or
on the edge side but persistence is a
really good use case for us because
right now we see that as a problem in
having reliability because we're on
using an SLA and you know when and and
we do a lot of work in country in places
like India where you don't have reliable
Network and lack of persistence is
actually a pretty big problem for us
today because we basically have you know
we basically have machine shops there
are streaming us huge amounts of data
over really really crappy network
connections and a soul story about the
scentee and wireless yeah and one of the
things I think we spoke to we spoke to
some of the Java folks about was some of
these wireless devices that have the
Java stack running on them so we we
definitely see that actually that's kind
of what makes us interesting for us is
that some of this capability we get for
free right we it's just provided asses
as part of the suite and it's a very
good fit with with our requirements yes
how do you see we have will so belt
who's the author of this heck so we'll
do you want an answer that question I'll
embarrass myself of answered in front of
him so we want to use the mic he thought
me yes you thought we just let you doze
off in the back ship and I was enjoying
my now no empty connect is a heavy
device devices basically it's a protocol
for getting data off of a device so it's
a read-only and it uses standard
protocols like HTTP and XML
representations of that data from an
application it does not go up to the
application level we don't interpret the
data we just report the data so it's
pretty low level protocol in that we
specifically designed it so that it
wasn't going to be deciding whether the
state of the machine was good or bad
machine report that information but it's
not as for reporting so the raw
information for the month raw data model
off the machine and contextualized what
we wanted to do is come up with a
normalized set of units and names so we
talked about the position of the linear
x axis we always use the same word to
represent that piece of information
regardless of what machine you get off
of it and everything is defined entire
vocabulary is a fine so when you go to
an application like ours or an
application like any of the applications
that use them to connect out there they
are all using the exact same vocabulary
to talk about that data which makes it
very easy i can go to any machine i can
immediately understand what's going on
that machine without having to build
specific adapters and
drivers within I application layer to be
able to interpret it so to get back to
your question basically empty connect is
it's below the application layer it's at
the data layer I'd say from a computer
type of but it's at about it's a higher
level than SNMP but it's in that domain
of raw information coming off our raw
data coming off of the machine which
gives a really good opportunity for
applications to then figure out whatever
they want to about that data we talk
about big data basically you're talking
about the idea that you want to collect
as much the raw information
uninterpreted as you can because the
more interpretation the more down
sampling that's done more assumptions
that are made at the low level the
harder it is to be 0 then at a high
level analyze that data and do anything
interesting with it because somebody's
already kind of around with it so
we like low level
actually that that's that's that's
exactly what we're working on this
device part because the person XO a
machine so the problem we the problem we
have in manufacturing is the average
machine tool is not IP capable the
average machine to sew the thing on the
box that we make the machine empty can
it compatible is the agent it's a little
web server that runs on the box if you
have a new machine with the right kind
of you know software and hardware in it
right you can basically run the empty
connect web server agent on the machine
itself right because a lot of new
machines they have that capability but
if you look at the two million plus
machines in the u.s. today or the 30
million plus in the world today about 5%
of them have this capability natively so
this is kind of a solution for the other
ninety five percent to even have this
basic capabilities of you know can they
you know can they run this web server
and can they respond to an empty
connector question
this is
whether it's good people start from
simple key value pairs and distant
future and then the question is where do
i scope and some well it's the standard
is extensible so mean we don't say we're
going to cover the entire manufacturing
domain because as you said it's infinite
but at the same time there's a lot about
the domain that we can define in an
unambiguous manner so for let's say we
hit twenty thirty percent of the known
data items we can give that twenty to
thirty percent very unintuitive find
names and the execution saves the
controller modes the positions of
various different axes and the paths and
motion control and things along that
line let's say we can define that layer
you've got that now let's say we go into
another domain like additive or you know
something that we haven't dealt with
like water jet or some other types of
machines you can always extend it out
create the new components that you need
it's XML extensible you can create your
own namespace to put in those components
and then add the data items in there we
can also do things like we have a lot of
sensor data we've probably covered more
sensor type of data in empty connect now
than any other standard has and we
standardize it in that we felt with the
units and the naming of the all those
data types as well as handling time
series and you know most most of what
people will need to be able to do
analysis on machines that we stream
audio data another thing so I think we
take wha and to connect as it is right
now you'll probably get most of the way
there you can then extend it out like a
lot of our customers are a lot of the
users have done you know implementers of
empty connect have done is 105
implementers right now out there 105
companies basically they've extended it
out to meet their needs whether it's you
know process level stuff or you know
specific components on their machine or
whatever they want to do and we allow
that we encourage that because we know
as a standards organization we don't try
to say we're going to you know solve
everything in the world
we'd be working on this thing and
definitely no get the damn thing out
there well and the other thing is from
the empty connect perspective there's a
level of pragmatism which you know which
kind of reflects in our approach as well
is how would how many what percentage or
what fraction of the problems are we
solving with the data that is
standardized and I think you know
version one of empty connect boys at
maybe seventy-five percent so with that
data seventy-five percent of you know
your low hydroxyl problems are solved
and now we are probably at 98 and I'm
absolutely certain that stuff we are
missing but we're pretty confident it's
in the two percent and the thing is
again like will said that's where the
extensibility comes in because that two
percent it sometimes it's not worth the
effort to actually compete and kind of
bang each other on the head to
standardize it and that is stuff that
people can't define on their own but I
think we have to run variation frontier
is cutting here's a good job of cutting
people off so yeah so you're not getting
to that question yeah its interest for
the stressful yes it's much prefer we
have a java one technical session at
three thirty today which is going to go
more deeper into the technical as this
is more business factor for presentation
so we encourage you guys
have more technical questions to come to
that so with that I thank well and tuna
and hope you guys had fun</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>