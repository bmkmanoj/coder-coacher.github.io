<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Oracle Database 12c demos: In-Memory Column Store Architecture Overview | Coder Coacher - Coaching Coders</title><meta content="Oracle Database 12c demos: In-Memory Column Store Architecture Overview - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Oracle Database 12c demos: In-Memory Column Store Architecture Overview</b></h2><h5 class="post__date">2014-07-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fMW2-TDheec" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome to this presentation
oracle database 12c in-memory
columnstore architecture overview my
name is Jonathan Siravo a working for
server technologies curriculum at Oracle
and I'll be your tour guide for this
presentation the in-memory columnstore
enable objects table and partitions to
be stored in memory in a new format
known as the columnar format this format
enables scans joins and aggregates to
perform much faster than the traditional
on disk format before we dive into this
new architecture let's review some
basics first what you see on this slide
is the visual row format representation
of a relational table here table sales
has four rows and six columns using the
in memory column store feature the same
table is represented in a columnar
format now imagine you rotate the sales
table 90 degrees you obtain the pink
table on the slide now reverse it and
you get the visual columnar
representation of the sales table with
this vision rows are now what used to be
columns now let's have a look at a
closer logical representation of the
sales table in row format you see a row
starts with a row ID followed by the
first column value then the second etc
then you find the second row and so on
with this columnar representation things
are very different the first part of the
table structure is in fact the first
column
you find the first value associated with
the first row ID then the second value
of that column associated with the
second row ID etc one of the benefits of
that representation is the possibility
to compress data here because the first
two values of the state column are
California it is easy to compress using
the e memory column store feature there
are free compression levels using
different compression algorithms you can
request the other big advantage of this
in memory columnar representation is the
possibility to do what is called vector
processing using very fast
cyndy processing which stands for single
instruction processing multiple data
values if you want to find all rows for
sales done in California all you need to
do is to scan the state column and count
the number of occurrences of the state
of California with Cindy processing we
can check 16 values or entries of the
state column in a single CPU cycle for
OLTP workloads the idea is to make DML
faster and reduce space usage by
dropping what we call analytic indexes
and use the in memory column store
instead other indexes like primary key
indexes should be retained anyway in
terms of queries using in-memory
columnstore feature is ideal for
scanning large numbers of rows and
applying filters querying a small subset
of columns in a table
joining small dimension tables to larger
fact tables or aggregating data removing
analytic indexes greatly simplifies
tuning and eliminates ongoing
administration after the logical vision
we can stop talking about the
implementation at a high level
there are two aspects of this
implementation here we look at the space
management level you can see the logical
columnar representation and each color
is used for a different column of the
sales table now if we look at the sales
table representation on disk it is
stored like before using what we call a
segment represented by blocks on disk
here we use the default block size of 8k
to represent the columnar version of the
sales table in memory the system stores
in memory a predetermined number of rows
using what is called an in-memory column
unit conceptually the table's rows are
dividing two large chunks called
in-memory column units and within those
chunks each column is stored separately
in a contiguous region of memory the
chunks will be large enough to achieve
the maximum possible scan speed unlike
conventional database blocks which are
typically 8 kilobyte in size imc use are
orders of magnitude larger typically 1
million rows or more pair amcu the exact
number of rows Perrie MCU is determined
at run time and based on table size and
structures and memory constraints the
performance of queries with simple
predicates against the in-memory
columnstore is much better than the same
query against the buffer cache because
the in-memory columnstore has access to
the minimum and maximum values of each
of the columns for each MCU the column
in the where Clause predicate is
compared to the minimum and Max
See Mom range of values toward any GMC
you of the column and if the value does
not fall in the specified range the EMC
you is completely skipped the EMC
uprinting applies to queries using
predicate filter on a single column such
as equality and inequality
just like exadata as storage indexes the
in-memory columnstore records the
minimum and maximum values for each of
the EMC use or extents now what did they
do to our SGA to implement this in
memory column store what you see here is
what exists since the beginning you have
tables stored on disk using either a row
representation of the exadata hybrid
columnar compression representation then
you find processes reading and writing
to the buffer cache in-memory
columnstore is not changing this
architecture however with the in-memory
columnstore feature you get a new SGA
structure called the in-memory
columnstore you can size with this new
initialization parameter in memory size
in addition there is a new background
process in memory coordinator or a MCO
that creates and refreshes EMC use to
populate and repopulate the in-memory
columnstore a MCO is the background
coordinator process which schedules the
objects to be populated and repopulated
in the in-memory columnstore every two
minutes the space management coordinator
and worker processes our background
processes which actually populate the
objects in memory progressively as an
administrator you can flag a table a
partition or even a subset of columns as
in memory yeah
create or alter table statement there is
no LRU algorithm to manage the in-memory
objects in memory objects may be
partially populated into the in-memory
columnstore if there is not enough space
to accommodate the entire object when
this object is queried as much of the
data from the column store is retrieved
and the rest is retrieved éva from the
buffer cache flash cache or disk when
you access the table for the first time
or when the instance starts up depending
on the priorities you define using the
in-memory close the tables are
automatically converted and loaded in
memory using the new column format this
conversion is done
each time the instance responds as the
in-memory columnstore copy resides only
in memory now whenever you select from
that table the optimizer can go either
through the buffer cache or the
in-memory columnstore depending on which
way is evaluated to be faster this is
done automatically and transparently to
the application updates are a little bit
more complex but to put it simple both
the buffer cache and the transaction
journal are updated as well as
corresponding EMC use and validated the
idea is to make sure we will be able to
do read consistency when going through
the column store the EMC use which have
had DMLs
are not refreshed on queries the rows
which have changed since the MCU was
loaded we'll get all the modified rows
from the journal so there is no refresh
at the query time the EMC use are
refreshed from the transaction journal
based on some internal threshold
which include the number of
invalidations or changes to the rows per
EMC you they may also be triggered due
to RAC and validations and transaction
journal running low on memory we use the
same IM CEO CM CEO and worker processes
to repopulate there is one last property
you can define for in-memory tables that
is a rack property here you can see on
the right a for nord rack cluster each
node has its own SGA an in-memory
columnstore on the left we have two
tables we suppose being represented in a
logical columnar format the sales table
has four partitions one for each quarter
and the shipping table is not
partitioned in a rack configuration you
can specify for a given object table or
partition whether that object should be
distributed into each instances in
memory column store like for the sales
table here where each partition is
loaded in one particular in-memory
columnstore this approach makes sense
when you have a table that is too big to
fit into a single instances in memory
column store but it can fit in the
aggregated space available across all
instances or whether that object should
be duplicated across each instances in
memory column store here the complete
shipping table is loaded and duplicated
in each in memory column store this is
the end of the presentation thanks for
watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>