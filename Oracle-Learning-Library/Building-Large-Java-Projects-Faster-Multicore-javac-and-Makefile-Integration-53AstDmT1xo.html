<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building Large Java Projects Faster: Multicore javac and Makefile Integration | Coder Coacher - Coaching Coders</title><meta content="Building Large Java Projects Faster: Multicore javac and Makefile Integration - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Building Large Java Projects Faster: Multicore javac and Makefile Integration</b></h2><h5 class="post__date">2013-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/53AstDmT1xo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Frederick I'm going to talk
about multi core java sea and how you
integrate java sea with big projects in
particular make files but also a little
bit about the aunt and I've been working
on J rocket for the last six or seven
years and since j-rock it was being
merged with the Oracle hot spot I've
been working on hot spot for the last
two years now we will start with an easy
question from a single Java source file
what do you get when you compile
something sounds simple doesn't it but
in fact it's quite complicated because
you can get anything from zero to an
infinite number of classes and they
might not even correlate with the file
name of your source file and this is
unfortunately perfectly according to the
standard so you have package info files
that contain no actual code and they
generate no class files they are only
there to generate javadoc you have any
classes and package private files and
they generate files that you cannot
really predict the source the file name
work and you have classes at the end of
your public loss in that file and those
also are unpredictable
and in fact if you're using an
annotation processor which is such a
pre-processing support in Java see it
gets even worse because then anything
can happen so the net result is you
don't know what's going to happen when
you run Java C so Java C requires
explicit source file names on the
command line and usually put a lot of
source files into the add file and these
explicit services are always compiled
and linked against the dependencies
outside of it for example the classpath
where you pick up the object class and
other thing now if you link or need
access to code that has not yet been
compiled you need to use the source path
argument to Java see how many of you
here has ever used the minor sore spot
67 that's great so you use source pass
to pick up code that you are dependent
upon but for some reasons you have not
been able to compile a part yet and
unfortunately the default behavior for
source path is to actually generate code
that Java Sea accidentally finds a while
its linking your code so even though you
didn't explicitly say that this Gauss
should be written to disk it will do so
for you unless of course you specify
implicit none and then it will not write
unexpected classes to this for you oh
and this is a minor knit that most of
you have not experienced it will
actually not three compile things on
your source path class if you have
classes in your boot class path with a
new timestamp what's on the disk so for
example if you will if you are a JAX p
developer and you have the decks p
sources on your disk and you have used
source path
exp it might wear a veil happened that
the Java Sea will ignore your sources
and pick the ones from the boot class
both because the boot classpath had a
new your time stamp because you
downloaded the data yesterday this is
very confusing but most people do not
experience this kind of problem so we we
can see that we have ramped unlinking we
have compiled time linking and we all
have compile time linking against
sources unfortunately when Java C goes
out to source path it will not just look
at the api's of these sources it could
actually compile them and this is one of
the reasons why it's so easy to make
circular dependencies in Java because
Java goes out of the way for you to spit
things out on disk that you didn't ask
for but it's needed anyway for this
circular dependency to work so you can
write circular dependencies in code very
easily and you don't even notice for
example you have a depends on be that
depends on see that depends on a you
explicitly tell the compiler I want to
compile a Lambie and if you have the
source path it will fill in C for you
well you probably wanted that anyway
unfortunately this makes it very
difficult for you to see these
dependences which of course causes the
need for all these nice tools which draw
the circular nest of spaghetti that
represents your dependencies soft words
yep
so usually implicit compilation is not a
problem because most people do not
develop code that's inside the dedicate
implicitly generated clauses contribute
to this confusion that I started with we
don't know what Java Sea is generating
and why is why is this a problem well it
is a problem when we start to integrate
Java with make phones or we want to do
proper incremental builds and keeping
things clean because for example another
problem with jealousy is that it doesn't
clean up after itself so if you compile
a class it will write in place this
stuff to disk or explicit stuff or inner
classes or anything and then you remove
at the inner class and it will not
remove the class file from disk and this
is very annoying so most people are
already quite used to doing make clean
and clean something like that just get
rid of its as soon as things start
misbehaving you just clean it out them
try again but I don't think it should be
like that so let's examine what the
current Java Sea creates for problems
when you want to write a make file for
it I know how many of you have actually
written make files yes that's why I knew
you would come here the only session
with the title that contains the word
make Val everyone else just runs away
scared so you have the make file it's an
imperative program it runs through from
top to bottom and while it does that it
creates a tree of goals and requirements
so after its run through it the first
time nothing has really happened but you
have a tree of gold requirements and
then it will pick a goal usually the one
who gave on the command line or the
first one in a file and it will recur
through this tree and decide which
actions to evaluate to actually generate
ago so it makes
is very powerful because you have first
this imperative program that can both in
this case generate flags and put flags
interactions but it you can also create
the goal requirement rules from within
make as an imperative program so you
should think of it as a two step process
first an imperative prom and then an
evaluation of the generated tree so in
this simple example we have the goal
which is app the source is to up compile
the sources and yep and make will of
course look at the time stamps of the
requirements and the goal to decide if a
goal is already complete now sins make
can generate gold requirements
dependencies from the imperative code we
can create macros that set up
dependencies so even though most of you
think make us rather inconvenient to do
big configurations this is an example
that I will explain a little bit more
later that uses a macro to set up set up
an entire dependency from the java
source code to the output classes and
then you depend on the output source and
you depend on the glass jar so this
first part here this macro it doesn't do
anything it just setups all the
dependencies and to actually get
something out you bind the all goal to
these targets however as you might have
guessed it's not that easy to write at
macro
and if we look at the Java Sea command
line this is an example that it might
look if you want to compile the data
case because what I'm talking about here
is our own product hotspot how do we
compile the data k so what you see here
is you say Java Sea boot classpath
classes minus D classes and then source
java.lang.object source java line
character data and eight thousand more
five this clearly doesn't work because
there is no command line in any OS that
accepts this amount of data on the
command line so we can use an add file
to work around the problem but
everything here means that we need an
external tool to help us configure Java
Sea to build the build projects and as
you all know the antis is standard too
and we have properties where we have the
source build a list we have an init goal
that creates a bin directory we have a
compile goal that compiles the source
and here you can see that the ant task
has already prepared for us so we only
need to point to the source and the
target we don't need to list all of us
sensible and then it generates a job
so if i want to write a make file to do
the same thing i can't use a logic in
make that i usually depend on because i
don't know what the goal is going to be
normally if you the first time you start
thinking about writing and make valpo
java you say okay i want to create this
class and i do this pattern
transformation that create transforms
percentage dot cos into percentage dot
java and then you compile the java files
to generate the class files on and
you're done but unfortunately it's
impossible because you don't know what
classes are going to be generated so
Java Java Sea has been incompatible with
make Val strong the beginning and in the
night is yours it's it's impossible to
set up rules for it so what we have to
do is to fake so the makefile begins by
setting a few variables in this case
colon equals means evaluate the shell
command that is popped in the makers we
don't need to revamp it later find all
the java files we set up a goal in this
case we know what we're creating this
across the jar file is output of jar
that's easy we set the gold jar depends
on the bill but what is a bill the bill
is just a fake file a little small
violets touched and it's only purpose is
to remember to timestamp in correlation
to the sources so when make runs is file
a second time it will see that the
timestamp of the build is newer than all
the time stamps for all the sources and
say okay it's done I don't need to rerun
this action but if any sources is
touched to change to anything it will
have a time spent near than the build
file and it will retrigger the
generation of their classes okay looks
simple enough
now incremental compile so you have this
JDK it's got 8,000 classes or more or
you've got an even bigger product though
many many projects that are a lot in
under obesity a it will always compile
everything that's very inconvenient
there is no incremental jar update so
the jar will accumulate everything all
the time no classes are ever clean way
and there's a limit on the number of
source files on the command line so you
can't drill this doesn't work it looks
easy but it doesn't work so the two
major obstacle and make files angela is
you don't know what's going to generate
and you have so many more java files and
you have C files and C++ files which is
of course because standard Java
programming granularity is you have many
small data files instead of being evil
so it's never going to fit
so what are we going to do it doesn't
matter if you use an to make because we
cannot fix this outside of jealousy it's
Java see that it's a problem and the
only way to get proper dependency
tracking from jealousy is to write your
own java sea and unfortunately quite a
lot of people have done that but it's
it's a definitely a waste of time and it
doesn't matter if you sound to make you
cannot get multi core support pics to
Java Sea is single threaded inherently
single threaded so and this is just not
possible to fix from outside of jealousy
so one and a half year ago when I
started looking at the build system for
the open to decay I started thinking
about let's fix and so that we can do
this thing and I looked into aunt and I
I eventually found well it's just a
wrapper to call java sea and it only
took a week to determine that ok now i
have to do something with other see
unfortunately since i work for oracle
that's actually a possibility and
yeah we have a few attempts at fixing
this from aunt for example aunt depend
but auntie Pam can only look at the
class files because they didn't bother
writing their own Java C compiler which
is perfectly understand so they can
obviously dependencies that are exist in
the classified and in the case file you
lost quite a lot of dependency
information like where did the final
static information come from for example
and yes there is a fork in aunt but it
doesn't help you because it can't for
the Java Sea task by itself you can only
start to Java Sea tasks manual okay so I
das yeah sure they are good at
maintaining dependencies they already
have a database they already have their
own compilers as it eclipses compiler so
they do that perfectly but they still
haven't figured out to do multi-core
compilations and of course we need an to
make for batch compiles so one and a
half year ago my first attempt to fix
Java Sea was to add a few things to Java
Sea and do the rest they make so the
things i added was a server
functionality a demon which is quite
common a lot of people have done that to
get around the problem with Java sea's
huge startup time Java Sea is really
fast compiler but the start time time is
tremendous because first you start the
JVM it's going to load the classpath and
everything that's needed to run Darcy
then it started interpreting jealousy
and while it's running the interpreter
it's loading all the classes again from
the classpath and perhaps at that time
it start optimizing Java C compiler and
then it starts loading your source code
and the start compiling so it's when
it's reach that point then it's really
fast but before that it takes a lot of
time so the first thing you want to do
is to add a server and then I added an
option to output dependency information
so that they didn't need to parse the
java source code myself because it's
trivial tab that's kind of dependency
tracking inside Java Sea just one single
line a month a secret place I created an
output for natives to see which classes
do contain native methods so that I
wouldn't need to manually list all the
classes that contain native methods and
I other than switch to output a public
API of a package because the public API
is what is important when you want to
propagate recompilation if a
recompilation of a package does not
change the public API yeah then you
don't need to recompile
independent packages but if the public
area is changed yes then you need to
recompile the dependence and yes in this
first prototype make was responsible for
flitting all the work tasks into many
many cores and it through each java
package randomly in some order that make
decided on to the Java Sea server
believe it or not it actually worked but
it what did to make I look like behind
that nice macro that I showed you
earlier well it looked like something
like this if you can't see don't be sad
but how do you figure out what jealousy
is generating well you have to remember
you do a list after the previous compile
store that into a text file clean out
the class files compile again do list
again and then do grep minus x DF to do
a set subtraction between those text
files to get out the differences between
the previous compiler new compiled to
get out which class files disappeared so
i can delete them from the door so it's
like yeah and this this little part
which is substitute / back / dollar
dollar dollar dollar / back / Dollard a
lot of others back / dollar dollar
dollar / that's a result of the fact
that all in the class files contains the
character dollar which is the worst
character ever to put into a violent but
which we now we have them that's all it
it's the dollar character is an escape
character on every single level from the
file system up to bash so you go bash
said make all of those treat dollar as
an escape characters you need to escape
it on each level that's why you have
twelve dollars in a row that
now it took a while to get that right
okay this is clearly not sustainable
even though it's hidden behind a nice
macro call so the logical waves of
course to increase the size of the
changes to Java Sea so now I'm calling
this changes the small Java Sea wrapper
and of course this is in anticipation of
that these feature as it actually gets
into the official jealousy because
clearly we want incremental builds a
multi-core in jealousy but it will take
a while for us to get it stable enough
and agree on the command line options
and things like that so but so it's
called Smart Java Sea wrapping in the
meantime it's going to be pushed and
it's already pushed into the public
repositories of the building protein so
you can play with it today if you want
to and the command line for the small
Java Sea wrapper is simply you point to
the source root and you point to the
destination root very simple now there
are many other options as well but this
is the basic functionality it will
recurse down into your source tree find
all the funds splitting them up in
separate course compile them extract all
the dependencies and write all the
dependence information the timestamp
information the public API information
into this java sea state fight and the
default location is just glasses /
dallas estate you can move it if you
want to it forces implicit numb and i
will explain why so it supports multiple
cores using a very silly implementation
but it actually gives twenty percent
improvement in speed we can improve that
later and this Java Sea rapper sauce
needs new hook since I Java C so added
hooks into Java Sea that enables code
to sub-clause for example resolve and
java compiler in the java c compiler to
add this functionality so it's a minimal
intrusive change to java sea so we can
test this without worrying about brayton
jealousy now this is actually the part
in the OpenJDK make file that we use
today and here you can see the goal is
called the batch now this is for plain
java see you can see the sources and
other depends it creates make the deer
output there it uses list pause safely
to get out to create this at five I
remember there was a problem with the
command line length and to get 10,000
Java source files out to this file is a
problem so one way to do it is to do a
macro and this is the actual compilation
of the entire decade we rounded a vm on
the Java Sea specification the add file
a is this batch file you put on the
flags the output and the header args so
that's how the new built-in seduces
playing diversey and small Java Sea is
very similar the only difference here is
that it adds
remote arguments to define the server
the smart Java Sea arguments within this
you have the minor source pointer to the
source it permits unidentified artifacts
and this is a temporary solution because
in the old build you had this sub module
writing to the same class output and
this sub modem writing to the same class
output so you had many different modules
just writing down to the same location
on this which of course made it totally
impossible to track which class came
from where so so and this still happens
sometimes in the and the bill so
normally this much ever see wrapper is
very very careful and if it sees a class
file that shouldn't be there it will
delete it because it wants to keep its
garden clean so it cleans out but this
is a for the moment it's acceptable the
next step next test here is just a
paranoia test that compares a list of
source files with the list that make
generated because this modulus e rapper
will look 03 curse and find its
ourselves by itself but we want to be
sure that we calculated the same my file
their source files and make yeah and
then you have the same thing and yeah I
would like your birthday present and
that's a new functioning in make to get
around the command line length clinic
now your future may trod on your side
should be this simple
you specify how you run small java c you
specify how you found the sources you
say the goal is to java sea state
depends on the sources then you run
small java sea on the source minus h
headers and destination to be this is
simple so small java sea takes care to
make sure that the java sea state filed
timestamp is updated whenever it
recompile anything this is of course a
unavoidable side-effect because it
writes information into that file but
it's it's important that it does that so
it gets the same effect so make will
will very quickly scan all the source
files for the timestamps and compared
with the gel estate and then if
everything is okay nothing needs to be
done very quickly if something has
changed make will start a small Java Sea
rapper this much Java Sea rapper will
boot up and it will redo the scam after
its read in the Java Sea State file what
has to do that will take significantly
longer than the scan made by make
because this mo Java Sea wrapper is
probably still interpreted by the JVM
but it's okay we know that we're going
to do some work so it's okay that we
spend at the time of this and it will
find out which source file changed
calculate the package to compile compile
a packet propagate dependencies
recompile other packages ah we are not
had time to fix joy yet so in our build
system we still have unreadable mega
code to deal with the incremental
updating of doors but it would be nice
if Joe actually could delete classifieds
it didn't need them anymore
for aunt we will write as much jealousy
task and you just replace Darcy task
with motive as it does so the with aunt
you always have the start of time of the
jvm and the scan of the directories so
starting aunt to detect if an
incremental build is necessary will
always be slower than running mate but
that's a cost of running doll just for
your information you might be curious
what's inside the java sea state fight
and it's for the moment it's a very
trivial text file might be optimized
later on but for debugging reason it's
very nice to have it in text so it's
lists a command line which is minus or
source- lee beam it starts with a
package comes Angela internal runtime
then it has a source and as timestamp
and this package depends on java line
and java HD piece o cake it's really
easy to get this information out of
jealousy but if you're outside of Java
Sea it's not fun then you have the
public API information for scanner it's
got a pebbly public method which is
abstract next token and you have a
public variable zoom and the artifact
that was generated or scattered applause
so everything here is what you need to
actually do in proper incremental build
so why is now now we talked about
incremental builds in relation to make
files and aunt the other part that's
really interesting is the multi-core
point how do we speed up things for the
batch compile when we build something
from stop well it turns out that java
see it's a little bit like a compiler
that shades shades all the files like a
cheese slicer so if you have each file
like this it will take the whole set of
funds that he wants to compile and slice
them all Finley from the top so it's
really an this because everything is
dependent on each other you have the
object it depends well you have a
dependency not on double but double
depends on object string of the arrow is
wrong it a double depends on object
string depends double depends on string
and of course dream depends on of it so
you have all circular dependencies
everywhere and these dependencies
currently are implemented in dollar c
compiler as a pass which scans all the
files at the same time it's it's not
really possible to just cut that up so
the interface deals with all the linking
and references to public a vis then it
lowers things and it starts getting more
detail about the types the type system
things like that
and eventually it gets to the Emmett
face where it has created a syntax tree
it has all the information now it can
just generate glasses and this part is
actually possible to put on multiple
course they meet face so as I said the
current multi core implementation in
this much ever see wrapper that gives
twenty percent speed improvement using
three cores is silly but it's it's a
proof of concept and it actually works
and it uses the sore spot so what it
does is that it splits the different
files in the JDK which you can see a
coracle net to Java util concurrent
that's 2985 files and then you have a
Java util concurrent atomic to some
narrow channels sctp and then the rest
just Blitzen alphabetically tick tick
tick and then start up three java
compilers and tries to compile so
clearly there are dependencies from the
other blocks to the first one because
java.lang.object is clearly in the first
circuit because that's where it is but
the other two will manage to compile
anyway because we have pointed a source
path to the source root so whenever the
completion of the other chunks failed by
all would have failed it will actually
find the missing dependency even though
it wasn't explicitly mentioned on the
command line by going through the source
book so simple enough and if we are
lucky enough there are enough unique
files that do not point dependencies to
everything all the time so for those
unique files you actually win something
because they are only going to be
compiled on that particular call so did
it work yes it gave twenty percent speed
informants just doing this silly change
and of course as you understand object
of Java is compiled three times it's
unavoidable because it's always
dependent so a lot of files are compiled
three times so why three because for
didn't give any more speed up on the JDK
because there are not enough well it
didn't give it slowed down either but
it's so and three gave a slightly better
performance and tubes so obvious
improvements of this very rudimentary
algorithm it is of course if one of the
compilers have shared a compiler class
what share it between the other compile
and it might sound easy but it's not
that easy because these data structures
are really really interlinked with each
other so would be a little bit of work
to figure out if you could just make
reference available to the other
compilers or if you actually need to
clone them or something we don't know
that but it's it's an obvious
improvement you can share loaded classes
from the classpath so in this case i'm
building the classpath because I'm
building this dedicate but in normal
cases you build and you have a reference
library which is they take a library so
when it's java compiler load something
from that reference library well it
should obviously be shared between the
compiler civility and we would like to
add a omit Donald course so it just
throw out the mix on everything I
haven't done that yet it will be very
fun to try and see how much faster it
goes
unfortunately it turns out that minus
source path has a problem with the Java
code that's a little bit sloppy written
and that's the kind of Java code where
you have a class that's appended to the
end of your file so the name of the
class does not correspond to the source
file and as long as all the references
to that hidden class are only from the
main class in that file everything is
fine but you can have a reference to
that class from another source file and
then suddenly source path cannot find
this dependency because it's hidden
inside that source pop you don't know
how to find the source to compile to
find it and this is it's rather
interesting to see the males on the Java
language Lang tools team where two
people discuss whether this kind of
classes are allowed not according to the
spec so the jury's still out on that one
but it doesn't matter because
practically they exist because Java Sea
has allowed those kind of references
since the start we have to live in but I
added a new lint option that warns for
such classes in the JDK we have
approximately 20 such references so it's
a nice one
ok so now talked about small Java Sea
make an aunt and as I said in the
beginning all of this work was triggered
by a need which was my own developer
need when I'm developing the open D
decay and hotspot and the problem was
that the build was very slow so
approximately 1 a half year ago I became
upset with the current situation of the
build system because it severely
hindered me in my work and we had the
problem with Java Sea as I just
explained all the problems the circular
dependencies undocumented side effects
with the implicit classes going out from
somewhere where they didn't expect know
working dependency propagation from C++
to Java to C++ and such lack of proper
dependency propagation immediately
prevents you from paralyzing the build
because you don't know what depends on
what really so you can't really speak
things up and if you if you got
dependencies then you can do incremental
builds and the old build system
essentially liked all of this so to be
an efficient developer on the open data
key sources you have to know so much
that you knew that ok Shange this source
file over here then I need to go down
into this make directory and type make
here because then it will compile just
this part here and then I can copy this
pot over here into an existing build
that i got from release engineering and
test it so it was very difficult for new
developers of the open dedicated to
quickly get into this process
and of course the OpenJDK is a complex
product no surprise there but it has a
Java compiler CC it says jvm C++ and
Java it's a jdk c and c++ and java and
it has complex interdependencies you
have c and c++ code generated from java
code that's a Jane I header is typically
you have Java code that's generated from
headless at the extraction operating
system for example the frameworks in the
mac OS operating system to get access to
cocoa you have x windows headers that
you extract and generate java reposeful
you have generated Java and C and C++
sources from all different places the
character set and break it two raters to
quickly trait over you're smiling huh it
seems like you know something about that
but those are generated the Nile native
are you stuff are also generated so and
the new Java code sometimes needs a new
Java compiler sometimes not something
like that and sometimes even worse than
in Java compiler needs the new year
decay which creates in very interesting
bootstrapping problem which is usually
sold by copying the code from the JDK
that the Java compiler needs to be
linked to stripping out the contents and
just leaving the public API of those
classes and then combining Java compiler
windows on the source both so that's a
that could have been solved if you had
made impressive compilation just look at
the public API of classes so you
wouldn't have to strict it venue yeah
the old build system
you had to set up environment arrivals
yeah a huge technical left so each
developer created their own build
scripts and the knowledge how to set up
this build script or share through a
human peer-to-peer network and in the
new build system we created a configure
script instead which when run creates
the similar thing that you previously
had to do by your hand by hand yourself
so how to configure and Bill using the
new build system I won't even give us an
example of Elvis you get the source then
you go into a subdirectory and this is
temporary because when we switch over
permanently to the new build system we
will move the configure script to the
root source directly and you run
configure and then you type make oh
that's how it should be and when you are
built you have the built jbm inside
build the name of the type of will
dedicate in Java so you can start using
the Java directly if you want the build
output to look exactly like the one that
you install when you unzip a package or
something that you do make images so
make him is reshuffle so the class files
and creates the RTO jar and the creates
the tools your and things like that and
then only next you can do make install
and it will install into user local bin
and i'll see if i can make a short demo
so I wrong
configure
and it tests all sorts of things and
then I type make
now it's building the Java C compiler
and it's located in a language
repository you can see it it's building
using the old Java Sea the bootstrap
line tools which is the bootstrap Java C
compiler now it's using the bootstrap
java compiler which is small jealousy
and you can see that it's split up the
source is two on three course and now
it's building korba and a lot of files
are generated now it's splitting up for
by into three course now it's building
decks p this is pure java and it's
creating door now it's building jax-ws
now it's building the hot spot JDM now
this will run past quickly and it's only
because I Prime the sea cash so it
doesn't really compile the c++ code here
because then I would have to wait five
minutes so buddy the sea cash pick this
up
we can see they took here sort of three
seconds from compile just burped version
but CPP that's a rather interesting
because there is a significant speed
difference between different C++
compilers so we have C elder on Windows
is really fast clang is really fast d
plus vs. not so fast and so it's a and
this is D plus plus
and now it's building the daily k here
you can see the generated break
iterators and my HR sets
now here here's a big build that's
actually building all the classes in a
decade
and someone told me two days ago here in
the conference they had a customer who's
java source out it's done took six hours
to build so it's there are huge projects
out there so we clearly need to start
looking at how to speed up jealousy in
this case well this was rather fast now
if we do touch
I think yeah i'll show it on them
yeah this is a configure script
generates a file with love arrivals
equivalent to the ones that you manually
had create before but this is part of it
contents the the configure script has
minus minus help which is very nice
which means that you can get help on
what kind of configuration options you
have this is what I already show you we
skip that one ah this is what happens
when you do an incremental build with
smart you'll see you touch a sore file
and as I show you earlier in talk this
will be detected by make it will respawn
the small java sea and it will compile
the entire package that surrounds that
java source why why the entire package
well because actually it doesn't give
you any speed in the fifth benefit of
just compiling a single file so the
whole concept of recompilation
incrementally is based around packages
it makes the database slightly smaller
it can be extended to source by if you
want to but for the moment it's packages
so it's recompiled a package and it's
done in less than eight seconds
if I edit socket factory in our the
public void foo method then clearly i
changed the public api or not class and
I remake and will say package the avec
snap pop API has changed and then it
would recompile the dependencies as
expected so if you look at the build
times on my workstation this is the old
bill using the old night rods and if we
look at this one with the new smart Java
Sea and no see cash it will recompile
all the C++ code we can see that the
line tools is almost the same for cases
and that's mostly because you need to
use the old compiler to compile the new
component so it's the same Cobra went
from one minute and 32 seconds down to
seven seconds and here the main reason
was that the Cobra make files were badly
written they restarted java SE for two
of them and as i said before the cost of
starting dollars is tremendous so by
only starting to obviously once you get
a significant speed informant but here
we also using the smart Java Sea multi
core functionality and we can see that
in this case when we have disabled the
small Java see whether we get 16 seconds
and compile time so this modulus e
rapper gives us a double bill
performance hotspot it takes three
minutes to compile the C++ code in this
case I get five minutes because I had
enabled see cash in it's empty and there
is a cost when you compile something for
seekers because it outputs all the
preprocessed source code from the c++
headers so that's why it's more costly
but on the other hand when I recompile
and i already have time to see cash the
recompile on it takes one minute
and now it gets interesting we have the
JDK took 10 minutes and when you're
using Smosh ever see in OC cash it took
1 minute and 23 seconds when the sea
cash is primed we can see that it took
50 seconds so um and when we run without
this multi oversee we can see that it
takes two minutes and nine seconds so
this value should be compared with this
well and again we see approximately a
doubling of speed you see Miss motive as
a rapper yeah you have the total
so we have only started with multi-core
we will do more and
we have initial support for multicore as
you saw we have incremental builds with
proper dependency tracking we have added
a new option to java sea that's called
minus h that will automatically generate
native see header files for you in a
directory that is specified after minus
h if you compile files with native
method in a very simple option that
should have been added 10 years ago we
have a newly in förening and we have a
much more inviting development
environment so it's interesting because
the need to build our own product the
hotspot OpenJDK foster spawn these side
effects and we are not yet done so we
have improved Java Sea on two cases that
will be part of dedicate probably the
smart you ever see stuff is not going in
the decade will be later on
what we want to do is to be pushed so
it's part of the official bill we want
incremental door updates should be
relatively simple need to write this
macho visitas grant should also be
simple something that I discovered the
two days ago here in this conference it
will be very nice to have a public API
tracking for classes and jars on the
cosmos because if you imagine that you
have a huge product and you compile 20
different jars and then you compile your
app and you do an incremental compile
and you update it to yours but you don't
know what part of your app actually
depends on those jars and what's inside
the doors so if you can just compile in
your app those Potter depends on the
changed ap icing those jars that will be
very convenient and it's also very
simple change to add I just haven't done
it yet because I we've got the idea two
days ago so that's it thank you very
much now I'm amazed that so many people
were here listening to make files of
everything in the world and questions
yes to question those question is how
many calls have you managed was it busy
well it keeps busy but it doesn't give
you a speed appointment because it's a
since its basic compiling all those
share dependencies that all need so for
example java.lang.object is one thing
but you have it so if you have a 1
million source file line project clearly
you can divide it up in 50 course
probably if 1 million source files but
in this case you only have eight
thousand source files so when you split
it up to a few of them are unique for
that chunk so it will recompile
everything in though so it's very busy
but it's not fast so three course is the
one okay
if you're using customization process is
part of your builder they can be updated
that's a very good question and our
anticipated annotation processing but i
am not implemented support for it so the
question is problem with an annotation
processor is that you have absolutely no
control of what it's doing hopefully the
annotation processor walks through the
file manager give in to it through java
sea because if it does it will get the
file manner that i created from small
TLC wrapper which collects all the
output data so it listens in and sees
what's being written so that's one way
that you could capture information from
the annotation but if the annexation
processor doesn't care about them you
don't know okay thanks 011 sorry you
pick up the police's between the
constants I know I don't look at the
class once a look at the source so this
it depends on another source or it knows
that it depends on that source so if you
change the constant the dependent
package will change really compiled okay
yeah but there aren't the tent ask us
problem because it can't see where it
came around yeah okay
ever at the same time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>