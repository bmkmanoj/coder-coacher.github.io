<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Real-World Compatibility and the Java Promise | Coder Coacher - Coaching Coders</title><meta content="Real-World Compatibility and the Java Promise - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Real-World Compatibility and the Java Promise</b></h2><h5 class="post__date">2013-02-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CfC9nUXwYhw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everybody and welcome to
day two the technical session here at
javaone my name's Tim Ellison and we
were talking about Java and real-world
compatibility now we're kind of given is
a really big room and I have some charts
that have some pretty small font
examples on so if you start at the back
you might want to move forward of it so
you can see all the details that we put
up on the screen and if you are here
earlier for the soundcheck you love
third foster that's that's the highlight
of the talk already right side I can't
be that thank you for the entertaining
start the mandatory disclaimers my BM I
am so let me just introduce myself
briefly I have history of implementing
virtual machines from small talk through
to java and other kind of stuff i'm
currently based at IBM UK in purley
which is about an hour's drive outside
of London and that's the center of the
Java Technology Center for IBM so I look
after all the class library I look after
Java rate deliveries obviously at some
time next year what we're looking to do
that and I have an email address looks
like that ok so we're going to talk
about today is compatibility and why
Java compatibility is important to
everyone all right users and employers
alike I'm going to describe the
different types of compatibility that we
consider and then talk about why those
different types of compatibility are
important what you can do to protect
yourself from changes that are made in
the Java platform and then at the end
there just a little indication of some
of the tools that are available to help
you address compatibility in your own
code as well as finding things in jdk
itself
so it's a little kind of scene setter
about why compatibility is important
obviously java SE is offered as a
universal computing platform which means
that we all get to program in Java and
leverage the implementations of Java and
across a wide variety of different types
of systems and at IBM were shipping on
windows boxes on linux boxes on the
mainframes on blackberry devices on and
so forth so you get the benefit of the
broad ecosystem where java is
implemented and of course all the
surrounding ecosystem of books and
technical conferences law all that kind
of stuff rate set I'm assuming that
everybody is pretty on board with that
idea given that we're all set here at
javaone so the java SE implantation
itself is specification based and by
that i mean there are a number of
specifications which describe how java
behaves that embodied in aspects like
the java language spoken vm spec
platform the iceberg of course the
Javadoc that everybody's used to reading
as an implementer and these are very
detailed documents they describe to
people like myself as an implementer how
we need to import the code so that we
fulfill our contract to people who are
writing applications or users and of
course the same documents are read by
users to understand what sort of
assurances and guarantees they're given
by implementers in terms of how their
programs are going to behave now java
evolves over a period of time obviously
going up through that many different
major and minor revisions and as Java
evolves and specs evolved with it to
describe the new types of behavior and
because we have the specifications we
can collaborate on what that sort of
behavior should be and so he actively
collaborate the java community of
influences on specifications and yet we
compete on different areas which are not
part of the specification such as
performance memory footprint and
diagnose ability
problems and so on and so forth and
platform coverage and those are areas
where we can compete but within the
bounds of the specification that make
sense so the compatibility promised that
you get Wiz Yabba is that when you stick
to the rules your program can be written
once and can run anyway right not for
that ability colors and so when you're a
programmer your programming to the Java
platform you're not programming to any
one particular implementation when you
write your code you're not writing it
specifically for a Linux box you're not
specifically wrestled for a 31 bit
disease series mainframe machine you're
writing it to the Java specification the
Java platform and then you get that war
a promise the implementers job is to
take specifications and kind of minimize
the distance that conceptual distance
between what the specifications are
requiring me to provide an implementer
and the underlying capabilities of the
platform so I want to really exploit the
underlying capabilities of the Machine
platform but do that in a way which is
consistent with the assurances which we
are giving to our Java programmer users
through the specifications and because
we have those strong specifications you
know different people can make different
trades often trade-offs in how they make
those hella do those implementations
right so at IBM and we kind of cover the
gamut but you know I'm also making
different decisions about when I'm going
to get compile the code and how much
memory i'm going to use for large
websphere installations are running on
mainframe devices or clusters of
high-end server machines compared to
other people with making decisions about
how java is implemented on a constrained
embedded device so you get this very
broad ecosystem of implementations and
with different goals in mind of what
they're trying to achieve as an
implementation
and that in itself can give rise to some
compatibility issues which will take a
look at bit later on now the way that
you can ensure that once you have
written your implementation that it does
conform to the Java specification is
through the technology compatibility kit
the tck is and when applied to the JRE
so-called JCK so you may see those terms
of their care one on the same thing the
purposes of this discussion this is a
suite of tests that you're obliged to
run and pass in all different modes and
before you can declare your
implementation to be Java and that is
the assurance that when we talk about
the Java platform and and we put the
coffee cup logo on it people understand
the suite of implantation specifications
and that that implantation has passed
excuse me so in the in the green box
down there at the bottom this is lifted
from the Java language spec I'm sure you
can read it if it's a fonts large enough
but the key point here is that yeah all
the implementation details part the
attention is that a program written in
the java programming language should
compute the same result should have the
same effect and across all different
machines in plantations okay so I trying
to drag this back to the real world but
in the real world of course
compatibility extends beyond those
specifications and we see many
applications which have a dependency
beyond that which is written down for
example the specification doesn't say
what the list of system properties must
not will contain right there's so
definition what sort of minimum set of
oliver's contain but I the system
properties can extend beyond that many
more set and some applications make it a
looking for system properties which are
not part of a specification or appear on
an implementation but may not be are
others command-line options anybody
that's sort of mood around between
different versions of Java will be
quite familiar with the fact that
different implementations have got
different command line options there are
some which are standardized and
well-understood obviously minus
classpath is one which you're going to
see everywhere put the minus x options
things which control the garbage
collector things which control digit
implementation these are not standard
these are ones which if your application
requires modification of the runtime
behavior of the GRE you'll be specifying
these kinda line options and these could
well trip you up when you go to to move
between implementations and also
building dependencies on other things to
not part of the spec so think mr. should
put out by the vm whether they are the
dutch version string that goes out there
i've seen applications which are parsing
that that's not even kind of closely
standardized within different releases
of IBM Jarvis so you know we kind of get
caught out sometimes breaking people who
are putting dependencies on our own
implementation details nevermind things
which are part of the Java specification
or not so when we talk about
compatibility its is these two different
things right it's the right once run
anywhere promise that says that the code
that you write for the Java platform is
going to work everywhere and and you can
have that promise for sure you can get
water in in real-world Java as long as
you constrain yourself to the set of
promises which are made by and
specification itself and but i'm going
to use compatibility at a slightly
broader sense than that and that is that
you know not only within an individual
version of java and trying to get to run
across different implementations but
across different versions of Java there
are compatibility issues as well and as
you want to move up three different
versions of Java obviously to get bug
fixes and enhancements and that sort of
thing and get the advantages of security
fixes as you move up through java as
we'll see in some of these later
examples there will be some
compatibility issues you may have to
deal with as a platform implementer java
collaborators through specification have
to make these balances and trade-offs
between what is the right thing to do
and what is the least disruptive thing
to do so let's go have a look at some
examples of those things and I'm going
to break down my examples into three
different areas and I'm calling on
functional compatibility meaning when my
program is running does it have the same
effect as it had last on the ground
source compatibility if I have some java
source code and I recompile it does the
result have the same effect as the last
time I compiled it and binary
compatibility which is can I take two
sets of class files and still combine
them together he when one set has
changed right and still have the same
effect at the enemy okay so let's do a
little bit more details
functional compatibility injuries as I
say here primarily defined by the Java
specifications and the specifications
themselves are very carefully considered
the information which is written into
the standard which you'll read in Java
Docs if you're an API on a level
programmer are are there as your
assurance of behavior but but we also
deliberately do not put things into the
javadoc where we do not want to make
such assurance it's and that could be
for a couple of reasons either we would
expect or we know that the libraries
behave differently on different
implementations in that aspect okay now
often that is called out in the spec to
say there is implementation detail here
but sometimes it isn't sometimes it's
let quiet and if you're not given
explicit assurance in the Javadoc and
then you shouldn't sort of run your
program to see what happens and then you
know make that as an assumption is
that's where is going to be on every
implementation and the other reason why
it might be left out is because the
implant eight we want the ability to
change implementation and produce
further optimizations and and so you
know again if you specify precisely how
an operation is achieved in that API
that could very well limit to your
ability to to change the employment
section later and having those
implementations could could lead to some
breakage a couple of examples here of
things which are not specified and hash
maps iteration order I think terrorism
Brian it runs to core libraries
discussion yesterday evening at the bar
and there's a discussion about the
changes should be made to
java.util.hashmap to allow for better
hashing of strings to avoid collisions
the hash map itself has an iterator of
course it's going to rate over the
values but the order in which those
values have been inserted into the map
into the
hashmap is an implementation detail
rather the audience s toward Europe you
put men in your application level order
they are stored based on a hashing
algorithm and when you iterate over the
results the values of the hashmap they
come back in an unspecified order now as
an application right if you through
experience you know regular program see
which order these things are coming out
and assume Lee so it's good to be that
way you will be brokered and as I say a
concrete example which is discussed
yesterday was the changes of key string
key string keys in hash maps will be
changing in gr eight and also seeing
examples of things like walking the
stack you can get hold of the stack from
Java but looking back up the stack to
see where you were called from you know
the stack traces is not a specified
format and that's definitely
implementation detail which will change
and pausing messages which other spoke
about earlier things like version string
and so on right error messages looking
for those they're not part of the
specification
the Java platform is very good about
ensuring that when you are given a
promise in the javadoc about some type
of functional behavior that that promise
will be maintained an Oprah version to
version release of Java when it's found
that the implementation is out of sync
for the specification as sometimes
happens we have two options right we can
either change the implementation to
actually do what the spec required it to
do or we can change the spec to actually
fit what the implementation is doing and
that's when those judgment calls I spoke
about earlier right it depends depends
on how on where we are in the overall
life cycle of that particular java
release if it's new code that's just
been written and it could be seen as
just a straight bug that it's not doing
what the spec required it to do and you
know it in their circumstances the right
choice will be to go in there and change
the implantation but if the code has
been out for a long period of time if
people have been coding to that
particular type of implantation you
could actually do a lot more harm than
good to change the implementation to
match the spec and in those
circumstances the right thing to do
really is to go and update spec and
saying it wash this is how it really
happens just to show that this is not
particularly uncommon this is a grub of
and it's not the whole listen I don't
expect you all to read the details here
of course but these are just a whole
bunch of changes of functional changes
which have happened in the Java platform
between five and six i believe so let's
look at a simple example again I
apologize if you can't read that shot to
get all i'll try and call call out some
the salient points so I've got a snippet
of Java doc from the java.lang float
class and a particular method here is
pass float so in java 6 api spec and the
relevant part is that it says
that it's going to pass a float from a
string it could throw a number formats
exception and it will return the floats
value represented by the string so I
have a little snippet of code just below
the line which says I've got a public
class called parser and doesn't do much
really is just going to parse afloat and
I passing in null okay so you may expect
to get a number format exception but in
fact what you get is a null pointer
exception now the spec didn't say this
method could throw a null pointer
exception it said it would produce a
number format exception and so here we
have the implementation behaving
differently to the spec and so in that
particular case in Java 7 the spec was
updated right that would be now there it
seemed like a reasonable thing but
passing null would produce a null
pointer exception and so if you go and
have a look at the javadoc for the same
method in Java 7 you'll see that the
spec has been updated even something as
fundamental as line float to say that it
can it will throw a null pointer
exception and so the same piece of code
they're written passing melly on java 7
just behaves the same way Mike still
throws a null pointer exception and the
point here is that you know when we talk
about compatibility it's not just in how
the code behaves how the implementation
behaves but it's how the specifications
are written right is it you can break
compatibility by changing a javadoc
coming like this for sure
here's another example this one's taken
from nao channels Datagram channel in
this case the specification has been
changed to say that if the socket
channel is not bound so here the methods
send receive and connect were with
changed when he votes on an unbound
socket so you've created new instance of
data data channel and you've gone to do
a send and receive on it directly
without doing any bind in the previous
implementation java 6 these methods used
to just return null because you hadn't
done the prerequisite which was defined
it but that wasn't specified in Java 7
when you go to doing those operations it
will do a default thing which is to do
the bind for this and then continue with
the operation and the spec again has
been enhanced here just say that that is
what will happen so this is another case
where this is a change both to the
implementation and to the specification
and so the specification used to be
quiet on the subject and the behavior
walls that you just get a nova in this
particular circumstance now the
specification is explicit and says that
a vine will be performed and the
behavior has been changed to do the bind
and continue with the operation now
that's obviously quite a significant
change in both aspects and on on
retrospect in retrospect doing the the
default bind there was the right design
choice and that's why it's written that
way in in Java 7 however it call also be
argue that that was quite a fundamental
change to the behavior of this and it
may well be rightly or wrongly
applications whoo-hoo fall foul of this
particular change in the specification
behavior and so in this particular case
there's a system property introduced and
you'll see this in a couple places where
you can specify
minus the sunday OCH bug level and set
it to 1.4 1.5 or 1.6 and and that will
reverse the behavior of data channel in
this particular case but potentially
other areas of the class language code
as well to the earlier type of behavior
so here's his an instance where the
compatibility has been broken the
functional behavior of the application
is changed because the platform has
changed this implementation and yet to
preserve compatibility the system
property is being introduced and given
people the ability to revoke revert back
to previous protection and it's not just
things which are quite as obvious as
that right so yeah you could find those
by looking at Java dot but there are
other things which you may not find
quite so easily I've given a couple of
examples here in Java 5 the class file
format was changed so that now when you
have references to classes in your code
they will be class literals in the
classifier and and that's important
because if you have code written like
this if foo is an instance of your class
right prior to job of five that would
cause a class load or the your class
definition and but beyond job five it
doesn't right it's just doing it test
against a literal name of that class and
why does that matter well because when
the cost is loaded the class will run
its class initializer and that class
initializer could have some side effects
and the side effects could do things so
yeah again it's a change in the in the
vm spec it's not one that necessarily
people would go hunting for and find and
yet it could have quite a significant
change in the functional behavior of
your application in this particular case
you know those references in the class
parts that are generated are done by the
java c compiler there's even more
interesting really in that
that functional change occurs if you
recompile your code and really on those
on those VMs not just by by by running
the previously compiled code on a later
vm you may we'll see some functional
changes due to changes in the way we
optimize the code so again as an
implementer we do just-in-time
compilation of the byte codes and
execute those so the JIT is at liberty
was in the definition of the Java memory
model to rearrange some code within the
bounds of the read and write barriers
defined by the specifications and unless
you're unless you're very careful I set
at Eureka there are some circumstances
in which it is possible that your
functional behavior changes because the
JIT has rearranged some of those byte
codes again within the assurance is
given by the job of memory model if
you're not familiar with the jumper
memory model you may get caught out and
start doing pretty static and then we
also see some functional changes and
behavioral changes to just due to the
way in which different people have
implemented the specification and all
the way down to particular example I
have here is class get name and we spent
quite a long time in IBM tracing down
above that was caused by cost get name
on Oracle's implementation and returning
an intern string so you always go back
the same incidence of strength for a
particular class name and then it was
used in an identity hashmap later and in
the IBM's implementation of the vm we
didn't in turn the string we returned a
new instance of the string so of course
the identity hash amount wasn't matching
these things
the spec doesn't require it to intern
the string and so if somebody sort of
further down down the track had made
that assumption and likewise unlocking
and so on you can soon get into
interesting situations so just to
summarize on functional compatibility
you know we assure that we're compatible
across the job platforms using the TC
case and you should stick to the
specifications and the assurances of
specifications give you for how the
platform is going to behave and when
things break then I typically will be
over changing implementation or changing
the spec and or providing some sort of
get out of jail command-line options to
to allow you to switch between those two
things and when the functional
compatibility changes get introduced
well really early at major platform
boundaries right and and even then only
after very careful consideration so that
is it is taken very seriously by
everybody they are quite hard to spot
and because you know it could be changes
in the confrontation you saw the list of
RFPs oh I put earlier each release comes
with a list of compatibility changes are
made for function so it's worth sort of
seeking that out and technique look at
it and when you need to resolve these
functional compatibility differences it
really does require some sort of
understanding of what the intent of the
program was to ensure that the new
function and the new behavior is
satisfactory or you need to change
implementation to match the video
okay so let's move on to source
compatibility
so when I talk about source
compatibility what I mean is given a
sort of Java file contains java source
code does that result in the same set of
binaries when you compile it using your
new java platform a different java
platform and the most obvious sort of
case to consider is that you get a
compile-time error which may occur
because some of the changes to the Java
language have made your previously valid
program invalid and or it maybe even the
way around writing me about a program
which wasn't valid in in one version of
the Java language and it sort of becomes
valid which is probably a less
interesting case because not many
peoples on keeper keep keep around
invalid programs and try them on later
versions so there's more interesting
obviously the case where you had a
program which used to work and compile
successfully and now it did no longer
does and so the main requirement here
for the source compatibility and is if I
compile my source code does it resolve
all the references that i have down
references down into the platform to the
same all right now the same any virgin
comments the same references in the
platform as it used to do and why
wouldn't that happen and maybe the
language has changed to introduce new
keywords and and it also happened
because we've introduced new types into
the platform so let's take a look at a
couple of examples here so again if you
take a squint at the top little snippet
of code this is a change it programs
used to work on Java 140 so here I've
compiled this program of 142 and run it
and it produces the output the word
false however when I try to compile same
source code on Java five onwards I get
compile-time errors and that's because
one of my variables is called assert and
assert became a keyword in Java 5
and so it doesn't make sense as a long
way as the Java a cert keyword to appear
there and my program was used to work
perfectly well I 14 to try to recompile
on Java five it doesn't compile and
here's a different example so again
little snippet here I've called out just
printing the results of testing whether
this class which is called passport
class for historical reasons and it's a
proxy to proxy dot is proxy class on 142
the answer is false it's not a proxy
class but when I come to recompile this
on Java five exactly the same source
code it fails to compile and the reason
here is that because if you look at the
import statements I'm not explicitly
importing the specific proxy that I'm
talking about and a proxy class was
introduced into the job and net so he
was talking about two different types of
proxy here we've got the object proxy
we've got the network proxy and so
because I've got Java line reflects our
and Java netstar it suddenly becomes
ambiguous in Java 5 when that second
proxy was introduced which one are we
talking about it was done big using 142
their only wall was one thing called
proxy or 14 to come Java fiber two
things called proxy sir and the compiler
 was all that and
and threats panera so yeah this is a
change in the job of platform itself and
I'm using the Java platform as examples
of course all of these examples could
equally apply to your application code
and that's why it's canceled it
discouraged to use the the star notation
for importing everything because it can
lead to the sorting ambiguity and it's
better to explicitly import times here's
a different type a little bit more
subtle I guess of source incompatibility
I guess it's more kind of behavior on
source together so here muddle program
I'm creating a new instance of
bigdecimal representing the integer
value one so that's just a digit one on
that constructor and the match
constructor here is bigdecimal double
right because that's the closest match
that the compiler is going to find using
the Java language rules I can widen the
int to a double and so that is a
perfectly valid program there is no
explicit int constructor and it will
match the double and do what you expect
however in Java 5 an explicit int
parameterised constructor was added to
bigdecimal and so now when I compile the
same program because there is a more
specific version which explicitly
matches the end I'm no longer linking my
source courier when a compiler that's no
longer a reference to the method which
is the double constructor it's now a
reference to the int concentrate
now in this particular case ya i bleep
it doesn't really matter we're still
constructing a bigdecimal the impact of
moving from that double based to into
based constructor there is not going to
be an issue for us but again it kind of
demonstrates that as you evolve your
class libraries and its platform evolves
and your recompiling your code the same
is a source code could end up actually
referencing different things inside the
time the application for who okay so so
i'll just point out that was an issue
for somebody's in rock all right for
this particular case of bigdecimal okay
and especially you know when those
constructors well likewise have a side
effect yeah that's that's really going
to i be noticeable okay so source
compatibility the goal is that update
releases the java will be maintaining
source compatibility again it's a major
release of job if you're going for five
to six six to seven and cemetery onwards
you there will be some work required to
move up between these different versions
it's not necessarily or write once run
anywhere story here the Java platform
may well break source compatibility and
if there is justification and a reason
to do so so
it's just just plug it up or at least
just to just to let you know that Sam
yeah these things are possible and you
need to look out for them and do the
adequate amount of testing and so on not
not not only at the API level that's the
place where so the true consideration is
given to do source and functional
compatibility but when you start
reaching into areas of the platform
which are beyond the spec then pretty
much all bets are off so any references
from your application to calm some
packages and you have no assurances
that's that's going to continue working
in fact almost the opposite right now
that the calm some packages and
equivalent things which are not defined
by the specification their role in life
is to support the api's themselves and
as I mentioned early part of the tour if
we think of better ways of implementing
some of those ap is we reserve the right
to change the implementation potentially
quite substantially and those internal
classes may well behaved differently
they may want disappear especially when
you look out towards modularity whereas
the potential layer to start to scope
some of the visibility we often the
reason you can reach those things is
their marks its public and that's so
that API types can reach over into
implementation packages to reference a
time for a corset unfortunately these
applications can also reach into those
public types when we get modularity will
be able to have a module level scoping
which means that you won't be able to
reach from the application down onto
those implantation times at all
so that again could cause some sort of
breakage and solving these sorts of
problems well some of it can be done
from this sort of mechanical
transformation and obviously that assert
that i showed in the earlier example is
a case where you can look through your
code figure out any places where you
have a cert it's a variable name you
have some discretion so what you call
that so that could be mechanically
changed and let's look at binary
compatible
so binary compatibility is interesting
because the the assurances are looking
forward with binary compatibility is
given two sets of class files can i link
these things together without getting a
linkage exception that's pretty much
biocompatibility definition so it's a
pretty simple definition and what does
that mean in terms of the assurances
that you're looking for in your binary
program files well perhaps you I
provider of AP is right you have a set
of libraries of reusable function which
you're distributing either in-house or
are out to folks and or you have
dependencies on other third-party
libraries and you want to ensure that
new versions of those programs are
binary compatible and replaceable units
with with later versions and of course
you want to do that because not many
people are writing applications of a
completely site alone where you compile
all source code but after linking to two
binary libraries ourselves so as library
implementers and library providers
library users we need to understand what
binary compatibility means for API so
we're going to consume or provide in
binary format
by the same token as a job implementer
we need to understand what the rules are
that allow us to evolve those class
libraries so one way we can ensure
compatibility is to never change the
signature of the methods and types and
things which we are providing and
however that can be very limiting and so
there are sort of rules which allow you
to change the binary signatures of your
your classes whilst maintaining binary
compatibility which course means it will
link in with existing programs in the
same way I did previously this Java
versions goal is to be binary compatible
with earlier versions one aspect of this
is just getting the file to load in the
first place right so when you run a Java
program against a particular class file
pretty much the first thing the vm is
going to do is check the version number
of the class file and check that it's
versioned in a format which people it
can understand so here I'm just running
my little java test i compiled it on a
later version of java and try to run it
on an earlier version of java and the vm
is throwing this exception saying it's
an unsupported class version error she's
pretty straight forward and what does
that mean well you know there is a magic
number embedded in the header of the
class file which describes the file
format version and just for your
reference here are the sort of version
numbers which are accepted by different
versions of Java and you can see
everybody accepts version 4 5 decimal
zero and onwards and there's a pattern
for life beyond Java 1.1 so version 1
point n of Java will be version 45 244
plus whatever the end number is
for example 1.6 can understand version 4
5 decimal zero two five zero decimal
zero cost file formats and however just
because you're running on an older
version of the GRE doesn't mean that you
have to stick with the old version of
the compiler backs up to the contrary
encourage people to move up to the
latest version of the java source
compiler to get all of the fixes in the
compiler and the optimizations in the
source compiler itself and you can use
the minus target flag to say generate
class file formats which will be
understood by this earlier version of
the vm now you know of course you can't
use any API so it's written a later
version so you also would have to
specify the boot class path of the Java
Sea tool itself so it compiles it
against the appropriate class libraries
but no use later versions of the Java C
compiler even when you're running
against early versions of to do okay so
that's one place in which you'll see
binary costs file incompatibilities is
the version numbering and other places
that we've seen it are things like
bytecode optimizers of the skaters
injectors up sort of thing which go in
there and they meddle around with white
codes the ordering of it and so on some
of them perhaps not as careful as they
should be and may well produce class
files which are not compliant with the
class part for my specification and
again you'll get very fires link link or
linking errors so to just do a quick
sort of dumped on the screen here of how
you would be able to evolve class ap is
and maintain binary compatibility
against it's not an exhaustive list it's
there to show really that there are lots
of different ways in which as a library
developer we can evolve Java and
maintained by Rick compatibility and
likewise as a
a library provider you can do some
likewise the URL there there's quite a
good paper on the eclipse a dog website
of course all this is in the
specification it's quite a good summary
that's right on the Eclipse org website
which outlines of these rules and says
which one's compatible original and the
one that's probably worth calling out
here really is in the list of things
which break binary compatibility is
adding public or pathetic message to
interface and again if you were Brian's
talk yesterday in lambdas he spoke about
the virtual extension methods that are
coming in for java 8 which will allow
which will sort of remove this
particular restriction to the extent
that it's introducing a default
implementation so this is sort of seeing
that there is a binary breaking change
and working around it and saying you
know how do we get around this
particular constraint and this
particular case is it's going to be very
helpful for evolving the existing Java
class file maintain these binary
compatibility and ensuring you don't get
those linkages
so I did kind of look pretty hard to see
if I could find some elites in the
platform and you know there's a good job
there's hardly any tissues from so this
is kind of a very modest example really
and it's down in the bowels of some awt
code as 2d double where a particular API
method was changed from not being final
to being final between six and seven
which is a binary Britain change if
someone were to be subclassing that so
you would have been in the past being up
to subclass that particular method in
java 6 in Java 7 you wouldn't but again
I think this is one where the right
judgment called was made because who is
going to subclass that thing is sort of
not designed to be so cost and that's
why smart is fine so now we'll fail to
link your you go if you have to know and
the other place of sort of binary level
compatibility on tits touch on with
serialization now sterilization is
obviously very useful or when you're
transporting objects across some sort of
protocol like Caroline some protocol
used by art liners the binary
representation of the object contains a
serial version uid which embodies as a
hash the definition of the class at the
point of which that object was that
instance of the class was serialized
which is all well and good however if
you have a class which is serializable
and you and you serialize it and you
persist a particular object you now have
to be very careful about how you evolve
that particular type definition to
ensure you maintain binary compatibility
of the serialized form on the serialized
form you ID say it's a hash that
embodies
a whole bunch of internal methods as
well as all the public and private
methods in the field definitions and the
orders and so on and so forth so it's
pretty tight and going to be pretty
difficult to evolve the class in a way
which doesn't modify any of those things
you're pretty much limited to change in
the body of methods so yeah again URL
there that shows you precisely what the
UID is based upon and I think the
general rule that that's pretty much
like accepted for a serialization now is
that if you do have a serializable time
its to hard code the serial version uid
so the serialization framework will look
for an instance very variable called
serial version uid for a particular type
it's being serialized and it exists it
will put that on the street if it
doesn't exist it will compute it so if
you hard code it and then you pretty
much have control now over the
definition of compatibility because you
can change that your ID when you
introduce a breaking change the
serialized form and if you don't change
if you're not breaking if you're able to
deserialize using the same form then you
don't exchange that number
so kind of final thoughts here as an API
producer obviously we have to think very
hard and long about the implications of
changes and limit to the different areas
of compatibility whether it's functional
source or binary compatibility as an API
consumer there are steps you can take to
ensure that your exposure to those
changes is minimized I've spoken a
little bit about the API Doc's again
compiler warnings are your friend in
this instance if you see things which
the compilers plugging up telling you
how to do something investigated figure
out what it's talking about and why
that's it why why not it's the case
another good way of doing it of course
is to get early access to development
builds and you know openjdk is a place
where you can show up you can have the
discussion about compatibility you can
also get early access to bills and try
your program if you see breaking changes
in the platform plug it up again it may
well be something which the developers
have deliberately decided to do an
assignment it may be something which
hasn't been seen before the place to
have that discussion is OpenJDK
and it's like I ended a little plug the
website application server migration
tool kit is a toolkit which IBM provides
as a free download this embodies all the
different rules and that I've spoken
about here plus others now it's called
the web CEO migration tool kit and it's
kind of targeted towards people moving
app server but in fact part of that is
moving the java SE version as well so
whilst is it is possible to go and look
at the compatibility document that's
produced on each java release and see
which one's apply to you this particular
tool will rummage over your source code
and fly up places potentially with quick
fixes for how to resolve some of those
it'll highlight in places where there
have been some compatibility changes and
you're using those api's or those types
and give you a chance to find them and
result there's some final links for
various tools in the IBM places and I
end with a copyright statement that's
all I have thank you very much for your
attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>