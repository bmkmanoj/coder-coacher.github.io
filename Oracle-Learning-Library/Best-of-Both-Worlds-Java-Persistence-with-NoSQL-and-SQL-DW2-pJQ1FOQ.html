<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Best of Both Worlds: Java Persistence with NoSQL and SQL | Coder Coacher - Coaching Coders</title><meta content="Best of Both Worlds: Java Persistence with NoSQL and SQL - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Best of Both Worlds: Java Persistence with NoSQL and SQL</b></h2><h5 class="post__date">2013-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/DW2-pJQ1FOQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you so much for turning out to
hear the best of both worlds java
persistence with no SQL and SQL now how
many of you program in Java a lot okay I
we got the right we got the right crowd
here okay we were we were thinking of a
subtitle for this talk and we came up
with hardly strictly SQL and they didn't
like that so much so we thought okay
about hardly strictly java and they said
that's really not going to fly in this
in this conference here so you're going
to hear a bit about Java and a bit about
not java and you'll hear a little bit
about SQL and a lot about no SQL we're
going to tag team this presentation
we've never done this before so I was
going to do it all by myself and then JD
wanted to do it all by himself and then
we just decided we would split the baby
right down the middle so as a way of
introduction I've been programming in
Java for let me see 20 years no more
than 10 less than 20 I was involved in
the Java EE development for the SQL
program the java persistence and java
data objects anybody here know about
java data objects ok so that's that was
one of my pet projects for a while until
they decided that they didn't need to do
java data objects as a there's a thing
anymore and i've been involved in the
mysql team and the mysql cluster team
since sun acquired mysql and then oracle
acquired Sun and then that all became
one big happy family so that's me I've
got a bias not against SQL not against
Java but I think the world is big enough
for a lot of different solutions so
that's me and here's shady
Thank You Craig and I'm I'm JD john
david duncan I'm I joined my askew la be
a little startup in about two thousand
four and and have been on on the ride
ever since so we're going to we're going
to talk a lot about MySQL cluster we're
going to talk about many different
languages and programming environments
what mysql cluster is really the common
theme except a little bit of what we
talked about will also apply to
traditional mysql and nodb so when when
we get to the nodejs stuff through
javascript that has multiple backends
and a normal MySQL client is one of them
but but the basis of in fact if we go to
our best of both worlds title that comes
out of mysql cluster and and it's kind
of unique position we think of being a
low-level database a low level data
store that's capable of really high
performance and also happens to to have
good connectivity with with the world's
most popular open source sequel database
so the standard oracle safe harbor
statement we will talk about some things
that are not yet generally available and
we're not making any promises about
whether they ever will be and especially
not about when so the vision of mysql
cluster is to is to become the default
database for any application that's
that's real time and by real time here
we mean your response time is bounded
you need to be able to
predict that it with great confidence
that it will be within a certain range
transactional at scale and where
downtime is simply not an option right
mysql cluster is a product that's been
evolving towards that over many years
and and i wouldn't have said a year ago
that we were there but but today we can
go out and make this statement so here
we big big slide full of full of logos
who's using it some of the companies on
here the ones that have been here the
longest are either they operate telco
networks or they sell equipment to
people who operate telco networks so the
origin of mysql cluster is in this in
this database that that you embed in a
in a in a in a situation where and let's
talk about network operators and some of
the requirements they have there is no
such thing as a planned maintenance
interval right the phone network the
phone system does not go down so a
change of a schema is an online
operation a backup is an online
operation an upgrade is an online
operation that we call a rolling upgrade
so you start with one node you upgrade
it your cluster enters a state where it
has to understand that some nodes are
running a different version of the
software than other nodes you keep going
you upgrade the next one eventually you
get to a point where the rolling upgrade
is complete and the whole cluster
understands that it's running a new
version and that new features are
available right the newer customers on
this slide some of them are online games
I've
zynga and and blizzard here so they've
taken those requirements 222 online
gaming where the reliability and the
availability are still required but the
use case is a little more general back
in the telco days all queries were
simple and all production code was
written in C++ going going into the
gaming world there's not so much
low-level C++ code either you use the
api's we're going to talk about or you
use sequel and part of the ability to do
that is based on the mysql cluster 72
release came out earlier this year and
really made joins perform the way people
expect them to because we're where the
where the the sequels the sequel node
the mysql server used to have to fetch a
lot of data no data from the data nodes
and run and join they're moving the data
to the query now we move the query to
the data and we press I'll push a lot of
that query a lot of that join logic down
to the data nodes so the design goals of
mysql cluster then this sort of
summarizes what what i've been saying to
scale out both reads and writes because
it automatically shards out your data
it's got it's got a sort of a multi
master kind of topology where any node
can go down and the cluster stays up and
you can add nodes and and get greater
parallel ISM because you've added notes
to a cluster very high availability
because any any node can fail any
network link can fail there there should
be no single point failure that brings
the cluster down and it can heal itself
and operations like upgrades and backups
or online the the performance is
real-time bounded know the heritage of
that is that we started as an in mem
database and an in-memory database is a
sort of a specialized concern right the
evolution has been so that now you can
have tables with data on disk but all of
your indexes still have to fit in memory
so it's a kind of a hybrid model here
even though it's always been an
in-memory database it's always been a
durable in-memory database so actual
transactions happen at the speed of
memory but there's always been a
checkpoint process running in the
background writing that stuff to disk
right and then we get to the really
interesting thing about a shared nothing
cluster which is when a node comes up
and rejoins the cluster there's there's
a node recovery protocol which is a lot
of where a lot of the magic is so sequel
and no sequel meaning we wanted to
perform really well as you expect from
the MySQL server even to the point of
reporting type queries data warehousing
quiet type queries and yet for
operations we want to give you high
performance api's so that starts with
the C++ API we call the NDB API which is
high performance but it's also very
large and complex and from there we
build api's which we hope are also still
high performance but much easier to use
um when you put all this together so
here's here's the basic architecture
down here at the bottom these are data
nodes these guys store the data there's
a management server here and this the
management server actually pays it plays
a surprisingly small role in the cluster
it's it's it has to be there for another
node to connect it has to be there to
start a backup that's that's primarily
what it's for and then all sorts of
other nodes connect as API nodes and by
the way there's no real security between
this layer in this layer other than the
configuration file that tells the
management so node whether whether a
note is allowed to join the cluster so
normally all of this stuff is on a
private network is on a private
dedicated Gigabit Ethernet and the real
clients whether their mobile devices out
in the world or web servers or a
front-end web servers connect to that
cluster connect to the API nodes over a
different network that has a you know a
different security policy um so we're
we're going to talk about Java API and
Craig will mostly do that and then I
will talk about mem cache API which is
usable for any language that has a
memcache client so Java has one called
spy memcache d that serializes java
objects and we can we can use that ruby
has a similar one and then perl PHP
python i'll have memcache clients that
are that are used heavily and then
finally we'll talk about the newest
product which is um just had its first
alpha release and the api's are not
quite stable there's we're still
actively doing a lot of work on it and
that's our JavaScript connector for
nodejs
so memcache d which I will I will get
into more detail here later memcache t
is basically as a key value store and
with a little bit more to it than that
and we've got we've got a memcache d
server that on the front side speaks
this memcache protocol and on the back
side can stores everything in minus QL
cluster or maybe even stores and also
cashes it locally and then here's where
I'll turn it over to Craig and we'll
start getting into more detail about all
of these cluster J is is our set of
api's or our ecosystem for four and no
sequel access to mysql cluster from java
and here I'll give it back to Craig to
tell you more okay thank you JD so just
got two more questions before I dive
into the nitty-gritty details how many
of you consider yourself to be competent
in JavaScript ok and I guess I'll leave
the other question for later no actually
the question is how many of you are
expecting to see some code examples
today today ya in the next 10 minutes ok
we'll get right into it then so the the
official name of cluster J is the mysql
cluster connector for java cluster j and
it's kind of a mouthful so we're just
going to talk about cluster j today and
what cluster j is if you google cluster
j you find that we've pushed out the
cluster I in the cluster k and the
cluster J get back into the into the
background so you can still google
cluster k and you can get a bunch of
variant analysis but clustered j sort of
pushed all that stuff sorry what we've
done with with cluster j is is basically
written a very thin java wrapper around
the c++ api's and give it done it in a
way that is
for Java developers can be a lot easier
to grok than the C++ native API style of
doing things so hopefully at the end of
this you'll you'll get some idea of
where we got some of these ideas I have
to tell you that we looked at other
domain object model persistence API is
like hibernate than JDO and Java
persistence and we frankly stole some
ideas from those folks actually they
borrowed some ideas from JDO and and
other things that came before but we're
not keeping score anymore so we've we've
achieved a lot higher performance than
jdbc mostly because if you look at this
diagram look at this diagram your
applications can go through jdbc ending
up through mysql and then mysql actually
the server actually has a C++ component
that is part of the network so we bypass
that and end up going directly from your
application through cluster J with the J
and I in the note itself to talk to the
cluster so we bypassed the SQL entirely
and so what we've hoped to achieve with
this is higher productivity higher rate
of adoption and actually less less
issues dealing with C++ you know if you
forget to untangle a pointer you'll end
up crashing your entire vm and that's
not generally a good thing so we've
we've made this thing idiot proof or
bulletproof I'm not sure they may be the
same thing actually so cluster J here's
some just examples of what you can do as
a no SQL store your mileage may vary
your application certainly will be
possibly Richard than these but we can
use this as a key value store with
arbitrary text storage strings are
mapped to clubs you can do arbitrary
data storage with byte arrays so you can
do binary operations you can use it as a
dot
in store you can store JSON objects in
it and you can also index the JSON
objects any way you like and get some
relational performance with with with
JSON documents one popular approach we
thought would be a session store for
your Java EE or your web session storage
keys the session ID value is the
serialized session state so it's a very
quick way of dumping state in so that
you can achieve load balancing any node
can retrieve for can receive a a message
from that session and then immediately
get and restore the session state from
that that object and we've experimented
some with the back end for a rest plugin
so your normal operations get input
operations can very quickly be
implemented using this API so if you're
not familiar with domain object model
mapping it's it's one of the concepts
that's used a lot in Java and other AP
is we basically take tables in your
relational database and map them into
classes or persistent interfaces and
I'll get into what a persistent
interface is a little bit later on
columns map to properties in your object
the column names default to the property
name in your objects and Rose map to
persistent instances so it's a very
straightforward mapping what we don't do
here is inheritance if you need
inheritance we're not quite there yet
and we don't do joint so joins are
pretty much on your own at this level of
the API or of course looking at
implementing joins across the entire
range of AP is in a way that takes
advantage natively of the very high
performance that we've just come out
with with the cluster 72 where joins are
actually implemented the data layer
instead of at the sequel layer so leave
it at that you do annotations there
either job annotations or well in in
case of JavaScript the annotations are
actually a class as opposed to in Java
where their native and you get
choose which you would like to do either
you're right a user interface and then
cluster J implements a class that
implements that interface or you're
right a persistent class and your
subclass from a persistent capable base
class so here's an example of a
generated class approach you define an
interface called tweet you annotate it
with a table name and the table name is
tweet and then you do normal Java get
and set methods to implement the
attributes the correspond to the table
so there's an ID column and author
column a timestamp column and a tweet
column in the database this is the
approach if you want to write your own
class and this allows you to implement
domain specific behavior whereas the
interface you don't get domain specific
behavior you just you just get your
basic gets and sets on the object so
this is if you want to want to implement
your own behavior this is the way you do
it so that's just in the thing that's
driving me nuts the table method is part
of your class and the table method
implements the the the return value is
the table name that you want to map this
too so it's a it's very trivial very
straightforward to get going each of the
attributes is mapped to a value get or
set this is pretty straightforward stuff
gets 0 you say well how do I know what
the what the column 0 is and it's all in
the metadata so the metadata is
available to you as well on that run
time ok I'm going to go quickly through
this most of the domain types that you
want to use in Java have been mapped to
types that are native to the to the
datastore so Willie invite short integer
long float double bigdecimal beginner
jur we map those to the appropriate data
types intrinsic to the to the store so
again this is not
sequel types these are native types in
in mysql cluster we have all for daytime
timestamp time and date and you can map
job you to update to those things java
sequel date normally maps to a date java
sequel time to a time and time stamp you
get to choose between a date time and a
timestamp they have somewhat different
characteristics one of them is a unix
time second since the epic whenever the
epic was back you know before some of us
were born i think and then we have
variable size column mapping so you can
map strings into Charizard chars or text
which is basically a blob type and byte
arrays map to binary VAR binary or again
blood types so cluster J interfaces look
very similar to some other patterns that
you may have seen in Java persistence
there's a session factory which is
basically your connection to the cluster
and you can have a database identified
the session factory as you might guess
is the factory object for producing
session objects the session is your
connection your personal private non
shared connection to the database so
most of the heavy lifting in this API is
done with a session object so you've got
a grab a session object do some work and
then put it back there's a transaction
object that allows you to have fully
fledged transactional behavior where you
have multiple operations in a single
transaction but as an ease of use thing
if you just don't do anything with
transactions at all you get the
autocommit behavior that you're probably
familiar with from the JDBC interface
and then queries is the way you get lots
of data from the database there's also a
very straightforward way of getting an
object by key which goes at blinding
speed but query is a way you can issue a
query you can navigate through a number
of number of tables sorry a number of
indexes on the tables and you can pull
back a range of object
so here's the view of cluster Jake and
it turns out that's also the user view
of the node j/s adapter as well so it
turned out to be a very useful paradigm
you have configuration properties here
and the configuration properties are
just what you'd expect is the job of
properties object the session factory is
configured using that and once you have
a session factory this is especially
cool for a web server or a or an
application server because you typically
have a single session factory and then
you can very quickly manufacture
sessions from that so it's a separate
modeling paradigm that you can use
especially appropriate for a server
environment here's the way you configure
this thing you properties new properties
object you initialize the properties
object with a couple of things in fact
these are the only required properties
there are lots of other properties that
you can set in there but these are the
ones that you want one is them is the
connect string which tells you your host
and and port number to connect to and
the second is the database that you want
to connect to so those things are
encapsulated in here as a side note you
can have this we will actually share a
sessionfactory among multiple databases
and that's all done behind the scenes
but your it's useful to have a default
database when you're connecting to a
cluster so the default database is part
of this encapsulation into the session
factory and then here's the money shot
the get sessionfactory is a method on
cluster j helper that returns a
sessionfactory given the properties that
you've initialized for it so again we
don't assume that we're going to read a
file if you want to read a file with
properties in it you can do that we
didn't figure that that was something
that as an API designer we needed to do
for you so you can you can go and read
your own properties from any object that
you want to and just deliver that
properties object when you when you
construct your session factory so now
that you have a session factory from
that factory you can get a session to do
your work and the session is a factory
for persistent instances so it's a
factory of factory kind of notion here
the session also manages the life cycle
of the objects so you create an object
you can persist it in the database you
can delete it from the database and we
try to maintain the the connection
between an object in memory and the the
row in the database that corresponds to
the primary key in that object so
persist is the API you use and persist
says I guarantee that there's no object
like that with that same key in the
datastore and if there is an object with
the same key you get an exception remove
similarly the record the row must
already exist in the database you can do
an update you don't need to read the
object first so that's an interesting
thing it's a little different from some
of the other api's you may be familiar
with you can just create an object with
the primary key and some fields and you
can say update the object in in the
database you don't need to read it
beforehand of course you can if you want
to read it beforehand you can but you
don't have to it'll do a blind update
for you your choice as an application
developer similarly the save API this is
real cool if you say I've got all the
data that I need for an object and if
the object already exists in the
database I want you to write it and if
it doesn't exist I want you to create
the record in the database so it's a
very useful paradigm for for many
applications that really don't care like
the honey badger they don't care if the
object exists they're going to overwrite
whatever it is in in the datastore and
sometimes that's useful the other thing
that the session does is a fine by ID
and that's a very fast operation if you
have the primary key of the object you
give it to a session and it gives you
back the the the values from the
database in the domain object and of
course there's a query factory the query
factor is very much like
hibernate or JP a query the query anyway
so that you get a query factory from the
session and that gives you query objects
that are specific to your session so
you're not interfering with other users
of the of the database okay here's some
code that implements an insert so you
start by getting a session and this is a
very simple operation get a session
create tweet and this is the domain
object you do a new instance so session
is a factory for new instances and it's
an instance of the tweet class and then
you do set ID set author set tweaks that
timestamp and these things so you really
only have to provide the author and the
message and you can create this with a a
random uuid and you can decide for
yourself whether uuid dot random is a
good key for you but in case it is we
can pretty trivially create those things
so you can also implement other styles
of of creating primary keys that's just
a real example so the last thing you do
is session that persist and of course
the session dot persist since you
haven't mentioned transactions at all
that's going to be an auto commit
operation so at the at the beginning of
this there is no such object at the end
of this persist that is the very next
thing you have persisted the object in
the database and you're free to do
whatever you want to with it so here's a
case of find where you want to find an
instance of the object in the database
you provide a string which is the ID
corresponds to the uuid dot to string
and the find will give you the instance
that corresponds to that ID and this is
the one of the things that we do is we
say if there's no object in the database
we just returned no we don't throw an
exception would just give you back a
null and if you get a null pointer
exception that's your problem sorry
it's easier to test for null than to
catch an exception to do all the stuff
that is exception yes question the
question is if you want an
auto-generated ID that is you want to
put this set ID and the answer is we
don't support the data store providing
that at this point so that's a it's a
good a good forum question for a future
release and no commitment but that's a
that's an interesting thing to do okay
so transactions does anybody here want
me to go through this whole description
of transaction okay everybody knows what
a transaction is you can be in commit
rollback you can sep rollback only get
rollback only if you the the centre roll
back only is really for the cases where
you're working in one part of your
application and you realize that there's
some tragic failure that it's not really
an exception it's just a condition that
you just don't want this transaction to
commit you can say several back only and
if you try to commit that transaction
you'll get an exception there so it's a
way of distancing the application knows
that there's some problem from the part
of the application that is actually
going to do the commit for you and
here's an example of creating a number
of objects in the database so at the end
of this we're going to create a tweet
from Amos barb Chuck and Dave and the
whole thing is going to either commit or
rollback as a group pretty
straightforward okay so that's a really
whipping tearing through the API and we
now have another API for your
consideration oh one question nope just
a yawn okay I understand
alright so all in this stuff can be used
together right we just saw you know
creating wreckage through through java
through cluster j those are going to be
visible through sequel right and they
are they can cooperate with some other
code in some other language may be using
this API through memcache T and really
the reason we chose memcache a big part
of that is that we had so we had it we
had a good no sequel API for java and we
wanted to move on to something that's
cross-language something that will be
accessible from a wide variety of
languages and so memcache d fits the
bill and and we look at it from two
different perspectives kind of from the
mysql cluster perspective down here at
the bottom we think of it is as that
high performance easy to use API from a
bunch of languages and also you know
also can supply an extra layer of
caching which might be handy sometimes
from the point of view of memcache and
memcache d and people who already use it
and are familiar with it it is
traditionally just an in-memory
distributed hash table when you connect
mysql cluster to it it becomes it
becomes a persistent data store right it
traditionally exists kind of alongside
the the persistent data store and now
here we take the the memcache and the
database and combine them into one so so
this is the basic idea goes back about
10 years ago was developed at a social
networking site called livejournal still
the most popular social networking site
in russia I think
so there there's an application it's
written maybe in Perl running inside and
apache web server uses a memcache client
we want we've got a key and we want to
know what what data we've stored with
that key so we hash the key we use the
hash value to pick a memcache server
from our pool and and then okay so we
pick a server we go to that server with
a key look up and that server hash is
the key again looks in its big in-memory
hash table and gives back the value
right so this is something that a you
know maybe there's not enough memory in
this server for the whole data set so
you just add a server and then because
you hash them over here to pick the
server you can you can you can scale
this to whatever degree and it's
basically key in value there's a little
bit more to it than that but there's not
so much more that I can't exhaustively
describe the whole thing in the next
three slides so the protocol has these
elements to it there's the key the keys
up to 250 characters by the way there is
there are two really two versions of
this protocol that run in parallel
there's a there's a text protocol and a
binary protocol so in the in the binary
protocol the key might be 250 characters
of a binary string there is an expire
time which is a number in seconds up to
30 days there's a 32-bit value called
the flags which is completely opaque to
the memcache server the application
surprise supplies flags and the
application gets flags back right the
server does nothing with them there's a
64-bit value called the Cass ID cast
mean here means compare and set this is
used as a version number check on the
stored
record and it can be used to implement a
kind of optimistic concurrency control
and we'll see that and then finally
there's the value and the traditional
limit on the value is that it can be up
to one Meg but actually that's
implementation dependent in our version
in our in DB server if you keep the
value under 14k you can store it in one
row of the database and you have a
performance advantage in doing that you
can actually go over the one mag if you
store it as a blob but you have to pay
the penalty of the fact that it's
divided up into into actually many rows
of a table so that's the complete you
know set of elements of the protocol and
then we've got about 12 commands that go
along with those so get a key you know
the clamp supplies a key and wants to
get back the value stored set a key and
a value the client supplies the key and
the value and the server stores it and
then there are some varieties of set so
add is a set that's a strict insert it
only stores the value if it does not
previously have one right replace is a
strict update so we'd only stores this
value if it does already have one and
then here comes the version number check
and the concurrency control forecasts
the client supplies here's the key
here's the value I want to store here is
my here is my case ID my version number
and the update will only succeed if the
version number on the server matches the
one the client supplies if there's a
mismatch this server sends back an error
and the client processes that error to
go start again get itself current with
the database and somehow recover from
the situation that it had a stale value
go on yeah okay then the rest of it
you can append and prepend you take a
value and you take the text of a value
and you add it before the current value
or after the current value increment and
decrement you treat the value just as an
integer counter and you add to it or you
subtract from it the decrement does not
flow below zero it has air trapping at
zero delete the the client sends a key
and once the server to delete the value
stored with that key flush all is an
operation that some has a lot of use in
a cache server you might clear the cache
in a database server it's a little scary
it would translate to you know delete
star from table so if you want to enable
it we let you enable it but we we give
you control over whether whether that's
that's honored or not and then finally
the memcache server can supply a lot of
different operational statistics and
there's a stats command that let's let
you get them so when you put this all
together you've got an application in
you know a wide variety of languages
it's got a memcache client for that
language connects to this here's our NDB
memcache server it consists of the
memcache d layer and the NDB engine
layer and then you go here this part is
the private part inside the cluster and
you go to cluster data nodes and
actually run the operations so finally
compared to traditional memcache there's
obviously a performance penalty in this
architecture because where originally
you just had one network hop here now
we've got to network ops here and we
want to measure the performance of the
whole thing and I measure the impact of
that I think this slide shows pretty
succinctly that it's it's no worse than
it should be so here
here's here's a pain time between the
test client and the test server if you
about double the ping time you get to
standard memcache d what we now call the
memcache d default engine and here my
green diamond is the read time and my
blue one is the right time and you sort
of double that again both for the one
node cluster and a two node cluster
connected as a back end so the top of
this graph is one millisecond right
we're still everything is is below 0 1
millisecond and in our worst case which
is the right performance for a two node
cluster the 95th percentile performance
here is still at six hundred
microseconds so well within the
millisecond and then our average is just
about 400 so so your average time is
below half a millisecond here and this
is a my client here is called mem mem
cache test here and I'm the parameters
control the value size and other things
that I forget so sequel access Java
access mem cache access those are all
production available in mysql cluster 72
also in a few more minutes talking about
what we call the mysql cluster connector
for now Jas and this is brand-new code
that we're we're just starting to make
available not stable for production yet
almost stableford for development but
but maybe not even that so no Dutch is
is a web application platform and and
you might say in some ways it is the
polar opposite of the Java EE app server
because you know that a Java app server
is multi-threaded probably runs really
well on see
mt machines machines with lots of course
lots of processors you know I think that
generation of Sun hardware was was about
running a java app server at lower cost
lower heat lower power consumption in
the data center no Jas is single
threaded it is event-driven it never
allows your main application to block
for i 0 it is supposed to handle a
really high number of connections with a
single core and a low amount of memory
partly it does that by by never giving
you a stack whenever you do something
that's going to wait for the disk or
wait for the network your application
gives up control gives up its context
and that context comes back a little
later in the form of a call back when
your operation completes so this is
going to look a lot like the Java code
here here's a JavaScript constructor for
the tweet class it again generates a
uuid generates a time stamp takes a user
and a message when the node.js starts up
there's a little bit of startup code
where you require the adapter MySQL GIS
you also require the built-in web server
module the HTTP you take my constructor
that I just showed you and here's the
annotations we're going to say no sequel
which is what we got when we required
the module map the class give it the
constructor and the name of the table
and then we're going to get a session
factory just like the session factory in
cluster J in concept connecting an indie
be here is the name of an implementation
they were using for the background
connection with all of its default
properties in this case it's in DB but
it could be MySQL so we've got the
native minus QL cluster connector the
NDB connector here but you can also do
this with nodb or you know anything that
any kind of server out there that speaks
the MySQL protocol
can be a back-end starting up the HTTP
server so we're going to create a
function that's going to run when an
HTTP request comes in it takes the
request in the response and what that
that the function is going to do is call
our session factory and get a session
right on session here's another callback
with the HTTP request and then create a
web server and what the web server is
doing is when a quote request comes in
this this function is going to run you
see this sort of bottom-up backwards
nature of event-driven JavaScript here
here's on session so this is the
function that's running from the aunt we
request right one session here we've got
an error condition a new session and a
request and basically we're going to
call a call the constructor the tweet
restructure constructor using the user
and the message that came in from the
from the web server that gives us an
object and then we use the session and
we persist the the object and do
something response acknowledgement back
to the web client and and that's really
it the rest of this might be waiting for
this to execute and recording the air
condition or the success and letting the
client know that that's what this stuff
is so that's that I it's a very
straightforward mapping from the
development paradigm for Java that is
supposed to be easy to use supposed
supposed to fly to supply this low
overhead bridge between the realm of
application logic
in the realm of the database but for the
event-driven javascript server in nodejs
which is a really different operations
paradigm question yes does the persist
call block so let me talk about this
here actually on this slide the persist
call does not block it takes a call back
and this so this was a big decision
about about how to make how to design
this is that if if every call was
synchronous if there were a lot of
synchronous calls that blocked in our
single execution context we would we
would get a low performance right so we
do have a few calls that are synchronous
they're part of the server startup they
they make your logic a little
straightforward since you can't do
anything until you've connected to the
server anyway you know we let you
connect to it synchronously if
everything was a sink the code would be
a little more complex than it has to be
because each individual operation would
be nested with its own call back so what
we think the balance is is that you can
define an operation as an immediate call
and then you execute them when you
execute them you supply a call back and
and go do so so here in this in the case
of persist if you had if you were inside
a transaction so if you had used your
session to start a transaction and you
were going to do multiple operations
persistent would be immediate because
you're in autocommit mode and persist is
your one operation in the transaction
we're actually going to give it a call
back here and and persist as a sink so
individual operations are immediate
calls that execute our async calls that
have callbacks and it so happens in the
in the simple one operation autocommit
scenario the call that defines it also
happens to be the one that executes sit
and so it's a Singh that's the whole
story I think we have some some time
from for no for from for more questions
mysql cluster the the best of both
worlds means uh joins reporting queries
through sequel and operations through
all these these lovely api's that we've
talked about so thanks very much but
wait okay there's more oh yes if you're
interested in actually getting your
hands on some of these tools we're
having a hands-on lab tomorrow in the
hilton franciscan room at two o'clock in
the afternoon it's a two hour lab you'll
get a get a chance to actually spin up a
cluster yourself will have access to all
three of these api's for your your
viewing pleasure and I think we have a
question in the back yes
does does the memcache support
replication so so yes mysql cluster
generally one cluster runs at one data
center you can but you can have a
cluster in one location and a cluster in
another location and replicate between
them right and yeah and that is a two
directional replication it's a got a
little bit more in it than standard
mysql replication because it's got two
masters and we do some conflict
detection so the memcache client is you
know making data changes on the data
nodes and really there's a mysql server
in in each cluster that has the role of
managing the replication channel so it
sees those chant those changes and it
sends them over the network to the other
side so yes it's it's sort of a big
complex situation but it does it does
work yes with two directions and and you
know so it's synchronous inside your one
cluster in your one data center and then
it's a sink to the other location yep
here yes
so the security within JavaScript right
now again there's no right right now the
way you would have to build it is that
your your javascript your nodejs app
server is inside the private network and
then there's a front-end web server that
that is outside that network that that
is you know being a front-end proxy to
it so the memcache client overhead I'm
not sure I understand what you want to
know it's a you know memcache it's a
really simple protocol the the clients
are usually only a few hundred lines of
code it's it's been heavily tweaked by
people like Facebook so that there's a
TCP version there's a UDP version
there's text and binary I think when you
get down to using the UDP protocol over
binary it's it's a really pretty pretty
amazing in terms of low latency
but okay so the question is why do we
introduced yet another persistence API
yet yes and the answer is we actually do
support jpa with a special version of a
plug-in to an existing jpa server so
that's true right one of one of these
one of the slides there had cluster JPA
which is actually built using this but
also if you have a complex query the
complex query goes through JDBC the
simple straightforward query goes
directly through cluster J so we we did
make an effort to do that you probably
can appreciate that cluster I mean that
JP a is a very complex very large API
and has a whole set of issues dealing
with you can't advertise it as compliant
unless you pass the compliance test
suite it's a relatively small project
within mysql we didn't have all the
resources actually sustain that kind of
effort so we actually implemented a
plug-in to open jpa and the plugin for
simple operations goes directly to the
database for complex operations
delegates back to the JDBC path yes um
as far as clutch the question is can you
pass foreign keys or use foreign keys
the answer is foreign keys are
implemented in the database and
therefore we don't care
yes okay so so the question is really
how do you navigate from one table to
another using foreign keys and the
answer is you define each of the the
tables independently mapped
independently you retrieve one object
you take the value and use that as a
look up into the other table and that
works at the speed of MySQL actually
because that's exactly what mysql is
doing in the cluster environment it's
looking up the two things and and making
the join basically in the server itself
yeah if you're using jpa through jdbc
it's going to the mysql server and there
are some optimizations some queries with
joins can actually optimize but we're
also looking at extending the clustered
j API to include doing the joins inside
cluster J and therefore pushing it
inside but that's one of those safe
harbor things we can't give you a date
it's just a feature that we're very
actively looking at and then there's
another part of that answer that there
can the for actual foreign key
constraints are not enforced in the
current release of mysql cluster 72 but
they will be in the next release 73 yes
databases that's abuse how many how many
nodes music
maybe you're Whitney doesn't know it I
yeah so 48 so we we have a limit today
of 48 date and 80 notes yes but family
and knowing his notes some you know some
other 200 application notes so so it's
not it's not something where you know
it's not like the domain name system
right where where you don't even count
the servers it's it's a small cluster I
think we're sorry it i think by design
it will always be finite but we do have
plans to make it larger yeah yeah please
don't okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>