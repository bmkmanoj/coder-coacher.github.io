<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>In-Memory Data Grids: Best Practices | Coder Coacher - Coaching Coders</title><meta content="In-Memory Data Grids: Best Practices - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>In-Memory Data Grids: Best Practices</b></h2><h5 class="post__date">2013-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vwYJuQm82KQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks a lot for being here this morning
it's early good morning when you sleep
we're going to talk about amor de
degrees today I'm the founder of hazel
cast his classes an in-memory data great
product it's open source apache license
I developed the implementation of Java
spaces nine years ago if you remember
Janie things like that was quite popular
back then and so I got into the space
and since then I beloved distribute
programming distributed data
distribution so four years ago I started
mr. cast and now it's being used by many
other big companies if you're working
for a big company probably some some
group in your company is just already
using his accost so what is the memory
did a good its first slice like several
JVM sharing data and then querying the
data listen observing the changes
executing code on the data and it the
degrade is using your own data objects
is not a different type of data like
it's not like a JSON or or just like in
the case of jdbc it's not it's not like
columns on the tables rose it's your own
objects you're starting into the grid
and then and then processing on
integrate currying manipulating the data
in the grid so it lays inside the
application or it's closer to the
application it understands the
application it's not like a remote
database has a spike as a straight way
of talking to it or
strict data type that you have to use
it's closer to the application why why
do we need that because applications do
need to share data just took just for
example in the case of session
clustering session application for
example or app application state sharing
Jose a very common use case would be
distribute caching obviously for
performance and also you start dating
the into the grid and then you follow a
process we see that a lot in financials
doing monte carlo simulations or life
sciences or doing a lot of modeling it
also good very good for scalability as
your users increased number of users
increase you should be able to handle
them chiba scale and very very important
feature of memory memory data greatest
is that it can be invertible it is
available it can be embedded into your
application this is very good for easy
deployment you don't have how your poem
the years uses of the deployers of the
application doesn't have to set a
different cluster and them maintain it
that's it can be it can become a part of
the application in it can start inside
the application embed abilities is very
very important feature of memory
etiquette not all support that but most
most most of the American Medical
Solutions to support him and better
compelling so also working with your
objects is very very easy you don't have
to deal with JSON and or a row column
row type of data so we do have options a
lot of options in the market we have
hazel cast Oracle coherence IBM Paul all
the
very famous solutions here can I see
hands a few people using hazel cast and
any ezek as user here how about the Ark
of coherence okay terra cotta okay all
right so not all but most most most of
the products do have partitioning they
partition the data store in two
different nodes and then process onan so
let's say we have five million entries
and five notes usually there will be our
like million each node will hold a
million record and some day is some
backup we have to know that so
implementations are quite different even
though we take them as a like memory
data product think that they are almost
the same they are quite different in
terms of how they is partition it and
how they backup the data so sometimes
they have dedicated backup servers
sometimes they have dynamic backup
mechanism like selecting a backup know
dynamically so there are quite different
in terms of how the partition and how
they take backup scalability it comes
with a cost it's not for affray really
so if you're running a single node
application whether you have a high
throughput everything is local obviously
all the reads and writes our local you
have a good performance obviously it's a
single node it's so now it's not so you
want to scale that but when you start
scaling you see something funny it's
actually the performance will throughput
will go down because now your reads our
rights are also going to other said the
other node right so so you through
people go down here with the second note
and then we start seeing the linear
scaling and
at some point x is at some point you're
going to catch up with the OneNote
performance when using a datagrid and
then you'll be able to go up and and get
better throughput so still even though
it's leaner how linner right so that's
also another question what's the degree
of lead Ernest so but eventually we do
scale so what's the X there it depends
on the application and how hum have how
it's using the datagrid it could be
three nodes it could be 5-10 even 20
notes to catch up with the one note
throughput so just be aware of that
common features of data grids most of
them do have of course bit distributed
maps distributed hash tables and most of
them can do caching right if with the
evictions with the official policies
your entries can expire at some time
most of the products do for like that
also they do have some form of code
execution in the grid in the in the form
of executive service or our MapReduce
because that's one of the biggest
benefits of degrees right we we have the
data distributed already be on a process
in paola ok also most of them do have
listeners listening for the updates in
india and the indications or maps also
querying is a common common thing
looking up for the entries of the
specific criteria they do have having a
second level cache implementations are
all different still but they do provide
that integration transactions are
supported that some degree like some of
them are local some of them are two
phase commit
but they do provide some level of
transaction and MapReduce map stories at
all so cash store or very common because
it's an in-memory stuff right we want to
be able to talk the backend a datastore
to persist things lot of things so they
all provide some some way of storing and
bloating so when it comes to deployment
it's your grid can be our remote cluster
and to to attempt to your application
type or application cluster so your
application cluster is talking to a
remote dedicated data grid cluster it's
good for isolation very very good for
isolation because you now know that your
your data grid is using a dedicated hip
where ya memory a dedicated to CPU and
also it's very very good for upgrading
your applications why imagine this so
successor is a remote server resting the
remote cluster upgrading your web
applications right every even every a
lot of times in a day won't affect the
cluster your operating only the
application web application layer
there's the cluster stays the same so
it's not affected by the deployment
sorry a lot of deployments of the
upgrades of the application so it's good
so but embedded embedding is also
excellent when it comes to deploying or
distributing the application because
it's part of the application you can't
be it is inside your war file or your
file as you run that application will be
a node will be starting in the in that
application and you don't have to deploy
or maintain a separate data grape
cluster it's your application becomes
the cluster data grid cluster and
application and data grid lives together
so
also decision that you will be making
will be depending on the amount of data
you you have so imagine you're caching
hundreds of gigs or even terabytes of
data right so let's imagine this and
then you're saying that you you wanna
whatever you up up upgrade your
application you'll be restarting your
web app right tomcat JVM or the project
then you don't want to you don't want
this data to be shuffling around so it's
if it is remote clustered then data
stays there nothing changes data is
still there your application just
getting up upgraded so if it is embedded
then you this Tara gigabytes of data
will be going down and rim migration
will hostile will happen so the amount
of data will also makes you make a
should guide you when choosing whether
it should be a remote or embedded we see
both of them a lot so sometimes like
they even run on the same box they run
web app and and the data grid node next
to it on a separate JDM okay stud out
away from the web app you're connecting
to a local grid member and it's sitting
on a different JVM so he's using it has
its own heap and you it's connecting to
the grid as a client so that's also very
common deployment so in terms of caching
behavior we have wii u vc cash aside and
cash cash managed heshes I'd means the
cash and the data database are separated
and you manage that the developer will
will be talking to both of them so the
developer the curve will be going to the
cash first if the entry is there will be
using it otherwise it will go to the
special data put into the cash for so
that you can next time you can read from
the cash this is caching aside and cash
manages more like you are only talking
to the cash and cash manages talking to
your data store so we threw means if the
record is not in the cache loaded from
the database and put into your cash
right through for the updates for
storing right through means of the right
hello right behind right through means
when i'm doing the put i should i want
to make sure that the store invoked as
part of the as part of the PERT
operation and my record is also in the
database wonderful returns so right
behind means i want to put into the cash
and mark it as a dirty record so that
every 5-10 seconds is configurable the
process will flash all the dirty records
to the data data store database so of
course for consistency right 3 is
awesome but for performance right behind
it's very good even the day with the
case of right behind like assume that
you're you have a database and you're
using right behind and your database
goes down for us for some minutes if the
if the data in the in the memories is
good enough for the min request coming
in you'd only won't even notice that
database is down because you can serve
from the memory it's not it's not tied
to the tight to the database so database
can go down for some time but when it
comes back up since it is right through
right behind it will flush all the
updates happen during that period so
it's a very good but of course you're
losing some consistency you are you if
you if there's a failure big failure
happening during the then you might lose
some of the data because it's stored in
memory but not not in the desk database
yet
it scales amazingly well we're way
better than right through of course and
legacies are very long so when cashing a
site then you should you should consider
invalidating the cash on update so that
you can have a higher level of
consistency because caching aside
creates inconsistency you can go out of
sync your your cash and database can go
out of sync when you're using cash aside
strategy so invalidating validating the
cash on update will increase the level
of consistency but still not
guaranteeing you the perfect consistency
so sometimes I mean most of the products
do provide a near cash meaning you're
you everything is in datagrid but you
can locally cash that so that you don't
have to go to the grid even you don't
have to go to the grid for every read
but anytime you talk about caches we
talked about the consistency problems
your cash might not be that up to date
so always consider I invalidating on
update for higher consistency but if
your if your update rates are is very
high then you might kill the cluster
because invalidation is also very costly
right so your if your if your updates
are very high try to use thi TTL based
near caching that's a that's a lot
better optimized salvation salvation is
the is the biggest probably the biggest
costing the whole thing ok that's a
biggest performance killer so try to use
custom sales ation that that's provided
by the the product itself and then most
of them do provide a custom way of
civilizing your objects and storage also
not not not that sort the way the data
is stored in the grid will be different
on the product some some of them will
store as an object some of them will
stores as a byte array and just just
don't have the wrong feeling that it's
going to be object all the time don't
don't get that feeling but they do have
good reasons for that starting as a
binary or showings of object some of
them do provide doing both meaning
storing both byte array plus object next
to it so that the if there's a query
query we read the object directly it
does not to diss I realize but if it is
reading from the remote machine then it
will write the byte array directly
through the wire so they both have good
use cases but just just know that they
are different not don't get a wrong
feeling about it always know the cost or
even feel it like when you're writing
mapped out or cashed out something try
to feel what the cost is for example map
that guess is very very cheap why
because it's 11 network all but on the
other hand map values with a predicate
or a filter will go to all notes doing
parallel query and bringing results bags
back so so obviously it's just way
costly and even though we have great
features in every every datagrid we will
love to use queries listeners and all
that stuff it's good to use but you have
to know the coast and make sure that
you're the cost is not higher than the
benefit itself as listeners are a good
and but is stalled a little dangerous
because it creates a lot of network
calls if you're listening a lot and
updates are very high always good to use
things like put all to optimize things
so putting in 10 and using
a atomic operations like put if absent
always good always good so these are
optimized calls so try to try to when
you need is just like you you do a video
right us SQL application right database
application you do get the feeling of
the SQL statement like hardly have did
it is select will work how closely that
is so we have to get in get the same
feeling from from when we were writing
distributed stuff so when you do cashed
out something just like just try to
predict the cost they're not complicated
though like when you when you when you
as you a zero so your read the
documentation and you understand how the
product works at some point you
definitely do get the cost of each
operation it's not something magical I
work something that's hard to learn be
careful about the hypernet second level
cache because if the objects that you're
caching or using the hypernet is a very
complex then lazy fetching might kill
you if you're using a second level cache
because each each fetch each object in
the hierarchy will be calling a cash to
get a cash to get the value so
eventually you might be calling 2050 a
cash call to create object complex
object so it may cost way more than
regÃ­strate writing reading from the
database so just be careful we've got
better performance for for some some of
our customers to use cash is cash
society instead if you can enable near
Cashel man in my help but cast aside
might be also a very good strategy here
so first the rule of distributed
computing is do not distribute of course
so try to stay local if you can
even even cash things for five seconds
five seconds might be a very little time
for a human but it's a very very long
time for a computer I'm not saying it's
always possible but if it is possible
consider capturing even for five seconds
and also for all the operations that
we're going to be doing so we should we
should try to look for a way of
localizing the operations even like
lenguin weird near caching that's what's
the purpose of New York a shingles of
course localizing the thing right so
some or when we are executing code on
the on the grid what's the purpose of
executing on the grid because we want to
localize the calls there we want to go
to the node execute the code next to the
data so that things can be local so a
lot of things that we're going to be
seeing our are going to be related to
don't do not distribute principle so
very common thing if you have a cash
just keys are distributed so you look
for the API that has similar semantics
like execute something on the key these
are optimized that that why because do
you don't this way you don't have to you
can get it get away with you don't have
to lock the key for executing that thing
or and also the data will be local to
you execute there so try to look for
api's like that try to execute next to
the data and avoid locking this these
are going to be guaranteeing these are
going to be giving you implicitly on the
key anyways so also how are we going to
start a story our data what's the what's
the way of storing it so one normalized
the way that we all know from the
relational database world so customer is
a customer or is a total separate
there's a foreign key in relation right
so then if for the MMI delegates top who
will have customers and orders david
maps right to akash's separately and
we're managing managing these two caches
separately so so this is good when
you're when you're looking or reading
for reading the artists by key for
example but what if you're looking for
what if you need is a is the orders of
the customer so getting orders of all
the customer in this case will be very
very hard because they're there are kept
separately there has to be a way of
knowing which p orders are belong to
which which which customers right so so
it's it this is a good when you're
reading things separately but it's bad
when these are very related and your op
op executing already customer and orders
together most of the time so EV EV even
if you have to do this you still have to
at least make sure that our audience and
the customers are staying on the same
note since they have different keys they
probably will end up on different notes
right there they're your customer will
be on this note your orders are going to
be spread across the other nodes so it's
still a lot of network politic even
collect them all together right so for
those cases it try to so most of the
products will have data affinity feature
try to utilize that so for example here
order ki will have a partition will be
partition aware meaning and implants
something like Bachna where it will be
different of course for product product
product product but something similar
and it will tells you that partition key
is the customer key actually so that way
your orders and the customers are going
to be sitting on the same now okay
denormalization also
or important so most of the time Eva
we're going to see this one orders are
going to be inside the customer object
store to get this store together so in
this case when you get the customer
right so see there's only customers map
there's no artist map so customer orders
are inside the kind of customers already
so when you do I get on the past
customers grace you get the customers
with Doris everything is together
there's nothing to like worry about like
the fires gays and blah blah but what's
bad about this one is that what if you
do what if you can have thousands of or
is per customer then like when you get
the customer you getting the giant
object back or when you're updating and
order removing adding something it's
kind of come in there it's going to cost
more so so there's no like I you have to
go this way or that way thing it depends
on the application so so you have to
look for the biggest problem in your app
so if your if your biggest problem is
adding this order into your app then you
might probably gonna go with a
normalized version because adding or is
in the normalized way is simpler but if
execution of customers together with
aureus is the biggest problem i'm
probably going to go with do you
normalize way that i just saw so we can
also i mean you might have to even go
and mixed so you might want to have a
normalized version of it and denormalize
so it's actually the principles are very
similar to the the no SQL world how do
you store things in nor SQL is very very
very similar so sick the same challenges
there so when you're coding try to code
code as a service so probably give don't
give like
the API to our developers and write data
grid calls everybody in your application
it says we will create a mass and you
won't be able to manage that for some
sometime it's it's it's a very good
practice to have a dedicated service
written by very experienced developer
knows the product and things like that
and X and do not expose the datagrid to
all developers I have them as a service
to other developers and and that way you
know exactly where did the great calls
are done and how wrote that how it is
written everything is in one once or a
package or one service make it more
terrible because you will definitely
need that like things like so what's the
so there's even there's a problem in
your application like the digression of
the performance or anything you should
you should so if there's not no idea
like if the code is everywhere if there
is no way to lock things and find figure
out where the problem is but if you make
it make it as a service then you can
have like jmx monitoring or even your
own the metrics to monitor how long this
specific service took what's the average
called time it took and things like that
and also lock things like Layton sees
higher than 5 seconds 10 seconds
whatever it is like we're so so it's a
it's a good way of coding it this is
this is not of course not related a
product but with the it's a very good
practice to separate the coding and make
it make it making it a service so thank
you for listening we have a booth at
5105 about capital your presentation
relatively small so that we can have
more discussions so any question
yes
what which one
Oh
excuse me okay he asked her how
obligated great is better than clearance
right cut so hurry this is another
product so so it says one of the data
grades itself so they have the same
things that we discussed so it's just
another date a good product we cannot
say like it's not like datagrid versus
Koreans Curtis is a delicate all right
the talk is more about that you did how
we should use it but is it a good I mean
who wants to hear that hi okay so first
of all all of these products that i
mentioned i am a big fan of them so i
try to not to say anything bad about
them but what I can say about us is that
first we are open source we have a
community behind us we have very very
good number of users testing it and
given feedbacks we have other data types
like multi map distribute q topics also
we have elastic memory something that
allows you to store everything off the
heap to avoid DC so so feature wise that
are we are different we have some extras
of course their clearance do have some
extras too so hmm I think we also see a
pattern stresses an outpatient affair
all right so I think you should you
should try both and see which works for
your
education better but in terms of feature
set and performance we are quite
confident oh yeah yes Cory's also does
yes
sure I mean first
so I could say something like chaka is a
little different than the remaining
others why because has a client-server
architecture even in their documentation
they say you're not data good so but I
just want it to be fair to everybody
just want to put the names in case
please they don't I don't want that to
complain that I've made explanation or
something but the others are do have 52
similar pitches but implementations that
that's what I'm saying that that's the
point very different like some of them
have like a synchronous backup for by
default and you don't know and then
you're comparing the product and then
the one product is faster than the other
it doesn't it's not it's not true but
because the backup strategy is due by
default at synchronous soon so very up I
think yeah okay let me let me tell you
this so at least when you're comparing
products I think the biggest thing will
be a biggest differentiator will be how
well they they they handle the
exceptional cases edge cases so i don't
think it's so the of course you have to
know the details of the product to
figure out I mean when you're
prototyping you should be fair to all
the products right so if it is as
synchronous backups and if the other one
is asynchronous obviously there's
something funky there but that's not
even the thing the most important thing
is how how well they can handle things
like network partitioning that's that's
a tough problem to solve something
happening to network things I mean
partial faders are worse things in the
data gets worse things if something goes
down like machine goes it's a good thing
there's nothing wrong with that but it's
something like if the kernel panics
that's tough okay it's nurse is a
partial failure or like it LGC right
this is the one of the biggest problems
in our in our world so long long JCS are
going to are gonna
so the when you're evaluating the
products make sure you look at the edge
cases that the other ones are easy okay
very very easy the features have sure
they similar they do but they can do
some other things and then I talk to
them talk to the guys implementing it to
do like we have of the common feeling
that they do they're they're doing
things similar but they're not that
definitely they're not doing it similar
like as I said like a backup strategy
they all different so how come so when
comparing like you can spaces for
example has a you have to set a backup
server for a given node so how it's not
like coherence or hazel cast that we are
doing a dynamic back up so its products
are different but they still shine when
it comes I mean the you can um you
should make the decision based on how
well they can handle the edge cases and
we are all running on in our network and
network is very very slippery so things
are going to go bad I at bad times and
how well they can handle these cases I
think that's a that's the most important
thing
we're just hanging you see that one day
there is there some obvious
I think there's I mean if your if your
app is heavily depending on the data
grid there's nothing much you can do
because it will happen regardless you
can enable near caching and all that
stuff to make it faster but when you're
using your cash kind of stuff you're
given up on from the consistency rises
so if you can live with that sure try to
have near cash on things like that but
if you're not using near cash there is
nothing you can do because there's a
network right that you have to do a
neverfull to get the thing or put the
thing so yes
data memory
if you if you're if so did you I think
you should you should deploy it don't
you don't lose data is is not the
biggest problem but imagining a big big
data and you're just cracked and
shutting down the data good note then
this data will be owned by others and
then baggage of the backups are going to
be taken again there are a lot of data
shuffling will happen right so that's I
know you're starting again then again
another migration to to the new new note
yeah so if you're changing your code a
lot is deploying the data grid as a
separate component will be a better way
so you have it is a very good cluster
and then your apps are going to be
sitting here and then your earring outs
are going to be climbed to the datagrid
so you're going to be using a client
call to the good so this way you can
update your applications as many times
as you like but if you're asking if the
class itself changed right suits them
you change it at customer claws right
then it's the new new classes are not
there so your rating you're getting no
class definition or things like that
unfortunately you since we rely on
civilization there's an there's one
trick that you can do but it's still
it's a trick so the the comments things
that think VC is rebooting the cluster
so you deploy the new color and reboot
the custard not a nice thing I know but
since we rely on the sensation that's
that's what happens there is one trick
that you can do but still it's a trick
that I don't even want to recommend much
it's a third so one I mean you can you
can implement something like version
aware and then a the his cats will will
tell you when she when deserializing
will tell you hey here's the bike bike
to the byte array and so he has the then
in use new york customization you say
hey this is the version so i have to
sterilize this way but after 5-10
version you're going to go out of sync
in a way so you won't be able to keep up
with the which version does which one so
it's not a it's good for a couple of
versions but after that it's going to
create more mass so I don't yeah but if
you if you do this like so if you want
to if you do if you write everything as
a byte array of course you don't have
that problem right so just like in the
case of man cash right so you you're
right everything is a byte array
everything's stored by writing the data
grid datagrid doesn't know in your
classes at all you you do this
digitization translation dissociation on
the web server cluster so then what you
still have the problem of upgrading your
have application right so because that
nodes can have different version of the
code so it's not our problem of data
grids I think it's a problem of
channelization in cluster it in and any
constant so because the one node has the
latest version of the object writing it
and then the other one is giving the
bytearray and visualizing and cannot
because this class is not deployed yet
so I think the question should be forget
the data gates how can I write that yeah
you got it
yeah we do support Phoebe dudes who we
hazel death right 3 we started talking
about his daughter and we support rest
memcache directly you don't have to
deploy anything to get lancair support
our socket can talk HTTP directly
memcache Brantley and our own binary
format
oh this gas doesn't use things like gay
groups or any other library it's all
from ground for discovery videos
multicast we use TCP IP also be used if
you're running on Amazon ec2 you can use
Amazon it to institute discovery
mechanism it's built into his house
already but after the discovery of thing
is tcp/ip we don't we don't talk
multicast act after the discovery yes
so when an EVE note start so what one
guy the senior guy in the in the cluster
will make a decision to which partition
to migrate to the new one okay and that
migration will start so some of the code
will be moving to the new guard ok and
then so it takes time of course it's
like a 20 minutes or so to totally get
equal again and then when a node dies
again said the backup server will be
owning the data and then taking the
backups of the lost partition partitions
so migration will happen most of most of
the time when when new node is added and
of course to avoid the the coast of
migration we have to adjust the
partition count so that the partitions
are small enough to make it very fast
oh I'm sorry you were talking about the
Taylor anything okay so okay so hazel
Cosmo okay yeah so when I never
partitions it's a bad bad thing you're
already so we have to all except that
something had wrong in the network and
it's not really a problem with the
datagrid but still it has to be able to
deal with it right so when they never
the problem is fixed you're you're
you're two separate clusters should be
merging right so what's them so well how
are we going to merge right right so
hazel caster will detect that hey I was
actually part of a bigger cluster but
somehow something happened and I look
separate I stay separate so I have to
merge so so it's a smaller cluster will
be merging to the bigger cluster so so
so when merging of course they have to
merge the data to so and as you can
imagine the same data can be updated or
might be updated on boat clusters so we
have to resolve the kind of conflict
right so in the map definition of Hazel
cars there's a section called merge
policy you can use this given provider
to merge policies but you can you also
write your own marriage policy and we're
going to give you the entries are both
entries with the hit count last updated
times and time stamps unlike things like
that plus the qiyam values and you make
a decision yeah
watch here hezekiah says one single part
and it's already when she are you ready
so you put it you can put things that
jar you to air what's your container
not sure that's that's wrong again
happiness
uh
it's absolutely horrible
that they're not to to us still the same
problem right there changing the class
yeah I don't think that there is a
magical very excellent answer to that
it's the same problem in any no asthma
even like stimulus data no ice girl
stuff who had the problem and if the
application depends on a field actually
there is gone what's it happened so
Eddie's might be a little easier right
sir you don't handle that new new one
but what your bar is removed then you're
screwed yes
of caution
i won
stacks action I'll check all the
complaints
show some
it's the first
ah
awesome okay so yeah i mean i understand
i mean coherence or terra cotta I'm
living out first as I said I mean what
the closet the day degrees are trying to
live like a single body right silica so
every part of the body depends on each
other so you're even like your speed
will be depending on the slowest guy in
the in the grid but so so there are
things that I mean normal i should say
like normal to any datagrid solution so
it's not a fault it might not be a fault
of coherence or terra cotta so because
there are problems like your application
having a GC problem right so it's your
your application it's your fault problem
in not now you I don't want to say your
fault but your applications fault okay
so you're painting a lot of JC issues
and then you're do you expect they're
good too but as I said with the they
were never questioning we should be able
to at least hand I mean deal with it
right so one one of the things might be
telling you something that telling you
that something is wrong write something
like I should be able to tell you hey
where we got a our memory exception do
you want to do something about it maybe
maybe like if i can tell you maybe we're
going to take this to the server down
we've given you're going to exit this is
exit the JVM and because it is getting
an hour memory error will will will will
create this the the problem that you
described so one guys having a big big
big problem others are stuck because of
that guy right so he killing that guy
might be a very good solution because it
when it's gone everything is will be
smooth but at least we have to be able
to tell you right tell you that
something is wrong with
with that node his attack can tell you
that we got exception do you want to do
something something about it it's part
of the API but still also the
applications and then the upper
operation guides responsibility is to
monitor the JCC the machine before a
health health of the machine all that
and take the actions sometimes manually
right so sometimes they're not really I
mean if it is that like a long GC right
so what can I hey a great can but what
do you expect me to do right there's a
long GC kick no but hikmah well how do I
make that decision like the one we make
the decision and just remove me from the
cluster maybe if I can tell you maybe
you're going to keep yourself out I
don't want to keep you out but maybe you
can say hey I got the exception let's
detach that note from the cluster right
so maybe it's that's why we didn't want
to do this like we have you be used to
have that we used to restart on out of
memory and some other people complained
like maybe it's my problem and I can fix
it well why do you restart the node I'll
fix it i can i can manage my memory and
get off the garbage okay then we're
gonna we're going to give the universe
and you're going to handle what you
should do an ink in the case of out of
memory so giving the interface or yeah
hook will be is as a better strategy and
we do provide that and still I should
yeah</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>