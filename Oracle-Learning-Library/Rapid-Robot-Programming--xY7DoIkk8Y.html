<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Rapid Robot Programming | Coder Coacher - Coaching Coders</title><meta content="Rapid Robot Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Rapid Robot Programming</b></h2><h5 class="post__date">2013-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-xY7DoIkk8Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so Paul Peron I've been coming to this
conference for a while doing a lot of
different types of robot presentations
over the years and some automation and a
lot of the bots that I brought here were
bigger like the DARPA Grand Challenge
and the urban challenge robots and then
there was Neil Young's car and these
aren't things that you can you know
readily just kind of procure
off-the-shelf so we started to think
about how to you know we've got this max
robotics platform built on Java how can
we make and we're gonna open source it
how can we make this more accessible to
folks because you know it's it's there's
only one link volt car of Neal's and and
limited supply of other larger BOTS so
so we focused on some smaller BOTS and
and and in codifying that in a book as
well let's see so there's only one slide
apparently how does this work
this is what multi-screen
let me see what's that
now I've got some I've got this
multi-window thing that I'm going to get
out of right now so that I can avoid
this issue because this is a new Mac and
things don't seem to mirror well or not
mirror well
let's see if this works
oops
set up show yeah this is what I need
okay there's a how-to on creating robots
we're focused here on just you know how
to rapidly program robots using Java and
these higher-level libraries the key
components of any robot is you know
sensing planning and actuation so those
are you know it's robot software in a
nutshell you sense from your environment
you formulate some plan of attack or
some decisions to make and then you
actuate something so this is sort of a
repulsively
cluttered diagram showing the the
components of play and and what we have
here is is the you know we've of course
run on the Java Virtual Machine we've
got you know different types of
operating environments supported by Java
run on different profiles of Java mes
see some real-time profiles and then we
built this sort of set of building
blocks that that make it easier to build
general-purpose and some specific types
of robots and automation applications
using just a number of generic
abstractions that are highly
configurable so we've got a sensor
object that's highly configurable that
we can specify how to packetize data
coming in over a serial port or an
Ethernet port without having the right
code we just specifying config files and
then the data comes in we get these
objects and in all the low level sort of
messiness of dealing with with that is
kind of handled underneath the hood
that's a good example of a service and
there's a there's a wide variety of
services and abstractions because
there's a big gap between writing
robotics applications and actually
getting something to run on hardware
especially if there is a wide range of
hardware we've got there's all kinds of
mobility platforms you've got different
types of processors you know just issues
running in in some micro environments so
felt the need actually this was
developed about a little over 12 years
almost 12 years ago started this
endeavor and built up this this this max
platform with some concrete drivers for
specific sensors and some frameworks for
for more vertical oriented applications
and it runs in a lightweight container
as an option or you can you know access
the objects using standard API calls
like like playing old Java objects so
that's max in a nutshell I gave a talk
yesterday talking a little bit more
about the architecture of it in the
embedded track but this is the smaller
robot family that that were targeting in
a book for through Manning called
programming robots and there's five
different BOTS ranging from something
imminently affordable that the junior
BOTS over there would be something
that's like under 200 dollars sum total
between the mobility platform which is
50 dollars in the processor and some
sensors and then we've got link C and in
the and I Robot I create robot that are
in the probably four to five hundred
dollar range when all's said and done
then we have rumbles who's who's here
today it's about a sixteen hundred hour
mobility platform so it's more research
grade and then once you add on sensors I
mean you know you can add on very
expensive sensors and the price can go
up from there but typically you're in it
for about twenty five hundred two
thousand for that so that's like a
computer but maybe it's your
general-purpose robot at that point then
we have Brutus here which can carry a
mean payload it's a very commercial
industrial grade robot it's about five
thousand dollars and and so the whole
idea is to show that the same
application code using these
abstractions can be written once and run
on these different platforms just using
different can different underlying
configurations you may even be using the
same sensor so you might not have to
change the configurations but you'll
have to tweak parameters like you know
the baseline between two sensors is
going to be different on on one robot
another so this is the the target we
call them the art bots because we're bad
at naming things but they're kind of
like ground our die think means ground
and our D means what does that mean like
retrieve and something but anyway that's
that's the name of these bots and so
this is rumbles hardware we've got the
mobility platform from this company
called a gears research group makes this
thing called SMP mobility platform MP is
probably redundant with my mobility
platform there but it's the surface
mobility platform it's designed for
outdoor operation and so we found of
course that when we run it on carpeting
like in a conference he doesn't oddly
enough do so well so we gave them like
the equivalent of wire chains to to make
them we put some duct tape on his wheels
to make them run more smoothly in here
environment like this but it's designed
for outdoor bots you basically the thing
articulates such that it can you know
one end can roll over a rock and while
the other while the other side stays
flat and and it can get up to oh I don't
know five or six miles an hour or
something like that maybe a little
faster with them and you can change out
motors there dear DC geared motors
driving the wheels on board there is of
course a battery we've got the fidgets
what's called company fidgets makes this
single board computer it's an ARM based
computer with an i/o kit and some of
their motor controllers that plug right
in to drive these motors it's Wi-Fi
connected and we'll see how Wi-Fi does
here today with the demo that's always
the oh you know we wanted to have it
Wi-Fi base because I wanted to show you
what it's doing without writing some
sophisticated GUI but so we'll see how
that goes but but we have it Wi-Fi
connected and streaming what it's doing
back to us to a terminal and and the
front sensors are there some cliff
sensors because we we heard
be bringing this out out on the show
floor later this week where there might
be a stage so we quickly added some
cliff sensors so that he doesn't drop
off the stage
those are IR sensors infrared sensors
just send out a beam and tell you the
range to where something is and so if
that exceeds a certain distance we know
we should respond and then there's some
front an ultrasonic sensor and an IR
sensor for redundancy to avoid impacts
and then some sensors on the port and
starboard sides for for detecting kind
of the sides of the vehicle or sides of
the environment and then we added sort
of towards the hole
not well one of the last later minute
things that we added was this fit PC
this x86 processor connected to this XT
on Pro live camera which is essentially
the Kinect sensor technology it's it's
got this chip in it from primeSense
there's a gentleman here actually doing
a talk or maybe here did his talk on
hacking the Kinect sensor that talks a
lot about about this how to use job at a
talk to sent this kind of sensor but
we're talking to this XT on pro live
sensor because it's something that's
more distributable than the Kinect
sensor which Microsoft kind of unless
you use their their development kit they
then will let you distribute it and use
their development kit you're bound to
Windows and we happen to be running on
Windows right now but that's not where
we want to always be so this is just a
picture of if you can't see the robot
from back there this is the what the
robot looks like now you can see the
Kinect sensor and some of the some of
the IR sensors and in his glory so this
is the software stack we've got a we've
got a on the fit PC there's the you know
we're running XP we're running Java SC
we're running Mac's common which is sort
of where 99% of our
lowest-common-denominator building block
code is for general-purpose robotics and
then we've got Mac's standard which
leverages some SC or
libraries as we need them like for file
i/o or something and then and then we
have our application here that we built
for for the book and for and that we're
demonstrating here which is this we call
open an eye robot eye where we've got a
driver interface that lets us talk to
these third-party drivers and and bring
this data into the into the application
from from the sensor the Kinect sensor
which is going to give you depth and
camera information we're using it fruits
its depth information on board on the
fidgets processor kind of a similar
stack from here except it's Linux
there's the fidgets drivers that talk to
some of the low-level fidgets devices
and we've got a max interface for that
that is basically wrappers and plugs in
that plugs it into the framework that
lets it expose itself as expose their
sensors as sensors that that can be
configured and their actuation
mechanisms as actuation mechanisms that
can be driven and then we have what's
called Max ugb core which is a smaller
subset of what we use for the DARPA
Grand Challenges we after the DARPA
grant we had this max ugv framework that
we applied to both the DARPA Grand
Challenge and the urban challenge and
then we generis started the genericized
a little bit so that the same some of
the same stuff for these outdoor GPS
based BOTS could be used for any type of
unmanned ground vehicle application so
indoor for example applications and so
there's some common libraries they're
executing a max app is is fairly
straightforward we just say it's it's
highly configuration based we say you
know Java and we point to some location
of a configuration file and we say max
and that's sort of like the main class
that that looks for an app an
application XML object we're actually
not bound to XML but there's different
configuration mediums but the but the
you know this is typically what we use
it will look for an application XML file
and then that tells the application how
to load everything else from there and
I'll just I'll show you that
you can also just just you can bypass
specifying the config and
and assume some default property
structure or if you've created an
executable jar you can just make a call
like that so it's just an example for
for how to create these met these up
objects so this is kind of what a max
config file looks like we've got you
know there's always some sort of cut
there's a context and you can have a
number of contexts or directories and
then you have your object name you
define you know the class this is like a
generic factory a class that's going to
be created and then configuration
parameters that are going to be passed
that are specific to that object that's
being constructed so as an example a
quick example for configuring an app
we've got an app dot application file
which says okay we're and these are all
generic max classes that that that that
you know don't need to be rewritten but
we reference a robot object which
defines some of the course core
components in this case this motor
exercise application object a planning
object and a sensor inputs command input
sensor just from the command line and
they said the command input sensor you
know when it gets data is is told to
route information back over to the motor
exercise object the motor exercise
object and when we'll show some code
examples of course to illustrate this
but is basically this application
specific thing that we wrote for the for
the book which says ok here's a list of
motors and each motor has configuration
as something like this there's some
generic motor configuration which
references how it's going to be pulse
width modulated in this case we're using
the fidget a fidget motor controller
approach to to drive these motors
telling it you know we're using this
fidget controller in this output number
so these are fidget specific XML files
and then we have to tell it things like
you know fidget serial number this is
all part of the fidgets infrastructure
and then we refer to a common target
which just tells us the IP address where
the where the fidget is is listening in
this in the case when it's running on
board the radha robot as it will be
today that's just you know one 27001
so controlling motors so you saw how we
had this the the motor DC motor exercise
object saying okay I have a list of
motors in this case there's this object
map we create an object Mac we tell it
to configure this this map and what that
does is it's going to load automatically
all those motor objects into memory and
call call these objects and creates this
object lattice such that when we get a
command than this in this case this is a
text-based input application we get a
command to say run and we parse some
data from the command like the like the
motor ID to look up and the run rate we
just tell it motor dot run at that rate
and then the motor will run at that rate
so that's controlling individual motors
which can be tedious so and so we'll get
into the roam free app here that that
we'll be talking about and demonstrating
here today you know controlling
individual motors again is not
necessarily what you want to do you want
to control the platform the mobility
platform you want the bot to move
forward you want them to to rotate you
want them to stop so that's where
something like this comes in play where
you say I can't get a load my a motor
mobility platform object in this case
it's a skid steer platform I don't know
if you're familiar with skid steer but
left side right side can be
independently you know controlled so the
left side can be rolling backwards as
the right side can be rolling forwards
and you're sort of turning it's just
skid steer based operation versus like
acraman steering which is like in a car
where you're steering a steering wheel
on the two front wheels are moving so
those are two different mobility models
and this happens to be skid steer
platform
so the calls here are now higher level
because we're saying mobility platform
move at this rate and so that handles
dispatching the these individual
commands to the to the motors for you or
rotate not handles you know depending on
the polarity of the rate which direction
it's going to rotate the platform and in
the speed and then of course you can
move the port side and the starboard
side at different rates if you want to
kind of effect turns and then stop
there's usually an important command so
this is an example of a mobility
configuration file so we had here smoke
this mobilization application which is
saying ok I've got my mobility platform
reference I'm gonna load the skid-steer
platform generic object this is in max
ugb core and there's a skid steer map
and it's saying ok on the port side I'm
linked up with these two motors and on
the starboard side I'm linked up with
those two motors and you saw an example
of how we configured motors before so
and that's all there is to it so it's
like it's it's this abstraction layer of
abstraction that lets you get to
controlling motors and controlling a
platform a lot faster because you throw
down some special configuration motoring
and mobility so there's the sensation
part and for this we've got what we call
these different object sensation
perspectives so with this robot we've
got four views we've got what we call
the front view which is basically gonna
be here as you can see it's the coat
it's it's referring to these two sensor
files which happens to contain the
configuration for the front IR sensor
and the front ultrasonic sensor then
we've got cliff view
which refers to the two cliff sensors
port view which refers to the portside
ir sensor and starboard u which refers
to the starboard side so there's there's
those different views so for for an
actual - so this showed you how for
example the front view refers to a
particular sensor file so here's an
example of a sensor file we've we're
specifying that we've got this this
generic max class analog input generic
and its interface is going to be the so
that we can talk two things independent
of whether it's a fidgets object if we
change over to some other object we just
specify a different interface but in
this case the interface is this fidgets
analog intercut which is telling us to
load this fidget driver and specifying
some parameters about it in terms of
like what input number on the fidgets
interface kit are we talking to and how
to in this case scale the raw data that
comes from this
it's basically an analog input from this
fidgets device it's telling us you know
what's the equation for mapping that to
a meaningful value so this these magic
numbers here map it and this is just
built into the sharp IR sensor nature
when it says it's this voltage to get
the millimeters range you have to apply
this you know this equation in here and
then we apply some limits on the minimum
input value and maximum output value for
for checking those sensors so so here's
an example in code now of of again using
the sensor so we've we've got our own
robot relative obstacle detection class
that we've created that extends this
this generic class and we say ok we've
got an object map of inputs we ask it to
load them during the start of sensation
we we clear our sensed objects and then
as we're when when this vehicle the
callback chain is invoked to sense
objects it loops through
analog inputs reads the value the value
read here will have already been the
transformed value the millimeters range
value from the RF sensor and then we're
passing it on to this to this obstacles
objects object to say okay here here's
here's this reading and this reading
will I'll show you right here this class
will say okay if the distance is less
than you know the collision the the
current worst case collision distance
make the collision distance this shorter
distance if the distance is greater than
some max obstacle distance make the max
obstacle distance that distance this is
a very simple class just looking for the
min and Max distances in this case we
only had two sensors so pretty easy to
do so that sensation in a nutshell so
now moving on the planning which is
where where the fun stuff happens so but
the interesting just sidebar on that is
a lot you know if you were creating all
this sensor code and and actuation code
from scratch it takes takes a long time
it's boring it's fraught with with error
and you know you're doing it over and
over again for 100 you know all these
different applications and all these in
this case five or so different BOTS if
you were to create all five BOTS or or
you want to move on to the next project
you want to scale up from the small bot
to the large bot as your spouse allows
you to afford the the Brutus 5,000 gold
standard robot so so we get to that very
quick writing very little code
unfortunately I don't include any like
statistics as to how much code there is
I was thinking about doing that but I
just never did it but it's it's a lot
less code that you would have to write
and so there what's the roam free
application this is just a simple we
thought about you know what should we
show for the book and what can we show
here in a meaningful timeframe and so we
took something simple that could be
built upon
and it's just a row it's a rumor so so
this robot is going to it's gonna roam
around since the environment that detect
collisions distances angles to those
collisions execute specific maneuvers
based on these sensed distances and
angles and with the key idea that a
maneuver is just a sequence of maneuver
actions so impact avoidance as we'll see
when we detect that impact avoidance
leads to stop
that's one action spin that's another
action
am I forgetting something and I know
stop back up spin and then move on so so
those are the three actions that form
that that form that maneuver and then
there's of course we have to prioritize
which maneuvers are executed first
impact of Ordinances it's got a higher
priority than just roaming yes
I'm sorry five or six miles oh yeah well
we started out just gunning it like at
its max speed and and which is and you
know we found that you know it wasn't
reacting in time so but then we tighten
some control loops and then we you know
it's just it's just something that you
tinker with and then and then you can
control what the max speed is and but
but we in the roaming mode as we'll see
it slows down like if it starts to see
stuff in its periphery it'll slow down a
little bit but if it feels like it's
home free he's like okay I'm going my
max speed so in an environment like this
is gonna be kind of hard because he's
gonna send them maybe that way and see
what happens but maybe we can maybe
we'll just take him out there and see if
he avoids the escalator I mean I'm game
for it if he you know well yeah if then
if the network works what will get that
going but the so this is the see where
do I want to be at 40 yeah so this is
the roam free configuration we've got
our base application object which is
saying okay now we have a movement
planner and this is this is the key
planner object and then we've got some
synchronous thread that's triggering
this thing every 25 you know
milliseconds and in a robot file has a
couple other things here I've got some I
can actually command it via the command
line to stop the minimal attention to
safety given to this given the size of
the robot but and for the in for
demonstration purposes but you know I do
have that to it typically I would have
like some sort of remote e-stop mecca's
for the big cars you need the remote
e-stop mechanism and and other safe and
you need heartbeats and watchdogs and
all that kind of stuff this thing's kind
of got free will and then there's an
interface to the
to the Kinect sensor so here's what we
want to accomplish algorithmically if if
we bump or we are if we are impactful in
the front we want to back up a bit
spin around move along else if all is
good in that front if we're collidable
we think on the Front's or sides based
on the starboard and port sensors we
might trigger a slightly more aggressive
rotation where it'll stop and rotate too
you know as a proportional to the
collision angle else if all's well and
there's no imminent impact or imminent
collision we're gonna roam around and
we're gonna trigger slight and just
adjustments as we see things along the
way we're gonna adjust our speed based
on these collision distances we're gonna
look for openings and hone in for those
openings and as we see things on our
left and right we're gonna you know make
corrections so and here's how movement
planning works this is a max framework
thingy but basically if we're in run or
enable mode we induce any sensation
updates so we they may be coming in
asynchronously but we've but we locked
them in for this planning cycle we ask
the manoeuvres based on this to detect
if they are active and then we resolve
and prioritize which maneuvers to
actually execute which ones have higher
priority and then we ask the remaining
active react we ask any of the remaining
active maneuvers after that they're not
told to ignore this cycle to execute
else you know we ensure the mobility
platform is stopped if we're not in run
enable mode so here's the movement
planner configuration we've got a
reference to our mobility platform which
we already talked about skid-steer our
object detection which we talked about
which is our sensor package and now
we've got a collection of maneuvers and
this and the mode is ordered priority
consideration where this one supersedes
this one supersedes this one this one
this one and the and the five modes did
I describe them nextslide no the five
modes
well let me I'll just i do describe them
somewhere so I'll describe impact
avoidance first or via example so this
is a this is a some sample code custom
code that one would write referencing it
where we say okay the minimum collision
distance is 250 millimeters for for
something to be considered an impact and
the actions that will execute our stop
robot roll back spin so here's a base
class for avoidance maneuver a custom
class that we created for this
application to to let us reference our
different views and read in our min and
Max collision distances it's just a base
class for doing that and so here's a
subclass of avoidance maneuver using
that avoid avoidance maneuver behavior
it's self exiting meaning this maneuver
will not allow itself to be considered
inactive until it completes all of its
tasks because you don't want it to sort
of as it backs up realize okay now I'm
not I don't have an impact and then I'll
just do the hokey-pokey for a while as
it right so this it's going to complete
all three actions in this case so so we
get our list of front obstacles we say
hey where's the collision distance for
the front if the front distance is less
than what we had it configured to be 250
millimeters we're going to say we've got
a collision vector straight ahead and
that's our collision distance return
true so that tells the framework that
that that that maneuver is active so
that maneuver will be told to handle and
so here's the three actions they're very
simple so the stop robot action this is
the code for it it extends this movement
action when it's told to execute it says
stop very simple roll back actions a
little bit more complicated but not much
we've we've only did something we don't
have of heading sensors and things like
that on this simple robot example so
what we're just doing with this example
and the
and the book and here is just we're
gonna roll back for 10 seconds at a
certain speed and so in this case that's
just just showing that this is
configured bi-directional wheel platform
is actually a super class of skid steer
it just makes it more suitable for other
other types of platforms so that we
don't make it skid steer specific but
the basic idea idea here is when it's
told to execute its it's going to move
at this rollback speed and it's going to
continue to move at that robotic speed
until until it times out because this is
a timed action maneuver that action
timeout seconds is configured and when
it times out this method is called and
the and the action stops so spin is kind
of similar to the last and that we're
going to rotate at a certain configured
speed for three seconds and when we're
done we stop so that's the code this is
try to keep it simple so these are some
of the other maneuvers that we have
there's cliff avoidance which is the one
I mentioned we're if we have it
configured such that if something's more
than five 550 meters away from those
cliff sensors it triggers that and it
goes into stop rollback and spin
I know the question on everyone's mind
is does this bot have any sensors on the
back the answer is no so so but you know
for this for these examples again that
keep it simple you know we try to limit
that but but that's an example where you
know you you know you add on something
you want to add typically something like
backup sensors for a bot like this so
that it can know not to back into things
and you'll see it wreak some havoc on my
son's toys that make some cries so so
that's good to avoid so and then we've
got a roaming maneuver where we've got
an Ethernet connection to the this rope
robot I sent so
River that we call on the fit PC it gets
a collection of features which just tell
us are we do we have openings dents or
bumps and it's looking for openings and
if it has openings it it goes towards
those it modulates its speed and it's
and it's you know port and starboard
adjustments to get into those openings
and it doesn't have any openings
presumably one of the other manoeuvres
have kicked in because it's got an
avoidance problem and then because this
was a late addition we actually started
out with I are roaming just using the IR
sensors and there's no there's our only
two point sensors so it's not very good
I mean you may drive by a chair leg and
see something and not see something and
then so he gets a little herky-jerky
kind of like looking around so the
Kinect sensor is has this has a sweep so
we've got multiple range points and
actually can go up and down as well so
we can get a much better view of what's
out there but if this if we lose
connectivity presumably with with the
with this thing it goes into the
graceful degradation mode of using IR
based roam so and I don't think if we
have time I'll come back to because I
think it's interesting the the feature
roam and talking to the Kinect sensors
but I wanted to give some time for for
for setting this up and I'm gonna try to
see if I can do that in multi well you
know I'll just show the videos and then
we'll just do it real time so these are
the videos to turn up the volume
we're the good wallah you made the baby
cry you'll be paying for some counseling
later in life I have a feeling
so that was a backup maneuver here he's
going roaming and then just tries to
turn in time but instead couldn't catch
it so he does invokes a probably a
impact avoidance maneuver here is making
slight adjustments during row mode
it's running over my shoes no it's just
getting it as it can so now here's a
beta version without the Kinect sensor
kind of using pure the IR roaming mode
and Luca my two-year-old expresses his
displeasure with the whole project he
senses the coming coming of the robots
so we have barstools in here and that's
when we added the Kinect sensor so that
better detect those oh maybe he'll back
up he's backing up now
now he's gonna turn around now maybe
he'll come out here
what do you think
huh here he comes no no he's alright
these aren't friends it's a good robot
robots are our friends Luca Luca the
robots are our friends do you want me to
turn them off I'm gonna shut him down
okay he'll remember that okay he's off
does that make you happy do you like him
on or off okay well I guess you don't
really appreciate my work
that's that's that so now Network
willing demo gods you know this is it's
always great to do live robot demos cuz
well we don't we don't really need it
but but what I wanted to do for
demonstration purposes is I wanted to
show sort of what some of the maneuvers
it's doing just and and start and stop
it right from the command line and be
able to also issue a stop right from the
command line we didn't build a GUI or
anything for it but yes actually so so
the other thing is yeah there's some
things that we have planned for the
community keynote that will is going to
lend itself to some wireless Wi-Fi
connectivity so I'm a little wary of it
and it may change in the next two days
or whatever but but it's because yeah
when you come into environment like this
everybody's got something computers or
or what-have-you but I think I mean
we've been we've been doing this quite a
bit in the lab so we'll see if this this
works
all right
okay
so we are connected
so let's see
Oh first I want to unplug this anyway I
wanted to have a charge did did it oh
did I
okay I'll check that
let's see and the other thing is when it
when I turn when I was turning it on
like having it automatically come on I
didn't get to see if everything loaded
correctly and and I just felt that this
would be better we get one response
it's the
this is our Wi-Fi connectivity
so while I'm doing this - I can
multitask and take some questions if
anybody has some questions Amma's well
it's practically autonomous well there's
no robot that's fully autonomous
hopefully because that means it decides
that it's got to go to lunch or
something so so yes there are shades of
autonomy if you know the programs
running on the board we but just to
start and stop it again I wanted to show
you kind of the states it goes through
so what I you know worst case I'll just
reboot the thing here let's see what
happens
yeah but it looks like I've got a
connection so just seems slow which I'm
puzzled by but but actually I'm not I
mean I was fully aware that this could
be an issue
so let me get him ready here
because when he comes on and goes
alright he doesn't do well with wires
unit so let's see
okay I'm gonna reboot them
powered down
power up you have a scary thing this
morning was it put itself in sort of
Auto Start mode I don't know how that
happened and I wasn't expecting it and I
had it we're gonna have it
oh yeah just just went went ballistic
and just knocked over some water and
yeah ah safety is this secondary concern
so yeah any other questions as this
being potentially comes to life looks
like he's a little bitter yeah yes it is
we're in the process of doing that we've
been meaning to do it for a while we
have we are gonna have a license that
makes it free for low you know
reasonably low and and no commercial use
so it's a hybrid license so you know
someone sells $250,000 worth of stuff
that's free but you know then once you
once you start to make a killing
you know we'd like to get some support
so but it's open you know it is open
source you know in that sense I already
open that so I'm already there
and
any other questions while we're waiting
for them yeah oh yeah no everything's
off the shelf nothing is is you know you
just you know maybe that you have to
write a driver for it it but that would
be that would be like the worst case you
know scenario but the drivers are
usually you know sit simple to write and
we have some information on how to do
that
yes and there's actually in some cases
you don't even have to write any code
it's it's if you if you're if you've got
an Ethernet or a serial based interface
you can you know you can use this the
packetization scheme
I'm sorry motors they are DC geared
brushed motors
see if I get to him from the admin panel
see he was just up
maybe a good thing would be just restart
the router how about that
clear out any collisions
yeah just for ya it's loose this is a
non real-time non real-time system
any other questions
yeah we've done some amanda our vehicle
apps we were here at JavaOne in 2007 i
think and did have an application
because you know at that level I mean
we've got a maxi ugv framework which is
catered for unmanned ground vehicles but
we don't have a a max UAV framework per
se but we've done applications using max
of course to drive motors and and
sensors and and and and things of the
like for air vehicles mainly was that
that was a terrain scanning application
so
any other yeah
and
the yes you can use Raspberry Pi I mean
that's if you can get one and it's it's
Linux based right the the open ni
drivers are not we haven't done we
haven't done any of the Linux porting
for the or haven't done any testing with
Linux using the anti open ni drivers so
that's been that that's been you know
sort of put off so yeah but but you
can't you can't use it at we haven't
we've got a Raspberry Pi I think I think
we just got one in or but we haven't
done any specific testing with but
there's nothing here that limits you
from any processor I mean it's just you
know we've run on everything at this
stage</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>