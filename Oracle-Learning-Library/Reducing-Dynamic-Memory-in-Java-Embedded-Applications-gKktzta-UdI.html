<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Reducing Dynamic Memory in Java Embedded Applications | Coder Coacher - Coaching Coders</title><meta content="Reducing Dynamic Memory in Java Embedded Applications - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Reducing Dynamic Memory in Java Embedded Applications</b></h2><h5 class="post__date">2013-02-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gKktzta-UdI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this session is reducing dynamic memory
in Java embedded applications and my
name is Sinkin Wang I'm here with my
colleague garum osich and we're both
engineers for from the Java embedded
group at Oracle and we've got a nice
small intimate crowd today so we'll keep
this informal if you guys have any
questions to shout it out if if you need
to interrupt me along the way to ask
question just feel free and also where
I'll have a demo at the end so if you
have questions along the end about the
demo then we could talk more informally
about everything so our typical safe
harbor statement blah blah blah here's
our here's our agenda first I'll be
going over the the first half of the the
presentation I'll give an overview of
what we're calling at this conference
the Internet of Things small embedded
devices you might have seen the previous
talk on the Raspberry Pi and using Java
that's what we're talking about all
these interconnected devices then I'll
give an introduction to our Oracle Java
embedded technology and how we're using
that on all these embedded devices and
the Internet of Things then we'll go
over the best practices for programming
for java embedded and Darrell will go
into detail about the techniques
especially to reduce your dynamic memory
usage when you're programming to these
smaller devices with more restricted
environments then we'll also talk about
the tools that are available for job
embedded and part of the demo I'll
actually show well how would you do your
typical type of profiling or measuring
your dynamic memory usage on one of
these small devices and then we'll open
up to Q&amp;amp;A at the end but again it's the
small crowd so you know feel free to
interrupt me and ask questions so what
is the Internet of Things here you can
see some of the examples of where we're
putting Java embedded and
and it's currently deployed on billions
of devices right now there's all kinds
of variety you see things like in the
enterprise there's multifunction
printers there's voice over IP phones
there's in a consumer world things like
you see the kindle on the left-hand side
there and fun things like driverless
cars that's an outie quattro that's
running java real time on it there's
also medical equipment in the health
care industry industrial controllers in
factory automation and of course you
hear about hear about java on feature
phones all the time also on smartphones
and we cover industrial use cases such
as smart meter smart grid also and much
much more and we span with our single
Java technology among all these
different types of devices you know this
from attending java one that on the left
hand side you see big iron the servers
where you run java ee you can also run
java SE as a platform on those big
servers but primarily you see java SE
that red block right down in the lower
left there that's where you have java SE
also on desktop and then it encroaches
into the high to mid-end of embedded
devices and that's where you see
underneath the robot there's these fixed
asset types of devices where you have a
smaller footprint smaller memory smaller
static footprint area where you still
want to run java SE full api so that's
the full specification that you want to
run and that's what we're talking about
narc discussion here is embedded java SE
embedded now you might get confused
because there's also a lot of talk about
Java ME and then there's an embedded
stack for Java ME well that's more for a
vertical market as you see going from
the middle toward the right you can
layer on top of Java ME embedded the TV
specifications such as B DJ that's the
blu-ray disc Java specification or Java
TV so that you can call java api is to
do things I
change your channel fast-forward rewind
your video that you're watching those
are more vertical because their specific
to a certain market such as TV or mobile
so if you want to change your or you
want to dial your phone's phone number
on your feature phone or if you want to
send an SMS text message you have java
api s that are on top of the generic
java platform for Java ME such as MSA
the mobile services architecture and
then that allows you to do something
specific for a vertical market such as
mobile so that's very fit for purpose
because it's a subset of the Java
specification so there's missing ap is
and you have to remember oh I'm going
from java SE the Java ME so I can't use
certain api's like file i/o or you have
to use generic connection framework
instead or you have to use mid p for the
UI instead what we're trying to address
in java SE embedded is give you the full
java SE spec so you don't have to switch
gears and remember what sub setted spec
you're using you just go ahead the same
way you program on your desktop or on
your laptop it will compile and then
just run the same bytecode same jar file
on these small devices like a raspberry
pi or a beagleboard just what i'm going
to demo later and then we have on a very
right-hand side the java card which is
the smallest stack is there any
questions along right here how many
people by show hands have either used
java SE embedded or no of java SE
embedded okay that's a good size crowd
and how many know of or have developed
in Java ME technology okay about not the
same breakdown so you guys mainly know
about the the the purposes of the two
and I'll just touch upon it real briefly
since you do java SE embedded again it's
a small footprint in terms of memory and
static footprint available and we're
trying to provide the full set of api so
here it says the full java's one not six
api right now we release java 7
for java SE embedded so we have the full
java SE 7 dot 0 api is available and a
lot of times our market is going to be
large commercial industrial customers
where they have those fixed location
assets and by that i mean your cell
phone you carry around with you you walk
around streets you go drive around with
a smartphone or a feature phone or a
tablet but for a embedded router or for
a multifunction printer or even health
care there's a biometric or there's
these medical devices that monitor the
patient's health they stay in a room and
they don't move around typically where
you need wireless 3g connection so
that's what we call fixed location
assets and the that's really a prime
market for java SE embedded since they
have more memory and a little more
memory than typical meta devices that's
more appropriate for the full api set
then for Java ME as many of you are
aware an audience that's for a subset
and even a smaller footprint than
typical industrial embedded devices and
the install base is in the billions for
the feature phones even Nokia is still
producing feature phone series 40
feature phones that are available for
for the developing world and for the
mass market where the people are very
happy with feature phones and don't need
a smartphone that's where job and me is
is well suited and run in the billions
of devices there and again that's for
mobile use you're concerned about
battery usage you're concerned about
keeping your Bill of Materials your bomb
to be very low cost so you're trying to
cut costs wherever you can leave out as
much memory as you can to keep that cost
down and this is why yes there's a
question here
yes so the question was where does
blu-ray and maybe even TV set-top boxes
where does that fall under the category
that would fall under Java ME embedded
even though it doesn't match the
metaphor of a mobile device it's still
there very concerned in the consumer
world of keeping the Bill of Materials
low-cost so they're not going to load it
up with one gig of ram there they're
going to keep it down as far less memory
as I can so that would be considered
Java ME to keep a subset of the
specification not the full java SE spec
okay any other questions okay so let's
dive a little bit deeper into java SE
embedded itself again that's the full
java SE spec but in the implementation
you get a different runtime than you
would for desktop or server and this
runtime even even laptops are different
runtimes since you have usually four gig
of ram nowadays it's very different than
running on raspberry pi or beagleboard
you want to have memory optimizations
which we do in our libraries and and
Darryl and I work in the in a libraries
group for job embedded where we make
sure to go through each of the core
libraries java.net javed at util joke
lang make sure all those classes in our
libraries are using memory efficiently
so that's one thing that's different
than the desktop version there's also
smaller persistent use of memory so your
footprint that you would take up for
storage for your flash memory where the
library RT dodge are for your runtime
would sit is much more reduced than the
amount of memory that you would use on
your hard drive and nowadays you have
one terabyte hard drives on your desktop
system so huge you don't really care how
big Java is going to be there on your
small devices if it's 128 megabytes you
don't want to take it up with all of
your RT jar that you
need for your java platform and also
because of that everything that gets
loaded by your libraries in the java
runtime is put into ram when you're
executing so you wanted to make sure
your your static footprint size is low
so that your use of volatile ram is low
awesome and then there's runtime
optimizations we have a special
just-in-time compiler we have a special
virtual machine that runs on ARM chips
and these typical risk-based chips for
embedded devices nowadays it is not the
same as intel quad core or eight way
multi-core processors that they have
nowadays it's a very different way of
creating a virtual machine and creating
a run time so that we take advantage of
all the the registers and the
instruction set that you would find on
arm vs intel and so you have a proven
and stable platform this is years in the
making and taking technology where in
the past Darryl and I have worked on
Java ME CDC technology which is kind of
in that that area of mid to high-end
embedded devices we took everything we
learned from that technology and now
apply to java SC embedded and then we
have a huge developer base everybody
knows java SCE api's you have all the
ides eclipse NetBeans jdeveloper all
those developed development environments
are able to allow you two to choose java
SE as your api set and we'll we'll do
all the runtime checking for you in
compilation checking for you so there's
no plugin that you would need also
there's a rapid application development
with those IDEs so you could use your
favorite editor your favorite
environment if if you choose eclipse or
netbeans it just doesn't matter and you
get all the goodness the apple pie and
motherhood of java the fully
object-oriented aspect of programming
and it runs on a virtual machine where
you have one jar file running on all
these embedded devices
and you have memory management of course
you're not using C natives and and see
pointers where you have to allocate and
then free up your memory that for
embedded programmers that are not java
programmers so they're not here at the
Java conference to have a one conference
they normally program and see so they
don't know the goodness of the memory
management that you guys are all
familiar with then there's portability
you have teams at Oracle that are making
sure that the runtime and the vm are
going to work on other risk-based
embedded environments like mips or
powerpc or any other of a number of
Linux distros and other operating
systems that you find an embedded world
and that's very different than just the
three major operating systems that you
find on desktop you find Windows fine
Linux and Mac OS on desktop and laptops
and that's all that java SE normally
cares about when you're talking about
the desktop version but then in an
embedded group we care about porting to
all kinds of different distro flavors of
Linux angstrom and debian and headless
and and all kinds of other environments
and that those environments also have
different CPU support so nowadays the
ARM chips are very widely varied where
you have things like multi-process
support in multi-core chips so there's
the four-way ARM chips that are
available now and you need to make sure
that your virtual machine is taken
advantage of all those cores of being
able to do multi threading and
multiprocessing on all these new arm
embedded environments and then you also
get security and networking that you
always get with with java SE technology
and what is different between java SE
for desktop and server versus java SE
embedded well that as I mentioned we
port two different CPUs so you get arm
MIPS PowerPC for example as different
environments for your virtual machine
versus the desktop
then you get these small profiles where
you're talking typically there's ten
megabytes that we want to allocate for
Java to use on these devices headless or
about 16 megabytes of RAM that these
devices would use and that doesn't mean
that's the total available it's just
that's the corner of the memory where
Java is going to run and usually if
you're a device manufacturer you don't
want everything a hundred percent of
your memory taken up by Java so we try
to keep that low and and small for you
then you want a choice of VM features so
that you as a developer can decide my
device should have a smaller Client vm
which means durably a smaller footprint
and this means we have one flavor of the
virtual machine where you can have just
the serial garbage collection and the c1
client for the JIT which means that
just-in-time compiler is just doing
client-side compilation that means you
get a much much smaller footprint that
you can put on these embedded devices or
you can choose if you wanted to a larger
vm a server vm with more it takes up
more memory and take some more static
footprint that's for when people are
saying embedded they mean just
installing a headless piece of software
on a machine and that machine could be a
big iron huge spark server for instance
a t4 server they some people still call
that embedded software but they really
just mean that they want to restrict
that software to run in a small
environment and we could do that too but
then you would be able to run a full
server grade vm instead where there's
more going on in terms of the
just-in-time compilation and that's the
trade-off is a bigger footprint and then
there's also a large full-featured
configuration that we support so if you
wanted all of Java headful Java where
you had a WT support and be able to run
on ARM chips still we also have that
option
now I'm going to turn it over to Darryl
and he's going to step you through best
practices in more detail on that hi
everyone is there anybody here that does
not develop embedded software ok but so
we have a few people one of the
differences between developing for
embedded devices and developing for
desktop and java SE is most of the time
desktop and server application
developers don't worry too much about
footprint and memory a lot of it is
about performance and usually there is a
direct linear graph where if you have
less memory to work with your
application is going to run slower and
if you have more memory to work with
your application is going to run faster
and that's usually because you can do a
lot of things that take up memory that
improve the performance of your
application like caching information and
things like that some of which we'll
talk about so the desktop and server
developers usually don't have to worry
too much about memory when they're
writing their application so they can
focus on the business logic of the
application and they can focus on the
performance and making their application
faster embedded development you not only
have to deal with the business logic of
your application but you also have to
deal with a limited environment both in
terms of memory and CPU and a lot of
times in terms of persistent memory or
basically your hard disk might be ROM or
an SD card so for embedded developers it
takes a lot more work to write your
application and of course memory matters
because there's a limited amount of it
on our device some of the things that
we're going to talk about in terms of
how to build your applications for
embedded devices are optionality how to
include you're a piece of functionality
or not include it or maybe make it
optional runtime in other words you
don't need it until it's time to use it
tunability which really means remaining
flexible writing your application in a
way
that you can set some parameters to tune
it so that if your applications running
on one device you can tune it one way
and if it's running on a more or less
capable device you can tune it a
different way and then efficiency which
is really that memory performance
trade-off so build time optionality is
there anybody here writing a framework
or a platform for their customer like a
couple people here okay usually the
build time optionality is something that
you get from a platform that you're
using or you use it when you provide a
platform for your customer and an
example is is let's say that you have a
application that makes a modem dial out
once a week your application read sensor
information and it collects that for
about a week and then every week it
dials out to the server and uploads the
data you there there may be cases where
you have features that you are provided
by the platform itself like another
example is a graphical user interface if
you have this platform or if it's one
that you're providing but somebody is
building a headless application without
the graphical user interface there's no
need to include that code along with the
product itself and so it build time you
can not include that in your application
then in the platform and of course it
makes the the whole persistent footprint
of the entire application that goes on
the device much smaller in terms of
runtime optionality going back to the
example with the communication if you're
collecting data through sensors in your
application and once a week you make a
dial out connection to a server and you
upload that data that event is only
occurring about once a week and that
functionality is only being used about
once a week so if you're able to take
that functionality and isolate it into
shared libraries and separate classes
such that they're not loaded all the
time then when it's time to make the
dialogue
action you invoke that functionality it
loads the libraries and classes you make
the connection you upload your data and
when you're done you unload those
libraries and classes you will save that
amount of memory when your application
is running when you're not doing the
upload so you're going to save a fair
amount of memory there as long as it's
not performance critical because when it
comes time to invoke that usage of the
code it's going to obviously a little
bit slower to dynamically load that code
so tunability again tunability is the
ability really to remain flexible and to
be able to change certain parameters and
to kind of tweak dials in order to
change how your application behaves and
one of the ways you can do that is
through the use of caches so if you have
an application for example that provides
a user interface to a user and in that
UI is text you may have that text stored
in a message properties file somewhere
and from a desktop or server perspective
you might load that text into memory and
keep it there until the user hits that
screen and then you can present that
text to the user but if it's a screen
that isn't used very often and the user
doesn't see very often it makes sense in
a bed of iron meant not to load that
information right away but again only
load it on demand so in other words in
this case you don't want to cash it and
usually in the case of embed
environments caching is not a good idea
just because you're running with limited
memory and you don't have a lot to work
with in terms of caching that
information yeah you have a question
Oh
okay so the question is about runtime
loading of information in the case of
Java you usually don't load your classes
well actually me back up so in the case
of Java that there's really two pieces
here there's the Java piece and then
there's the Native piece from the Java
perspective it's almost like the caching
where you will not instantiate a class
until it's time to use it so late ya
lazy instantiation yeah in the case of
shared libraries those are native deso
files typically or dll files in the case
of windows and there's an actual load
library call in Java code that allows
you to load that library and again you
wouldn't call that until you actually
need it as an example there's Java that
Lang got system load library and that
that's where the the actual call method
is used for doing that
right it's
but you do it just like you mentioned
and Darrell mentioned for when you
instantiate a class do it at the very
last moment and absolutely only when you
need it so you do it lazily is don't do
a system load library every time you do
a static initializer of all your classes
exactly exactly right the question was
there's no way to unload a library and
that's correct because we rely on the
operating system to figure out hey
there's news memory that's being used up
that I should just unload the library on
the operating system level so Linux does
it differently than Mac OS does it
differently than solaris we rely on that
right so the question was it's it's
controlling when you trigger the the
initialization or the loading and yes
that's correct we we recommend you do it
lazily as Darrell it's mentioning and in
case of Java classes the more you can
have your classes or your fields for
example instantiated for example within
a method or something like that then
it'll get garbage collected exactly it
goes out of scope okay so moving on with
tunability we have the use of buffers
where you might have an array and again
in the desktop server environment
typically you will allocate your array
as big as you think you're going to need
it excuse me and fill it up only as you
need in the case of the invited
environment though you don't you don't
really have the luxury of being able to
allocate your large size array so what
you want to do is allocate it as small
as possible and then let it grow as you
need it and then you what you need to do
is as you don't need some of that
information you want to shrink that
array back down and you need to do this
again with lists hash tables hash maps
basically any list type of field or
construct yet you have a question
I
Oh
yeah I think in the case of in the case
of most of the questions classes you can
define how large the collection is
initially and then there is a another
parameter you can set for how much it
grows when you add to it okay so those
are two things that you can configure
and then if you want to shrink it what
you do is you create a new array of the
smaller size and you copy the data into
the new smaller sized list or a rare
collection
control your size
and I think that's a programming style
question but I'll repeat the question is
using a linked list better than using a
hashmap or where it's automatically done
for you in the core libraries it's if
you find it more convenient to use hash
table then go ahead and use it because
the trade-off is you're relying on the
system to make decisions for you but if
you want that fine-grained control then
use a linked list it's more programming
more lines of code but then you decide
how to shrink and grow it specifically
so i think that's one way to answer it
is it's a style of a programming style
question
champa space that
once you're done with it is
right its members
using part of the list and we sense
right sure it just to summarize it using
a linked list you do have that
fine-grained control of when to release
an object and when to have it no doubt
yes so again in terms of being flexible
you want to be able to tune these
parameters so in a really small system
you might allocate a really small array
and grow very small in small increments
but in a larger system you may allocate
your a larger and then grow in larger
increments and if your application is
going to be running on different devices
that have different capabilities you
want to keep that flexibility so you
don't have to rewrite your application
for each different device so next we're
going to talk about efficiency when you
do profiling you're going to see that
there are some objects that are used a
lot in your system in a regular Java
desktop or server application for
example strings or an object that are
often used and these are what we call
high volume data objects because you see
a lot of them instantiated within the
system every time you create one of
those classes it takes CPU cycles to do
that and it takes memory depending on
how many fields you have in that class
itself and how they're set up so you
want to keep your declarations in your
fields to a minimum if possible if you
have a field especially a high-volume
class with with a lot of fields in it
let's say that you have a class with ten
strings but those ten strings aren't
used very often one thing you can do is
to create a hash table instead and then
when you need ten strings you allocate
ten strings storm in the hash table use
them and then when you're done delete
them out of the hash table and you get
that reduction of memory back again
another thing you need to keep a look at
is keeping your stack frame small this
is especially important when you do
recursive methods and recursive calls
and especially if you're in a
multi-threaded environment also because
every fret thread that you create also
consume CPU cycles and member
moving on with efficiency you want to
keep your class files compact we talked
a little bit about reducing the number
of fields that you use so you want to
eliminate those extra fields if possible
you want to use the smallest types
possible so if you're using a long
consider using an instead if you're
using an ink consider using a short
instead use object pointers instead of
inner classes so basically every when
that class gets constructed the inner
class insider also gets constructed and
what you want to do is take that intern
class out and put it into a separate
class that is only constructed when you
need it
more on efficiency you of course want to
eliminate unused features sometimes
you'll inherit code maybe if your work
on a platform again or even an
application you'll inherit some legacy
code that you find that no longer is
being used or maybe could be rewritten
in a more efficient way well if it's not
used then go back and get rid of the
code embedded devices we also have to
worry not only about memory and CPU but
we have to worry about power certainly
in the case of cell phones we have
limited battery power a lot of the
devices that were working it with our
low consumption devices so we need to
take a look at how we can conserve power
usage as well one of the things that we
need to do is we need to avoid idle
tasks and basically things that are
going to prevent the CPU from going to
sleep and certainly in the case of
battery-powered devices conserve that
energy so things like idle tasks that
keep the CPU going and don't allow it to
go to sleep polling that again will keep
the CPU going or if it's doing heavy
polling then you're going to be
consuming more power and more resources
blocking on asynchronous events all
these things are going to keep the CPU
going and you want to be able to provide
some time for the CPU to sleep and for
you to conserve that power on the device
also don't assume when you're writing
application that you're going to be
running on multiple cores because again
if your application is going to be used
on different devices some of those are
going to be multi-core and some of them
aren't and if you've written assuming
multiple cores you're going to probably
take up a lot of CPU cycles and maybe
threads and on a single core device
you're going to be starving the system
that may need those CPU cycles for other
things
Hank Minh mentioned that s he has the
serial garbage collector and the
parallel garbage collector in it the
main difference between these two is the
parallel garbage collector uses multiple
threads for better performance in almost
all cases on an embedded device you're
going to want to use the serial garbage
collector in either case we you want to
tune the garbage collector to suit your
needs and profiling is going to be
important here there are a lot of
options for tuning on both the serial
and parallel garbage collectors I've
provided a URL at the bottom for a
document that describes a lot of these
tuning parameters so I recommend if
you're dealing with the GC that you take
a look at that Pinkman is going to show
us a demo of using profiling and this
the profiler is probably going to be one
of your best friends what you want to do
is take your application in the use case
that you're going to be using it on the
device that is going to be deployed on
and put it through its paces through the
application use cases this will give you
information on how much memory you're
using which objects or high use objects
ones that you want to take a look at so
you can shrink them down as much as
possible how much memory is being used
what the garbage collector is doing the
heap pretty much everything so if you've
written your application so that you can
tune these caches and the array sizes
and a lot of the other capabilities then
you can go in and see how your
application is performing using the
profiling tools tweak those parameters
change those not dials and knobs and
increase the performance of your
application so for managing limited
memory you really don't want to use
static initializers of possible statics
get they don't get garbage collected
until the class loader that loaded the
class gets garbage collected so they're
going to stick around for a long time so
try and stay away from those use lazy
memory allocation if possible as we
talked
earlier you also have to worry about
persistent footprint sighs how much of
your application when it's stored on the
device itself how much of that storage
is being used because you might be using
a limited amount of ROM or a small SD
card or something like that so you can
take a look at your application and get
rid of features that you're not using if
you're building something that's only
going to be used in the US then you only
need a small set of locales you may only
need one or two or a few languages
instead of a bunch of languages all
that's going to save you footprint again
you want to limit the use of threads
those costs CPU cycles and memory you
want to reduce your resources if you
have message properties images you know
you can shrink the image size you can
reduce the quality of the image all
those things will help you with
persistent footprint so as embedded
developers we need to really question
every footprint increase is this feature
needed can it be removed can it be made
build time optional is it something that
we can just completely get rid of if not
can it be made runtime optionals it's
something that we can delay its use
until only when it's needed can we make
it tunable so it's easy to port our
application on two different devices
with with different capabilities and how
can we make it more memory efficient
without sacrificing too much performance
so I'm going to turn it back over to
Hank Minh
thanks Darrell so Darrell went over the
best practices where should you apply
these best practices and again we talked
about those embedded devices as fixed
assets the fixed location assets like
medical equipment network routers
multifunction printers and the common
characteristic is they have smaller
amounts of memory and lower powered CPUs
and in the best case the best practice
use cases that Dara went over address
why it's important to do those type of
techniques those programming techniques
normally nowadays they're wirelessly
networked these devices might be like
the Amazon Kindle where they piggyback
on top of the sprint 3g network they
call it they rename it whispernet but
actually is just the unused broadband
spectrum of the sprint 3g network and
that allows a nice communication
machine-to-machine between the Kindles
and the back-end data server at amazon
so that it can do things like software
updates and update your your book lists
and and where you are in certain ebooks
as you're reading them that type of
communication is necessary so that the
the headquarters and enterprises can
keep track of all the metrics that it
uses for all these network embedded
devices nowadays just having a
standalone embedded device with no
networking is not very interesting
without that big data that you can
collect from it also the screens that
you find on these embedded devices are
either going to be headless no screen at
all or very small LCD panels like on a
multi-function printer where you're just
hitting some buttons to output your
print job then there's also the input is
very limited it's either got a touch
screen like on the multifunction
printers where you're choosing very
limited amounts of text to enter and
certain menus to choose or it's a keypad
where it's just a simple alphanumeric
keypad that won't let you do a full
qwerty style touch typing on
and now let's let's move over to a demo
and in the demo I'm going to switch to
my other computer here in this demo
we're going to show all the techniques
that Darryl was covering on this device
I'm going to hold it up as best I can
without messing it up this is a beagle
board and a beagle board has linux arm
on it the ARM chip is a arm be 6 800
megahertz chip so it's no work near the
3.7 gigahertz chips that you would find
on your desktop or even on a laptop
computer and it's a single core it's got
the 256 megabytes of RAM on it and I
have it connected with a serial cable to
my computer so this is the typical type
of device we're talking about linux arm
and you might have been in the previous
session where they were armed was
talking about the raspberry pi that is a
totally different device in the
beagleboard especially because it's only
thirty-five dollars so if you have a
chance to buy the Raspberry Pi go out
and go ahead and get it because you can
run java java SE embedded on it and play
around with it it's just a really nice
price point these beagle boards are one
hundred ninety nine dollars but but they
do have networking capability it's the
same as the Raspberry Pi and it's just
more available right now so it's easier
to find and then I'm going to move over
to my laptop my laptop computer has
NetBeans running and this is one of the
advantages that I talked about it when
your program for java SE embedded it's
the full java SE spec so nothing special
this is just regular NetBeans 7 dot to
running and once you bring up a java SE
project just go ahead and start program
in the api's such as here you can see
it's the typical security api's that i'm
using and in my demo i'm going to go
ahead and do encryption and decryption
which is a common enterprise type of
activity since you want to hide your
data from prying eyes
either when you're storing it on disk or
when you're going to send it across the
internet you want to be able to encrypt
and decrypt and that's a common function
like I said but what are the best
practices to keep in mind it's exactly
what Darryl was pointing out watch to
watch that you're not caching too much
watch that how you're allocating your
memory make sure to use lazy style
allocation of those objects and in the
main of the application i'm doing i'm
just taking a source string hello this
is a test and then i'm going to start my
timer just to make sure the performance
is is right and then i'm going to do an
aes style if you know encryption this is
the the most current way of encrypting
and the best way of encrypting some data
using java SE the standard providers
that you get and i'm going to generate a
key i'm pointing this out because this
through experience is something that
you'll have to know about when you're
doing embedded programming and it's not
really something glaring like using too
much memory in a byte array allocation
this is something that you'll have to
know that behind behind the scenes under
the covers this generate key does a lot
of programming and processing using
chewing up your CPU possibly chewing up
your battery doing this generate key
step because everything that Darryl
talked about you can go off and look at
the other parts of your program that
you're responsible for like going ahead
and saying with the proper api's i'm
going to encrypt the string and then
doing cipher do final and that they
should rename that method because it
doesn't really tell you what you're
doing you're actually encrypting your
source string bytes there when you say
do final because it's in encrypt mode
right now that's your key is a knitted
to do that and then you do the opposite
here which is to decrypt it's in decrypt
mode just so that you can show the in
your system out print line what it looks
like before or what it looks like after
cryptid and then what it looks like
after it's decrypted and that's it
that's the demo and then I'm going to
check the performance time but of course
with all that in the demo there's got to
be something extra to it so what I'm
going to do is first run it on my
desktop and this is just a cygwin window
where I go off and and I've compiled
that program and ran it and it tells me
that the performance is 187 milliseconds
and I'll just run in a couple times just
to make sure I have an average 170 180 7
so I'm around a 100 80 milliseconds and
that's very fast so you wouldn't even
notice it go in and off and churning
away on my laptop and then coming back
and returning the encrypted string here
and that that's what I was talking about
is you want to hide your data but now
let's go over to the beagleboard and
just to show that this of course the
demo gods have required me to reboot
here okay so so just to show that this
is really a beagle board and nothing up
my sleeve it's rebooting because I seem
to have lost my power before but when
it's rebooting you can see it's got 256
megabytes of RAM its CPU is the omap CPU
which is Linux arm and I'm going to do a
song and dance as it's doing its reboot
it doesn't take very long to reboot just
has to go through all the memory running
through that and this is a great target
device to again you do your proof of
concept on this device and then it
represents Linux arm that's on something
like a network router or printer and
we're ready to go here so let me go
ahead and run that same program that I
developed and met NetBeans for java SE
asep now you can see that was 2.8
seconds so the assumption was hey it
runs fine on my laptop
it comes back in 180 milliseconds but
you could see a visual dividual type of
delay where it's getting uncomfortable
for the user to say hey I want to
encrypt this little string that says
hello test this is embedded encryption
and you can see it's doing it the same
same level of encryption using AES as
before but now the performance because
it's an ARM chip is 2.6 seconds and you
got to watch that that's something that
is performance that Darrell mentioned
that you're going to trade off because
you called aes which is a it's a higher
end type of encryption algorithm number
one so you're trading off that that
encryption level and especially this
call which as an embedded programmer
you're going to get more used to seeing
hey in this in the core libraries I know
this generate key on an ARM chip on
embedded device is going to take a long
time 2.7 seconds but on a on a desktop
desktop developers won't even notice a
blip on the screen of a hundred 80
milliseconds when when it's using an
intel chip so with that experience
you're going to be able to develop for
the embedded world better because you're
going to watch out for that in including
all the best practices that Darryl
talked about so any questions on that
I'm just pointing out that there's
non-obvious places in in terms of
library calls that you have to be aware
of also as a developer in embedded world
okay so I'm going to do a little bit of
profiling now where I'm I'm going to
also check to see what my memory is
being used because I in the program
itself I didn't see any place where I
was grabbing a huge amount of memory
right so there's no big arrays there's
no hash maps there's no soft references
nothing i'm just at most doing this
string so we you think well you know how
much memory is being used maybe you know
a couple a couple of kilobytes
right so if you go over to the
BeagleBoard and run the program again
I'm going to let it run and it takes
that 2.6 seconds this time to actually
execute and then it's still running with
everything it did with the encryption it
did and I'm going to put it in a
background and now using Linux i'm going
to do a PS and look for specifically
that job and it's got a PID or a process
ID in linux of 1918 and there's a trick
in linux if you cat / proc which
represents the process and that process
ID status / status like this cat / proc
/ product at the PID which is the
process ID / status you're going to get
profiling information and i'm going to
show you where to zero in on there's one
value in the status under linux it's
called vm RSS that's a resident stack
size and that size is what java is
taking up it includes java objects and
it also includes the native side if you
did and a native J&amp;amp;I called to malloc
something this is where it would show up
also but take a look it's 15 megabytes
so even though you would guess and you
know it's showing also some other peak
size 211 megabytes it could grow too
because it's got 256 megabytes of RAM on
this system but what's resident right
now in RAM is 15 megabytes and let's go
back to look at your main and all you're
doing is just the source string what's
happening is that this whole setup for
all the encryption is what in the
library is taking up that 15 megabytes
so not only do you have to be aware that
the processing is going to take 2.7
seconds but you have to be aware of your
libraries of what eats up a lot of
memory and in this case the key
generator get instance needs at least 15
megabytes well it's not all the 15
megabytes maybe 12
megabytes to do the encryption algorithm
so any questions about that again it's
just showing you non obvious places
where things are going to eat up memory
that that's significant when you're on a
256 megabytes Ram device it's taking up
15 megabytes so you got to watch out for
lots of areas and embedded development a
lot of people think oh it's a full java
SE spec i could just program willy-nilly
use any api is that i have on java
desktop no you have to be aware of your
memory you have to be aware of your
processing and that's what Darryl and I
are trying to show is follow the best
practices but also double-check your
work use your this method of cat / proc
and and you'll be ahead of the game
you'll be ahead of all other embedded
developers that might not be able to
make the switch from desktop programming
to embedded programming and so I'm going
to switch over back to the slides and
this will give you a chance now if
there's any questions about the demo if
there's any questions about the best
practices that Darryl talked about or if
there's any questions in general about
embedded java programming let us know
anybody have any questions yes
what is the best practice to hen handle
string manipulations I think that's for
you Darryl so what kind of manipulations
ok
yeah i mean i would say the lazy
initialization and and localize the
scope of them so that when you're done
using them they can be garbage collected
or probably to the biggest things and
then this gentleman also mentioned using
a linked list if if you're controlled
controlling all those thousands of
strings with a linked list you're going
to have more fine-grained control and
when you want to release the memory then
if you're using a hash map or some other
caching mechanism so that might be a
technique to also look at is using
linked lists to keep track of all those
strings
yeah exactly yep any other questions
comments yes
ok
okay the question is the different VMS
that were talked about the the different
sizes for a client vm the c1 vm and the
server vm where are they are they
different downloads no they're not
different downloads are all part of the
single jdk from oracle and what happens
is that in your JRE in a typical java SE
desktop JRE and jdk you can choose
during the runtime which of the VMS are
enabled but of course if they're if
they're enabled you can enable them
during runtime they're going to be there
whether you want them or not during run
time for our build we make it so that
there's only the client vm available so
we subset out one aspect or one feature
of the vm when you get a runtime for
embedded so even though it normally you
would get both we kind of watch out for
you for embedded to to make sure it's
upsetted down correctly any other
questions okay well that will be a
Darrell and I will be here after the
talk so if you want to come up and ask
more questions please let us know and
this concludes our talk thank you very
much and enjoy the rest of the
conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>