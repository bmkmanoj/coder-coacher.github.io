<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Real-World Performance - 11 - Aggregate | Coder Coacher - Coaching Coders</title><meta content="Real-World Performance - 11 - Aggregate - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Real-World Performance - 11 - Aggregate</b></h2><h5 class="post__date">2014-04-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/on_R2d8OoaM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the final sort of discipline associated
with the manipulation of data as a set
it would be to produce aggregates and
aggregated structures very often used
for querying for export in small data
Mart's or very often within the data
warehouse or for use in reporting and
those sort of things so the generation
of the aggregations usually involves
reading a large amount of data
potentially joining it to other
structures and then segmenting sorting
and grouping the data according to some
of the columns that we've defined this
process again takes CPU and can be
either done manually or we can use you
know core parallelism within the
database in multiple ways and I'm gonna
do it the same techniques I'm going to
run some races and we're going to bake
them all off the techniques against each
other and you know we're gonna run the
race and this one's a little bit more
interesting compared to the other one in
that you'll notice that the the way
things are running that the homegrown
parallelism hasn't actually done that
well you'll notice that the set-based
processing took about ten seconds
whereas an estimated time for the row by
row processing of about two and a half
hours and you'll notice by the time we
stopped the homegrown processing hadn't
really achieved much now this is one of
the challenges you have with trying to
code your own parallelism in very often
the startup costs and figuring out the
date ranges and all that sort of stuff
has a fixed overhead and so you have to
do a certain amount of work before and
the work can actually start in earnest
work in parallel so what we've learnt on
this one is to actually is play a little
bit of a delay such that what we do is
we if we rerun the race will actually
wait 25 seconds before the set-based
parallelism proves that solution starts
work and we'll let the others get to
work and you'll notice the homegrown
parallelism initially didn't do anything
and now it's starting to pull quite a
long way ahead and it's certainly we
haven't even started the set-based
parallel in because we kept him waiting
25 seconds and you can see that the
homegrown parallelism was way ahead of
the parallelism and the array processing
but look a separate processing is
starting to catch up and it looks like
it's almost tied nope but it still wins
even if you've given it a head start of
25 seconds to all the other techniques
so again it teaches you another lesson
about homegrown parallelism there's
usually quite high startup costs or
configuration costs the characteristics
of the system pretty much as I showed in
the other cases where the array and row
by row processing was just using a
single call the homegrown parallelism
very often using a lot more CPU and
getting the Machine a lot more busy than
the set-based techniques because it's
running effectively serial algorithms in
parallel rather than running parallel
algorithms which as you can see as soon
as they start they almost finish because
they're over and done with so we
aggregated a hundred and one million
rows and you can see it just happened so
quickly in ten seconds by the time it
was up to full speed it was time to
finish whereas the other techniques as a
homegrown parallelism it made the
Machine look busy but it was an
inefficient program running in parallel
and again that's the other big challenge
we face with people who effectively try
to convert serial programs into
multi-threaded parallel programs the
store not using good set based mechanics
or set based algorithms to execute the
code they're just using the inefficient
row-by-row stuff it's just happening in
parallel which means you're wasting a
lot of cpu and the other thing we tend
to see
that is against a high startup costs and
there's a fair chance that they're going
to contend with each other if this was
an operation that was updating common
tables you may find that this contention
in those tables or contention on the
indexes on those tables as you
manipulate them so you can see there are
challenges with trying to implement your
own parallelism so let's just have a
quick look at the code just to do that
and we'll be very quick through those
the row-by-row program if you want to
scroll through it you can see what it's
actually doing is we've written a whole
set of procedures that keep running
totals inside the PL sequel program and
incrementing counters as we go through
each key so the counting is being done
in it effectively in the application
code and this is potentially a
inefficient way but we tend to see
people doing this sort of thing
particularly if they're using
conventional inserts and they're
worrying about little datasets becoming
so big that they're going to cause
robach segments to explode and things
like that
so they actually break down the DML
components or the inserts into smaller
chunks and so by doing that they've
basically forced themselves into doing
running totals inside their programs
very often these are programs that have
been converted from old procedural code
that may have been working on flat files
and so the original versions of the
programs didn't even have the concept of
relational operators and set based
techniques in the language and so we've
just inherited all these old counters
and basically they've used use the
database to grab data and push it back I
can describe and there's not much to be
seen from basically the programming in
the array techniques again we using
array techniques to grab and push the
data away
we've been slightly different on the
homebrew programmer instead of using the
ORA hash well we have use the Ora hash
but we design we're sending the rows as
we send them back and we're pipelining
them through a table function to get the
parallelism through a table function so
that basically everything
can be computed as a series of streams
but really the one that's the most
interesting one the most important one
is to look at the simplicity of the
set-based solution which is basically an
insert of a query and some group base
where all the running totals are done
for you and some of these grouping
factions very often you need windowing
functions to segment the data in the
format that you need but again we're
pushing everything down into the core
parallel engine inside the database and
as you can see there's huge performance
gains again it's it's all in each case
we wrote less code it may be argued that
the code is harder to write but look at
the performance and let the performance
of the situation speak for itself we're
talking ten seconds versus two hours
this is a huge performance difference
and again a good engineer once they've
learned to exploit these set based
techniques and they see the performance
gains they can actually start to be
innovate business processes to run semi
real-time or much faster and get rid of
these ludicrous batch jobs that run for
six or seven hours every night and
become really quite stressful for many
people because if they fail in the
middle of the night they may never catch
up the following night and so again set
based techniques not only be are faster
in terms of performance using less
system resources and more efficient but
it makes your whole business process
more robust and less frightening and
takes the risk out of manipulating and
managing large data sets and it's really
a case of just understanding large data
sets take specialist programming
techniques and when applied effectively
they can perform just as well as small
data set problems it's a case of just
learning the right tools to do the right
job
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>