<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Deep Dive into Java Performance Analysis with Advanced Toolsets | Coder Coacher - Coaching Coders</title><meta content="A Deep Dive into Java Performance Analysis with Advanced Toolsets - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Deep Dive into Java Performance Analysis with Advanced Toolsets</b></h2><h5 class="post__date">2013-02-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CskLWP_8JT8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi welcome to the Java performance
analysis with advance to set stock
we are from Z on Java engineering team
at Intel
my name is Santiago so anathan at
yarmulke and there is the fruit
participant who could not you know come
today is Vladimir Ivanov
we all work on Java performance analysis
for z1 platforms so before I begin the
talk here are some legal disclaimers and
here's some more
and finally an optimization notice so
what's the motivation so as we all know
modern hardware has features like
multiple cores per processor multiple
processors in a system there is a CPU
cache hierarchy with multiple levels for
example l1 l2 and the last level cache
to reduce the memory latency there are
cache coherency mechanisms and the
course support advanced instructions for
example 128 and 256 bit sim D arithmetic
instructions the SSE and AVX
instructions and also complex
instructions like a yes ni and digital
random number generator also the
software has grown in complexity there
are multiple threads and across multiple
threads there is data sharing going on
and there are synchronization and there
are various new software model that have
come up like virtualization and cloud so
with all this complexity in both
hardware and software
we need more advanced tools to do
performance analysis and tuning and to
identify the bottlenecks so there are
some standard performance analysis tools
that you could use for example you could
use a stack to see the Java stack or get
some clock deadlock detection you could
use j map to get the
keep them know about the object
histogram our could use the netbeans our
Eclipse profilers for identifying the
hot spots in your application if you
want to do more complex analysis tasks
like looking at the JVM Java and Java
native interface stack and heap or want
to do a basic hardware and software base
profiling or a combination thereof or
you want to look at your LLC cache
misses or where the memory locks are
happening or branch misprediction then
or you want to visualize or filter all
this data that you have collected there
are two tools two of the tools that can
do all this our Intel's v2 an amplifier
XE and Oracle's Solaris performance
analyzer so in today's talk I will
describe I'll give the introduction to
between amplifier XE and Alexei we'll
talk about the various real life
examples with different analysis types
and then half mil due to time
constraints will briefly touch on the
Oracle Solaris performance analyzer and
we'll take questions in the end after a
talk so we'll keep ten minutes at the
end of our talk
so intel vtune amplifier XE is available
as part of the parallel studio XE and
it's also available standalone it works
on Windows and Linux and supports both
x86 and x64 platforms the Java support
is a product feature in the amplifier XE
2013 and it has been recently released
so it is no more beta and it's
completely redesigned and has new
algorithms - dual overhead of data
collection so we tuned amplifier XE
supports to data collection types one is
Hardware event-based sampling and the
other one is user mode sampling they
have it even based sampling uses the
performance monitoring unit available in
the processor and it is very low
overhead sampling and you can do
lightweight hot spot detection using the
hardware pmu based sampling also you
could do advanced analysis for example
where are the LLC misses are occurring
or where is the branch misprediction or
where are the LOC instructions getting
executed using hardware even based
sampling so user mode sampling is time
based sampling basically the application
snapshot is taken at regular intervals
by default it is 10 millisecond and
using the snapshot the call stack is
analyzed and the hotspot is identified
and also the calcloud estimation is
so using VTL amplify lexi for your
application is very easy you can specify
your Java command line in the project
properties and after that you can press
the new analysis button at the top in
the toolbar and once you do that the
various analysis types available they
are shown in the left pane you can click
on any of the analysis type once you
click on an analysis type in the middle
pane a description of the analysis is
given it shows what that analysis does
and if it is a hardware even based
sampling and then it also shows what are
the hardware events that are collected
as part of this analysis and if there
are any more configurations that can be
done for this particular analysis type
those options are also given in the
middle pane which you can configure so
once you have done all this
configuration then you can start both
the data collection and your application
at the same time or if your application
has a warm of phase and you want to do
data collection only in the study state
then you can start the application and
do the data collection after a pause
this pause duration and the data
collection duration can also be
specified in the project properties if
you suppose you want to do data
collection on a remote server where you
don't want to take the traffic all user
interface so then on the lower right
hand side there is a button get come
online you can use that button to get
the amplifier XE command and using that
command you can do the data collection
on the remote server and bring the
results back to your notebook or desktop
where your
graphical user interfaces and then you
can look at the data you can filter it
and you can analyze it or graphically
view it so in this slide we are showing
the various analysis types that are
available and I'll briefly go over them
and Alexia will go over them in detail
so we already know about the lightweight
of hotspot which is the hardware even
based sampling and host the second one
is hotspot which is the user mode
sampling and then there are certain
preset analysis type using a combination
of hardware events provided for
different architecture for example for
Sandy Bridge architecture there is an
analysis type provided called bandwidth
so with this analysis you can see what
is your read and write memory bandwidth
you can see where your LLC misses are
occurring or where D ROM accesses are
happening then there is another analysis
type called access contention which
tells you about the memory where the
memory locks lock instructions are used
and there is another analysis type for
identify the branch enos of your program
and where ranch mr prediction are
occurring that's the branch analysis and
for high performance applications you
can use the loop analysis which will
give little or detailed information
about the loops
thank you sang yeah so now we come to
the most interesting part of this
presentation which is related to the
real examples and we are going to
analyze three examples the first one is
mixes tech test which is a simple java
application which also has a native C++
port and we are going to look how we are
going to show you the major capabilities
of into eternally fire when analysis of
mixes tech applications then we are
going to look at the real case example
which is Krypton received from spectrum
2008 benchmark and we will show how to
resolve resolve a real issue in real
application and then at the end we will
look at cash stress example and will try
to use one of the advanced techniques to
analyze where the problem comes from so
first of all we will try to compare
event based analysis and time based
analysis using the first mixes tech test
example
so generally sunder has already
mentioned how to run the analysis type
it's very simple but as a result of time
based analysis you will have the
following view which consists of three
different windows the first window
describes for function hotness its you
know general view for most of profilers
then it will show a call stack per
function and the third one is a phred
timeline we're not going to talk about
friend line timeline because it's pretty
no typical view in many different tools
so in general you can see that function
hotness includes several columns the
first column represents you the function
name the second column shows its hotness
and they're actually sorted by the
hottest functions on the top and then
the the next column shows the module the
module represents you in which model is
which model the function belongs to for
example for Java methods you can see
that it's inside compiled Java code and
for native methods
Billo like inside GBM well you can see
that the model is Joanne they lo so
generally you can see both methods
native and Java here then they are going
to compare it to event based analysis so
Sangha has already mentioned that this
analysis are you know based on different
mechanisms of how data are collected
time based analysis is collected using
interruption process of your java
application in certain intervals of time
and when base analysis is based on
hardware events so generally even based
analysis is very simple to what we just
looked at time based analysis but it has
additional information like two
additional course instruction retired
and CPI ray and generally we are very
interested in this very powerful metric
CPI rate which actually represents if
they have any issues in our application
so generally it could represent any
issue in the application and so what is
CPI CPI is you know is a clock ticks per
instruction so generally modern CPUs
allowed to process you several
instructions for one clock tick and for
examples in the bridge system it allows
you to process up to four instructions
for clock tick that that's why the you
know best CPI you can get there is one
clock tick divided two for instruction
its dot 25 and in spin you know in
general case if you have sit at less
than one it's absolutely okay because
you have you can have some dependency in
your assembly code or maybe you have
some data dependency so generally we
usually consider CPI around one till two
is okay for you know for every
application
what if CPI is more than one then
generally it means one of two cases the
one case is that you use you use a lot
of low latency instructions like
multiplication in that case one
instruction could take many cycles to
execute and therefore you will see
you know pretty big CPI but that's not
you know very usual case usually if you
have a big CPI and you know that your
method does not you like like a lot of
multiplication instructions then usually
it means some problem in your
application it could be hardware
problems it could be synchronization
problems anything so generally when you
do an analogy one based on Alice you
always look at CPI rate and if it's more
than two it's probably subject to look
at this function more tangibly so
generally getting back to the major
capabilities of intel vtune amplifier
I'm going to show you a mixer stack for
a particular function and generally you
can see that on the top of the stack you
amplifier results resolved jovian frames
generally you can see what functions
have been called in G DM to do that you
need to provide the backing for for this
DM that amplifier could you solve them
then you see that they're coming mixes
tech tests Java frames and then met by a
green arrow you can see the native stack
frame it means that amplifiers show you
both Java and native frames inside so
generally if you have mixes take
application you see both frames and this
is kind of unique feature because now
you don't need several tools to analyze
your you know java application which has
native part you just need to have one
tool which allows you to do you know
both analysis and the problem could be
for example performance problem could be
all in native part either in native pipe
or in java part so the additional
capability which is actually pretty
typical for performance analysis tools
is the ability to look at source line
code and assembly code and generally you
have information here which line of code
has taken most of the time for execution
and the same for assembly okay so what
is the difference between time based
analysis and even based analysis and the
difference there are not too many
difference first
we all provide function hotness then the
old both provide cools tech support and
event based analysis is actually stated
as a lightweight provide analysis it
means that it doesn't take too much work
to execute button generally if you you
know set of like to collect call stacks
then it would behave the same way is
time based analysis with the same
overhead then they also provide threads
timeline source and assembly and the
main difference between event based
analysis and time based analysis is
support of CPU events one could ask why
should I care why should I you know use
CPU events I don't even know you know
any CP events I've just hold a cup about
a couple of them like last level cache
miss events and so on so let's go deeper
and look at the second example of why I
should use CPU you know event based
analysis so generally we are going to
consider eclipta workload this is a real
work quote from critter from spectrum mm
bitch mark which does series of
encryption and decryption operations
with specially configured GDK to use a
native crypto library called MSS and
this native crypto library can be used
and the Oracle Java we so called pixie
SLO and crypto provider you can see the
link here which shows you you know some
became how to use that we for a call
Java and it also provides you some you
know some performance benefits on linux
including you know possibility to use as
an instruction so generally here is my
you know favorite but it's ask ability
testing of cryptic RSA workload on 16
cores 2 sockets and bridge system and
you can see that the real data show
about 20% less performance then the you
know ideal case we expect here so
generally we have some some problem and
we need to understand where this problem
comes from ok so then let's use
time-based analysis which provides us
with a function focus
and we can see here that the profile of
execution of crypt RSA is pretty good so
we don't see any specific problems here
we see that you know the hottest methods
are inside this native crypto library
and we don't see any specific problems
so generally time wisdom and analysis
doesn't tell us what is going wrong but
now let's look at if the event based
analysis
they've been based analysis already
mentioned provides you with additional a
very powerful metric called CPI clocks
ticks per instruction and you see that
one of the hottest methods there is MP
copy which has CPI equals to 14 it means
that for one instruction execution of
one instruction takes about 14 clock
ticks it's not typical it's definitely
says about some problem in our
application and we are going to source
code and assembly and look at the code
of dysfunction and we see that there is
a increment of some global variable in
general this is a you know template
problem which actually says that it's
true sharing problem when we increment
the same memory address from 0 course or
even worse from you know several sockets
and it could result in you know
exhaustive synchronization problems of
your data cache and generally if you
look at the assembly the most of the
time we spent on increment instruction
so generally it confirms my idea I'm not
going to talk about you know how to
solve that in general you should move MP
copies to to be a thread local and in
that case you avoid this problem with
truculent problems
so in general we just look the fixed
version of this benchmark run and we see
that MP copy now has CPI less in ten
times so generally we fix the problem
and see pair went down 10 times at the
same time score went up about 10% so you
can see that we use just a couple of
steps to identify you know not a trivial
problem one can ask me but you how
you yeah you saw a big CP and you just
found the problem by a source codes
coming it's not a general way how to
find such a complex problems right yeah
I agree
and then let's go deeper and look at the
next example where we are going to look
at you know some advanced analysis
capabilities here so we are going to
consider so-called iterator example the
iterator example is a simple java
application which has a list inside list
consists of list entries and each Lantry
list entry refers to the next list entry
and so on and this simple application
does of zero runs over the list entries
and reads some will you inside them
compares to a golden value until it
finds one so generally our application
goes through a list and rest a lot of a
lot of times and this is a very you know
general programming model because the
same model is used in for example hash
tables so generally this workload should
be representative okay so we look at we
try to measure the average one list
entry access time and we see the
following that up to 20,000 elements of
our list we observe about Oh point 25
nanoseconds of one least three list
entry access time but starting from
20,000 elements the one list entry
access time grows up significant like
after 40 thousand elements we observe
about six times more you know one list
entry access time about 1.5 nanoseconds
what doesn't mean to us so it means that
we start no experiencing some problem
and we actually don't know what problem
exactly so generally we want to try
event based analysis and then based on
Alice's showed that for the major
iteration function list iterate iterate
it we have CPI equal to 7 7 is too much
we execute one instruction
for seven clock ticks it's too much so
generally we want to look at this
function just realize that the code scan
should show that there are no you know
template promise inside the court so you
didn't fight any truth sharing problems
or any no synchronization so what can
you do else what can you loop so here we
try to present you a very powerful
approach this approach is called
top-down approach it was you know a very
you know big step for amplifier team to
introduce this approach in into it you
know play fire because it allows you to
identify in which component exactly you
have the problem just realize that CPU
modern CPU consists of several
components the first component I would
say about is front-end front delt is
responsible for instruction decoding
then the next component is back and the
count is mainly responsible for getting
data to execution unit for example it
could be loading data from cache to
register so from memory to register so
generally this is back end and then
execution unit itself so the top-down
approach allows you to end and enter fie
in what exactly area you have you know
your application have problem problems
so generally it could be from 10 bound
problems became Brown problems or bad
speculation front end bound problems are
usually caused by some instruction cache
misses a TLB misses and so on beckon
bound problems can be caused by some
detail be misses data cache misses and
some other events and there is you see
the read of pet speculation modern CPU
allowed to you know execute some number
of code ahead of you know the execution
process and in case of for example some
branch was not taken this execution
results are dropped and that causes
speculation problems so generally into
the tuned amplifier has an analysis
called general exploration the
exactly implementation of this top-down
approach and I'm going to show you the
results of this analysis for our
particular iteration iterator example so
generally you see the you know the top
function here iterate it which has CPI
about 6.5 and you see here that draw
following four blocks they are retired
by plants Lots cancel pipeline slots but
can bound slots and front end muscles in
general this is this these four blocks
describe exactly the same stuff what
I've just talked about with top-down
approach they describe in which
component you have problem in in
generally you can see that you can see
that retired pipeline fluids is actually
as bigger this number is is better
because retired retiring instruction
means that execution best okay if you
have this value around 1 then it you
know the perfect case in case you have
canceled by placements that it means
usually some speculation problems but in
general we don't see a lot of
speculation problems inside you know
general some typical application and
then draw come in to most frequently
made problems it's become bound stalls
and front end bound stalls and in this
particular example we see that we have
you know became bound problems because
we have mostly 95% of all stalls coming
to from the cam back end it means that
we have some you know maybe some memory
problems so probably some cash problems
anything can be there so generally to
understand where we have these problems
from we tuned amplifier team integrated
a special support
you can click on the you know double
arrow icon here and you will have
expanded into a number of events on the
bottom of this slide and you see that
the RAI events like last loCash missus
detail be missus and a lot of father
events so generally in to attune
amplifier provided you with predefined
number of events which can contribute in
to the bad performance of your
application if it's become bound and in
generally we are lucky enough to see
that our applications has close to 100%
percent of last loCash misses
so generally it means that we are most
likely out of last level cache our work
set sizes too big and it doesn't fit
last low last location so and every time
we access a new list entry we get a new
you know last local cache miss generally
we work with memory directly so what
does it mean for us such approach it's a
bit different level about all
abstraction there is a comment you know
common sense so generally it's not it's
not needed right now to know all events
which are going to analyze currently
it's a bit different level of structure
you just need to know the component
where most of your problems come from if
its back-end then there could be some
cache misses or something else or you
can have just exhaustive synchronization
and it also will be reflected by some
hardware counter and you can consider
this approach is a feedback of hardware
to you software application that it has
certain problems in general I would try
my application using these two and try
to understand what problems exactly I
have in my application and try to update
it and to avoid you know well most of
the people don't know
about you know some specific events
therefore if you drag your mouse cursor
over some event then it will have a hint
what exactly this event means it means
that if you use this approach and you
found that for example you have a lot of
last level cache misses and you don't
know what this event means means then
you can you know get a hint from
intuition amplifier which says that you
have you know last level cache misses
and it would probably it could probably
propose why this could happen in your
application for certain areas for
example for contest contestants accesses
it provides information that it's mostly
probably caused by exhaustive
synchronization and you should look at
synchronization problem of your
application the same applies the same
hints applied to for example back-end
problems you can see that it's
represented as a you know as a hint
phobic an back and bound pipeline
so generally hints also contain formulas
of how these events are calculated but
you don't need to care about it you just
need to find where your problem is and
then try to solve it by changes changing
something in your application okay so
coming back to our example we see that
starting from 20,000 list elements we
start observing a group of last level
cache misses and starting from 40,000
elements we observe about 100 percent of
long last level cache misses so
generally we are out of last level cache
and every time we access a new list
entry we get a cache miss and that's
what happens here and you know there is
no like general solution but the
proposal here can be just to decrease
work set to decrease the size of your
hash table or list entry and make you
know more iterations to do that to
process some data
okay so there are still certain
limitations inside amplifier Java is a
new feature it has just been released as
a you know officially supported feature
of into eternal afire
so most of advanced capabilities of
amplifier now available for Java but we
still have certain certain limitations
like the source line map and can be
inaccurate because optimising JIT
compiler could move you know could not
trees provide us with accurate
information about mapping from IP
address to bytecode index to identify
which Java code line we should you know
map to there is still no resolution for
interpreted frames so in general if you
have interpreted Java frame which is
still interpreted not compiled then you
will probably see that it's simply
interpreted frame to work around this
you just need to use minus X conversion
when you use hotspot or you can you know
do a little bit more warm up that more
methods could become quieter and we have
a plan to implement a dynamic page which
is very useful when you analyze a very
complex applications especially those
ones which require a lot of warmup time
and you know the complicity of starting
these applications is huge so for
analysis of such applications there
should be a dynamic attach mode ok
that's it about interview to
non-preferred C and we are going to look
through Oracle Solaris performance
analyzer main features and I will try to
mostly concentrate on comparison the
main Oracle Solaris performance analyzer
features two into which one amplifier to
simplify our talk today
so generally Oracle Solaris performance
analyzer is a part of Oracle Solaris 2
there it's
available mostly on Solaris but it's
also available on Linux with limited
support and it has so-called collector
and performance analyzer tools for
performance analyzers for performance
analysis and the Java supported
implemented for two analysis types for
claw profiling metrics and hardware
counter metrics you can compare it to
into which one amplifier looks alike
time based sampling can't event based
sampling so generally that's the same
and here is our example with exhaustive
last level cache last example I used in
intuition of Laphroaig see and you can
see that it also select phones on either
also has function hotness it reflects
you the hottest functions the function
name and how many time we spent in this
function it also reflects it also
supports code tree analysis so generally
you can see call through where your
function was called and particularly you
can observe a distribution of time spent
in in every function in this call stack
and generally it also has so called
statistical call graph which allows you
to see it's called coalesced Collies so
it allows you to see from which methods
this method was you know called from or
which methods which method called then
there is hardly a counter or low profile
this the same is even based sampling and
it's very close to what we've seen with
intuitive Nakhla fire and it's close to
what we see that with a time base the
time based sampling but it's different
because it doesn't for some reason it
doesn't have CPI inside so generally we
know proposed to use CPI is a one of the
major metrics when you are now as your
application but generally it's also
based on events and here is the last
slide about Solaris performance analyzer
so generally we want to analyze which
events are responsible for
you know for the problem of our
application for the performance problem
our application and in general Solaris
performance analyzer also allows you to
collect events like you see here that
for the you know main function elite
list iteration iterate it we observe we
collected last level cache miss events
and the whole life you know in these
functions in in general unfortunately it
doesn't have you know similar approach
is intuitive Nakhla fired us which is
called top-down approach but anyway you
can collect the events there right so we
have come to a summary and the summary
is the following we have observed today
the two advanced tool sets which are
intuitive amplifiers see ancillaries
performance analyzer they that target a
bit different operational system so
Solaris performance analyzer is mostly
targeted mostly targets Solaris but has
limited support of on Linux and into
which you know pre-fire mostly targets
Linux and windows so generally you need
to use you know that one the tool which
you need for your particular operational
system and most you know popular
operational systems are cover then these
tools provide you with more capabilities
analysis more powerful analysis
capabilities because they provide
hardware based information which is not
available in you know in typical tools
for analysis and in certain cases we
observed that many many problems cannot
be detected by you know typical tools
like when you observe a lot of cache
misses and a lot of such hardware
specific problems then result in like
scalability problems and you probably
know that if you you know solve some
scalability problems you can get really
huge performance gains like several in
several times so generally the tools
provide you with you know a lot of
capability capabilities of analysis
and the new platforms coming are already
addressed addressed by this tool so
generally you don't need to care about
if you how you are going to analyze some
some new problem or some new additional
feature in you know new CPU all these
problems are usually already addressed
in new versions of these tools and
generally you can you know give us
feedback of what would you like to see
in into which one amplifier XE and what
would would help you to analyze your
application and probably you know I can
provide this feedback to amplifier team
so here are a couple of links the links
to into with tuned amplifier oxy and
tutorials and documentation then there
is a link for 30-days evaluation version
so generally you can simply download it
and try to own your application then
there are also links to Oracle Solaris
studia product and Oracle Solaris
performance analyzer Docs
so generally generally everything is
available and I also talked about
top-down approach and I'd like to pay
your attention to this approach because
it's know it's a different abstraction
level you don't need to know mostly
anything about hardware else you just
need to find which component the problem
in your application come from and then
there will be you know a set of
predefined events which you have in for
every event you have you know a hint
what it means so generally it's very
simple to analyze application using this
tool right now questions
yes
now
I think that is in the recent 2013
version they have added support for
frames so you can say when the frame
begins and when the frame ends and then
on that you can do the analysis he is
introducing the latest version and there
are some videos how to use that yes
I'm sorry so generally it will work on
veto machine but only time based
analysis so generally it will not work
is a very basic analysis it's what what
is it is now so generally I know that
they you know try to address some
problems there but I don't think it will
you know event-based enough to walk over
virtual machine
that that was the question
yeah that was a comment yeah thank you
yes
so first of all look we look here so for
every minute we have average CPI inside
that method right
yes it's average but if you look then
into assembly no it's so see if you look
at the assembly then we can actually
find the distribution of instruction
without there right and in general you
should look most mostly into the
instruction which have most of you know
time spent in it and generally it means
that it has the highest GPA so generally
this time on on the right side in
assembly right CPU time it's it means
clock ticks in generally if you spend on
some instruction like move most of your
clock ticks it generally means that this
instruction took too much clock ticks to
execute and therefore it has you know
the biggest CPI so generally you need to
look at CPU time distribution
yeah but you can look at the you know
method coat and understand that you
don't have like multiplication
instructions you just have a lot of
moves and some simple instructions which
don't produce a lot of you know very big
CPA
yeah
yeah I mean yeah I understand what you
mean but in general this is you know a
statistic even waste analysis is that is
a statistical tool most likely if you
have some real problems inside that
method you have huge CPI and this method
will be most probably be hot it's you
know it's statistics
I think it's it's you know calculates
based on CPU frequency and how many
clock ticks we spent in this particular
method so generally it calculates the
time spent in this method because it's
based on events okay
yeah I think so it allows to you to
understand what is what was the average
frequency inside so generally I think it
yeah it takes into consideration okay
any other questions then thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>