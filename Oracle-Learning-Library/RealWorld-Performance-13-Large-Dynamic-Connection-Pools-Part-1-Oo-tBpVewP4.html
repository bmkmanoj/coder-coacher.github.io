<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Real-World Performance - 13 - Large Dynamic Connection Pools - Part 1 | Coder Coacher - Coaching Coders</title><meta content="Real-World Performance - 13 - Large Dynamic Connection Pools - Part 1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Real-World Performance - 13 - Large Dynamic Connection Pools - Part 1</b></h2><h5 class="post__date">2014-05-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Oo-tBpVewP4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">they were going to talk about connecting
to the database and how we choose to
connect to the database and in previous
YouTube videos we've shown how
developers might connect to the database
and how they would use cursors and
arrays and things like that but we're
going to do a topic that really should
be thought about from both the system
administrator and the system architect
and it's the number of connections that
we make to the database and how they
connect to the database of those
connections permanent or are they
dynamic and this is a topic that my
colleagues within the real world
performance group have been dealing with
for probably the best part of 20 years
and basically it's done wrong in many
cases and it's usually done wrong
because of over optimistic views of how
they think the database can just keep
them absorbing more and more connections
the reality of the situation is that
there's two things at stake here
one the database you cannot add infinite
number of connections to the database
and the second thing is the number of
connections that database should ideally
be static should be the same number all
the time
and unfortunately today's applications
tend to get built in middle tiers and
they tend to specify dynamic connection
pools very often it's a minimum number
and then a maximum number and there's
under people under this illusion that
basically the application servers will
keep on creating connections as required
and then potentially cut them back hit
the load goes off well in fact this is
actually the worst thing possible to do
in fact one of my colleagues Hawkes
often divides this sort of architecture
as a gun ready to go off and if you have
the potential to rapidly create a large
number of
actions we have the ability to basically
destabilize the entire database
environment and for this reason itself
we've actually got quite tired of
talking to people about this and for
this reason we've built demos and we've
bought built graphical screens to
actually show what happens when the load
comes on a system so to demonstrate the
the challenges associated with both a
large connection pool in a dynamic
connection pool what we're going to do
is we're going to simulate the load
coming on a system in slow motion so we
can actually watch an interrogator
system as the load comes up the reason
being for that is if we see it in slow
motion we can actually see what is
happening and watch your system fall
apart in front of you rather than it all
happening in two seconds
and the system just falling over and
everyone curious as to what has happened
and this is becomes particularly
important to understand what is
happening and how quickly these things
can run out of control so we're back
using the real world performance demo
screens and you'll notice we have
basically three windows down the middle
which is reporting what we're doing now
we have a very stable system here
running at this point in time you can
notice that the response time from the
applications is two milliseconds we're
running a quite a modest transaction
rate of just under two thousand
transactions a second but let's talk
about what our user community is doing
what we actually have is nearly 15,000
individual Java threads all playing
effectively cards online and they're
basically pressing the button each
thread once every 10 seconds what we've
done is we've created a connection pool
that can literally go out of control and
destabilize the system the initial
connection pool was 144 connections to
the database but we're getting there let
it grow to 6,000 connections to the
database when the load comes on now if
we look at the system at the moment you
can see we're barely recording anything
on the AWI report or ash reports the cpu
utilization is extremely low and the
other thing to notice is that even
though the utilization on the system is
extremely low we've already extended the
connection pool to over 200 connections
to the database up from 144 just because
the application servers occasionally
found that all their connections were
busy we allowed it to grow and with that
in mind I'm going to force it to grow
even more and we're going to watch the
system as we start to grow so I'm going
to start doubling up the workload so
instead of everyone pressing the button
every 10 seconds we're not going to make
it every 5 seconds and we'll double this
up and I'm going to continue doubling
this up until it gets quite interesting
and we actually start to make the system
yield at this point just doubling up the
workload you can see that there's just a
tiny increment in the workload the
transaction rate is doubling the
response type hasn't been impacting at
all we're starting to see a little bit
of a climb on the CPU utilization which
we can see we're barely even using seven
or eight percent of the system at this
point in time so let's double it up in
another step
and again here we go doubled up the
workload again and at this point in time
we can see very linear behavior on the
system we're seeing the transaction rate
literally double with each step we're
barely impacting the response time and
we're seeing the CPU getting a
proportional response coming up as the
workload comes up so at this point in
time people would start to think we
built a linear and a scalable system the
other thing to note is that we're
starting to see the connections the
database and the size of the connection
pool now it's now approaching nearly 500
okay so in really about 4 times bigger
and getting to five five times bigger
than the initial connection pool yet
we've hardly stretched the machine at
all so there's a lot of connections that
actually aren't actually even doing
anything in fact there's four hundred
and sixty five at this point in time
where we're actually not doing anything
at all we've only got 16 active and this
is on a machine here with actually 24
cores on so you can see we're not even
fully utilizing the machine in terms of
sessions per core at this point but you
can see again the connection count is
increasing just because you get
occasional timing glitches where of all
the 32 JVMs that we have driving this
application all the connections are busy
for one point in time and so it just
pops another connection so let's double
up the workload a little bit more and
then we should start getting into start
seeing load come onto the system a
little bit more seriously
so we're doubling it up now and we're
starting to push the transaction rate
much higher we're getting up into the
fifteen sixteen thousand transactions
per second thing to note here you
starting to see a much more noticeable
increase in the CPU on the system and
we're approaching at this point 25
percent utilization on this
but again nothing to see in the database
on the ash report not much to see it to
user response time now this is the point
in time work very often we see system
architects and administrators
congratulating each other because they
think wow we've built the scalable
system but it's only scaleable to twenty
five percent utilization of the database
sir but that's hardly the best
utilization of hardware resources
software licenses so let's double up
again and see where we get to when we
start hopefully now that we're going to
get to use 50 percent of the utilization
on the machine so we're doubling up
again and we can see again a very
immediate response the transaction rate
is doubling
we're seeing the CPU work workload
doubling and we're nearly at 50 percent
utilization on the system barely any
increase on the system response time
again a very stable system but the thing
to note now is we really are starting to
create a lot more connections to the
database because the middleware is now
getting to situation it's running at a
higher rate and the statistical chance
that all the connections used from one
JVM being in user is increasing all the
time so literally as I've been speaking
we're seeing the connections pop to over
nearly 2000 here we're at 1900 as I
spoke and before we were in the hundreds
and within a second or so I imagine
we're going to be greater than 2000
fairly quickly
but you can see quite quickly that you
know still at this point in time the
system is very predictable very linear
and everyone's seeming great and this is
at the point where we're about 50
percent utilization on the system now at
50 percent utilization on the system we
can see this is a point where our
statistical chance of getting scheduled
is 2 in 1 as I cranked up the
utilization on the system your chance of
getting scheduled immediately is
starting to get reduced if you starting
to not get scheduled all the time we
start going to start seeing more
variation in the response time
as the response time varies we're more
likely to have more application servers
waiting and they're more likely to
initiate more connections so you can see
as we crank up the utilization we get
more likely to basically get more
variable response time which is going to
force the app servers to throw more
connections at the database which in its
turn are going to get more and more
unpredictable response time and we're
going to get details into orders is
known as a race condition in this race
condition we very often call a
connection storm when basically we're
initiating a storm of connection
requests but we're actually getting
nothing back and remember which we
showed in previous youtubes that
actually logging on the database is
quite an expensive operation so this
just compounds this effect and we start
going into a spiral of degrading
performance so I'm going to not double
the performance at this point in time
because you can see it's been quite well
behaved we've got over 2,000 connections
to the database at this point but what
we're going to do is we're going to do
it in smaller increments so instead of
doubling it I'm just going to take it up
to 400 milliseconds so point four of a
second between each mouse click so some
fairly serious card players and we're
just going to jump the workload up a
little bit more and you can see that
basically suddenly the small increment
in work suddenly caused quite an impact
on the system okay
so almost like a 50% increase in the
workload we saw almost twice as much CPU
we see this a disproportional response
in the CPU utilization getting extremely
busy we're not seeing proportional
increase in the transaction rate and
we're now starting to see the
transaction rate starting to become
quite choppy and we're starting seeing
queuing in the middle tier we're seeing
extended database response times and for
the first time we're actually starting
to see wait events inside the database
through the ash reports and some of you
may have seen some of these the wait
events in your life before latches on
nq's row cache objects latch free NQ TX
index
engine buffer busy weights quite common
weight events as and well we get into
the situation where we're starting to
over subscribe the machine where the CPU
starting to get extremely busy and we're
starting to see more and more weight
events we're sewing to see the CPU get
busier and busier and you can see now
that the database connection for work
that was at 2000 is now approaching 6000
remember we have a limit here of 6000
144 so very quickly we're actually
getting to the situation where we're
approaching our connection limits and
you'll notice the number of active
connections on the database is massively
oversubscribed compared to the number of
cores on the system it's now telling me
I have six thousand active requests into
the database at this point in time as a
result you can actually see we've
completely over subscribed the machine
so the response time has gone out of
control the weight events inside the
database have gone completely out of
control just looking at that you can see
in qtx
index contention contention events and
the throughput has dropped right off and
in fact what we're starting to see is
the monitoring of the thing is starting
to become unpredictable and even fact
the CPU has dropped off because this
machine is now actually rendered itself
completely unstable and at this point in
time we've actually simulated a failure
in the system and then sometimes it
starts to recover and it's erratically
you can see the transaction sometimes
bounce back but effectively what we've
done is hang the system and try to use
the keyboard and things like this
becomes impossible so getting debugging
information out of such a system into
this state becomes next to impossible
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>