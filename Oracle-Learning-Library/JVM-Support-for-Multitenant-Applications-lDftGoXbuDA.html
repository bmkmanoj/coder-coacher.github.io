<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>JVM Support for Multitenant Applications | Coder Coacher - Coaching Coders</title><meta content="JVM Support for Multitenant Applications - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>JVM Support for Multitenant Applications</b></h2><h5 class="post__date">2013-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lDftGoXbuDA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Graham Johnson I work at IBM
on IBM's jab drill machine may refer to
it a few times as j9 and today we're
going to be talking about JVM support
that we've been working on for about the
last 18 months for building Multi multi
tenant applications in Java we always
get to start with the legal disclaimer
what you're about to hear is a
forward-looking talk so you know any of
the dates you see mentioned not carved
in stone but you know the talk is
accurate based on our best knowledge
today this is me free cookie I've been
building virtual machines for basically
my entire professional career I started
with a language called small talk back
in the early 90s and after building VMs
for other languages like PHP and working
on portability and a lot of the 50
billion should support my new day job is
making the JVM a better citizen and
cloud environments that includes things
like the multi-tenancy support that
we're going to be talking about today
and improving elasticity increasingly a
number of artifacts that we can share
between JVM instances and you know the
classic good vm stuff of footprint and
performance you should walk away with is
good understanding of what multi-tenancy
is what it's good for why I think it's
compelling some of the challenges about
building multi-tenant java applications
today and hopefully you get a good grasp
at some of the features that we're
working on today that we think it's
going to make make it easier to convert
existing applications into multi-tenant
deployments basically allow you to stack
more applications on the same piece of
hardware than you can today so here's
the plan for the next hour we're going
to level set hopefully get everybody a
baseline about what multi-tenancy is
what it's all about learn about some of
those challenges we're going to spend a
fair amount of time talking about
dealing with bad behavior so it's one
thing to get a multi-tenant application
working it's another thing to keep it
that way that requires good walls
between your tenants we're also going to
explore where the limits of density are
today
I've got few performance numbers that
are crushed in the lab to stake in the
ground things are going to change pretty
rapidly over the next year but this
should give you a pretty good peek at
what we've got as I say we've been
working on this for about 18 months with
a combined team of VM guys class library
guys and jit folks we've got a pretty
good comprehensive solution I think so
the basic premise simplifying the
software stack by removing all the
extraneous bits makes things simpler
when you remove stuff footprint goes
down complexity tends to go down as well
so simpler we can make it the cheap here
it is to run and deploy and my favorite
anecdote here is actually comes from my
living room where we started off with
you know the classic 5 remotes and my
first passage simplification which I
thought was great was the intergalactic
remote on the left from Logitech I
enjoyed the power but it gave me my boy
if my grandparents and the kids did not
enjoy that level of control and from an
operational perspective it required lots
of me time to actually have the
audio-video visual stuff working on a
reliable basis so to get beyond this I
had to kind of re-evaluate what i
thought was extraneous and what wasn't
extraneous that led us to iteration
number two which is a little apple TV on
the remote on the right-hand side
honestly I didn't think it would work
get the little pad two buttons seems
like you've gone a step too far you're
giving giving up a fair amount of power
there right the increase in customer
satisfaction as soon as I toss the other
one instant everybody's happy simpler
it's predictable it's actually cheaper
to produce which is important when your
four-year-old goes and dumps the remote
a cup of coffee its twenty bucks to get
a new one instead of not twenty bucks
requires a bit of hard engineering work
on my part right had to refactor some of
the whole media stuff around the house I
view that as an operational thing
biggest thing is probably shift in
mindset on my side to do
what was extraneous and what really
mattered so let's see if we can take
that it just works approach into the
data center second example you're
pragmatic programmer fan you hear about
single source of truth and you know make
sure that there's basically one piece of
machinery in your code that does a given
job right so you have a bug go one place
fix it seems obvious but for most of the
new grads that we get in first we have
to talk them down off of the complexity
sort of wall at you know the more
buttons and knobs that I can add to a
solution the better because I enjoy
doing that you hand this to an ops guy
and they don't appreciate your buttons
and knobs the second biggest thing we
have to teach new programmers is
actually a copy and paste isn't reuse
right you're just picking up code
duplicating it all over your code base
turns into a maintenance nightmare
although it's really really easy right
seems fast seems expedient so this one
hit home for me because I've seen the
problems that I consult and I played
with this day to day but then I look
down the hall into our labs and we
suffer badly from the copy and paste
problem you know we literally have an
army of clones sitting in the lab we
manage individually and you know the
techniques that you use in your data
center when you've got 20 machines don't
really scale that well to 200 or 2000 so
again simplicity reducing the number of
moving parts I think can have a big win
in some of the big software stacks so
thank you for bearing with me through
the anecdotes here's how I think
simplification and principle there
relates to multi-tenancy so instead of
having multiple copies of operating
systems app servers your apps deployed
into them a multi-tenant application
says let's have just one one application
we're going to look at the request is
coming from figure out which tenant
we're talking about and have one copy of
the OS one copy the app server to manage
one copy of the app if you want to be
really extreme about it you know one
copy of the database you know why is
this a good thing well
you've eliminated a bunch of parts parts
all costs footprint but by in addition
to you know the footprint which I as VM
guy appreciate you've also taken a lot
of operational complexity of the whole
story so now you look around at the
industry and these a lot of the
companies here are the examples that you
normally see you know salesforce com
probably the best example I know of a
stack that's been built for
multi-tenancy from day one and you know
that's great if you've got the
forethought to have done that other
folks have core metrics an IBM company
you know again built with multi-tenancy
in line and day one but for the rest of
us that didn't think about tenants ten
years ago what the heck do we do right
and that's why I'm calling out companies
like atlassian right this one's near and
dear to our heart so use a lot of it
Lassie until zinner development job
these are things that index your CVS
repositories and track your bugs and
there's wiki's and they got build
engines and if you'd asked me five years
ago is that the kind of tool that you
would buy in as a service model if the
answer will be no not a chance but if
you look at how they're running their
company today they've got this new
atlassian on demand and now the bulk of
their development effort and their sales
effort is going into and as a service
model in a pretty non-traditional way
right another example New Relic their
application performance monitoring
company we see a lot of them because
we're vm guys we care about performance
they care about performance again
another non traditional kind of tool or
normally you would set up profilers and
things like I tcam run them behind your
firewall and that's how you determine if
your servers and apps we're healthy or
not they've turned that on their head
just small little emitter that runs
inside the JVM all the heavy-lift
happens up at new rail new relic edwards
and as a user you're basically paying by
the month and deciding you know how big
your monthly bill is going to be and
that controls your service level so the
take-home here
is no there's a lot of existing software
out there and you know if you're driven
there are opportunities to take that and
bend it a little bit and turn it into an
as a service kind of world it's not easy
hard engineering work needs to be done
and I think there are actually some
things of the jvm can do to help with
this kind of transition excuse me my
voice is leaving me so let's talk about
software stacks there's a giant white
paper that accompanies this diagram and
I realize it's probably pretty hard to
read the important thing is that there
are a fair number of bubbles on the
chart at the bottom you have hardware
that's the dark box operating system is
close to it theory on top you of
middleware databases schemas inside the
database finally your application your
application instance riding at the very
top but I just described s0 and that's
the no sharing story if I have dedicated
hardware for everyone my deployment of a
new tenant when they knocked on the door
and says I'd like to sign up your
service means i go and acquire hardware
install operating system to stand up the
whole stack the great isolation i can
customize the heck out of it without
hurting anybody else but it's slow and
expensive alright s2 or the multi BM
stock you know it's basically where most
people gravitate today and really you
know it's a very similar picture the
only thing we've done is added a
hypervisor so now I have multiple
operating systems stacked up on a given
piece of hardware again the traditional
isolated database middleware stacks
applications writing at the top and you
know the good news here is that it's
easy right all of the tools you know
them up today all work here as well
other piece of good news is you can now
capture idle cycles so if one of those
stacks is idle and the other ones busy
you can scare up some compute resource
the bad news is that you now have paper
suddenly and noisy neighbors can cause
you problems so let's keep going
because each of those bubbles is
expensive right how BIG's an operating
system measuring gigabytes right every
application server instance also
gigabytes so let's keep trying to merge
some of those bubbles if I look at the
the s2 or multi stack picture the
difference here is we now have one
operating system and you know the
challenge is suddenly we've opened
ourselves up to resource collisions so
you can meet on the file system you can
meet on ports there is only one port
8080 on the box so these are usually
problems good Ops guys can deal with on
their own without too much developer
into intervention but you're starting to
have to spend money to move from the
left hand side of the slide over to the
right sure middleware harder still
because you know now you're not only
sharing an operating system you're
sharing application server instance as
well your neighbors are even closer and
today really the JVM doesn't give you
particularly good walls to protect one
application from another and that's what
we're going to talk about today as we
keep going so into PS 4 stacks and the
s5 stacks you notice that that purple
box writing at the top that says
multi-tenant application that's merged
together so at this point your code is
actually tend to wear and usually your
decision point there is whether you have
a separate database schema for every
tenant or if you go all the way and one
database schema and add tenant IDs to
all of your tables but again going from
the far left over to the far right the
further to the extreme of sharing you
get the more development effort is
required to get there the other
interesting point those you know removal
bubbles who's great right the real point
is that the customer can't see what's
behind the curtain so they don't care if
you're running out to fedex and getting
new hardware and setting it up as long
as you do it quickly and don't charge
them an arm and a leg every month what
the customer does care about is stuff
like cost right they're going to see the
we bill at the end of it and the smaller
ideas the happier they tend to be and if
it's low enough people are willing to
take a risk on a service they might not
believe in until they try it that's what
a lot of the APM guys are doing it's so
if it's like new my new relic it's free
to try for a while if you like it they
have you hooked you're paying a few
bucks a month time to value is always an
interesting challenge because it
traditional cycles say you know let's go
through a long sales process we'll
schedule up a project to actually get
the gear installed in your heavy labs
and the applications set up and running
usually measuring the amount of time in
months if you can bring people online
quickly and allow them to cry ideally
self-serve you know I think there's
actually some nice results to be had on
most companies bottom lines quality of
service is another interesting point
instead of people having to decide how
much infrastructure their IT teams are
capable of running they have they
replaced that decision with how big a
monthly bill am I willing to run and let
somebody else deal with setting up the
hardware making its scale and deal with
power and cooling it and you know not
all IT teams are created equal sometimes
there's big backlogs and getting stuff
done internally and oftentimes you know
it's easier just to pay that monthly
bill and be up and running in days or
weeks rather than months from the
provider viewpoint you know these guys
that are charging you know tens or
hundreds of dollars per month the
cheaper they can deliver that service
the happier they are it's money in the
bank for them right and by eliminating
parts so you know we took operating
system instances out we took application
server instances at at the extreme end
we had single database tables when
things change in those stacks and you
need to go and patch the operating
system it's a lot better to have one
than a thousand Sam deal with the app
server and database migration all kind
of stuff so although it's scarier in a
sense because you have a lot more
applications balanced on one point the
number of moving parts goes down the
operational costs if you're clever can
go down and let's keep the one so that
was the the million mile an hour
introduction to multi-tenancy and you
know you may not be ready to go and
convert your payroll applications to a
world like I described where you know
you're sharing database tables with your
competitor beside you but you know for a
certain class of application you know
typically stuff that's what up quickly
is maybe isn't going to last for a long
time doesn't have to have three or four
nines of availability you know the
multi-tenancy story is actually a pretty
good fit so we're basically at base camp
for the next maybe 20 minutes or so
we're going to climb to the top and
understand what you what you need to do
to Java and the JVM in order to deliver
really good multi-tenancy support so I
alluded to this a bit the biggest
reaction I usually get to be the start
of this talk is your trading off
isolation right I no longer have an
operating system prefer to protect me or
another process barrier to protect me
I'm suddenly in this big soup with other
applications and the answer there is yes
so it's the right choice for everything
no but I think on the JVM side I can
reduce the chance of a failure happening
you know we can already take a program
and have it run the same way on Hardware
ranging from the little raspberry PI's
you saw it at the giant mainframes don't
have to change the code at all so the BM
is doing a lot of magic all ready to
make that happy for you asking you to do
a little bit more seems reasonable the
impact of failure however is your
problem and the way we deal with that
today is all about choreography right so
if you've got a mission critical service
you probably don't have one app server
serving it you've got a load balancer in
the front you've probably got multiple
labs right that's choreography and
you're usually careful with your
right you understand how the machines
sit in the lab so you're going to avoid
same machine failure there's no point in
setting up a stack on the other side of
a hypervisors the hardware goes down the
whole thing disappears right so you know
about the same machine problems you know
the same rack problems you know about
same geography problems its standard IT
stuff that we're all doing today it
becomes even more important for
multi-tenancy the second big challenge
here though is cost of entry so again
most people are sitting at this sort of
multi vm stack where they use
traditional tools in conjunction with a
hypervisor the reason they do that is
it's easy your neighbors are relatively
far away the hypervisor are actually
pretty good at protecting one guest from
another and as soon as we get beyond
that and we start sharing operating
systems with other guys we've got sort
of these pork collision file system
collision security challenges but the vm
can actually start to help you in these
instances right so if I'm running two or
three app servers in a given operating
system a lot of the code there is
actually identical and the IBM JVM for
examples got a feature called shared
classes where we split every class into
Ram half that contains volatile
information and our own half the wrong
half is the same from vm to vm those
things can be shared dump them in shared
memory and you can recoup somewhere
between 60 and a hundred and thirty
megabytes of memory per vm so that's
pretty decent right if we keep going and
we start merging those those middleware
bubbles and the database bubbles we've
got a data isolation problem right ten a
day is in the same arena as ten it be we
need to do something in order to keep
them separate if tenant b is going to be
misbehaved and suck up all the
computational resources we need to erect
some walls so that can't happen and
again this is this is work the JVM is
doing today anyway to a degree asking
you to stretch a little bit and provide
some primitives to help here
isn't a giant leap so i'll be a vm guy
throwing stones at java for a slide when
I look at a JVM instance there's you
know there are some issues there that
aren't great stories compared to some
other languages java heat is a big
problem it's hundreds of megabytes of
memory most JVMs today aren't able to
share heap objects between JVMs so it's
all private space not advertised in any
way in order to keep that heap clean
you've got garbage collection threads
typically one of those four core depends
a little bit on how many quarters are in
the box but the GC is stealing time from
your application as it's trying to do
work in order to keep the heat plain
just-in-time compiler is another fairly
big source of both cpu burn and memory
burn consumes tens of Meg of memory just
for the code caches and metadata on its
own the code that we're generating again
private it's big and has an added bonus
it's really expensive to produce
compilation is hard work so again steals
time from your application and again
we've got lots of compilation threads
you know to sit around in your address
space and make it confusing to debug and
all that kind of stuff also bm's act
like silos today they're not aware of
each other so there's no choreography
going on at the JVM level that says JBL
jvm one is busy durbridge collecting and
using all the cores if i can defer the
GC activity and JVM be for a little bit
and let that finish that would be a
great decision right doesn't happen
today that's the other part of my job
but if we can improve the choreography
that goes on within the JVM there's an
opportunity to get some of those paws
times back under control make things a
lot more predictable in production
environments so what do we need to do
fixie the cost of entry problem first we
got to fix the state isolation problem
10 a day being able to see 10 mb second
we gotta fix the resource hog problem
and the additional constraint that i get
because IBM like probably a lot of you
we have a lot of software out there
already and we're not rewriting the
whole thing so i get to do that without
making any application changes at all so
let's talk a little bit about data
isolation where some of the challenges
comfortable typical pattern here that
causes some pain for multi-tenant
applications you can see the web server
lat annotation that's got some very
convenient syntactic sugar for things
like the servlet name and the URL
patterns that's great it's a as a
programmer you know I do like this it
makes life easier as an ops guy trying
to deploy the code that we built I like
it less because suddenly the class files
have configuration metadata embedded in
them and I either need to go and undo
that with more configuration files which
is always exciting or using tools like
DCI to rewrite the code which again Ops
guys don't tend to enjoy a lot because
they add another element of
unpredictability to the stack so you
could wean yourself off of these
challenge number two is a little harder
static variables so you know within the
heap if I give an instance of an object
out to a tenant and each tenant has
their own instance you know that those
two computations can run off and not
share any state and you know basically
complete happily right the problem
occurs when you start introducing static
variables into the world so this is a
bit of a contrived example I've got a
little locale settings class and I've
got some static finals declare instances
of those you know one for Canada one for
the UK USA and because I sit in Ottawa
the default locale
canada and it makes me happy but now
we've got a problem so when I got a
customer that sitting in the UK or in
the US and they would prefer to little
Cal to be different what do we do right
so we've got some options I guess we
could wrap the whole class in a class
loader and load up one per tenant which
is kind of a lousy solution because
again got to go to rewrite the code to
do that kind of stuff right get rid of
the static variables but again we've
broken the South shalt not rewrite all
your code rule or again we could do some
DCI to go and make every access to a
static variable in direct and you know
that actually works I know because we
went and did it as a first cut it tends
to be a little bit error prone because
there's some some statics in the class
libraries that you don't want isolate
and one of the other challenges bc is
when you get multiple DCI agents running
at the same time they don't always talk
this very well so you know as a
across-the-board kind of solution that's
one that we weren't terribly happy with
so when you're stumped with a hard
problem you do the normal thing and go
and read for a while and I have the
advantage of actually working on a
pretty cool product back in the 90s
early 2000s called visual age for java
it it was one of the first IDEs for java
it was actually all built in small talk
so it was one of the most ambitious all
talk project i ever worked on had a very
cool virtual machine that had both small
talk opcodes and java code zand mixed
language stacks so really fun however
for the guy trying to develop job
applications what they saw was a really
tiny footprint and blazing start up and
the reason they saw that is we shared
all of the code and we kept the data
separate and I show us a point out son
did similar work
round the Java language of a project
called Barcelona of sort of 2003-2006 so
you know there's lots of good references
to look back upon we did they just need
to be updated a little bit to work in
today's job environment and I had a
chuckle actually when I saw the hardware
requirements you need a massive 256
megabytes of RAM to run visual age and
this thing could actually run tens of
Java applications that much space so you
have the full IDE the full run time and
i'll probably 20 to 30 apps running
reasonably well in 256 meg which is a
number if I'm a cloud guy that's pretty
compelling right so how are we going to
get there I had to make one change so
the one change I I'm going to force
people to do is a saint had a single
argument to their JVM command lines so
this is a fairly major change you
probably don't want it by default so
enter xmt for multi-tenant your java
command lines that says yes i'd like to
opt out into multi-tenancy what you see
is your application behaves exactly as
if you have a dedicated JVM but in
reality runs side-by-side with other
applications and the reason we think
this is cool is smaller faster because
everything's in an address space we have
an opportunity to do some of that
choreography that I was talking about so
that you know GC activity on tonight eh
eh doesn't fear of Tempe we've
eliminated a lot of duplication so we
have one garbage collector one jit the
heat objects are all in the same heap so
I now have an opportunity to share them
startup time because the vm is already
up pre-warmed the Jets had a crack at a
lot of the code that's important startup
time is blazing so how does this feel
you can actually read the text so the
Java xmtr one jar and you know this
feels just like a regular Java launch
would what happens when the vm comes up
a
is you actually don't run a full Java VM
in that process you run a little stub
that goes off and finds our Java demon
so the Java demon is literally like any
other demon process it hangs around this
is where all your shared state lives and
a large amount of the class library
that's common run to run we can scaffold
up once share between instances and
that's exactly what happens so Java d
has all the expense of shared state we
create a new little box inside javidi
for your tenant and pass control back
and you have yours if your own standard
in standard out standard air screens you
know because you launched a separate
process command line you have a target
for sending signals to so it really does
behave just like a regular job
application the interesting part comes
when you launch the second one and what
we do is the same series of steps we go
looking for the java demon oh hey it's
here this time so i don't have to do any
of the startup all i have to do is
inject the new tenant into it and we're
up and running I've got some performance
numbers later but on startup we're
seeing about 3x faster which isn't too
bad because from elasticity standpoint
you know the best idol application is
the one that's not running at all and if
you were just on the edge of being able
to take the applications down but the
Java startup time is killing you with
three times faster startup may make the
difference so that when your app is idle
completely you just shut it down kill it
and use a multi-tenant demon to get up
and running fast and you probably caught
me in the lie that I hadn't actually
fixed the data isolation problem yet I
just distracted you and described a
shared container so here's what we're
actually going to do about the data
isolation challenge we're going to add a
new annotation the language it's called
at tenet scope it's in my column IBM
tenant package which is what
for spread rectangle showing us here and
what we need to do to tell the virtual
machine that the default locale variable
should be stored for tenant is to drop
the town and scope annotation in front
of the variable that's it so at class
file load time the vm recognizes these
things that's a couple of bits and we've
added some path length to the the get
and foot static paths so that it does
the extra level of interaction for free
you know no b/ci involve none of that
stuff no naturally J&amp;amp;I works as well and
the end result is that every tenant now
has their own locale settings default
locale unfortunately what I've just
shown you is a code change right and a
year ago when we were standing up doing
this talk we said it's going to be
reasonable to have people go through and
mark up their code with our lovely new
annotation and we promptly got told the
answer was no so this year I have a
different answer this time tenant scope
markup gets out at automatically as
classes come in so every static field
gets it for free at load time and you
know this is okay because the JVM is
doing like Club verification anyway
right we're already traipsing through
all the byte codes having a look at the
fields making sure the types are
compatible so the extra little bit of
work that we have to do really is in the
noise are we leaving some sharing in the
table you know absolutely there's some
variables that don't need to be isolated
but you know as a first cut I'd say the
extra a little bit of sharing that we've
lost is worth it for not having to make
any application changes because I'm a
sneaky vm guy actually snuck in some
extra stuff because we're talking there
we've implemented a lot of this stuff
you know in the class library up in Java
decide you know almost like a
java.lang.class worked at a length
string you know it's basically a
primitive java class of the vm has
intimate knowledge of so we think we can
actually expose
a lot of the tenant infrastructure for
people that are trying to build no real
tenant aware applications we use it to
build something fully transparent like
the XMP support but we have a tenant
class that knows about data isolation
knows about resource management Scott
API for both of those things it has look
up so that you know when you're running
on a thread and get your current tenant
really really efficiently you can get
from an object to the tenant that owns
it really efficiently and it's it's a
fairly thin API so this is still in a
fairly heavy state of flux as we
implement features like XMP we notice
rough edges so we're evolving the API
and I think the timing here to do
something out of the JCP in kind of the
Java 9 time frame is excellent because
we found that quite often we find
ourselves classing you know blocks of
code to a tenant and say hey tenant
please run this piece of code that would
become a lot nicer syntactically with
some of the language features like
lambda that are coming so I think some
of the some of the work streams out
there are starting to merge in ways that
will make life easier for your average
programmer so this point we're done
right yep question
for using one vm how about perm john j 9
doesn't happen to have that problem but
yeah and i think the the hotspot guys
are on the path to doing that as well
it's a good question though actually
because ii in all seriousness i'm sure
we've made design decisions that are
tied tied in some way to the internals
of j9 and you know if we're going to
standardize this stuff for real we got
to have discussions to the other vm
vendors yeah so yep
yep
right yeah so can I guess the question
was can yep if their heap objects then
your objects get allocated in the tenant
that you're running it and i think i may
have the slide that answers your
question in like two slides so if i
haven't answer your question in two
slides stop me again because vm guys are
sneaky so protecting the innocent right
this basically just requires good walls
between the tenants and the closer your
neighbors get to you whether you're
sharing a process between multiple apps
today and a regular JVM or a
multi-tenant JVM well i'm trying to
build the better wall you can create the
more predictable paint set so the kind
of controls that i've got today our cpu
time the amount of heat pierre allowed
to consume you know number of threads
you're allowed to consume how much file
i/o you're allowed to do so your read
and write bandwidth how much socket i/o
you're allowed to and I'm sure they're
going to be more of these as time goes
on but this has been enough to do some
fairly interesting things and actually
one of the more interesting points that
we've run into is even if i don't use
any of the new fancy multi and it's
tough the tenant api is lightweight
enough that if i'm curious about the
behavior of a given piece of code all
I've got to do is create a tenant say
run this block of code inside the tenant
and then the resource management stuff
can tell me how much he pit use and how
much CPU it used so it's a you know as
you're developing it's a nice tool to be
able to understand the performance
ramifications of the code that you're
writing a little more about ergonomics
command line switches I wish I didn't
have to add switches but this is a new
concern so for things like CPU
throttling we have ranges we took the
inspiration from this from the AIX w par
stuff so we can in the first example
specify the minimum amount of CPU
that we want to give to a new tenant
maximum a CPU it's allowed to consume I
want to do just the maximum i can drop
the first number if I want to do things
like Network I oh I can do that existing
options though we map for free so people
are used to saying here's how much keep
your allowed to use we might as well
make it easy on people and just take
those options alien alias them to for
tenant things and yeah we're working on
the MX beans so you can see how much of
each resource for using we've kind of
got an open research question right now
as to whether we should take over the
default ambience that you're used to
using or grow a new set for tenant so
you know there's arguments on both side
of the fence and I don't have the answer
for you today I talked a little bit
about putting the teeth into throttling
here's the the basic story is there's an
existing jsr out there for resource
management it's jsr 284 it gives us a
good api to describe resources and how
much of them you're able to use and to
avoid reinventing wheels we just decided
to underpin with a JSR 284
implementation so tenants sit at the top
of the stack we've got a resource
management layer jsr 284 sits underneath
those and then you'll see that the
resources that i mentioned before like
cpu and memory etc inside our
implementation of jsr 284 however we
have two choices for providing the teeth
one is the JVM does the enforcement
choice number two is we ask the
operating system do the enforcement so
so far we've done linux see groups and
AIX workload managers I've got a
performance chart actually next it talks
a little bit about that so this is a
this is a graph of Fibonacci computation
a multi-threaded thing whose job it is
to go into CPU
and we've crank two tenants up in this
case and given them a thirty percent in
a sixty percent slice of the CPU
respectively and then we went and
measured how much they actually used and
the graph on the Left shows what happens
when we ask the operating system to do
the CPU throttling the graph on the
right shows what happens when we do jvm
sampling to control cpu usage and you
know you'll notice that we managed to
get the lines in the right order but
there's still a heck of a lot of jitter
on the the JVM supplied version and the
table at the top just shows you the the
running time of the two they're about
equivalent cost wise so I certainly like
the picture on the left a whole lot
better and the operating systems good at
this however the OS workload managers
really do not like working at the level
of a bunch of threads within a process
they much prefer to deal with processes
so we have some work to do with the OS
guys if we want to go to the go with the
answer on the left hand side if we can
clean up the jitter a little bit you
know we have a nice portable answer on
the right hand side already but you know
at the end of the day we can already
control resource consumption between 10
and a and B in a way that you can't do
with today's JVM it was three slides
here hopefully is the answer to your
your geek question so we've had a new
region based garbage collection
technology in the IBM's JDK for a while
it was designed for large big 64-bit
heaps and the way it works is by
subdividing the heap into a bunch of
fixed size regions and we do that so
that you can do more work in parallel
and don't have to traipse all over
memory in order to collect so again
we're in my cloud hat I looked at this
and said you know what that's almost a
perfect fit for what I'm going to trying
to do with tenants so if I can say hey
tenant here are a number of GC regions
you know enough to satisfy your minimum
allocation and you can come too
me and asked for a new region but I may
say no one you can't get it that gives
me a way of capping how much he
somebody's allowed to use and we've
tweaked the allocators so that when
you're running code in a given tenant so
the way this picture works is there's a
and a day which is blue 10mb which is
green they each have some number of
garbage collection regions when code is
running inside tenant one it will be
allocated into a blue region when code
is running antenna to it'll be allocated
into a green region and the two objects
two sets of objects are never allowed to
mix so objects are fully segregated yep
yeah and now one of the the the nasties
here is we have a fixed number of
regions it's just a implementation
detail right now so that I can't hand
you about less than a full region today
so it impacts the the minimum amount of
heat by can hand to a tenant but you
know so far it seems like a pretty good
model and actually it's going to be
important when it comes time to deal
with Miss behavior because you know
there are circumstances where you have
to take out a tenant you know it's being
badly behaved you want to go and shoot
that thing and one of the big problems
with thread stop is the vm is capable
going on unlocking monitors on a stack
but as soon as you've gone and broke and
monitors you basically corrupted all the
objects or talking about however the
advantage we got here is we know all the
objects are segregated and if the
tenants dying anyway you've sort of
you've minimized the splash damage right
it's going to occur within the JVM when
you do things like kill the other
another nice feature about segregated
objects is allows you to do things like
mapping quickly from an object back to
its own antenna right it's just an
address compare also GC read and write
barriers give us an opportunity to catch
people that are trying to point between
tenants at the source so you
particularly for class library
implementers that are working on that
shared piece there are situations where
you can wind up with a green object
point eight a blue object we want to
disallow that right now it runs across
all of them and the the region based GC
was always selecting the regions that
wanted to collect based on highest
chance of reward basically and it's got
a heuristic built into it that says this
is a fruitful region to collect them to
pay attention to that one and leave
these other ones that are less hot on
disk so we're just tilting that existing
decision to say look please pay
attention to the tenants that are
currently hot GC tuning is one of the
the areas where we got a lot of work to
do the next year I was I want to dig
that up and I'll fix the slides of your
uploaded I'm trying it was trying to get
to the white paper on balance GC so you
should probably be able to like a j9
balance GC and find the white paper yeah
right so the question is what does it
look like from the operating persistent
perspective and if the answer is you
have one instance of javidi which is the
shared demon and one instance of Java
for every tenant that's attached rude we
were typing java dash xmt that process
is still there still kicks around it
just happens to be really really small
because all the heavy lift is happening
over in Java d and that's the reason
we're doing beans so that you can snoop
around at what's going on inside the
cavity so out of the world questions
so the the question was how does this
apply to something like tom cat or jetty
or a typical application server and I
may have actually been the segue I was
looking forward to my next side will
skip this how dance can we go right
here's what we're actually working on
today so IBM's been doing a lightweight
server its websphere liberty profile you
know it's similar to a tom cat or a
jetty or something it's osgi base but
it's a small server what we're doing now
is running multiple Liberty instances
inside one process so one javidi lots of
Liberty instances so lots of Tomcats
running on one process you separate the
configuration information so you know
they all have their own port you got to
be a little careful about log
directories to make sure they're not
standing on each other but that's the
same problem you would have if you ran
multiple Tomcats on one operating system
it's instant it right what are we doing
about safety stronger walls between
tenants is our current to do we've got
the read and write barriers in and we're
now working on robust finalization and
cleaning up some of those entertainment
references that we don't want happening
we're looking at a different take on
quota enforcement actually so one of the
way jsr 284 would like you to deal with
over running your quota is to throw an
exception which isn't really the
friendliest thing that you could do to a
thread you know you might be better off
stalling it for a period of time and
then giving it another chance to run so
we're looking at different ways to to
deal with the overrun cases there may be
a little for a little more friendly a
lot of our focus right now is
performance so figuring out how to
measure density and quantifying what the
throughput tax is again we've added path
length to ever get input static right
and those things are used heavily and
logging framework stuff like that so
we're currently doing the JIT support
and I should have some throughput
numbers for you shortly and then
simplifying configuration for things
like those command lines about how much
of a given resource are you allowed to
use and you know I think we're at the
point where big applications are running
we're at the point where we really need
feedback right so we're as part of the
Java 8 beta program going to put some
drivers out on developerworks so people
can pick this stuff up and you know use
it in anger see how it works in their
environment I have thick skin so if you
don't like what you see please tell me
and we can try to try to fix some of
that stuff up and you know if that shows
promise I think doing something through
the JCP makes a lot of sense so
performance data that's the next thing
how we measure this is actually one of
the more fun little hacks who done
recently from our mainframe experience
we know that you can actually overcome
it on cpu but in a ratio of about 40 to
1 so a 140th slice of a cpu you can
actually get some useful work done on
memory is the tightest resource so the
way we measure this stuff is a tiny
little VirtualBox guest running Linux
one core 1 gig ram big advantage here is
you know it's really easy to control
really reproducible you can reboot it
get right back to the same state every
time and then what we do to make the
math easy as we just add applications
until that system starts to swap as soon
as you go in to swap we say hey you're
full more applications is better and
your per tenant cost is how much RAM is
in the Box divided by the number of
tenants were able to bring up so
everybody shares in two equally in the
operating system bills and that takes
care of the Java versus java d
accounting an odd sort of junk so far
we're seeing about 3x faster startup
which i think i said earlier and up to
about 5x the density so five times as
many applications on the same box which
is pretty compelling and of course i
pick the best number i've got and that's
that's for simple apps you know
stuff that's mostly using base libraries
as soon as you get into user defined
class loaders we've already instrumented
the JVM the yeah the bootstrap and EXT
and app loaders they know about tenants
user written class loaders like the ones
that are in osgi don't so you know
there's sharing we're leaving on the
table but you know for a 10 the numbers
you looking pretty good we're still
working the JIT support I don't have a
good throughput numbers for you yet but
you know we're already seeing numbers
like four megabytes per tenant the thing
that killed us in this particular i
should explain so performance chart on
the bottom more tenants is better so
longer bars are better untuned i got 19
slow application started i crank the
heat sizes way down i managed to get 51
packed onto the box and our multi tenant
stuff ran out of gas at 250 and I think
we have a path to make that number about
a 500 pretty easily by lifting some
internal region count limitations so for
a certain class of application the
numbers look pretty compelling in case I
made this seem easy there are details as
soon as you start to share heap objects
some of those things are special
particularly java.lang classes and
java.lang.string instances they have
monitors and you don't want 110 a day
interfering with tenant be from a
synchronization standpoint so we think
we have a solution there by allocating
monitors when they're contended
finalization again that's a shared
service there are lots of shared
services within the JVM but whenever
you've got one you're duty-bound to
protect the shared service in this case
that means fast mapping from object to
its owning tenant and the ability for
the finalizer to be able to recover from
a malicious denial of finalization
attack these tests are actually the most
fun to write you can sit down and write
misbehave Java code for a week or two at
a time it's awesome I'll do questions at
the end actually support for Jay and I
natives this one's hard so you've only
got one process
if you have multiple load library calls
and they're talking about different
libraries the operating systems not
going to let you all in two different
versions of lib food s oh so the
solution there is to run the jni natives
back in the launcher process remember
every tenant has its own dedicated
launcher process that's the place we can
send signals it's also the place where
it makes sense for on Jan I code the
problem here is path length and some
latency because the day and I path is
pretty performance critical but folks
folks like it will already do stuff like
this we have similar technology and j9
killing misbehaved tenants is hard again
we talked earlier about you know as you
unwind stacks and break monitors you're
effectively tossing the internal state
of every object you do that too but
again because we've segregated all the
objects we can make that as safe as it
can be class loaders we talked about a
little bit Barcelona actually had some
really good thinking in this area and
Eclipse has got a CD s adapter so this
is a piece of technology they notice how
to play nice with canines class sharing
so the thinking here is that once we've
made the decision that it's safe to
share the wrong portions of the class
there's a little bit of extra work
required to share the RAM course as well
we think that that'll save us about an
additional twenty five percent but it's
going to be a 20 kind of an activity and
then post-mortem debugging is really fun
because if anything goes wrong in Java d
all the information for all the tenants
is in there and you have choices about
either filtering what people are allowed
to see as you're generating the
artifacts or trying to cleanse the cores
after the fact so that's a fairly big
open question for us so thus far focus
has been zero application changes the
primitives we're building we think
you're going to be generally useful I
can make it fully transparent but the
same tools I use to build that we want
to expose to people building regular
multi-tenant applications as proper API
lot of this stuff is already
standardized so resource management sout
there
isolates throughout their tenants
coalfields we'd like to put out there
and we're already seeing some evolution
in the Java ecosystem right so we've got
ee8 se9 with multi-tenancy on the on the
slides you know maybe this is part of
the solution eclipselink you can pick up
today it's got some some sort of alpha
multi-tenant support and our beta
program should be March April next year
it's probably your first chance to try
this and in case you thought you got off
easy what should you be doing to your
code today performance tuning so you're
a better neighbor right so when you're
idle don't choose cycles that will just
make you a better neighbor in any case
and also prepare for over commits
remember we talked about orchestration
knowing the busy and idle cycles of your
applications can help you pack them
denser today by Li aligning the busy and
the idol gets get more out of your heart
so hopefully you believe at least some
of what I've said I think simplifying
and removing some pieces of the software
stack that are arguably extraneous and
maybe a bit of an extreme view to make
things simpler keeper to run and a whole
lot more dense than we can get today and
yeah we're going to trade some isolation
but we're going to get the footprint and
agility back out of it this is my last
one yeah so we can get to single-digit
megabytes hard work for me ideally easy
work for you guys and when that beta
comes out the thing that you can do post
to help us is just give us feedback less
how we're done
yeah actually so the question was do we
have plans to contribute any of this
stuff back to openjdk and the answer is
yeah definitely in order to do the
resource management pieces we've been
through most of the the native layers
where the class library touches the
operating system in order to insert
throttling and you know I think that's a
series of changes that are useful no
matter what right now we're been qing
them to make sure we haven't addressed
performance in any measurable way once
we're through that then you know
filtering them back in through OpenJDK
makes a lot of sense tenants cope stuff
again unintentionally I'm not trying to
be evil but I bet yo we've baked in a j9
is one or two to the way the API expect
so i think when we converge on a an api
we're really happy with having a
discussion with the hotspot guys makes a
lot of sense listen yep right so the
question was today we run our
applications under different user IDs
and how is that going to work in a
multi-tenant world and the answer is
that we actually create one instance of
java deeper user and that enables the
java d process to reach to all the
places that users allowed to reach do so
it's not like there's one java demon per
machine there's one java demon per user
that makes sense I don't I'll draw the
picture for ya
right so that the question was I what
I've shown today does every tenant have
to spawn its own Java process and the
answer is yes that it's a simplification
basically to allow you to type javed xmt
on the command line you know that
process you created when you type that
you know we're going to make it as small
as we can but you do get a new process
it actually happens to be really handy
because a lot of the our service folks
have tools that are built around send
the process that you're interested in a
signal and have it produce core files
and diagnostics and that kind of stuff
so having a first class operating system
thing that you can send that signal to
actually is pretty important
right
right
right yeah and I guess the I figured how
to restate the question i guess it was
you reality says we're actually going to
have to have multiple instances of an
application and how are we going to deal
with that from multi-tenancy and i guess
my answer is sort of twofold we've been
trying to make standing up ensembles of
infrastructure easier through things
like if you look at the pure app talks
they talk about virtual application
patterns where you describe things like
you know I want a load balancer on the
front and by default i want three
instances behind it and here's how
you're allowed to scale that thing up
and down I think that's part of the
machinery that we're going to want to
use to try to put the scaling decisions
into the middleware and the nice part
about multi-tenancy is that you know you
can probably bring up more instances
because the individual ones are cheaper
right they're not costing you gigabytes
or choc costing you single-digit
megabytes hopefully but I don't think
that the load balancers is tough the
world are going away question
great so that the question was how do
you solve the IO conflicts and my answer
is you know that's not one of the things
that we're trying to fix so if you have
a problem running multiple regular JVMs
in a single operating system you're
still going to have the same problem
with the multi-tenant version so meet
typically that means you need to
configure your app servers in the sort
of the configuration metadata so that
they're all writing into their own own
homes basically yeah so I guess the
question was if I was going to run in a
cluster what is the the layout of Java
and Java T's look like so that the
cardinality is basically 11 Java
instance per tenant and wow you can
configure how many javadi's you're
allowed to put into it I think again
we're going to want to teach the
deployment machinery what the policy is
you know we were going to have hard
limits of probably you know 200-300
tenants / process which actually is more
than most people are likely willing to
put into a given basket but yeah it's
basically that you know one Java to one
tenant it's today's answer bushnell with
that
right so the question was if Iran if I'm
using that sort of user isolation and
running I each Java as a different user
and i'm only running one of them will my
multi-tenancy buy me anything and the
answer is if you only got one no it's
not the right tool for that job it this
the sweet spot for this stuff is really
where you have lots of copies of
basically the same application and you
need them discard fast so that it's
actually a for a lot of batch workloads
it's almost an ideal fit where you know
you're going to wake up then do some
piece of java work and you want that
startup to happen as fast as you can and
it's going to be the same computation
time after time we see a lot of that in
the main print space actually question
cool
right yeah so the question is are you
targeting larger hardware and the answer
is yeah absolutely current
implementation for example is 64-bit
only it because you have that one big
shared shared region it really does
cater two large heaps and
yes
yep yeah so the question was now that
you're co-located have you thought about
shorter path links for vm to be on
communication and the answer is yeah
we're really really interested in that
stuff we see a lot of it today you know
we're looking at things like RDMA and
exposing verb api's directly up in the
Java layer so that you know you can
minimize the amount of copy and going on
it hasn't been the killer issue for the
multi-tenancy stuff yet you know you can
probably see that we're just trying to
get this stuff up in bootstrapped I
think there's huge opportunities when
you're all on the same heap you know
that you should be able to take that
path length way way down all right and
I'm happy to stick around so it's I'll
stay up here talking as long as you want
me to so what's the amount of heap we've
tested we've run this up to about 28
cake so far
yep so the question is uh I thought the
isolate API was was dead and the answer
is it's been quiet for a long time like
GSR 284 you know that that jazz are has
been around for quite a while it it
might have been an idea that was before
its time right because you look at some
of the cloud concerns and you know small
containers and being able to throttle
resources are pretty fashionable right
now so whether we can just reach back
and you know take what's there you know
it's sufficient do we want to shine it
up a little bit for you know that the
next generation of multi-tenancy support
yeah probably
yep so that the question was if I have
three different applications as possible
for them to live within the same Java
demon the answer is yes if you would run
them with the same JRE on disk then
you're free to share the same java d as
well so you know the things that are in
the EXT director would be visible to all
of them but if that's a restriction
you're happy to live with and great i
right right so the question was you told
me that you stole the x ms and x x MX
settings to be pertinent things what are
you going to do about the the java
d-demon as a whole and the answer is
we've actually got a config file of
options that get used by java d on
startup it's you know it's a regular
Java invocation behind the scenes so any
option that you know and love on the
standard JVM you can feed into the demon
and that's how you could cap and set
initial sizes presentable yeah yeah so
you can yeah you can define the resource
envelope that you want the Java d to run
it as well
right so that the question is that our
oldham is all the memory allocated in
Java di aggressively and the answer is
no we give you a minimum reservation we
allow you to grow up to your maximum but
you know it's sort of like overcommit we
basically about the system sort it out
up to the limit that javadi's allowed to
hold on to so we've set an individual
tenant you know can't get bigger than
this the java d you can't get bigger
than that but you know if you put more
work into it then the thing can hold you
can still blow it up
you think yep
right yeah so that the question was do
you do cpu Tracking's for charge back
and yeah so yeah so the way that we've
got that working today is that you can
check in on a tenant to see how it's
running you know as it's running and
that's what we want the beans for and at
the end of a run you've got sort of
aggregate usage stats for what that
tenants done and hinted at it earlier
but you know one of the things that
we're actually using it for is you can
create a tenant and you can say please
run this block of code inside the tenant
and you know the tenant dies at the last
line of your little program but it can
also give you resource data there in
that right so it's a very cheap way of
saying please help me understand what's
going on resource wise in this block of
code oh so the question is do we
optimize jetted code differently for
different tenants and the current answer
is no we're and we're just trying to get
the JIT support going at this point it
but it's an interesting question yeah I
think this is the beginning of you know
multi years of work right
yes the question is did you compare and
contrast your yourself with war attack
which is the other company doing
multi-tenant stuff and the answer is no
I didn't even know about them until I
saw they were a bronze sponsor but
they're on my list to go chat with cool
I've exhausted the supply of questions
so thank you for coming it's been fun to
show and tell and my contact info is on
the slides you know feel free to reach
out so you have questions comments
anything or thanks much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>