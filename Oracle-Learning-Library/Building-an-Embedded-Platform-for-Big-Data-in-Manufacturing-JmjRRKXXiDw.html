<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building an Embedded Platform for Big Data in Manufacturing | Coder Coacher - Coaching Coders</title><meta content="Building an Embedded Platform for Big Data in Manufacturing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building an Embedded Platform for Big Data in Manufacturing</b></h2><h5 class="post__date">2013-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JmjRRKXXiDw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so Who am I yes I'm run beard I'm a
principal sales consultant with the
worldwide Java sales group my specific
areas of interest are embedded small
footprint JVMs I work a lot with
industrial automation manufacturing
automotive type customers I try to
understand their problems the focus
areas and try to help build ecosystems
architectures which are based on Java so
that's my background I came over from
sun microsystems when arc like wired son
so I have that Java background and what
we're going to talk about today is big
data architectures and how to build an
embedded platform for big data in
manufacturing so I have my co co speaker
partner in crime at Olin who is from the
manufacturing domain and he has ton of
good stuff he wants to share with you
and that is going to be manufacturing
focused what I wanted to do was I wanted
to give you guys lay of the land in
terms of what is big data and not all of
us understand what is big data or we
care about big data so this is a code
which I found from the human face of Big
Data project which is essentially a
project by a photographer called Rix
mullen what Rick's mullen is trying to
do is he's trying to create these
humongous amounts of photographs which
essentially captures the essence of what
big data is because all of us it's like
that story where these seven blind men
get into a room and they're trying to
figure out what an elephant if somebody
touches the trunk and say so it's a
snake and somebody else touches the legs
and they so it's a tree somebody else
touches eyes and I know you get the
drift so essentially what we want to do
here in this session is kind of cut
through some of the fat some of the
myths and we want to basically give you
guys an overview of what we believe are
a traditional or non-traditional ways of
approaching big data to give you an
example of best analogy for big
it is essentially the whole planet
developing a digital nervous system it's
not about automotive it's not about
utilities it's not about manufacturing
it's about us humans pretty much
becoming digital sensors we have now at
least three or four devices on each of
us we are interacting with Facebook we
are tweeting about things the whole
social media side is is on us and we
also when we go to work we work with
desktop systems we work with back-end
system so big data is essentially a
collection of all of this this is it's a
snapshot of our life which is captured
in a digital sense traditionally the big
data was understood as something which
is not just relational data so you the
data so big that you and dis dis de
sperrit that you need different styles
of storage district different mechanisms
by which you can introspect analyze and
make decisions on those a typical
example of that is essentially sky study
which is done in Singapore and what they
found was they actually overlaid weather
patterns on GPS coordinates of cabs and
they found out that taxi drivers don't
necessarily pick up customers when it's
raining in Singapore and by the way of
guys who have actually been to sing up
it always rains in some part of singer
Brook is right on the equator so it's
that's that's what it is and the
frustrating thing about that was people
were getting delayed and they were not
getting cabs and what they did based on
this analytic was they found out that
the cab company had a bond for any
accidents which happens so the cab
drivers had to really pay for that and
essentially what they found out was this
was the reason why they were not picking
up passengers when it was raining
because chances of accidents are hired
so what they did was they because of
this they got that feedback they went to
the cab company and they waved the bond
and they saw a thirty percent increase
in their capacities in terms of cabs so
essentially what
big data big data is a convergence story
we talk about device to data center we
talk about edge devices is sort of the
tree know the tree leaves and we talked
about compute at the nodes we talk about
compute at the back end which is a data
center but essentially what we believe
is this whole big data architecture is
nothing but a convergence story between
a device and a data center it's a story
of mashups we as human beings we have
tremendous ability to interact with
different kinds of perceptive devices
beat our iPhones where we are using
multi-touch to talk to that device beat
our Twitter applications and we tweet
about things we are checking into
foursquare we're doing a bunch of stuff
and essentially the reality of that is
we have a device which does compute
which does something which brings value
to our common life and those devices
what they are doing is they're
essentially enabling us to do course
corrections so if we find out that we
have been tweeting a lot we have a bunch
of followers which are giving who are
giving us feedback about what we are
saying so if I am really not speaking
with something which makes sense i would
have blog posts and comments which lets
me course correct so essentially what is
this feedback loop the feedback loop is
what big data is all about you have an
ability to create data both at the edge
devices and then take it back to the
cloud and essentially do compute on that
and get results and solve problems which
brings us to why are we excited about
the Internet of Things of course we are
a Java company all the products we make
are built on Java there's a tremendous
value proposition in architectures and
then also in a generic sense where we
see 31 billion devices and 4 billion
people who are touched and connected by
2020
some people are talking about 50 billion
devices by the next 15-20 years that's
easily five to 10 devices per human
being so this is ass mandes amount of
edge devices and as this snapshot shows
you have your personal devices you have
sensors you are now carrying credit
cards which are intelligent there's near
field communication you have your car
which is connected think about all the
different devices which are generating
all this huge amount of data what
happens typically is all that data and
specifically in domains like
manufacturing that that data falls on
the floor because nobody is doing an
introspection nobody is doing any
analysis on those and the java internet
Internet of Things is essentially an
architecture which lets us capture the
edge devices and also consume all that
data and push it back to the enterprise
side so just to introduce you to the
stack which Oracle has for this internet
of things so we have obviously the whole
on-premise public private and hybrid
types of cloud infrastructure which we
offer at the back end but as a complete
stack what what we have spent hours and
hours building this whole architecture
is creating best-of-breed solutions
doing vertical integration and we have
not not lost focus on performance and
creating engineered systems so why Java
when we have conversations with CTOs and
CEOs and developers essentially what
they're trying to do is they're trying
to grow the ROI and they are trying to
reduce costs growing the ROI means you
have to have a stable product lifecycle
you have to have competitive advantage
you should be able to do innovation
which is boundary-less if you are
creating edge devices which are spitting
out information you need
that infrastructure for somebody to
create that fat pipe to consume that and
do analytics on that reducing costs
means is the solution portable if I am
creating a solution on a PowerPC chip
can I seamlessly take that and implement
that on an arm linux device that's what
a developer wants if we see if you have
if you where the creator of angry birds
and you were writing that application on
a platform which is not seamless which
is not portable imagine the amount of
developer compute cycles man-hours you
would need to keep creating that
application on different platforms
imagine now as a manufacturing or an
automotive or a specific domain
developer being able to use a language
use a platform across disparate node
nodes devices which run on different
kinds of architectures and have that
value that's cost reduction for us
standards is a big big initiative for us
because we believe in Oakland standards
we are working with standards which are
domain-specific and a thorn in his stock
will kind of capture some of that
essence from the manufacturing
perspective and to this effect what we
have currently is an Oracle event
processing product it essentially does
even processing across different nodes
so you have these edge devices you have
the gateways or the concentrators and
you have the big iron the big servers in
the back and what what we are trying to
do is we are trying to create these
chain of events which moves from one
node to the other and depending on the
use case you guys have the ability to do
introspection and analysis on specific
nodes
just to give you a view of the stack we
have this Java embedded stack which
essentially provides the security
management GUI the networking I oh and
whatever you guys have known to love
about Java in a smaller footprint it is
java SE spec compliant so all your code
which you write which is compliant with
the Java Sea spec automagically works on
this what we have done is we have built
a stack which has an embedded database
so persistence is one of the key use
cases we believe will make sense on
these edge devices what we have done is
we have slapped on a embedded glassfish
on top of it so now you have the web
profile to go with your standard java SE
architecture on these small footprint
devices and one on over over and above
now we have the Oracle event processor
which is nothing but an embedded complex
event processor which is slapped on so
that now you can intercept events and
essentially do things like the complex
query language type queries to create
analysis and introspection into the
different events which you capture and
the reason why we are talking about oep
and the embedded stack is because we
believe there are different use cases
which mandate capturing all all the data
and sending it to the cloud because the
cloud has the infinite compute but what
we see is depending on certain
situations certain use cases you might
want to do that analysis on the edge on
the device so what we are prob what we
are proposing is an architecture which
allows you to do that so if you don't
want to have that round trip back to the
data center back to the cloud to do that
compute and you you believe that the
edge device is capable enough to take a
quick decision you basically are making
that process near real time it's not
real time as in the heart deterministic
latencies but it is real time in the
sense something which had to
back and get analyzed and then the
results push down you are basically
eliminating that step slide kind of
aggregates what I've been talking about
edge devices do data reduction so we can
do filtering we can do aggregation we
can do basic pattern matching and
essentially it it eliminates network
load and autonomy actually gonna is
going to go into much details about that
so with that I have my last slide this
is the link to downloading the job I
embedded I'll recommend you guys who
have not played with this to download it
the full stack is available tried kick
tires and give us feedback so with that
I'll invite athlon and he will talk
about the manufacturing side of the big
data architecture and the problems they
face and how they are solving those
okay thank you Ranbir my name is Ethel
on I'm the CTO and co-founder of system
insights and i'll be picking up from
where and be left off and talk about how
do we actually apply this technology and
other technologies in actually building
an embedded platform for manufacturing
big data okay so little about myself for
the company system insights the startup
based out of Berkeley not too far from
here we build software tools for big
data analytics in manufacturing we're
very specifically focused in the
manufacturing domain our product is a
software platform called vimana that
helps you monitor analyze and improve
manufacturing productivity and our
vision for the product is to first
monitor manufacturing systems and find
ways of improving productivity from
there move on to detecting events that
can affect productivity and help you
know eliminate them and finally based on
data we collect from the shop floor
build tools to predict the performance
of manufacturing systems so that these
problems can be avoided in the first
place and in order to do this we use
core technologies like complex event
processing to make these detections and
to find these patterns and we use
machine learning in applying in applying
the historical data in understanding
what these patterns look like and we
pull all of this together and we deliver
it using our software as a service
platform vimana okay so I want to spend
a little bit of time talking about
manufacturing and and why we care now
I'm from manufacturing I've always been
a manufacturing engineer first and it's
a very interesting domain and I think
there is the reputation deserved or not
that it's
it's not a very interesting domain
especially from an analytics perspective
and there's also this feeling that
manufacturing is is a domain that is
kind of it's it's it's a sunset domain
it's not a place where exciting things
happen well first of all manufacturing
is big in fact it's huge it's about
twelve percent of the u.s. GDP it's
about a two trillion dollar sector and
the American manufacturing sector is I
think twice as large at least compared
to the Chinese manufacturing sector so
this is still one of the biggest sectors
to work to work on in the US economy and
if you look at discrete manufacturing
where manufacturing things one at a time
as opposed to process manufacturing
where you manufacture continuously
discrete manufacturing supplies products
directly to the consumer say like a gear
train in your car or a turban blade an
airplane and discrete manufacturing
makes parts that are then picked up by
other downstream manufacturing companies
for example you might have a discrete
manufacturing plant making a mold that
is then picked up by a company that uses
them to make you know iphone cases so
discrete manufacturing results in parts
that are directly consumed and parts
that are part of the supply chain and if
you look at the metal cutting industry
in discrete manufacturing which at least
as of now that's our prime focus area
the average piece of equipment spends
about twenty-five percent of its time
doing something useful in the factory so
if you look at the total capacity
available in the United States today or
in the world today with the right kind
of analytics with the right kind of with
the right kind of information we can
quadruple capacities without adding any
equipment because the average piece of
equipment is only doing work for twenty
five percent of the time and in order to
make these decisions in order to drive
these improvements in order to find this
extra 75 percent and get useful parts
out of it we need to use the data from
the manufacturing shop floor now here's
the problem the problem is we don't have
a lack of manufacturing data we actually
have a ton of data but the problem is
most
this data is falling on the floor and
very little if it leaves the
manufacturing shop where we can actually
analyze it and do something useful with
it so what are we trying to capture what
is this data trying to capture at a
fundamental level now let's take an
example of a big Hulk of titanium that's
being made into a part that goes on an
airplane right so this is a jet engine
part so what we are trying to answer is
how effectively are we performing this
transformation and we can answer this in
multiple different perspectives and in
any company all of these perspectives
are valid some tend to be more valid
than others and at different points of
times different perspectives become more
important so we have the more
traditional you know the management or
kind of the c-suite perspective what is
my productivity how many parts of my
making where am i making parts am I
making the right parts what is my
profitability how much money am I making
off these parts what is my return on
asset am I using my machines effectively
I'm actually making enough money on my
machines to justify keeping them around
then I can look at the exact same things
from the perspective of the part have I
made the part correctly what's my
quality is the party reliable right if
it's a jet engine part this has to run
for 30 years have I manufactured it in a
way that it will run for 30 years am i
doing this in an environment where my
employees are safe and then we can look
at issues that go well beyond just a
single company what is my environmental
sustainability what is the energy of
consuming as this part is made am i
creating pollutants so this very simple
transformation from you know raw
material to a finished part it kind of
makes it kind of pops up a bunch of
questions and the interesting thing in
manufacturing is that these questions
aren't new the fact that we have these
up here the fact that we are trying to
answer them is in no way in innovation
the neat thing about manufacturing is
we're not trying to find new questions
to answer we've always known the
questions we're just trying to find
better answers for them so in many ways
half the problem you know doesn't exist
will really know what we're looking for
we
trying to find better ways of answering
them so let's focus a little bit more on
discrete manufacturing so discreet man
of action again you're making things one
at a time here we are talking about
large facilities with very very
different and disparate types of
equipment these equipment internal to
them they sometimes can or cannot be
automated but they don't perform a lot
of activities as a system so inside an
entire factory you don't have a lot of
automation and most of the control is
using a human being so many of the
decisions are taken by human beings so
it's very human driven and human control
the average piece of equipment is is
relatively old we're talking 10 years
and beyond and the average piece of
equipment has low computational power so
the average piece of equipment is built
to do exactly what it can do in a very
good way but but not beyond that and so
what we have are these unintegrated
islands of excellence so you have
individual pieces of equipment which do
their job extremely well but they have
no way of communicating and talking to
each other and this and as they do their
job they give out a ton of data or
rather they make available a ton of data
which can be captured so here is you
know representative machine tool it's
making a pretty complex part something
that looks like a gear that would go on
an airplane and here we have different
kinds of data that this machine could be
potentially emitting we have quality
data we have static data as to what can
a part is being made we have alarms
notifications warning alerts messages we
have geometric data like the position we
have kinematic data like speeds feeds
then we have sensor data we have
vibration we have acoustics we have
temperature so we have a lot of types of
information a lot of types of data that
can be captured depending on the vintage
depending on the kind of machine
depending on the available interfaces
out of the box you may have ways of
directly capturing this in some cases
you may have to add your sensors but we
can definitely envision a lot of types
of data and all of this data has
specific kinds of business value and
some of the data for example of tribal
knowledge this is very very useful in
trying to improve the productivity of
the process because tribal knowledge
represents the data that the human
brings into the process this is
sometimes reactive this is sometimes
proactive but by and large this is data
that the human being knows to bring in
at the right point in time based on his
or her experience so as we talk about
automating these processes that have
been until this point of time completely
manual capturing tribal knowledge is
important because only this tells us how
the human in the loop has been behaving
so we have a lot of different types of
data the average piece of equipment in
the shop floor can generate and when you
add them up right when you look at the
two something million machines in
America today you're talking about
anywhere from 200 petabytes to an
exabyte of data per year and this is a
pretty considerable number McKinsey
sometime back to the survey and they
estimated the total stored data and
manufacturing to be about an exabyte but
what we can see here is when we actually
unlock all of these sensors when we
unlock all of these sources of
information and we start streaming them
and we start capturing them we could be
generating an exabyte of data per year
and that's really exciting because this
gives us a very interesting
technological problem to solve and this
gives us this kind of makes it possible
that within this data we can find better
answers to the questions we are looking
at and obviously there is a scale effect
if I have a small shop I'm streaming out
maybe you know a few terabytes a year if
I have a large shop and maybe streaming
out tens of terabytes here or collecting
tens of terabytes here and if I were an
enterprise if I were Lockheed Martin or
Boeing I'm streaming out you know a few
petabytes a year so there is a big
variation in the scale depending on the
kind of equipment depending on the kind
of sensors this could be more or this
could be less but what's interesting is
that this is an industry that has
traditionally dealt with data in the
megabytes right decisions have been made
by you know Excel sheets being passed
around or somebody writing on on a
notice
word so now how do we transition
decision-making from bites kilobytes
megabytes of information to petabytes
and exabytes and that and that is the
big data challenge so how do we approach
this how do we begin to construct a way
of looking at data from manufacturing
one interesting way of looking at it is
excuse me one interesting way is by
looking at it across temporal decision
scales so what do I mean by this we have
the time we have the different levels of
analyzing a manufacturing system so we
can analyze a manufacturing process at
the level of the physics right that's
kind of the business end of Matt you
know that's that's where the part is
being made right so we have the actual
process physics of the process interface
we can then can start zooming up we can
talk about pieces of my manufacturing
equipment we can talk about the
equipment itself we can then talk about
an entire manufacturing enterprise and
then we can talk about the whole
manufacturing supply chain so we can
keep zooming up these analysis skills
and as we move up we're looking at
larger and larger pools of information
and we're looking at decisions that
affect a larger and larger scale of
things similarly we can also move across
in terms of time some manufacturing
decisions have to be taken very very
very rapidly so if I have a piece of
equipment that has these complex
kinematics that's moving very very
rapidly at hundreds at a hundred of inch
at hundreds of inches per minute then
controlling that requires decisions that
are made in the nanoseconds or the micro
seconds so that I like to think of as
the real time domain in the real time
domain we're making decisions that
affects the actual manufacturing process
physics and these have to be made in
microseconds and nano seconds and then
way on the other head we have on the
other end we have decisions that drive
how the process is managed these are
business decisions and these are made
over the course of days or weeks or
months and these are managerial
decisions that are taken way above the
shop floor itself now there are very
effective systems for dealing with data
and
corporate level there are very effective
systems for dealing data in the nano
seconds because that's how plc is in cnc
is what the big gap is how do you deal
with data right in the middle how do you
deal with near time data there's how do
you deal with data that is in the
seconds minutes and hours that you can
apply in improving productivity in
improving the process in reducing energy
and in helping many of these other
problems that we can apply this data so
for us especially when we talk about an
embedded platform to drive big data
manufacturing the near time domain is
what's really important and you can see
you know with this example of energy of
energy consumption we can have this kind
of a temporal this kind of a temporal
view where if I have energy data by day
right I am talking about how much energy
do I consume in a day to run a machine I
can understand which days I should turn
the machine on or off depending on the
pricing in my grid i can then zoom in at
a resolution of hours i can look at how
much energy is going into making a
specific part and then i can zoom in two
seconds and say to make this aspect of
that part how much energy goes into that
and then i can zoom in further and say
ok let me now look at the microseconds
and if i see say a spike that means have
made a bad part so there is a lot of use
and there is a lot of need for tools
that can go across these temporal scales
so we're not just talking about
so we're not just talking about
collecting data we're talking about
collecting data in a way that makes it
effective to these are over it at
different scales from the days to the
hours the seconds to the to the
microseconds and here is where
technologies like complex event
processing can also help so ranbir spoke
about oep articles approach to complex
event processing and complex event
processing can help us build clever
abstractions which will allow us to take
similar concepts and apply them across
and apply them across different types of
manufacturing systems or processes so
something really simple like send me an
alert when I use excessive energy during
a process now we can think about
multiple ways of abstracting this one is
what does it mean by an alert is it
sending an email is it sticking in
analog somewhere is it flashing an alarm
similarly what do you mean by when I'm
operation right I could be operating
when a certain program is running when
my spindle speed is has a certain value
or based on what may be a robotic arm in
my system is doing and what do you mean
by excessive energy right is it based on
a day's value is it based on a micro
seconds value is it based on a
five-minute rolling window so we don't
know right so now technologies like CEP
can help us make sense across these
multiple temporal scales and build some
useful abstractions that can focus on
the business value while making the
technical details flexible and adaptable
and the other kind of capability we need
is multi-dimensional reasoning so we
looked at a hypercube if you will of
manufacturing data with multiple
dimensions we can have dimensions and I
have three here because I try to draw
for D cube and I couldn't find the
fourth dimension it's a really bad joke
by the way it's it's it's 4pm on the
last day so I'm yeah I'm not helping am
I um anyway so i have three dimensions
here i have time i have what's being
made and i have the piece of equipment
so multi-dimensional reasoning gives us
capabilities of slicing through any one
of these dimensions saying
trace one product through all the time
it spends on all the machines or trace
everything that happens in this machine
for a day or any combination that if so
again this is a classic big data problem
or this is a classic Big Data
opportunity because when you have this
giant hypercube of data you want to be
able to take any kind of slice you want
and extract value out of it now
obviously there are a ton of you know a
ton of places where we can flip up how
do we handle multiple data sources right
factories are complex factories have
disparate equipment how do you handle
data from these various types of sources
how do you deal with something so
fundamental like a timestamp how do you
make sure that you're correct you're
collecting the correct kind of
timestamps how do you make sure that the
temporal data and the temporal
correlations are accurate because all of
them stem from this initial timestamp
and how do you detect these correlations
and finally when we have this multi
dimensional cube how do you accurately
know what dimensions you have right if I
had to know if I had to find a basis
vector for my manufacturing data space
right what you know how many directions
does it have so understanding some of
these questions is really important in
setting up the way we do data collection
and because we don't exactly know how
the manufacturing space looks because we
haven't tapped out the space fully we
need very very flexible tools that can
allow us transfer all of these questions
so with with this right what would a big
data stack look like and and this is our
interpretation there are many ways in
which this can be done and this is what
we in system insights have come up with
and we have based our platform vimana on
on this kind of a view the first piece
is data collection we need ways of
efficiently and easily collecting data
from various types of manufacturing
equipment the second piece is data
storage we need ways of basically
storing tons of data at very very high
resolution and the third piece is
analyzing the data and we apply complex
event processing and machine learning in
making sense of the data and on top of
these three pieces we build romana and
other applications that
actually make sense of the data so this
is the actual architecture of Vimanas
this is our platform for data analysis
manufacturing data analysis we have data
flowing in from user facilities we
capture it and this goes into reasoning
engine where we do CEP to find the
patterns this goes into a machine
learning engine where we make sense of
the historical historical patterns and
we also store it in a high-speed
database and all of this comes together
in into user interfaces dashboards
iphone apps reporting tools you know
machine learning with programs like our
in providing the user various ways of
accessing the data and getting value
from them so this is great right because
we seem to have everything mapped out
obviously we know manufacturing as data
and clearly we know what to do with the
data so there's there's no problem right
and but the problem is there is a big
gap right and we really wouldn't be here
if we did not have a big gap and the big
gap is in data collection so this is
really where everything starts I mean if
we had you know we've been hearing the
the device to data center architecture
right so if i have the device on the
left and the data center on the right
this is kind of how we think it should
look it should be pretty close we don't
have a lot of gaps and it's easy to go
from the device of the data center but
that's not the case the problem we see
is that is actually a pretty big gap
from the device to the data center and
the reason we have this gap the reason
it's not easy to go from the device to
the data center is because of lack of
standardization and as we have seen seen
in manufacturing there are a ton of type
there are tons of specialized equipment
there are tons of legacy standards that
are tons of proprietary interfaces and
because of that the biggest gap the
biggest stopper in getting data from the
shop floor and then establishing this
end-to-end connectivity from the device
to the data center is a lack of
standardization and this is also one of
the reasons why manufacturing is not
excuse me manufacturing is not as well
represented as it should
when people talk about data analytics
because we have not traditionally had an
opportunity to get data from the shop
floor and actually do something with it
so one piece in solving this problem and
this is probably the most crucial piece
when we talk about an embedded
architecture for big data in
manufacturing is a data standard and one
data standard I want to spend a couple
of minutes on is empty connect now empty
connect is an open standard it defines a
protocol and an interchange format to
enable communication between devices in
a manufacturing system so empty connect
is is below the application layer it
does not force any specific kind of
business logic and it just standardizes
the way machines communicate information
and the wave machines announce what
they're doing so it's an open source
state exchange standard it's based on
XML and HTTP it's extensible in
lightweight and it's been about four
years in development and rather it's
been it's been around for four years and
it's been improving and evolving over
time and it has addressed about it is
addressed a very significant size of the
kinds of information the kinds of data
that's being collected from the
manufacturing shop floor and in empty
connect we have addressed problems with
incompatibilities and different kinds of
protocols incompatibilities and
different types of data formats issues
in having inter device communication you
know having data go from one device to
another and dealing with proprietary
interfaces and ap is that you see in the
shop floor so the idea of empty tonight
is to make the cost of collecting
information the cost of collecting data
in the shop floor as low as possible and
we've also done a lot of work in playing
nice with other standards so if you have
a legacy standard empty connecting can
empty connect can come on top of that
and make these legacy standards part of
the emt connect ecosystem so very brief
you on brief view on on the architecture
so the empty connect data stream is
basically it's an XM
stream and it's generated by the empty
connect agent which is basically running
a web server and we're still in the
early days of the standard and there are
many many devices that are not empty
connect compatible so you can have a
software a piece of software or a piece
of hardware called an adapter that
basically it acts as a device driver if
you will to enable a legacy device to
become empty connect compliant so if you
had a machine of you had a piece of
equipment that was running the empty
connect agent and it could serve the
empty connect XML then that machine is
empty connect compliant so once we have
data in the empty connect standard right
once we have that stream it makes any
kind of downstream visualization and
analysis and analysis application
possible because you don't have to deal
with these proprietary interfaces
anymore and you'll only look at the
empty connect standard so what what we
see as helping both us as you know as a
company in the in the manufacturing
space and others who are trying to
improve manufacturing productivity is an
integrated solution that basically acts
as a bridge between the device and the
data center and we think that java SE
embedded is a great platform for that so
how does our integrated architecture or
integrated solution look so we have the
devices we have many devices on the shop
floor we have the data center in this
case it's it's the cloud running vimana
and we envision java SE embedded
technology going in powering these smart
boxes we see embedded devices that
basically can bring empty connect
capabilities to non empty connect
capable machine tools and one of the big
challenges we see in the spaces or
rather one of the opportunities if you
will that embedded technology can
address is there are many many devices
that don't have the intelligence to
stream data that don't have the compute
capabilities to basically run that empty
connecting a web server and run an agent
so this is what we see
java SE embedded technology is powering
is basically powering a black box or or
any colored box if you will to make a
piece of legacy equipment or a sensor or
some kind of a node in a manufacturing
shop empty connect compliant so this
will have to allow device agnostic
integration so you can basically work
with CNCs plc sensors power meters or
any kind of equipment again will she be
based on empty connect so it's an open
standard so you have maximum
compatibility and this serves up data
into other systems like vimana or any
other empty connect compliant
application to actually analyze and make
sense of all the data coming from the
shop floor so what should this look like
what are the requirements this this has
to be pervasive so we're looking for a
solution that can be ubiquitous ly taken
to any kind of sharp any kind of machine
so that means it also should be
cost-effective the hardware or the black
box we're building it has to be device
agnostic so it should have the
capabilities to work with both old and
new machines it's easier with new
machines with older equipment you need
to be able to deal with proprietary
interfaces and you have to deal with
with sensors and plcs and other kinds of
systems it has to be based on standards
empty connect is a great fit but other
standards work as well and the solution
has to be scalable so we need something
that can be taken to a mom and pop shop
with five machines all the way to a
Boeing or a Lockheed Martin with
thousands of machines all over the world
and we see a lot of the products and a
lot of the technologies that are going
into java SE embedded like when we
mentioned jess the embedded sweet on the
oep the complex event processing engine
we see these technologies as forming a
part of the stack because this this box
if you will will need to have
capabilities of supporting adapters so
that old old machines can become empty
connect compliant it should have
capability of running the empty connect
agent itself so that it can basically
act as a web server and serve empty
connect XML and depending on the
application
should have compute capabilities to do
basic analysis so depending on the
requirement it should be able to do some
analysis in the edge itself so now you
have a distributed architecture where
analysis can happen in the cloud and
analysis can happen in the edge so this
is our vision of how we can use java SE
technology and right now we're kind of
in the early stages of applying this we
have our own we have we have taken some
other approaches and we're heading
limitations on how we can scale them up
so we think that that this is 11 good
way to to move ahead and with that I'm
done so we have a few minutes for
questions
I think they're too tired to ask them
okay we really call it a day then thank
you guys for attending thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>