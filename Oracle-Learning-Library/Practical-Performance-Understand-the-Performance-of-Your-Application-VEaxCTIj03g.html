<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Practical Performance: Understand the Performance of Your Application | Coder Coacher - Coaching Coders</title><meta content="Practical Performance: Understand the Performance of Your Application - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Practical Performance: Understand the Performance of Your Application</b></h2><h5 class="post__date">2013-02-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VEaxCTIj03g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so I try and talk through
everything that's on the slides if I
miss stuff and you'd like to some
clarification just stick your hand up
and ask a question as it's the last
session I'm gonna try and get through
this relatively quickly so you just ask
questions if I'm going too fast or
there's something you want to know about
so there's presentations entitled
practical performance and it's not a
deep dive into how to tune the operating
system how to enable large pages whether
you want to adjust run cues and use
round disks for fast i/o it's not an
in-depth guide to tuning garbage
collection or anything like that what it
is is a high-level methodology and
process of how to go through the
standard performance analysis and tuning
process for an entire deployment and it
teaches kind of like the the 70/30 8020
rule I'll highlight the major things
that you want to look for but it doesn't
go into real detail but if you've got
questions right specific things I'm
quite happy to have a conversation about
that afterwards
so yeah the presentations practical
performance on the first slide of every
IBM presentation is one of these it's a
legal disclaimer if you can't see at the
back you're lucky and what's even better
than that is they've done it in block
capitals to make it harder to read
because legal statements are little bit
too easy so if we ignore that okay me so
I work for IBM in the Java technology
center based in the UK in a village
called Hursley I've been working as part
of the Java technology center for 12
years and 11 months and two and a half
weeks or something I get my 13th
birthday in on October 20th and in those
almost 13 years I've spent my time
working on customer engagements doing
customer support and consultancy and
then I've moved on to that to doing
usability so monitoring diagnostic tools
etc and I'm now doing the deployment of
Java into the cloud so what's in these
slides is kind of a high-level summary
of the sort of thing I used to do fit
with customers for years my Khan
informations at the bottom so it's an
IBM email address I'm on LinkedIn as
Chris Bailey IBM so it's easy to find
and I'm on SlideShare net which is where
these slides will go everything that I
presented a Java one this week is going
to be on SlideShare for you to download
if you want them so the goals of the
talk as I said is to introduce a general
methodology to a performance analysis
and and trying to identify performance
bottlenecks in your system so it is the
high level process rather than the
detail of how to analyze in tune
specific areas what it will do though is
cover some common performance
bottlenecks things that which will have
a noticeable impact to your system and
we'll go through a process of looking at
sample application and correcting some
things and seeing what the what the
improvement is and I'll give you a
guideline of the sorts of improvements
you can actually make to your own system
so in order to do that we'll start off
with the approaches to performance we'll
look at layers of the application so
operating system JVM application
external resources and so on and as I
said well we'll do some examples or how
to look at each of those areas to to try
and resolve performance issues so really
there's two major approaches to looking
at performance the first of them is kind
of outside in and this tends to work
better when you've got an identified
performance problem so you know you've
got a user that says if I do this action
performance sucks if you've got that you
already have your start point you have a
user metric that they care about and if
you've got that it makes sense to take
an outside-in approach right so you've
got the performance may be at the HTTP
server
and you can track that transaction all
the way through the system
so from the HTTP server through to a
servlet through to an EJB invoke through
to JDBC drivers through to the database
and then you can track it all the way
back again so you could put timings in
there to find out which of these steps
is causing your performance problem but
that's that's a very specific approach
you need to know that there's an a
problem there before you can start the
the other side to this is the layered
approach which is probably more
important
appropriate if you're you starting off
just doing general performance
improvement so I want to health check my
system and I want to see if there's any
glaring bottlenecks that I can start
working on so we knew you're taking the
layered approach obviously there's
there's two ways you can approach layers
you can either start at the top and work
down or you can work at the bottom and
work up now I always advocate starting
at the bottom and working up see looking
at the Machine first then the operating
system then the Java Runtime then your
application and then maybe external
things that your application accesses
and the reason for that is in all
honesty at the Machine level there's not
much for you to look at so there's only
a couple of things you need to do to
check whether it's right or wrong and
correcting it doesn't take too much
effort and it gets harder to analyze and
harder to diagnose and harder to change
as you go up the stack so the easy wins
are at the bottom and the hard work
which may involve changing your
application changing architecture
changing your code getting developers
working on this is at the top of the
stack in your application so I always
start at the bottom where I believe it's
easiest to identify problems and make
changes so before you start anything you
first of all need a performance baseline
you need to do a performance test to
find out where you are at the moment and
because we're going to be doing
performance improvements then we want to
check whether it's actually improved it
you need a repeatable test you need
something that you can run again and
again and again and it needs to be
representative of the workload you're
actually going to be doing in production
right these are obvious things but it's
actually quite hard to get a rep of
representative tests you can use things
like apache jmeter loadrunner rational
performance tester there's whole load of
tools which will record user actions and
run that multi-threaded against an
application but if you only hit two or
three code paths you can end up with a
test that's not particularly
representative now there was a pitch on
Monday I think it was by a guy called
Renee who works for a futures exchange
in in Chicago CMA and the approach that
they take to this
is is actually quite elegant what they
do is they actually record every single
transaction that comes into their system
throughout the entire week and they use
that to identify their six minutes of
busiest workload record it and they run
that through the system on the weekends
so they have a system that's only up
Monday to Friday they therefore have
Saturday and Sunday in order to run
performance tests so they use exact
workloads from during the week at the
peak of what they need to be able to
react to and that's their work that they
can run repeatedly so you need to find a
way of having something that's
representative and repeatable you need
to be able to run it several times so
once you've got that and you've got the
ability to run it several times you need
to make sure that the system that you're
running your tests on is consistent and
there's two ways that you really want to
be consistent the first is it needs to
be representative of production right
having a test system that's got
different hardware has got different
memory has got different levels of
network associated with it is going to
have a big difference to the way the
test is run and it can well identify
different bottlenecks and if you run on
a test system where you don't have the
same level of network capacity your
application is going to run slow because
of your network connections and you
won't necessarily identify the
bottlenecks in your application that
you'll find if you're running in
production so you do really need ideally
the same level of hardware and the other
side of ensuring consistency isn't just
your test system to where you're the
performance matters it's in the state of
the system when you're running the tests
so there's actually some really
interesting stuff that happens at the
hardware level so when you run an
application bits of your application
gets loaded into memory and it gets
cached and whether you've got useful
data in cache or irrelevant data in
cache is actually going to affect your
performance test so ideally you actually
want to clean out the entire system and
start from exactly the same baseline
when you run each of the tests now
that's actually quite hard to do and a
one way of doing this is to run your
test several times before you start
measuring and that's primed it to a a
certain situation and if you can do that
repeatedly then you kind of avoid some
of these these hardware issues that can
arise so those are the kinds of things
that you want to do in all honesty the
important thing is have a baseline have
it repeatable so that you can then test
after you've made changes that those
changes made in performance improvement
and as far as possible make it
representative of what your application
actually doesn't in production so what
I've done is I've taken a simple
application and that simple application
is the WebSphere application server
running plants by WebSphere which is a
sample I get shipped with it and in
order to create a performance test
ideally I would have had production data
but you know it's just a sample so I
took something like jmeter ran its proxy
server that lets me click around on some
windows and save that as activity and I
ran that with ten concurrent users from
a remote system so that's my consistent
performance test I can run that several
times and the tooling that I was using
gives me a breakdown of the response
average responsiveness for each of the
pages and each of the actions that's
done by the load generation tool so this
gives me a profile of the responsiveness
of different bits of my application so
so this is my baseline this is where I'm
working from and I'm trying to improve
on as I go through the process so I've
got my baseline now I said to do a
generalized approach to looking at
performance I would take a layered
approach and I would start at the
infrastructure at the bottom and then
work my way up and when it comes to keep
the infrastructure largely there's two
things you need to look at and that's
going to be CPU and it's going to be
physical memory availability so that's
what you've got at the infrastructure
level with your operating system and the
machine hardware if you move up one more
level at the Java Runtime in all honesty
there's not much you can influence other
than garbage collection
so really garbage collections the only
things worth looking at at the Java
Runtime layer then above that at the
java application you've got all your
java application code and that's going
to have potential issues around memory
CPU usage synchronization so
synchronized blocks and contention on
locks and i/o so those are the four
resources that could be applicable at
each level but really they're only
applicable at the application level
infrastructure it's CPU and RAM the Java
Runtime it's really just CPU and memory
2 which is both garbage collection and
then at your application escape for all
of them so at the infrastructure level
if you don't have enough memory then
you're going to page right you you start
backing bits of your applications memory
with disk and spinning disk is well it's
slow and certainly an order of magnitude
slower than having RAM in which to store
your application and access memory so
memory is a big issue the next one is
CPU so if you don't have enough CPU for
the amount of load that's coming into
the system then you can only scale so
far you'll reach a maximum level of
responsiveness and stop and in fact if
you have too much workload you end up
contending on the CPU that's there and
your performance drops off so you
actually lose performance if you don't
have enough CPU it doesn't just stop
getting better it actually starts to get
worse after that so memory and CPU are
pretty big IO is another one but it
tends to be a little bit harder to work
out what's going on there and it's not
something I'm actually going to cover
here so memory usage so RAM on the
system is used for a few things so it's
used for your application so the Java
heap the JVM the operating system is all
backed by physical memory and it's also
used to cache files so if your
application reads or writes to and from
file what the operating system will do
is it will try and hold those files in
memory so that the access is quicker it
doesn't go in writes that file changed
directly to the
disk because that's slow he writes it to
memory and then that memory will slowly
write it back out to disk afterwards so
it does make it there eventually but
it's not a blocking event so your RAM is
actually gonna be used for two things
it's not just used to backward with the
applications it's used for files as well
and if you run out of physical memory if
you don't have enough the first thing
the operating system will do is take it
away from file caching so your i/o gets
slower and then it takes it away from
the application and has to back your
application with spinning disk which is
slow so accesses two bits of the Java
heap slow down and that's one of the
reasons why most people are aware that
paging is bad for a java application
it's mentioned a lot and the reason for
this is really garbage collection so
operating systems design paging that the
bits of memory which you're not using
are the ones that they'll write out to
disk and then get backed by spinning
discs now that works well because we've
paged out the stuff that you don't
actually need that you're never going to
access so the idea is put on disk give
the performance problem to the things
that's we're not going to worry about
then the unique thing about Java is
garbage collection kicks in and in order
for garbage collection to work out which
bits of the application you're using it
has to also identify which bits of the
application you're not using and those
are going to be the things that are
paged out to disk so it walks through
every single bit of memory including the
stuff that's been paged down so whereas
a normal application wouldn't touch it
at all
garbage collection does so that's what
paging is particularly bad for Java and
much worse than it would be for other
application types so paging is a
particularly bad thing so next is CPU
usage if you don't have enough CPU as I
said you'll you'll reach the limit of
how far your application will scale and
then once you've gone past it in your
CPUs running at 100% you actually start
to slowly degrade performance because
your different bits of the application
are competing for the CPU so that's what
happens if you don't have enough
overall CPI the other type of problem
that can occur is if you've got other
processes on the same machine which
spike their CPU usage and suddenly take
all of it and a good example of this is
databases doing a backup job that say
one o'clock in the morning when in the
database is backing up the rest of the
applications on the books run slowly so
if you get a very specific performance
impact at a given point in time there's
a good chance something else in the Box
is just stolen all of the CPE so how to
check for this well you're looking at OS
level resource contention and that means
it changes by OS the the way to do it on
Windows is listed there so on Windows
there's a tool called perfmon does
anybody know you about perfmon that's
pretty good a few of you D so it's built
into the operating system and Windows
effectively puts counters in everything
that it does and perfmon lets you access
those counters and graph them so if you
care about paging inside perfmon there's
a pulldown menu for process counters and
under the process counters there's page
faults so that basically says tell me
about the page faults that are happening
on the system you can do the same thing
for file cache to find out whether it's
taken all the memory away from the file
cache you don't have any file caching
done by the OS anymore and that's just a
different counter you go to memory and
you go to system cache resident bytes so
that lets you look at paging the similar
counters for CPU usage so you can find
out about the CPU usage of your
application or the individual threads
inside an application and it gives you
similar counters for i/o now if you
wanted to do this sort of thing on Linux
so for most of CPU and memory you'd be
using top but you can also use PS on AIX
you'd be using top a s and you'd be
using vmstat to look for paging so the
tools change per operating system but
they are all available now if we go in
and look at my test case running on
Windows this is what perf 1 shows me for
paging so those spikes of activity is
paging happening on the
system and there's a pretty good chance
that those spikes of paging activity
happen at the same time as garbage
collection because as I said garbage
collection pages in all of my memory
touches every single bit of memory to
work out what's live and what's dead
so if paging is going to happen is going
to happen during GC so those spikes in
paging happening on my system happen at
the same time as garbage collection so
that says to me that I want to fix
paging because it's probably having an
effect on my application now the way you
fix paging is fairly simple you give
your system more memory there's not much
more you can do than that so if you're
in a virtualized environment you can
assign more real memory to it you can
stick it on a box on its own if there's
other things there which are using
memory but effectively you've got to
give it more memory and it's the same
with CPU or i/o if that's your
bottleneck really what you have to do is
give the system more of it and that's
why in some ways it's a simple thing to
fix because there's nothing complicated
here in a lot of ways is too difficult
things to fix because if you need more
RAM it's a good chance you have to order
it through procurement if you work for a
large company and that's right three or
four months so this is where we started
off right and we started off with our
baseline and I can run my baseline and
I've realized I've got paging so luckily
I'm on a virtualized environment I can
just assign more RAM to this partition
and take it away from another one so the
effect of doing that is this I have a
very slight increase or in my throughput
performance for each page which is a
very slight decrease in the
responsiveness of each of the pages so
my performance has got better that red
line is slightly slower than each of the
others now the performance is only very
slightly better and that's maybe not
what you expected so here's the
breakdown per page a couple of pages
actually have a noticeable percentage
improvement but the ones where there's a
big percentage improvement are the ones
that didn't take a lot of time in the
first place
the overall improvement is actually only
about 4% so by entire application as a
result of removing paging is now
actually only running about 4% faster
now as I said paging tends to happen
during garbage collection so do we only
have a four percent change in garbage
collection so what's on the screen here
at the moment is a graph of my garbage
collection pause times so this is how
long each of the garbage collection
cycles took and the longest took about
1.1 seconds in the table though below
there's a full breakdown of statistical
analysis of it and it says that the
overall GC overhead so that's the amount
of time spent doing garbage collection
versus running the application in this
case was about 8% so about 8 percent of
my time is spent in GC and I have pause
times of up to 1.2 seconds now if I look
at the same picture after fixing my
paging problem I now have a longest
pause time of more like 0.65 seconds
so my pause times have cut in half and
my total amount of time in GC my GC /
head has gone down by about 2% so I'm
spending less time in GC but the biggest
change is my pause times have now
dropped significantly because I'm not
having to page in and paging when I'm
doing garbage collection so possibly the
surprising thing there is that during
the normal run time of my application
paging hasn't particularly affected it
but what it has done is cause these 1.2
second delays in garbage collection and
if you've got responsiveness SLA su
service level agreements and your
transactions then that's where it's
going to kill you it's going to be the
ank lawyers where you have long long
transactions the application itself
isn't too affected because all the bits
of the application which you're running
have been paged in and it's the stuff
that you're not using that's been paged
out now I will also admit that the
paging happening here isn't significant
right if paging does become significant
then a
fool throughput does could degrade as
well but for small levels of paging it
actually only hits GC so here's the
summary of those the effects of GC pause
times the maximum pause time was reduced
by 38% so we not you know a significant
amount of time off our maximum pause
time the average went down 13% and we
spent 11% less time in GC so all of
those things improved our performance
and all I had to do was give my box or
my partition an extra one or two
gigabytes worth of RAM okay so if we
then go from the operating system and we
start moving up to the run time really
for the Java Runtime it's all about
garbage collection right this is the
only thing that you have much access to
tune there are like hieroglyphic options
available for adjusting the just-in-time
compiler and this sort of thing but in
general the only thing you should worry
about making changes to is the garbage
collector and again being able to do
this is actually easy to diagnose and
it's easy to change you just add some
command-line options so the amount of
effort to change GC is just the amount
of effort it takes to restart the system
so in terms of the Java Runtime memory
is actually used for a fair number of
things when you start your process
memory is used for the OS and the C
runtime right the fact that you running
an operating system takes some memory
your Java heap takes some memory and the
JVM itself takes some memory and there
is actually a relationship between the
Java heap and the JVM memory usage so
when you create a thread write a new
java.lang thread object that creates a
thread object on the Java heap but it
also needs a thread at the OS level in
order to be able to run what threads do
and it's the same thing for sockets
anything that requires machine resource
or OS resource has an allocation on the
other side of the line so you have both
the Java heap and a native heap and what
you create on the Java heap may actually
allocate memory in both places so
what memory problems are there so the
first of all if you don't have enough
Java heap or you don't have enough
native heat the other side when you run
out you'll get an hour of memory error
and that's going to give you a pretty
bad performance problem because you
basically shut down and that's your
worst performance you're not running so
yeah if you don't have enough Java heap
or native heap you'll have an hour of
memory error what's actually worse than
that
because if you have an out of memory
area you'll shut down you can just
restart the application and for things
like clusters that's done for you
automatically what's actually worse is
if you have only just enough memory in
which to run because then you end up
garbage collecting all the time and you
actually spend a lot of time in GC doing
garbage collection rather than having an
out of memory air and just restarting so
having only just enough memory to run is
actually quite a bad situation to be for
performance so if you in that kind of
situation it increases your CPU usage
for garbage collection because you're
spending all of your time in GC and and
so that's our performance problem really
that you have to worry UI so in order to
detect problems at the java level
basically you want to get verbose GC
output that will tell you about the
garbage collector and if you want care
about native memory usage there are
tools you can use at the OS level so PS
perfmon sv mon on AIX and so on now
there are tools which will visualize
both of these for you that you in this
day and age you should not need to be
reading for those GC output you should
be loading into a tool and showing it
via graphing it makes it significantly
easier to work out what's going on now
there are various tools available which
will graph of HTC for you one of them
are Amit this is a plug from IBM is
called garbage collection memory
visualizer it's free so there's no
charge for it you can download it it's
an eclipse RTP based application and it
will load in verbose DC output from
hotspot or from IBM so that will give
you graphing
of memory usage pause times etc as well
as statistical analysis of everything
that's going on it'll tell you how much
time you're spending in GC it will tell
you what your longest pause time is and
it will use that to try and highlight
problems in your system so if it thinks
you don't have a large enough Java heap
it will tell you that Soji CMV will do
this will for you and it will also do it
for the native memory that non Java heap
memory so you use OS tools to find out
about that whether it's a PS or or
perfmon that we saw on on Windows and it
gives you a script that you can run in
order to gather the data and then it
will load it in do the the statistical
analysis and the visualization for you
so again that works on any operating
system so if we run our tests what we
see here is that the Java heap usage
that blue line is at about 100 Meg and
the Java heap size is at 128 Meg so
we're using the vast majority of our
Java heap we don't have a lot of spare
space so at this point with this
configuration our proportion of time
spent in garbage collection is listed as
8% so we're spending 8 percent of our
time doing garbage collection and 92
percent of our time running the
application so in general that's a bad
number you should be able to get garbage
collection I ever had for almost every
system down to one or two percent but
the thing to notice there is that the
garbage collection overhead is currently
8 percent and the target we can get to
is 1 or 2% so all the tuning that you
would ever want to do to garbage
collection is only gonna get you 6 or 7
percent was worth of throughput in this
case right if you if we took the GC
overhead down to 0
I've only gained seven eight percent
throughput so tuning garbage collection
tuning the JVM is not a panacea for
performance you're not going to run to
three times faster by modifying the JVM
you're going to get maybe five percent
but but in this case we're using a
thanks Bertha's Java heap and 128 Meg's
so we're using you know 80% of the heap
at any given point in time so the theory
on garbage collection heap occupancy is
that you want to keep heap occupancy
roughly in the middle of Java heap usage
because if the occupancy is really low
if the amount of memory that you're
using is say only 10% of the Java heap
you actually spend longer doing garbage
collection when you garbage collect
because you're traversing a lot more
memory than you really needed to so
you're also wasting memory there and as
we said you know if that's RAM that
something else can be using that another
process may be suffering from lack of
RAM so ideally you know you don't want
to have your coupon seized actually
being too low
but more critically you don't want it
being too high if your occupancy is up
at the top so you're using say 90% of
the Java heap because you're using 90%
you've only got 10% to allocate into
before you have to do a GC cycle and
that means you can say allocate 10 Meg's
worth of data then garbage collect
allocate another 10 Meg and then garbage
collect if you could allocate a hundred
mega before your next garbage collection
then garbage collection would be only 1
in 10 so you attend to the frequency of
garbage collection so you want space at
the top and usually the guideline is to
make sure your occupancy is somewhere
between 40 and 70 percent of the total
Java heap size anything above 70% really
is too much anything below 40% you could
probably shrink the heap and in fact for
the IBM garbage collector we will that's
the trigger point in which we expand or
shrink the heap above 70% will expand
under 40% will shrink but the guideline
of keeping a window in the middle
applies to hotspot j-rok IBM and
whichever you're using so resolving the
problem if your javy isn't big enough
well what change minus X MX make it
bigger again because we don't want to
cause a paging problem you need to make
sure you've got enough RAM on your
system to be able to do that
and you want to make sure that as we
showed back here you've got a Java heap
and then you've got this native heap
thing which is what's used by the JVM
now the amount of memory that's used for
the native heap is just what's left over
once you've allocated the Java heap so
if you make the Java heap too big you're
actually constraining the native heap so
ideally you do need to measure both and
understand what the memory usage of both
is before you start increasing the Java
heap size but in our case our Java heap
size is small so it's not a problem so
we've gone from we have our case where
we're using about 90% of memory and if I
then increase the Java heap size so I
get it into this 40 to 70 percent window
of occupancy and I rerun my test with my
increased Java heap size I'm now still
using 100 megabytes worth of live data
but my heap size is now more like 160
Meg's so I'm in that 40 to 70% region
and my GC overhead the amount of time
spent running GC rather than running the
application has now drops from 8% to 3.3
percent and that means I've gained four
and a half five percent of performance
just by changing a command line option
to give myself a little bit of extra
Java heap but you know at this point my
GC overheads down to three percent so
any incremental improvements a G C
tuning now can only gain me three
percent of throughput so the effect is
to reduce overall time in GC by about
sixty percent however that's only 4.8
percent of my application throughput so
so far paging got me about four percent
changing GC has got me four point eight
percent
so I've improved my performance by eight
point eight percent which isn't a huge
amount but all I had to do for this was
assign a bit more RAM and change a - xmx
option on the command line so it's
pretty quick to do and the effect that
this is had on my performance benchmark
because I've now run it again to make
sure this has actually made it
improvement is before I
had this I fix paging and it got a
little bit better now I fixed garbage
collection and it's got a little bit
better again so I've now got an improved
picture so there's the oval breakdown of
improvements per page in general they're
not great one page it's now 30% faster
but that's because that page didn't take
long in the first place overall I've got
about a four percent incremental gain so
next I've looked at the operating system
I've looked at the Java Runtime next I'm
going to look at the application itself
so for the application you care about
memory you care about CPU you care about
synchronization and you care about IO so
all of these are candidates for the
application itself in the case of memory
it's usually that I've allocated
inefficient collections
you know I'm traversing down an array
list rather than using a hash map and
that's causing me an ear problem for CPU
it's often that you don't have enough
threads and therefore you don't scale as
you add more CPU and that's kind of the
other side of synchronization where
you've got bottleneck locks inside your
code so the approach to looking at this
is to first stop by looking at CPU usage
so effectively this is just doing simple
analysis of your code to find out where
the CPU time is being spent and whether
we can reduce the amount of CPU time
that the code takes to perform the
function that it does so there's various
ways of doing this and the one that we
use inside IBM is using a tool called
health center
j-rok it has Mission Control and we'll
go through looking at that in a second
the other thing to look at first is
synchronization so this is where you
have locks synchronized blocks of code
and you have multiple threads trying to
access through that block at the same
time now if you have lots of threads
trying to access the same data structure
it's not necessary
problem contention isn't a problem
unless when that lock is taken the
thread that works on that data takes a
long time doing it so it's it's a mix of
how long a lock is held for and how
often it's contended so those are the
two interesting bits of data that we
care about so first of all trying to
identify where there's CPU and
performance in efficiencies in your code
so this output here is from an IBM talk
good health center which is free you
plug it into the JVM but it only works
for the IBM platforms and what it does
is it gives you a breakdown of what
methods are using how much of your
application CPU so in this case it's
identified a method that's in the
shopping servlet that's using 80% of the
CPU of the java application and at the
bottom it gives you a tree and that tree
is the method call graph so what method
is called what method which is called
what method to get me to my servlet
methods causing me a problem as I said
this is IBM J rocket with Mission
Control does the same thing and there
are third-party tools which we'll walk
through and find CPU bottlenecks as well
so if I look at this and I say ok so I'm
spending all of my time in plants by
WebSphere Shopping servlet deliberate
slow method that might be a candidate
for optimization and in fact in the case
of Health Center on the left hand side
it does some analysis of the nature it's
got and it says deliberate slow method
might be or it might be a CPU hog that's
appropriate for optimization so if we
look at the next bit which is our our
synchronization again health sensor will
look at every single lock that's running
in the system and Mission Control this
does the same thing for J rocket so it
analyzes every single synchronized block
whether it's JVM level or whether it's
application level so object locks and it
tries to work out whether or not there's
any contention and how long those locks
are held for so we've got some high bars
and these are actually that lock is
contended so in this
1% of the time a thread that wants to
get that synchronized block has to wait
because someone else owns it but the bar
is green and the reason the bars green
is because when a thread holds that look
it holds it for a very very short period
of time so yes one time in 100 I'm gonna
have to wait but I have to wait a couple
of microseconds so that really isn't a
problem what health center will do is it
will paint bars red when they become a
problem so that you've actually got
something to go and look at so in this
case I've got an alert that says I've
got a deliberate slow method which is
running slow and that I don't have any
problems with my locking so if I look at
the code for deliberate slow method
someone's written a loop that just waits
for a time to pop and then stops going
through the loop so it's it's a banal
tester to show that you know this is
what you need to look for so if I fix
that what happens is this was my
original baseline and from my baseline I
went to fix paging and I got my 4% I
then and fixed the the fact that the
Java heap wasn't big enough and I made
the Java heap bigger and I got another
4.8% so at this point I've got an eight
point eight percent performance
improvement and then I fixed some bad
code and suddenly for the shopping
servlet I've got what looks like 10
times faster and for this one I've got
significantly faster as well so in two
cases doing some modification to the
code has given me a huge huge increase
so in the case of one of them I've got a
5x pin performance improvement and in
the case of the other one I've got 20x
and an overall performance game of 48
percent now this is a fairly banal case
it is that I made some code spin for a
little bit of time so you're never going
to find anything that should be quite
that bad but the important thing here is
actually that you know you tune the
operating system you get
digits you tune the JVM you get single
digits and this is because smart people
that work on operating systems have been
doing so for years and they've optimized
out-of-the-box performance so that it is
95 99 percent of the time right and it's
the same for the JVM huge amounts of
work done in the just-in-time compiler
and in garbage collectors to make them
self tuning and so on so there isn't
much that you need to do and even when
it's wrong it's not catastrophic ly
wrong whereas let's face it most
applications don't have a huge user base
and they don't have you know Java's got
15 years operating systems they've got
30 years of pedigree so that's where
it's most likely that you're going to be
able to get performance improvements so
I've identified a problem in my code and
I fixed it and I've got 48 percent
overall and 20x for one of my servlets
so the next thing to do is then go back
and check that this is actually fix
something so at every stage you need to
go back and look and make sure you
haven't broken something and look for
the next improvement and now you're
looking at the CPU profile
it all looks pretty good there's nothing
that's actually using huge amount of CPU
so that seems to be okay and I can go
back and look at the locking to see
whether that's now become a bottleneck
and there's nothing obvious there either
so actually at this point I've got a
fairly well running application which
you would hope because it is a sample
that we ship with the JT with WebSphere
so we're trying to show it off as
something that's works well so yeah I
mean we've got a well running
application and by the way we don't ship
it with deliberate slow method I did
that so the summary is that when you do
performance testing you do need some key
things to begin with one is it a
repeatable benchmark you need to run
that benchmark make up a single change
run it again and make sure that you're
always getting better and in fact you
don't want to run it just once right you
do get those variations so when you run
a benchmark you could actually do with
running it five 10 20 times after you
make a change
to make sure that you've got a full set
of measurements and they correlate with
each other and you don't have a one-off
anomaly so you need to do that in fact
performance is something you should
ideally be doing constantly and if
possible measure this stuff in
production as well in terms of being
able to find out what's going on you
don't need to be going into log files
anymore there's visualization for all of
this so Windows is particularly good
they all graph perf mod for you personal
as a visual tool for most of the OS
locks that you can use to look at memory
and CPU and so on there are visualizers
for it out there we provide one called
GC MV that this is free and it works for
the boasts GC and it works for some of
the OS stuff and then when it comes to
your application there are again free
tools out there so mission controls free
in in development health center from IBM
is free in every case so productions
free as well and this will visualize the
data for you and try to identify
bottlenecks and do statistical analysis
I mean performance is something we're
trying to make easy for everyone to do
and most importantly don't think that
there's a go faster button on the JVM or
in the operating system that we don't
tell you about because we want to sell
you services right it's not there the
only thing you can do is you know
usually play around with GC a bit but
remember if you start off with a GC
overhead of 8 percent you can only save
8 percent so usually it's not the
problem the problems going to be
somewhere further up the stack whether
it's actually middleware code whether
it's your application code whether it's
third-party code you know in a lot of
ways you should just look at who's code
newest because they're probably at fault
so in summary
yes infrastructure affects performance
yes garbage collection affects
performance but yeah the upper case is
most likely where it is and but I would
always start your analysis at the bottom
and that's because it's easy to look at
and it's easy to correct whereas if
you've got fundamental problems in the
application you suddenly have to start
grabbing large numbers of developers and
discussing whether or not you actually
need to change your architecture and
that's something that you introduce risk
into the project and takes a while to be
able to design and implement and deliver
properly so there's a whole bunch of
references and as I said the slides are
going to be on SlideShare so you can
download them there and they should be
there by Monday okay any questions
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>