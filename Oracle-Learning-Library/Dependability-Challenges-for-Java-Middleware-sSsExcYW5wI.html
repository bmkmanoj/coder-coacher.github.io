<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dependability Challenges for Java Middleware | Coder Coacher - Coaching Coders</title><meta content="Dependability Challenges for Java Middleware - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dependability Challenges for Java Middleware</b></h2><h5 class="post__date">2013-02-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sSsExcYW5wI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I my name is Mark littell I'm the CTO
of jboss hopefully you've heard of jboss
which is the middleweight division of
red hat in the next 45 minutes or so I'm
going to talk about a few challenges in
the area of dependability that I see for
java middleware in the next in the
coming years so the aim of this talk is
to try and give you an idea of where
research and development is or should be
heading over the next few years and
hopefully by the end you'll see that
there is quite a lot of work into these
challenges going on elsewhere some of it
is happening in the Java communities but
quite a bit of it is happening outside
and I hope that you know after this talk
you'll be encouraged to look at what's
going on elsewhere if you agree that
these are and ability issues and you
know maybe try and drive some of this
into Java middle earth because I think
that it's really important if if java
'the the JVM and enterprise jailbroken
tin you to be as relevant as they are
today in some of these new areas then we
need to address these issues i'm going
to give a brief history of enterprise
middleware just to kind of set the
context hopefully most of it will be
known to many people in the room but
it's it's useful to at least understand
where java has come from and you know
the components in your typical e6 stack
how they've been influenced over the
last 40 odd years and again by the end I
hope to show that it actually is it's a
really good time to be a Java developer
I can't think of any period apart from
when Java and subsequently j2ee were
first created when it's probably as good
a time to be a Java developer there's
despite the fact that I think there are
a number of dependent
the challenges you know that means that
there is there are these areas that if
you're really interested in doing some
groundbreaking work then there's a that
there are these areas and they're open
for good developers and good open source
hopefully contributions and like I said
hopefully go out and fix these problems
and then maybe in a few years time I'll
be sat in the audience listening to one
or two of you talking about how you've
solved the things that I'm about to
discuss so enterprise middleware didn't
just spring into existence when java
j2ee came on the scene you know it's
been around in one way or another for
well over 40 years you know our PC for
instance dead back dates back to the
1970s obviously what people in the 70s
considered to be enterprise middleware
was significantly different to what we
consider be today but you know
middleware has evolved continues to
evolve with each new wave it builds on
what has gone before throwing out some
things that may no longer be relevant
updating things that are you know that
need to be changed and if you look at
your typical e6 stack you can see
influences by one or more of the things
that I've written on this slide even web
services whether you like it or not has
influenced ee 6 rest Korver Cobra was
the middleware platform of choice in the
mid 80s and early 90s dce which predates
Cobra and then in the Microsoft world
who have calm D calm and net and going
back even before some of these things
there are there's lots of work on
bespoke middleware platforms such as
Argus and emerald and the light all of
these have influenced their successes
and you know the ultimate success or at
least in our world is e6 you know if you
look at a typical e6 stack whether it's
you know a glass fish or a
a s7 you can see we have our pc and
message passing like I said our PC dates
back to the 70s message passing to even
even before that distributed objects so
I mentioned koerber before Cobra was
probably the first certainly the first
standard distributed object stack out
there that popularized object oriented
programming all of these frameworks and
stacks in one way or another how to
focus on reliability when you're
developing in a distributed environment
having reliability and having fault
tolerance whether it's through things
like transactions or replication is
extremely important because the failures
on failures of a component in
distributed environment can take down
your application that's running
elsewhere so having an ability to it's
often masks and certainly tolerate
failures in one way or another is very
very important and and there's a kind of
a common thread through most if not all
of the successes of the e6 so you know
given given all that you know somebody
selling from the outside looking in code
could ask you know well surely we're
done you know we we've got everything we
need many of you in the audience are
hopefully no developers of complex real
world applications written in in Java or
some other language you'll you know
you'll know as a result you know today
we can definitely do reliable
inter-process communication we can
maintain distributed state coherent
distributed state consistent distributed
state across multiple instances in the
presence of a potentially an arbitrary
number of failures we can detect or
suspect errors and failures and try and
mask them and recover from them we can
have secure interactions you know all of
these things for instance have helped to
turn the web from you know the original
document server that Tim berners-lee
thought about to the backbone of
e-commerce today so you know as I said
surely with all the things that we've
done over the last 40 years
as an EU six were done that's it we can
all kind of kickback do something else
become farmers or whatever else takes
your fancy and let the world just build
on everything that we've done well
unfortunately the times have changed
over the last few years and certainly
over the last decade and that's going to
influence where we need to go in the
future with our middleware stacks so
just to give you an indication of what I
mean by that well here we have a 68,000
40 never show hands of who actually
remembers let alone use to 68,000 not
necessarily 68,000 40 but three okay now
I feel even older than I did why in the
room so 60 1040 was like the processor
of choice about 20 years ago it it ran
you know desktops it was the you know it
was basically like your your I 70s today
it was the thing everybody aspire to
have it pushed the envelope it was very
very fast let me put it that way well on
the further down on that screen on the
left hand side there's a 16-bit
microcontroller you can see that it's
roughly 8 the size of a penny this is
from five years ago and it has more
processing power than that 68,000 of 40
from the 1990s and that's five years ago
so you can only imagine the equivalent
today is orders of magnitude more
powerful has more memory on it than you
probably have on your laptop of a decade
ago here's a graph that I dug out from
that somebody did from 2010 that showed
the performance of various processes
that were running in mobile devices back
then so pretty much first generation
smart smart phones compared to the
pentium 3 arm hands up anybody who's
used a pentium 30 more great okay so you
can see that you know two years ago with
the exception of floating
point which you can pretty much
understand you know you've got your
nexus one your Snapdragon processor at
the bottom of that is beating a pentium
3 on certainly on integers and again
that's two years ago so fast forward to
today when we had the iphone 5 with an
a6 processor you know I've got a galaxy
tab laptop aside lock that cell pad
that's got a quad-core processor in it
pentium 3 which again was you know the
thing that was powering latin laptops of
1012 years ago and was considered to be
you know the fastest of its time
definitely faster than that now a lot
faster than that and if you look around
at the world that we live in today and
you know look around at what probably
you've got on your laptop and your pop
on your lap in your pockets maybe you
know at home these these processes that
are in mobile devices are typically also
in cars in you know ipods in cameras
these things are what some people of 30
years ago would have considered to be a
super computer and certainly of 60 or 70
years ago people wouldn't even have
imagined that we could ever ever need
let alone be able to develop all of this
has a significant impact on middleware
middleware for the next decade is going
to have to evolve and take into account
the differences in the deployment
environments and the characteristics of
these devices just as middleware 10
years or so ago had to evolve to you
know the evolving Pentium threes and
Pentium fours and multi multi processor
not multi-core but the small number of
multiprocessor boxes that were out there
so what this means is that there are a
number of problems that we haven't
really had to tackle up to this point
because the environments that we've been
developing for could really be classed
as last generation if you like
if we're thinking about the the next
generation as there's ubiquitous
computing the you know that as I said
they pose completely new while some new
challenges that we haven't had to
contend with to this point and I've
categorized these in the following four
things which we'll cover in the rest of
this talk so their coordination and
consensus multi-tenancy which is not
just for cloud large-scale data storage
and access and governance and
accountability so all of I mean about
coordination consensus well consensus
and consensus protocols have been around
in human history for thousands of years
and used in computing for a lot less
time maybe 40 years or so if you've used
transactions in for instance in it in in
a database whether it's an Oracle or my
sequel or db2 for instance then you may
have come across transactions and i'm
going to use trend transactions simply
as an example there are other other
areas where consensus protocols are used
but I a consensus protocol fairly
obviously is used to ensure that
multiple parties within some activity
agree on the outcome of that activity
and in a transaction system we have a
designated coordinator whose role is to
ensure that the parties come to this
consensus using a protocol the typical
one that's used is what summers
two-phase commit there are other ones
three-phase commuters is another example
but it's not that commonly used
consensus protocols today are typically
based on a central coordinator where you
have this designated party whose role is
to run the protocol amongst the
participants and to ensure that they all
agree to the outcome so in a transaction
system the coordinator will ensure that
all the participants agree to either
commit the transaction or roll it back
we have no participants that go one way
and others they go the other that that
would not become sensors
and consensus protocols today run with
our pcs typically our pcs that have
guaranteed termination protocols built
in so there's no way in which a
consensus protocol can just arbitrarily
continue until the heat death of the
universe for instance now as I said
typically they have a coordinate or
single coordinator but in just in a
distributor case you may have a tree of
coordinators which is what I've got in
diagram here it's pretty much the same
thing I only mention it here to show
that you know there are protocols that
that span multiple coordinators but
ultimately the outcome is the same the
route coordinator at the red circle here
is controlling the consensus down the
tree with the blue coordinates that are
the proxy coordinators and the squares
which are the real participants but the
protocol two-phase commit for instance
runs across all of these participants
the subordinates and the square boxes
driven from the top and it's synchronous
and everything even in the presence of
failures in a transaction system
everything will agree on the outcome of
the transaction as in to commit or
rollback because it's all driven by the
coordinator there's a lot of work that
the coordinator has to do for failures
such as logging for instance but the the
protocol will ensure that even in
presence of failures we have a
guaranteed consistent outcome that works
fine if you control the environment and
typically if you have a small number of
participants that dont span a large
number of network hops but what about
the you know the kind of environment
that i mentioned before the ubiquitous
computing where we've got processors
mobile devices let's just think about
mobile devices for instance in this kind
of environment it's extremely loosely
coupled and the parties are or
autonomous their peers there really is
no way in which we can have a
centralized coordinator or even a tree
of coordinators that doesn't scale it
creates a bottleneck and in the presence
of failures
then it also causes a lot of problems
and actually getting a resolution you
know in an autonomous peer-to-peer now
network of mobile phones the network can
go down at arbitrary points you know
just try using the network here or try
using white Oracle's why fights know
exactly the most reliable you might want
to switch off your phone and you will
still as an application developer you'll
still want the application to resolve in
a consistent manner in this kind of
environment as I said we don't really
have the ability to designate a single
part that participant as a coordinator
to drive the the outcome of the the
protocol we have multi-party
interactions it's asynchronous and that
means it's often truly asynchronous not
just a thread that's running a an RPC
that will then eventually join a truly
asynchronous fire-and-forget environment
is one in which there is no guaranteed
termination period the message goes out
and just because you haven't got a
message back a response back doesn't
mean to say that you've had a failure it
just means you haven't had a response
back yet that kind of environment you
need to take into a into account network
latency and other things in order to
develop a protocol that can still
terminate and still terminate with a
consistent outcome that the application
can then use in this environment we tend
to need to have the parties being able
to control their own outcome their own
destiny each of them needs to
essentially be at the same level as as
any other party in this activity they
all need to be able to make unilateral
decisions about their own outcome based
on their current state and the messages
that they have seen and maybe depart a
small number of participants that they
know are involved in the at in the
activity but without having to get
global consensus which is what happens
with a coordinator so here's a quick
pictorial representation of what I what
I said it's a typical one if you've used
amazon then you know this is this is
exactly an amazon you've gotta buy
you've got a seller who's amazon you've
got a shipper there's no
there's no need for a central
coordinator here each of these
participants the buyer the seller the
shipper is its own entity and wants to
control the interaction as it sees it I
could or you could model this using
two-phase commit you could model it
using a traditional centralized
coordinator model by a protocol however
as I mentioned before there would be
significant issues in terms of
reliability and fault tolerance it
really doesn't make sense particularly
when as you can see down the right-hand
side when the time between message
exchanges could be measured in hours and
days again traditional selling
transactions but traditional consensus
protocols tend to fail or tend to work
less efficiently when you're talking
about hours days weeks or months in
between message exchanges so what we
need to see in terms of improvements to
Java and Java Enterprise middleware our
new conversation message extractions
basically that allow for coordinating of
these peer to peer interactions without
a centralized coordinator but that allow
for multi lack multilateral termination
guarantees that give guarantees to the
application so that it can reason about
the state in which the conversation is
terminated there are a number of loosely
coupled protocols and efforts that have
been going on in the industry for a
number of years as I mentioned at the
start you know some some of this is some
of the work that we can talk about the
next few slides has been happening in
the Java world a lot of it has been
having at happening outside some of the
work that we have been doing in the
industry around loosely coupled
interactions has been happening in web
services and rest because Web Services
is as at one point or another being the
backbone of solar and service-oriented
architecture has always had loose
coupling as its main reason for
existence and if you look at some of the
web services transactions standards that
have been done in Oasis there's a long
called business activity which is
specifically about this kind of inter
actions not about using two phase commit
it's about having loosely coupled
interactions where the parties are in
control of their own destiny there's
also work going on in the rest
environment with something called rest
compensation which is basically very
very similar to business activity just
modeled in terms of resources but
probably the two most interesting areas
to look at our rosetta net and eb xml
has anybody heard of rosetta net rebe
xml to okay three there was a JSR around
some of the work that was going on in
rosetta net 156 that one so 157 they got
withdrawn i know that some java
middleware products i will mention in
competitors oracle has some work in the
Rosetta net space so despite the fact
that there aren't any standards here in
certainly in the java space there are
products that that push for Rosetta net
if I go back this down here on the right
hand side is from Rosetta net so you can
you can model these kind of
conversations in some Enterprise
middleware stacks in Java but not in all
and I'm hoping that you know that we'll
see a lot more of this coming in the in
the future whether there'll be a new jsr
round Rosetta net or some of the stuff
has gone or went on in eb XML I don't
know but what I hope we don't do is
reinvent the wheel despite the fact that
correctly I think some people can say
all eb XML was a little bit too heavy
weight which which kind of was there are
some really good things in eb XML and in
rosetta net I think we should learn from
without having to reinvent the the
eponymous wheel as we often seem to do
in software engineering so the next area
that we will need to see improvements in
certainly for Java is on multi-tenancy
now as I said at the start it's not just
for cloud but I'll focus on cloud just
for them so hopefully most people here
have heard about cloud enough over the
last few years at Java on and
other events to understand what i mean
by platform-as-a-service but in order
for platform as a service to deliver on
on on its benefits which is you know you
don't have to fork out for your hardware
for to sit idle for eighty percent of
the time you you know you pay for what
you need when you need it we need to
have high density of applications it may
be cheap for you as a user of platform
as a service but as a provider of a pass
who's building it on an infrastructure
whether you're an Amazon or a red hat or
an Oracle it's not zero cost you still
have to buy these machines you still
have to house them somewhere so what you
really want to do is cram as many
applications onto a device as possible
and ideally as many applications onto a
single VM image as possible
unfortunately typically Java middleware
stacks haven't been architected with
multi-tenancy involved so it
multitasking in mind and I don't mean
just solving the classloader issue class
loading is is a problem but it's not the
only problem with multi-tenancy what
this means is that in order to ensure
that we have fairly containment so that
a thread a rogue thread on on an
application that may be running
completely independently on a JVM from
other applications they're running on
the same same jvm in order to prevent
that rogue thread bringing down the
whole JVM we tend to run a single users
apps in a single JVM and have a single
JVM / virtual machine and that really
doesn't scale so the JVM hopefully
nobody in this room disagrees that the
JVM is here to stay whether it's Java or
not that's running on it I think that's
that's irrespective the JVM is is a
great piece of software you know if we
were to reemployment it from scratch
would look probably looking at hundreds
of man years and it's not just the JVM
itself all the languages that run on if
the ecosystem that's built up over the
last ten plus years with editors with
maven with all the other associated
things that we take for granted so one
way or another I think the JVM its
future proof but there are only really
two ways of solving this multi-tenancy
problem one is to make
the jvm so small and so lightweight that
you can run one app / JVM and not worry
about it and that's kind of the dalvik
route so if you've got an android phone
each of your apps is running on
essentially its own JVM so if an app
crashes it's not going to take down the
whole phone although for some reason my
HTC take crash on the way down here so I
need to figure out what was going on
there but I ultimately it shouldn't be
crashing the whole phone if an app goes
down the other way is to remember some
of the things that we probably or some
of us may have learned in operating
system classes and make the JVM much
more like an operating system so that
you can run multiple processes / JVM and
have them red zone protected what I mean
by that is that in your on your
operating system if it's a mature
operating system then if a process
crashes it's not going to take down the
whole operating system these days you
very rarely have to reboot your machine
if a process goes or goes awry you know
if you're running something like fedora
and you fire up a terminal and you kill
minus 9 a process you would not expect
the whole machine to die that's because
all of the processes are red zone
protected so we can have isolation and
independent failures that's the kind of
thing that we need in the JVM we also
need to be able to have more real-time
capabilities and have deterministic
scheduling and garbage collection
there's quite a bit of research going on
in this area unfortunately some of it
has been pushed out so there was work
going on an SE a particularly around
modularization if you've been keeping
track of that you'll see that that's now
being pushed out of SE a that's now
further out there was the JVM language
summit that was held previously to Java
one and there's some interesting things
going on there and I know that there was
some work that that you know ba and
others were doing in this area of a like
a real operating system for the JVM so
the rib there has been work going on in
this area there is work that is still
going on in this area but we need we'd
certainly need to see a lot more being
done in this and you know if you if
you're interested in this go and have a
look at what's going on and OpenJDK
because despite the fact that
modularization has been
asea I know that the work is still going
to happen in OpenJDK so that we can at
least get this into into the open source
community and people can start playing
with it and giving feedback so the next
big issue is what we can largely up so
broadly call large-scale data access so
relational databases are great
generalists you know they've been around
for 30 or 40 years most of them today
even in open source support acid
transactions they support strong
consistency and you can replicate them
so you no longer have to worry about
single point of failure you can have
multiple copies of your database running
on the same typically the same local
area network and they'll be strongly
consistent but they weren't really
designed designed for large-scale data
and by large-scale I'm not talking about
hundreds of gigabytes or maybe even a
terrible i'm talking about petabytes and
beyond and also a large scale it's not
just the quantity it's the it's the
distributed pneus of it so the scale how
far apart the data is also plays a real
role in what i mean by large-scale data
access these issues have resulted over
the last couple of years in a no sequel
and a new sequel effort probably most
you've heard of knew of no sequel you
may not have heard of new sequel it's a
term that was coined by the 451 group
about 18 months or so ago basically some
people some of the original developers
of our DBMS believe that there's nothing
actually inherently wrong with our DBMS
as far as scale is concerned in terms of
their the principle but the way in which
they were implemented than 30 years ago
they've implemented bottlenecks so
they've gone back and they've looked at
our DBA messes and they've reimplemented
them from the bottom up and this is
resulted in something called new sequel
which they believe are that they're kind
of it true in memory relational
databases they don't hit the disk at all
and they believe that they offer a
better solution to a lot of the problems
that we see the no sequel just give you
an idea of what i mean by large data
though
in the last 10 years so in the last five
years we've seen a tenfold growth in
data the end of this year the amount of
information that is stored on the
internet will top three Zita bites if
you were to write that information to
DVDs you would be able to to create our
of DVDs from here to Mars it's that
amount that phenomenal amount of
information much of that data has these
days either or location or timestamp and
therefore most of it is coming from
sensors or and or mobile applications
the kind of queries that we're now
seeing people do on this data are very
speacial or time to mention aware which
again is not necessarily something that
your traditional relational database is
very good at so this led to as i said
the no sequel movement and there's quite
a lot of no sequel efforts around
there's a number of categories there's
no tuple space there's column there's
document and there's graph-based
typically they go for a kind of a weak
consistency replication approach where
it's as you scale things up and you have
your your your replica sort of a better
term on different machines that are
physically remote from each other they
may not be strongly consistent they may
there may be some level of inconsistency
between these replicas if the replicas
are close by you may have domains of
strong consistency so if you're running
a number of cache copies for instance on
a local area network then the
implementation may guarantee that they
are strongly consistent but as you move
out of your local area network they may
just they may have a level of
inconsistency typically in order to
maintain consistency whether it's how
inconsistent whether it's consistent or
inconsistent they use a gossip protocol
so you don't have a protocol where
suddenly I will tell everybody stop the
world here's the latest update of the
state and now everybody moves on from
there it's I might tell somebody else
what my state is and then he tells
somebody else and then that person tells
to other people etc etc in fact in some
pro
calls no one member of this no sequel
group will know about every other member
of the no single group gossip protocols
have been around for a number of decades
by the way and they're very good for
disseminating updates in the presence of
failures but they there's typically no
bound on when the updates will have
fully propagated one of the downsides of
no sequel is that there's a thing called
cap theorem I'll do it again hands up
loser of cap consistency availability
and partitioning okay so cap theorem
basically says in any environment you
can either have you can only ever have
two of consistency availability and
partitioning so consisting availability
you can't tolerate partitions
consistency and partitioning you don't
have availability what what many of
these no sequel solutions have gone and
done is they've ignored transactions
because distributed transactions are
typically a strongly consistent protocol
and strong consistency in cap don't go
hand-in-hand so in some cases ignoring
transactions because of cap makes
perfect sense however in some
implementations they cite cap more as an
excuse rather than as a good reason one
of the other knock on side effects of
weak consistency though is that it's
weekly consistent it can be much more
difficult for developers to actually
understand when I do a read I'm not
actually really necessarily reading the
real estate that state may be updated a
millisecond or after I read it and I
won't necessarily know about it so it
becomes more complicated for developers
who who lived in this strongly
consistent world for 30 or 40 years and
also your requirements may change over
time so your your applications
requirement on consistency may move over
time from strongly consistent to
completely uncle inconsistent and back
again so a bit like i said to the jvm I
don't think relational databases and
sequel are going to go away they're a
fact of life they're very very good
generalists and most implementations
most deploys I've seen we're using no
sequel are using it to augment
relational databases I think we will we
are actually starting to see a lot of
the no
a sequel vendors who had given up on
transactions now coming back to
transactions and looking at what are
known as extended transactions in the
North sequel space or an extended
transaction is where you can relax in a
controlled way some of the acid
properties and again the business
activity spec that I mentioned earlier
web service is an example of an extended
transaction and in fact some no sequel
implementations have moved to say we
will support strong consistency as the
default with full acid semantics but I
think we'll see a lot of exploration in
the selling in open source and in the
research community between trading off
strong and weak consistency what it
means for application developers what it
means for the underlying implementation
and these days memory is the new primary
store it's very very easy to just ramped
up 16 32 gig of memory it's very very
easy to just have a heap size so big
that you really throw a lot of the data
that you're doing you don't need to ever
think about disk that has an impact on
applications it also has an impact on
frameworks and some implementations that
have been implemented with the
assumption that disk is always going to
be a certain level of speed compared to
the application transaction systems for
instance I keep coming back to
transactions but again it's just as in
them just as an example transaction
systems have been implemented over the
years using a log to record where the
transaction is as it progresses so that
if there's a crash we can recover and
continue the transaction the disk is
typically where the log ISM is written
and the disk is slow compared to main
memory the disk is often slow compared
to the network so transact transaction
systems over the last forty four decades
their implementations have spent a lot
of time optimizing the log making it
typically like a pendulum right once and
maybe you know I so write many and read
once during recovery a lot of effort has
gone into that if you take the disc away
and say that you don't ever have to hit
this and you only ever have to hit
memory and memory is so reliable and so
fast then
maybe you don't have to spend so much
time on the log maybe the log
implementation is no longer needs to be
something no longer so complex and there
are other trade-offs other areas of the
transaction environment that you now
need to optimize there's a lot of effort
going on in no sequel in the jsr or I
say a lot there's two efforts this Jess
r107 which is caching and there's jsr
347 which is data grids I expect it's
certain well I had hoped in the seventh
time frame but that's not going to
happen so it's going to be e8 to see
more snow sequel standards making the
way into the JCP I still expect to see
that but like I said I think it's going
to be ESET aee 8 it's very very
important that we do this as in push
more Jay Sowers in this area because at
the at this point people talk about no
sequel as though it's like sequel as
though there is a standard there is no
sequel standards for no sequel even
amongst tuple space vendors or or
graph-based vendors there is no standard
it's very easy to get locked in to one
no sequel implementation and not be able
to move off I would really like us to
see a lot more effort going into
standardizing some of these things so
the the fourth issue is governance and
accountability so if you think managing
local environment is hard enough well
obviously think about what it means to
manage a distributed system it's an
environment where you may not even
control the whole infrastructure you may
not have access to the whole
infrastructure to monitor it you may
have to work with your peers in other
organizations and the failures that can
happen in a distributed environment are
much much wider you can have the failure
of a component that takes down another
component in a completely different area
of the network you can have network
partitions that eventually heal or that
never heal you could have participants
just because participant a can talk to
participant be doesn't mean to say the
participant be can talk to participant a
for instance a large-scale distributed
systems are even more complicated to to
manage
I would not want to manage the web for
instance it would be impossible if you
look back at the ubiquitous computing
slide that I showed it at the start just
think about trying to monitor and manage
all of that it again is going to be
almost impossible and then we start to
move into the areas of trust if you
don't control the infrastructure it
becomes even more difficult to trust it
and as a user you you know if you're
using your back office system in your in
your VPN hopefully you trust what your
IT and your IT people give you that it
will work and that they're not going to
leak your details to somebody outside of
the VPN but if you're using somebody
elses system that you don't know in fact
you don't even know who they are why
should you trust them governance becomes
extremely critical in this kind of area
governance and trust you need to ensure
that you know what services are running
what service level agreements are up and
running on each of these services and
have something that monitors these
service level agreements and lets you
know when when they are violated or even
if they are about to get violated so
cloud and the same can be said for for
mobile what cloud raises some very
important issues of trust and
particularly around storage there are
legal implications of using third-party
components in certain countries as well
one of the reasons I think that private
cloud is probably going to be far more
important than public cloud is that
hopefully private cloud if you're using
your back office system you will not
have the trust issues that you will have
with public cloud despite the fact that
a lot of people are storing things on
public clouds for instance amazon if you
read the small print that an amazon
gives you all bets are off you know when
the Amazon outage happened a few weeks
back and then the one that happened a
year or so back the small print
basically says you know sorry you can't
sue us and you know if we leak your data
sorry but again you can't sue us so
trust is is something that needs to
improved significantly in cloud sir liam
in public cloud in the area of trust
there's also an area of accountability
if I say I'm going to do something to
you and you agree with me that you want
me to do it later on if you find out
that I didn't do it it's very it can be
important in legal in a legal situation
for you to be able to prove that I said
that I would do it and that you enacted
on that that's accountability again in
cloud both public and private at this
point we are missing a strong
accountability so ideally what we should
have for cloud is this notion of a
flight recorder a black box now I'll
kind of skip to the to the last bullet
here because all of what goes before is
kind of summarized in that there is
there's a component hardware component
called a trusted platform module anybody
heard of a trusted platform module okay
I if you if you want or I encourage you
to go and look up TPM trusted platform
module basically if you if you have a
machine that has a TPM on it that
trusted platform module maintains
information everything that happens on
that machine in a non reputable
accountable manner in fact in a way that
can be used in a court of law something
like that for the cloud is critical for
the cloud to really succeed for big
businesses for any business to whether
it's a bank or a health care system to
want to move its data to the public
cloud you'll have to have something like
this and at this point there really is
very little research going on in this in
software it's all been happening in
hardware and there's not a lot of
hardware that has tpms there's a hell of
a lot more on my french there's a lot
more cloud hardware out there that does
not have tpms in it that has TPM so a
software version of a trusted platform
module I think is critical for cloud for
the four I said for the success of cloud
so the next decade I think certainly of
Java middleware has got to be defined by
ubiquitous computing enterprise
capabilities are a necessity the types
of apps that we think we're running
today on our mobile devices and pads
they may be games but they're really not
going to be game so very much longer in
fact if you look at what's going on with
the Department of Defense giving
smartphones to every one of the gut army
guys healthcare environments probably in
the US but certainly in the UK giving
pads to doctors and nurses so they can
access patient data across the network
and putting RFID chips on drugs the
applications that are running on these
devices are growing in complexity and
require enterprise middleware
capabilities java should play a leading
role in this the JVM should play a
leading role in this there are issues
that need to be resolved in the JVM and
in enterprise Java middleware in order
for us to ensure that we can play that
leading role because you know one way or
another whether we do something with JVM
and Java and II 78 or not these problems
aren't going to go away and somebody
else somewhere is going to solve them I
would like it to be on the JVM with Java
or with a non Java language running on
the JVM and as I said at the start I
think it's a very very rich area of
research and development for the next
decade and hopefully some of you will
want to get involved in it and push the
standard before I open it up for
questions if there are any I just leave
you with this quote from Richard Hamming
who gave a speech when he accepted in
1968 cheering award and basically can
summarize it as not invented here
syndrome so
any questions no questions yes so I say
that because sell you from football fair
enough for two reasons the first is I'd
be saying for the last three years and
it can just comes out because I really
do believe it i think that the trust
issue the security issue the fault
tolerance issue it's it's a big those
are big problems with public cloud and
hopefully they've been solved by you
know your IT department ain about i.t
you know I complain about i.t I can
never get a mailing list crater in less
than two weeks but the infrastructure is
that they pull up typically are pretty
good and if they crash I can lift a
phone and I can shout down the phone at
somebody and they'll fix it I don't have
a direct line to amazon for them to fix
it the other second reason is certainly
when we've been talking to our customers
we're getting a lot more drive from from
customers on private cloud than on
public but for these reasons as well but
they've also they've gone and invested
you know they've spent millions of
dollars on back office systems and they
want to keep using them they want to use
public cloud for cloud bursting and in
which case they need the security and
the fault tolerance issues to be
resolved but ninety percent of the time
they're going to be using cloud on the
back office on their existing
infrastructures oh sorry um well red hat
i know i mean that because an awful lot
of people are running you know linux in
one way or another fedora rel centos
like it or not probably microsoft and
it's usually not and it'll be the usual
suspects like
an IBM and i would say HP but not these
days so probably IBM Microsoft Red Hat
maybe SI p you know if they can get
their act together some of the public
cloud vendors like you know Google and
Amazon I suspect they'll try moving to
the back end I don't know how successful
they'll be I wouldn't discount them them
any other questions because well i think
that the future is is ours to lose i
don't i don't say that as a kind of a
glib statement i think if you look at
you know dalvik its kind of optics kind
of java it's not really job but it's
kind of java and a lot of the cloud
platform as a service that's out there
if they if the platform the service
vendor didn't come out with java to
start with they followed up with it
pretty much but pretty much pretty
quickly afterwards if you look at a lot
of new languages that have come out
right so i've been in the industry for
best part of 30 years I've seen lots of
languages come and go and I've seen lots
of like explosions of languages but I've
never seen as big an explosion of
languages as I have in the last three or
four years now we've got huge number of
languages I counted the number of
because I'm doing a different talk but
the number of languages running on the
JVM is it's like 18 plus things like ADA
for god sakes who wants to run a drone
JVM but apparently some people do and
people who come up with new languages
they either target the JVM first or they
pour to the JVM pretty quickly after
that the JVM is is the place to be so
like I said I think it's the future
whether it's running on pads mobile
devices sensors laptops desktops
in the cloud it's it's java-based it has
to be all we've really fumbled the ball
but we could fumble the ball by not
addressing one or more of these issues
that are put here like them for instance
the multi-tenancy want if we don't
address the multi-tenancy issue it's
going to become much much harder for us
in some areas any other questions ok
thank you very much for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>