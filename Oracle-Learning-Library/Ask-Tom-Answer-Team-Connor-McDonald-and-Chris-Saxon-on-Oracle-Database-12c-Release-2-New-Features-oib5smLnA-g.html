<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ask Tom Answer Team (Connor McDonald and Chris Saxon) on Oracle Database 12c Release 2 New Features | Coder Coacher - Coaching Coders</title><meta content="Ask Tom Answer Team (Connor McDonald and Chris Saxon) on Oracle Database 12c Release 2 New Features - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ask Tom Answer Team (Connor McDonald and Chris Saxon) on Oracle Database 12c Release 2 New Features</b></h2><h5 class="post__date">2016-11-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oib5smLnA-g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is Connor McDonald
I'm with the developer advocates team
and I'm here today with Chris Saxon
alright this is the continuation of the
OD tag code talk series we're gonna talk
about some of the really cool stuff in
12.2 which will be coming out shortly
after open-world so first I'm going to
speak about today Chris Wright is index
monitoring or index you should striking
so you say this is something in 12 -
haven't hasn't this been around like
since nominee or something like that
well that's true we've had we've had a
crack at this before darlin and you know
you know in all honesty it probably
wasn't our best effort it was useful
they're not spectacular so you can see
here on the slides what we use through
an oral nine we do alter index my index
name monitoring usage and we had a
dynamic performance review video feed
all the object usage and what would
happen is if you passed a query and the
plan was going to use that index then
what would happen is we would set the
fact that the index is being used - yes
yeah so that it works yeah there's a
number of issues with that go on number
one is it's a yes or no so if we pass a
thousand queries look at that index that
index is probably pretty damn important
we simply say yes it was used we can't
tell you was used two thousand times or
once or whatever we can't tell you if
you just did an execution plan right
yeah so you might say just explain plan
yeah exactly
and we say yep an index is critical yeah
and obviously we don't know your
application so as a DBA you might just
be sort of looking that index and we go
on we pass the crew is index we say yes
if you wanted to sort of get some idea
of how often it's being used the only
way you could do it was to turn off
monitoring okay and then turn it back on
again yeah yeah yeah what do you have a
snapshot of periods and see when it was
and wasn't you exactly turned off Morris
turn it back on and you know jump back
and forth the other problem is it's a
pausing thing right so what happens if I
need to use an index but it isn't in the
query that I'm pausing right now
probably the most simple example that is
I say a parent child
foreign key relationship okay let's say
I have an index on a child table and so
I have on delete cascade and so on the
child if I do a delete from the parent
delete from my parent and doesn't use
that index yeah
the subsequent on delete cascade
desperately needs a yes but if we look
at V dollar object uses okay you're good
yeah we didn't use that charlie next you
can drop it yeah you drop that index the
next time you try to delete it you know
you go get a coffee or if you think
you're getting coffee and come back
everyone screaming everybody go come is
like yeah ah 112 is missing so so that
that's the problem it's looking at index
usage just on a passing basis missing
dramas so we've had a fresh look at this
okay
and the motivation of this is pretty
simple is indexes are often seen as as
the the golden solution to everything
yeah I've got a query it's slow it could
be the worst piece of SQL ever written
yeah no one cares Emma says add an index
yeah and very quickly you have a table
with ten columns and 500 indexes in the
various permutations of all those
columns because everyone just keeps
saying add an index an index a genetics
so I don't think we'll ever stop that
yeah be great if we could I don't think
we'll ever stop that what we do need is
some means of saying well let's maybe
take a monthly or six month look at
those 500 indexes how many do we
actually really need so what index
monitoring does is now is as your system
is running at execution time okay
we'll look at those indexes hmm and so
we had this view DBA index usage and so
for each index we'll have the number of
times and it was accessed but also we
had the sort of general histogram of how
often it was used in terms of how many
times was accessed and how many rows
actually came back from the index and so
that's quite useful because we might be
able to use this information to work out
how valuable indexes we might use an
index once but we might still say it's
just not worth the effort yeah you know
if they're that one-off query let's let
that run query run a bit slower because
it'll gonna speed up all that DMLs
yeah so you get some idea of priority
and you
attack the most or the least used
indexes and say yeah and so it's often
that balancing and balancing active you
know that in a perfect world yes I'd
love a thousand indexes yeah
but the reality is I can get away with
three yeah exactly
one of another nice columns here are
some sample data here's and yeah we have
last used and obviously that's gonna be
usable because if it's used every six
months maybe we can get away we had it
so it sounds pretty cool so how do we
enable it it's always on always it's
much like you might remember a table
monitoring which came in in 8.1 you'd
have to turn it on and then we made the
code really efficient inside that inside
the database kernel and we could always
leave it on and now we use table
monitoring for DBMS stats and all other
stuff this is the same right it's just
gonna be on um I don't think you can
even turn it off it's just okay it's
just always there just chugging away in
the background looking you indexes no
cool something so one thing I should say
is I mentioned before it's about when we
execute
yeah the queries go there is one thing
that's it's this is like a boundary
conditioner that's quite interesting is
just because we're monitoring every time
you execute queries can produces an
index that doesn't mean that you can
take your brain out and put on the shelf
and forget about and say this will solve
all my problems
yeah we have to still be aware that
indexes might be used for other things
right here's an example this this is a
interesting example I've got a table
here called t1 it's got a few columns if
I do this query select count star with
c1 equals 12 and c2 equals 12
we get 200 rows back let's see what the
optimizer thought about that the
optimizer thought there was only going
to be four it has a bit wrong in there
but that's fair enough because by
default we don't have any stats on the
correlation between columns and I
manipulated the example to really upset
the optimizer if I had an index on those
columns c1 and c2
notice the optimizer now gets the
estimate right now that's pretty smart
of the optimizer
what it's done is it's managed to work
out that using some stats contained on
the index right I can use that to
optimize my query yeah you notice it
actually still it's used for that full
scan it didn't use the index for the
execution it used the index to come up
with some good numbers right now because
we didn't use the index on the execution
it will not be classed as oh I monitored
that index
yeah okay so if I raced out and drop
that index yep it's you potentially I
potentially changed the way the
optimizer looks at the world yes and
therefore I might change some plants so
obviously we can get around that we can
use extended statistics on those two
columns to replace the information that
we've got gleaned from the index but
it's just worth noting that just because
index hasn't been used an execution yeah
doesn't mean that I can just cut by a
choice blow it away it's you know to be
careful a little bit of thought is still
required a little bit thought is always
always doesn't it that's right you never
follow recommendations blindly yeah
exactly
so you've got to make sure that you keep
like the definition in the index and
just take a little bit of care I guess
before going whole hog exactly and one
of the cool things with them extended
stats is you could in eleven point two
and up we've got those automatic column
groups so we could enable that and
actually let the database work out for
itself what Colin grits might be
required yes and that's going to
insulate yourself from those kind of
issues that's a really good point there
okay so it's index uses is pretty cool
so that was index usage what's next
color this is huge okay this one's
called analytic views now anyone that's
been to my youtube channel knows that I
do a lot of talks on analytic functions
and Elinor sequel this is related but
not the same topic okay analytic amuses
different yeah and they've uses a whole
brand-new sort of subsystem framework it
takes advantage of some analytic
functions and its sequel but it's quite
a distinct yeah instead of functionality
probably to set the tone for it right is
I know you're a fan of good data
modeling I've you know you you do the
data design questions on Pele secret
challenger good data modeling is
sometimes really wasted this is a sad
thing is you really said that you know
we'll come up with these beautiful data
models you know such that yeah our
tables reflect sort of this perfect
world yeah I'll have a table of
financial results it'll have a column
called what's the fiscal year yeah and I
have a column called profit yeah
and so anyone with even the tiniest bit
of secret knowledge when someone says
what's the profit for 2006 right yeah
that's pretty simple
yes Agnes lick some of the profit column
yeah from my financial results table
with the fiscal years 2006 yeah it can't
be that hard and you come up with a
number
mmm and that seems you know what's meant
to be this is also a magical place which
seriously
we can't just query the database and get
results I know it's it's a terrible sad
thing that you know that that's how it
should be yeah you know data should
reflect the real world of the business
and and it starts out that way yeah and
then what happens is tools come along
evil things called tools where you'll
have a database and then someone says
well I need a bi tool because I want to
do things like hierarchies and
dimensions and aggregations that sequel
just can't do right so what happens is
we put a framework on top to make life
easier for the users we might use
something like Cognos or Business
Objects all those various tools
well our and B our publish up rather
than just being them being a window into
the data just simple queries into the
data
there's the results they become a data
manipulator your profit might come up as
10 million from the database yeah you
know and your report when mobs onto a
desk
yeah we're quite proud of ourselves we
look after the data warehouse we open up
the annual report nurses the profit was
ten million one hundred and twenty three
thousand four hundred and twelve and we
go pretty sure that wasn't the database
yeah and that's because in the BI tool
they've taken that data and they've done
manipulations on the data if you look
inside the BI layer it says the
attribute called profit isn't select
some profit it's like some profit then
take out public holidays yeah then we
have this perturbation factor called
0.98 which we apply when the sales came
from an overseas country then there's
our there's this fringe benefits tax we
need to take into account and there's a
goods and services tax and and there's
all these appreciate something and you
write off something else and and all
this stuff gets in and do you think
anyone ever says you know we should
reflect that in the data that a basic oh
we'll just take advantage let me know
we'll just use the BI told now we're
just yeah a little formula here etc etc
and so you get these disasters where
then the auditors come in yeah and there
you go we're doing in order to it says
here this is what your profit was can
you help us out show us how you got to
that profit and we go
no problem we'll run the query and then
we look really embarrassed when what we
have you know doesn't do this but the
owners are really happy unlike orders
like that fantastic and the problem is
is in the utopian world
sequel was meant to be our our our black
box
ie we take data run it through a sequel
black box and there's profit mm-hmm the
problem now is we've introduced lots of
black boxes we take data we put through
a sequel layer and come up with a result
we put that through our bi to a lab and
what the result then like there's the
worst black box that's Excel where the
the final result comes out we give it to
an accountant in the organization he
goes you know I know better
yeah I'll just do a little bit a little
bit of work here little bit away a
little bit of shuffling around here that
belongs in last year's fiscal year and
etc so you know you know you end up with
ultimately nonsense yeah and of course
because most companies have more than
one financial person you know have seven
definitions of profit yeah yeah and so
there's one of the annual report there's
the one that you thought was in the
database and there's 12 others which
goes through an emails and Excel
spreadsheets and etc etc and you just
lose control of your information so
analytic views is where this comes into
place what we're trying to do is rein in
all that complexity yeah it's it's
almost acknowledgement that complexity
will never go away right we're never
going to replace that utopian view on
the data
simple sequel there's a result so that
complexity needs to live somewhere but
what we don't want to do is have that
living add in user excel and in 12
different BI tools yeah because the
moment we've got more the
one definition of profit we have no
definition of problems echo yes
so what analytic views are is let you
reigned all that complexity back in and
define it inside the database okay
now you might be thinking well that's
just a view just a normal view but an
analytic view lets you reflect the kind
of things that we would normally do in
the BI tools as well in terms of
hierarchies that in a department belongs
to a region a region along to a country
etc and also defines how we would roll
up information across those hierarchies
right okay we also that do things like
often like reports will have things like
here's the sales but also here's the
sales as a percentage of something else
yeah or here's the quarterly sales as a
percentage of annual sales okay normally
those kind of things would require some
pretty complicated SQL maybe with some
analytics etc to get that stuff all to
work out if we can put those
relationships in the analytic view then
the end user doesn't have to come up
with very complicated SQL we simply say
you know quarterly sales rolls up to
annual sales right thank you and we
define that in the olymic view and what
we're offering into the user is you'll
never need to do a really complicated
SQL you just do slate my results from my
analytic view yeah with the regions
California where the fiscal year is this
year and by the way I want it rolled up
by cuarto and by month exception so they
don't have to come up with all those
analytic functions and aggregations
whatever that's all defined in the
analytic view okay and we're trying to
get back to what we are hoping to get in
the first place which is I have data my
users have simple sql's and somewhere
magically all the complexity has been
defined know and defined once yes so we
can get back to that kind of single
point of truth we put that information
in the database everyone can select it
and I get the same result
exactly I know security is important to
you Kanha and we all want to protect our
data and then some there's some new
features to help with that in 12 - it's
funny you talk about security the other
day I just got an email from Dropbox
yeah going change your password change
your passwords like okay one of the
things that obviously inside Oracle
we're big on security we did the
software and silicon security on the
chip encryption on the chip so it's good
that even sort of at a much more simpler
scale just what's important to
developers and DBAs there's also changes
in security in 12.2 and that's the thing
that I always find interesting is is it
used to be if you had a hardware adage
as a company that was a big deal you're
all over the news like you know recently
those I think Delta had like a power
outage but yes of you know you see on
the internet like you know don't have a
power outage you know as you were had an
outage in their cloud Google had an ad
in their cloud and and all these things
they make they make headlines but it's
some like people run screaming from the
building going we will never use
provider X again we will never fly this
you know this airline again it's not
such a big deal anymore high outages
people almost accept the fact that you
know that they're rare and there's a lot
of mitigation circumstances around them
what will kill you nowadays is if you
get hacked yeah it's funny how you know
you know if I can't log on to a website
Oh a big deal I try getting out if the
website says look we've lost all your
you know credit card details that's
that's massive and so it's it's funny
how you actually often see now that
companies get put out of business when
they get hacked you know because that
consumer confidence just this just
absolutely just kills them this is a
quote you know what does my one of my
favorite quotes consumer trust is the
new high availability right now the
reason I like that quote is because I
came up with it I'd love to say I was
done by some expert but now I just I
just I I dreamed it up but if it is true
is its customer trust is the definition
of high availability nowadays you know
it's not whether your site is up all the
time it's whether people have faith in
your site you know it's like when Ashley
Madison got hacked yeah like you know
let's get it but I wouldn't know
anything about that
the problem with security and then this
is like another quote stating the
obvious is it's not easy and and if you
do a quick Google you'll see like heaps
of websites that have like here's your
checklist of things you should do yeah
and it used to be the checklist had 10
items on it yeah now that is a checklist
have like 10,000 items on about you know
took all these passwords check all these
profiles tick who's got privileged to
this ticket previous to that whatever
it's so big nowadays that companies
makes you know a lot of money selling
services for that but the other thing is
it's so big that people don't do it yeah
it just becomes ah it's just too hard
that's right
and that the days of people bring up my
mom used to have a really basic password
system because she was unaware that it
was important she's now very aware that
it's important she's less than done
anything about it because it's hard it's
just hard to manage so what we've done
in 12.2 and in fact this is actually
available even not in 12.2 people can
get this available today is this thing
called DB set ok database security
analysis tool and it's pretty cool all
you do is you go to my Oracle sport and
you download a little zip file and what
it does is it does a good chunk of that
work that you would ideally not have to
do yourself
so you unzip it run on your system it
creates a little simple user and then it
runs through and does all those things
that are on those checklists you know
which passwords which accounts are
unlocked and maybe should be locked
which things don't have a proper profile
on them there's just a whole list of
things that goes through and checks yeah
and the good thing is it'll I'm assuming
it'll be something like Oh patch where
from time to time it'll get updated and
you can download a fresh one from a link
but what happens is you can sort of see
you run this thing through it runs on
your database click some information and
at the end of it you get a nice little
HTML report oh yeah and it just shows
you you know just certain the other and
you get sort of a passing smaller and
stuff like that so the nice thing with
this is the tool is free
you're kidding me that's not a typo
that's like yeah that's actually free
tool yeah you downloaded from meddling
and yet basically just run it it's it's
trivial to use and you can last report
at the end there and even if you don't
do anything about it which would be
wrong yeah we suggest you know look at
the recommendations and take advice on
them but even if you didn't you've at
least gone that one step forward in
terms of identification and also you
know for those people that are being the
employee remuneration is ranked on the
diligence on security at least then
they've got something to actually it's a
tangible thing they can produce and show
their manager saying look I'm actually
actively engaged and trying to pick my
security issues and okay then condone
what's up next
um cloning okay now funny I've done
talks in the past on a facility called
clone DB which is actually using
Oracle's direct interface and that's
actually been around since 11.1 and
anyone who's not familiar with clone DB
do some googling forward to go to meddle
Inc or my Oracle support that's a really
cool feature and you can use that you
know on any database this is more the
concept of cloning when it comes to a
multi-tenant so in cloning we can do it
in 12.1 mm-hmm and it's actually not
that hard to do you can see here that
all we do is we set the database to
read-only created like a would say it's
clone it we got to set our database
read-only so if we want to clone our
production system people can't write any
changes for a few minutes yeah well that
might be a bit of a drama yeah I'm going
to do a production database okay so but
I'm glad you brought it up because you
know 12.2 right let me fix that kills in
12.2 we have plot cloning so what
happens here is whereas you used to you
have to do alter database read-only
create your pluggable database open up
your new database and then open up your
old database again mm-hm
those initial steps have gone cool so
what happens now is your database
remains readwrite mmm which I take your
point of production that's probably a
good thing yeah but yeah you simply
create pluggable database from products
and copy from production may be found
conversion and off it goes the way that
works is think about like hot backup
yeah
the way a hot backup would work is you
would copy your active files across you
would then copy and apply your redo logs
and it's then effectively hot backup
plus instance recovery right so we copy
those active files copy the redo across
then we apply that redo to resurrect the
undo information and that effectively
then lets us rollback uncommitted
transactions so it's almost like more
sort of data guard metaphor but like
your hot backup followed by an instance
recovery and then you have your clone
pluggable database ready to go one of
the things that's you probably want to
be looking at doing there is in 12.2 we
also have a thing this is more of a DBA
featuring all the local undo ok so
what's that in 12.1 in fact nadal
database since before that you would
have one undo tablespace per database if
you're running RAC you'd have 100
tablespace per instance that we 12.1
with the pluggable database concepts we
still had one undo shared across all the
pluggable and which is fine and that's
still supported in 20.2 but one of the
things you have in 12.2 also is the
ability to use a thing called local undo
and when you turn local undo on what
that does is now you get an undo
tablespace / pluggable right okay now
both what so the old undo style is
now called shared undo and the new style
is called local undo both are supported
in 12.2 and you can almost do all the
operations that you would normally do in
12.2 with either mode of undo just with
local undo some of these things a bit
easier so in particular hot cloning with
local undo is just as we saw in the in
the slides they're simply just a one
line of command and and pretty much the
job is done after you've done the clone
right you're gonna give me a gotcha now
there's two general reasons why you
might want to do a clone mm-hm
you might copy soap rod back to you IT
environment and then you might me use
that UAT in Ramat to do all sorts of
things
in the modern world what a developer's
what nowadays they want their own
version of the database yeah their own
copy yeah so especially if you're doing
things like unit testing or just some
sample queries and stuff like that yeah
there might be demand to actually have
hundreds of clients and you want to be
able to grab me a clone do some work on
it or do some queries on it and then
throw it away
give me another clone because the
production database has moved on yeah or
whatever database you're copying has
moved on what used to be the problem
there is you know if that's a fairly
large database cloning is pretty busy
yeah I'm pretty expensive what we've got
now in 12-2 is after you've done a clone
if that clone is left read-only mm-hmm
right so not your production one there
but if your clone is left freed only
okay what you can do is do alter
pluggable database refresh the clone
okay so will it'll actually bring it up
to date with what the current version is
so that's kind of thing like a bit like
snapshot standbys that you'd have effect
if you'd like that yeah so what happens
is I can take a clone yeah keep it
read-only next day refresh my clone data
gets brought up to date Yeah right
and then next after that refresh the
clone again hmm so that's a really cool
thing especially for that developer
mindset of I want to see some data I've
done some read only testing I've done
some unit testing but now I want to
throw it away and get the next version
so I view that as possibly a scenario
where you might have a common test
database that testers use and developers
can then take clones of that almost at
their leisure without interrupting with
the test data that's really cool because
it's really useful for things like
investigating production bugs it have a
recent copy the data to actually be able
to see what's going on isn't it exactly
so I like the refresh concept you know
there is still a restriction that if you
actually open your clone readwrite and
then you break the ability to do a
refresh yeah but that's probably
understandable because if you go and do
all sorts of yeah you've really broken
that link I'm so yes that some hot
cloning yeah and yes you don't have to
take that primary drive anymore really
cool that's great okay so I understand
you've been looking a bit of material
so talk a bit about that um yeah
materialized views been around obviously
forever and one of the cool things that
came out geez mom be as far back as 0.1
is query rewrite yeah which is I always
really enjoyed this because you don't
have to teach your end user community to
use materialized views you simply let
them use the queries they were always
running and the database comes on it
says ah you're doing an aggregation by
month for sales yeah I've got a
materialized view that does that I'll
just rewrite your query silently and run
it the problem with that is one row
mm-hmm like one lousy road yeah can
really mess up your date yeah because
you might have a table you know with
billions of rows and data warehouses now
these you know they have to have yeah
and and you've done you know you've
become like this materialized view hero
mmm
because you'll have a query that runs
for hours yeah like you know say sum of
sales by yeah the business users will
come to you and they say look this is
killing it's running than ours what can
your help and then you'll create a
materialized view to serve that purpose
and you're like materialized view
superhero because all of a sudden this
credit ran for hours yeah runs
sub-second yeah and they didn't yeah and
they'll never know that their query it
looks like it's summing up all the rows
in this massive table is no longer
running it's actually silently yeah
running as materialized views so as we
spoke about before in analytic views the
the utopian view the data is perfect and
never change and manipulated is a bit
false in the real world so what happens
is will have this sales information that
says great 70 billion rows yeah and then
someone says we need to make an
adjustment and they'll add in one row
being some sales adjustment you know for
something that was wrong all of a sudden
your materialized view is no sale
established by one row at its best
rating isn't it and all those people
running those queries that used to be
silently rewritten to you materialized
view and no longer rewritten
and so all of a sudden although
sub-second queries for which made you
the materialized view hero all of a
sudden you limit really bad I hate you
looking real exactly everyone or
anyone's like you all I can see is that
stupid hourglass on my screen yeah and
you promised us it would be fast yeah
and that's the problem so very quickly
you have these emergency changes okay
quick let's refresh the view Norma gets
refreshed each night but let's refresh
it and as the world becomes more 24/7
you start doing these data adjustments
during the day mmm it's the next thing
you know we're refreshing the view every
minute yeah every five seconds and it
just becomes a new strain your neck so
what happens now is in 12.2 we've
created a amines now where you don't
have to just get into this endless cycle
of refreshing the materialized view
hoping that you're gonna pick up many
data changes we've this thing called
real-time refresh okay now you might be
thinking don't we have on commit
materialized news yeah it's not an on
commitment realize view it's actually a
taking materialized view that's stale
but when someone runs a query and I want
to do a rewrite write effectively in
real time refresh the materialized view
just for that query okay so it's just
applying those changes since it was last
refreshed if you query the materialized
view itself you still get the original
data exactly right so what happens is we
might even have an explained plan here's
an example of a materialized game so
I've got one here tmv and the new
keyword is enable on query computation
and what's actually happening is is
there's a normal materialized of you
rewrite explain plan mm-hmm now I put a
row into my table if I make my
materialized view stale when I rerun my
query it's still using the materialized
view right and still gets the correct
answer mm-hmm now you might be wondering
how does the data because a stale yeah
so if we look at the explain plan you
can see it's almost quite a bit
dramatically so what we can do is we can
break up into three sections here it's
because it looks like it's in sort of
three logical sections yeah the first
one is effectively
grab the existing table grab your
materialized view log and apply all the
deletes that live in the materialized
really yeah then we might apply all the
inserts and the final stay is apply all
the updates yeah
so what we're actually doing is doing
the refresh processing mm-hmm
just for this query yeah and that brings
our materialized view up to date for
that query I should stress it doesn't
change the materialized view it is still
stale right but the query shows
up-to-date data that's pretty cool now
obviously if you've got 10,000 changes
in your last view logged it would be
better off just to refresh materialized
view yeah but this is more for that case
we spoke about before some of the some a
couple little changes that come in dribs
and drabs and so we can make sure those
queries still get rewritten and it's
gonna be heaps better than five our run
time yeah so you've given us a lot of
cool stuff so far I think we've got one
more feature to cover corner yep
exchange partition okay now I know it's
been around like yeah it's funny how you
know exchange petition the reason we've
done something into open two is because
a is producing one of those things that
causes a lot of confusion for developers
and DBAs because sometimes you can do
the same position you just alter table
exchange position it says done yeah
sometimes you can't you can't and it's
not immediately apparent why right and
and we'll fly through an example here so
you can see I've got a table here called
path mm-hmm it's got two columns x and y
and it's got two petitions here's my
table called exchange part this is the
one I'm going to exchange in it's got
two columns as well same column name
same data types yeah everything's the
same when I tried to an exchange
partition hmm it says I can't it says
there's a column part sounds a mismatch
and that's the thing and and this is the
thing that created so much confusion hmm
is that I've got two tables seemingly
identical hmm I should be able to flip
one petition out with this one in but I
can't the reason for this is somewhat
historical when partitioning came in an
8.0
the columns you had in the table pretty
much with the columns you always had you
know you are the added columns that was
it you start
for five columns you might add a six
yeah that it reflected the state of it
as we've got smarter with all the
features inside Oracle that's changed in
8.1 you could actually set a column to
being unused and yeah in version 11 you
can make columns invisible yeah in
version 11 point 2 of this thing called
fast default where you can add a column
give it a default value right and it's
immediately back populated without
actually backpal physically actually
updating all the rows the way we've done
a lot of those technological changes is
by adding invisible or hidden columns
and into the database dictionary so what
happens there is is even though table
might say I've got two columns x and y
there might be several other columns on
the table reflecting the changes that
had gone through in that tables lifetime
yeah
here's back to our example again the two
columns look identical if we go look at
the user tamp coals review we can see
that actually use a tab coals for a
table this is hidden column called sissy
c00 - that reflects a time in the past
when our part table had a third column
called Zed but what we do is we set it
to unused in terms of getting rid of it
any table that we want to do an exchange
partition on needs to reflect not just
the current state of the columns but
sort of the historical view yeah the
fact that we added three columns we
removed one we set one to hidden we
added a function based index fault now
some places have really good change
control and so you could actually places
you could work out that that list of no
changes yeah by going back in through
your change control I would probably
contend that some places don't have that
level only and so you look at your table
and when it says you can't do an
exchange you just throw your hands in
the air and go I have no idea yeah this
happened and that's fair enough it's a
fair criticism that it's been quite
difficult in recent versions to do an
exchange partition or at least to deduce
what I have to do yeah to my exchange
table template to make it exchangeable
yeah yeah so in 12.2
what we've done is let slip through the
syntax okay so you got an example yeah
yep
so in 12.2 very simple we go
create table exchange path for exchange
and so what happens is we're now
undertaking the work internally of going
looking the data dictionary finding at
all the bits and pieces that might have
happened at that table and we'll create
you a template table which reflects that
once you've done that then alter table
exchange is just going to work yeah
that's pretty cool when you do a create
table for exchange it creates a table
with no rows right so whereas before we
might do something like create table tea
a select star from the other thing and
use that to exchange data straight in it
now becomes a two-step process so you
create a template for exchange and then
direct mode insert it and then you're
good to go
and that's exchange petition okay one of
the things that as Adi putting my DBA
hat on now is we saw before about the
external tables and you know a tiny
change creates an error in an
application which is often viewed as a
catastrophe as a DBA there's nothing
more embarrassing than doing something
structural to a table yeah like
partitioning it and as a result of that
action
you know you've created on what I call a
sleep a problem where everything's fine
then six months down the track you know
Emmett says our application has stopped
working and the error is something with
partitioning and that's something that
you did six months ago we remember and
and next thing you know you know I'm on
the intent looking for a you know job
vacancies so what have we done in 12.2
that's going to save my job
well example this imagine you built some
kind of generic file import routine this
was built you know 15 20 years ago or
whatever and the time it's built there's
only two types of files we imported
fixed weight from the CSV and because
they've got different characteristics
we're going to handle them differently
and so on we decided to list partition
the table so picked one fixed stuff
going one partition CSV goes in another
partition then of course what happens
about 15 years ago what was the new kid
on the block XML
everybody loved XML
someone tried to insert it and we get
the lovely aura
14400 area this this reminds me of that
famous quote they say XML is like
violence if it's not working
use more exactly so you know and this
wasn't great so it's like you say you
your application will fail and you know
some DBA would get that what I am call
out and then go around and share to all
the developers because they haven't
built something robustly and so what do
we do well the solution in the past was
failure
well here we obviously created a
partition to store XML values but we
also know well we don't want things to
break unexpectedly in the middle of the
night or any of anytime really
so we also created default partition and
it's all well and good so new values we
get from now going that default but of
course over time we've got our
partitions fixed widths given the fix
see it's being the CSV XML in the XML
but the default partition becomes a bit
of a dumping ground
you know you get I was gonna so it's
funny like you I mentioned that it's
really embarrassing when the theme falls
over but it's it's in these scenarios
when you know when we end up putting a
bucket in a catch-all bucket mmm we
almost want it to fall over because we
that's how we discover sometimes at our
this HTML armors JSON there's yeah
malware yeah we saw by solving an error
we often mask yes a deeper rooted issue
exactly and of course I mean the real
tragedy of this is you lose the benefit
of partitioning and so whatever whether
it was performance whether it was
availability maintainability
everything's going in that default
partition it's not partition exactly and
you know again it falls on probably some
DBA who's got a every now and then check
are there new values is it worth
splitting them into their own partition
or not so that's a bit of fat so I'm
12-2 we've dressed that we've introduced
automatic list partitioning so if you're
familiar with interval partitioning so
regular dishing table pretty much the
same concept just apply to this
partitioning
what you do very easy to set up you say
get your partition and say automatic
automatic keyword and then when Oracle
sees a new value rather than getting an
exception it will create a new partition
for you so is there any limit on how
many values I can have you know I don't
know it might be standard partitioning
limits which I think I have a million
partitions it's a ridiculous number I
know and one thing you will need to
watch for though is you know you've got
these existing this partitions with a
default for your catch-all you go okay
we want to move them to be automatically
less partitioned because we want them
printed for us those are mutually
exclusive options which sort of makes
sense because yeah exactly why why would
you have a default but nothing's going
to go in with you're automatically
creating the partitions for you but
other than that you know it's pretty
easy you can alter your tables so if
you've got existing list partition
tables you can do in it simple alter
table automatic I forget the exact
syntax but remembering to draw the
default part is about making sure the
default position is empty and dropping
it okay so I suppose what we will do is
in terms of a migration process or
something that's more flexible like
automatic we go looking our defaults get
the distinct values build our own just
split them in their own petitions yeah
do we end up with nothing in default
ditch it and then we're done yeah okay
when it comes to unstructured data I'm a
bit of a dinosaur you know I'm getting
pretty on pretty old now so you know my
definition of unstructured is what I say
to the cab driver on the way home after
too many beers of the pub so as I
educate me on unstructured data in in
12.2 okay so unstructured data one of
the more popular formats now is Jason
everybody wants to use Jason and in 12
102 instead of previously release we
introduced some new functionality to
work with Jason in your database
what we did is if you had a JSON
document and you wanted to store it in a
var car or Club you could create an ease
Jason check constraint and then you had
some extra functionality to kind of
extract the components of it so if you
wanted to the value
for a particular field you could get
just that out without having to read the
whole JSON document pretty handy in fact
I remember seeing the Jayson indexes and
stuff exactly so that you know there was
extra things to help me search it
efficiently work with it which is cool
but of course you know as he said I I'm
big fan of well modeled databases
structuring it properly and I don't
really think you should be using this
commonly I don't think you should be
storing Jayson directly in your tables
and most of the times you should be
shredding it out into your relational
tables I suppose people in fact one of
the beautiful things about relational
databases and the maturity is we can set
up environments where you know we could
actually store it both as JSON or not
jason shred of that on whoever use case
requires at most or even both if we
needed to but that was the best thing
about relational database we can be all
things to all people exactly exactly and
you know there are definitely use cases
where you want to store Jason but a
really common use case that people then
have is oK we've got this data in
relational tables what we want to do is
extract it out as a JSON document and
you know this is something you not had
so that this is what's great about
community you know writing Jason
documents trying to build your own for a
sequel queries pretty tricky for
anything other than like select dummy
from jewel
I've seen some blog posts in like it's
yeah it's very hairy as you all exactly
and so the community kind of stepped up
and got things like peel Jason so some
libraries and frameworks you can
download and install which actually
helped generate JSON documents for you
but you know we've moved on in the
database every week so 12-2 we've
incorporated all that ability directly
into the database so it's all native
functionality now that's awesome yeah so
we've got four new functions so JSON or
a JSON object jason array egg and jason
object egg and that's certainly familiar
to I remember with xml type we have xml
egg yeah acceptor so it's like a kind of
complementing yeah it's it's very
similar to the
XML equivalents that exist now some you
know you're saying you're not too
feeling familiar this what's the
difference what do they mean well the
right ones means you get your output
with square brackets and the object
month means you get it out that's at the
right level for my level of
understanding that's good
exactly so you know people who really
familiar with this but that's what you
need to remember if you want it an array
you know array values in square brackets
use the array functions and if you want
an actual document then you use JSON
object and you get the curly brackets
because we said there was the AG
versions the non tank versions the
non-ag versions take the values from a
single row and will produce a JSON array
or document for each row or each row in
your source you'll get a row in your
output egg versions you'll group
together multiple rows into a single
JSON array or a single JSON document
fairly straightforward that's good
so we've a couple of slides ago we saw a
JSON document producing a for each
department an array of an employee's to
do something like that it's pretty easy
now we got query that looks a little bit
a little bit like this if we start kind
of from the inside out on the inside
here we've got JSON object because each
employees are in kind of mini JSON
object document it's a good JSON object
for that produce there the attributes
and give the values we want to group
those together by department as an array
so we just do JSON array egg around
those documents and we see we group by
Department at the bottom so for each
department they'll get their own array
and employees and as that so
I suppose that nesting layer functions
reflects the JSON hierarchy that we're
going to be exactly yeah so you know you
can be as easy or as complex as you like
obviously more complicated there hardly
a sequel is gonna be right but that's
okay well I think it's funny how I
reckon this will be huge because people
love relational databases
it's such a it's makes life so much
easier in accessing data but the
developer world as you said before is
JSON centric yeah they're in love with
Jason and that's that's the legitimate a
legitimate love because probably the the
development environment du jour nowadays
is anything to do with JavaScript and
JavaScript and JSON pretty much go hand
in hand so this is an awesome glue I
reckon because you'll have JavaScript
programming they want to deal with JSON
yeah
but they also want that security of
having relational data yeah and this is
that great blue that's going to weld
them together exactly so they say you
you can have your relational data build
your queries maybe you could build some
views which actually do this for you
so then people are just back to
selecting you know select star from
jason view yeah and I like that because
that's almost a throwback to their days
where you would have people with the
next database expertise and they'd write
they'd be in charge of data access for
efficiency whatever they can now wrap
that in terms of JSON as an output yeah
and we have developers who really know
JSON really well and that's what they
want and expect and the tool just merge
together pretty nicely
exactly I miss them before about the new
real-time materialized views where you
know there's nothing better than that
sort of nice joyful moment of saying
here's a queer that runs for hours and
guess what I've made it run nice and
fast you know and you didn't have to
change your code that's materialized
views if I haven't got materialized
views is there anything else you know
are there any good performance things
coming in twelve to that are going to
help me well step back a bit for a
minute in 12 102 we introduced some
enhancements to count distinct so count
distinct on really huge tables like
hundreds of millions billions plus rows
can take a long time to run thing is
when you're doing account distinct quite
often you don't need to know exactly
what the number is either maybe it's a
starting point for analysis in that
analysis did we have more
less than a million customers visit the
website yesterday or what's happened is
your boss is coming a lot just come to
you and said I've got a meeting now I
need to report to the CEO or the CFO how
many customers or how many products we
sold yesterday I need it right now and
of course he's gonna take that and he
doesn't need the exact figure all he's
gonna do is run out round it we sold a
million dollars we sold half a million
dollars or whatever you don't need that
exact figure a lot of the time what you
just need is an estimate quickly so we
introduced props count distinct this is
faster than count distinct and it
produces a figure which is very close to
the original runs much faster not exact
but for those cases where you don't need
exact you just want to finger me yeah
estimate it's good enough after me I
remember when this came in in 12 102 I
was I thought this was awesome because
what we used to do beforehand we'd use
the sample Clause inquiries which is
good I mean it was still fast but the
problem example was it was literally
that it was a sample and so you could
easily get very distorted results yes
but a no count distinct actually you
know doesn't sample the table it reads
all the data exactly typically very
accurate like 99% accurate things like
that and that's very well and good but
of course there's a good chance if
you're doing a lot of countless things
you've got a lot of code which does
count distinct isn't there so going
through and changing that could be a lot
of effort so first thing we've done in
12:2 is we've introduced a new parameter
so this is new aprox four counts inked
he set that to true and then Oracle will
implicitly convert your count distinct
to the aprox count stinked alternative
so it's pretty cool there we go so we
don't have to worry about changing those
1700 you exactly does exactly so and
again a lot of the time there will be
times where you want the correct figure
you don't really
have to go through your code and
actually write to you know add a
parameter approximate or non approach or
exact to you you can just change this
on-the-fly at your session level if you
want to so that's pretty cool and when
you start digging around you might find
there's a couple of other rocks for
parameters so proximate aggregation of
props or centaur though so props count
four distinct and pretty obvious what
that says
well there's and more new approximate
functions in twelve to so along with
counts of stinking camp stinks is a
proper scent I'll so the percentile
Contin disk junctions which say give me
the tenth or the twenty-fifth value of
an ordered set there's now the
approximate equivalents of those which
is pretty handy so you give your
expression and we've added a bit bit
more nuance bit more options to this
first up there's a deterministic laws so
you can use this to set whether or not
it always gives you the same answer so
other things if you use deterministic
it's a bit slower but repeated runs on
the same data set and give you the same
answer the other thing is you can only
use it on numbers so if you want the
tenth date in a range of date you can't
do that you've got to go
non-deterministic the other thing is as
well when you're producing estimates you
kind of want to know how good your worst
bit is you know how sure are we this is
an accurate figure so there's an extra
clause you can say give me the error
rate or the confidence for the
percentile giving so say how certain are
we yes this is the 10th percentile value
and we are 99% sure it is correct or we
are 98.7 percent sure was great so
you've got that fast estimation with
kind of the safety blanket of yes we're
pretty we're pretty sure that it is
actually the correct value I really like
that because I remember I went to how
many years ago when I was at when I was
at university I did statistics and one
of the things we learnt was
confidence intervals and how almost all
statistics nowadays is never about being
a hundred percent sure it's being able
to reliably say how sure you are yes and
that's how we make decisions and how to
me I reckon the percentile stuff is cool
because you know what what's what's
probably the after average probably the
next biggest dominating step that people
use as median and percentile fifty is
the median
yes exactly well they you say mention
median there is also the problem like
Oakland as well so they say it's just
the special case of Brooks percent are
where you want the middle value and it's
the same same clauses it's just a proxy
median that's good I've done some of my
features that I really like I'm spent
it's time for you to do some talking but
I'm curious I see like I know you have a
real focus on some of the more developer
level features especially around sequel
so what are the some of the things that
like when twelve to come across your
doorstep that really jumped out he went
these are really cool really hard things
this famous quote in computer science
I'm sure you're familiar with there's
only two hard things in computer science
cache invalidation and naming things now
when it comes to using Oracle database
and cache invalidation as a developer
you kind of don't need to worry about it
too much you know buff cache manages
itself so on yes it's useful to
understand how it works but you don't
actively need to do much about it day to
day we've pretty much got that one down
pat exactly but when it comes to naming
things we make things just a little bit
harder than perhaps we needed to when it
came to using an Oracle database so
let's take a look an example to see why
so let's take two tables so we've got
customers and we got addresses many to
many relationship between them so we
create a table in the middle so when our
first question what do we call that
table probably customer addresses yes
like that the standard you just keep
kakak and adding table name to customer
addresses maybe address customers if you
some crazy people might call it that but
and naming that's pretty
but things get a bit more interesting
when it comes to things like what do we
can name the constraints on that table
would have you pull the indexes and this
particularly a problem because a lot
companies tend to have naming
conventions so we take our foreign key
to the customers table got a naming
convention which said something like
you've got to call your foreign keys
table name underscore column name
underscore okay classic what happens in
this example so we name it Franky's
called customer addresses under soar
customer ID underscore FK and you know
at this point I see something like
that's like it's like it's looking
promising because the limit for
identifiers so table names index names
constraint names things like that that's
been 30 bytes and it's been 30 bytes
forever and so this could be a real
problem when you've got these naming
conventions or stands for compound
foreign keys and things like that and
especially like it's that thing of I
hate it when when we can't with the name
is down especially when you involve
prefixes and suffixes yeah yeah the
actual available window for meaningful
stuff just shrinks and shrinks and an
address
we've just been as guilty as anyone like
inside Oracle used to be you know
because you're materialized view logs
have M log dollar we'd say keep your
table names under say 25 and if they
were involved in queues we have a huge
dollar in fund lemon some suffixes at
the end or text indexes that have the
suffixes so we'd say look you can have
30 characters of your table but
preferably maybe 23 22 and just get so
down and down so yeah that's it's a pain
yeah acceptable abbreviations is it
customer or do you just strip out things
like that and it's so easy when we start
writing scripts to look at all our data
dictionary we say okay we you know we
start making assumptions that every
foreign key will be table name
underscore FK and all of a sudden some
of our reports are missing them because
you know we didn't we didn't see this
X runs away yes so it's no surprise that
over on the database ideas for them so
this is placed on a TN you can go you
can suggest improvements you want to see
things added to the Oracle database or
things change about existing
functionality one of the more popular
suggestions is increase the maximum
identifier length and it's got a lot of
votes and people who've been there may
notice a little you know the little
yellow box that says coming soon and be
wondering well when soon soon it's now
finally yeah so starting in 12 - you can
now have longer identifiers how long can
we have so the limit is much higher now
more than four times higher in fact 128
bytes oh this one 12.1 some of the
dictionary views are already showing
that yeah inside me in preparation
that's cool so you can go out and go
really crazy you can create yourself
some tables with some really really long
names and lots of really really really
long column names and so on and it'll
just work i've atom it it's fine like
I'm gonna develop an hour but I wasn't
used to be a DBA and I could see myself
going just what I need all my 3d you
know my sort of middle tier program is
coming up with variable names this long
we stay already dunno I'll just
translate that straight into the table
column name so yeah oh I suppose not
much we can do about that yeah so you
know this is cool and you know it's good
that you can create longer identifies
but and we've gotta check your
application you've got to check that you
haven't imposed restrictions yourself on
fire let's take a look an example so
this tag it's really cool function
produce comma separated list and if we
got but if you using that to read your
data dictionary so we've got something
here we're going
gotten table names and producing comma
separated list of indexes on those table
names problem this tag only supports up
to four thousand bytes thousand
characters now only twelve one in before
this probably wasn't too much of a
problem for this query because
you could have 130 or plus indexes on
the table before you hit any issues that
and we'd be breaking the index usage
monitoring that come along and kill some
of those index falling over
but now we've gone from 28 bytes
potentially then we're dropping that
substantially down from you know
hundreds of indexes on the table to just
30 or so before we problems and you know
people are going to go out there as you
say they could create those really long
indexes or they're gonna create you know
self-documenting indexes where they say
what why it was created so we have this
monthly batch run and it took hours and
hours and we fixed index fixed it so we
call the index this is the index to fix
the mud run ticket from 3 hours down to
2 minutes I've got to put my initials
because I'm so proud of it date we
created it the service goal number and
the project number and so you know
quickly we get these really long index
names and people go out and we've
already talked about people over
indexing what happens we've created all
these and list out for them get an
exception instead of it working and
that's one of the things that I love
this day because it's fine when you look
at the old ways we used to do we
concatenate lists the solutions were
modern flaws or you could use XML
transform or the OCI aggregate stuff but
they're all like this much code and then
someone says this tag one line it was
just awesome the thing that always
bugged me at least AG was this thing
where the list egg falls over it's it's
a chicken and egg problem you don't know
if it's gonna fall over until it does
yes and and if it does you're stuffed
you can't work around it so you end up
with these sort of awful things of I
want to see how long it's going to get
before I actually do it and that's
really hard to code because if the
moment you make the string too long to
see how long it is you fall over and so
you guys I it's one of the critical
problems of list egg which is a bummer
because it's a cool function yeah
exactly
we'll have this problem I mean we talk
about data dictionary things here but if
you've got things like product
descriptions and other stuff which can
already be you know 100 characters long
nearly and a lot of people ran into this
issue so there's a lot of cool to make
this tank haven't failed gracefully look
so slightly 12 foot - that's what we've
done
there's a new clause for this tag and
improved improved overload flow
semantics specifically there's an
overflow truncate cause or non overflow
so we take a look here just after you
know whatever we said our separator is
comments here we say on overflow
truncate now when we run this query with
our billion well 40 or so stupidly long
in those names on instead of an error we
just get at the end we get dot dot dot
that's so what's what's the 42 so the 42
is how many characters Oracle is
stripped off the end oh ok so we have
another year of oh yeah yeah so it was
you know 4042 characters long we know
that there is more information and how
much more information there is and the
dot can I control the dot dot dot yeah
so let's this look at like these syntax
in its raw form so we got like on
overflow truncate or arrow defaults to
error because we we stay with the
default it evolves yeah and they say
then you can optionally specify some
text so you get deep you could say more
you could say you know if it's appearing
on the screen click here to see the
phone you know use something other than
this time to get the full details it's
like an apex app or something exactly
and then with whether or not you want to
include that in count okay oh that's
that's excellent
I mean how to make that count thing I
think could be really valuable because
if you're one or two bytes over mmm
you know people I don't want to look at
the rest yeah they for ten thousand
bytes over yeah that people say I know
you that's that classics justification
for the click here to see more or hover
over so oh that's yeah I do I knew I'd
heard rumors that we were fixing the
error yeah but I didn't know they were
gonna give this extra information
maquette that's awesome
it's really simple just an extra cause
so cuz he I mean that brings listo back
on my listen back at my list of favorite
things that's cool
dates dates are always a pain to work
with particularly converting strings
into dates
what's happened you got your CSV file
someone's opened it up in Excel
they've got dates are in day month year
format they've got their own special
settings they like it in your mom's day
save the file and it preserves that
year-month-day format and Excel in
particular it's a bugbear for that
because in Excel the dates are in their
own internal format and so it's all
about their custom formatting so yeah
it's like in one click exactly they can
ruin your day okay so what happens and
the reason we've got problem with this
is you know we created our external
table and we actually you know we
thought this columns our date so we made
it a date and we've specified the format
mask as part of the external table
definition which it sounds great but
we've run into these problems actually
querying the file the table itself which
isn't great so whatever we do at this
point most people take the cop cop-out a
break down by constraining everything a
stream everything is a string and you
know it's good so you can actually reads
the data into you but you can read the
file always now or at least because now
that's gonna fall over at some point
we've got to convert that string into a
date and like I say when we do that that
falls over instead and that's almost
worse because least with the external
table we get the log file the bad file
never where's this one it's like we're
with ya and this is where people do
things like you know write their own
custom is date function or people are
really crazy try and write a regular
expression to validate either date and
query that and so again there's a couple
of announcements that come in in 12 -
that make these conversions are working
with these conversions and when they
fail really easy first up
you function validate conversion well
that does so pretty easy you take an
expression variable whatever it is give
it a datatype and Oracle checks whether
it can convert that expression to that
data type things note so you can specify
your own format mask or and less
parameters you don't have to but of
course if you don't it picks up your in
LS settings so you know if you've got
you month a format some one ourselves
day month yeah
different clients forget so today's
today's code might not work tomorrow
exactly so you know this is something we
say anyway we like to Carl always you
know specify your format mask isn't it
so try I'm in loss like validate
conversion so are used telling me that
this has helped me I'll be able to run
and it's not going to crash when I run
the query exactly so what it does is it
checks and whether it can convert that
expression to that data type with the
format mask defaults as appropriate if
it does work you get a one and if it
doesn't work instead of crashing you get
0 oh I can oh that's really cool yeah
exactly
so if we're querying our external table
we can we can set up to processing
things now we can set up one which says
validate conversion if it's equal to one
stick it in the correct tables and if
it's at zero we can put it in like our
processing key or something like that
for someone else to read so much easier
isn't it especially I'll especially as a
where clause because it used to be that
terrible thing where you wanted to get
some dates back and it would crash but
you couldn't simply say well where to
date because it would still crash yeah
and then yeah you're into that regular
expression he'll you mentioned before so
oh that's really nuts yeah so you know I
said those validate conversion so
there's two things there's actually a
new clause forecast
so on the cast function there is a
default on conversion error clause
that's now appeared and if this works
very similarly to the validate
conversion it says instead of error Inc
if Oracle can't convert that expression
to the datatype it gives you that
default violet value instead says and
that default value has to be the same as
the data type coming out
yes so you know if you're trying to
convert something to a date you can't
have a default of not a date okay you
know it does have to be a string that
map's to those to that date that you
want now you might be thinking okay
Casca but I mean do you actually use
cats from very often a lot of cast a try
I tend to use cast a fair bit but only
because one of the things I've had in
the past is when you're comparing
timestamps to dates because people tend
to use the two interchangeably but it
can have optimizer implications so it's
one of those things where often I'll do
where I'll you know I'm just lazy and
using a date value and I'll simply say
cast it to a timestamp so I can compare
with the time centcom but yeah I've
dammit in normal usage you don't see a
lot of people using well remember that
all those two functions to date to
number to timestamp they're also a form
of casting so this default on conversion
error cause applies to those various two
data type functions so I can use that
there's been put through all of them
yeah yeah oh that's because yes
certainly the number of times you'll see
to date to number I'd say is a hundred
to one outweighs the times you see cast
exactly so you say we're casting that
traitor dates and giving it a default
about you know a magic date first of
January 1 BC nd or whatever it is and
then now you again who's back to using
and where calls we can look for that
magic date and filter it we'll do
whatever we want as appropriate automate
one thing I do hope though because I
think that's a very cool function
because there's nothing worse than code
that falls over without much clue as to
where yeah and especially I found when
I've had code that falls over you know
as performance people we keep telling
people to use bolt collegues bolt fits
whatever but what that means is there's
the there could be an area out of one
over a hundred rows and we can't tell
people which one it is I tell you one
thing though I hope people don't because
my worry but this is will
dancing tables filled with special
special boundary values yeah but that's
a problem for the optimizer team not us</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>