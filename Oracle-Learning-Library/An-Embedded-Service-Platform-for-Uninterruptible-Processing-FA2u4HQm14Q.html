<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>An Embedded Service Platform for Uninterruptible Processing | Coder Coacher - Coaching Coders</title><meta content="An Embedded Service Platform for Uninterruptible Processing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>An Embedded Service Platform for Uninterruptible Processing</b></h2><h5 class="post__date">2013-01-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FA2u4HQm14Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">what this presentation is about is I
work for rockwell automation my
associate here's Paul schmurder also
works there and is going to be doing a
demo for us in a little bit but what we
did is a couple years ago decided we
wanted to try and use Java in a new
product line that we're developing and
so this presentation was actually done
last year Java one but we've updated
based on some of the lessons learned in
the last year some lessons that those of
you who are considering putting javon
your products might be interested in
hearing a little bit more about so I
find it I hope you find it worthwhile
roughly for the agenda then what I'd
like to do is go through some basic
introductions kind of like where we're
coming from for those of you not
familiar with industrial automation say
a little bit about that space because
it's kind of a bizarre space especially
if you come from IT or some other
disciplines talk about some of the
decisions we had to make to decide on
Java pick the right Java in the right
Java execution environment because I
think those those were tough decisions
I'm thinking we probably made the right
ones so far a little bit about osgi
which was one of those decisions a
container for execution of Java talk a
little bit about our experience with an
embedded database because we needed a
place to store data and had some pretty
significant requirements for being able
to run sophisticated queries Paul's
going to do a demo and the demos not
actually of that product but it's of a
not dissimilar stack where he has a
gateway to the cloud collecting data
control data so we'll go through the
demo and then just kind of recap with
some of the challenges we had in terms
of performance you know working with
flash memory was kind of kind of new for
this kind of a stack for us and the
limitations of that and then really
toward the end of this development
lifecycle some of the things we had to
figure out in terms of hardening a
security issues you know making a
tamper-proof arm protecting your
intellectual property that's in code and
otherwise you know so those are some
things that we had to deal with and then
a little bit about try
shooting this environment because I
think we work closely with the oracle
team on a couple of challenges we had a
troubleshooting and as you'll see you
know you don't have all the tools on the
target necessarily that you have in a
typical development environment so there
were a few challenges with that and then
we're just going to open up to a QA I
think we should have plenty of time here
got a small group so introductions for
those of you who weren't in the earlier
talk we are rockwell automation we're a
medium-sized company about 20,000 people
around five billion in sales we're
headquartered in milwaukee for a long
time now i guess more than a hundred
years we have customers all over the
world and we research labs in Milwaukee
and Cleveland Shanghai in Prague and so
we've got projects kind of going around
a lot of different places in terms of
the verticals that we serve we have a
large partner network of system
integrators and preferred partners just
like Oracle and other folks have but
we're really in the automotive food and
beverage paper handling in Wisconsin is
a big deal Pharma moving material around
we our control systems are involved in
that increasingly in mining offshore
rigs also and you know we sell all kinds
of stuff it's not just plc's the Ellen
Bradley brand that we inherited when we
bought that company has a catalog of
devices from push buttons to switches
two relays up through more intelligent
devices and then all the way up to you
know small plcs and the very top of our
logics line so there's a lot of
different stuff we're also into motor
drives in a big way and we've got some
pretty deep experience there and we have
a fair amount of software that we ship
today you know things like asset
management software and scheduling
software for your factories so the soar
into a lot of different spaces and
always looking for new opportunities my
name is Tim beer net I've been with the
company about five or six years now
previously worked with some interesting
places General Dynamics work on the f16
avionics and you know that system as a
distributed computing system there's
over two
seven computers along with all
associated sensors and it's a fairly
real-time system I mean you've got to
get data from the radar at a certain
rate to paint the heads-up display to
provide targeting cues you know so that
was a real time system was good
background for getting into some of this
other work I think but worked on Telecom
at Motorola did some teaching and
consulting with IBM and my own company
software mentor for quite a few years
and now here I'm very interested in Java
I've been working with it for quite a
while from the get-go pretty much but
also distributed computing and real-time
fault tolerant systems Paul let him do
his introduction here in a little bit
when he kicks the demo up but he worked
with a funds has a business background
business applications in j2ee eagle
technology and paul has been doing a lot
of work in the cloud computing and
mobile technologies so with that we'll
move forward and tell you a little bit
about this kind of bizarre industrial
automation space that we're in in terms
of you know just general production
processes there's there's really three
big categories that you can be involved
in and a lot of players will just
specialize in one of these we're
actually we have offerings on all of
them so traditionally we come from a
discrete manufacturing backgrounds we're
talking about you know discrete events
in manufacturing on assembly lines you
know you're putting assemblies together
step after step and getting the work
done but we're also involved like in the
food industry and batch production
things like you know beer processing
where you recipes that have to be
processed and cranked out so more
continuous all the way up to truly
continuous processes like glass and
metal production in certain refining
processes we're in all those spaces so
we have a lot of different lot of
different things to offer we also have
service organizations who have deep
domain knowledge in these verticals too
but you know the equipment that we make
is really in tough environments there's
you know lots of times there's a
washdown requirement this thing is
washed on with a you know sulfuric bath
or something like that you know it's
very hot cold a temp
pictures are not necessarily very common
a ting there's lots of dirt and dust
there's am issues I think I mentioned
earlier you know we've been challenged
by trying to use any kind of wireless
technology in the factory which
obviously would have some huge
advantages but because of such a noisy
environment sometimes it can be very
challenging also some of the handoffs
that happen in typical wireless hardware
that's available I may be too long for
us to tolerate so it's a tough
environment to work in and we can't just
grab stuff off the shelf I guess is what
I'm trying to say we have safety
concerns people operate around the
machines they have to maintain the
machines the machines have to be able to
be placed in a safe mode or our
customers and we will be held liable
security is increasingly coming up on
our customers radar screens probably it
should have a long time ago but you know
with the advent of things like Stuxnet
and higher levels of integration between
the factory floor and IT folks are
getting more and more concern that maybe
just a simple firewall isn't good enough
so that's a big area for us this is
obviously a cutthroat space to be in
manufacturing I mean you know if
people's margins are tend to be low but
so you know price is always an issue but
downtime is typically not acceptable
especially in some of these more
continuous manufacturing processes and
lastly and perhaps most importantly for
the topic of this discussion is our
systems are really long lived I mean you
talk to people who build consumer
devices and it's like it's got a life of
a couple of years it's very easy to
update it with new software a new
operating system our systems our
customers put them in place they get
them working and they don't touch them
again you know they don't touch them for
15 or 20 years sometimes and they like
it that way okay so this is kind of a
you know you've got to think a little
bit about you know where am I going to
get spares where's my you know operating
system where's my linux kernel going to
be 10 15 20 years down the line you know
can I support it how am I going to
troubleshoot and I diagnose these things
so these are these are
all real problems that we have in our
space it's a slow moving hard to get
into space it's really different and it
was primarily a hardware space you know
even if you look at the way you program
the control logic right it was a
hardware metaphor of ladder logic it
looked like you were wiring up a system
so it comes from a very serious hardware
background but increasingly the things
people want to do in their factories to
improve the processes require more
software so today you're seeing a
definitely an expanding role in
visualizing what's happening in the
plant integrating and better
communications from the smallest device
on the edge up through you know the top
level collecting data even in the cloud
today and of course we still have to
close loops to do control so we got to
make sure we don't compromise that it's
fine if you're you know visualization
goes down but the line better not go
down right so that's a whole other level
of reliability that you have to build
into your system and historically those
of you who have worked in the space know
that this technology and the software
side has been totally dominated by
Microsoft I mean it was you know all com
based OPC technologies and you had to
run on Windows if you wanted to do
supervisory control and collect data
from your control system so that's
historically where it's coming from but
that's starting to change even with
technologies like the new OPC UA that's
out is platform agnostic and there's
stacks built that can run on just about
any kind of a platform today there's a
increasing desire across the boards
despite you know the concern I mentioned
earlier about don't touch my stuff
there's a pressure that we have to
connect to the enterprise we want to tie
to real-time supply chain stuff we want
to do more advanced quality we want to
look at our KPIs in real time the datas
got to get up higher into the IT side
the enterprise side of things so that's
unavoidable and what used to be a couple
you know little proprietary platforms is
now it's like you know your software's
got to run and it's got to run a lot of
different platforms the same software
one of the reasons that job is so
compelling so you know we may have
virtual machines that were running we
run on the PC we run an embedded devices
we run in very small capability devices
too and we're dealing with windows and
increasingly Linux in addition to
proprietary real-time operating systems
so why was Java compelling for us I
think portability was a big deal because
we wanted the ability to to build out a
stack for stuff that could run a lot of
different places Linux is something
quite new to us and we wanted something
could go back and forth from Windows to
Linux and change the hardware underneath
and probably the second most important
thing was productivity you know if you
look at writing native code on a lot of
these platforms you wind up writing a
lot of stuff yourself or paying somebody
for it whereas if you look at just the
base java SE AAP eyes that are available
to you now you throw in all the open
source stuff you know the way you design
these software systems today is you
don't you shouldn't plan on building
that much software from scratch you're
missing the boat if you are because
typically there's stuff out there that
either off the shelf or with limited
changes will will suit your requirements
and that's from security encryption on
down the line so that large open source
palette is a big deal but there are some
challenges not the least of which is
trying to convince someone that a
language like Java is even at all
remotely appropriate for the environment
where these folks have been working with
native languages and real-time operating
systems so they'll say things like you
know how can I control that heap you
know that's out of control what about
this non-deterministic garbage
collection and the bottom line is Java
has a pretty big footprint in its SE
distribution for a lot of different
embedded applications while we might not
need hard real-time for all of our
applications we often need a bounded or
deterministic response time that can be
frankly kind of tough to get in Java
sometimes so that's a bit of a problem
and the other issue is you know Java by
definition
one of the advantages that abstract so
way the hardware in the underlying
operating system that can be a problem
too because sometimes we've got to drill
down and get access to low-level
interrupt or signal or something deeper
down then it's traditionally available
through the Java API s so we did decide
to try and use Java and the next
question is you know what flavor of Java
right there's a lot of different ones I
mean we wanted a requirement was that we
were going to be embedded and headless
as far as Java was concerned so we
didn't need to worry about you know the
awt and graphics libraries and all that
stuff we were really building up the
stack below that level as far as job is
concerned we needed to target a multiple
hardware architectures and we decided
that since we wanted our architecture to
scale from the bottom to the top that we
really wanted to try and have the
standard edition full set of API is
available everywhere we we would
consider Emma if we had to but we really
wanted to do SC top to bottom and we
needed performance that was
approximately equivalent with native
code especially in a couple of the the
HMI the human machine interface devices
that we were doing so we needed to make
sure that was going to be there the
options that were available included
OpenJDK obviously which you can go and
pick up off the shelf Oracle standard
edition or the embedded version of
oracle and then there's all kinds of
proprietary versions of java and
real-time java that are out there some
of the discoveries that we did a couple
years ago and we first consider this was
OpenJDK is fine but it's jit performance
on arm which is one of our targets was
just miserable and today it's it's
improved there's still not to the point
where our Oracle is with their embedded
Java jit so that was a problem with
OpenJDK we did run a bunch of benchmarks
I'll show you some of the data we
collected on Oracle embedded and it
looked pretty good especially in the arm
platform keep in mind we're going to
talk about this some more that Oracle
embedded is just a JRE it's a target it
doesn't have the full JDK toolset so you
don't have all for instance the
troubleshooting tools that you might
have
of in a jdk environment they're not
available on the platform so that can be
a bit of an issue yes its standard
edition embedded is the official term
for it yes so java SE is a jdk but java
SE embedded is distributed as a tarball
right as a JRE and associated and they
can route they can debug remotely on arm
yes yeah they are working on that we'll
talk about this some more on but for
instance you know what I cannot do is I
can't go and fire up like a.j console on
the target and start collecting data and
generate heat dumps did carlos show that
then that's something very new I can
connect remotely I don't know if that's
what he did I can set up a jmx
connection and we'll talk about that but
I can't run and on the target at least I
couldn't oh yeah we'll talk about yeah
that's not a problem but but that's
fundamentally different than running for
instance generating a heap dump can be a
problem that way and collecting because
you're not on the target necessarily but
what we'll talk some more about
troubleshooting in a little bit so one
of the things you had to do is come up
with some benchmarks and amazingly there
just aren't a ton of very good java
benchmarks out there there's there's
other benchmarks but java specific
application level benchmarks are a bit
of a problem when what we wanted to
establish was you know kids is the arm
hardware fast enough with this java for
this type of an application you know
oracle would claim that they'd improve
horsepower a little bit performance a
little bit from release to release and
could we verify where they were headed
with this with some independent
benchmarks and so we ran these on
that hardware with OpenJDK standard SE
and then embedded SC edition what we
were looking at and what I wanted was a
benchmark they had some applications
representative of the kind of software
we were building out so terms of a
service provider type app benchmark an
embedded data store which I knew we
needed and would be a hot spot for
performance and we had an ide like
design time that we also wanted to
benchmark so we stumbled across
something called de coppell which is an
open source java benchmarking suite that
actually has these kinds of applications
available this is a pretty cool
benchmark it's really easy to use they
include a tomcat which is kind of like
your service provider an h2 database
benchmark eclipse which is your IDE and
then they do some Zalon processing and
some other types of benchmarks are all
available there that's very pluggable
you can build it into your test harness
you can have callbacks and really build
up a nice big suite for your
benchmarking work in addition it
supports concurrency so you can fire off
10 threads to run through the service
provider and see how it scales up if you
want to do that it also will support
multiple iterations as you know
especially with server style jit it
takes a while to warm everything up get
all the code compiled and you'll see
that in some of the benchmarks i'm going
to show you so they can specify hey i
want to go through you know seven
iterations or i want to go through
enough iterations that there's no longer
a big difference in the performance from
run to run and so i can warm up the JVM
so this turned out to be a pretty good
find we collected a lot of data i'll
just put up a couple things here that we
can talk about but in terms of on x86
we're running this the ided capo
benchmark and on the left is basically
performance so so fasters is lower on
the graph and then that we met the
iteration so it printed out data for
each iteration as it went through the
benchmark and as you can see depending
on the JVM which might be a little hard
to read things got better as we went on
through iterations and the JIT code got
compiled and code caches got populated
in classes were loaded etc and in this
case um it looks like we had SE embedded
16 up day 21
looking really pretty good there in
terms of getting down quickly in an
early iteration so you know startup time
is going to be pretty pretty good for a
situation like this and then really
holding its own against the standard
edition and OpenJDK version both client
and server for OpenJDK jet this is on
x86 so that kind of told me hey I can
expect decent performance out of this
embedded SC edition from Oracle even
though it's using the client jit and has
some other restrictions in it so that
was that was kind of good to see we also
did some comparisons back and forth
between arm and x86 to see you know is
the arm hardware really kind of scaling
up the way to what x86 hardware would
and perhaps the interesting thing to
look at here is the benchmark on the
bottom the pink line is x86 on an atom
processor at about 1.6 gigahertz with
Java embedded and then we've got an arm
1,000 with the same version in the brown
line and that's at 1000 so it pretty
much linear scaling performance with
cycles between the arm and x86
architecture using this embedded JVM and
I don't have numbers up here for OpenJDK
arm but they were utterly miserable
didn't even quit collecting data using
because they just didn't have a
technology that was that was there yes
yeah i actually did I ran the IDE
benchmark and I ran one other one and
what I saw was either on par performance
or slightly less performance on those
benchmarks oh sorry that was between
Oracle embedded 16 update 21 and version
7 embedded I didn't run I didn't run
that yeah in general what I've heard is
that 70 maintains about the same level
of performance but didn't go out and
benchmark it on x86 rope and shady can
so so now we got a pretty good warm and
fuzzy feeling that this thing's going to
be able to
be rather performant so we had some
other questions we had to get to in
terms of a container we didn't feel that
a strict JVM environment with without
some additional container was really the
way we wanted to build this architecture
we wanted to be able to do hot deploy of
services to run concurrent versions of
things to take advantage of things like
dependency injection so that we could
you know why are things together without
having them all hardwired together and
have some more flexibility so we're
looking for this kind of a container
that would allow this and still be
embeddable and so some of the options we
looked at were on the I pojo dependency
injection framework one called juice one
called spring DM which is a hybrid
between osgi and the spring application
framework in Java and then straight osgi
and kind of the conclusions we came to
that spring DM was really nice but it
was fairly complex and had a rather
steep learning curve and our guys were
ready coming up with a new no experience
to Linux no experience on Java and so we
didn't want to throw a very complex
container on top of all that so we kind
of ruled out spring DM for the near term
but maybe moving to it in the more
distant future and we felt that osgi was
a really good fit it kind of hit all of
these key bullets that we wanted it's
lightweight it's been around forever but
sure spec and mature multiple
implementations available we wound up
going with equinox although Felix was a
strong contender and frankly if its
dependency injection framework would
have been complete we probably would
have gone to Felix in stettin X but so
you know osgi dependency injection
support is fairly coarse grained
compared to things like spring DM so it
gives you some advantages but it's not
really where we ultimately wanted to get
to with the pendency injection
yes yes it is so how many people messed
around with osgi anyone in here oh yeah
okay great so you know osgi is is nice
it supports modularity through bundles
you'll hear me talk about bundles a
little bit and the presentation is class
loader model provides for isolation
where there's one class loader per
bundle which is also kind of a nice
thing to have you can restrict
visibility between bundles very
explicitly with imports and exports you
can provide for identity and versioning
of the bundle via symbolic names and
other metadata and if you have to work
with native code and we expected we
would you can create bundles that
include native code from multiple
platforms and they'll resolve to the
appropriate native code in the bundle
through the OSGi mechanism so that's
kind of a nice way to deal it's like
this is the bundle you know the
platforms are all supported that way
lifecycle is very important we needed a
dynamic lifecycle that was sort of
independent of what was happening with
the JVM we'll talk about the states that
are well defined but the the key state
is the resolve state which says that all
those dependencies that you specified
our resolve before we even attempt
execution of the code and of course we
have things like activators that allow
you to start up and to start up the
bundles processing and manage and hook
into various lifecycle events for those
states we do have a service based model
for our architecture where we create
services and deploy them as bundles this
allows us to be you know somewhat
decoupled dynamic and very much
pluggable and of course there's a
management console and other things you
get when you when you come into osgi so
when we started the project we had these
services than they were running every
service in its own JVM right on this
little constrained platform that wasn't
working so good for us and so what we
were on that we were on the red curve
the red line when we were doing that
right so we're deploying 89 services and
we're ready up to a hundred megabytes of
RAM which was basically blowing our
whole budget so it's like you know this
is not going to scale for us we know
ultimately we're going to have even more
services what can we do we put it an
osgi the
manages being you know the Java code is
loaded once in the OSGi container same
thing third-party libraries shared
native code and what within our
measurements we found that the OSG
runtime overhead which you just take a
hit for once was actually about two to
three megabytes even with equinox which
is one of the more heavy duty osgi
containers Felix was even less it was
like one a-two megabyte overhead so we
wound up with a line which is the one in
green once we deployed all of our
services and one JVM and one osgi
container and so that let us scale up
much more nicely and gave us some some
room well basically 67 JVMs running yes
yes so say a little bit about the
database because we spent a lot of time
in this area you probably will to it I
would advise you to you know pick one
that's going to work for you and do a
lot of testing make sure you get the
right one because it's a big commitment
even though all of our applications use
standard interfaces like JDBC to
interact with the database still you're
going to invest a lot in this technology
so we were looking for something with
small very small footprint and we're
under a 1 megabyte jar with this h2
database it's pure Java there's no
native component it's quite capable on a
16 megabyte heap and in fact we've run
it down in even smaller heaps of 4 to 8
megabytes and had some pretty good luck
with it it's very tunable as you'll see
in a little bit on our benchmarks
comparing it to these other databases
like Derby which is the java DB
cloudscape hsqldb postgres a number of
other ones it was by far the best in
class across the board for transaction
processing and queries it has a a very
good ecosystem in terms of people using
it it's well tested there's frequent
releases and lots and lots of tests and
the suite so what we had confidence it
was a pretty good piece of code other
things that supported standard SQL had a
nice license had full support for
transactions which was important for
some of our use cases was really super
tunable an embedded databases can
a have to be so you can adjust the cash
you can adjust when your transaction log
is processed both by time and size
number of transactions and really
important things to get more control
over over the database in an embedded
environment basically it even has a
engine level encryption which we are
using in some cases but the hid here is
about it's about two to three times
slower when you turn that on yeah I
looked at Berkeley DB which I consider
basically a hashmap in memory right and
it's really fast but it was a native
code implementation also we would have
had to pay Oracle for it so those were
some of the reasons i think it was
tossed out of the consideration i don't
think there was when we considered it
though it's more constrained yeah i
think that came out last year or a year
and a half ago but yeah that otherwise
that's that's an interesting one we did
look at some nap i let's see what was
the other one we looked at a couple
other no sequel databases but ultimately
felt that working with a sequel based
database would minimize our risks in
this area because we had some pretty
complex query processing requirements so
we thought this was better than writing
our own query engine on top of something
like you know a persistent hash a key
value persistence mechanism so anyway
the stack basically generically comes up
to look something like this we're
running at RM x86 we have Linux which
we're actually using Monta Vista as our
Linux provider for embedded Linux
Oracle's se embedded equinox osgi and
then we've got our bundles which are
common infrastructure bundles like the
database messaging and logging and then
in terms of our services we have
separate bundle deployments for
interface and implementation which is
nice because you can switch the
implementation without switching out the
interface if you don't need to
okay with that I'm going to give you a
little break from from my talking and
we're going to let Paul take over here
and see if he can put together a
demonstration for you you want to use
this through them okay can you hear me
coming over the speaker at all okay um
what I'm going to talk to you about is
over the last year or so I've been
working on a proof of concept that we're
looking at at rockwell where we're
looking to start providing some software
as a service implementations on on in
the cloud currently we're running on the
in the Windows Azure cloud so we've this
is this slide here is dem is showing on
the left here we have quite a few
clients that have our control systems
out either on Riggs someplace very
remote and you don't typically have that
many engineers going out there at any
time so what we needed was something on
those rigs to push data up into the
clouds and so we came up with a an
architecture a proof-of-concept
architecture that we're working on
hmm in the top you'll see that we're
we're running we have access where we're
putting together dashboards html5
dashboards for visualization from the of
the data that we're analyzing in the
cloud we are have put several of our
product products in the azure cloud
system platform and those those systems
then are talking through rest-based API
s to both the upper end our dashboards
and then to our to the system that has
the controllers on it in order to do
this we needed a gateway system in the
in the remote areas so that we could
push the data up into the clouds we can
only do a push so everything is going up
towards the clouds we're not opening any
parts on the on the lower system that's
the basic architecture of our system now
so basically what we ended up with we
you know we brought some of our systems
into the winter windows or cloud and we
already had our controllers out on the
in these remote locations and we needed
something in between to gather the data
from the bottom all the data sources
that we have our controllers and couple
other pieces of equipment on those rigs
and to push that information up through
normal cloud-based api's into our data
retrievers in the cloud so that that
data then could be stored and analyzed
on the cloud and pushed
out are pushed out to the dashboards the
mobile dashboards that we had so we
picked out arm board well we we have it
running we have Java software running on
java SE embedded with an osgi
implementation on there and this we have
it ported to several different hardware
pieces just for the proof of concept at
this point some hardened Windows systems
and a couple of armed systems so the the
gateway system then is a very small
footprint system that will collect the
data from all these different pieces of
hardware on the on the remote machinery
and then aggregate those compress it and
then at regular intervals it will
collect it up aggregate it compress it
then at a separate interval it'll push
that data up into the cloud if it's ever
disconnected then it also implements a
storm forward capability so that they're
on connection it'll push the data up to
the cloud at regular intervals we went
with a pure job by implementation so we
could move it to different platforms and
scale it up and so we're running is
windows services on some platforms linux
damon's on others one of the things that
we were missing we were the currently
the Gateway goes on to a system and
it'll pull down its configuration from
the cloud is to the data requirements
and the mappings and then send the data
based on those but we in the currently
in the proof of concept when we need to
update or actually provision the Gateway
someone actually has to go out and
physically put this on those remote rigs
and so currently I am looking at some
different technology stacks for doing
some of the provisioning getting our
bits out onto these arm boards out in
the remote field without having to be
accessed by an engineer so one of the
systems that i'm currently looking at is
apache ace for the provisioning what ace
has is it is basically you have a
provisioning service which we're
deploying out to the cloud the a service
then has a set of metadata for gathering
up the different artifacts putting them
into like a feature bundle and then
putting those feature bundles into a
final deployment and and show end and
then taking those deployments and
targeting them at the individual target
arm boards that we need to deploy to
there's also then a component repository
which I have depicted here in the cloud
in and we currently have it in the cloud
but it can be separated out for IP
reasons and you could actually have that
on a private cloud somewhere or
somewhere else that to access the
component repository the the other piece
to this then is the deployment
administration console which is pretty
crude for patchy ace at this point but
it works and so it allows you to set up
take the different artifacts load them
in literally load-in of your different
components and then start working from
there and section them out into
different features and and then into
deployments and then target it the last
piece is is the piece that I'm mainly
concerned with at this point is the
management agent
it's a very small piece that loads into
our OSGi container on the board and this
management piece then has an ID it
there's automatic discovery of the
system so in the deployment
administration then you'll see any all
these targets be identified in there
that so that you can target those
systems and then then it has scheduled
update messages that it'll send out and
look to see if there's anything new
that's been deployed for it in the
deployment management and the
provisioning server so if it sees
something it'll take the Delta of that
of that new bundle and and send that
down it'll retrieve that from the
provisioning server and load it up into
OSGi and automatically start those
bundles hmm so
so some of the features that are
currently in apache ace we went over a
little bit of this but the man image
management agent the small piece that
goes on the arm board again it has an
identity and it it's automatically
discovered it has a schedule for looking
for the updates and then we'll actually
go up and get retrieve those updates and
contain and right to an audit log as to
success or failure of any individual
update and then those logs get
propagated back up to the server so you
can see what what went on in the during
the deployment the deployment
administration tool has versioning
automatic versioning so as you put new
artifacts in and you create features and
distributions to go out to the targets
it will version those it's transactional
so if for some reason one of the updates
does not complete it'll roll it back it
only does Delta updates so so it'll look
through your your distribution and see
what has changed so that it doesn't load
down a full distribution every time you
can use digital signatures for security
and there are extension mechanisms so
that you can add different types of
components into the provisioning service
the again the provisioning server only
stores metadata so you don't have to you
know you don't have to put your bundles
up in on the provisioning server and
then there's a separate component
repository that it accesses and there
again you can extend that into different
there's extension points to create
different types of repositories if you
have something else that you're
using to hold your artifacts and so I'm
just going to show a quick demo on the
provisioning for the using eighth on
against the Raspberry Pi arm system that
we currently have osgi in java SE
embedded running it's a just a simple
proof of concept demonstration it's 191
ok so i already have up and running on
basically a private windows azure cloud
system I have the DA server running lets
going to the administration console
ok and
I knew I was good ya might have to do
the demo after you the rest here
yeah it's probably I'm not about reset
it and get it all set up and what you
want to go through years and then I'll
get it reset so we'll come back to this
oh boy my Microsoft so it's microsoft
stuff okay so the last few screens that
i have to i would like to talk about is
um some of the challenges that we ran
into as we move further into this
product development effort with java and
some of the ways we're trying to tackle
the job performance has been a problem
on our low end we've got this arm
hardware which is uh you know somewhat
constrained both the memory and
processing and so some of the things we
have to deal with is we have hard
requirements at least customer generator
requirements / how long it takes an
assistant to come up and show that the
base screen in the HMI and so we have a
look at how can we speed up osgi
initialization it was taking a long time
right operating system starts up java
starts up osg starstuff the bundles get
loaded these are all the things that are
happening so we started taking better
manage of using the bundle of cash which
is turned off by default we divert start
up of some things we didn't need so you
can say when things are required things
are loaded based on required
dependencies so we looked at that a
little more carefully and eliminated
loading some things we didn't
we also looked at and concurrent
activation so every bundle has an
activator basically the next one will be
bloated until that bundles activators
completed so we felt some threads in
those activators so that we can book
concurrent initialization where it was
possible that made a significant
difference on your 10 15 seconds we went
to strip bundle loading instead of
taking advantage of some of the plugins
for us yet let us do dynamic on the lord
how that saved a few seconds and one
thing going to look at these on Carlos's
video of a performance discussion for a
couple days ago from oracle and he
suggested that he spent possible if we
could consolidate jars that that alone
can resolve a pretty significant
improvement bundles are jars but we lost
other jars that are bundles that we can
consolidate so i'm going to go back and
take a look at that a runtime you know
we do need to terminus thik response
this is not a hard hard real-time
control system but we do these things
like screen switches to happen within a
certain amount of time sorry i'm not
using the microphone right oh ok so this
is a this is a challenge what were some
of the things that were getting in the
way we found out that the database was
doing things we didn't really expect it
to do the unexpected times it was Jenna
doing some housekeeping for statistics
it was doing some work with generating
regenerating indices and if we didn't
exactly know when this was going to
happen also the order that transaction
wants when they were processed we had a
very large setting for transaction log
and when it finally hit that transaction
log and processed it there was a
significant delay so these are some of
the things we had to watch out for and
typically we're running into trouble in
terms of the database also we wanted to
limit our use of Jay and I J and I
especially done poorly can be kind of an
inefficient way to invoke code and we
wound up basically getting rid of most
of the native code in our stack as far
as this goes managing memory there are a
lot of things you can do to man
the heap jvm settings in particular you
can consider tuning the JVM to more
aggressively release heat memory because
by default the tuning pretty much holds
on to it and in our case we had other
processes in Linux kernel that would
actually could have taken advantage of
some of that heap that we were still
holding onto in our java process so you
need to be careful in doing that but it
is something you can consider we took
some more measurements we looked at
stuff like java cipher performance for
various algorithms turns out that
aes-128 is actually pretty good here
scales quite literally with block size
and and we wound up using that that was
not a problem for us h to some of our
intellectual property is stored in the
database it's important that certain of
these databases were encrypted to
preserve that intellectual property and
it turns out that in general was about
two to three times slower but one
interesting thing here is to look at the
difference in the read so I have purple
is no encryption read is using the
database red is using AES and green is X
T EA and notice the reads are almost all
the same it's really not much of an
increase when you start encrypting and
we believe the reason for that is we
were using a fairly large database cash
so that it was basically in the reed
case pulling things from cache that had
already been decrypted and gone through
that that phase in the engine whereas
you know obviously for updates and
creates that wasn't quite the advantage
flash memory was something we had to
keep an eye on as you know I'll know
I've told you automation systems are
long-lived the flash memory wears out it
has a limited number of right erase
cycles could be a hundred thousand could
be two hundred thousand depending how
much you pay for it there's lots of ways
to try and extend that but the bottom
line is the software guys have to think
about it okay we made a lot of
assumptions that in many cases we could
use some read-only databases that
wouldn't have to be updated their
indices wouldn't have to be regenerated
we didn't think that you know various
housekeeping things were going on in
terms of counter
diagnostics in the database itself that
were stored down so all these things
were kind of surprises for us and we had
to get to actually stunned look at how
much I owe was going into the flash
system turned out we couldn't use
read-only databases in most cases we had
to have at least some level of update so
we had to retune and take and take into
consideration some of these things and
you will too if you're on a flash based
system and of course there's just the
general stuff about where you know where
you placing your swap file your temp
file you can collect an awful lot of
logs and diagnostic data on one of these
devices and you have to think about
where that's going to go and how often
that memory is going to get written so
these were all kinds of gotchas as we
went further into the development and of
course we thought about security from
the get-go but a lot of things like you
know protecting intellectual property in
code obfuscation that we really kind of
saved toward the end of the development
lifecycle but they're important things
especially you know we invest many many
staff years coming up with this stack
and and some of the features that are
going to be in it and it's going to be
out in the field for many years we don't
want it reverse engineered in 18 months
okay so we had to think about that we
have certain requirements to demonstrate
that our code has not been tampered with
and so we needed to basically handle
that and how are we in handle things
like private keys and secrets in this
invented environment the device has to
have access to this stuff for things
like encryption and connecting to other
systems you can do stuff like attempt to
hide it in the file system to obfuscate
the key and code you can somehow crypt
it and place it on a dongle but you've
got to have a strategy for dealing with
that and it's particularly difficult
when the system is often disconnected or
running in a disconnected mode which is
quite often our case so it's not like
you can go out and throw out some big
pki infrastructure and say we have the
answer to this thing we considered some
build time techniques for some of these
challenges identified just what are
those security sensitive critical
components maybe take them off into a
separate cleanroom development where
they're just done by a smaller section
of people they're locked up pretty tight
they're signed they're encrypted and
then deployed as part of the general
process we also looked at obfuscation
and I'll talk a little bit more about
this but obfuscating the code and
scrambling symbol names and stuff makes
debugging that much harder later on so
it needs to be a consideration we doing
on time we're running out of time so I'm
going to go through this pretty quick in
terms of code obfuscation we looked at a
number of different options proguard was
one a particularly promising open source
technique and what's interesting about
it is not only does it obfuscated code
but it will do some level of
optimization and shrinking of the code
almost to the extent of up to maybe
one-third reduction in the footprint of
your jars now this is both your code
input jars and the other library jars
you're using from Apache and other folks
but that was kind of a nice bonus if
you're considering going with something
like proguard to shrink the footprint
there yes we did some I didn't see much
of an improvement in terms of the
performance optimization
really it's actually slowed down
execution yeah interesting huh do it
instead that's a good tip you know we
talked a little bit about
troubleshooting but specifically you
know that the bottom lies is a JRE not a
jdk so there's lots of the standard jdk
diagnostic tools that aren't there on
your target they're not there at all jay
map JPS the good news is as you saw in
the demonstration that Carlos did the
GRE can can be connected to remotely as
long as you set up a jmx connector on
the target then you can hook up tools
like J console or what I like visualvm
which is kind of a superset of a bunch
of these tools from Oracle and you
cannot do things from a remote
workstation so the key is if you're
working with virtual vm make sure that
you're at you're running it inside of
the same major release of the jdk and
the same architecture or it will have
seriously constrained feature
availability you won't be able to do
much with it but you can do all these
monitoring generating heaps analyzing
heaps and profiling and I won't spend
too much time going through this there's
a lot of good information online but
this has been an almost invaluable tool
and in particular the profiling can be
done on CPU or on memory and it's really
sampling it's not pure profiling as
weird as we would think of it which
means it puts a very light load on the
target system so when your target system
is gasping under you're trying to figure
out what's happening and last thing I do
is hook up some big heavy duty profiler
that takes half of the CPUs resources
out of it so this is a very lightweight
way to connect remotely and still do
some pretty legitimate understanding of
you know where you're spending time and
your code so I think that's about it for
me you can look at the slides a little
bit later for our team we put together
some troubleshooting scenarios there's
so many different techniques available
what to wonder when what do I want to
try for looking at memory utilization
how do i wanted to garbage collection
what if i just got general performance
these are kind of a matrix of the tools
and techniques that can be used and some
folks found that to be useful
okay so I'm going to turn it back over
to Paul we're almost out of time but
hopefully we can get a demo in here I
got to start the manager so as you'll
see over here there's a there's now a
target up here in the fourth column that
was pulled or pushed from the Raspberry
Pi opt in to the administrator I have
some artifacts listed here for the demo
and I've created a feature and
distribution from my purposes and just
going to have even number of features
and distributions but typically you
would break down into features and then
put those features into distributions so
basically to get it out and get this
base system out to the target I just
drag and drop it into the target and
then at the store button and then so in
a little bit once the everything loads
up I'll show you what that's done but
I'll go through a few of the features of
this Management Council basically what
you do is you can add a feature just
caught one what I have is uh is just a
basic website with with just a hit
counter on it and I'm going to show that
show how you just deploy individual
incrementer components into the system
at runtime and have them switch out and
be available to change the pic culprit
so if i take component one component
that you can drop it into the future
I had a new distribution then they can
take that feature and drop it into the
distribution and then i can not i'll
create a crate the next one right away a
new feature called 10 which will
increment by 10 distribution bad traffic
in
running to go out to the web this is the
web server serving up HTML page from the
raspberry pi just a simple hit count now
if I hit I don't get any count change
because they haven't put in an increment
yet so if i go back to my counsel and I
say oh I want to put in incrementer by
one and I drop that into the target hits
store come back to my web console now it
starts incrementing by one the rest of
the application didn't go down it just
added in a new component it's using osgi
declarative services so it automatically
pulls that component in as the component
it's going to use for the incrementer so
then I say well you know I'm not getting
a lot of hits so I want to I want to
change that out and make it look like
I'm getting a lot more so I'll count
each hit as 10 so I can take my ten
component drop it into the target I say
well I don't want the one component
anymore slice I take that component out
of my target deployment I hit store
again go back to my web web screen and
now it's incrementing by tens instead
it's it took the one incrementer out
replaced it with the ten incrementer
associated that with the web server and
automatically started to get an upgrade
in place at runtime kept the web page
kept all its state but headed in a
different component to increment at a
higher rate any questions on that
okay so that was pretty cool I'm
actually glad you got that to work it's
the first time I saw it but you know so
basically uninterruptible processing
deployed from remote against a lot of
targets you can kind of see the
potential of this this kind of
flexibility so that was pretty cool all
right I think that's just about it i'm
sorry we've kind of used up most of our
time but if there's any questions trying
to answer them now okay all right thanks
for coming yes</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>