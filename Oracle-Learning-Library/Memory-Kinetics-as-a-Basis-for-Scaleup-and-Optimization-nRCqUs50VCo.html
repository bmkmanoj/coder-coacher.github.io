<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Memory Kinetics as a Basis for Scale-up and Optimization | Coder Coacher - Coaching Coders</title><meta content="Memory Kinetics as a Basis for Scale-up and Optimization - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Memory Kinetics as a Basis for Scale-up and Optimization</b></h2><h5 class="post__date">2013-02-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/nRCqUs50VCo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to this afternoon session will
be talking about memory kinetics
kinetics studies the rate of change in
the case of memory we have the
application and erica's memory of
concerns memory we have the GC that
cleans it up so um how the system
performs that them is determined by the
relative strength of those rates my name
is Kenny you I don't just watch TV I
directivity that's our slogan so have
you ever had problems with these issues
like excessive GC activities prematurity
know and I've had a plenty of this I was
called into situation why the system is
hanging so I took a straight nom look at
what's happening it's running GC one
hundred percent and GC was four and when
I increased say heap it does the same so
we're going to look at these issues and
to an end I will present a prescription
to these headaches now objectives they
sound very simple high throughput little
pause time and low cost of GC very ideal
okay but they were very vague and
abstract so let's look at something more
concrete usually when problem happens we
see the GC costs going up the total cost
of GC is the frequency of GC times cause
priorities okay when we increase the
load
the frequency increases as well as it
costs participe because you have more
debt objects to clean up or possibly and
that's not the worst case maybe you have
more live updates right so they cost mgc
as a percentage of CPU increases when
Nick opens up at sudden level of load
the CPU is consumed by GC you can no
longer run your application so the goal
here is to change the red one to the
Green Line we want to maintain the cost
of GC below ten percent little bit of
course but we don't want the line to
burn up sharply our approaches is to
control generational distribution and
managing Eden and survival spaces to
control GC intervals and manage odeon
capacity OC to minimize ogc this is a
call this is everything we need to know
about kinetics little saw the capacity
is a rivalry times the whole time a
rivalry in this case is how fast the
application advocates memory whole time
is how long those objects live and the
product is how much memory you need this
law applies to not only the whole the
heap as a whole but the subsystems even
survival and origin because their
problems can happen in any of those
regions and
littles law is to regardless of the
distribution of retention time if we
take the hip as a whole it's quite
interesting that it's obvious that we
want the objects to live as briefly as
possible that is the whole time and we
can minimize the capacity when you to
keep this in mind as we go forward now
to make sure what we are talking about
we use hotspot the memory is divided
into a few regions even survivor tenure
or what we call OTC and Prem ampang we
are primarily concerned about the first
three regions in Survivor and origin
first we want to stress the importance
of generational hypothesis we wanted to
be enforced in a previous previous slide
will mention the whole time we want a
whole time to be as brief as possible
therefore we want the Musa sorry we're
on most objects to be here to live very
briefly inevitably we have some long
living objects like the caches that
structural data we want them to stay
forever but because the population is
relatively low most subjects not here we
want this point to be way high so the
average age that is a whole time in
littles law will be brief to achieve
this at some point in our case we did we
redesigned application to polarize the
generational distribution by
mechanization
lighter we make sure the objects don't
stay too long you only stay as briefly
as possible therefore we if possible we
put the sessions in requests instead of
settings and we set up nonliving caches
for that area now with that in mind we
can move into some numbers we can
measure how much old gene space that's
needed as a minimum to get that will
trigger a 4g see now that will give us
upon the 4g see we have this odeon size
that will be the minimum size that is
like all fixed elgin notarization the
origin is reading can be divided into
two parts one is fixed net will not
decrease that's for the structural data
and caches another is variable that
depends on your load level the faster
you run your application the variable
power increases so in this case we
measure the fixed part of the origin to
be 1.5 gigabytes right also from another
GC run we can measure the rate of
allocation in the young gee mr. lounging
it copied this much objects in 0.3
seconds so here we can measure the old
gene utilization fixed part upon a 4 GC
to beam up on some gigabytes and we
measure the survival coppery one and
forty megabytes per second those will
come in handy when we design the sides
and from littles law we also know that
the origin capacity minus the fixed
point that is a variable part if you did
divide that by the reign of usage of the
old gene that will give you the 40 c
interval so when negative Oh genes for
it needs to run for for GC we want that
to be wrong ideally once a day with that
information we can move on to young GC
we want to control how often they don t
see runs if it's to brief the objects
well over flow to origin the folder that
if the time is too long you need other
memory and the pause maybe longer to
determine young jeezy interval we would
need to measure the response time that's
a rough estimate of how long your
updates live in the young generation to
capture most of the objects we measure
the response times without GC I low load
because I low load GC done I run often
so the response times is are not
affected by GC and I want multiple that
by a factor to make sure when the young
jeezy runs most of the objects in a
young Jean are dead so in my case I said
for some people suggested studying a
statistics to make sure over ninety
percent of the objects in jungian are
dead when you run point kick off the
young ji soo
so we know how often we need to run it
on young GC and we know we need to know
how fast application allocates objects
in the engine with that we can calculate
the capacity of young of Eden to measure
that to make a memory allocation rate on
the load by on the load I mean you check
the cpu utilization you make sure it's
up to reasonable percentage thirty fifty
percent then you trigger and two runs of
young GC from this here we have the
stunning point we have that size and
studying time and until the next one we
have a new size young in size here we go
four gigabytes and we'll have another
time so if we take the difference in a
memory utilization divided by the
difference in time we see the
application allocates 80 megabytes per
second therefore we know the young jeezy
frequency we got that from the response
times with do the multiplication we know
they in size used to be two point four
gigabytes that's quite sizable in
so the seconds
30 seconds that's young jeezy frequency
that's at that time we figure within 30
seconds most of the objects in enon web
bday so so we application response time
same river exactly so most of the
objects are used by the request you send
a request since our response during that
time period the objects should have been
there that's how long they live the
rough estimate so we know the Eden size
now we move on to survival size to
measure the actual utilization of
survival size we use that to determine
to fix the size of Survivor space to do
that we manually set the survivor size
to be very large very very oversized
basically and you watch what size is
being used the actual utilization of
survival and you set your survivor
capacity to be twice the maximum
survival utilization in our case with a
girl that will be 200 megabytes as to
how to measure this you'll see in the
following slides let me jump with me I
use just snap to measure survivor size
capacity and survival utilization you
see survival utilization change the
change the jump to hear when copy from s
1 to s 0 so I figure that's like 50 my
comments right there so yeah that's how
I measure
survivor utilization yeah anyway we
measure survivor utilization now we come
to two key relationships Eden
utilization is proportional to the load
the more load upon on it the more it in
size your use because we fix the
frequency young jeezy frequency
similarly the more loading port on the
system the more survivor the tradition
right these two I opponent because they
are both proportional to the load
response per second if we take the ratio
that should be constant to the
application there for survival ratio is
independent of workload because they in
and survival both the proportional to
the workload you take the ratio the
workload is cancelled out so survival
ratio is a property of the application
no matter where you run application how
many CPUs you have on different only
where survival is you should be kept
constant night will come handy it will
be important in our design of scale up
and optimization in our case a figure
even used to be this much survivor needs
to be this much iteration used to be
tell to be more conservative you can
keep it smaller 12 to 10 to make sure
survivor is never for in my experience
if the survivor is too small or if you
let the jvm adaptively say the survivor
size usually that size is too small when
that is too small when you ramp up the
road now objects a prematurely
promoted to origin in some cases I saw
survivor utilization to be zero because
it's not enough for the copy so the
objects goes straight from into the
odeon and Odin gets fed up very quickly
all this appeals are running GC 40c oh
by the way 40 CEO or the GC in the old
generation is very slow ok now we figure
out Eden size survivor size and survivor
ratio now we look at the origin how much
size will give it and what behaviors do
we expect we could measure the overflow
rate on the load and this how fast Oh
jingle tradition grows here for example
we get a number every 10 seconds using
Jeff stack we fetch the numbers every 10
seconds in five runs we watch Oh Jean
utilization because the first few digits
are the same with just look at the right
numbers to the end in our case the
promotion rate is change of old gene
utilization divided by the time I'm in
this case 50 seconds we get the
promotion rate
with that we can determine odeon
capacity we have a wish we want that old
gene interval to be long we don't need
to run we don't want the 4g see to run
too often but in the night we will
refresh the caches would do at the kind
of cron job so you can't really prevent
it for TC to run in a night so it's fun
to let it run in the night so we can set
the old incapacity to be a fixed plastic
a spare the fix is what we measured
previously by triggering a 4 GC and the
spare is a promotion rate times the
interval how often you wanted to run
here's a prescription for the memory
headaches our goal is to design all the
sizes and frequencies of the sizes of
the regions and frequencies of g0 upon
for TC we measure the fixed odeon
organization and we use that as a basis
for auditing capacity we increase the
load use the response times to determine
young jeezy interval on the load load we
increase the load to measure the memory
allocation rate given an interval we can
calculate the insights then we oversized
the survivor to measure the survivor
utilization with that compared to the
engine size we get a survival ratio with
load and
indan capacity survival capacity we can
measure promotion rate with that we
determine the for GC interval and the
size of OG so we have prescription based
on the kinetics the rate of a location
and rate of Reclamation we design the
tcp heavy the final configuration goes
like this we fix the survivor ratio and
we want to disable the adaptive
survivors as policy because adaptive
size as I pointed out earlier it's not
that meaningful because it changes
survival ratio while we conclude that
the survival ratio should be kept
constant for the same application and we
use CMS for the OG in parallel for the
young Jean and we control how often at
what condition and this disease run and
we give it the heat Toto heap and young
generation size for scale-up now we have
our
we got the basics for scale up to faster
and more geez CPUs that is also
optimization on the different hardware
conditions son intense we need to keep
constant that is fixed so gene
utilization that we can measure and
survival ratio other factors are CPU
dependent as challenging you MTC
interval that depends on a cpu power
that comes from the measurement of
response time other factors need to be
adaptive in fact need to be proportional
to cpu and throughput that is how fast
asleep iran's how many calls you have
and how much lowly plant to put on the
system knows what determine a in in size
and spare audiences
so in the end we report the performance
results as designed we want a 40 °c to
run once a night so in the day we don't
want the focus to run we were quite
lucky to realize that because we
refactor the application such that most
of the objects die in Eden and survived
because we said their survival space to
be quite large so within 31 Alec GC runs
that be dead memory problems solved the
system is stable GC pauses for about 50
milliseconds the application becomes CPU
brown this needs some explanation how we
are sure about it because we design the
even size add fifty percent cpu
utilization and if we double in size
then even if you put on double the load
that is even if the application runs and
one hundred percent cpu that GC will not
be busy therefore we realize we made
sure that GC is not an issue the
relative cost of GC as a percentage of
cpu utilization is below ten percent and
response times is stable outliers are
eliminated
I thank my colleagues for help to get to
these numbers we had people running low
runner and configuring the system always
and weblogic for large pages usages and
thank you for coming up regard to
entertain your questions
we r memory
well it depends on when the memories you
see if users heap memory is still here
right if you don't use heap memory we
cannot control that
you could you can study the allocation
detail with some profiling tools but
that will make things much more
complicated than studying the heat
cassius extra stay in the heap I've you
see okay profile but for your purpose
i'm not sure that's needed because you
you know the life cycle of the caches
right you set it up it's in the
configuration file so you have some idea
how long they live so you can estimate
their impact on the og cash is stapled
alone you want them to stay on and you
know they live in OG
you need to do similar studies with each
release you need to study the kinetics
how fast a application allocates memory
development jobs we have the test system
set up in development so we have fairly
different machines in the event we can
run such a nice
you could there are tools for recording
allocation and the sizes but they are
very intrusive the change that
application profile and also in the case
of web application they each thread
pretty much behaves similarly so you can
just do the average
Oh
well the closest then I did was to study
one type of request at a time if they
requests are not homogeneous and then I
get some idea about the average and then
I'd tune for certain problematic
requests
yeah he's asking about is there any
easier way than reading the GC love with
your eyes and as ical familiar with the
GC log I found it quite convenient just
to read are you some tools that draws a
lines before and TC after t see this
wonderful
you
another device
right dear no they don't like that and
the application I study is the business
application is whenever you go to the
website when partners call us when
people complain they run our vacation
well we can't make it longer because in
the night we have refreshes in the night
we add new rules and new models prices
far as channels so we expect something
will happen at night so we cannot make
its way into longer than 24 hours so yes
potentially yeah so we figure in the
night we could rotate the servers to
refresh so 24 hours
yeah it didn't work well for me you see
even CMS parallel new didn't work quite
well that's why we are manually setting
notice parameters and disabling the orgo
as the adaptive policies yeah because
the default survivors size by those
systems are quite ROG that is the size
similar size was too small and eden size
was too small the default allocation is
huge Oh Jane small yangjiang that
doesn't fit our me
that's right
classic
depends on how long you live as littles
law they show that those things live
they better or if they have to live very
long they have to be very few otherwise
you'll be in trouble so you want to make
sure I don't they live very long much
much longer than 31 that's the maximum
and generation before they get promoted
yeah very briefly if you have caches
they live for save one hour or two that
you cannot clean them up in Eden or
young Jin they have to be promoted then
you have to run more often ogc there's
no hermana
well the way you set up concon mock and
sleep will help so you want knows medium
term objects to be managed by the
concurrent threads
yeah it's only possible if you don't
have the problem here is that is you
have an objects Cashin objects that I
live for like one hour then public with
his problem probably you have to run it
for GC in a day
to origin yeah that would not work cause
thumbs and other thing is we use each
cache it is how long objects live at the
time to live one time too I know those
parameters are the key yeah once it
obviously is 64 bit so you can use seven
eight gigs of memory
yes I give my sides to match in turn so
you're probably uploading let me know be
available
thank you for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>