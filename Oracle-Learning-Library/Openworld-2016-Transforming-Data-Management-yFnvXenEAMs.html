<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Openworld 2016: Transforming Data Management | Coder Coacher - Coaching Coders</title><meta content="Openworld 2016: Transforming Data Management - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Openworld 2016: Transforming Data Management</b></h2><h5 class="post__date">2016-10-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yFnvXenEAMs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the optimizer will now be aware of it
some future careers will be directed
towards the memory card store without
changing the application very one of the
key benefits of using both Oracle
Exadata and Oracle Big Data of clients
is the built-in integration between the
two system and being able to just move p
db's pluggable databases straight from
on prem into the cloud and back if you
need to through a couple of clicks and
sequel developers really really is a
compelling case for looking strongly at
oracle public cloud
you
ladies and gentlemen please welcome
executive vice president database server
technologies Oracle Andy mandelson okay
good morning everybody we're going to
talk about a number of things today well
start off with just saying where we are
with 12 CR to you know this is a slight
Larry show last night for those of you
who were at the keynote but then the
bulk of the presentation is going to be
about how the world around databases and
information management is changing quite
radically and we want to talk about how
you know it's really critical if you
want a database technology that's going
to be relevant to you you know as the
world changes that we put in major
investments in our product to create the
innovations you need so that you have
the best you know if you go with oracle
database you will have the best database
technology to deal with all the changes
going on out there it's not clear a lot
of these other lower cost alternatives
that people talk about are going to be
able to do the investment to do that
sort of thing so that's the big thing we
want to talk about at the end of the
presentation we're also going to
demonstrate the new exadata Express
cloud service that Larry mentioned last
night and we'll show you how easy and
fast you can build a demo I'm build an
application using that cloud service and
we're really excited about it for a lot
of reasons and we'll talk about that at
the end okay so let's get going so what
are the big changes going on out there
now that are going to radically change
you know database and information
management as we know it today you know
the big three transformations that I
think are going on or number one we're
moving from disk-based in-memory
databases and this is a lot not quite
what you think it is because we're not
really there yet and what we're going to
talk about in-memory database and beyond
what we think about in-memory database
today to the next generation which is
going to be you know in-memory databases
in persistent DRAM data warehouses
moving to Big Data you know you all know
about that one and then finally of
course we're going to talk about cloud
cloud is the big generational change
that's going on now out there all of you
I'm sure starting to get pressured from
your management to start looking at
cloud and and looking at we'll talk
about what it means to have a database
that really is optimized for cloud and a
cloud that's really optimized for
writing database ok so let's start with
in-memory database so where we go in
here obviously you know 30 years ago
when relational database is actually 40
years ago when they were first designed
data was all stored on hard disk and
today of course the majority of you
still store all your data on classical
hard disk and the big challenge was that
was i oh you know I always slow you had
to minimize I oh and we created things
like buffer caches to cache data off the
disk to sort of minimize i/o as we move
to in-memory database you know now
you're optimizing for memory access it's
all about reducing cpu io overtime is
going to completely go away we know in
database 12c of course when we announced
it a couple years ago we talked about
adding our new going from just a row
store to a row and column store we have
this duel format methodology that lets
you get best of both worlds you still
get high performance transactions out of
a roast or but now you can get high
performance analytics of course out of
the column store and then finally you
know we're moving from this disk based
world where things like buffer caches
are really important to a world in a few
years where you're going to be storing
your data in non-volatile deram you know
there will there may or may not be some
hard disk backing them up or some flash
backing that up and once you do that
again the world is really going to
change for you and the world changes for
storage underneath databases to all
those existing sand storage technologies
a lot of you use their they're already
moving to obsolescence now they're going
to be completely obsolete in a couple
years as we've moved to the persistent
d-ring okay so let's talk about what
we're doing here
database 12c of course when it came out
with our new do formatting memory calm
store really let you do what we call
real-time analytics against your live
transactional data now you didn't have
to sort of have your old gb system over
here and then move data to another
system to have a data mart to have your
business users analyze that data
elsewhere so that that had a lot of
benefits it reduces complexity you know
you don't have to do this data movement
process and it also lets you have you
know incredibly high performance
scanning and aggregation of your life
transactional data right in the live
system performance was pretty incredible
last last time we demoed this we showed
you you can scan data with a single core
on an intel chip or spark chip you know
billions of rows or values you know per
second you know some incredibly high
performance scanning you can do
high-performance aggregation star joins
things of that sort work really well
using this technology of course we're
not seeing this technology make sure
transactions run faster in most cases
there are some cases where it does when
you can remove no analytical indexes and
replace them with in-memory column
stores but in general this is really a
technology to make analytics go faster
things like star schemas start queries
go really fast with this technology and
then of course the big thing is when we
do innovation in the database group our
big goal is to make sure we deliver this
innovation to you without disrupting
your applications you don't have to
rewrite your applications to use our
in-memory columnstore you just need to
turn it on tell us which columns you
want us to create in memory calm stores
for you and we're off and running okay
so um as I mentioned earlier you know
one of the big goals was was doing trend
you know analytics on your live
transactional data well a lot of
customers get nervous about letting
their business users you know running
analytics on light on their transaction
processing systems so what I would I
would say definitely was the most
frequent
enhancement for 12c and memory database
was the ability to move the calm store
off the production system and move it on
to an active Data Guard standby and
therefore they can get the most of best
of both possible worlds right they can
get high performance transactions just
using a pure roast or on the production
system no calm store there at all and
then use active Data Guard to replicate
the data near real time to a standby and
just create the in-memory calm store
over there so that's what we got for you
in in 12 CR 2 on the cloud and this I
think is a really key innovation that
other vendors don't support for their
in-memory database technologies of
course in-memory databases we're just at
the beginning of this technology there's
huge performance opportunities moving
forward in 12 CR 2 we're continuing to
do work to improve the algorithms we
have for doing joins complex queries and
actually Jason processing using our in
memory calm store I'm sure all of you
well actually I don't know if any of you
remember but when 12c was announced of
course we added support for json in the
database you can use sequel access to
your JSON data to extract data elements
right out of your JSON documents from
sequel and now on 12 CR 2 we will
automatically if you tell us a column is
adjacent column put that column in a
column store and have incredibly
efficient access to that data we're
talking about 60 times faster access for
JSON data which is force the the cool
new data format that are are your
developers want to use these days okay
and then the last thing I'm going to
talk about and of course there are many
other things in 12 cr2 around in-memory
database is on our Exadata database
machine so exadata of course has this
technology called smart scan and smart
flash cash and the smart scan technology
lets you do really high-performance
massively parallel scanning of your data
on the exit of storage well what we've
added now to exit eight is the ability
to take the data off storage which is
the first in the row format move it into
our comm store format in the flash cache
and now we can do these incredibly even
faster smart scans on Exadata using the
data in the column store format in the
flash cache so that's going to be new
with 12 CR 2 and exadata and now we're
going to do a quick little video and
have some customers talk about their
experiences with in-memory database once
which one initialization parameter and
that's it you're ready to go that in
defining tables to be either in memory
or not and the optimizer will now be
aware of it some future queries will be
directed towards the in-memory column
store without changing the application
very easy doesn't need any application
code change whatsoever that the fact
that you're able to take a row major
format turn it essentially 90 degrees to
the left and sideways makes it much
faster to get answers out for especially
analytical queries you can now run more
users higher degree of concurrency more
queries so that can be significant
really speed up the handling of for
example unstructured data like JSON or
XML in a database so for example on a
query that uses buffer cache was taking
around 72 seconds when we turned on
oracle database memory immediately
completed in five seconds it was about
up to 300 times faster than usual butter
care quit okay so just to close out this
section I want to just mention what's
going on that's really going to take
in-memory database to the next level and
that's something called an nvram or
non-volatile memory a number of
different vendors have announced they're
working on this technology and we're
expecting to see the first significant
shipments of this technology in early
2000
and this is going to totally change you
know this totally changes the
foundations of how you build a
relational database or any kind of
database for that matter because now
your data will be stored in memory
persistently right and so the need for
hard disk especially for smaller
databases or even flash memory is sort
of not important anymore for a
relatively small middle sized databases
you'll still want hard disks for large
data warehouses your big data use cases
but when you're in an environment with
non-volatile memory the whole original
classical architecture for relational
databases using buffered caches to
minimize iOS too hard disk is no longer
relevant and so all the database vendors
if they want to be relevant in a few
years when this technology starts coming
out I need to rethink their whole
database architecture so if you know
you're using a database that was
designed 20 years ago and nobody is
really doing much enhancements of that
product anymore it's not likely going to
be other wit be radically redesigned
here so we are going to put the
investment in do you completely redesign
the Oracle database architecture for
this technology in the short term we're
also going to do a lot of work in 12c
and you'll see as this technology starts
rolling out 12c will have support for
this kind of for using non vult oh dear
am in some interesting ways nom to
volatile DRAM is going to be an
interesting technology that's sort of
in-between DRAM and flash it'll be much
more expensive than flash but much
cheaper than DRAM and it'll be much you
know the performance will be almost as
good as DRAM and so it sort of fits in
between those tech to technology and so
one of the initial use cases will be
just using it as sort of an extended
memory so you can extend the size of
your buffer cache extend the size of no
other in memory structures in the Oracle
database using non vult oh dear am as a
use case so that'll be sort of the first
thing we do with this technology and
then we'll go on from there to do some a
lot more sophisticated uses but anyway
this is an area of huge investment in
the oracle database group just want to
let you guys know about
okay so let's go on to this second big
transformational area moving to big data
or would we go our big data management
platform and I just want to go through
the history here a little bit because
there's a lot of hype and confusion
about big data even now years we've been
about five years into this so we're
we're going from a traditional data
warehouse which by the way is still very
popular and most customers only need
traditional data warehouses they don't
really need any other platforms but a
lot of customers were looking at using
now not just relational databases for
their data warehouse but they're also
looking at other platforms they consider
big data platform for storing other
kinds of information we'll talk about
Hadoop and no sequel there and of course
we're moving to cloud as well the other
big change is what is really what kind
of data your business is trying to
analyze in your data warehouse or big
data management platform originally data
warehouses were really about gathering
up all your transactional data from all
your transactional systems and you know
integrating it together into a data
warehouse now customers are looking at
gathering more kinds of data there get
at gathering data off the internet from
from the social media to get more
information about their customers if
you're a manufacturer you're getting
information out of your you know your
real-time manufacturing processes now
all the devices and cars and every you
know in your home or computerized
there's a lot of data now streaming in
from those devices so there's new kinds
of data that people are trying to
analyze okay and then finally you know
on the analytic side you know we've
always had sequel analytic functions
we've had data mining in the database
for 20 years now we're also moving into
the world of machine learning machine
learning you know some people claim it's
just a different name for data mining
but it's it's you know it's actually
slightly just the next generation of
data mining technology and as you saw
Larry's keynote last night machine
learning is really cool these days and
it is another big
area of investment around the data
management platforms and so just
visually just what you know just walking
through what we just talked about you
know we started with the data warehouse
people start have started looking at
using Hadoop HDFS as an extent as a file
system that sort of sits in front of the
data warehouse and creates what people
call the data like which is a place
where you can capture large amounts of
this data that's now streaming in maybe
from the internet the web internet of
things and you can store it at low cost
before you really decide whether it's
really valuable to the business or not
and Saudi the lakes are forming as a
replacement for the you know old vanilla
file systems that people had and it's a
way of storing pretty much all the data
you think is relevant to your business
at low cost you can do some filtering
some ETL on that data and then you can
move the valuable data into your data
warehouse to do you know
high-performance interactive analytics
okay so that's sort of the foundational
elements of what we now call our big
data management platform and then
strategically on top of this platform
the idea is to provide you with all
kinds of analytics across all these
different kinds of data it shouldn't
matter where the data is it could be in
Hadoop it could be in a relational
database it could be in a no sequel
database you should be able to plot
employ all kinds of analytics from
sequel on to things like graph and
machine learning spatial etc and all
those api's should be available for your
developers to use across all these
different data repositories and it
should be transparent to your developers
they shouldn't have to know what
repository they're getting the data at
it and then finally of course any kind
of language or developers want to use to
access that data beyond sequel things
like Java rest are Scala Python etc all
those should be available as well so
this is what we call our big data
management platform and this is sort of
the foundational element of what you
know what we're doing is to help you
move into
is era of big data now the big
technology innovation that my group is
working on here is around this area of
transparency you know how can we give
you transparent sequel access using
Oracle standard Oracle sequel to all
this data no today you can go first go
to Hadoop and you can have you know they
have 17 different dialects of sequel you
can use to get data out of Hadoop
systems but those those languages you
know like hive sequel they can't really
get at data in your no sequel system or
data in your Oracle database so what we
are working on and what we we've been
shipping now for definitely about a year
and a half now is something we call Big
Data sequel and it gives you transparent
access from a single sequel query to all
your data in your big data management
platform and it it does a lot of the
same tricks we have figured out for the
Exadata platform except we do it across
all these data sources we ascend
effectively do are doing smart scans
across a Duke and smart scans across no
sequel systems and then we can join all
that data together in massively parallel
fashion and return results to you okay
and also because we're sort of you start
off from the metadata in an Oracle
database you can take advantage of
security rules that you put in the
Oracle database for things like data
redaction row level security etc okay so
that's big data sequel what's new is our
Jason support you know I mentioned we
now have native support for Jason in the
database and Now Big Data sequel also
will support Jason as well across all
these different data sources and you can
use big data sequel to query your JSON
data whether it's in Hadoop for no
sequel or an Oracle database in the
Oracle database in particular actually
actually in all the different
repositories we have a new capability
called our data guide for Jason and that
basically lets us sort of scan through
your JSON data and we can sort of figure
out if you know if all the jason combs
seem to have the same schema we can tell
you sort of what the scheme oh look
like we'll publish it in our dictionary
to make it easier for you to query the
data okay and i talked about know beyond
sequel we want to have a whole
collection of standard analytic
capabilities that let you seamlessly
query and access and analyze all the
data across relational databases Hadoop
and no sequel and the two big areas of
emphasis now are around machine learning
and graph technologies we've had spatial
and multimedia of course capabilities
for many many years in all these
different repositories machine learning
now of course is a hot new area people
are using are especially to do things
like certainly a little just aggression
algorithms things of that sort to do
predictive analytics spark and spark ml
are becoming very popular for analyzing
data especially in Hadoop HDFS so we are
working on within the context mostly a
spark ml to give you parallel high
performance data mining algorithms that
will work across all these platforms and
essentially enhance and extend the
capabilities in spark ml on the graph
side we actually have built completely
unique algorithms from the ground up we
have like over 40 algorithms of
in-memory graph processing algorithms
that let you analyze things like social
networks or our networks you know if you
look in different industries there's all
kinds of different kinds of networks you
know telcos out telecommunication
networks you can create networks based
on you know in the telephone space you
know who what person calls what person
who calls another person and create very
interesting networks to use to reduce
churn and other things there but anyway
graph is becoming very interesting as a
technology and we've put in a big
investment to have these graph
algorithms available in both the Oracle
database and Hadoop and our no sequel
engine as well so this is a big area of
investment for us as well to give you
you know the analytics against all your
data and your big data management
platform and now we'll hear from some
customers on what they're doing with big
day
the biggest challenge has not been about
finding data about the customer to try
to understand what's most relevant to
them but it's been you know applying
every science to the large volume of
data knowing that we were going to use
production our production environment on
Exadata the idea that we could leverage
a bigger plants and have that direct
link the direct integration was another
big benefit saves us a lot of time saves
us a lot of energy since we adopted
accelerator we no longer look at data
samples we look we can now run our query
on on the entire data set the ability to
get that answer get that that that
insight within minutes rather than days
is quite quite impactful to your
business one of the key benefits of
using both Oracle Exadata and Oracle Big
Data clients is the built-in integration
between the church system so it's given
us massive advantage from a speed to
market perspective we've been able to
all our solutions test them and roll
them out much quicker than we were able
to do before
okay so we're going to talk about cloud
next but before we go to that section I
thought I'd just you know for this
section just remind you all we have two
services in the cloud for big data of
course we have our Exadata cloud service
for the relational pair of massively
parallel query part of a big data
management platform but we also have our
big data cloud service which gives you
the spark and Hadoop capabilities as
well and those two platforms are being
integrated together in our cloud and we
will very shortly have a big data sequel
cloud service also that lets you do this
massively parallel scanning across all
the data in in both cloud services the
big news in our big data cloud services
we're just now adding you know probably
a couple weeks away from going live with
support for no sequel database as well
and so will soon have all these three
platforms i mentioned that make up our
integrated big data platform you know
oracle database a dupe and our no sequel
engine will be all up there in the cloud
and you'll be able to use big data
sequel across all of them it's very
exciting offering quite differentiated
from what I think you can get anywhere
else in the cloud with around big data
okay so let's now talk about cloud of
course this is the big
multi-generational generational change
that's going on out there and it's sort
of interesting a couple years ago I
talked to customers and cloud was
something of interest but they weren't
really planning to do anything but now
even the big enterprise customers are
getting under immense pressure from
their management to start looking at
cloud and so it's really important that
we make sure you know we have excellent
database cloud services up there for you
and we're going to talk about what we're
doing in the cloud for database and why
we think it's better than what everybody
else is doing so as a preliminary part
of this first I thought I'd talk a
little bit about engineered systems so
if you think about it engineered systems
are a very interesting
transitional technology to clouds you
know they automate the process of
designing and rolling out complex
computer systems optimized for running
like the Oracle database Hadoop doing
backup and recovery etc so these kind of
technologies are really important things
for you know things you can use on Prem
but there are things that are going to
appear in our cloud and they're really
what makes our cloud uniquely optimized
for database so I thought I'd put that
up here and there are a lot of sessions
this week that are going to go in detail
about all these different systems
Database appliance we have a whole new
class of lower and versions of that that
actually are now just single server
versions of that but they're not they're
not rack clusters so you can start up
with the database appliance now at a
price point that's I think it's on the
order of 20 K or so very low-end
low-cost servers optimized for database
the recovery appliance has been a very
successful new engineered system for us
we're seeing a lot of customers who
haven't ever you know up take any of our
engineered systems who really viewed
recovery appliance as solving a major
headache they have for how do you backup
and recover in you know very rapidly
large numbers of database systems out
there in their data centers so that
product is doing quite well so let's
move on to the cloud now and we want to
talk about a cloud that's not just any
cloud you know that's you know everybody
can put up commodity servers and storage
and say they can run databases on them
you know that's really if you look at
what what are the competitors doing out
there that's what they're doing there's
nothing special about it it's just
database running on commodity VMs you
know nothing exciting and the problem
with that design is that you can't run
anything other than stuff that we can
run on commodity systems and so all of
you know that when you get up into the
mission more mission critical systems
large data warehouses those kind of
infrastructure is just 0
work and so customers who have looked at
moving oracle databases to these
commodity clouds sort of can do it for
some simple use cases dev test simple
production systems but they can't really
move everything up there and what we're
trying to do is create a cloud that is
really truly optimized for database and
still satisfies the key requirements for
cloud you know people want a lower cost
they want high agility you know
provision me a database in a couple
minutes and they want elasticity and
we'll talk about now sort of how we are
delivering on you know the cloud
challenges using our database optimize
cloud so lowering costs so people think
oh the reason I can lower cost is
because I can go to a cloud and the
hourly costs are cheap well you know
that's when people do the math
especially the enterprise customers who
have big investments in data centers
it's not necessarily all that cheap just
by looking at the you know the hourly
cost but the place you really save money
in a cloud is around how you sighs your
systems so on Prem you tend to size
these big systems based on peak capacity
demands and you know for example your
retailer you sighs your system to be
able to deal with the Christmas shopping
season right um so what happens on Prem
is you end up with a lot of servers that
are very underutilized it's very
expensive to have these underutilized
servers out there and the big thing that
cloud can can help you with is if you
only temporarily want to run a project
or you want to burst to peak demand you
only have to pay for that and then after
the peak demand goes down of course you
can lower your cost infrastructure after
that and that's that's the big way you
can lower costs in the cloud another way
you lower cost of course is just the
time to the deployment you know cloud is
very low cost Rapids self service
provisioning an upgrade upgrade of
course is very expensive process on the
cloud it's all automated for you for as
part of the cost of the service and then
finally you know if you have large
numbers of databases managing all those
databases is expensive doing all
patching in uh parades and everything on
the cloud that's all automated for you
and at the same cost of the subscription
so what is the key technology we
delivered in 12c for cloud well the key
thing is we made a huge investment in
what we call our multi-tenant
architecture we think any database
that's going to be used for a cloud
whether it's a private cloud on Prem or
a big public cloud needs multi-tenancy
in order to solve these key challenges
we mentioned earlier no you need to be
out of provision databases instantly you
need to be able to manage across large
numbers of databases very low cost multi
tendency is the key architecture for
doing that and if you have a database
that doesn't have multi-tenancy you
really don't have a database optimized
for the cloud so just simple review what
does multi-tenancy do it gives you this
new 12c container database inside that
container database in 12 cr1 you could
have up to 250 two of these things we
call pluggable databases or virtual
databases that you can use to run your
applications your databases in from
previous releases on this lowers
operational costs because now you can
manage what we call managed mini is one
where you can manage across all these
pluggable databases in a single
container with the push of a button you
know do a back up with one of all those
databases in the container do an upgrade
do a patch etc the other improvement
here is it's much more efficient so you
can actually lower capital costs as well
because all these these pluggable
databases are sharing the same hardware
infrastructure the same computing
resources for CPU and memory are all
shared across these databases and you
can there forget you know cost savings
because of the sharing and get many more
pluggable databases or databases on a
given server with multi-tenancy than you
could do you know when you have
dedicated databases ready on the server
and finally agility I'm pluggable
databases give you huge agility you can
unplug a database from one container you
can plug it into another container and
you can clone the pluggable databases
especially for test dev that's a really
important use case so it's a very
good infrastructure to meet the needs of
agility and lowering the cost that
people want out of clouds so what are we
doing in 12 CR to the big thing we're
doing especially for customers you know
as we look at public clouser or SAS
customers who want to deploy maybe their
their applications on a public cloud you
know sometimes 252 p db's isn't enough
and so we're going up to supporting all
the way up to 4096 PD bees per container
we're enhancing resource management to
improve the isolation between the
tenants from a performance standpoint
who share the same container we're
adding memory resource management into
12 CR 2 we also are adding io resource
management across all platforms as well
in 12 CR 2 and finally the last area
especially for public clouds where you
you need huge you know very strong
isolation between tenants we have
stronger ability to lock down the
ability of two tenants in a multi-tenant
container to to share information you
don't you know in a public cloud you
don't want any sharing in a private
cloud on prem you actually might want
cheering of information across p DBS you
might want to do distribute query across
PDP's for example but in public lab note
you need really tight lockdown isolation
and we've added you know strengthen that
in 12 C or two and then the last thing I
want to talk about is SAS so if any of
you are is vs or thinking of becoming is
vs and you want to take your existing
application which might have been
written for on Prem and you want to
become a software as a service vendor on
the cloud Oracle multi-tenant makes it
really easy for you to do that and you
know you create a container database up
on a cloud each of your customers can
get a PDB and now you're in business you
can do a very low cost very simple to
implement SAS for your application so in
12 CR 2 we're we've added some new
capabilities to help make the SAS use
case even more efficient the big thing
we're doing is
enhancing sharing so of all your
customers up on in the same container
running the same application you can
create what we now call an application
container that lets you share the
metadata and the code you know the
stored procedure code and even reference
data across all those tenants so you can
have even more efficient SAS on the
cloud okay so we talked about sort of
lower costs and now let's talk about
agility here and agility of course is
one of the core concepts of cloud
computing and you want to move from your
your on-prem infrastructure where it can
be months to provision a new database
and getting it through getting those IT
guys to get it up and running for you
sometimes the business users are not
really happy waiting a couple months and
so they really like this notion of self
service provisioning where they can just
say give me a database with this kind of
configuration push a button and get the
database in a few minutes right so
that's what people really like about
clouds from a use of usability
standpoint and so you can go for months
two minutes to deploy and of course
upgrade all those kind of things and
we're going to talk about especially in
12 CR to some things we're doing around
multi-tenant to make our cloud
technologies even more agile okay so the
big thing we're working on in 12 CR one
we had the ability to you know unplug
and plug pluggable databases to move
them from one container to another we
had the ability to clone those pluggable
databases but to do those operations
required some downtime you know while
you're unplugging and plugging or
cloning in 12 CR to all those operations
are now hot online with no downtime of
any sort so you can do hot clones you
can also do something we call refresh so
if you've cloned a database for a test
environment and a few weeks later you
want to refresh it back to the contents
of production you can now just push a
button and it'll refresh it for you
again live online for you and then we
can do this on
like plug operation online as well we
call that relocate of a BB so that's big
big improvement in 12 CR 2 and now let's
hear from some customers about
multi-tenant thousands of pluggable
databases and being able to manage those
resources more effectively is definitely
a great new feature the ability to do a
whole lot of new activities with it
never taking that database offline so
the business interruption in 12.2 is
zero division is really complete the
ability to do application containers the
cloning facilities everything is just
going to make delivering a SAS solution
much much easier the ability to have a
proxy pdb that essentially allows me to
reference that pdb in a completely
different container database and never
even having to worry about presenting
that difference to the user it's
completely transparent location
transparent to the user as we say okay
so we talked about how clouds lower-cost
how clouds give you more agility and
then we're going to close on the last
section which is you know elasticity so
what do people mean by last icity well
this is the ability to you know scale up
on demand scale back down again you know
we call that bursting actually in our
cloud service so we have some new
capabilities there I'll talk about we
already talked about provisioning for
capacity on demand as a big attribute
for lowering costs in the cloud and then
finally we're going to talk about a new
area called sharding which is a way of
scaling your applications as well on the
clown okay so on the elasticity side I
thought I'd just remind people you know
we have this technology called real
application clusters that we designed
you know back in the early late 90s
early 2000s to make Oracle into a
scalable platform for both transaction
processing and data warehousing parallel
queries
this technology has turned out to be
hugely differentiating technology for
Oracle other vendors have figured out
how to run parallel queries and do scale
up for data warehouse but they've never
really figured out how to do scale out
for transaction processing so our rack
technology has been really important for
customers who want to scale out on
whether it's on Prem and now moving into
the cloud of course it's really
important that rack be available in our
cloud and of course if you look at other
clouds as I mentioned earlier all they
care about is running a single server
oracle database on commodity
infrastructure they don't support rack
technologies which you know it's another
reason why other clouds are not really
good for running your Oracle database so
so rack is an area we're still investing
in in 12 CR 2 of course there's some new
technology to make sure that if you want
to run a rack cluster with a
multi-tenant database there are various
kinds of interesting optimizations we
can do there you know a lot of the
multi-tenant pluggable databases may not
be big work loads that need to scale out
across the cluster they tend to maybe
just need a few cores on a single server
so the crack cast fusion protocols are
now being optimized in 12 cr2 to
minimize any traffic if you're just
running a workload that doesn't need to
scale out but you can still have the
advantages of having a large scale out
cluster to run your hundreds or even
thousands of pluggable databases in a
single container we're also adding some
capabilities for a rack for customers
using a big data warehouse where you can
now you know our typical big data
warehouses today are up to maybe 40
nodes in Iraq cluster frankly a lot of
customers haven't really needed to go
any higher than that but in 12 CR 2 we
now have the ability to go out to
hundreds of nodes if you want to run a
really massively parallel huge data
warehouse style database for something
like the big data use case we mentioned
earlier so what about charting what is
it first of all so you know rack works
for scaling database applications with
high performance and high reliability
for almost all the use cases you know
customers even our biggest enterprise
customers have but there are some
extreme cases and my favorite example is
ecommerce you know thinking about
amazon.com you're raining this global
e-commerce system across the world you
can't run this whole system in one
database even a big rack skala cluster
can't do it and so what you want to do
is something called sharding and what
amazon has done for many many years is
they they don't run their e-commerce
transaction processing system on just
one oracle database they run it on
hundreds and these databases are called
shards and they built this manual
sharding process where they too have a
database that does the e-commerce
transactions let's say for the western
part of the u.s. over here another
database that does e-commerce for the
central part of the u.s. another
database that serves the East Coast and
then another database that serves you
know japan etc etc so there are hundreds
of these databases running their
transaction processing and of course
this is incredibly scalable
infrastructure it's highly available you
know if any single database goes down it
only affects a small part of the world
and they can fell over even in that case
so it gives you very highly reliable
highly scalable infrastructure the
problem with it is you have to design
your applications for this kind of
environment because you have to make
sure that when the request from a
customer in California goes in that
request gets routed to the right shard
the Tamil in the California database and
there's all this operational costs
around setting up and configuring all
these databases so we have a lot of
large customers who want to deploy these
kind of global transaction processing
systems who have asked us to help them
automate that process you know take away
the labor costs make it much easier to
use so that you can rent sharded Oracle
database at very low cost and that's
what we've delivered in 12 CR 2 and the
interesting thing about this if you if
you think about it if you want to be a
start-up let's say e-commerce vendor you
can now as we deploy you know sharding
in our cloud have the ability to build
something like what amazon.com has very
quickly because we can just automate
that whole process of configuring all
the shower
for you in a clown the other thing
customers really like about this is we
offer two ways of replicating your
database in a shorted database you can
use active Data Guard for creating
replicas or you can use golden gate and
we will automatically configure all
those systems for you and so for a lot
of customers this is going to be a
really nice way of automating the
process of creating replicated databases
especially using Golden Gate where you
can have these complex multi master
configurations etc so that's what
charting is all about and we think it's
a really key component for any database
as you move up to sort of cloud scale of
course we have announced and have been
production for now well over a year with
our Exadata cloud service so this is
what I mentioned earlier in our
engineered systems are really what makes
our cloud optimized for database you
know other vendors just run commodity
infrastructure and you can run you know
whatever databases can work on just
commodities storage and servers on
oracle we now have an easy way to use
our Exadata technology up on our cloud
the price for the x rated technology is
actually just the same as when you run
what we call the extreme performance
edition of the database on our commodity
infrastructure on our cloud you get all
the power of Exadata without having to
have any IT people trained on how to run
the Exadata systems of course exited is
just Oracle so all your applications are
written for oracle database can just run
on this cloud service you have all the
benefits of the cloud business model
subscription based pricing etc one of
the new things we announced with oracle
exadata and we're now in production
there and also on our commodity database
enterprise infrastructure is something
we call bursting and this is exactly a
match for the use case i mentioned
earlier you know you're a retailer and
you want to grow your infrastructure to
meet the needs to get through that
holiday shopping season you know how do
you do that well our cloud service in
our Exadata cloud service you can now on
demand
line you know double the size of the
compute infrastructure under your
database no raise it for to the level
you need and just pay for those extra
capacity you need during the holiday
shopping season and then when that's
over you can go back down to your normal
subscription size so this is a big
reason way you can lower your costs by
running on our our cloud Larry talked
last night about how two of the big
tenants of Oracle cloud our
compatibility and portability so our
cloud you know Oracle databases are
compatible from across your on-prem
systems and into our cloud and even
other clouds right they're portable you
can move the database application the
database data from on prem to cloud and
back and forth all the same seals apply
all the applications just work no you
can't do this on other clouds and you
can't do this with other cloud software
you know Larry pointing out things like
you know red chip Amazon's written is
the service they have for data
warehousing if you build an application
to rich if you are completely locked
into that cloud forever you know you
can't move it on Prem they don't have
red shift on primp with Oracle you can
take your applications you can move them
up to the cloud you can run them there
you can move them back on Prem no
problem you're not locked in okay now
the biggest new thing we have in this
space is a third alternative to on Prem
and cloud something we call cloud at
customer so there are a lot of customers
in industries that are regulated like
banking or health care you know where
they need special environments for
running their systems there are a lot of
countries they don't let you move data
out of your your country you know
personal information about your
customers can't be moved out of the
country those customers are in and so
for these customers public clouds don't
really work today and so what they would
like is all the advantages of the public
cloud you know the business model
subscription pricing capacity on demand
etc but they wanted in their data center
behind their firewall and that's what
Oracle cloud a customer gives you and so
now for example Exadata can be
wait in three ways you can rent it on
Prem now the ex a database machine the
classic use case you can rent it as a as
the infrastructure optimized database
infrastructure on our cloud and get all
the benefits of cloud and now we have
this in between the approach at the exit
a a cloud machine Larry mentioned it'll
be available for 12 CR to actually in
December and this gives you the
advantages of the cloud cloud
subscription models Oracle runs it for
you but this will be in behind your
firewall in your data center so we're
seeing a lot of interest in this thick
this approach for customers as well and
then Larry also announced the x8 Express
cloud service last night so this is our
new entry-level service for the Oracle
database you get a full capable oracle
database using running on our optimized
Exadata infrastructure with enterprise
edition and all the relevant options
that can run they're all at a very low
price 175 dollars per month and we set
this price by the way so it is lower
than any entry level capability you can
get for running databases oracle or
otherwise at amazon so this service is
something we you know we'd love for you
all to just you know swipe your credit
card and you can today 12 CR 2 is up and
running there as of yesterday and we're
very excited about the service because
it gives us a really nice easy way for
customers to start playing with our
technology and you get to get the
benefits of things like Exadata cloud
subscription models etc and you know
what are the use cases for the service
so this is a low-end entry service we do
this is not a scalable service you know
you're essentially getting you know the
equivalent of a processor of capability
for compute we're giving you you know up
to 50 gigabytes of storage and you can
use this for things like application
development testing if you have some
short-term projects you want to run for
a couple months up on the cloud this is
great for that this is not for your big
data warehouse your your big
mission-critical whole TP system but
it's a nice place to get started you can
run your departmental production
we're close here and very exciting new
offering and we're just going to close
now with a little section focused on
application development so of course the
one of the big things that clouds are
good for is his development and test and
so we want to make sure that our cloud
has all the capabilities that developers
want these days for running modern
building modern database applications
you know we support you know all the
laundry list of programming environments
shown on the right and art cloud the
database now has full support for Jason
I mentioned that earlier and rest which
are sort of very are very popular
capabilities that modern you know the
new generation of developers really like
using and of course with our database
every oracle database comes with a tool
called application express whether it's
on Prem or in the Oracle cloud or any
other cloud that's available there
sequel developer of course is available
in all cases as well so we have very
powerful tools that help both
sophisticated programmers and less
sophisticated built of business users
build applications and application
expressed just for you who don't know
about it is a very popular tool used by
lots and lots of you know thousands of
ISVs and customers for building database
applications fully browser-based this is
a very unique tool that other clouds
like amazon don't have and it's
something I like to keep emphasizing
because if you want to build a very
quick application on something like our
Exadata Express service for example
using apex is a great way to go and now
and also I we have built in a whole
bunch of productivity apps there as well
things like project management apps bi
apps etc all fully baked in available
for free come with apex and now we're
going to have Gerald wenzel who's one of
our developer advocates and developed
and development show you how easy it is
to build a modern application using our
exit Express service Gerald let's go
thank you Andy so in December will show
you how as
startup can actually leverage the
excavator Express cloud service to run
their entire business on we have here a
gourmet coffee shop startup called the
Brooklyn bean they have retail stores
throughout the u.s. that sell coffee and
as of as of that they don't want to have
any on-premise IT I do just want to sell
coffee do you want to have any service
at all however they still have to store
their coffee sales somewhere in a
database to them do further analysis on
this so they decided to go with Oracle
Exadata Express cloud service the house
degenerated these days using mobile
devices tablets essentially right so
they just want to be able to send
restful service calls over the internet
and then just sending json documents
with those which allows them to give the
schema flexibility and have this in
dependency of the individual retail
stores throughout the u.s. so first
thing for me to do is for them to be
able to send those rest courses to log
on into the service console and create
one of those restful services so log on
here in the accelerated Express service
console of your three different areas
that I can manage after web access here
the client access and then the
administration so you are going to
define the rest data services to define
those rest services or that rest service
for them to be able to send this via the
mobile devices if a pre-configured rest
service here coffee shop which I have to
set to your status published which
allows it to be accessible over the web
so that those tablets can send those
Rascals so just set this to published
apply changes and that's it the coffee
shops are now all good to go they can
all now use those tablets and send
coffee sales orders across the web into
the Oracle database and exited Express
cloud service so now here's the
interesting question so now as we have
data coming in and then you would ask me
Wallace is all great now but what's
actually the revenue that we have made
you well last thing I want to do is go
ahead and say well here's your rest call
or your sequel query just file that off
and you will actually see what you got
what you really want to do is give him a
really nice simple UI a dashboard that
shows him the actual coffee sales going
in now sandy has just tab we have
application Express also available in
the exadata Express cloud service so you
can actually just build a very simple
dashboard in x-ray to express and then
give that to end it
run so all i have to do nearest go into
this application and click run and here
we have our sales coming in and as you
can see this is periodically refreshing
the bars are growing and I can use this
dashboard chest to drill down here for
example how did the cities in the
individual state do or can hear go from
sales by state to sales per city and
back again the last aspect of this demo
is also very interesting interesting
thing to talk about is as you load data
into databases databases grow and then
data loads usually get slower so there's
a couple of ways how you can remedy that
but we have in memory technology also
now for our chase and document support
so you can see down here at the bottom
this response time of the application
refreshing 350 milliseconds and I can
actually just go ahead and load this
into the memory columnist or and this
response time over here on the right
will now drop to a couple of
milliseconds while the data is still
being loaded live in to enter the
database that's it Danny well that's
simple thanks girl thank you
okay so we're just going to close now
just wanted to review where we are with
our gay based cloud services we talked
about our new entry-level x8 Express
service gives you up to 50 gigabytes of
data for running oracle simple tests
Devon departmental applications we have
our enterprise cloud service that runs
the Oracle database on our commodity
infrastructure you can get up to 16 CPUs
terabytes of data for those databases
you can run more mission-critical
enterprise applications there and
finally rx8 his service that lets you
run you know hundreds or thousands of
processors petabytes of data it can run
all different workloads you have from
the smallest the largest in your
organization and so just to summarize
what we talked about here in the
database group at Oracle we are doing
huge investments to make sure that as we
are transitioning through these
different eras moving to in-memory
database in-memory databases on
persistent non-volatile Ram things like
moving to big data moving to the cloud
we are going to deliver a huge amount of
innovation in the database to make sure
that no as we transition to these errors
your whole database will be a great
technology for you whether you're on
cloud in-memory database doing big data
or all the above so thank you for coming
good</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>