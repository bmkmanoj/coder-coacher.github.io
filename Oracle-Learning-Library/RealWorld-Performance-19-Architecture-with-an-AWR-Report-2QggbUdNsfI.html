<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Real-World Performance - 19 - Architecture with an AWR Report | Coder Coacher - Coaching Coders</title><meta content="Real-World Performance - 19 - Architecture with an AWR Report - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Real-World Performance - 19 - Architecture with an AWR Report</b></h2><h5 class="post__date">2014-09-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2QggbUdNsfI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi welcome back to the another video in
the series from the real world
performance team today we're actually
going to actually do a slightly
different approach to real-world
performance we're actually going to
debug and analyze a real production
system that was sent to us and we're
going to make reference to the
techniques we've described in many of
the real-world performance videos and
the scenario we're dealing with is we've
been given an AW our report by a major
online retailer internet-facing retailer
that's got some high volume transactions
coming up and they're sending it to us
two months before Thanksgiving in Black
Friday and they're asking are they going
to survive Black Friday and what we're
going to do with my colleague here
Graham we look at the aw our report now
to introduce Graham it would be not
doing him justice to say he knows a
little bit about aw our reports he's
actually the father of aw our reports so
he's done a lot architect I prefer
random father but that's but certainly
you know we are going to analyze the aw
our report in the manner it was designed
to be analyzed and looked at and what
we're going to do is we and is going
through and see what we find and point
out things that make us concerned about
the performance the reliability of the
system and would hopefully it's
something that you can do on your own
systems in the safety of your own home
and figure out whether your systems are
vulnerable to various aspects that could
bring them down or poor performance and
the awr report is quite a big report
these days one of the things that you'll
notice in through the next few minutes
is that we look at a very small
percentage of it most of the data that's
in there is detail that you're not going
to use unless something higher up
in the hierarchy of the report is really
pointing you to it so there's a couple
of key areas that we'll we'll look at
and we'll start off looking at the at
the top of the report so up at the top
we have information that tells us about
the system that this is is running on
and so you know one key thing that we
look at up here here's how many cores
are on the system and this is telling us
that there's 32 cores it's obviously
hyper-threaded because it's saying
there's 64 CPUs
alright so we've got 32 cores on this
system the next section is telling us
that at the start of this period which
is just over a hundred minutes we had
3300 sessions
running against the database now if
you've got 32 cores you're not going to
be able to successfully run 3300
sessions if you come back to the
computer science of it you cannot run a
hundred sessions on on one core it they
just can't do it
so first red flag there is that's a very
high session count and then if we look
at the end snap it had actually grown
from 3300 to 4,600 so we started with a
very high session count and now it's
grown dynamically over time so you know
two red flags immediately it coming out
of that one it looks like we're way over
subscribed and over processed and the
second one is we have a dynamic
connection pool and we've covered in
numerous demos of what happens with a
dynamic connection pool so that
certainly the data here is starting to
indicate one to many processes and to a
dynamic connection pool perhaps what
should you look up the log ons per
second and do some mental arithmetic
with that yeah so if we scroll down to
the low profile we have log ons per
second of 10.5 right now that works out
at 100 minutes yeah
they it per 100 minutes
that's about 60,000 logons
so that's obviously not DBAs logging
into the system you know often when we
highlight logons per second and normally
if it's one logon per second
customers will say oh yes the DBA is
logging on checking space or something
if it's 10.5 logins per second it's
obviously not that and this is the
average over a hundred minute period
yeah that's 613 that's you know think
about that you know 60 seconds 10 of
these thing that's 600 log ons a minute
you know you don't even a rocket science
how many think there are that's not
someone just being curious about
checking space there is an architectural
problem with the middleware at this
point right and that number of logins
per second log ons don't come for free
they're very expensive in terms of the
resources that are needed both for
logging on and actually logging off is
more expensive than logging on folks
don't often think about the log on the
log off side of it but you've got to
release all of the areas that you had in
the shared pool that can get very
expensive and we actually think this is
actually a lot worse than this because
you know this is a hundred minutes and
this is the average you know this is
probably a dumb down result by virtue of
the averaging process right yeah one of
the problems that we have when we're
looking at ALW hours especially longer
period ALW hours like this is that
unless the workload is completely stable
over that time period there any peaks in
in problems will get averaged down so it
may well be that this 10.5 average
logins per second there were times when
we were doing over a hundred logins per
second and remember when we were having
the demo of the gaming application we
peaked out and we couldn't get beyond
about 300 logins per second and that
would be upper limit for the application
right that was it done finished yeah so
it's it's very easy to have a period of
time when you're just completely maxing
the system out on or your serializing
behind log ons in your awr
over a period time period like this it's
getting getting averaged down the other
reason why that's a concern why dynamic
connection pools are a concern if we
look up at okay DB time we've got about
260 active sessions on average over the
time period we've got 32 cores and
there's 39 sessions on CPU over that
time now how much of that time is being
spent in logging on and logging off we
obviously we're short on resource so
spending a lot of that time logging on
and logging off isn't really helping our
throughput and the other thing is you
see you see 32 CPU seconds per second on
32 cores well we're going to have a lot
of that accounted through both at
getting virtue of the hyper-threading
but you can see we're fairly well over
subscribed and what did we learn from
the demos when you are oversubscribed
the response time becomes volatile it
becomes variable it becomes
unpredictable so at this point of time
we have a system that we are measuring
when it's in an undetermined estate
unpredictable state not the sort of
thing you want to have on a flagship
website ik thanksgiving right yeah you
know ok so just very quickly you know
the other things here no particular
problems in terms of number of part
number of parses nearly 40,000 per
second is kind of getting up there hard
parsers point one that's obviously
obviously fine transactions per second
is 1,300 now for a stress test of a
major retail system that seems kind of
low I would expect to be able to manage
many many more transactions per second
notice we're just shy of 60 thousand
transactions for 64 cents per second and
so you can you can see the number see
statements per transaction but again you
know for a system that's got 32 cause
you know this is not a dramatically high
number so there's two questions as you
know is the connection architecture
string dumbing down the performance like
we saw in the demos or is perhaps some
of the sequel fairly suboptimal and
actually could be better designs a
little better optimizer no I'm sure
we'll come back to the sequel in a bit
it always clear right okay so now we
looked at the top of you have a look at
the cases at the top oh do a sort of
leakage check yeah okay so the the other
thing that we we notice up here as well
as increasing from 3300 to 4600 sessions
the cursors per session has gone up from
8 to 26 now if you think about that this
is the same application that's been
running throughout this hundred minutes
because it's it's a stress test of that
same app so if the number of cursors per
session is changing that means that we
are leaking cursors the only way that
you can start using more cursors over
time is if your application is leaking
cursors so again that's a red flag for
us
yeah so maybe if we actually look at the
bottom for the initialization and it
Dora
parameter settings let's go and have a
look for open cursors and see what that
set up right so open cursors here is
2,000 again open cursors is often
misunderstood and people think that it's
a per session at per system limit
database wide limit it's actually a per
session limit so this is saying that an
individual session running against the
database can concurrently have 2,000
cursors open and returning data or
inserting and one clever program right
now you've got to be pretty smart to be
able to remember the state of all 2,000
cursors to do that now in practice what
happens with these things is that they
open cursors get set to a high value
because at some stage they've run out of
cursors
the DBA has been told oh the
applications hitting hitting the error
saying max open cursors exceeded so the
DBA will bump it up so that it gets it
off his list of things to do and it just
goes away well in fact it's not going
away all that's happening is he's just
masking the the problem and it will come
back at some later stage all right so
we're basically allocating memory and
resources that aren't needed that can
never ever be programmatically reached
because they've been programmatically
leaked so you're wasting resources and
it's just like a time bomb just by
setting it off for a time a bigger
number it means it's going to blow blow
at some point you just don't know when
it's going to blow right yeah so as well
as I think the limit what we like DBAs
to do is actually look at the system and
look at be door open cursors for one of
the sessions that's having the problem
you'll probably see that there are many
many copies of several of the cursors
and that's kind of how you identify
cursor cursor leaking and once you're
looking in the right place it's real
easy to identify real easy to bugs wages
good development practice comes in you
know if we can identify the sequel
statement that is being leaked and even
better if they are attaching module
information associated with the sequel
statements or good comments on the
sequel statement basically it can help
the programmer trace back to the sequel
statement that is leaking a cursor and
then we may be able to find out where
the logic problem is where their paths
throwing an exception without tidying up
behind themselves and things like that
as to why the cursor leak took place in
the first place so you know it's looking
like we've got here session leaking
we've got cursor leaking there's one
other thing I should look for which is
the last type of leakage which can bring
a system to its hole and that's lock
leaking and that so I mean you mentioned
session leaking having sessions set to
8300 here is another indication that
that might be might be a problem so for
for well the lot leaking let's go back
and find our seafood opening any what I
mean ink is really yeah let's get back
to our top ten
there we go our talent events now okay
so our top weight event is actually
library cash mutex X now again I can see
I could see from what we've already
looked at two possible courses of that
one is the log ons per second which mean
that we're actually having to parse
statements each time we log on the
second one is that we're CPU bound on
the system and on a system that is CPU
bound lectures and mutexes will tend to
come up as the top events because in
normal operation they're held for a very
very short time and then released again
if you're CPU bound to that very very
short time gets increased dramatically
by the time that your process is
spending in the run queue it's
ridiculous in this case you hear every
time and I know we don't like to talk
about every years but even an average of
seven milliseconds waiting for a mutex
which should be microseconds it should
be in microseconds that's that's the
speed of an i/o we're exchanging control
of a piece of memory this is yeah this
is something that's not right yeah and
you can see there's this also another
latch down here as well which that one's
got some nearly two seconds a ver egde
average wait for that one so right but
then yeah getting back to the the
locking issues our second highest weight
event is TX row lock contention so
waiting for row locks and we've got
quarter of a million of those over this
100 minute period with an average time
of a little bit over a second so that so
we're spending a lot of time waiting for
the locks now of course that then feeds
back into the application server because
our sessions are waiting for the locks
the session is active as far as the
application server is concerned for
longer and therefore the application
server ends up creating more sessions so
that it's got a free session to work
with and it all just spirals down from
there so that is probably at least part
of the
reason why we've got our increase in the
number of sessions as well I've heard
from this site that they have scripts
that go off and kill lock holders that
have been holding locks for a while so
you know we should be suspicious of all
three types of leakage
you know cursor leakage session leakage
and lock leakage then enough evidence
there to ask those hard questions right
yeah and well the fact that they have
kill scripts that run on a regular basis
is in itself you know and then the thing
that we always hate to talk about is
that you've got kill scripts that are
killing off lock holders you know are
they logically corrupting the database
at the same time the problem is nobody
will ever know until it's too late and
it's rather unfortunate and so there's
that aspect of it right and so well we
have lock contention so if we look down
at the the sequel then we should be able
to identify fairly easily which sequel
statements are responsible for most of
the locking because they'll be the ones
where we spending most of the time and
so if we look at the first sequel
statement here which is responsible for
12% of the the overall load of the of
the system and oh well this says it's a
select statement yeah so well you
wouldn't expect a select statement to
just look at those numbers at 12 percent
of the load but it's barely even 0.6
percent of the CPU burnt on the system
right so it's actually a tiny resource
consumer but is it in terms of wall
clock time it's taking a long time and
if even if you include the i/o times in
this it's still just a little bit over
three percent of the execution time of
the sequel statement is spent in on CPU
and i/o and the rest of it is likely
spent waiting for waiting for locks okay
so let's go look and see what the sequel
statement is and here's our here's our
sequel statement and yes it is a select
but it's a select for update so that's
why we were seeing a select there as
being responsible for a lot of time
which is probably down to the the
locking that we
and so select for update is going to try
and take out the locks if it can't get
the locks it's going to have to wait for
them okay so you can see they've
probably got a locking problem but it's
also me as you were scrolling from it
through the sequel statements just then
I saw some state back yes there's a
mighty long endless and some system
generated bind variables all right so
yeah we we didn't look at it in the unit
dot when we look down at the unit Dora
but the fact that these bind variables
are all sis underscore B and then a
number the system must be running with
cursor sharing equals force because
that's the way that system-generated
binds will will appear recession with
its a or a session will yeah so as you
can see it's a long illness a long
dynamic in list so basically someone
wrote a program to dynamically create an
endless probably with a variable number
of elements in the in list put them in
as literals and now we've converted them
to bind variables and so we have to
pause that statement and then binding
all the bind variables it makes me
wonder shouldn't have that being a
sub-query feeding into a join you know
this is just sequel efficiency but you
know at this point in time we're not too
worried about these things from a
performance perspective because we found
the big hitters up front which was the
dynamic connection pools and potential
resource linkages but the thing is we do
get nervous when we start seeing curses
sharing equals force and these sort of
things and yeah because it has all sorts
of knock-on effects so if we look down
down here this next statement actually
is a to date statement and that second
bind there will have been a date format
now i'm sure that the developer when he
wrote this put in a literal of a date
format which has been converted into a
system generated by a date in a date
format and then the format mask right
yeah and it's and now it's all being
bound in at bind variables and any
formatting and would have been lost
associated with that yeah and in this
case obviously that wasn't affecting the
application but in some cases just
turning curse of sharing equals
for that sort of substitution which is
not necessarily what the developer was
expecting to happen can cause barrows
anyway the other thing that makes of
course about nervous about people
basically saying cursor sharing to force
because they have either a programmatic
screen scraping application or they're
dynamically generating sequel statements
it makes them awfully vulnerable to the
sequel injection and with that in mind
we just get nervous and all we can do is
red flag this and say potentially you're
open to sequel injection and again two
months before Thanksgiving you don't
want to hear that the reality is
potentially this system may have some
security flaws so you know just to wrap
up what we've done we've basically had a
look at the we can we now to reverse
engineer a lot of facts about the
connection architecture probably about
how much QA went into the programming
looking for resource leakages and we've
identified a potential security flaw and
we've done that by looking at a very
tiny proportion of the the awr report we
haven't listened in to looking at all of
the systems we haven't gone into all the
disk i/os wasn't relevant in this case
so Graham yeah two months to
Thanksgiving should these guys be
checking up on their resume I would I
would hope so thank you that's what I'd
be doing if I was that okay so again
hopefully everybody when you've seen
this video it's given you some ideas as
to what to check for the sequence and
what to check for and and start
critiquing your own systems at home
don't wait to figure it out to wait for
it to blow up you can start doing this
proactively or yourself use it in
conjunction with the real world videos
in many cases these videos get sent to
educate other people about the nature of
the problem because we have demos
demonstrating the race conditions so you
know perhaps this conversation should be
happening over cups of coffee all around
the world and people attempting to make
their systems more robust faster and
stable
now that point Graham thank you very
much okay thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>