<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Challenges in Exposing Data Through APIs: Optimized Data Serialization Techniques | Coder Coacher - Coaching Coders</title><meta content="Challenges in Exposing Data Through APIs: Optimized Data Serialization Techniques - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Challenges in Exposing Data Through APIs: Optimized Data Serialization Techniques</b></h2><h5 class="post__date">2013-02-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UzUYz1qIK64" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the session thanks for
joining the session on works first thing
in the morning 830 so it must be really
interested in the topic and hopefully
I'll try to cover and won't disappoint
you in what you're looking for my name
is um sorry milady I'm currently with
ebay actually stubhub recently
transitioned to stop up which is another
he become paneer I've been with ebay for
six plus years been around in the
industry for a lot longer than that
close to two and a half decades with
portico IBM bull all over the place
bending the distributed computing
semi-circular architecture for quite a
while and this particular topic in fact
I did give a talk last year November at
q con if some of you attended that what
I try to cover today is um you've
probably heard a lot about them in some
of you probably are developing these
api's as as we speak what does it take
to develop this API is what are the
different formats what are some of the
challenges you have especially with
newer data format that's coming up
pretty much by the day and what are some
of these best data formats to choose
from to expose your eps i'm going to try
to cover that both for internal and
external and i will also touch upon
worsening washing is another perennial
problem in the KPIs and you know in fact
five time i'll do a demo if not we'll
conclude with with any questions you may
have before I get started on just the
topic just for kicks I wanted to start
off with some fun facts oops about ebay
you know we have what close two hundred
million active users anytime i'm not
going to read through all of that
interesting to know that every second
about two thousand dollars worth of
goods is being exchanged every second
and we process daily about 80 plus
petabytes of data from our analytic
infrastructure we have bought 40 billion
api calls in a month that's that's the
number of calls that we process anyway
and of course 100 plus billion sequel
executions were there lots of oracle
lots of new
sequel databases as well which of course
top hobbit in contrast is actually a
small company which eva bought few years
ago for 22 million active users every
ticket being sold a second ticket per
second is being sold it's still pretty
large not not not as big as the kind of
numbers that you're seeing an ebay just
for information rip and compared to 100
billion we have about 300 million sequel
sex equations today at step up right
it's just for information now 77
architecture at eBay has been it's been
a journey for us so back in two thousand
six when I actually you know join ebay
ebay was a pretty monolithic
infrastructure in the company everything
went some from the time the request
comes into the app so can you guys hear
me back whether any problems in hearing
me good when a request comes into the
app server everything stays within the
app server until the whole you know
execution is complete and the response
goes back out there I mean obviously
just adding more boxes is not the answer
right you need to distribute in service
or into thing not only for external
consumption innovation by applications
but even for internal even for internal
we use in productivity right so we went
to the domain decomposition did all of
that and we have about you know 400 + 4
maybe close to 500 services even
internally I mean the only subset of
those are exposed externally from a
product standpoint both support you know
rest and soap as well but nobody
actually uses soap it's primarily pretty
much everybody is using rest technology
stack was actually a mix of the
homegrown as well as open source
products in fact whatever we did some of
the innovations have been open sourced
at ebay open first arad under the
codename turmeric and it stubhub
actually I'm kind of doing the similar
process now was service or anything and
distributing the whole thing to get to
the point where ebay was few years ago
this is again a dead Britain topic I'm
not going to spend a whole lot of time
but just to set the context we have
obviously the two types of api's we have
soap invest aps and so being there in a
formal contract with wisdom and you can
have of course you can have bindings you
can HTTP bindings and even have you know
sir bindings and so on and you can have
arbitrary set of operations you can
define as many operations as you want
inside inside your service right and if
you look at the typically the industry
in the last about six to eight years
people have actually moved away from it
not not many companies have been
exposing or using these eps we name it
Twitter Google Amazon eBay facebook name
name any company that that you see all
of those are exposing only the rest
api's right rest api sorry notionally
the concept the whole concept is very
entered resource audited when you know
that Roy free links fair dissertation
and PhD dissertation about the rest ap
backing on HTTP verbs HTTP has this you
know get post put delete kind of herbs
so the whole concept is that there is a
resource on the web and you are
interacting with the resource you are
changing primarily or obtaining the
representation of that resource right
the presentation of state transfer you
are querying for a resource getting the
representation updating it changing it
and all other operations that we're
talking about there's no formal contract
in the case of rest it is primarily
through documentation to requests and
responses but this is where we actually
we have done some innovation and again
hi permit how many if you're familiar
with hypermedia it's good few of you so
hypermedia think of it this way so when
let's say you are in San Francisco today
you are searching for you're looking for
some restaurant you go to Google type
your restaurant or type the type of food
that you're looking for it gets whacked
with a bunch of search results you click
on it maybe it takes to do they review
the results and you click on it further
and say you know how did those reviewers
actually do anything essentially self
navigable everything is self-explanatory
nobody ever taught you how to go to
google and search nobody ever taught you
how to
click those links nobody have to talk to
how to get to where you're looking for
that's a whole concept of even in the
rest api how do i apply and it's been so
successful how do we apply the same
concept for the rest ap is using
hypermedia in other words if I'm cutting
using an API to try to get some data
what I get back based on what I get back
how does it tell me what to do next how
does it give me the hyperlinks that I'm
looking for how does it tell me further
we have taken this photo how does it
tell me how do i modify if I want to
modify that resource if I want to query
further if I want to update that
resource how do I do that if you can
give you that metadata plus the
documentation if it can give me some
documentation along with the data that
is being returning that's even wonderful
so you don't have to go anywhere else
right this is what is typically in the
world in the industry now being called
as hey Toews hypermedia as the engine of
application state this is also being
included now parts of it is being
included in jax-rs to java developers
the jax-rs is the specification for the
rest api is somerset implementation in
jax-rs to data which I'm also part of as
part of expert group is defining a
subset of the hypermedia capabilities
that I'm talking about which is due
sometime soon in fact those of you who
are interested in this should go to
there is a buff on jax-rs together I
can't remember exactly when but one of
these days all right so let's now switch
to the data formats not too much on the
EPI i'm actually play this out and then
so typically when you expose the AP is
externally the data format that you
exchange that you expose needs to be
something that's commonly understood
something that's interoperable right and
therefore typically you know people
start using it in XML or JSON these days
right but over over time these data
formats have evolved them as you will
see in the rest of my talk and number of
other formats binary formats have popped
up each claim
to have its own benefits and women
examine what the benefits are for each
of those formats and based on some of
the benchmarks that we did we'll also
try to show you the results that we saw
but these are for an external kind
standpoint but internally I mean
obviously have epi so we're assuming
that your service or renting your
website internally also have eps and
services when you are communicating and
exchanging messages internally you don't
necessarily have to stick with xml json
you can explore these binary binary
formats right and assuming that they're
they offer the benefits that they claim
to be so but the whole point whether
external or internal in this case is the
implementation you want to make sure
both the API implementation which is the
server side and the client
implementation which is the application
does not change the logic does not
change their designer code based on what
format is being exchanged between the
client and server that's a challenge
right we have done that but is a
challenge if you stop begin to start
using this binary data formats right now
one example of give you internally is
that in the ebay search api when
somebody tries to go to search and do a
keyword search sometimes the results can
based on amount of things that you have
sometimes the results can be rather
large I mean you could argue define the
EPI as a good design you should never
return large amounts of data but
nonetheless one of the EPS actually
happen to return based on the keywords
that you are searching close to a
megabyte of data in XML if you want to
serialize and destabilize that one
megabyte of data it's going to take up
100 milliseconds it is unacceptable 100
milliseconds is too much right now of
course we then went into fast enforcer
fashion for set is a binary xml iso
standard originally developed by sun
essentially think of it as in asn.1
notation those of you who are familiar
how compilers work so if you have XML
data a repetitive elements for example
you know item name description price
whatever in the kids repeating itself
there's no point in just repeating the
same elements over and over and over and
again so what the sn1 notation does kind
of similar to how the compilers use it
is to tag them at the very beginning of
the message you know name description
price whatever put some sequence numbers
1 2 3 4 5 and rest of the message you're
going to repeat and substitute just
those numbers so if you look at a 1
megabyte of XML message suddenly the
thing has been reduced to depending on
how repetitive your message is to
anywhere close to half or less than half
right but when we did that it was still
about 40 to 50 milliseconds which is
still not acceptable what we're looking
for how to do for three to four
milliseconds for one megabyte of data
that's the in especially in internet
world that's the kind of response and
agencies you're looking at but so the
point is there is a cost there is a cost
of serializing and deserializing the
message the question is how do we reduce
the cost so the rest of the presentation
which is comparing all these different
data formats is going to focus that as
one of the points of course there are
other aspects of it as well
so the challenges are kind of twofold
here one is about the platform itself
the the container that you're going to
use to develop your AP is the other one
is the API design itself and both go
hand in hand you have to take both into
account what I've been alluding to
earlier serialization desalination costs
that's that's more on the container side
the platform side am the worsening the
hypermedia support i describe generating
the documentation security aspects of it
all of these are challenged from
platinum side but from an API design
side this is where you would use the
ease of use and the interoperability a
backward compatibility and granularity
right so you can depending on how you
define your API is to say you know I've
seen some people defining the aps to say
I'm going to give you a bunch of a hash
map of efficiency and name value objects
when you query for it so I'm keeping it
extensible so that in future I can stick
anything in there I want but think about
from a client perspective when he sees
just a name value pair they really have
no idea how to interpret that they have
writing you know tons of documentation
to understand what it is right but the
same time you don't want to define your
API such the so rigid that these are the
five fields and those are the only five
ways that you are ever going to see
right there is a good trade-off that you
have to let you make and and the
granularity is also extremely important
is it you know modeling in terms of
resources and sub resources is it all
single one big resource and all of the
times people I see even people using the
rest api you are a resource as verbs you
would never use verbs as you are ice and
resources do your eyes and resources are
nouns you can't you can't have a
resource to say purchase purchase is not
every source it is a verb it's an action
on a resource right you have to be
really careful on how you model this
stuff so it's seamless and easier for
people to use this what this is showing
just quickly is that the number one of
the comments that I made where you want
to make sure this is really you want to
make sure that when you are changing
this data format
the implementation on the API side or
the implementation on the application
client site which is using the API you
don't want it to change because you
can't afford to have them reinvest every
time that there is a new data format so
one way especially if you're using Java
that we have done is in the you know the
java jax p a p is there is a mechanism
for Jack speed the way you know how many
effin with Jack's be hopefully most of
you it's the good number it's a it's a
mechanism to see you lies and
destabilize xml fortunately that's how
it came about XML into Java and back but
in what we did is underneath actually
the way it works is it the concept of
stream readers and stream writers so to
the application code that's calling Jax
PE to Marshall and Marshall it looks as
if it is just a call from Java XML and
xml to Java but underneath the way it
works is like I said XML if you look at
the stacks parser there is the concept
of readers and writers stream leader so
what we did is we replaced all road
actually not replaced but rode a bunch
of stream readers and writers for
different formats so to the color it
doesn't it just looks the same call but
they're underneath the format is
changing based on what reader and writer
is being used they make it look like
these readers and writers or stacks
readers and writers that make it look
like as if it's XML but it's really not
XML so this this diagram is just trying
to show that if you have a if you have a
message that you want to serialize rd
sterilized and you get a corresponding
factory and then the factory returns you
the corresponding stream leaders for
each of these factories we wrote this
thing called stacks parser stream
leaders for this output the color which
is this application which is calling
this it doesn't make any difference
actually the same thing put it in a
different where you have different types
of messages coming in through the
pipeline this is the pipeline that
actually this is terminated by the way
is one of the this is the product that
we open sourced
ebay open sourced at arc but the concept
is the same it is standard Jack's p
stuff where the course are coming to the
pipeline the serializer diesel is a
factory he just the corresponding stream
leaders and writers and natively
serializes in detail into java objects
this is different from a lot of the
things from some of the other open
source projects you might turn into
everybody who actually might say yeah we
support multiple data formats but most
of the time what people try to do is to
convert the incoming format whether it's
soap whether it's XML where's Jace on
whether name value into some common
intermediate format from that common
intermediate format then the Detailers
into the native object but that's a
two-step process in a high volume side
in a high one in 100 scenario you can't
afford that so what this gives you is a
way to natively civilized and
destabilize whatever format they're
coming in now this is all good stuff for
when you have just things that are not
necessarily special binary formats like
xml json name value things like that
right but we've already seen that there
are some performance constraints with
these formats so how do we take it to
the next level where we can then start
introducing the binary formats and
that's what is where the performance
changes are coming in
like I said with XML with those formats
that I just talked about there is still
significant amount of cost especially at
larger payloads right and the cost not
only is the justice see a performance in
CPU latency it also affects the network
bandwidth because the higher the size of
the messages and especially if you have
large number of messages flowing through
the system the more the network
bandwidth is going to take and as a
result it's going to overall slowdown
your entire system so what are some of
the alternatives well alternatives
obviously binary formats we looked at
things like protobuf mount go through
all of them avro thrift message pack
fast infoset so we looked at all of
these formats right because we have to
find a way to improve our performance
for the API for these data exchange and
so the next several minutes in fact I'm
going to spend on these formats and how
they compare and what we have done in
what is the result that we found so one
challenge with each of these unlike XML
JSON name value that I showed you
earlier where you can just these are
just data formats all these other
formats that are coming up whether it's
a google photo before apache Avro
through Facebook thrift and whatnot they
have their own schemas each of them have
their own schemas to express messages
each of them have their own IDL if you
go because they are not only the data
formats but they're also an RPC like
mechanism you can actually use prada
buff to communicate and create your
services in client you can use stuff to
create your services in client you can
use a blow to do that right so they kind
of mixed up both an RPC mechanism and a
data format mechanism into the same and
each have their own way to express their
schema and you will see i will show you
some of those schemas that's one the
second is not all of these
formats actually support all of the
schema types some of them don't support
inheritance some of them will support
polymorphism some of them don't support
union some of so if you have a message
structure where you want to define
inheritance you want to define some
unions you want to find some enums not
all of these actually support that
that's a challenge to write second is
each each of these formats have their
own way to generate some classes given
some schema you want to generate some
classes that represent that schema and
each of them have got their own tools in
each of them have their own formats
remember the the number one rule that I
talked at the beginning which is to say
as you are changing these data formats
you don't want to change the API
implementation or the client
implementation but when you start using
these each of them have their own schema
tools each of them of their own classes
and therefore the application now has to
interface with different classes is no
longer like this standard javabeans that
we're talking about right that's another
issue too but we have overcome that
obviously because we want we we have a
we had a dire need to improve the
performance and scalability of this EP
is and start looking for these other
formats and not have to require changes
to these api's so we did some
benchmarking by the way there are some
existing benchmarks actually you
probably can't see that this is blue
color here or the link on that you will
find all of these shares slides will be
actually shared at the end of the devil
once you have the content but those
benchmarks are not as detailed and not
as essentially a real world scenario of
an application or message senior design
so these are the formats that we are
comparing right now xml json json we has
various implementations of it jackson
jettison ji-sun are you familiar with
those parsers okay and the fasten for
set which I talked about which is a
binary xml this is the most popular
binary xml it's based on the asn.1
notation that I talked about pro
of error 03 from a suspect so what will
the areas that we try to compare for all
of these formats the serialization d
civilization cast what does it take
what's the cost of taking a message and
serializing into that form at the
network bandwidth in other words the
serialized size of the message it's not
like I said it's not only the time that
it takes but it's also that the size of
the message after you see your life the
schema richness what is it support what
is it not support in because depending
on what you are trying to do it may or
may not support what you're looking for
how easy it is to do versioning because
versioning is is important you have to
version your messages if there is
anything that's constant in this world
let's change change is constant change
is going to have to happen right ease of
use backward forward compatibility if
you hip if you define a message today
and you want to change it to something
else and what is it you know what kind
of capabilities does it have to support
the backward compatibility in a wrapper
ability well by definition because of
the fact that these are binary formats
and actually none of them are
interoperable in that sense stability
maturity how long have been these around
and what language support do they have
out of the box because as you know these
days you know it's chicken pretty much
develop your API send clients and
applications any language you want
doesn't have to be Java it could be in
any language so what support do they
have for what languages and finally the
velocity of changes how often is this
thing cheney this mature is this is this
is this table or is it how quickly are
those things changing so the goal of it
is we need to understand these formats
and understand them in those categories
that I talked about what is not a goal
of this benchmark our comparison that
I'm we did is to use their RPC
mechanisms we ignored or did not use
their each of these formats are
corresponding RPC mechanism because
that's not the girls exercise but only
to understand just use the data format
point of it we in and to simulate
the real world scenario we actually
created a massive structure that it is
more like a tree structure that is at
least up to a depth of level of 4 and
that includes reasonably all sorts of
mrs. type definitions standard message
step definition schema types that you
would normally use right and again what
I would like to follow the sum of the
numbers that you would see in the next
few slides these are all take them as
relative numbers those are because
depending on which machine as you all
know benchmarks are benchmarks right all
of these companies publish benchmarks
but they're only relevant in the context
of the hardware and the environment that
they run they're not generally relevant
so that's that's the disclaimer that I'm
giving here to that take these numbers
as relative numbers and understand how
they compare not so much the absolute
numbers part of it because they're going
to be different based on where you run
them it's a lot of text here hundreds
very very busy text but i'll try and try
to simplify that so in this thing i'm
trying to compare lists the proto buff
arrow and thrift as three different
formats let's just look at protobuf
first this is this is the original
protocol that came from google which is
the binary format it has its own ideal
schema much like each of them have and
the way and and the way you represent
each of the elements within your schema
is to what is called a sequence number
i'll show you the examples what i mean
by that it's a compact binary
representation and most of the xml
schema elements are supported in this
schema with the exception of polymorphic
constructs and choices unions and things
like that but other than that majority
the xml schema constructs are supported
here you can achieve inheritance through
composition so if you want to inherit
from in a message complex type A to B
you can kind of do that through
composition i'll show you what i mean by
that there is no attachment support
typically in the in the API wall in the
message world like
in XML schema if you define base64
binary as the type in XML schema that
typically maps to a mime attachment
using M Tom are picky depending on wood
protocol using with its soap with
attachments or M Tom based on the rest
but there is a concept of an inline
message for example let's say you want
to send you want to upload a picture you
want to send it you know somebody's
you're querying for an item there is
some base information but then there is
a picture you don't want the picture in
the message in line you want it as an
attachment howdy how do we do that there
is a way to express that in XML but
there isn't a way to express that here
versioning is kind of similar to XML but
is a bit more complex because you're
actually pinning down pending down the
sequence number for each of these
elements it's currently version 2.4
available in pretty much many languages
Java C C++ and Python that's pretty buff
and all again I will give you an example
of the schema so it will be a bit more
clear and what we talked about but just
the highlights why is it its own schema
it's an ideal supports a lot of these
constructs and it has its own compiler
if you go in other words if you take
that schema definition if you express a
message definition in protobuf and if
you want obviously at the end of the day
writing code in some language let's say
you're writing in Java so you need to
deal with that message in Java so there
is a tool called proto see that you run
on top of that message it will generate
the bunch of these class much like
jack's b generates the java classes when
you have an xml schema same thing here
in a burrow to Avro schema is basically
JSON a breeze is JSON itself as a schema
to express its messages and it has both
a dynamic typing and a static typing so
what I mean by that is that so if you
are send while you are sending in a
virile message on the on the wire you
can prepend before the message you can
prepend the schema itself so the
receiving side actually knows what is
the scheme of the message that follows
so versioning is actually a bit more
easier in this scenario because you
don't have to explicitly tell the
clients to say
well I worship my message because the
schema follow are the message follows
the schema that's one way another way
would be the static content type where
you actually pre generate the classes
and give them and it's fixed and you
don't send the schema there are pros and
cons on both sides whether use static or
dynamic much like photo above other
things are pretty similar inheritance to
the composition most of the xml concepts
are supported although there are some
work on some tweaks that we needed to do
and it's actually i'm not going to each
of them but its original devil has
developed as part of the hadoop family
avro is part of that when it's actually
used pretty heavily in all of the Hadoop
family products and it's also available
in many languages now drift very similar
they actually originally came from
facebook as part of the Cassandra and in
that family of product and this is
actually similar to protobuf more than a
bro actually Avro is kind of slightly
different but thrift actually more
similar to put above the nav row it also
has a way of representing these sequence
numbers and rest of it is more or less
the same now the other three formats
that we are also comparing is proto
stuff by the way how many of you have
heard about all these formats that I'm
talking about is it all week in Latin
you guys already know everything about
it okay good okay some of you know so
when Google developed this product off
few years ago I mean it's pretty good
right so one of the guys actually who
apparently worked on photograph and
actually when he left Google he started
another project called proto stuff which
is really a slight variation on top of
protobuf and he he actually did pretty
good so the Prada buff doesn't do
sealers indicia listen in streaming mode
in other words it tries to serialize and
destabilize the messages into memory
buffer completely and then try to write
to the socket or right to the wire for
example if you're exchanging it so
whereas what he wanted to do is as you
are serializing as you are
utilizing the message you want to stream
the message across to improve the
performance and that's the change he did
to put above and he called that sort of
stuff and he also of course has added
additional capabilities where in
addition to taking a message and writing
into this portable format you could also
write to XML and JSON formats if you
wanted to consume it if your system
actually is to consume those messages
message pack is relatively new format on
the block it just came around maybe in
year ago little more than a year ago at
it really has no schema but it has a
compact binary representation there's no
code generation Vidya is actually a lot
more restrictions you need to write your
code and declare all of them as public
fields and in all sorts of things that
it doesn't have necessarily support for
defining inheritance and tree-like
structures and things like that but
whatever types that it actually supports
it has a very compact representation of
those types on the message first input I
already talked about it's actually kind
of same as XML the schema is really XML
it is just that on the wire instead of
putting the XML message you are putting
this binary format of XML on the other
side you have to have the same parser
that understands this binary format
again it's pretty simple if you have
repetitive elements the way fast
enforcer works is put all those elements
into a table at the very beginning
represent those names through some
numbers and the rest of the message you
just substitute those numbers so you
don't have those names repeated all over
the place now let's take examine some
schemas how they actually look in
further above comedy in your time okay
so this is a XML I don't hopefully don't
have to explain anything here you guys
are familiar that this is you know
depending on the cardinality and the
types of elements that you have you know
if I were to take the same XML message
again this this message the way as you
can see here it's more like a tree
structure right now it has a self
reference to it so and it has a list of
those self references so I can control
the depth of the tree
in depth of the message structure if i
want to express the same maximal message
now in protobuf this is how i do it this
is what I'm talking about when I said
there is sequence numbers associated
with each of them so with different
syntax different way to express the
schema but what you are pinning down
here is the sequence you are essentially
telling hey my number one feel in the
message when I am sending my number one
field is this my number to fill is that
number three so when you compactly put
the binary format on the wire on the
receiving side it must exactly know
because it's going to expect that by the
next bits of zeros and ones are really
this value so I know how I'm going to
interpret that right so if you want to
wash in it you can't go back and change
these numbers you have to add edit of
Lee
same thing if you want to express an
avro this is how we do it like I said a
voice the schema is JSON itself the way
a virile message Apache ever does is
your message itself is expressed as a
JSON right which is familiar here it has
some media sync reese's into in the
sense that when I'm expressing for
example a self ref or a sulfur frist in
terms of the structure you have to
declare that it is its value can be now
I mean it's it's really just a way to
work around how to express those three
structures but nonetheless it is
possible as you can see there are no
sequence numbers this is just a much
like XML it is like a schema you can
prevent that schema on the wire with the
message thrift on the other hand has a
bit more restrictions oopsies like I
said similar to prote above it has
sequence numbers it just said protobuf I
sequence numbers at the end it has
sequins about the beginning there are
some differences like that but but it
doesn't have the tree like structure
support inheritance so as a result what
I have to do to simulate the exact same
message that I showed you I have to
create a fifth message to + actually
refer to message to over here because I
cannot do a self reference of the same
message in thrift it doesn't support
that tree structure so um this is
examples of water then essentially did
is take that kind of message tree
structure simulate the randomness of the
message and run a bunch just a bunch
benchmarks and all of these formats to
compare right each of them actually did
this in Java each of them ran in to
supper JVM each payload size itself is a
JVM just to ensure that there isn't any
remnants of these messages or passes
from a memory standpoint of left in in
the JVM and I took the 95th percentile
numbers and also i took the real world
like I said randomness if you are
repetitively just benchmark lot of the
times what happens is you are inserting
the same message over and again just
doing it several times a lot of the
times the compilers the JVM optimizes
that but in the real world in one
like that you won't be exactly repeating
the same message over and over and again
the messages size and content will be
different so I introduce that randomness
to simulate the real world scenario so
with that context in the background
civilization so this is a graph so the
time taken to see your eyes different
sizes of messages I took different sizes
size of one case small payload 10k 100k
in one megabyte so some small to large
messages and with all these random tree
structures similar sizes compared with
all of these formats are chronically
benchmark as it so the net net is that
at small payload sizes you know up 200
care product off you know surprise
protobuf protest stuff message back in
Avro have done better but however at
higher payloads protest stuff actually
has taken over no surprise again there
because proto stuff is trying to stream
the message as opposed to put everything
back into memory supporter stuff has
done better followed by interestingly
enough Jackson JSON Jackson parser from
json is actually one of the best parcels
that I've seen compared to any of the
end you will see to it some of these
results so the other parts are like the
Jason and jettison some of those things
are really out of whack when you're
talking about these kind of performance
numbers right so not not much surprise
this year further go further stuff lower
payloads message I have row but higher
payloads protest stuff followed by
Jackson and then protobuf now let's look
at d civilization the same thing on
desalination again anything percentages
to take out the outliers I took out the
outliers for the five percent and tip
the 95th percentile numbers again for
even for desalination for above is the
best followed by avril and product stuff
and while these tip message back and all
of these are good at lower payloads
as the message size increases they are
really getting out of whack fifth ave
row and these are getting out of whack
as the payload size increase as you can
see for one megabyte this stuff is
really out of whack let's combine the
two total time because it's important to
have total civilization and desolation
cost there so if I were to combine those
two together overall for higher pay
loads the best formats is full of stuff
as you can tell followed by protobuf
this is streaming this is not streaming
avro and then Jackson then pretty
actually close if you can see pretty
buff product of Jackson and Avril
they're actually relatively close even
though given that order but they're
relatively close for lower payloads yes
thrift and Avro of thrift also coming in
a picture but drift kind of grows out of
the picture when you start increasing
these sizes that's the primarily the
difference between higher payloads and
lower payloads
now let's look at the size of the
message the same message when I take and
serialize it how what's the size of the
thing so obviously XML XML is the
reference here so if you have one
megabyte of XML but there is no
reduction there it's a reference there
but XML thrift message packs if you look
at anything about this line so these
points which is XML thrift message back
they don't seem to have any advantage if
you have one megabyte it is more or less
having the same size on the serialize it
doesn't have any advantage of the
compactness all other formats pretty
much seems to have about thirty to forty
percent depending on the types of
messages about thirty to forty percent
reduction in size based on the other
formats so really the punch line is that
considering all of the factors that I
talked about how easy it is to
versioning the richness of the schema
ease of use velocity language support
plus performance and size and network
ban all of that right all of the things
that I've listed if you're really
thinking about where it is not a
critical performance thing in the sense
that you can live with a one millisecond
here and there then really Jackson is
the overall best to use in spite of the
fact that these are all the different
binary formats that we have seen but if
you can live where one millisecond plus
or minus 1 to 2 milliseconds is not a
problem I would we would still go with
Jackson days and that's kind of what we
have done but there are scenarios where
you know this is what we had even 12
milliseconds extra time actually it does
matter in some specific scenarios in
those scenarios we went for protoss
stuff
but this is again these formats
internally typically when you start
using proto stuff and protobuf and never
any of these things typically you can do
that internally between AP ice but the
moment you try to expose the externally
then we have to explain to them and they
have to use the same they have to
understand it's not very common so for
external formats for sure I would
certainly stick with JSON format now how
do we plug these so earlier I showed you
in one of the slides how to plug in
different data formats for XML JSON but
now that we have gone through all of
these for other binary formats I mean
how do we how do we plug them in
seamlessly without changing the api's
even the rest of all especially if you
are using jax-rs there is aware jax-rs
has this concept of message readers and
mrs. writers so for each format you
write a message later and a message
writer there is an interface in jax-rs
and in fact there is a publicly
downloadable if you are download Jersey
which is an open-source implementation
of Jack service it also has a built-in
if i'm not mistaken built-in message
readers and writers for protobuf but
even if it didn't it's actually pretty
straightforward so you can write to
readers and writers use a proto see
generate your classes and write your
readers to use those classes so it's
transparent to the API developer and the
API consumer if you are using of course
this is the jax-rs stuff that I talked
about message readers and writers if
you're using turmeric which is the
product that we open sourced and the way
that works is essentially you take that
format whether it's Avro protobuf for
anything we have given and used a
corresponding tool to generate those
classes because each each format comes
with its own tool you generate those
classes and then use our eclipse plugin
that you put it out there that eclipse
plugin allows you to generate what we
call the delegation classes
to do the application it makes it look
like there's only one way to deal with
it there's only one format but
underneath we are changing this so even
though you're generating these different
delegation different data format
specific classes will generate a rapper
delegation class on top of that to make
it look like to the application it's all
the same formats you just changing
behind the scenes so what I mean by that
is it kind of looks like this so if you
have a client-side application to the
application it looks like that just
standard Jack's BB i have an xml schema
message i defined my beam and here are
the attributes of the beam that's what
it is but but the eclipse plugin that
i'm talking about here generates this
format specific delegation object that
knows how to delegate the corresponding
fields to this format specific object
and uses that corresponding civilization
put it on the wire and the other side it
nurse the corresponding visualization to
use it and then creates the format
specific delegation object which then
extend from these beans and then again
the service implementation here only
deals with the beans so the magic
happens here same same story same thing
with with jax-rs west as well
so one other thing that I want to touch
is worsening Washington is actually a
pretty big problem always in AP ice and
and it's more an art than a science
because a lot of the times all my
developers they already went over I've
made a mistake I didn't change this
stuff we need to change this they have a
different API we've got to change the
structure inputs and outputs you have to
be real careful how do you deal with
versioning because you're dealing with
sometimes internal customers sometimes
external customers who are writing to
the api's right and unfortunately there
is no standard for this there is no
standard defined by anybody for how to
do worsening or what is the right thing
or what is the wrong thing there is no
such thing it's all about conventions
and what works of what works best for in
what scenario that you have so what we
have done so different approaches
internally how do we deal with
versioning how do we expose that
versioning externally internally we have
you know again this is not a rocket
science probably most of you are
probably already following this is a
three-part versioning scheme what I call
three-part versioning scheme major minor
and maintenance so once you define your
API one so define your message
structures and you let's say you call it
one out of 100 of course from time to
time you have to fix bugs you have to
change the things but you're not really
changing the behavior of the EPIRB hey
or the structure of the API I mean it's
straightforward to increment your last
it is it which is the minor number I'm
sorry maintenance number and then this
middle digit which is the minor number
is when you have additional capabilities
additional functionality that you want
to add to your API or structure but in a
way that's backward compatible in other
words if you have an older or existing
client that's talking using your api's
it's not going to break just because you
have added new functionality right if
you did that and you can you can
increment the minor version and then
finally if you are in fact changing
making changes that are backward
compatible then you bump up the major
version
which is Gerardo for example right at
that point you have to run we run both
wondered x + 2 reduction simultaneously
in parallel so existing clients who were
previously connecting to wonder X will
continue to work and new clients who
would like to leverage the new
capabilities will hit the two point O
endpoint right so and of course they're
typically based on companies you have
deprecation policies and how long you
run both of them simultaneously and so
on right that puts internally now for
externally we don't want to expose all
of that we want to make the people who
are external developers who are writing
to our API is their life simple so we
want we don't want to expose all of that
we will only expose the we only expose
the major version in the URI resource
versioning in the you or I right example
being if you have for example services
that you better calm your domain service
and then the v1 so in the URI it's going
to be just v1 or v2 or v3 which is a
major version number you're not going to
expose all of these miners and
maintenance that's behind the scenes as
far as an external customer is concerned
you have given me version 1 of the API
as long as I you keep changing behind
within the same version as long as my
app continues to work I'm good that's
version one you call it one or two one
or three I don't care whatever it is it
continues to work but the moment to
change the API definitions such that my
app no longer works are I have you know
then you call it V 2 but continue to
support v1 and it's still running where
I can hit my endpoint new apps hit the
veto and we have course policies for
that now in the case of rest some of
those some of you who are in the room
who are pure rest oriented folks you
would like to argue sometimes that hey
you know in the rest world you don't put
the version number on the URI there is a
accept header content negotiation
mechanism in HTTP that you would
actually do that in other words in the
HTTP accept header in addition to
specifying so I'm expecting I would only
accept JSON or
xml or forever for whatever message that
you are specifying there is also a way
to specify I one version 1.2 or I one
version one I want version 3 and then
you can negotiate HTTP protocol allows
you to do that now the problem with that
is number one it's not visible to people
who are writing the application
especially the external customers who
are simply looking at the or ice and
writing programs to that and they don't
necessarily have an easy way to
manipulate or change those headers and
second is that in especially in caching
when you're when we knew when the
clients make a lot of these calls that
are Akamai like cash that were set up on
the server side and those guys know and
how to cash based on the euro is they
don't cash are no based on these headers
right so as a result even though yes in
a pure rest of all you would use the
accept header to negotiate your version
but it is pretty industry standard
convention that everybody uses this V
once in fact this is not just as if you
look at any your eyes any AP ice in the
world pretty much everybody start using
that right but i do want to mention
there are people who would argue that
you can still do that you can still do
that it doesn't this mechanism doesn't
prevent you to do that but there are
caveats you're cashing maynard work your
I browser to browser said apps
especially if you're writing a
JavaScript a browser running in which
wants to make an API call it's sometimes
difficult to manipulate these headers
within that code and of course the like
I said depending on which format that
you're using implementation of the
version on the server side varies
because if you're using photobook forces
avril versus you know json vs xml how
you improvement the versioning behind
the scenes is going to be the complexity
is going to be varying degrees so that's
in summary we were saying is the api
platform itself has several challenges
in addition to the EPI design and both
are equally important it's not just the
EP design or the platform design both
Polly important and performance
usability of worsening interoperability
are some of the key aspects to consider
when choosing a data format when you are
developing an API which form i do expose
and the good thing is if you design it
in such a way that even if you choose
today some format and that's what we did
we chose XML several years ago then we
change it disease on we change it to put
above but we didn't have to go back and
ask our users to change their apps right
that that's the key so choose something
that's best for you based on what we you
know these key factors and but more
importantly make sure that when you
change the format don't is that you're
not asking your app developers to go
back and change the occurred the types
are going to be slightly different I
mean the challenges are going to be
slightly different for internal external
and we went through that as well binary
data formats while they have their own
benefits it has its own challenges like
I said each one you have to keep
learning the way at least the people who
are implementing it keep learning the
new semantics new idea your schemas and
each one has its own to class generation
mechanism right in its so nothing is
free there's no free lunch if you want
to leverage those you have to go through
that pain but at least what you want to
do is that as a API developer you want
to take that pain and not give that pain
or translate the pain to the APA
consumer this benchmark study that we
did pretty detail in fact I i will put
that code on github I'll probably try to
send that link also include that when i
send the presentation so you guys can
all take a look at the benchmark how the
benchmark actually works and take a look
at that so again worsening deal with
simple conventions you know you got to
be pragmatic you have you can't be
theoretical but at the same time you
can't you can't be either extreme you
have a pragmatic what works what is the
convention the industry what works and
how
how to make it e the API consumers and
developers life easy and the some of
this stuff is also open sourced or like
a mention on ebay open source dead organ
turmeric if you want to take a look at
that but that's pretty much what I
wanted to you've got five minutes for
questions any questions was that useful
is that what you are expecting we're
expecting something totally different i
know a lot of the times it happens you
expect something come to the talk and
then you heat something else hope I
haven't disappointed you first thing in
the morning but any</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>