<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Real-World Performance - 7 - Set Based Processing | Coder Coacher - Coaching Coders</title><meta content="Real-World Performance - 7 - Set Based Processing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Real-World Performance - 7 - Set Based Processing</b></h2><h5 class="post__date">2014-04-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/II9qxyBw23g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all you talk about here is a prelude to
give you an idea of the importance of
doing set-based processing rather than
doing row by row processing the
challenge we face is that historically
programmers have historically liked to
write things in paragraphs or paragraphs
or or chapters of code that dealt with
one row or one object at a time and this
whilst it's greater producing producing
functional code relatively quickly and
making meeting their objective in terms
of meeting the functional requirements
of a program it inherently is results in
serial programs that will undoubtedly
never scale when the data volumes get
large or if you're trying to exploit
parallel techniques on big computers of
the nature that we deal with now at
Oracle so we have this challenge in the
industry where datasets are getting
bigger computers are getting bigger
computers are getting better at
processing in parallel also the
computers are less likely to be IO
starved as they were historically when
people wrote programs or went to school
because a whole generation of
programmers have grown up thinking IO
was bad and done everything to avoid it
and now the game has changed data sets
are big very often in the millions or
billions or even trillions of rows
computers have got up to hundreds of and
even thousands of CPUs and i/o with
technologies like excavator and main
memory computing has largely been
mitigated so it meant that things could
run a cpu speed and so we needed to
start our architecting code to run at
CPU speed
not just one CPU but to exploit all the
CPUs but the challenge is in many cases
just even on small computers the
programs were done in an inefficient
manner and this is what we want to show
in a very simple case of just how we can
make a serial program in fact more
efficient than someone's attempt at
doing parallel processing because it was
being done in the right place and what
we're gonna do here is demonstrate
loading 20 million rows and what I'm
going to show is we're going to do this
by a series of races and we're gonna
race two types of racer there's racer 1
and there's racer 2 and racer 1 he's
using a dedicated connection to the
database just one connection and bulk
loading a thousand rows at a time the
second racer is using a classic Java
connection pool and it's having 16
connections to the database she has a
hundred and twenty eight individual Java
threads within the application and what
we're gonna do is we're gonna race them
instead of in front of you and see who
can load 20 million rows first and as
you can see both processes are starting
up I mean it's very apparent that if we
actually look at the graph you can see
which racer is pulling ahead it's the
guy that's doing the array insert and
using only one core if we actually look
at what's going on within the computer
you can see the machine that's doing one
core is only using one process and it's
very evenly loaded and if you look at
the the host that is actually running
doing the pool of 16 you'll notice we're
getting more CPUs busy but we've also
got a lot of processes in weight states
and if you actually look at the CPU you
can see that the CPU utilization on the
threaded case is actually higher than on
the array case yet if we actually now
start looking at the performance after
the first race finishes the first single
thread was able to load 20 million rows
in just over a minute now we're going to
stop the race at any second of time when
it's finished and then let's see what
sort of time we were if we'd actually
gone with the threading model it would
have taken us 22 middle 22 minutes to
actually a load the same 20 million rows
so a system architects had architected
to use a connection pool and do
everything one row at a time and now she
use the java pool it'll probably blame
the database and said the database
couldn't load 20 million rows in an
acceptable period of time so you can see
two different programming styles again
all running on the same hardware one
works really well one doesn't work very
well and is in fact 20 times slower so
in many cases we say well you know we
didn't use up all the hardware on the
other case on the threaded case so we
should potentially give it some more
connections for the database so I'm
going to increase the connections quite
dramatically to the database I'm going
to give it 64 connections to the
database and I'm gonna give 512 threads
to the application server so there's no
shortage of connections threads or
whatever has and I'm gonna run the race
again and let's just see what happens
and again we're seeing similar
characteristics
we're throwing a lot more hardware as
you can see popping up here we go but
many of those processes whilst busy are
will in a wait state they're not
actually doing the inserts we've got no
shortage your threads we've got no
shortage of processing but you can see
that the threaded model because it's
doing things lots one at a time it isn't
actually achieving any of its objectives
of trying to make things work because
basically with funneling effectively
contention downstream to the database
where is the one that is running serial
is running extremely efficient and is
able actually to wrote load rows into
the database much faster in this case
and in fact
we're starting to see some interference
where in fact the threaded one is
actually slowing down the serial process
but you can see that we've shaved a
little bit of time of the race or two
we're going to get it to finish in about
13 minutes and racer 1 is still taking
about a minute to load 20 million rows
so that didn't show just throwing
resources at the problem it just showed
that the programming model was worse if
we start to index the table that we're
inserting and making it much more
real-world let's rerun the race and see
what happens at this point in time as
you can see the anticipated times for
the jobs are going to take a little bit
longer even the one with the racer one
with the array insert is taking slightly
longer because we have to maintain that
index but it gets more interesting if we
actually look at the second case the
threaded model with all those threads
and you can see that we're getting
experiencing a lot more database
contention inside the database usually
associated with TX index contention and
buffer busy weights as you can see here
and this is basically just us creating a
program that builds inherent contention
into the database at a later time and
very often we hear people saying oh it's
the databases fault it cannot scale its
current it can't accommodate the
workload again you can see a row by row
programming paradigm is the challenge
that we've got here and you can see that
basically whilst we're putting lots of
threads in motion most of them are
stalled because they're contending with
each other whereas if we set up the
workload to work in batches we're not
only saving code paths but we're
eliminating contention because there's
so few threads active in the game so
again we're going to reproduce that
basically we need to learn how to deal
with in sets and think about CPU
efficiency and how to mitigate
contention this is a very simple case
and you can see again with orders of
magnitude faster by doing it
using an array and asset based
programming method rather than single
row at a time and effectively manual or
homegrown or homespun parallelism
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>