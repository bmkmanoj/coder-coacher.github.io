<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Delivering Performance and Reliability at the World's Leading Futures Exchange | Coder Coacher - Coaching Coders</title><meta content="Delivering Performance and Reliability at the World's Leading Futures Exchange - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Delivering Performance and Reliability at the World's Leading Futures Exchange</b></h2><h5 class="post__date">2013-01-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sMkahGYynbw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Ronnie Perrin I work for the
Chicago Mercantile Exchange it is a
futures exchange based in Chicago and
I'm here to talk about two of the big
tenants that dry the department that I
work for which is performance and
reliability I'm not going to be a shrink
a lot of code because the lawyers got in
and they said you just can't do that but
what I will try to convey to you
throughout the presentation is the
different types of strategies we use to
measure our software and to get the
reliability I have a legal announcement
Freddie it's sort of like gambling it's
fun if you make a lot of money to snap
if you don't so it's not for everybody
take my word for what I'm saying but you
know it may be truly may not be true I
hope it's mostly true but that's the
legal stuff who's this eme group it says
exchange I was founded in chicago in the
eighteen hundreds we've been around for
quite a while and now it's merged with
other exchanges in the united states so
it is the force blood but it is the
largest exchange for futures in the
united states in the world we have four
different division the Chicago
Mercantile Exchange which deals with
agricultural products mostly the bottle
train which deals with financial product
the trader rebounds do you have a
mercantile exchange oil natural gas and
come axis precious metals so platinum
gold so we cover a wide variety of
different assets the application work on
is the match engine that is the piece of
software that we see hoarders from
traders another five possible trades and
matches an executable straight it's part
of larger Sweden soon
application that's Google backs low
backs with the first futures electronic
exchange and it's one of the highest
reliability fastest application for
futures trading platforms that we have
around today for those who are familiar
with the industry futures is somewhat
different than stock stock exchanges
like the new york stock exchange so our
response times when we say were the
fastest were the fastest in the future
meaning we are looking at response time
around 11 millisecond a stock exchange
is a different requirement their
business it will be different I will go
and showing that why that is the case in
a little bit but with it their response
times are faster than ours but the
business requirements are quite
different the application itself is
relatively simple we receive orders from
traders it comes in in a gateway which
basically reformats the messages from
some external formatting to our own
internal format we have a match server
which analyzed the possible trade
execute the trade sands the order
acknowledgements and the trades back to
the traders we produced almost way to
storage so we have a record of that and
we also have a market data component
which you're probably most familiar with
is the ticker it's the little scorer and
the bottom of the screen that shows you
start prices and the price of oil to buy
olive oil and thing think of that nature
so every order it's it's an anonymous
market every order that we receive we
publish to the world saying without
trader information saying this interest
to buy or sell a certain commodity at a
certain price and for certain pony and
then we have a clearing house which is
responsible for moving the money between
buyers and sellers and we also are
notified from the appliqué
when you train the doctors so basically
I just described the application of the
the behavior of the application in open
market receive orders maybe new orders
modify cancel we identified a possible
trade not in the fly GL and I mentioned
two possible kinds of trades it's all
right or implies are going to what we're
opening in a minute but we have
different types of matching that we
support different types of application
to order so that everybody received a
fair share of incoming orders we must
identify all those execute all those
persist to database and notify and again
generated market data so the kind of
course in matching basically a took
something I'm sure Holly recognizes clz
too that's cool oil sometimes some but
something we should all be familiar to
v2 just mean it's intuitive it's
December up 2012 so another I trade is
if somebody wants to buy some contract
of crude oil and somebody wants to sell
we match those two and we execute it we
also have what we call strategies
calendar spreads I shall crack here and
the crack is a contract that will resign
actually whatever refinery days which is
the cracking or the raffle and refining
of oil from crude oil into eating oil so
h o stands for aiding oil in CL for
crude oil so when somebody buys contract
actually it's really equivalent to
buying one of the underlying contracts
and selling the other line contract and
the sale is directly opposite so here
again if those are all my trades people
are buying and selling things that match
exactly when it gets really interesting
its frame we do imply trading because an
implied order in this case is actually a
combination of
different orders if to traders I put the
two underlying orders for that one
component that you can see as being the
equivalent of the crack one instrument
and therefore we can imply an order from
the toner lying legs and train those to
drink about these is those are not
actually order on the books these are
things that the engine the training
engine identified as orders arrive and
execute and then we can take it a step
further is this in this case one of the
wag is not really present here but I can
implied it from a different type of
strategy so we can change those things
and come up with more combinations of
coming with all the pieces that we need
in order to execute the train we stopped
at two we have technology that would
actually do more than two but there is
very good reason to stop at two so here
on our light rain if you can see that we
have 1557 instruments in that set of
instrument that I selected that the
train one against the other if we try to
break him down just one letter it's very
manageable we come up with 2734
different combination it's not too bad
about twice price let the original count
not quite but once we add another level
you can see it grows exponentially
46,000 different combinations we have to
to check every time in order arrives
that's a lot that's a worst case basis
it doesn't always happen but it could
that that's what the model has to
support so here I have some statistic
that says every time there is an
arriving order we can really look at
2050 instruments that can participate to
match without one driving order and
that's foreign currency two different
types of
nations so the mathematics behind it
it's not hard buying and selling it's
adding subtracting a little little bit
of poration percentage very simple math
but just the numbers get very very very
large very quickly so that's a challenge
in occupation so again massively nothing
that's not difficult not complicated but
a lot a lot a lot of it once we identify
matches we have to apportion the match
to each of the participants and there's
five different ways of doing that so
let's additional calculations as well
another characteristic of application is
people put in order and order to arrest
on the book as long as they cannot trade
so if somebody is willing to buy
something but nobody's selling or they
are selling but not at the price let
that both parties can agree on the
orders would still the book but every
once in a while you can have a very
large order somebody sees your good
opportunity in the market a lot of
orders resting and they put a matching
order on the other side of our order
book and that generates tremendous
amount of activity on the system as well
so it's very picky and the problem that
results because of this is because our
reading is very important we must q
every new order that comes in while the
one order is being processed and that we
result in availably in a large amount of
lading seeds which we really do not like
so knowing the problem whatever our
constraints will other address explain
to you it's really the market has to be
seen as at all anybody has to be able to
travel is everybody all the products
have to be avail
money so we cannot take a style approach
and try to divide and compare which
would be in a scalable application the
traditional way of trying to resolve a
capacity problem just make smaller unit
of works divided in four more more
workers and the work gets done faster in
a non-violent it is not possible
customers has to be able to try anything
at any time against in your videos or
order and to make matters worse the
ordering of orders is important as well
when somebody puts an order in the
standing line and that don't like to
lose that's just bottom line either so
ordering is very important so again
there are traditional scaling and
performance solutions that are widely
used but then do not really apply to
throw on right in
a little advertising here we have this
this is from or marketing literature you
just picked a time it's not the most
up-to-date it's up to two thousand
eleven numbers might be a little hard
especially for the one in the back to to
see but basically it shows the enough of
the billion of orders a month we
processed and back six years ago or
they're bad we were in the neighbor of
one and a half we've peaked during the
peak of the financial crisis about a
year a year ago in a neighborhood of
thirty to thirty three billion orders a
month and we had now we are down a
little bit from both Williams the way
record volumes the blue line and the
yellow line with those our response time
and you can see that going back six
years ago we are response time of it in
the neighborhood of setting at eleven
seconds I have an 80 seconds I'm sorry
and we are down to about one millisecond
now so you see that what we will achieve
quite impressive business groups an
order volume growth or response time
have decreased your warrior in a quite
an equation quite impressive fashion so
I would like to keep it going that way
the key force when it comes to to Derek
performance is measuring we measure
performance all the time every day all
day day in and day out and magog with
reports so this is a report every time
these market events primary key with the
the federal bank speaks we have we have
a number that comes out and we measure
that activity very closely cool
adventuring comes out big big peak in
the activity in on the system we measure
that that's a number from let me get the
dates tray here this is from may eight
and all be just six minutes this is a
six minute interval from 1325 from 1331
so what about 113 afternoon we we
processed during that six minutes an
average of two thousand six hundred
message or orders a second we peaked at
15,000 15,000 cycle orders a second
that's not bad our response time is six
milliseconds average the worst that we
process in that time going back to the
volume being very peaky was the 177
milliseconds so at some point there was
a large event and we backed up and all
those factual in the statistics here but
if you are if you are interested in the
performance of your system you have to
get it comfort constantly and we do that
one of the saying that I was surprised
when i first started at the chicago
mercantile exchange we record every
single message coming in and coming out
of the system each message is
time-stamped we can look at every
application every message that flows
through the system and look at the
performance and those are the type of
instrumentation if you're really serious
about performance that you do need to
have in your application you need
visibility and by the way this is not
this building this is a six-minute two
seconds you don't really know where
where the time was spent in your
vacation it just gives you a baseline
which is important to us but it's just a
baseline of how are we doing are we
doing better are we doing worse but if
there was a problem this gives you up so
we know inside of what the problem could
be so it's an important piece of
information but it's not the most
critical piece of information but again
the baby yes
why are we measuring six minutes it's an
ethical number we picked with we don't
only the narrow to the window to be too
narrow because the it would not be very
sensitive and if you make the window too
large then you lower your average and
when there's a market event that occurs
I'm pretty cool group that i just showed
that the most of the activity is going
to occur in a about a five six minute
time frame that's one of the answers the
other answer that is also relevant is
this is not only use for monitoring and
it is a something particular to on
violent I came from banking environment
where we were a 24 by 7 by 365 no
downtime the stock markets we have to be
up when the application is up but we
shut down on the weekends and saturdays
and sundays are dedicated to making
changes and testing those changes and we
test goes into doing that later we take
that five minutes 6 minutes 56 million
interval worth of order I just say we
record all the messages coming in we
have the ability to take that data
replay it to the system make some
changes change all database
configuration change do a hardware
upgrade software upgrades run the same
set and say how we better off or worse
off than last week is these problems we
can do this over and over 6 million
users we can it's representative we can
do it several times if we if we need to
it's practical but thank you very much
excellent question
so again we saw two thousand twenty six
hundred orders a second with a pickup 15
side 15 solid so it's very bursty we've
seen pics of about ten times average and
that from the planning capacity planning
a performance standpoint there's a lot
of application implications as you may
as you may guess also when we look at
the performance of implication all
orders that come in and on equals in
order that arrive and definite rain does
not generate the same workload of a
system that one then an order that
writes in trades so the full file varies
from the type of order we're processing
orders may have cascading effect there's
special type of orders that are cool
stopovers but not really in a book so
when an order an order arrives they're
not really taken into account for
matching but those top orders are
triggering points that says if something
happens in the market and if they do buy
or sell at a certain price on the market
then I want my order to become active so
every time in order arrives in trains we
have to look at or stop orders and see
if anyone get triggered we have to pass
a soul before we process any signal is
cubed because even those those tough
orders were not physically active
they're on the books so they have
priority then we get executed as a
matter of security then they trigger
other stuff orders so in the event of a
wall market swing that we had a few
months ago these stuff orders can sort
of snowball and generate a lot of
activity on the system which again needs
to be taken into account before we end
of any of the incoming messages so
that's another profile that we have to
account
one and we try to be reasonably quick
and doing that so this is sort of a
guideline that we have a response time
and we sing 0 to 1 millisecond is really
good in that in that amount of time if
you want to put it in perspective sounds
will travel about the foot people are in
back of the room you but you may
experience a slight delay before you
here like we travel 300 kilometers a
large caster so you'll see my lips
moving before you hear me but I'm not
lip-syncing 5 milliseconds it's okay 125
milliseconds that's the average seek
time of a 10,000 RPM disc 5 25 to 30
milliseconds we consider slow fastest
ship time bugatti veyron very fast part
3 8 milliseconds to ship here that's
pretty fast once we fall below that
stage we just consider ourselves very
slow and that is that is not good so
again how do we measure how do we
validate or performance we've led do
every week every Saturday we do nothing
but validate performance and we friday
at four o'clock the markets closed we do
all methods the nature of the futures
market if you're selling the product
that has a bill every date every month
some of the product expires some new
products to come out on the market we
configure those we have to tell us that
those changes have not negatively of any
negative impact we may change some of
the business rules how will allocate to
orders the various algorithms that can
be used though that to be tested as well
any change on is introduced on the
system is tested and it's tested
specifically for performance if you're
serious about performance you have to
measure if you take 11 message out of
this presentation
I hope that's what it is so the way we
do this is taking all the orders we
recorded for every we have 19 different
platforms futures options and futures
agricultural financial energies met
metal markets 19 different platforms we
test every Saturday every single one of
them we take the sixth busiest minute
whenever it is in a week you can tell
that information the report as shown
earlier we run it on the weekend we make
sure that it's in line I'm never
identical yes sir necessary
so you know we have an application the
other most we playin director that
actually loads is six-minute intervals
in memory and injects them there is
dials and you can inject in real time
that's what we normally do for testing
you can do the half time again twice the
speed this be you can add wrestle down
up and down as you will but the injector
actually time that's the time you is it
perfect you know when you think of a
business we have very large trading
firms otherwise especially names
probably not but they plane all the
markets so they have one connection to
over to us we have the routing routers
that send those messages to the crack
platform thinking the coup Mingo is
orders from other traders these books
carrying they are never identical we are
looking at that in the future the way
you make it an article is left to be
single North a single pipe but it's not
and just a minute please so the day
expose the replays are closed but
they're not a hundred percent accurate
just a second yes sir you're next should
you replay the density in every way the
actual trades with the numbers that they
traded at
in other words they are you saying okay
during this minute we have this many
transactions so we'll just play back to
transactions of the state of the
database
that would expect it he just listens
dismayed at this minute this minute they
have different states you've actually on
different rates
your algorithm
excellent question a high sustained are
impacting the replay so we've captured
six-minute the six-minute can be from a
Monday morning or it can be from a
Friday afternoon when we start the
replay well what are several things that
first of all we start with a clean book
so if you took a snapshot the statutory
plane is on Friday if you're missing all
the odors that we're putting it in
during the week so it's slightly
different also there's a burn in any
bench language of burning period like
the first 30 seconds typically out a
little off but when you look at the
market the orders especially in today's
world where the orders are generated by
triple two-minute trading systems they
are in responses to over the last event
so at some point is an event that the
trigger the norther order to come in and
and that unity physically is preserved
that six min when we when you look at a
six minute interval that kind of effect
and reaction is preserved doesn't answer
your question there was another question
here
six minute recording and you test with
that
no remains the messengers the orders
that come into the system i recorded
swallow every single message is required
for the entire week at the beginning of
the test we clean up the database we
clean up your books because that's the
only way we can guarantee that if we
repeat the same test that the state is
similar so we clear all the books and I
no need to state the same as it was in
production and beginning of the test
that would be preferable but in order to
achieve that if I took a snapshot on
friday i would have to every time I want
to test I would have to be run every
order from mullet morning when we open
until until that friday when i take the
snapshot it's just not natural but we
never know when when that six-minute is
going to be you I we can remove this
constantly and at the end of the week
you say here when 26 minutes but
whatever it happens to be we have no
control over that so we can we can say
okay now we going to pressure so we're
going to take a snapshot that's
impossible
yeah yes yes it is but when you're
talking about 15,000 message of the
second you moving you race officially a
working environment very quickly and
it's a solid line of being number sir if
you will that the number of alleged
whatever the status of the database was
rather digging doesn't matter when
you're just we when we started fast look
at that a bitch is totally clean there
was another question yes sir
you
I'm sorry can you repeat it yes we test
in production and I will come to that a
little bit later what's better amazing
question we taste in our production that
is the the advantage I won't say that we
have in the market is on finding me
clothes right it is not a library that
everybody has but it takes the same
hardware at the same software and the
same network it's tara singh the same
it's not a test bed it's the actual
production system yes sir its own goal
every time we run the test we clean up
everything so if you run the same test
several time to clean that up and then
on Friday on on Saturday evening when we
get ready for a Sunday morning open of
course all testing that has to be worked
out of the system so we have a very
extensive database roll a cleanup
procedure if you will to make sure that
we don't have the prices I mean if you
run if that I was captured on Monday the
prices you injecting in the trading
hundred from friday may be way off from
where they were on Friday night let
alone whether it'll be on Sunday morning
when you open so we are very strict
procedures about cleaning up all that
data that's one of the drawback of
testing in production you have to be
really good about putting it up when
you're done limitation of the outside
too i think be done that force to death
that's when we are just talking about
what people snap here i can wear out to
you did it by the way so if we can i
call that Vieira and we need some kind
of tool to to analyze the data because
it just only are unmanageable otherwise
so we have two types of tools that we
use or techniques out i should say what
is the matrix and matrix a discount or
how many events have occurred over a
certain period of time and figure we'll
know normally count every 30 seconds how
many orders are coming in at 30 second
how many order traded what type of
trades we did that type of thing and we
also have tracers and tracers are
timestamps nanosecond thanks Tam that
the application takes at each critical
step of processing though that so that
we can after the after the fact not only
a boson average yeah just good to know
it's a good benchmark but it really
doesn't give us any insights in terms
if something goes on what did go wrong
that to be able to do the
troubleshooting you need to do in that
case you need to be able to look at
where was it stands the time span and
for that we use spacers we capture three
tracers every 1000 messages so we trace
three let a bunch of go by Chris tree
and we capture the data on roundest so
that it limited impact to the system so
the little bit older they want me to
show ID so that when having an order
that arrives basically we have pressure
comes down metric constants we count
stands and we time Saints not
particularly interesting and the metric
there is dressed in a large it's
basically a counter at some kind of
counter name so no no go to receive
number of trades executed and a number
the pressure that I again you need to to
look at because this is this is just a
little Greek to me it means actually
nothing so where were we wrote one
called the dashboard that's allow us to
look at that data the interesting thing
about the dashboard and the source of
the data is the source doesn't have to
be production we use it a lot but it
doesn't have to be from production we do
continued integration yet we use bamboo
bamboo server to do that we can run
every night the performance test based
on the latest code that we push our
development stream and every night we
can't see how do we do in performance we
actually measured two flavors of that we
measure from Bill to Bill so in other
words if I just did something really
really wrong I'm not going to have to
wait until he goes to performance
testing six months from now or in
production I will know tomorrow morning
when I get in the office you brought a
performance test much easier
much faster feedback much easier to
identify what the change was that
degraded performance that if you wait
until the end of the project we also
measure we also compare not not only be
able to build but from a baseline that's
established at the beginning of the
project so that we don't have a slow
decay over time we can identify that as
well so the source of the data when
you're looking at analyzing performance
that are not necessarily have to be
necessarily from production it can also
be from your development environment or
from your tetas from a performance
testing environment but basically it
looks something like that we can select
any one of our 19 engines select a day
of time and then the filters the blue
box on the lab allows you to add some
metadata premier on during the
discussion I said different orders are
not equals so an order that will if you
add in order modify or cancel an order
those orders behave differently in the
system and using the tool such as this
one you can actually validate that so
you have a set of tech select any order
that comes in an entry you can add
several of these filters so I added
sweet of them new modifier canceled and
I can look at the numbers the number
shows the performance but an even better
way to look at it is for graph so here
you can clearly see that the red line
the council's actually faster than the
modified and in order so that's valuable
information in insight into the
application its top of insider the Nemo
report the previous report a show that
is ok you did 15,000 collector orders a
second and the other is 5 millisecond
response time ok
but you know 11 made that up we don't
really know with this type of
perspective into the application you can
actually gain additional inside so as
you're contemplating monitoring
performance you have to instrument your
application in order to court to provide
the correct windows into into the
workings of your application issue there
are different ways to look at the event
manner where thing is no some kind of
cumulative distribution you can clearly
see that the red line here is much more
much faster response time than the other
two it's also interesting here it's all
the same data so the average showed a
five minute second response time you can
see here I mean 77 90 seconds that's the
final two to process to process an order
or cancel an order you can see the
cumulative distribution ninety percent
is around screen right back with a yes
microseconds so what's the difference
between the 10 in microseconds at the 5
millisecond it's wonderful when a ladder
comes in it calls it cause latency
everything cues up beyond and that is
the perfect illustration for that type
of situation I mentioned earlier order
that trades versus orders that don't
trade in order that it just goes on a
girl I only any work so the yellow line
no much lower sometimes doing a lot
skerries will be better because it kind
of sprite things a little bit otherwise
think they get console bit together
again distributed
I'm sorry I'm going to acknowledge our
cumulative distribution so I don't I
believe those method particularly I
don't have a preference it's whatever
where you find to visualize the data
that that works for you by only using
make mega data speak to you did someone
ways I handed you a question no okay
some time to change no we measure things
that have nothing to do with with
application we are dating a red hat
version of Linux we had a nice
performance of improvement and you can
see next day you come in you can look at
this it's very clear the technology we
use for that basically we use care why
scalar because but those are just list
of things we have skype internet over
there so we like it I like 4i functional
programming so it was nice my new
database while it was very easy to use
very easy to implement that there is
captured from the production life let's
move to developments it's really or role
as a development team to advise and and
police report on that we didn't need to
get involved with the database group an
Oracle it's very good database don't get
me wrong but they have almost people in
try to administrative to administrate it
and that sometimes it's not the easiest
way for us to work so my ghoul is free
my boss didn't didn't have any problems
with it it works well we like it the GUI
and none of us are doing kind of people
where server folks so we just took the
google toolkit and it cradles of web
pages and
it worked pretty good so you know
whatever is out there that's available
that would make your life easier by only
using I mentioned earlier we don't
really test from production we look at
daily meals we use bamboo but I don't
know what kind of continued continued
continued integration you are using the
whatever it is you can certainly
configure a build other ones and perform
a test of data collector performance
data and you can add analyzer
performance data so do it if if you have
a production if you ever is introduced a
change that will negatively impact your
production performance the sooner you
find it the better off you are and I
believe it with everybody will agree
with me on that yes sir
what do you mean by posting
the information i'm showing here is not
public so if you are customer you'd
already have access to that information
no we pull the statistic from the
collection large once a day at a
two-front drop and at night and we
update and we will get into next morning
that being said if we need it to it's a
nice city coffee and that I run into the
parser takes about 15 minutes to parse
it load it and then just use the inner
page so it it can be quick but we do it
once once a day so far
the
yet
so do we need that information right
away oh my yes and no we every time is a
packet event we generate a report takes
about 15 minutes and it goes to upper
management and offer management look at
this you'd say it just sit in there in
their mailbox like a thousand of a
message I can see when I said have a
message they never look at it that
message they do look at it if the
performance is bad i will i will hear
about it very quickly now that I mean
are we going to do anything no you know
will will first of all no one unless
it's broke I mean unless this the
application has come crashing we are now
going to do anything while the system is
up and running we're going to wait at
least until the evening to to do any
change at all so when it comes to
analysis looking at the data the
analysis we have a delay but management
looks at it like an arc a guarantee so
yes sir
Oh
we are using a 216 cipa cpu spot course
it's running we have the GBM runs which
is typically a 212 megabytes gigabytes
of memory the application itself is it
it's not beams oriented it's it's plain
old java and suppose you'll play no
logic job not single is right-handed it
is multi-threaded in some respect but
when you're looking at matching for
example it is it is very single threaded
why because FICO is a point so as fast
acknowledged it's not fancy it isn't
fancy it's big machines we don't wait
for 60 database updates we don't wait
for it's done it is its kind of found
out and really really worried about it
is a slow we are pleased Iraq that's
database database is obviously the
slowest part of our application yes you
started talking about it you've got all
these numbers telling you
how did that affect you cut out a little
bit overall application design
they said no beans says great job that's
not even more than that to say you know
first of that is going bad what do I do
and then the other part of that is you
know the title is with performance and
reliability a reliability standpoint you
give a about ok when I a machines
go down your second screen will pound
I'm just I'm just coming to that to that
point so if you'll give me a just a few
minutes all right one more question that
I have to move on
the person
you know wow
well hopefully because you are doing
this you're looking at performance on
your daily bill I mean if you're seeing
if you look said something maybe a
little better something maybe a little
work I mean here you would have to look
at it at that point it is not no one
change all that five or six set of China
was on that day how do that in fact
there from us if you look it you know if
you wait until the end and you takes
three step forward one step backward is
very hard to say but if we took to step
forward as a result we're happy with it
you know maybe it's not as good as you
could good at man but if it's better the
one thing is we don't want it to be
worse I'm sorry I gotta move on
otherwise people will if you have
questions we have free time after the
session please come and talk to me i'll
be happy to address them I want to go
through the rest of the material on the
web behind as it is so they're very
liability what is real I'm building a
better system that what it's supposed to
do that's the basic how our residents I
mean the software residency how do you
may not fall you get the blue screen
another blue screen of death not a very
good way of hemming errors you know a
little exception catching and emailing
is a lot better and then fall towards if
something goes down how in your
application yeah so when I talk about it
I be interesting as you we've done all
you've done all the testing that you
normally would consider part of the
development the acceptance testing the
regression testing the integration
testing all this is done for what's left
what's left is the real world is what is
it that you haven't sought off that you
have not naturally are calculated in the
test that you run on as part of your
build process so that's where we can use
the H I that the data amused
on Sunday to test all changes we can run
against our software and make sure that
it does not break everything it's a good
tool for performance it has some pros
and cons the pros is obviously you're
taking real data not something that's
intended that you drink your head and
and it's really nice and clear and at a
nice test case no that's real there from
the real world that's what your
application is going to be subjected to
you whether you roll it out it's good
the bad thing is when you're sending
millions of messages and one causes a
problem that's kind of looking for a
haystack right and you know with a
haystack so it has caused an comes but
it's a technique we find very useful for
qet will not release software to
production until they've done HIV plays
for several days so we like it now the
HR is a good tool don't get me wrong we
like it but it doesn't really that
necessary say that what your application
is doing is correct it's like EDM crash
that's a good start but the other
lysates correct message comparators you
can look at your results from
productions we can look at the results
generated from a test run and make sure
that we have not messed anything up the
pros again this is a really good tool
it's really detailed they'll go fill my
field and you can there's a few feel we
just don't share because the dates are
not going to match and seem like that
but everything else we do validate feel
my field message by message very own
event in size vehicle size we love it
the back sake is if you change your
messaging you have to write some kind of
adapter or the tools loose and it times
it's a big change messaging the two
losses it's some of its usefulness at
the very beginning so that can be a
problem what piles do we test a software
furniture and then that's maybe serve to
answer the question you asked me earlier
a production engine listen to orders
that are coming on a typical bus and the
process those orders and listen that out
back to the customers trade or
acknowledgement and so forth when come
up with a new version of software will
set it out and where we go pal we listen
to the same feed in real time the same
orders puppets run a software make sure
it make sure it works so this is not
even playing an HR I and a child of six
minutes an old snapshot it's good but
this will one for two or three weeks
follow posting the same the same orders
that for two or three weeks so when
we're done with that typically we have a
pretty good level of confidence that
whatever we did it's not going to crash
as soon as we turn it on it should be it
should be should be very stable yes sir
you have a replica of your database
behavior adding your handle to two
engines running the same order they
listen to the same input they use a
totally separate database they don't
publish obviously to the same album bus
because we don't want people to get to
execution or you know that that would
not be good so then listen to the same
input and downstream it's so segregated
but it's monitored by oropeza by
operational staff just like the real
engine so that if something happens
we'll know right away so that's why we
for pop our testing runs in fallon
listen to the 7-foot process the same
input before we actually put something
in production we do my recovery rolls or
only holdouts so on a Saturday we'll put
it in run all the performance tests make
sure it works and only writes like the
last ditch check that we do before
before wearing putting it in production
so put it in running for
saturday afternoon do all the
performance test fully doubt to in my
opinion the management won't let us do
anything if we don't do that of course
although in my opinion if you've been
running in parallel for two or three
weeks you were you you don't learn a lot
and there's nothing wrong with running
one more set of tests but the value from
my perspective is maybe not as great as
one thing but the one thing that is
interesting with this is you do get to
test your rolling procedure so from an
operational standpoint how you deploying
this do you do it correctly what are the
guards of deploying a new application
configuration changes and rolling it out
if I wanna get out if you have a problem
and we need to own your application out
important that you test that as well
this is a good way to do this role in
roll out we do this and then one less
thing talking about fault tolerance we
actually run two systems in parallel one
is the primary which means that it not
only to process the order but also
generate the outputs to the clients and
we have a backup that passes the same
order at the same time but also risen to
the primary output making sure that the
primaries are putting something this is
the both butts in the middle the photo
and synchronization system now who is
alive who is not their voiding asked
Leibrandt decision that's the split
brain syndrome sorry that's a mouthful
so the fall terms synchronization takes
care of that is a product of primary the
backup takes over so that's sort of
addressing oppressions via something
more specific in mind wanting to ask you
know
the application and what rules you might
have put in place saying we don't know
election because we know
x and so anytime that you see your angel
eyes will ever before restarting grade
and it might just be in your testing how
does that affect your wife or your
application design make sure that you
don't introduce things and you
things that are known to reduce perform
ure address you know Yogi's and not
going to understand my straight job
but I would think that there's an
application design aspect to be asked it
is not fancy you'd be amazed the world
where we've come to earth is keep it
simple and I'll give you a simple
example that that started the whole
tracers application the dashboard
performance dashboard effort we had is
we will live about a year ago and
application a change and we saw the
rated-r enters the first corinne find
the first day when fans who only have
the testing that we had done on saturday
shi every single for thursday look at
the single and find the second day
fifteen percent degradation in response
time and we had absolutely no idea where
we went am now we divided into teams
some people did the batch board and the
tracers and providing the
instrumentation to original insight into
the application and the other guys did
well what we do when we don't haven't
struck an instrumentation is we looked
at code a long time and we looked at
everything we change for a long time and
we change the things we change and try
to run tests and it didn't do anything
now where we said really and it turned
out to be some very somewhere in code
somebody did hash bash a hashmap are not
clear turned out to be hash map that was
the cause of the problem so all your
line is you know don't put your eyes
maps if you need a new hash it up just
create one
yes yes it's like though don't try to
don't try to be smart don't try to know
them and a lot of times that that's how
we get into trouble it's trying to get
smart you don't want to be done we are
doing a lot of number crunching we have
to go some smart in the application
don't don't get me wrong but don't try
to be too fancy God simple and if you
have a problem than fix it don't with
the other ran all the way around it
never pays but it's a broad statement to
make but that is really the one that I
would strongly strongly emphasize it
starts simple start clean and if it
doesn't perform no put some don't be
stupid about it you know put some
thought into it but don't try to be
already fancy start simple and if it
needs to be tweaked then tweak it but
that that's my recommendation yes sir
have you taken your application through
a major java upgrade oh very very
interesting are you thinking done by
seven and that equals for example
comparable things that are comparable
you know that I'll ever get this
straight but the same between another
hashcode and equals before the damask it
didn't matter now if something is
comparable with the i equal the hash
code has two people with guess we have
problems like that I would say you know
jaja does a really good job with the
pains event but not not too bad but
we've got a seven in particular yes yes
you're saying that the tide of the rules
we did not observe the rules
the personally enforce the rules and we
have to change applications and that's
so painful but you know it's we were
kind of sloppy in the first place so we
got nobody to help do to blame but
ourselves yes sir to you straight do I
use what okay brain what that's funny
very little very little there is our
expression market data because we have
to calculate so much dear life going out
especially in implied we're over you
coming with one order and you can have
as many as 4 950 things that that that
can change we use fighting there now
remember threading is only goodness you
know you cannot once right for Kole and
after that you're just shooting yourself
in the foot and then it's raining it's
good but it is overhead is locking so
with we would rather be single stranded
and not a blocking issue of immutable
state immutable objects yeah and do it
try to achieve performance now Adam
sweating it helps in some cases but it's
not a panacea it's not it's not the
silver bullet it won't answer all of
your problems yes sir a lot of what do
we do a lot of caliber garbage
collection with we never do in a week
food garbage collection we have only
done and indoor spaces survivor spaces
excuse me Phil carefully allocated so
that we don't do a can of garbage
collection that you stop the word of it
and clean things
we were ready we monitor that Vic very
closely
what
what
so the question is the way I understand
your question is do we put objects for
example do we do we have an architecture
that limits of respiration no we don't
have a problem with garbage collection
as long as it's not a full garbage
collection no it is standard no its
standard the it's not a Concord who can
market sweep I don't know this to flavor
that we've tried but there it is we
don't have custom build garbage
collectors or anything like that it did
straight out of job there's nothing
that's expression yes yes I think that
it requires tuning and not get me wrong
it's just out of the box it depends when
you mean by out of the box it requires
careful tuning but we don't have a magic
garbage collector on a back pocket to
making this work there
no both system is two different
delegations they don't show that it is
then listen to the same message there's
a little bit of a dialogue to identify
that the primary has failed so it's not
instantaneous but it's very quick and by
the time we hang out by that i mean the
backup has taken in the orders process
the orders it knows the results it's
it's holding on publishing those results
waiting for the primary to fail it talks
to the primaries are you still there if
the primary says I'm still here healthy
than the back of the set okay that I can
discard that set it's so invent
processed by the primary we'll move on
if we get to fail to get an answer from
the primary then it is a form of
takeover but it's very quick because
Oliver has only been now this there's
some cleanup to do obviously established
sessions and things like that but it's
already done a single gentleman is
basically four times so thank you very
much everyone</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>