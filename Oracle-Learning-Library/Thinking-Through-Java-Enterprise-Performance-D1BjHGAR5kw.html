<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Thinking Through Java Enterprise Performance | Coder Coacher - Coaching Coders</title><meta content="Thinking Through Java Enterprise Performance - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Thinking Through Java Enterprise Performance</b></h2><h5 class="post__date">2013-02-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/D1BjHGAR5kw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's of course a perfect example of
lousy performance first me showing up
late and then the computer take a long
time to build a might as well get
started talking at least and you will
hear me talking quite a bit in quite
fast as well I've got too many slides
for the session show so showing up late
is a very bad idea and just to warn you
this is really not going to be a
technical session I didn't invite my
mother but I think she could have
probably gotten maybe seven seventy
percent of the presentation is not
looking at performance from very nearby
it's looking at it from far away and
we're not looking to gain performance
improvements in the order of ten percent
or maybe even fifty percent we're
looking at orders of magnitude we
looking at times ten or x 100 better
performance and for that you don't sit
down and look at the little things but
you have to step away and look at the
big things and that's what we're going
to do by the time the computer has
started and I've got my slides up
actually most of the examples i will be
using start out in the real world and
then at some point we'll dive into
concepts in an enterprise Java
architecture but most of the things that
I'm trying to get across live all around
you especially during during conferences
like this one where you have lines
everywhere we have large volumes of in
this case people to process the same
concepts apply and actually I took a few
a few photographs last last Friday
because they perfectly illustrate the
point I'm one of the points I'm trying
to make my not mean I have a few slides
my name is Lucas yellamma i'm from the
netherlands that's quite a very subtle
excellent i live in two worlds really I
and some time at the moscone center for
oracle openworld because i'm doing
oracle development and presenting at
oracle openworld that's one of the
reasons why I'm slightly late and also
attending and presenting sessions at
javaone because I'm also in that world
and its really where to connect and are
many places where they connect
especially better connected the database
level
that's where I typically can sort of
bridge the worlds well there we are
thinking through java enterprise
performance and it's really about
thinking through and performance and the
java bit in between is to get into the
conference so very brief overview will
not just skip it that saves one slide
first definition when you talk about
performance you see an arrow pointing
downwards is that a good thing or bad
thing well it's rare it's probably not a
good thing but and performance goes down
well when response times goes down it's
good well the next slide says response
time end up so in this case the
performance deteriorated but it's
something that you have to clear her to
have to get clear what exactly our
talking about when it's about
performance and it's not just about it's
the arrow pointing upwards or downwards
it's about expectations you can really
only say the performance is not good if
you have define beforehand what the
expectation is maybe what the service
level agreement is and if it didn't make
the expectation then performance maybe
is not good or the expectation was wrong
definitely try story I try to sell to
the users of course real performance
requirements should come from real
business requirements most businesses
business sis I know will say something
like well response time of it web page
on average should be one second and a
half and it may never be longer than
three seconds based on nothing really
and of course in a single page
application architecture what exactly is
the low time of a page because the page
will be there and then you will start
refreshing bits and pieces of the page
if the user is not able to work maybe
then there's a wait time involved if the
user is still able to continue to even
though processing takes place in the
background that may be perfect perfectly
acceptable performance so definition is
important and driving the definition
from what the business really once is
important too although we have we have
some feeling for it ourselves of course
we know that certain types of forms
probably isn't acceptable theatre
manager sees this group of lovely ladies
and he may think well you're happy about
the performance turns out they're
actually not so again it's about
definitions so performance if you're
trying to quantify it and your typical
enterprise java application would have a
multi-tier architecture let's let's keep
it simple we have our web tier browser
and client here we have the je
applications whoever where things happen
and there will be a database you could
be other enterprise services as well to
kabhi web servers involved let's let's
keep it simple the performance as
perceived by the user has something to
do with weight user has initiated
something has performed an action as
push the button has entered the field
value and the system goes away and the
user has to wait and the time that a
user has to wait is at least associated
with performance maybe that's not
exactly performance maybe you have to
divide or multiply or whatever but
definitely in association there and what
determines the wait time of the user or
it deter it's determined by the
processing time on each tier so for the
the web browser tier the user has to
wait for as long as the web browser is
doing things and as long as the web
browser itself is waiting for the lower
level tears to do things or to wait
themselves and the time that the web
browser has to wait for the low level
tier is divided where is split up in the
time the application server is doing
stuff any application server is waiting
for the database and of course as a
network traitors here in between as well
so that's the entire picture even we
though we haven't exactly define what
performance is at least we know what the
elements are that make up the
performance so performance can be
screwed at any level and can be
optimized at any level but of course if
the performance goes down by a thousand
percent at the database level tuning for
performance at the
patience of a level where we can maybe
achieve ten percent improvement in
something that's not all that big to
begin with doesn't make sense so it's
important to realize how is the
performance composed how is the way time
composed and where does it make sense to
try to improve it so we could be talking
about advanced tuning concepts and this
place is definitely not exhaustive and
most of it isn't even that advanced to
begin with you stringbuffer rather than
string that's something we all learn in
one of the first java class we are told
it's not like a huge performance gains
can be had there maybe ten to one
hundred percent 100 sent is good but
it's only in the final stages of
refinement at the really matters we're
looking for performance improvements of
orders of magnitude send out ten to one
hundred percent but 10 to 100 times
improvement and like I said that
requires this step back a little and too
carefully thing and I come up with this
term the is why ITF method and I did at
about a year ago and I presented this
presentation a couple of times but I
didn't prepare for well quite some time
until I last Sunday looked at the
presentation again and I couldn't
remember what the abbreviation is for or
the economists for and took me well
maybe now and a half I've been scanning
through my email somewhere the string
must be defined and it's a bit
embarrassing it stands for it's staring
you right in the face but it didn't or I
did but I didn't recognize it so it's
the staring you right in the face
performance improvement method and it's
all about well the fastest way to
perform a task what's the fastest way to
perform a task well actually that's to
not do it at all
well you may love it are quite some
tasks that are performed in our
application architectures that didn't
require doing at all it may not be easy
to find them but when you start thinking
about a maybe we will be able to find
them it's a very simple example and
again this is fine-tuning at a fairly
low level this is not good code so it
should have been something like this if
expense of evaluation equals true
evaluates the true and some flag in this
case in the red case we'll always do the
evaluation if the some flag which is
just a boolean who is false then we
wouldn't have needed to perform the
expense of evaluation but we have to
switch the operands around and we have
to change the operator as well like I
said this is still at the fine tuning
level this is not what we are really
looking for this is another example
you're probably familiar with it in this
case we always tell our logging
procedure to write out a debugging line
and the logging method will say well I
we are currently not at debug level so
we won't ride it out after all but by
then we have already done the result of
expensive processing method and we have
taken a performance hit even though we
didn't have to the better approach here
would have been to first check if do a
debug level is enabled and only then do
the expensive processing but still
fairly low level now we are at my modest
level it's about shopping what's a good
algorithm to describe how to shop for
some article but we leave our home we
drive the car to the shop we walk
through the aisles we get the item pay
at the cash drive back home and we are
happy anyone who doesn't agree to this
is an example of shopping algorithm we
don't have time for discussion so thank
you for going along
if you put it in code it could be
something like this it's not real code
as close to real code maybe it's well I
wouldn't it wouldn't compile just like
this but this is the way it could look
in code okay you're still with me yet
this week's groceries that's a shopping
list to go through we have our algorithm
to buy an item at a store now we have to
buy multiple items so there's the code
we iterate for the list of items that we
have to buy and for each of the items we
invoke the algorithm to buy an item at a
store that's the way we usually cupped
we haven't we have a method it performs
the task we need the task before
multiple times so we will invoke the
method multiple times the effect of this
of course is that we keep driving back
and forth to the shop for each
individual item this is where you end up
you may think well it's a nice story I
didn't even if out of myself by the way
it's a nice story but it doesn't happen
in real life later on in the
presentation I will show an example that
I encountered two weeks ago at a
customer and I thank them in the bottom
of my heart to present me such a perfect
example for this presentation then I
resolve the problem for them they did
exactly this and give you a small peek
ahead if you're using object relational
mapping frameworks for presenting data
in normal web pages and then you use
these same entities for reporting you
quickly end up doing exactly something
like this but we will return to it so
best of ours do not do it at all but if
you have to do it at least do it not
more often than required that's with the
driving back forth to the shop where is
more involved for example this is in the
Netherlands at least i'm not sure you
have something similar and now you're
all electronic we don't use it at all
anymore but this is an inventory of all
the addresses and telephone numbers that
we regularly use instead of going
telephone directory or yellow page every
time the numbers we frequently use we
write down is something like this you
could say it's a cache of telephone
numbers the ones that we frequently use
we don't have to search through the
thick book all the time we can pick it
easily in this handy mechanism that
breaks down after the children have
touched it something similar when you're
cooking you won't drive to the shop for
every individual ingredient with the
same examples we have before slightly
different context instead you will have
something like your your your kitchen
store where there are multiple items
that you have bought before and that you
can well top really reuse it's not the
same item you're using but it's the
family sized box that she bought that
you can now take something out of so you
don't have to go to the store again so
the store or your your your personal
cupboard is like your cache of the
things that otherwise you would have had
to fetch at the shop it's like the show
us the database and you have your middle
tier cash or the shop itself of course
wouldn't go to their wholesale suppliers
for every item that's being bought by a
customer it's it's the same mechanism
that only at a slightly different level
don't do anything that you don't have to
do don't do it more frequently than you
have to win with items that you buy at a
shop their physical items you can't just
reuse them because they perished at the
moment you will use them or at least the
things that you eat with data it's much
easier to reuse data doesn't really
perish it may be no longer fresh but it
won't perish so in general you could say
something like if the thing that you
need the data that you need has been
produced before reuse it before you
reproduce it provided that it's still
fresh that's always the balance of
course that you have to strike if it has
been shipped before from one tier to the
next we use instead of we ship it is no
longer there if it's no longer fresh
then of course you do need to reship
otherwise we use and always provide it
it's still fresh it's very obvious
and there are several caching mechanisms
because that's really what i'm talking
about caching mechanism that will really
help improve performance not to
reproduce but to reuse if you have the
resources to store and if you have the
algorithm to find out things are still
fresh but many things hardly ever go
stale if you have these things available
then caching and preferably caching at
the highest level is a perfect way of
improving performance that's really one
of the main reasons the no sequel
movement is making such huge gains and
you can call it a sequel and it's all
grand an architectural pattern but using
a middle to your cash is not all that
spectacular or at least there are many
implementations of cassation really
readily available to us of course the
browser also has a cache JavaScript
memory JavaScript variables that will
live between requests even better with
the lady generation of browsers html5
html5 to more structured persistence
that you have at your disposal in in
browser even in a database you have a
case you can say what a database itself
is a cache but there's quite a
distinction between having to
recalculate a result from the data
that's actually living in the data files
and perform the query over and over
again versus having something in for
example the Oracle database is called a
materialized view but the result of a
query some aggregation is stored for you
to Rio to reuse until it has grown stale
and then it has to be required if you
use it many times more than it is
changed then a cache is definitely
something to consider and again the
higher level caches are much more useful
than it comes to performance and the
lower level patients it's a route it's
an old road it's a sand road it's dusty
it's not a very fast road you want to
improve performance let's put some
tarmac on it that isn't going to give
you all that much performance it will
clog up all the same to really boost
performance with this road we have to go
parallel putting tarmac may improve the
performance
the road by fifty percent maybe one
hundred percent adding five lanes will
improve the performance by five hundred
percent nah I'm all the much in favor of
adding lanes but we should reduce the
number of cars butts different
discussion altogether it's going to go
to different example we have a very old
till and there's the more electronic
format but if our supermarket really
wants approach has large numbers of
customers you have to go parallel it
works in real life and the same applies
to our application systems so if you
have to do it at all that's too bad
don't do it more often than required and
if you're going to do it don't do it on
your own if this opportunity to parallel
eyes is that word yeah good sorry yeah
that's great yeah you know Moore's law
the capacity the processing power
improves by factor of two every so many
years not sure what it is we have
reached the point where the physical
limitations of our CPUs are reached
there's only so small you can go the
atom has a certain size stop somewhere
but we can still improve performance by
adding course so now the speed of cpu
speed of our processing units are
improved by adding course and doing
things in parallel those scores are
processing in parallel that's something
that eventually we probably will have to
deal with although job is pretty good at
dealing with it already there's not a
level at which we're going to discuss it
I won't go through every single bullet
on the slider slides are available
afterwards you can look at various
options for paralyzing things again it's
something that you can do it every tier
not as well on every tier as on the next
year's are not very good in the browser
tier but pretty good of course in the
application server and also most
databases will perform a substantial
degree of doing things in parallel when
you're going to do things in parallel
you do have to bear in mind a number of
things in this case we have this pretty
little pretty lady operating
coffee machine and she's pretty popular
given the long line that's there now
maybe you could hire for more pretty
ladies and a pretty guy may be as well
to shorten the line but it wouldn't help
us in fact the line would get longer
these five people would be in each
other's way there's still only one
coffee machine that's the real
bottleneck here so we should probably
add both people to serve and machines to
brew the coffee at some point like I
said I'm also a bit from the other side
from the Oracle side database site in
the database we could keep on improving
the facility ability to do parallel
processing use the parallel capabilities
of the CPU on people improving the
degree of parallelism in the database
and we found out performance actually
got worse problem walls performance of
the database wasn't constrained by the
CPU it was constrained with IO
operations and if you start paralyzing
the CPU even more processing threats
will try to get access to the date on
the disk so it's it's it's like the
coffee machine they're all trying to use
the same coffee machine the same I all
channels and eventually it will get
worse you don't get improvement so you
have two parallel eyes in a smart way a
place where they didn't paralyze in a
smart way or at least how is it a Hilton
last Friday we were in a fairly long
line I think about 50 or 60 people and
there's only one lady doing the check in
they had prepared for parallelism but
only by a single resource type and then
require to resource types are plenty of
time to take a photograph like I said
you see it everywhere around but the
performance is something that you will
experience in a web application how fast
do I get the response when I do a
certain form a certain action in my web
page we also have it at the level of the
business process in this case we have a
business process it's something about a
loan request that starts with doing an
identity check with the Federal service
it's sort of a Dutch context not sure it
applies around here it's very simple
example really then we do a bit of fraud
analysis
we evaluate the request once we have
established the identity and Donna for
analysis then we either reject the
request there were transfer the money
the business process can take up to six
days and three minutes not sure where
the three minutes came from let's meet
girls the first step could take up to
one day the second step can take up to
two days and a third step could take up
to three days how can we improve
performance here well I'm not going to
go into the evaluation of the request if
that's process that that's programmed
badly or that's performed wrongly that's
not what we're going to get we're still
looking at it from very far away it's
this helicopter view and that's first
like to take a look at a different
example our for your information about
ninety-eight percent of the identity
checks checks out okay at about ninety
nine point ninety-nine percent of the
for analysis cases indicates that there
is no fraud in our example that dinner
is taking mighty log we've got four
people sitting around the table they
reserved at the end are all satisfied
but it takes up to three hours and her
again three minutes let's big long why
is it taking so long let's take a look
at how the process of the dinner is
implemented we've got John we've got
married we've got Daisy and with god
Marty and this is how you could describe
the process they eat soup they eat the
main course and they eat dessert at
least two of them a dessert why would it
take so long wells in sequential process
first one person eats soup and only when
he's done the second person starts
eating soup to make diculous isn't it
well we could redesign or not it's not
necessarily redesigning revision to
process like this it's exactly the same
process it's still completely sequential
that the only rearranging a few lines
there we go now all of a sudden it's a
parallel process they ate soup at the
same time they eat their main course at
the same time and eat dessert at the
same time and we've gone from three
hours and three minutes to one hour and
three minutes now that's more like your
American dining speed and
check please could even get a little bit
better if not more refined and instead
of a set of waiting for all of us to
finish our soups or waiting for all of
the people to finish the main you could
also just eat your soup then eat your
main and be done with it and then we get
down to 53 minutes back to the loan
requests turns out that on closer
inspection the different steps in this
business process are not related we're
not using the result of the identity
check for the frozen alisis we are not
using the outcome of both the identity
check and the flawed analysis to
evaluate the request of course if either
the identity check fails or the photo
Ellis's indicates that it's fraud we
don't have to evaluate a request but
since it happens only in very few cases
we might as well assume that it's a
valid request and perform the evaluation
so if you know during this business
process in a parallel one what we get is
well it's it's in parallel next one day
next two days max three days and the
three minutes of course and now we're
down to three days rather than six just
by taking a closer look as I was
actually at a customer three weeks ago
different one than the one I was
thinking from the bottom of my heart
this one's nice too and at the moment
all their documents are paper documents
are hard copy documents it's the Dutch
port system and whenever a new case is
brought on especially with use a new
case is initiated some documents are
created or are received and they travel
from desk to desk now we are thinking
about digitalizing old documents and we
have tremendous opportunity then to
redesign the business process because
there's only a single hard copy of every
document the process now needs to be
sequential the documents go from desk to
desk and there's only one document at
any given time but once the documents
are digital
moment multiple people can be working
with the documents at the same time so I
propose this the organization said we
can really speed up the process if we do
start doing things in parallel I said
well you know for now we have this
folder that holds the hard copies of the
documents and it's full that goes from
desk to desk we are now taking out the
hard copies of the documents they're
going to go into a Content repository
with this folder will still go from this
to desk because that's the way we
organize our process and on the folder
on the on the outside of the folder it
says it now has to go to this version to
perform this task so for now we're not
going to change the process only change
the way the documents are handled
sometimes you may feel as though you
can't do things in parallel it's a Dutch
custom to eat pancakes especially at
children's parties so with pancakes you
sort of have three stages you have to
prepare the better you have to bake the
pancakes and it will be eaten can we do
things in parallel well better bake eat
you have to first make them before you
can eat in yet to first make the better
before you can bake them we can do
things in parallel you could ask for a
second and they could at least bacon
parallel but actually you can make a
much larger improvement if you think
about and something i would call
pipelining it's almost like the conveyor
belt once the first pancake has been
eaten one of the children can start
eating sorry it has been baked one of
the children can start eating so instead
of making the entire stack of pancakes
and only then starting to eat it's much
better or at least if you want to get a
chill out of your house as quickly as
possible it's much better to bake a
pancake give it to a child make the next
one give it to the next child and do it
like that so instead of waiting for the
entire activity to complete before
starting the next activity pipelining is
a concept that would suggest that you
hand part of the result of one activity
to the next activity while continuing
producing
other results fairly obvious when it
comes to pancakes actually it's not all
that hard to implement your in your
applications as well so for example in
the Oracle database which is my home
ground as a concept called pipeline
table function that really allows you to
perform a query against the table the
results of this query are still being
fetched from the database but the first
rows are all already handed over to some
peel sequel some stored procedure that
can start processing them it could even
end them to a next process or two
declines requesting the data she will
have this line of at far end the process
is still fetching rose and the second
station the first rows are being
processed at the next station tapping
processed are being further process etc
so you have this horizontal parallelism
I'm not sure if that's a way to to to
describe it but you can probably imagine
that if you don't wait for activity to
completely completely completely
complete to no.4 results to be
completely to be complete when instead
start processing one of the results if
the result themselves are independent it
doesn't work always but frequently it
may help you out and it can be done with
energy it could also be done across
tears so for example in your application
server Tia you could start processing
data and once you have processed the
first piece of data that might make
sense to the client you could use a web
socket for example to send the
information or to push the information
out to the blind by talking about
performance it really all boils down to
this guy and it may look a little bit
differently on different operating
systems but in the end it's whenever the
hourglass appears the user can't work
that's where the experience of bad
performance takes him why do actually
show the hourglass on many occasions
they may not really have to for example
it's printing probably recognized beast
and if the user in an application
requests
document to be printed we probably
should not do this as a synchronous job
tell the printer to start printing wait
for the printer to let know let us know
that the document is complete and then
tell the user well the document has been
printed you may continue that would be
results in a user complaining about bad
bad performance there's no reason for
the use of reapplication to wait for the
printer to finish it's more like the job
has been submitted it's a
fire-and-forget action and the user can
be informed that the job has been
started and the user will typically
accept that he or she knows that at some
point he or she has to go to the printer
to get his or her document this PC thing
is tiring so instead of doing
synchronously and making the use of the
application and the user wait for for it
you frequently can improve the perceived
performance tremendously you haven't
actually sped up anything but the
perception of it is much better so as
part of the it's staring you right in
the face approach the baby situation
where you don't have to do things
immediately synchronously having the
user wait for an operation to not not
only start but also complete and again
that's something that you will see in
the real world as well looking at our
application architecture and different
mechanisms that we have at our disposal
to implement this in many cases we can
just submit information and we don't
have to wait for the result we've got a
synchronous web services we got JMS cues
we have the option to even though data
in the end should be persisted to the
database there should be a database
transaction to really persist the data
one of the ideas in no sequel is that we
persisted to a great that's distributed
across multiple tiers that's thereby
and use a right behind a single ously
detached from the application to
actually commit the data in the database
so we can decouple the operation to
receive the data from the application
ensure that it's safe and then persist
later on asynchronously the database
itself also has a mechanism like that
well actually this is a different one at
the database level you can define
constraints you're probably familiar
with them you've got primary caicos a
unique eco strange foreign key
constraints and the many databases are
constraints like check constraints as
well and typically these constraints are
enforced at a statement level and as
soon as a row has been found to violate
the constraint the statement will fail
that's the way it usually is set up if
you're doing in a large batch operation
and in a moment I'm going to argue
against batch operation if you're going
to do batch operations anyway you might
be updating many many roads could be
100,000 could be a million now suppose
that is taking place during the night in
the morning he comes into the office and
turns out that only nine hundred
thousand ninety nine thousand and not
going to complete this eight hundred and
twenty fifth row the validation failed
and the entire transaction was rolled
back that would be a pity especially
since you probably would have wanted
this transaction to complete for all the
rows except the bottom where it failed
well in the Oracle database and don't
know about other database but he may
have a similar mechanism there's the
option that's called the DML error log
where you can indicate if I perform a
d-mail operation against this table and
no more than X number of rows violate
the constraint then go ahead and
complete the statement and all the roles
that violate the constraint should be
written to a separate table so I can
inspect them and decide what to do with
them just the mechanism it might be
handy to know though of course it's more
up to the database administrator but
don't use matches
maybe that's too broad a statement many
of the batches in our systems are there
because they are there if you ask the
people responsible for system why do you
why are you doing this in a batch
they've already say well it was always
done in a batch or they say something
like we don't have enough resources to
do it online and it used to be true
twenty years ago or maybe even 10 years
ago with the processing power that we
can throw at our application and the
activities in history form has increased
so tremendously that many things that
really had to be done in batch in the
past may very well be possible to do
online maybe not synchronously but at
least asynchronously near real-time
right now so you should revisit matches
especially when those matches can put a
peddler a big load on a system and be
used to have these night windows but we
are increasingly working at 24-7
operation so you don't really have this
night window that's reason why I would
like to get I get rid of the batch but
it's it's it's frequently no longer
require necessary to have bad for
example to do data replication data
exchanged one database another database
should be updated as a result now we bat
 up and it during the night we will
update the other database well that
means that for 12 hours or on average 12
hours we have data that's out of date
well that's not already there I was at a
customer two years ago and is it
actually true when the marketing people
needed to have the latest customer
information and it were in a different
database and a database it actually
contained the customer information they
had to submit a request and wait for
four hours before the batch job was
being run during the day by the way to
transfer all the information that was
required to the other database
completely stupid but I left over from a
time long ago so revisit your batches
iiiiii can't say that any batch is bad
but many batches are not really
necessary any longer
we people we know this one don't call us
we'll call you I've their children and
sometimes they're waiting for something
my my youngest recently has birthday
received some coupon for a webshop and
they decided to buy a keyboard and
twenty dollar keyboard not really high
quality in fact when he received that he
broke it right away but it's different
story and he had ordered this keyboard
over the web largely by himself and then
every day after ordering it he asked is
already here is it already here daddy is
has the keyboard arrived he asks it
every day and then after six or seven
days he stopped asking then it arrived I
forgot all about it all about it and
only three days later at all you people
it has arrived that's not really true
it's a way to make to explain this but
the first part is true he kept on asking
for it but he really kept on asking for
it in an application an end user may be
interested to learn about the latest
data and the most web application to
learn about the latest data you press f5
and you'll press 5 again when you are
expecting you information you'll keep on
pressing f5 you're constantly calling to
ask has my keyboard right get my latest
information some systems can experience
quite a load because of this if it's all
handled well if you don't detect the
question has been asked already sounds
like some uh nevermind different
different association if you keep on
asking the question and eventually you
may stop asking the question or
decreasing the frequency with which you
ask the question you may actually not
get the information at the moment it
becomes available because you stopped
asking for it or at least you didn't ask
it right after it it arrived on the
server so let's reverse it let's express
interest then he you please tell me the
moment my keyboard arise okay son that's
okay I will he doesn't ask keyboard
arrives I tell him he didn't bother me
he received the information the moment
it became available everybody's happy
the same applies to our system if we can
use push to inform any system or any
user that has an interest in certain
data there might be prevent the load we
would otherwise be experiencing from the
user constantly asking for the
information and use it would get the
information the moment it becomes
available one of the main themes during
this you have one conference of course
is the ability to use web sockets html5
in combination with WebSockets that's
one of the tears or one of the bridges
between T is where you could do push
there's actually more so in our list of
staring it's telling you right in the
face don't do things necessarily per
request or at least not per constant
requests express your interest once and
then push the information once it
becomes available you will get the most
up-to-date information you will decrease
the load on the backend system that's
really what you're gaining here I have
to move on it seems like i'll be out of
time few more minutes 30 minutes
morrison challenge and don't bite off
more than you can chew or then you have
to chew I've seen many web applications
that have several areas tabs maybe a
tree with many notes that may have been
expounded but frequently are still
collapsed all these pieces on the web
page have information associated with it
with them but as long as these pieces
are not expounded are not exposed are
not navigated to we don't actually need
the information it's not yet shown so
why should we take the burden of
collecting all the information before
making page available to our end user if
the end user doesn't read it doesn't
need it right away we can do a post
float fetch of the data either
immediately after the load of the
initial load of the page is complete or
when the user expands a certain item
depends on well it depends really on how
much data is needed and if it's needed
most of the times they're only
some of the times but don't always just
fetch all the data that may be required
it will have the user wait for much
longer than really is necessary so don't
do it in two big steps or two small
steps two big steps would be to get at
all at once even though it may not be
immediately required and there are some
examples on the slide two small steps
that's the example that I think this
customer for from the bottom of my heart
its pension fund and they have this
simple data model they do pensions for
multiple employers and all these
employers have participants in some
pension scheme and each participant will
have multiple elements in this pension
scheme depending on the jobs they've had
and the salaries that were associated
with these jobs so from one day to
another data would have been a certain
job with a certain celery etc that's all
part of the information stored and this
information is presented on a web page a
single employer multiple participants
and when we select a certain participant
will see the jobs and benefit details
for a certain participant fair enough
they've done this using an
object-relational mapping framework and
what you get is a single query to fetch
the employer a single query to fetch the
participants that work for this employer
or the heavy weight for this employer
and whenever we select a participant
another query to fetch all the benefits
and you see an indication of the numbers
of records involved one record one
several hundreds of records and tens of
Records now they use the same entities
the same mapping situation set up for
doing a report so you get many employers
with all their participants of each
participant all the jobs and benefits
what you see is the same queries and the
poem is not in the queries the problem
is not necessarily in the numbers of
records we now have several hundreds of
employers tens of thousands of
participants and hundreds of thousands
of jobs and benefits and fries but it's
fine that's not huge numbers for your
typical database the problem is with the
number of queries it's like the shopping
algorithm we are growing back a forth to
22
to the database for each participant and
for each employer but that's not really
the problem it's the participant so in
or to fetch about 100,000 rows will
perform 10,000 queries the peeri is not
a problem but performing at 10,000 times
to prefer to put produce a report is a
problem so what can you do I'll try to
build it up try to tell the database
give me all these employers give me all
the participants for all these employers
give me the job some benefits for all
these participants for all these
employees that's three queries and then
try to fit it all in into your car and
perhaps your car is big enough and you
have to do several round trips to the
store but even then the total number of
queries will be far smaller than
currently is the case don't do it into
small steps why it's like darling and
operated to request it but on the phone
number and request it digit by digit
it's me again the third digit of the
telephone number of this person etc
don't do things the hard way obvious one
the only things in a convoluted way and
you have to look very closely there's
going to be a box on this monster truck
and this box is delivered and the box
turns out to contain a memory stick this
is not the way to do it and sometimes we
do it like this only it doesn't look
this obvious so don't do it in a
convoluted way stay pragmatic if you
don't think out of the box if you don't
step back to reassess the way you've
been doing things you always follow the
same approach that you may have fought
in the past or that you may have learned
from standards that are not necessarily
flexible then you may be doing things in
a very convoluted way and there is a
number of examples on the slide not a
good idea that the single printer we
have in our office and someone is
printing birthday invitations for his
dog and we need his resource for sending
out invoices very important with our
bottleneck resource is
being helped by some ship optimal
presume non-critical process so don't do
things in a suboptimal place which
really means don't use an important
resource for an important process there
are ways of we're dealing with your
resources handling your resources I'm
getting out of time years I have to
treasure on one example would be in the
past we used to render HTML on the
application server we don't do that as
frequently as we used to we now do much
more dynamic HTML rendering in the
browser and only doing Jason based data
exchange with the server because the
only thing really that changes is the
data this is a good example of doing
things in the right place using the
processing power of the browser and
don't wasting both the processing power
of the application server and the
network for sending HTML which is not
really a very compact format at all
don't perform a task in resource that's
not really up to an enterprise level job
that's what I'm saying here and here are
some examples and one of the discussions
I'm I'm frequently having again being of
the other side as well is what you do in
a database what you do in the middle
tier i have seen organizations that
implemented unique key constraints in
the middle tier i don't consider that a
good practice database has been
optimized for it far better than you
ever could and you are bringing data
from the database to the middle tier
that you don't really need there and
maybe your database vendor-independent
but that's really not a big deal anymore
so that's the entire list don't do it if
you have to don't do it in these other
circumstances when you architect for
performance you take this list into
consideration there's a number of
features that you may want to at least
think about applying to your application
to your architecture it's far too hard
to read in the back so if you're
interested please take a look at the
slides they are available for download
from SlideShare that will be available
to download from the Java one website it
gives you an indication of various
mechanisms
you may want to to use in order to
address performance along one of the
dimensions I mentioned in this
presentation these you know view of
which mechanisms go with which parts of
the it's staring you in the face
approach to wrap it up you need to
define performance unity with the
defined performance requirements you
typically should do it based on business
requirements performance and
availability a part of the same spectrum
when you availability is zero your
performance is here buddy other way
around he performs is zero then you are
no longer available loop perform look at
performance across the stack and look at
where performance is really spoiled
where it's where it's going down the
toilet if you like don't start tuning in
a place that only makes up one percent
of the entire processing time and the
number of it's staring you in the face
guidelines don't do it if you don't have
to don't do it on your own etc so I hope
this has been of some value to you and
at least thank you for sticking around
till now so if you're being late</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>