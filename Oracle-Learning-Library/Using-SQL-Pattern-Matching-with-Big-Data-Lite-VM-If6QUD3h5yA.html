<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Using SQL Pattern Matching with Big Data Lite VM | Coder Coacher - Coaching Coders</title><meta content="Using SQL Pattern Matching with Big Data Lite VM - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Using SQL Pattern Matching with Big Data Lite VM</b></h2><h5 class="post__date">2014-05-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/If6QUD3h5yA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">feature the much recognized clause with
data from our big data light movie
application my name is Keith Laker and
I'm a senior principal product manager
for analytical sequel and part of the
data warehouse product management team
before we get into the full part the
demo let's start by looking at the big
data like virtual machine just in case
this is completely new to you if you've
not yet looked at the big data like the
end then there are links on the Big Data
webpage that will allow you to download
this virtual machine within the virtual
machine is that a sample moving the
application that lets customers browse
our movie catalog select films to watch
and then rate those films all this
activity from our application is
captured in a log file and we're going
to analyze the data captured in that
file so as you can see on our ATM page
there's a lot of material here that will
guide you through the key features for
the Big Data environment and the movie
application if you want to find this
page again it's either linked on our Big
Data site or you can just search for big
data like VM and the first link that
Google brings back will take you to this
page now as I said there is information
here on our oracle movie plex
application links to our hands-on laps
and our websites and white papers etc if
you want more information about database
12c pattern matching feature again you
can search for our analytical sequel
page on OTN and the first link that
comes back is here will take you to our
OTN home page on this page you will find
general information about patent
matching as you can see here along with
all the other sequel analytical features
and this links to the
as white papers Apple iBooks if you have
an iPad or Apple Mavericks operating
system along with online tutorials as we
said we've already started our virtual
machine
we've pre-installed an Oracle database
called our CL into this environment that
is up and running I have a listener and
that is already started and has
connections to our CL so my environment
is ready for me to begin this
demonstration you'll notice that we've
pre-installed sequel developer for you
and I already have that running in my
environment here for the purposes of
this demonstration we're going to use
our pattern matching demo user which is
called PM user but before we get into
that let's have a look at the lock file
that we're going to use during this demo
that contains all of our information so
all the data we need is stored in our
movie application log file that is in
the directory home Oracle app log the
file name is movie app and the bar
30-month log and this contains all of
the click events that are generated by
our movie app if we view the file at the
command line here you can see that we
have a very standard JSON like file
structure we have a customer ID the
movie ID assuming that the customer
actually viewed a specific movie and the
associated genre for that movie there's
the timestamp for each click event and
there's a flag to indicate if the film
that was being viewed was recommended or
not the last field tells us about the
of activity for this event now the movie
demo application schemer contains a
table with the descriptions of each of
these activities for example activity 8
is a logon event activity 9 is a logout
event activity 7 is a search event and
activity 5 is a browse event if we'd go
back into sequel plus we can see this
table here and here's the full list of
all of the activities that are captured
within our movie log file as a lock file
into a database and to do that I'm going
to create a new directory object in fact
let me tidy this up a bit so we can see
some more information I've actually
created a directory which is here it's
called session file underscore dir and
it points to my movie log file if you
want the exact syntax for this command
this is how we did it so they create
directory points to my log file and
points to the directory for my log path
and then I've granted read and write on
that directory to my user p.m. user so
that objects now ready for me to use if
we have a look at our log file again
just step back over here we can see that
I can use the comma to indicate the end
of each field so I'm going to try and
load is the customer ID the movie ID is
your ID the session date or click event
date
the recommended ID activity ID and a
rating ID
now I'm going to use the directory to
create an external table statement and
to make things easy
I'm not going to enforce any deep data
cleansing processing as part of my
external table so what I'm going to do
is define an external table so I'm going
to create something called raw session
data it's going to have my customer ID
movie ID genre idea cetera
and as this is going to be an external
table I going to use that directory
object to build out the information so I
have my session file directory
information about the file the fact the
file the fields within my file are
terminated by a comma the location of
that file is my session file there's my
log file name or reject limit one and
that command will then create my
external table for me I haven't got that
set up the obvious thing to do next is
to see exactly what happens if we try
and view that so let's try accessing the
external table and see what comes back
so you can see how external tables
actually worked the syntax is correct
and looking at the information here it's
pretty much consistent with what we have
in our log file except obviously now
we've chopped it up although we've still
got some data cleansing that we
to do here to remove things like double
quotes curly brackets colons etc but we
have a basic external table in place we
can access our movie log file so we're
at stage one so no table will return us
some data next step is to do some data
cleansing on that and to do that we're
going to use the substring and some case
statements
so let's paste in this new block of code
as you can see we're going to substring
as we did before and we're going to look
at the activity ID and break that out as
required and strip out one of the curly
brackets so let's try executing there
and there it is there's my cleansed data
set so now we have the basis of a
cleansing exercise now as we run this
we're obviously pulling data from the
external table every single time so
maybe the next step is to load my
clickstream data set into a table of
course you could skip this step and just
continue to use the external table if
you have the file on a dbfs main point
for example and you'll probably find
that performance is really good anyway
which means you can leave the data where
it is in this case I'm actually going to
create a table and populate it with my
clickstream data now at the same time
I'm going to scrub the data to remove
the irrelevant parts of the field I'm
actually going to do some extra
processing I'm going to transform or
more precisely pivot the activity column
so that I can have a separate column for
each type of activity but with a boolean
yes or no to indicate whether that
activity has occurred or not
now this is really useful once you move
on to building data mining models
because attributes such as type of
activity typically need to be broken out
into separate columns to provide input
into the data mining models so
by doing this we're going to save our
data scientists from having to do some
extra work so we're going to use the
same approach again except this time
we're actually going to create a table
so let's look at the code for that and
let's scroll up a bit so we're going to
do create table we're going to call me a
session data as selects and then we're
going to use our substring so let's just
take this out for the moment too let's
check that this is going to work so we
have our sub strings that we were using
before we have our case statement for
taking our activity ID
and then we break or pivot out our
activity ID into separate columns and if
the activity ID is triggered then we'll
get yes if it's not then we'll keep it
with no so this is going to give us a
much wider data set so let's try running
this data set now and here you go so
customer ID movie ID session date etc
all the way across here we have pivoted
out our activity IDs and you can see
straight away a lot of yeses for logins
which is very good picked up a logout
event there we've picked up a list or
search event list here searching here
customer browsing and so on so this is a
nice additional transformation that we
can do as part of our data cleansing
process and we can then hand over to our
users now we did our said we're going to
do a create table and I've actually done
that in advance so let's quickly look
and see what's in our table make sure
that it's got exactly the same data than
we were expecting so here's my session
data table and this is now reading
directly from a table so rather than
having to go
to the external follower I'm now
actually reading directly from my Oracle
table so as you can see our data set
looks good and we're ready to apply our
specialization logic but firstly we need
to establish the maximum time interval
between clicks whereby we'll consider
that a new session has started now for
the purposes of this example I'm going
to assume read about 150 seconds or 2
minutes is the maximum interval that I'm
going to allow between click events
beyond that time limit I'm just going to
assume that a new session has started
even if the users not logged out and we
know that that logout activity is
captured by event number 9 in my
activity column data set we've loaded it
in so now let's actually work on our
match recognize clause and here's the
statement that I'm going to use so I'm
selecting data from my table that we've
just built which is session data and
here's the start of my match recognize
Clause and in this code I'm dividing the
data up by using the partition by Clause
and we're working on the customer ID
then within there we're going to sort by
session date now it's part of the course
I'm going to compute some measures and
the first one I'm going to compute is
the session ID now this will be an
incremental number within each partition
which is in this case the customer ID
and we'll see that in a minute
I'm also computing the number of events
that are occurring within each session
I'm computing the start date and the
start time the end date and end time
each session and I'm also computing the
duration of the session here by using
the end time or the last time within my
pattern and the first time event within
my parent and then I'm recording there
in minutes
now how we define a session so we can
create or compute their session ID from
how much number is determined by my pan
where I'm looking for any number of
events s where the event s is going to
be the current session date minus the
previous session date in minutes and I
want that to be less than two minutes
so if between click events as we're
going through our result set if the
session date all the time of the session
here is less than two minutes than the
previous session then I'm going to
include that as part of the same single
session so let's try executing this
statement now and see what comes back so
that's now off running which is always a
good sign because it means my syntax
might much recognize clause is correct
and here we can see some of the output
so we have our first user user 50 as 8
sessions recorded in our log file user
83 has quite a few sessions locked by
the looks of it but most importantly
they've got more than one event recorded
in here bear in mind that this is just
our manufactured data for our log file
rather than actual live data from users
clicking on our movie app so some of the
results might look a little strange but
the important thing is the calculations
are
and you can understand how to use the
match recognized clause and the value of
the information coming out so we have
our start date and start time our end
date and time and duration and we've got
that one minute 0.75 and so on so you
can see there's quite a lot of
information that we can get out of here
for each of our users so user 83 years
had 50 sessions and then because we're
partitioning by the customer ID as soon
as we get to the next user 104 you see
that that match number here where we
were computing the session ID resets to
1 again so that's a starting point for
building our Maps recognizer
functionality here that I pivoted the
entries in the activity column so now
let's calculate some counts for each of
those activities within each session so
here's our complete statement and in
this case I'm actually rather than using
the Select star which we've used in the
past so go back to our first one we just
said select star now I'm just showing
you that we can actually pull out
individual columns by referencing them
with the MRR prefix which as you can see
is at the end of my match recognized
statement I'm actually going to use that
just to show you a different way of
doing this so again still taking data
from our log file table when we load it
from the external table and we have now
got our counts so using the same
information as before I'll find the
lowest activity ID so again going back
to my table here that's probably going
to be on
one which is a right and the max and the
maximum we have is eleven which is a
purchase obviously in this case we'll
get the max and the min for each session
and then we're going to count for rates
completes Paul starts brows etc for
activity columns how many of the
activities occur and again we're looking
for or defining a session as where the
difference between the session dates is
less than or equal to two minutes so
let's run that and see what comes back
good sign that query is running again so
obviously one-way measures and syntax is
correct and again we have our customer
50/50 we have eight sessions start date
start time end date in time duration
activity ID last activity ID and then
how many activities they completed where
we got one log in another log in down
here we have an activity for browse
start a movie complete a movie and so on
so we've starting to build up very
quickly a large amount of measures
related to our session ization
information it's going to be a value to
people like our data scientists and as
you can see by simply adding in things
like counts on our pivoted columns we're
getting a lot of information here very
quickly using some very very simple
syntax so now let's make the
identification of each specific session
and little more sophisticated by
considering what the activity ID is so
extending the pattern to search for
instances where the start event has
occurred ie
the user started to watch a film and the
complete event has occurred ie
the users finished watching a film this
creates a conflict with our time
calculation however that we probably
need to look at so if you start watching
a film that it could be a considerable
period of time before you click again to
complete the film so if we want to start
and complete events to appear in the
same session then we'll have to extend
our time interval from its current two
minutes to something a little more
realistic say 150 minutes so let's look
at this new code so I've changed the
pattern here where I'm now going to look
for two new events which I
see f is where we have a start event
occurring C is where we have a complete
event occurring and again we're still
using the same duration calculation but
rather than two I'm now looking for 150
again we're going to use the prefix map
and red you have much recognize here and
assign that to our column names there's
a prefix we cannot list out columns that
we're going to call we're still
partitioning by customer ID and sorting
by session date and everything else is
the same what we should find is that say
the first rows that we get back we'll
probably lose user 150 and we're
probably going to lose a lot of user 83
records so we should get a completely
different results there now so let's
execute that and the queries often
running let's see if we get any results
back and that's predicted first users
dropped off we've now got user 83 got
one session started on tenth of December
at 2023 they're obviously watching a
film until 22:08 generation 104 minutes
and we had the complete flag yes start
flying yes and so on so you'll see some
of these here we have for example this
one user 693 is more than 150 minutes in
total duration so when we're looking for
our match here and forget we're
comparing against the previous session
as we're going through so where we bring
together a full session obviously
matching multiple entries the total
duration of the session could be more
than 150
minutes which is why you're seeing some
numbers here less than 150 and some more
depends on the type of activity that was
going on and the total duration of the
session now obviously we could fix that
in here if we wanted to compare the
starting session time we could use first
or min session date here against the
current session so the total duration of
the session could be less than 150
minutes if we wanted so that's a further
refinement that we could make to create
a different result set so it's very easy
she can see here to add layer upon layer
the sophistication to our match
recognized session realization
calculations is the incredible
flexibility that it provides to
prototype new ideas and the speed at
which these changes can be made for
example if we want to completely change
the focal point of our analysis from our
customers and sessions to say movies but
it's relatively easy to change the
partition key from a customer ID to
movie ID and then we can count the
number events aligned to each movie and
this gives us an overview of activity
maybe the popularity of that each movie
so let's quickly take a look at creating
that code so again we're going to use
the same principle of the session date
and comparing that and assume that the
difference between events is more than a
hundred and or less than or equal to 150
minutes and here we've changed the
partition key to movie ID from customer
ID and that's really all we have to do
there's nothing else that needs to
change
apart from up here obviously now again
we're referencing a column movie ID
rather
customer ID so that simple change we can
now just here enter on that and our
query is off and running and then we'll
get information back about or focused on
the movie idea itself and from movie ID
maybe we could go step that up or
aggregate data using other analytical
features to take into account the
hierarchy of movies around genres etc so
we can see movie 100 has been quite a
bit of activity around movie 100 lots
and lots of rows of data some days 10
events by events so we get some measure
here of how often each day a movie is
being used and therefore its popularity
how long people are watching it for are
they watching it all the way through as
in here or are they stopping
maybe after 34 minutes to go off and do
something else or maybe within 8 minutes
and doing something else or maybe here
they just come in and and rated it so we
get a lot of information about the
interaction of our users around each
movie and this is sort of the real
beauty of sequel as a data discovery
language it's rich it's sophisticated
and it's an agile language all the
attributes that you need for Big Data
projects and they allow power users and
data scientists to very quickly evolve
their analysis as we've seen here
they're Oracle's match recognized clause
for pattern matching builds on existing
sequel principles so it's relatively
simple to learn how to use it and we
have lots of training material on our
website and I've showed you earlier if
you've used other sequel analytical
features such as the windowing functions
then a lot of the match recognized
syntax will be immediately recognizable
to you
well that's the end of this
demonstration thanks for taking the time
to listen to this quick workshop on
sequel pattern matching for big data for
more information about match recognized
clause please follow the links listed on
the analytical sequel home page that we
looked at at the beginning of this
session
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>