<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Part 3: Oracle Big Data SQL | Coder Coacher - Coaching Coders</title><meta content="Part 3: Oracle Big Data SQL - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Part 3: Oracle Big Data SQL</b></h2><h5 class="post__date">2017-01-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yb2o6ShUPBU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">come on ma or global day to the house
latest in and today I'm going to
continue our big data stick roll deep
dive serious and that today I would like
to talk about chance during different
data sets in Big Data sequel but before
all let me do quick reminder what is big
data cycle will be physical it's process
who are rich rich data are on HDFS or
HBase or Oracle molecule or other no
sequel database so in other words from
the soldier and big data security
processing engine like a spark like
mapreduce like Paula and we didn't bring
something new into soldier we just
install our process on every data not on
every head movement which can storage
data so on oracle database site ah you
have to define external table either
oracle hive or oracle HDFS type and then
you specify all connection credentials
to your de placer so you specify which
had to cross for each table in hive i am
going to use and you do some kind of
mapping in oracle database when you run
the query just what you're going to do
you jump to the name node or have a mega
store and get back all metadata which
stores data location data structure so
some other our net information about
directory or sub directories which
you're going to n then database do our
cleaning and tark eggshells can actual
can filter out all unnecessary data come
out all unless your column and then move
back on the small piece of flick of the
data on the database side and then we do
final transformation for example judge
for example you could join our external
table which is on our College surface
and Oracle internal table within the
same query cool how to do this
efficiently I will talk today so but
another one are important not you're not
a no matter how big takes it works so
this is view of one of the Hadoop note
and as you can see you have data nodes
which extra stores the data we have
smart scan which is inherited from
exadata and we have another one process
which converts any type any block either
HDFS or no signal fleet HBase split into
oracle format and pass it to the smarts
came to the Oracle smart scan so you
read any type data format then using
Thursday and record to either you catch
the record and you are sched the records
you purge the columns and then you can
work these data into Oracle data tab and
pass it on into smart scan starts can do
actual can filtration so like Exadata
snap Conda and then move up to the
database on the necessary data so just
huge optimization which Orca has for the
giant is groomed future before all let
me arm let me remind or explain what is
computer and right now our next couple
slides I'm going to tell about contact
about mathematical concept what is being
filter independently of the technology
so it is data structure which could
answer on question is this very
exists in some particular area well and
answer could be definitely no or maybe
let me show you one example again it's
so far its technological independent
it's just mathematical example what is
bloom filter so and let's imagine we
have three different hash function and
they return whether in range or between
1 and 12 so and we have array of strings
oracle database filter and we need to
create bloom filter or relief data set i
apply have three hash functions on
oracle i apply 3 hash functions on
database i apply 3 hash functions on the
filter and then i'm mark letters which
has at least one matching as 22 or one
so much i'm arkham house with its field
over so and after this i have created
bloom filter for array oracle database
and filter i'm going to check tough
Oracle is in our array I got the values
145 and I kept three of three matching
which could tell me that Oracle maybe
exists in this data set because 3 has
function certain value which is
represent in our array but let's check
what are what will happen if I will
check Alex if I will check our Alex
existing existence in this array answer
also will be maybe because again I got
three of three matching of the for loop
filter but
first one came from Oracle second came
from database third one came computer so
and if we have maybe answer we have to
reject to exact check to have exact
check so and what's the profit of what
the sense of the bloom filter let's
imagine that we have work bite and we
want to check that might exist in bloom
filter and here we good answer
definitely now because element of the
array not ah is not true so and the real
power of bloom filter is definitely no
answers because they could help us to
eliminate significant amount of data let
me give you an example let's imagine you
store small dimension table in oracle
database and huge x table into Hadoop
and you want to join it so you create
dual filter into oracle database push it
down on the Hadoop site and apply it on
the hedges side so in other words you
will push down all processing on the
head website let me give you one example
are around the same query and plant
statement join fields or create tell us
that we create bloom filter our small
table small dimension table into
database and then we push it back
towards the head tube site and apply
join filter ease and these allow us to
eliminate ninety-four percent of the
data so these optimization allow us to
leave ninety-four percent of data on the
south side and bring back on the
database had only six percent of the
data
so our next optimization is using
broomfield together with storage
yesterday out our foreign mathias in the
last last webinar I was talking about
storage indexes and let me do quick
reminder what is it so it's promised
feature of our Exadata and be
statistical which works in kimmel ray on
those platforms so the many day when you
can the block and you don't have any and
it doesn't return any rules you create
some stuff some metadata over it so you
create minimum and maximum of this
column and when next square will come
you may skip part of the blocks you may
skip some of the blocks and you will can
include signal and way less blocks so
and oh um so here the you could find the
statistics how efficient these are all
search indexes is it called cell
external i abide site by start index and
the good news if you run the giant like
a show in my example you also could find
in these statistics pleasant surprise
it's torch index emphasis works together
with bloom filters so you run the giant
you apply the bloom filter and bloom
filter applied our storage indexes and
in the end you scan much less data only
one thing that it's not going to work
utter system just start up so search and
it have to be from apt but as soon as
you build it you could start using it
and here the plan of the current we
could find it again with bloom filter
and automatically usually use searching
so starting this could significantly
improve your turn are your joints if you
sort out hdfs files properly you will
have all better profit and better
performance restore chances so and now
let's talk about it was old good
Canadian football to people it's like
standard scenarios and a giant dimension
table and a stable but what if I would
like to join our two big tables likewise
carbide stables and speaker by see a
table first of all I don't think that
it's akhil case because if you have to
do some company with these data sets
that have to do is report or they'll
drop and many cases which are so it's
just wrong use case or for the database
when you need to join this data set but
make sure you could do some
optimizations even in this case try to
fit as much as you can in memory so use
bj for this increase pj aggregate target
and this will allow oracle database to
use more memory or the Giants so in
class c or to be safe we also recommend
to set up pj aggregate limit it's kind
of hard limit to prevent ought not to
prevent using monomer rather than you
have so second thing that one parallel
slave could use a 20-percent of pj
memory so and if you want to have more
if you don't have more memory and have
to run more processes so by default even
more by default it kept by two gigabyte
and the obvious solution for this run
more parallel sides so but anyway you
may still work through the temp you may
still work through the temp and at this
case what you can do you can apply one
parameter which will increase I Oh sighs
I attempt hi and you your tent huge will
be more efficient so there is Zeus three
basic steps which you could do to
optimize join up to big data sets but
again I encourage you don't do this with
or with the Oracle database and think
wisely is it really what you wanted to
accomplish because most of the real
customer records turn right to a small
table which could be covered by broom
filter with the some small some big X
table so more details you could find in
our documentation and a big data sequel
blockbuster ok any questions
and now questions are
okay I read the question from the chat
to start to begin our conversation so
and these are asked about do we need
exact license to use big data sickle if
we have oracle DB and oracle exadata or
could be doing so yes Big D testicle
it's software product and it requires
the bed licenses so that somebody else
has any questions
okay I hope that I think love kale you
know buddy hi Jessie or hey hey I can't
it's Nick I've got a real clapping and I
was just wondering hey the sort of bloom
filter functionality than in here you
mentioned simply really external table
with hive or HDFS is there anything else
that that it works with now or is it
just those two sources ah what a good
question ah actually a high foul
preferable way to define X
anti-ballistic beta codes to find Oracle
hi otherwise you have to explain all all
the metadata but while the great news
that you could define for example or
using search engine or you could define
no cyclic based Oracle nautical database
or a dream within hybrid and then you
could reuse it with the big data sickle
and it's how we query no sequel
databases you define no sequel database
be high and then you define archive in
like pork external table so the bloom
filter would still work across then yeah
ah so storage index will not work
broomfield will work okay let's check it
out in the search indexes for HDFS and I
don't like that yeah oh ho ho I would
play for high stakes for high schedule
results or gender okay okay so if you
define annex a high schedule results are
Chandler feel fine if you define mr.
Chandler we've quite getting quite
complicated
you cannot heal okay gotcha all right i
mean it sounds like the way to go and
then probably the most common use case
would be via hives at this point correct
yeah yeah i don't think that i don't
think that within will work in really
case it's different yeah I something
that they hired by default our way to
define data into H different so yeah
right marinade over yes it simply
because you'd be the inherent shared
expressivity is a meta store manager the
functionality of five queries or
anything like that yep yeah</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>