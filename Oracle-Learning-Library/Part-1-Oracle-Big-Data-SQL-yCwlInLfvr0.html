<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Part 1: Oracle Big Data SQL | Coder Coacher - Coaching Coders</title><meta content="Part 1: Oracle Big Data SQL - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Part 1: Oracle Big Data SQL</b></h2><h5 class="post__date">2017-01-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yCwlInLfvr0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so hello Iran I'm allocation enoki
or maybe you know and remember me and
part of the goal that your healthcare
your group and responsible for Big Data
technology cell so today we're going to
start our series about Big Data sequel
and it would be more computers and every
webinar every ritual meet-up will
explain some feature of big data circle
or some approach for Big Data sequel
today we're going to start with the
Enterprise Manager for manager and other
way to analyze performance of your Big
Data
cicatrice but let me start with our
beginning and let me remind what what's
the sister of this product and which
challenges have each result so many
customers have are inside the enterprise
different systems and like Oracle
database like a dupe like many non
sequel databases and every single system
has own API it's going to be either
Oracle sequel or or Hadoop
sequel of inside the head of you could
have is a Impala engine or hive or
pressure or somebody else found
something else
so every single non sequel database has
own a P I and it's quite it's getting
quite complicated to support all those
KPIs what people want to have single
sequel or all loose sources the critical
walls designed and built just for these
services
so how look like analytical process
before without a physical one very smart
guy right my produce code right some
five sequels right maybe some big
earthquakes and in the end it analyzed
somehow text files with big data sequel
you could use sequel which you put in
front of the ah di tool or some
analytical tool like like Houston use
fast for example and just great data in
your usual way so and how we'd how to
recommend to use big data together with
Oracle database figuratively
technologists together with Oracle
database use on big data cycle we are
used to say that you have to put all
your data in the head do then build some
aggregates prepare it cook your data and
then move on the database tire then on
the from only this database tire you
have to work real after it your end user
application have to work on the rich
database tire
so with ticktick sequel you are able to
query data on end tube and Oracle
database turtling from the your
application from your application so
it's main intention of big data sequel
okay and now ah let's have a brief talk
how does it actually work maybe you know
that Hadoop has two different logical
tires its torch tire where you actually
put your data it could be either a do
file system HDFS or one of the non
sequel databases as well Hadoop has
plenty of processing engine to query
data to procedure data to work with your
data to do real analysis
just all those components or MapReduce
or it's most convenient implementation
of MapReduce which we call hive or it
could be spark or it could be Impala or
it be called a search or solo and it
could be big data sequel so big take a
circle it is another one process which
you run on every single head just not on
every single data not and it proceeded
data which is so on HDFS or not equal
little bit we can't bring something
special on the storage layer on the
storage layer we work we work with HDFS
or no sequel data be done to any
specific optimizations for storage we
just put our processing engine our HDFS
what has to be done on the Oracle
database in our on on the Oracle
database site on the Oracle database
side you have to create external table
since Oracle 12c
you do have to use type of the oracle
external table it could be either or
high or oracle HDFS we recommend use
Oracle high as always when it possible
it inherits metadata from the heisman to
serve if you already defined it there
you just reuse this metadata and
definition and which our recommended
approach if for some reason you could
not use hive we you could define
metadata with Oracle HDFS type of
external table so and inside this detail
you are you explain how to access your
data which two are going to use so you
explain cluster which you're going to to
use for this course so and after this
you are able to create Hadoop data
through the Oracle database what happens
under the hood when you run sequel in
Oracle database you login into Oracle to
be put some table statement and then
query come to the name not from the name
node you get file location state
structure you define pearlies and you
plant some you create some our plan you
create some scan time and start smart
scanning data on them on the header
player so
on the head do player use can the data
you filter out unless your data and then
move back to the database only with
Peskin block only block which matches
with your criteria listicle criteria and
then join it with AA with oracle data
for example with our datastore in Oracle
database okay and let's zoom out Big
Data Park what's going on on the head
website and here you could find very
familiar from exadata both works smart
scan smart scan it's a kind of a kind of
back part of the Exadata smart scan
which could read or code blocks and to
smart scanning so which could do all
filtering job but on the HDFS you store
any you could store any type of data
could store is a CSV or party file or
JSON or XML or whatever you want you
need to have some extra component
external table services how it's called
on this side which we any file format
and convert it in Oracle format then
pick string it's all happens internally
on the sell side of the head website on
the headed note and then extreme data on
the smart cat smarts can do all
situation so column pruning our
predicate push down it parse JSON it
tells our XML so it could apply in score
models you do what you can to do this
smart scan scan on this file and then
rest of the data you sent to the
database for today towards the database
sound good but how to start working with
big data secure let's mention that you
already installed it and you want to do
literally self step with
this big data sequel so it's easing up
an Oracle database for example likes
critical path for Tiger and run the
query from releases but let's imagine
that I run the query
and it takes a while
and I don't understand why the square
takes too long so something is going on
but I don't understand what I wanted to
figure out what what's happening right
now with microwave and that t bar and to
approach is the same like with Oracle
database so step are going to be
Enterprise Manager you go to the
Enterprise Manager or database Express
often our performance bookmark open
monitor to group and here you could find
am see groups which Iran recently or
which is running right now so for get
more details for drill are you have to
drill down on some concrete tech related
you click on this circulating and get
more details about your query right what
we can see here lateral equator sequel
it's Oracle sequel
it has Oracle plan it has a it has
Oracle statistics and so
many optimizations which is relevant for
Oracle database are relevant here for
example if you met some performance
problem it could be even on the Oracle
database site so if you write some
complex query ah the real problem could
be on the Oracle database site so that
big logistical plan is Oracle pad
you just work against external table and
here on the career plan you could find
on my last role in my query plan
external table access storage pool which
means that you run smart scan over
external tape
and second thing which you could find
that we introduced new waiting event I
all sell external table smart can so
these event says that can happen on the
head website it says hey you float
something on the head up side and in our
concrete example all workload was pushed
out or towards the sell side towards the
head website so database was not
utilized there well very good arm now I
know that I push all down something on
the sell side but what's gonna on the
south side
interesting to note mi cpu-bound or is
bound for answer on the discretion it
will be great to jump into cloud or
manager and/or on bar in case of what
works and then you could find a CPU
utilization and health on this schedule
ization across the hall or even across
disk and this information will help you
to answer on question what's going on on
them on the sell side if you want to run
these to run you to to to catch
utilization in the real time you may use
this top so it's Linux to which you open
on any deep build and then after this
you are not you are able to see what's
going on on your cluster how utilize how
your CP utilized how your disk utilize
tell what's going on over the wire
what's going on this network so it's
like dynamic picture pulses of
hospitalization
well let's imagine that you query we're
done and you want to know more details
okay I say that Isis it are we offload a
lot of data so we filter out plenty of
data on the sell side and move back rest
of the data towards the database side
but let's imagine that you have very
natural desire to know how much data in
numbers we moved on the database side or
you want to know some from expert
sophistica coming this query you could
run the simple sequel statement which
you list here which joined my start
table and start name table and we filter
out everything for by xt predicate here
right now we're going to extend this
list but today we have all five
different metrics which will help you to
analyze what what what was happened on
the big beta sequel side on the head up
side last one are ronald io by state by
search index I will explain later
oh very good metric but we will have
dedicated seminar for search indexes I
will explain more details about this
counter and let's talk about other so
cell exocrine also quest for predicator
flow it shows you how many blocks do you
have on HDFS so grano and blocks are
synonymously for big data sequel and a
second metric cell external pipe request
to predicate the float it shows you how
many bytes to store on your on your data
not
how many bytes are going to scan cell
interconnect by photon by X this month
can shows how many bytes sent to the
database so in our example let's jump
back to the previous screen we could
find that we are we had about 300
gigabytes of data and towards database
we sent only 35
megabytes so we filter out 35 mega mega
bytes of 300 gigabytes of data and quite
it was five efficient query break and
another one metric which we have and
which is equal to zero it's cell XA
grano predicator float 3 twice ideally
it has to be equal zero this something
went wrong with your query we start scan
another one Brassica or switch to the
fallback mode and then we will find that
this metric are different route than
zero we have this cases where that
signal we have to check the quarantine
we have to check the log and we have to
figure out what was wrong with the query
but endearing it has to be you know so
useful basic step of the four basic
steps to debug and understand what's
going on on your big data secure platter
you could find more information on in
the documentation or in Big Data sequel
blog post which we have on the on our
data housing blog post
all right that's all for today any
questions
you
everyone is unmuted no yeah</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>