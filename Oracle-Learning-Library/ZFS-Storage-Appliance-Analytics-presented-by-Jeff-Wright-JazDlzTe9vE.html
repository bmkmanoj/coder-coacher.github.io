<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>ZFS Storage Appliance Analytics, presented by Jeff Wright | Coder Coacher - Coaching Coders</title><meta content="ZFS Storage Appliance Analytics, presented by Jeff Wright - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>ZFS Storage Appliance Analytics, presented by Jeff Wright</b></h2><h5 class="post__date">2013-10-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JazDlzTe9vE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello my name is Jeff right chief
technologist with the Oracle storage
organization I'm here to talk to you
today about the ZFS storage appliance
analytics feature the CMS toward applies
analytics features comprehensive
instrumentation that covers all the
major hardware and software components
of the ZFS storage system it tells us
who is accessing what resources in the
system the quality of service delivered
for to the users accessing the resource
and the consumption of the individual
components in the system using this
information we can quickly diagnose
bottlenecks take care of quality of
service escalation related problems and
identify where bottlenecks recurring in
the system so we can proactively or
reactively upgrade or change the system
to increase newer increased service
requirements initial login to the ZFS
storage appliance shows status page here
we see a general overview broken down in
the last hour the last day and the last
week of activity we covered the CPU the
network and disk has major physical
components in the system and the
workload incident on those components
through that NFS b3 and b4 protocols SMB
protocol ftp and I skizzy this quick
dashboard gives us an overview of the
work incident on the system and the
consumption of the different components
in the system more detailed information
can be found on analytics by going to
the analytics section of the worksheet
and selecting the statistics to look at
on the system the statistics are
comprehensive from a CPU consumption
standpoint we can see cpus broken down
by utilization including the utilization
and different CPU modes we can tell how
the software in ZFS storage appliance is
running in which parts of that specific
software are being used to support user
workloads similarly and the arc access
our primary cash we can see cash access
broken down hit and miss filename l2r
college ability which tells us if a
particular miss is something that we've
been populated and yell to are a good
indicator of you need a red flash we can
see this broken down by project share
and lungs from a block access standpoint
other important bits that arc size how
big is the cash you can
when the cash is warming up but when
it's stable other interesting bits the
l2 arc access so just like the primary
cash the secondary cash we have on read
optimize flash we can also observe
access by hit miss filename project
shares lines and so on l2r excise
similarly to the arc size in the system
we can observe how big it is and when
it's appropriate to add more components
for secondary processing data movements
such as ndmp we can watch bytes to
transfer to and from disk bytes
transferred to and from deep file system
operations number of jobs that are
running in types as well as shadow
migration which files which projects
which shares and so on we cover this in
bytes number of operations and finally
requests physical component standpoint
disk we can watch the number of i/o
operations this is that active q if you
use to IO stat we can see the disk
broken down by present utilization
individually watch the number of i/o
bites by disk and by type and aggregate
similarly i/o operations with those
operations we can see the offset as well
as a response time or latency this is
really handy when you're trying to
troubleshoot problems related to
randomly accessing data versus
sequentially accessing data and in cases
where sometimes the application behavior
is inconsistent with what we think it's
going to do we can look at the disk
broken down by percent utilization
similar to the disk we can look at ZFS
in terms of how many logical I 0 bytes
he's running compared to how many bytes
are actually going to disk so good
measure when you're looking at the
inflation from raid and mirroring
calculations memory standpoint we can
observe most aspects of the memory
including specific usage of applications
running on the appliance so that we
understand which parts of the memory are
being consumed we also could look from a
network perspective data access in terms
of bytes transferred on the data links
at the interfaces physical interfaces
the interface bytes this is the IP
addresses assigned to those interfaces
whether we can track IP bites by host
protocol direction IP packets similar
be the tcp stack we can look at the
client as well as service and direction
and similarly with TCP packets from a
front-end protocol standpoint or the
application protocol standpoint we
instrument the fibre channel or block
protocol from a perspective of the
initiators targets of lumps similar to
the bytes transferred we look at the
operations we see here the operations
are also broken down by latency so
that's where we observe the clients
response time delivered of the client
run similar statistics for FTP HTTP web
dev I skizzy just like fiber channel
operations and bites and the
demonstration we're going to show today
is NFS operations so we can see
initially drilling down by type client
file name share project blade to your
response time size and offset like NFS
we can watch SMB similar statistics and
finally srp for people that run I scuzzy
over infiniband with RDMA protocol we
watch SRP just like we can watch I
scuzzy those drill downs are beginning
of what we can look at in the system
just make it easier to work with the
system we can also build these into
pre-loaded worksheets and save those
worksheets for reference later and see
this particular test systems used by a
lot of us here in the sales and
engineering groups and we cover
different aspects of demonstrations we
give with the system i'm going to show
you is the worksheet i like to use that
just covers general NFS monitoring we
start up this worksheet we can see i'm
watching first and foremost NFS
operations broken down by type we like
to see the read and write operations
broken out separately gives us an idea
of what the clients are doing watch NFS
operations by client so we can see the
users that are accessing this system and
how much those users are accessing the
system this particular case the 1080 54
92 represents a VMware system i'm going
to show you later these other systems
are people sharing access to the rig
right now NFS operations broken down by
file name is very handy if you want to
know when users are accessing data you
can see the specific files or accessing
and on this particular example we see a
user is scanning what looks to be a
large number of five
and we can even look at that more
graphically see in a pie chart what
those users are doing to the data in
this case we can see there are roughly
10 files that are taking care of most of
the work load in those 10 files we're
highlighting here are you accessed just
about uniformly so it's a you know a
nice picture of how the application is
running so we move down the stack NFS
operations per second broken down by
latency this includes read and write
lumped together it's nice to have this
statistic as a single statistic from an
easy you stand point later we'll show
how to break them out by reads and
writes separately network interface is
broken down my interface here we see our
NGE 0 link running very close to line
speed and then finally moving down
through this the disks we can see just
broken down by utilization relatively
idle in the screenshot CPU at seventeen
percent not really working our arc
access broken down by hits and misses so
we can see the data hits and data mrs.
broken out separately in this particular
example we have mostly mrs. in the
system for those misses that are
occurring or mostly hits in the system
for the missus that are occurring we can
see the yellow sketch here those misses
all would be served by an l2 arc so we
can invest in the l2 arc with confidence
for this particular workload and one
last bit we can watch files broken down
my offset this particular workload we
can see there randomly distributed and
finally read and write operations
severally broken down by latency and
last a disk utilization ninety-five
percent by disk this tells us when our
just start to get pegged we can light
them up individually to help tell the
difference between a disc that's failing
mechanically versus all the disks that
are getting saturated so with this
instrumentation how we apply it to
solving a real world problem the first
problem we look at is I have a customer
will imagine in this terminal window
that's going to run a workload in this
case he's going to run a Miss operation
to the disk 32k random reads 64 pending
iOS and this particular user is going to
look at the quality service that's
delivered in terms of the average
response on total i owe rate
make a judgment about if that I our
response time is good or bad and then
let us know how they feel about it way
they're going to measure the output of
the system is with iostat and from that
I of stat report will be able to see
what the client thinks is happening from
the storage system here we see about
1,100 1,200 reads a second data
transfers about 37 megabytes per second
service times about fifty three
milliseconds and 64 pending active iOS
this particular user I know well has
complained that this is insufficient to
solve the problem I think performance is
terrible we need to do something about
the storage system as a storage
administrator I can look very quickly at
the workload real time try to find out
what's going on this particular
screenshot we can see our 1200 reads the
second match is pretty close to the 1200
reads the second reported by the user as
we can see the 1080 5490 to user is the
one that's accessing the system and as
before we can see that workload that
I've shown you this is this particular
set of test files that are getting
looked at those particular test files
the quality of service looking at the
system we can see most of the iOS are
coming in under 70 milliseconds with
most of them happening in the range of
72 38 milliseconds the reported average
response time of just over 50
milliseconds is shown in the screenshot
is consistent with what we have measured
on the storage system so so far we agree
with our customer what the performance
of the rig is now we need to go look
through and find out what the problem is
with the rig performance looking at the
physical back end of the system we can
see there's almost 50 active iOS the H I
break group that backs up this system
you know with 50 iOS pending is about
six iOS per dr six iOS per dr is enough
to keep the drives pretty busy just
broken down by percent utilization we
can see is nearly under percent in this
particular system the bottleneck is
clearly the physical disk drives so our
user has completely overrun the capacity
physical disk drives in
from a Headroom perspective CPU kernel
space is about eight percent we have
plenty of CPU left in the system and if
we look at the way the cash is being
used we can see nearly all of the i/o is
coming across as mrs. very few the iOS
hits as cash hostile work load those
mrs. well-served would be well served by
an l2 art we can see that almost all the
missus would be accessed from the L to R
canal to ark was installed which means
if we install an l2 ark we could
alleviate the particular quality of
service problem by increasing the
throughput for those random i/o
operations sighs perspective could
double-check with the application we see
most of the iOS are coming in right
about 32k like our user says and the
physical access of the data file we
picked one data file eight to look at by
offset we can see relatively uniform
access throughout the entire data file
last read operations broken down by
latency gives us a little more detailed
pitch again we see the same roughly 40
to 70 milliseconds consistent with
reported 50 millisecond average and
writes not very many of them going on
last disk operations greater than
ninety-five percent broken down by disk
this is a handy statistic that tells you
which particular devices are being used
to support the workload which ones are
pegged an interesting way to break this
down we can see the drive tray AK 0 0 1
and there's eight disk drives that are
completely maxed out so this is all
consistent with the raid groups not big
enough to support the client workload
last from an arc size we can see there's
about eight gigabytes worth of capacity
in the arc this is a very small system
that's the limit the arcs not warming up
we know this isn't a warm-up problem so
we can confidently say that if the users
workload fit in cache to the l2 arc or
the arc we would increase the quality
service likewise if we increase the
number of disk drives in the system we
could also increase the quality service
or throughput delivered
as an illustration of the test we're
going to go through and rather than
change the size of the rig we're going
to change the size of the data that we
operate on this next bit instead of
scanning over hundreds of gig with an AK
cash we're going to scan over just a few
gig for that 8k cash effectively what
we've done is we've increased the cache
size with respect to the workload we can
figure out the clients going to be happy
and if the clients not happy how to
solve the next bottleneck as we use
before we run I ostad to keep a sharp
eye on the system we can see with this
particular miss workload we've got a
hundred eleven megabytes a second 30
almost 3600 iOS per second 63 active io
just like we had before in a 17
millisecond service time 17 or 18 the
client is peanuts better than 60 but
we've still got some question that we
want it faster and clients complaining
again the storage system is a problem we
need to alleviate the problem you need
more cash you need more disk drives
rather than just react to the system we
can again look quantitatively to find
out where the problem is and then very
accurately sort out what's going on like
we did before we can match up the NFS
operations from the client seeing the
same 35 36 hundred matches well with
what the clients reporting 35 36 hundred
we know that the dot 92 client again is
the same one accessing the system so
there's no conflict of workload in this
case same data files are being accessed
which again shows us the workloads the
same going down to NFS operations we see
our first hint as to the effectiveness
of changing the cash see here of the you
know thirty five thirty eight hundred
operations per second going on nearly
3500 of them are coming in under a
hundred microseconds this is the cash
response time of the system the maximum
response time we see observed for this
workload is only four milliseconds
therefore the reported client-side
response time of 50 millisecond
milliseconds is well in excess of the
response time from the NFS server on the
target that means the bottleneck in the
system is somewhere upstream from the
NFS server and the ZFS storage appliance
downstream from the application this
puts us in network layer as well as the
the network link layer so network
drivers and network links moving down
network interface bytes broken down by
interface we see 120 megabytes per
second on n GE 0 r 1 gigabit ethernet
link that is very close to the maximum
possible data we can push through that
one gigabit ethernet link once again we
see clearly the bottleneck in the system
is letting up by a completely saturated
Hardware resource so double check on the
rest of the rig disk i/o operations
broken down by state before when we had
50 active iOS to the disk now we only
have one so the disk drives are clearly
not the bottleneck in the system adding
two strands would not help to support
the workload CPU mic for CPU consumption
is up which we expect with more
throughput in the system we have plenty
of headroom at sixteen percent
consumption arc access broken down by
hit and miss we can see the efficacy of
changing the size of the data set with
respect to the size of the cache instead
of mostly mrs. we have nearly all hits
and system we can't even observe the
misses and with very few misses there's
very little eligible for the l2 arc and
if s operations broken by size again we
can see client is running about 32 k
just like they said by offset we can see
it's the same workload roughly uniformly
spread however now it's 10 megabytes per
file instead of several gigabytes per
file and last the reads broken out by
latency a response time first see the
reads are handled individually 3400
writes non-existent going back to the
disks the hierarchy that we had here
needs to be refreshed show that there's
no disks that has a utilization greater
than ninety five percent the disks like
we said our idle and finally our excise
is the same as we were before so with
that we've shown you a little bit about
how you can compare the application
response time the storage system
response time as well as a component
consumptions to pin down the bottlenecks
in the system quickly and accurately and
then take proactive steps to alleviate
those bottlenecks by adding the right
kind of hardware hope you found that
interesting we'll look forward to giving
you more talks on how to use analytics
in the future thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>