<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Up, Up, and Out: Scaling Software with Akka | Coder Coacher - Coaching Coders</title><meta content="Up, Up, and Out: Scaling Software with Akka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Up, Up, and Out: Scaling Software with Akka</b></h2><h5 class="post__date">2013-02-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GBvtE61Wrto" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so my name is Victor clang I
work for a company called typesafe we
with the company with the software stack
for applications that scale and I happen
to be the tech lead of a project called
acha which is a part of typesafe and i'm
here today to talk to you about akka and
how to scale software both up and out so
without further ado akka besides being a
really beautiful mountain in the north
of Sweden it's also happens to be a
goddess of all beauty and wisdom in the
world and also a software project but in
that order and akka is built to be a
runtime and a middleware platform for
doing concurrency and scalability on the
JVM so it's built using your normal JVM
stuff so Java util concurrent and all
the magic we can do with that but it's
also built in a language called Scala so
how many of you are familiar with the
language Scala yay that's that's like
everybody cool so what's important is
that we don't really target Scala only
so we think it's very important to sort
of be open like letting everybody in so
we want to make sure that we have a
really good Java interrupts story so we
want you to be able to leverage what you
already know so if you're a Java
developer you've spent a lot of time
learning Java you have a lot of
ecosystem you have a lot of experiences
and you have a lot of tools that you're
already using
so with akka you can use it from Java
today as much as you want you have the
option of using it with Scala Scala lets
you do some stuff that Java doesn't but
it also allows you to integrate with
what you already have like your
infrastructure in your deployment
scenarios your web app it's an
application containers so you might ask
your case anybody really using this well
there's a couple of aqua production
users just to get you started
Oh take some water you might recognize
some of these companies there so this is
a something that just appeared out of
nowhere and nobody's using it this is
really solving real problems for real
companies in the world so what is the
purpose of alka in itself well we want
you to be able to program at a higher
level so if any of you have done any
concurrency and parallelism work on Java
on the JVM before you know that normally
you end up with a lot of coordination
code within your business logic you end
up with locks you end up with
synchronized blocks and you're sort of
mixing concerns in your code
normally it also means that your code is
very tightly coupled with how its
executed so it's really fixed like how
many threads are we using where are we
deploying it to it becomes a part of how
your application is written it's sort of
hard to extrapolate and scale that out
when it's already baked into the source
code how it should be deployed and how
it should run so we want to allow you to
program concurrency and scalability at a
higher level we also want to be able to
both scale up and to scale down and the
scale like in and out so we have people
running akka on android phones we have
people running our caon huge boxes we
have people running arc on their normal
workstations and we have people running
act on a lot of servers so it's really a
paradigm to both scale up out and in and
sort of it's a very flexible way of
doing things and we want to be flexible
we also want to be able to manage system
overload because to be frank if there is
a crash in the market and you can't log
into your stock exchange to sort of sell
or buy what you want to do it's not
like a situation you want to end up in
so managing system overload is an
important aspect of building scalable
and highly concurrent applications we
also want to be able to automatically
replicate and distribute your
application so you can sort of scale out
in a more dynamic way you don't have to
sort of as I said earlier have don't
have to hard-code that into your
application and the reason is simple you
can't really have any fault tolerance if
you don't have any replication because
then you have single points of failure
we also want to be able to automatically
load balance the application this sort
of ties in to handle system overload but
it's really important because some some
workloads end up being very sort of
targeting one node or a specific part of
the system and to be able to
automatically adapt to those scenarios
is important so the question is how do
we achieve this well how can we make a
programming model that doesn't really
tie these things together in hard code
and make everything very sort of robust
in a bad sense well what about something
called actors and how many of you have
heard about actors before so an actor
this is an actor but not technically
what I'm talking about today so in my a
really good actor but in any case an
actor is sort of a unit of code
organization or a unit of computation
and actors they helped you to create
applications that are possible to make
concurrent scalable and fault tolerant
and that's it's sort of a part of how
they are built that sort of lets you to
to take advantage of this well you can
see it as sort of a like if you go back
and see like a unit of code organization
so if you
easy stuff it's it's like station beans
or something like that but it's it's a
way that makes it possible to not mix
concerns in your code in the sense that
you would do with with locks and
couldn't synchronize and stuff like that
so you don't want to mix different
levels of programming like coordination
with actual business logic with other
things so this the actor model allows
you to sort of write that kind of
programs so a lot of you have actually
already heard about actors but for those
of you who haven't it's is not something
new it's it's from the 70s like all cool
stuff in computer science that we're
sort of rediscovering today but it's
really tried and true Erlang has been
using it since the 80s with great
success and they use it for telecom
systems with really high uptime I have a
colleague of mine from Germany and I've
heard that they have other definitions
of nine nines of uptime will you ask is
it up nine is it up nine and it's a
different way they do it there but it's
not the same thing so tying back to
racing the abstraction level like
programming at a higher level don't
think in the terms of shared state it's
shared state is sort of making the
illusion that it's cheap and easy to
peer into the minds of others so it's
cheap to read state from somewhere else
it's cheap to update state for somewhere
else that is true when you're in the
local virtual machine are very closed in
memory but when you have things that are
running on other boxes potentially on
the other side of the planet thinking in
shared state means that you have a leaky
abstraction that the optimization of
doing things locally leaks out to the
assumption that it's the same way for
everything else this is not true threads
and locks it's a it's a means of
execution it's not a means of organizing
code so when you write threads and lock
you're trying to mix in execution with
logic with your business logic that's
just wrong completely what have anybody
of you ever try to debug someone's
really nifty concurrency code yeah how
many of you want to do it zero for the
record for the record it's not something
you want to do and you're never sure if
you're actually fixed or broken
something else and it's just hard to
test these kinds of things
concurrent collections are good when
you're local it's a good good
optimization mutable state is a good
optimization when you can keep it local
with actors low-level concurrency
plumbing becomes workflow you think
about how things are flowing in the
system not necessarily how that is
actually done it's communicating intent
and not the the how the imperative way
is always the how how you do it this is
sort of like what as a consequence of
this you can get high CPU utilization
and high throughput and scalability just
for the sake of the model because you're
going to use the model in a sense that
doesn't make assumptions on how things
are done and it also has a very good way
of dealing with failure like the actor
model has a very good way of dealing
with failure and Erlang has sort of
pioneered this and how you deal with
with failures in a very highly
concurrent a highly distributed system a
lot of things in when it comes to fault
tolerance it becomes tacked on as a sort
of an afterthought when you realize that
the happy scenario isn't always the case
actors have a very nice way of dealing
with failure that we're going to talk
about a bit later another good thing
about actors is that they are
distributable by design and what do I
mean by that it's they are location
transparent so it's sort of like you
have a
identity or something you can address
and it makes it possible to just as you
have a post address you may live in the
same building or you may live in a
different city or a different country
it's an address to something that you
can send something to and addresses are
provably a very good way of making
things distributed scaling up and up as
a part of the model I'm going to show
you later in this talk how we can build
scale up and out which is the title of
the talk you get a perfect fabric for
the cloud because it means that since
you're not encoding in your application
how things are done or where they are
located it's more easy than easier to
just make things configurable and
automatic how it will be deployed at
runtime you might have the same
application deployed in two completely
different sized systems or or data
centers or whatever but the important
thing it's possible to optimize for the
actual deployment and I'll change the
application to fit the deployment it's
very elastic and dynamic message passing
which actor uses to communicate is very
very elastic sort of send emails every
day it's very non strict in how you can
send email it's full torrent of
self-healing I'm going to show you how
you can make systems that self heal so
they react to failure and has a strategy
for dealing with failure and you can
also do the adaptive load balancing and
rebalancing and also in an extension you
can move actors to where they are most
used just as in your company you might
take your distributed team and move them
to the same place for a month or two
when they're doing something really
important so this allows you to build
extremely loosely coupled and dynamic
systems that changes with the runtime so
how does this fit into my building of
applications this is up until now it's
been sort of really fluffy the high high
level
speak but how does this relate to what
you guys are doing well you can sort of
see like in different scenarios because
there is always like different way of
seeing things you can have actor as an
alternative to a thread for instance a
thread of execution or an object
instance a component of sorts a callback
or a listener something that you can
notify a single tune or a service like
you wrap a web service or you wrap a
database service in an actor you could
have it like as a router for routing
things amongst multiple boxes or
multiple other external systems you can
use it as an alternative to a session
bean or a message driven bean a question
I get a lot like what's the difference
between a message driven bean and an
actor the message you have being is not
stateful and the actor can be stateful
or you can see that just as an out of
process service something running on
another box and communicate with there
also pretty much described as finite
state machines so we have an API naka to
really have a good DSL for building
finite state machines so what does the
actor model actually mean what's the
definition of the actor mode so this is
Carly with the the sort of the inventor
of the actor model and if you go there
there is a nice talk that you can watch
his him speaking about actors so for him
it's a fundamental unit of computation
so it's computation it's not a
fundamental unit of message passing
so it has processing it has some sort of
storage so it can store state be
stateful it as a means to communicate
with other actors so actors can
communicate and there's three action so
when an actor receives a message it can
either end or in any combination you
want it can create new actors sort of
spawning new sub parts of itself to do
work
it can also send messages to other
actors that he knows about and against
and how many messages it wants an order
and it can also designate how it will
react to the next message
it receives so just as you can affect
how your coworker will react to the next
thing you say by insulting them or
giving them praise you can sort of have
effect the actor can change how it
reacts to new messages it's a very
flexible way of doing things and I will
show you what that means so there are
four core operations to actors and the
CEO here is just because we need some
way of defining an actor first before we
can actually do anything with it so we
start with with a prequel thing which is
called define and this is my first code
slide by the way for all you developers
so first we need to sort of define some
message that we're going to send you can
send a string or a primitive or
something like that but it's normally
good style to define a message so here
we define a greeting class it's
serializable so the default akka uses
Java serialization when you communicate
via notes but it's fully configurable so
whatever you want anyway whatever you
want to use and it just has one field to
agree to then we define the actor class
the actor type what is the actor doing
this type of actor well you define the
class meeting actor it has a it's
extending untyped actor which is a class
that we provide so there are both typed
and untyped actors but for this
presentation we talked about untyped
actors we define a behavior on receive
so when I receive a message what do I do
this is the the behavioral part of the
actor in this case we're saying that
when I get a message that is a greeting
I will just log that message and look it
like hello whoever I was supposed to
greet
does that make sense message class just
a normal class nothing magical extends
on typed actor has a behavior for how it
receives and how it reacts the messages
of course you can do like anything you
want in there
the good thing about this is that we are
able to execute every actor in a
potentially its own thread so as you can
see here there is no synchronized no
logs no nothing there is no nothing that
indicates how things are being executed
it's just declarative what this actor
does when it gets a message the first
operation now that we have actor actor
type and something to send to it is that
we want to be able to create actors we
want to instantiate our actors so the
create operation creates a new instance
of an actor in our kits extremely
lightweight compared to threads so you
can approximately have two and a half
2.7 million actors per gigabyte of RAM
so when you do thread based program and
you have to be very very careful about
how many threads you create because
after a certain threshold you're going
to get diminishing returns from context
switches so you can create virtually how
many actors you want as long as you have
memory for it they don't occupy any CPU
resources if they don't have anything to
do so that they're just resident in
memory and it's a very strong
encapsulation compared to normal normal
classes because you will see that how we
instantiate this actor it is very very
isolated from its surroundings if you
see in the previous slide we could we
add some state here we have the log so
it can have state it's a stateful thing
we have behavior and we have some sort
of message queue that make sure that we
get the messages in the received method
so the messages are received one at a
time this is important so akka
guarantees that every actor can only
process one message at a time so then
you don't have to have any synchronized
you don't
have to have any coordination things
it's it's the guarantee that we give you
and we take care of safely publishing
the changes within the actors so you
don't need to worry about unsafe
publication on the DM and other threads
not seeing updates this this we solve
for you it's also a tight coupling
between state and behavior so one object
like an object that has state that has
behavior and the only way to sort of
observe the state of an actor is by
sending it a message in query what state
are you in
you can't reach into the head of another
person to see are they happy you have to
observe what they're saying to you you
have to ask are you okay so how do we
instantiate an actor well I can has
something called an actor system which
is the logical application so like a
spring context or something like that
that encapsulates a logical application
and from that actor system we can create
using actor of using something called
props which I think all actors should
have and I think there's only one genre
of movies where they don't really need
any props but your actors is going to
need some props you put in the clasp of
the actor so this in this example we're
not showing how you use constructor
parameters so this is simply a
definition of how we instantiate your
actor here so we create the actor system
first we give it props which is the
configuration for this particular
instance and then we give it a name when
we create it it has a logical name this
particular instance has its own identity
make sense everybody everybody with me
blood sugar is still high
so the question is can an act receive
multiple message at the same time no
that would be completely completely up
entering the shared state synchronized
thing again yes yes so a message can be
a reference and absolutely you can do
that so we have the we're trying to
design things to be distributed by
design and then make optimizations
locally so locally what ARCA does is
that it passes things by reference
because it knows that it's inside knows
what it's communica munich ating with
whether it's local or remote so we can
optimize for that because passing
references inside the JVM is extremely
fast but there is an option to turn on
serialization of messages even within
the VM if you really want to have strong
isolation between your actors so it's
it's up to you how you want to do it we
also encourage all messages to be
mutable just because it's a good good
sort of standard to have and it's good
it's easier to reason about messages if
they are immutable does that answer the
question
advantage if you share yeah so if you
can share references actors are no
longer independent well it that's true
but on the other hand on the JVM any
actor could call system.exit at any time
which would kill the entire process so
it's not really something we can solve
also think even if you have classloader
isolation a lot of stuff are loaded in
the system class loader which is shared
so it's not something we can really
solve here but it's an implementation
detail so it's not inherent in the model
that you need to have reference
isolation or not all right
everybody with me now we can create
actors we can define we can create them
we can create how many we want as we
have RAM at least so it's interesting
about apke at Erlang doesn't really
enforce Erlang by the way is the
Erickson thing that I talked about
earlier with the German 9s so what's
interesting about AK is that it enforces
a hierarchy of actors and this is
interesting because when you create an
after using actor of on the system level
it's top level and every actor so this
is the name I created an actor called
foo it's created on the top level as foo
but every actor can create other actors
as I said earlier and if foo creates a
then a is a child of foo and you can do
that like how much you want but does
this structure look familiar to you
like a graph and a tree well when you
have this sort of a tree every node has
a name you can sort of address it right
so we know through and we know the child
of foo foo a this means that it's really
easy to sort of look at how my
application behaves how its structured
it can reason about how its structured
because if everything is standalone the
human brain is going to have a hard time
picturing what it looks like but when
you have this hierarchy it's easier to
reason about and computer scientists and
people using computers have been using
file systems for ages so it's very
natural to think about operation number
to send we have actors they don't really
do anything unless we send the messages
so we need to send something so the send
operation takes a message and sends it
to the actor pretty simple
innaka this is asynchronous and
non-blocking so put the message on and
the actor will process it when it gets
cpu time when it would it's that message
is turn it's a fire forget operation
actors receive message reactively they
react to messages so there is no tight
coupling between sending and receiving
you can see messages ask the kinetic
energy in the actor system so actors are
sort of passive or they have a potential
energy until they receive a message to
which they can react and then after we
try to make everything asynchronous and
localized because we love asynchronous
and look let's you can do a lot of
interesting things when you don't risk
dead locking yourself that every every
corner right as an example part of the
goals of this presentation is to show
you how we use Java util concurrent and
up until to the dough we're sort of
heavily using this this guy the thread
pool executors it has an interesting
performance profile or a scalability
profile this is just our benching things
so if you have as many actors as you
have course and you send the messages
all the time you're sort of saturating
the system right so what does this look
like to you is this a good for like
scalability profile is this something
you would yes that's how would you look
it completely bottlenecks after about
eight actors and we were sort of
scratching our heads because we weren't
really expecting this
how many course this was this was an
eight-core machine so it's fairly
logical to see see how this falls out
but the interesting things is that since
everything is asynchronous and there's
nothing blocking each other
it could essentially have a lot of
throughput right but this really
bottlenecks out so we scratch our heads
and we were trying to debug this and we
sort of found out that the single task
queue of the thread pool executors is
the bottleneck that's the single point
of bottleneck that everyone tries to put
things into the task queue so you cannot
scale at all yeah was it on the 48 core
growth okay
48 cores yeah this was completely
unexpected so we sort of investigated
alternatives to this and we saw the fork
joint pool for Java 7 but this looks
interesting it didn't have that good of
a performance profile either because it
bottlenecked out because we don't do
Forks and joints we can never join
messages there is no join face so the
fork join pool in Java 7 has a single
task queue for external submissions and
every worker thread have a local queue
for the locally submit the Forks and
then they join that so we sort of try to
get to the bottom of this and Doug Lee
has improved so for Java 8 it has a new
fork jump ooh that has this scalability
profile so this is the triple executor I
was talking about earlier and this is
how it looks on the 48 core box with the
new fork join pool a lot better and this
is just using the Archaea standard
configuration on the on the 48 core box
and we were sort of a case and how we
now we're getting somewhere so let's see
what we can do if we actually try to
configure it for throughput and with
just changing some configuration
parameters we got 250 million messages
per second on that box so Java 8 fortune
pool way better than Java 7 Program pool
so
how do we send messages well it's fairly
simple
they said method on the actor if the
isolation of an actor that's called tell
so you tell the act or something and in
this case we give it the greeting so
this is what we tell the actor that gets
into the actor so this is
fire-and-forget just async respires
fire-and-forget so now we know defining
an actor creating an actor and sending
messages so this is the full example
this is sort of the whole thing so what
we do also yeah yeah so the question is
the message send semantics so in akka we
guarantee that the order of messages are
retained
per sender and receiver so if sender a
sends a and B they will be received in a
MB order for but interleaving for over
other sends is completely non
deterministic in that sense so all right
so we also give a short of a convenience
way to reply to messages so whenever you
process a message there is a get sender
and you can tell the sender a reply you
can do that how many times you want or
not at all so that's how you reply to
things and this you see the self get
self there it's who is replying because
technically you could be forking out you
could tell a bunch of other actors to
sort of go and retain the original
sender and forward the messages and then
in the end sort of reply once so there's
there's no hard coupling between sending
and rapine become so the third operation
in my opinion one of the most important
ones it's the possibility to
redefine the actress behavior at runtime
scary stuff right so become it's
naturally triggered by processing a
message so if somebody tells you
something that you might change your
behavior towards that person in the
future sort of like a type change in if
you're talking statically type systems
it's a type change of the actor and it
will react differently to the next
message and potentially other messages
after that it's possible to stacked and
push and pop new behaviors if you want
to it's a behavior stack and I guess the
question you guys have right now it's
like I want to do that
it seems terrible well in a highly
contended system you might want to
change the behavior of the actor to sort
of forward messages to other actors to
cope with the load so it's no longer
doing the same thing it was doing before
but it's changing behavior to try to
provide the same guarantees that it did
before but in another way
might be a finite state machine so it's
now in another state it's going to react
differently to stuff when it's in a
different state it could gracefully
degrade so if it determines that
something it's calling like it does
request to a database it might say okay
this database is not responding as fast
as it used to I will throw away every
third request or just say I'm completely
overloaded right now and try to keep the
same as late it could also mean that you
create a bunch of worker actors and you
want to use them in different ways
depending on what you're doing so it's a
generic worker pattern I have workers
but I define how they work or you can do
whatever you want it's completely up to
you but it's very useful once you get to
use it and this is how you do it get
context is available inside your actor
so it's the context of this particular
actor
and it has a become method we have
something called a procedure which is a
single abstract method interface because
it simply doesn't return anything just
side-effects so in this case we define
any behavior when we get a message we
will do something else
you could also unbe come to say okay
whatever I was doing right now let's
stop doing that and go back to what were
you doing before everybody with me yes
or no all right all right so there is
another one and I think what this is one
of the most important ones it's
supervised so we will talk about full
tolerance earlier and how that sort of
tacked onto things at times and actors
have a very nice way of dealing with
failure so what we can do is that we can
have actors supervise other actors so as
since we have a tree right we can have
actors suit supervising other actors so
like a hierarchical company where you
have somebody supervising someone else
that is being supervised with someone
else and what the supervisor does is
that it detects in response to failures
of its children or its sub actors so the
since you have a hierarchy all the
children you spawn your response you're
the parent of these children and you're
responsible for supervising them so they
don't misbehave so when an actor crashes
like there is an exception occurring
when you're processing a message that
notification of failure will be sent to
the parent saying that this child has a
problem what should we do and then the
supervisor decides what to do and this
provides a very clean separation of the
actual processing with how you handle
the failure so instead of sprinkling
your try-catch block we're we're
actually doing the thing it separates
the try-catch block from what you're
doing so the child itself does not need
to know how it's being supervised
normal ways it's like how do we deal
with failure well just run around and
scream right it's the normal way of
dealing with failure on the JVM is sort
of like what do we do when things happen
we just hahaha something bad is
happening
failure management in Java C C sharp
these types of languages is really ah
you all understand what I mean like you
have like four different levels of try
catch finally and like all the file
closed will actually throw an exception
and then ah you give them one single
thread of control in these languages and
once you have your thread of control
it's precious to you so if things blows
up your accessories could you have what
you only had one thread and now it's
gone so you need to do all this try
catch in every place and you don't
really know what kinds of exceptions so
am I supposed to handles like yeah if I
use checked exceptions I might get to
get those but I also might get the
runtime exceptions and what do I do
what kind of runtimes exceptions do I do
and it sort of becomes very messy
because you are responsible to handle
your own failures and they don't
propagate even if the exception goes to
the top of the thread the thread is dead
who do you notify this thread died
alright what do I do what what did it do
how do i how do i resurrect a thread
from the dead you don't do that so this
leads you to this try-catch stuff you
tangle everything up if you try to
protect your precious precious to it and
it gets scattered all over the place
your business code has the try-catch
blocks it has the synchronized blocks
and you have like all different concerns
in one place so there is a solution to
this and what's called the onion onion
model or the onion layered model or as
the Erlang errs usually called the error
kernel so you try to structure your
application where you put push risk down
in the layers so you have one core which
is very very dear to you and if that
core blows
the application is host anyway so you
try to push the risk out to others to
isolate the most precious thing from the
worst thing so what does this mean well
you have a crew like a Erik Colonel
let's let's let's say that this is the
top level actress that we created using
system actor of and these are the
children that they created so this is
the hierarchy and the things at the top
if they blow up your application can't
continue anyway because it's so severe
it can't recover but if a child blows up
something happened it notifies the
supervisor and the supervisor can decide
to re instantiate resurrect this child
but it also means that if a child blows
up the supervisor you can say I will
kill all my children and restart them
all on you and it goes up in the
hierarchy so if a child blows up
the supervisor determines I can't handle
this this is this is completely
completely over my head I need to
escalate to my manager and he will sort
of try to deal with this very very
severe problem so it means that you can
push risk I have a risky operation I
will create a child and he will do the
risky operation I don't risk my stuff I
just let my kids do the really dangerous
stuff
by the way this is not parenting advice
only is it in practice but interesting
about this though is that you can
supervise things over notes over
physical notes you can you can have
parts of your application running on
different physical notes and supervise
and deal with that over notes so how do
we supervise actors well every actor as
I said supervises its children and there
is a default parenting strategy but you
can override this so just to break
things down we define a supervisor
strategy in this case a one-for-one
strategy which means one child dies that
child gets handled yes also all for one
strategy that deals with all children if
one fails because they might be
interconnected in some way this is the
ten there is how many times it's
supposed to be restarted so how many
times am i going to apply this to this
child and within which timeframes you
can sort of say that if this child fails
at most five times per minute then
that's acceptable because I might have
an unreliable input source of sorts but
if things just blow up all the time
things are getting bad and I need to
sort of deal with that so for every
child failing you get the exception what
happened and you can say okay if it's an
arithmetic exception I will just resume
the child it was trying to divide by
zero let's just let it be and let it
continue if it was a
nullpointerexception
there might be some state within the
actor that is broken now so we issue a
restart which means that take your
current instance of this actor throw it
away we instantiate the actor with the
what you provided in your props so if it
was created using the class it will be
recreated so you re instantiate it in a
known to work state really important or
as I said earlier you can escalate it
I can't handle any other exceptions than
these so if there's something else I
need to escalate to my parent then you
need to override the supervisor strategy
method to say this is my strategy when I
create a child here the worker I will
just forward messages to that worker and
this is just an actor the other thing is
just an actor the worker in his turn can
also be a supervisor for his children he
is a supervisor for his children that he
might not have in each other.we it's
defined in our in our framework so we
provide what possible operations are
yeah
all right so in the event of having a
net split or a partition network how is
that handle in terms of supervision well
it's sort of I'm going to talk about
more the clustering stuff later because
if you can't know from within the system
the status of the other system that's a
normal problem this so what we have
there is that you will have to define a
formula for when you determine that this
thing is dead
operational that chapter
I'm sorry I didn't
okay okay so if a child on another node
become logically parentless because the
parent was living on another node then
that will be notified and handled by the
system for at least four to one at least
because it's really difficult to to say
when do you say that the parent is down
because it could be just an intermittent
Network failure but we can discuss this
more later because it's a really
interesting topic if there is a
convenient wave so so what we have right
now I will come to a part of this of the
of the answer to that but the question
is regarding a discovery service
discovery or actor discovery and I'll
address half of it and then afterwards
we'll talk about the other half because
that's coming in the in the next version
yeah so the question is regarding
message retries so what we do out of the
books is that we discard the message
because it could be a poisonous message
it could be really broken what we allow
you to do is to configure per actor if
it should be possible to retry a message
or not and we call that the stash you
can stash away a message and reapply it
later yes if there is a
nullpointerexception and it happens all
the time well you saw earlier that I
said at most ten times per minute the
actor can restart so that's how we sort
of try to throttle restart yes yeah so
how do you handle sort of the escalation
of failure so what we do by default is
that we kill the entire sub heart
hierarchy because they can't exist
without their parent so otherwise you
would you would end up in a in a weird
state right so what we do now is that
when you escalate it's the same as
saying okay this instance with its
children it's not really working anymore
all right I need to continue just we
will have some more questions later I
just want to make sure that I get
through everything awesome questions by
the way and yeah this is just moving
things up so everybody in the back can
see as well we also have some callbacks
that you can define on your actor let's
say you have an actor that makes a
really expensive connection to a
database and you want to sort of clean
that up before you restart so you can
hook in okay what do I do
before I'm restart that I will close
this file or I will close this database
connection I will clean up and then you
can re initialize afterwards so this is
a hooking system for dealing with
restarts all right
router's is a special case type of actor
and an actor normally on a commodity box
like at 3 gigahertz Intel something
something or an AMD processor do around
3 million messages per second so
sometimes that is not enough so what we
have is routers which make it makes it
possible for a very quick bypass of the
mailbox of the router to just set it to
one of its children instead so instead
of having the mailbox of the router and
everything going through that we sort of
try to avoid the the routers mailbox and
send directly to the children so it's
for high performance stuff but it also
allows us to do things like round-robin
routers where I will send messages to
this child that child that child that
child on the first this that you can
completely define this in your prop say
this actor should be a router and it
should be a round-robin router and it
should have this number of instances of
children that it will send to so this is
the type of the children in this case so
it's logically an example actor but
practically it's multiple there is a
whole host of different types of router
like random routers consistent hashing
routers scatter gatherer routers stuff
like that for for particular use cases
you can also have this dynamic so how
many members how many children do I have
in my router so you can grow you can
have a lower bound and upper bound you
can have different sort of parameters
for how you should resize this pool of
actors but the interesting thing here is
that akka has a configuration system so
you can outside of your application you
can define this so this is a deployment
detail I have a big box I can run a lot
of these I don't want to change my
application code just because they
happen to run the same system on
differently sized data centers or
differently sized servers it's a
complete no-brainer because it makes it
completely impossible to test all these
combinations so it's possible to define
outside what what your deployment
scenario
so here we can say this path of actor so
whenever I get this actor it will be a
round-robin router and it will have five
instances you can also define a resizer
for it to be elastic in that sense but
what's even more interesting is that you
can in your configuration you can
specify that this actor when I create it
I will create it on another box on
another akima sheet so we first have to
define that we're using remoting so it's
not just a local system anymore for our
greeter that we created first when we
create that greeter it should be remote
and it should be remote using the akka
protocol on that actor system on this
host machine using this port so if you
run out over there you have the
possibility to deploy your actors on
different machines this all was Ocotillo
so this is already out it's been up for
more than half a year and in a couple of
weeks we're going to release akka to one
and what's interesting about akka to one
is that we're shipping a cluster as an
experimental module so we've implemented
our own clustering which is based on the
thoughts of react and and the dynamo
paper to make it possible to to have
cluster fostered actor systems and to
enable this it's fairly simple just as
we said earlier that we were using
remoting now we're saying we're using
clustering and we have a couple of seed
nodes that you try to connect to
initially that just bootstraps
everything so it's completely
peer-to-peer and it's gossip based and
we're also the reason it's experimental
is that we're not sure if the AP is that
we provide or the right ap is for what
people are going to do so we won't feed
I want people to try this out and give
us feedback so we can make sure that for
- - we have the right ap is and we have
the right kind of functionality that the
people need so with
ARCA clustering we can define that our
router is now a clustered router and it
will be running max number of instances
per node and it will allow to have local
copies of the thing so you can really
tailor the the deployment of the actor
for when you're actually using the
system if you are more interested in the
clustering and how we've built that in
case you're that kind of person that
finds that interesting we have a white
paper about how we're doing things we
have documentation how you're supposed
to use it and we also have the code if
you want to take a look and dive into
the deep end also with two one we have a
camel which is our sort of bridge layer
for using apache camel using actors so
you can route two actors and you can
route from actors so you can use Apache
camel with actors and address actors and
use actors for building up your
workflows and pipelines and this allows
you I don't know how much of you you
know about apache camel but it has like
a hundred different connectors to
different types of software and
protocols and like an enterprise
integration patterns package so this
really allows you to make akka a part of
whatever infrastructure you already have
what's new also is the typesafe console
that we have a console for using the
akka and so you can monitor akka it
looks like this I wasn't really sure
that the Wi-Fi was gonna work for me but
there is a link later so this is how you
monitor an arc application so we allow
you to see what actors are running what
kind of problems are happening etc you
should definitely have a look it's a
really neat piece of software there is a
live demo in case anybody you have
internet access you're going to go on to
console demo that type sitcom login
check it out it allows you to see a lot
of interesting metrics up
your prison but about your present
applications so what kind of message
rates traces of messages the Layton sees
and ladies you just you be like a
scatterplot thingy you can see your tree
the queue sizes average queue sizes of
your mailboxes and average throughput
and a lot of all this metric stuff that
are really interesting when you're both
running an application and when you're
developing and debugging against the
neck application but there's so so much
more I want to make sure that we have
time for questions I just want to make
sure that there's a lot of stuff to akka
there's a we have type that if you have
data flows your MQ integration we have
something called extensions that lets
you write your own integrations with
like a lot of stuff so there's a rich
sort of ecosystem around it this is
where it's at so ARCA dot IO is the mr.
site we have a team blog at let it crash
calm and this is the type safe site
where you can find out more about the
console and I also want to mention that
we have a typesafe developer contest
starting now so we are looking for
awesome examples of how you can use akka
and play in scala to build cool
applications and there's some fabulous
prizes that martin order ski has donated
for promoting this and you can read more
about there and this is all I had so I'm
sure there's a lot of questions right
now and I'm really glad that we have
like five minutes to go so shoot yes
so if message queues are unbounded or if
something else so by default we use a
concurrent length queue which is really
fast low latency and it's thread safe
but you can define either per after or
per group of actors what kind of message
queue you want to use you can even use
your own implementation so you can use
durable versions or you can even make
use like a broker and have a broker
handle it so we really separated the
transport and the delivery from the
actual model so you can completely into
that yes yeah so if there is design you
should really go in to let it crash calm
and there's we had like a our customer
blog so there's a lot of interesting
blog posts on how you can use actors in
different use cases that's a really good
resource for that yes what do we do with
CRM queue so some people have like a
very heterogeneous system so they have
some see stuff they have some Python
stuff and the UCR MQ to sort of
integrate and that is what you use the
CRM q integration so if you want to
communicate with other CRM queue systems
yes okay so how do you manage fit on an
EE container so what we allow you to do
is that you key arcus shipped with
different thread pools and how we can
configure them in the configuration file
but you can write your own provider so
if you want to use container manage
thread pools you can just do your own
wrapper and load that into a key and you
can use it as you would use any other
container manage that pool yes so resume
what we do when you resume an actor is
simple as as you were it's a simply just
a ok to continue processing messages the
message was
Glaser exception but we mean continue
processing and message so on the pale no
no so we throw away the failing message
by default if you want to reuse you can
stash that message resize or how does it
determine it's time to resize up or down
yeah so the recites there's a default
one which was in the code there's a
default resizer that has a lot of
different parameters that you can tune
how and when it should reset so you
should really look at the docs because
it's really rich in that sense we could
also write your own yes if a lot of
people are using agents well I know that
just a couple of days ago Clark was
reading or writing a blog post on how
they use futures and agents with akka so
they use it they have like a billion API
calls a day or something so there's
quite a few people that use that but
since the SDM isn't distributed you you
have to know what you're getting into
because the model of SDM means that
you're going to use shared state that's
sort of the point of it so it's good for
certain use cases and that that's sort
of what akka tries to do is there is no
one tool will fit all use cases so
whenever you find a good fit for
agencies go ahead use agents and don't
use them if it's not the best choice yes
gee-ya so so since you can pass
reference around you saw the actor f
thing that was returned by the actor of
call that is transparently going to be
converted to a remote version of that
reference when it crosses the boundaries
to another system so we see ur eyes that
to be a remote representation and when
you re get it in we see if it's a local
one or if still a remote one so it's
sort of transparent this but the only
thing you can deal with an actor F is
send it messages so there isn't that
much things you can assume about it
except for you send it messes yeah yeah
so the message itself of course if you
if you if you have mutable messages
you've already said that I'm going to do
this so there's really nothing I can do
to prevent you from it but I can
encourage you to use immutable data and
sort of choose a serialization mechanism
that will fit your use case and like
performance and network wise so it's
flexible in that sense yes yes so flow
control it's sort of a problematic area
in a distributed sense but if you're
doing local stuff you can have bounded
mailboxes and have that either drop the
messages or have back pressure but back
pressure only makes sense if you're
local because having back pressure over
a network connection where the back
pressure is only actor to actor is sort
of you would essentially have to have
one connection per actor which wouldn't
really scale yes
yeah yeah there's there's a lot of
examples so there was a was a student at
the University of Illinois or something
that that sort of did a write-up on all
project and github that you Zack which
was quite of an extensive list so if you
google like a key example projects or
something you should be able to find it
anyone else yeah that knows the issue if
you you know Q yeah yeah so that's where
the the the issue debugging thing when
you have performance or with that sense
of problems that that's when the console
really shines because you can see what
like the average and average size of the
mailbox is what kind of throughput
you're having and what kind of average
latency of each message here what we do
is all the issues because let's say if
there's convention on the law I have you
know our list of strategies I can apply
like you know start the log think about
doing some concurrent coding what what
can I do here now you can you can hook
in whatever mailbox you want you can
deal with it in any way you want so so
when you when you have when you have
contention you I mean it's completely
open in that sense what what I mean is
if I have a system built on logs right
yep then by looking at latency I could
determine where an intubated
engine system self throttles yeah and I
can address Vasia I know how to do it
but then if I'm passing messages the
same problem is reformulated in terms of
Q's I'll resolve a problem when I have
you work with the method methodology yes
so what you can do there is either you
have to decide do I want to spend more
processing time processing messages do I
want to split up in more actors or do I
want to it's it becomes a more
distributed problem like how do I do you
deal with a distributed
denial-of-service attack it's
essentially what you're saying how do I
prevent myself from it yeah yeah yeah it
was if there is a concept of forking
drawn with an actress not per se but you
can definitely use actress to form
fork/join behavior but I normally
recommend so what I recommend for
fork/join
types of operations is using futures
which is a very nice way of doing that
so and with akka has with Scala to ten
sort of the akka futures has been sort
of merged into the skull of standard
library we've had it's like a it's like
a jsr for futures and like we have
Twitter and everyone try to harmonize on
one single implementation but I really
recommend using futures for that sort of
thing because it's so easy to reason
about yes
so if Java security context is pushed
between threads no mainly because it's
really tricky when once you go over
nodes but of course you can you could
hook into your own you can write your
own message dispatcher that runs the
actors are hook into that and propagate
between so in two 10 are in scala 2:10
akka 2 1 there is something called an
execution context that you can hook into
and before you jump you can set the
thing and reset it on the other side so
you can sort of get the same behavior
but
it's not yeah I yeah it's a tricky
tricky situation yeah you could always
do the the message dispatcher approach
where you sort of restore save and
restore the the context or you just
capture it within the actor itself
because I think somewhere the secure the
context has to come from so how does it
relate to does it relate to the message
or does it relate to an actor it's so
you have to see how you structure that
yes is IKS yeah secure akka yeah well so
so what's interesting about two one is
that we support SSL and TLS for remoting
now so you can pick and choose whatever
ciphers you want to use so you can have
I guess yeah all right ah the first
slide let's see if I can do that I don't
want to that's me thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>