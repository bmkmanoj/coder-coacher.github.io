<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NoSQL Usage Patterns in Java Enterprise Applications | Coder Coacher - Coaching Coders</title><meta content="NoSQL Usage Patterns in Java Enterprise Applications - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NoSQL Usage Patterns in Java Enterprise Applications</b></h2><h5 class="post__date">2013-01-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KDoyIJEdUYA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi welcome thanks for staying this late
into Java one last slot on the last day
we know that we're the only thing
standing between you and happy hour so
we'll try to get through this and
appreciate you being here
so I'm Randi Stafford I'm from Oracle
and this is Chris Davis from Nike and
our topic today is no sequel usage
patterns in Java enterprise applications
so in terms of an agenda just at a very
high level of detail we wanted to start
out with a little bit of context setting
maybe go through some of the terms we're
using and then we'll get into the sort
of the meat of the usage patterns and we
have a pretty extended example from
Chris of what he's done up there in
Portland and finally we'll try and save
some time at the end for discussion and
Q&amp;amp;A session so with that let me allow
Chris to give himself a little bit
deeper introduction I'm Chris Davis
direct one of the directors of
engineering at Nike for Nike Plus so you
think Nike you think shoes for a lot of
other stuff too the platform that I've
been working on is everything Nike Plus
so the FuelBand GPS apps choose connect
training that's coming out and behind
all this is our big scalable platform
that has to deal with all this data
there's no sequel wait do any of you out
there in the audience
happen to be wearing a Nike FuelBand at
the moment really ok we gotta get a nike
down to the conference next return and
I'm Randy Stafford I've been with Oracle
for seven years I've had this kind of
bad habit of flipping back and forth
between technology vendors and
technology consumers in my career I'm on
the coherence product development team
and prior to this I was with a company
called Ikey navigator as their chief
architect I've done some publishing
along the way contributed the service
layer pattern to Martin Fowler's
patterns of enterprise application
architecture book and enjoy speaking at
conferences so I also want to
acknowledge
Micke Quinlan who was going to be a
co-presenter here I invited him to
co-present but he had a conflict and
couldn't make it
Mick developed the architecture drawn
here it's it's the only system that I
know of that's using both Hadoop and a
data grid in the same production
architecture maybe is anyone out there
in the audience doing a similar thing
you have Hadoop and the data grid in
production okay so this is pretty unique
this has been in smooth production
operation for three years now and Nick
or Mick was kind enough to sort of
review the outline for this talk and
make sure that it sort of passed his
sniff test
okay so let's get started with the the
context setting I want to just sort of
deconstruct the title of the talk a
little bit and sort of go over no sequel
and relationship to data grids and go
over what we mean by usage patterns what
we mean by enterprise applications so
let's start with no sequel I'm sure
you've heard the term it's probably what
what drew you here so under the no
sequel umbrella there are generally
recognized to be four broad categories
of data management technology key value
stores document stores column family
stores and craft databases and one of
the questions that seems to be on
people's minds or certain people's minds
over the last year or more is where do
in-memory data grids fit how do they
relate to no sequel and I'm prepared to
give my opinion on that here I think
there's some overlap and there's some
difference and I think I've gathered the
same opinion this week from other folks
like Manik sort Ani of JBoss and from
what I've seen of Jem fires chief
architect Jags Ramnarayan
he generally says shares the same
opinion so how many of you have seen
martin fowler's new book no sequel
distilled how many of you are aware of
this
I think this is very valuable I finally
it's been in print for a month and I
finally read it cover-to-cover
it has very good treatment of
the various data models that were on the
previous slide
consistency terminology distribution
models etc so I'm happy to give his book
a plug I think it'll probably serve as a
good reference for the meanings of a lot
of these terms so in in the first few
chapters of the book Martin lays out
what what he regards as the common
characteristics of no sequel solutions
first of all they don't use sequel as a
query language second of all they tend
to be open source they're explicitly
designed to run on clusters that from
the beginning for the most part they
were developed in in the 2000s usually
for large web estates and they are
generally schema-less so he further
points out that none of these
characteristics are definitional and he
says that he doesn't think that there
would ever be a you know perfectly
accepted definition of no sequel so when
you oh and before I go on let me let me
point out that one thing is notably
missing from this list is persistence or
durability and a few nights back at
there was a birds of a feather session
on jsr 347 led by Monika certainiy and I
asked the the room how many of you are
you know how many of you think that a
data management technology must
implement persistence in order to be
regarded as a no sequel technology and
there weren't there wasn't a strong
opinion about that
I asked Manik if he considered in finis
ban to be no sequel and he said yes and
I said does it implement persistence and
he said no or he said yes and I said how
does it implement persistence and he
said well we have a cash store spi so
there's the when you look at the
datagrid products out there there are a
couple of them that implement file based
or this is one of them that implements
file based persistence for its caches
and most of them have data source
integration through a cache store
so I think there's a little bit of a
consensus emerging here and when you
compare the features of or the
characteristics of in-memory data grids
against that list of common
characteristics in an Fowler's no sequel
distill book in-memory data grids
generally don't use sequel some of them
are open source some of them aren't they
are definitely designed to run on
clusters they were definitely developed
in the 21st century the oldest one of
these products is tango solve coherence
now now oracle coherence tango saul was
founded in 2000 release 1.0 of coherence
was late 2001 so the product is almost
11 years old now and the the existing
data grid products are schema less so
then when you look at the data model of
an in-memory data grid and you compare
it to the categories of no sequel
product in my estimation in-memory data
grid products tend to implement key
value store behavior of you know
particularly coherence for example and
they also tend to implement document
store behavior as as described in no
sequel Distilled they don't really
implement column family store
functionality or a graph database
functionality so much but they also
bring some features of their own that
are quite useful and quite distinct from
the other no sequel products they
implement rich eventing models they
implement in-place processing facilities
the analog of stored procedures and they
tend to have data source integration
features such as the cache store
previously mentioned so that's some of
the overlap of the two categories so I
want to move on in terms of context
setting and talk a little bit about
patterns I put I put up here a favorite
quote of mine on on the value of
patterns from Kent Beck this was written
in 1996 he's saying the bottleneck in
software engineering is human
communication and if we can make a word
mean more to more people that that
improves communication there's a
another quote this one from Brad
Appleton Brad's kind of a longtime
figure in the patterns world he's the
author one of the authors of a book
called software configuration management
patterns so if you've ever used the term
read release branch or task branch
that's a pattern that he documented in
that book and it perfectly illustrates
his point if you know what release
branch and task branch means then you
know the name of the pattern is a
conceptual handle for you that allows
you to discuss that little nugget of
information so what about usage patterns
I did want to delve into this a little
bit because we we use the term usage
pattern kind of freely and I tried to
find a definition of it and it's
particularly applicable to software
development and didn't really come
across anything so obviously a usage
pattern is a pattern of using something
and I think we we mean a pattern of
using a software technology in an
enterprise application and more
specifically well-established and and
proven usage patterns patterns that
almost all was you know satisfy the
motivation for adopting them in the
first place and this ultimately leads to
evolution of common practice and so I
I'm a farside fan and I picked out one
of my favorite far side cartoons that
kind of captures this sentiment you know
here's here's a bunch of cavemen holding
pieces of meat over a fire and burning
their hands and then somebody else
figures out to put the piece of meat on
a stick and then you can cook it without
burning your hands I think this is you
know it's very analogous to what's
happening with in-memory data grids
Hadoop etc we're coming up with better
practices for solving problems so
finally a little bit on enterprise
applications this is a pretty old
definition this is from Fowler's
patterns of enterprise application
architecture enterprise applications are
applications that have large amounts of
persistent data concurrent access by
many users for example do any of you in
the room play League of Legends
riot games yes no maybe they have
500,000 concurrent users and their there
number of concurrent users is doubling
every four months and the rate of
doubling is increasing I think that will
end somewhere it'll hit an asymptote but
enterprise apps tend to have many user
interface pages complex integrations
with other systems complex logic
these are Martin's characteristics I
have a few of my own that I like to
throw in a complex domain model heavy
load and transaction volume that you
guys know this you're probably
enterprise application developers
yourselves no surprise here so in
addition in terms of enterprise
applications
I think there's reasonably well accepted
layering models for how they're
architected I've seen it drawn different
ways but I chose to draw it this way I
suppose from the bottom up there's
there's a persistence layer you may have
a layer of domain objects you may have a
layer of services and one of the sort of
newer things to come along with so ax is
an orchestration layer or mediation
layer like you have a you know a
business process management technology
in there or maybe an enterprise service
bus technology in there and then finally
user interface layers on top and I've
drawn a few dashed lines where there's
process boundaries in this stack the
reason I'm pointing this out is because
I'm later will come back and we'll talk
about where the usage patterns fit with
respect to these layering models and
this is actually kind of quaint because
in a real data center what's happening
is there's there's an instance of this
layer stack scaled out horizontally and
there might even be multi-site active
active architectures and so forth so the
complexity has grown in the last decade
since this stuff was first drawn so
that's the context setting and like to
get into the usage patterns now so here
they here they are in terms of how they
fit against architectural layers
obviously you know I think the the birth
of all this is that no sequel and
in-memory data grid technologies have a
a heavy adoption in terms of domain
object storage these technologies are
used to store domain objects near the
persistence layer of an application in
addition they are used for service
response caching and I have detailed
slides on all these of course so either
a user interface or maybe a an ESB or
business process management layer might
call some kind of a service get a
response back cache it etc these
technologies are also used for session
state management this is a pretty common
use case offloading application server
heaps and moving the session state into
a different place so that it can be
shared and and the concurrent usage
scaled and there are a couple of other
less obvious ones that people are doing
work management basically coordinating a
set of workers that are that are doing
jobs and tasks simple state sharing and
I drew these in association with the
service layer of an application because
that seemed like the right place to put
it and finally we're starting to see and
and Chris will talk about this a little
bit we're starting to see examples of no
sequel technology or data grid
technology get used for enterprise
integration in preference to other
alternative technologies that that were
used before so in terms of prevalence
prevalence of both these patterns and
and the motivations for using these
patterns I've made two lists here
there's not any implied correlation
between the list lists of the patterns
by prevalence of usage in decreasing
order and the motivations for using
these these technologies in decreasing
order so just starting on the on the
usage pattern side as we already
observed domain object storage I think
is the top usage pattern for these kind
of technologies the session state
management is the one that I see next
next most I didn't mention in the
introduction but in in my role at Oracle
I'm usually engaged with customers most
of the time in the field so I've over
the last seven years I've gotten to see
a great number of industries a great
number of companies a great number of
projects and seeing what they're doing
and that's how I came up with these sort
of prevalence orderings service response
caching is third and then the other
three work management Enterprise
integration and sort of simple stage
sharing are much less prevalent but on
the on the motivation side most of the
time when when companies adopt these
technologies in a project that the first
reason for doing it is for performance
meaning low latency data access second
second reason and closely related is
scalability horizontally scaling a data
management technology to allow low
latency data access as load increases
third reliability and availability the
ability to survive the failure of a
process or a machine hosting some data
or even survive the failure of a
back-end data source that an application
ultimately depends on and then finally
an interestingly expense reduction
especially with the state sharing and
service response caching usage patterns
customers are finding that they can
avoid calling expensive resources like
mainframes for example or they can avoid
having to scale up database tiers of
architecture to meet application load so
let's drill in on the the most prevalent
usage pattern domain object storage can
I just ask how many of you in the
audience know what domain driven design
is okay a minority I would say so domain
driven design is the name of an
architecture style that was described by
Eric Evans in a book in 2003 it's it's
the architecture style that is kind of
at the core of the object-oriented
tradition it
that domain layer that's in between
services and persistence it features a
model of the problem domain that's
historically been expressed as you know
POJO classes and it's the architecture
style that object persistence
technologies have always been designed
to support things like object databases
object relational mapping layers the
reason these things exist is because
people were doing domain driven design
style applications but interestingly a
pretty recent phenomenon is that the
representations of domain models are
starting to change domain models are
starting to be expressed in XML
documents JSON and it's a fair question
to ask well what what about the behavior
side of things but if you if you ask
Eric Evans what is really the essence of
domain driven design it's mostly about
getting a group of people a group of
stakeholders to use the same language to
describe the the problem domain and the
concepts in it and and share an
understanding of the meaning of those
terms that's really the essence of it
but anyway here here are some important
concepts and I know this is going to be
hard to read for folks in the back of
the room but this is one of my favorite
domain models it's from an airline
operations domain and it has the idea of
a flight and a flight has a one or more
actual flight legs and every flight leg
has a scheduled flight leg and as we all
know if lights get delayed and that's
the difference between scheduled and
actual and every actual flight leg in
every scheduled flight leg has a little
tuple of four timestamps associated with
it when your airplane pushes back from
the gate that's called the out time when
it lifts off the runway that's called
the off time when it lands that's on
time and when it gets to the gate that's
in time and so if you ever had an
experience where an airplane pushes back
from the gate and then goes back to the
gate again like a mechanical failure
that's actually to actual flight legs
each with its own time to bone so on and
airplanes have cruise which consists of
pilots and pilots have trips which are
duty periods and layoffs so it's a very
tangible domain model and the reason I
like it is because it has a lot of the
features of domain driven design there
are aggregated structures existence
dependencies so for example a pilot trip
you know strongly consists of these
other objects and and they would be
created and destroyed together so there
there are examples of value objects you
know a time tuple doesn't have an
identity and it you know if two time
tuples have the exact same state they're
substitutable for each other but
something like a scheduled flight leg
absolutely has an identity it's got a
flight number and a date and all the all
aggregates have an entity as their route
and this becomes really important for no
sequel storage concepts that's why I'm
going through this so it turns out that
there are a bunch of related patterns
for domain object storage I think
there's potential actually for a pattern
language here a lot of times companies
do domain model storage and no sequel
products for for read caching they want
to read domain objects essentially from
other sources store them in a in a data
grid or similar for lower latency access
that this is very popular in in retail
for example there there are a number of
retailers that are using these kind of
technologies to catch their product
catalogs and serve their their websites
faster another related pattern is write
buffering I know of several cases where
companies are generating so much data
that they're exceeding the write rate of
the most capable database stack in the
world that's a full rack of Exadata I
know I know companies that are writing
at a greater rate than a full rack of
Exadata can handle and so they're doing
write buffering in front
of a full rack of exadata event
processing if you have a domain model
cache we have incoming sensor inputs
that that update the state of the domain
model that those are often used in
comparison and Chris will talk about
this or use it in conjunction I should
say grid computing similar you can
execute parallel distributed algorithms
in a clustered data grid technology
there's there's a pattern it's in
Martin's book materialized view you may
have one representation of a domain
model that needs to be projected into
another representation that's
specifically designed for a certain
query and that synchronization of those
two projections can be accomplished with
eventing so that there's key mapping as
well which Chris will get into and then
there are even other topics and patterns
to do with given a domain model how do
you store that in us in a set of caches
or whatever abstraction your your no
sequel technology gives you they they
all have different names for for the
abstractions
I intended to put in a chart that
compared the names to the concept of
like a database instance and a schema
and a table and a row roughly translated
into what a document store gives you
what a key value store it gives you
there are some some correlations and
given a domain model how you map that
into the abstractions that you're no
sequel technology gives you makes a big
difference if you store entire object
graphs together and as one entry or if
you break up every entity and store them
separately and depending on how you do
that mapping there there are
relationship handling patterns and I
know Chris is going to go into this in
great detail there are also some really
interesting transaction management
patterns which are discussed a little
bit in Martin's book having transactions
that only operate on a single key value
cash entry or a single document is is
easy but it's also not really real there
are enough applications out there that
have application transaction
that need to modify multiple things at a
time that you need
atomic commits essentially into these
kind of technologies and that's that's
actually a hard problem so finally there
are some other patterns to do with where
behavior lives now in in this in this
kind of world you have an opportunity to
put behavior into especially a data grid
tier that used to be in an application
server tier and I know at least one
project using coherence that that has
moved the service layer into the data
grid so it's a really rich field in
terms of potential pattern languages
just in the area of the domain model
storage usage pattern the other usage
patterns are not quite so rich but at
this time I'd like to turn the mic over
to Chris and he can give you a detailed
case study on what Nike has done in the
last year with their Nike Plus system
cool thanks yeah so thank you plus if
you guys does anyone does everyone know
what Nike Plus is No
yeah kinda all right well so for those
who don't know Nike Plus is but at Nike
what we call digital sport so about six
years ago we came out with a iPhone app
for runners you could run it'll track
your run on GPS a couple years after
that we came out with a sports watch GPS
watch like a garment but of course I
think it's better because it's Nike and
you run with that and you could plug it
in it would sink and we'd get your GPS
data would show you maps of your runs
and show you all kinds of cool
aggregates and stuff and then a few
years ago let me say what's my right a
few years ago we took took earlier we
had we had millions of users we had a
new product that we wanted to build the
fuel band and we had a bunch of other
ideas and we looked at what we had and
where we
to go we thought this systems just not
gonna scale to be what we wanted so we
started over we kind of got to carve off
a little section as a startup ish kind
of group inside of Nike and we just
built a new platform it was a lot of fun
and learned a lot of lessons along the
way so I'm gonna start with some of the
lessons we learned when we were going
through the salt process kind of the
first thing and you know I'm gonna
dedicate this to Alex in the back of the
room love your domain what I mean by
that it goes back to domain driven
design and your domain model so I saw I
don't know hopefully maybe you guys are
just getting tired seeing the conference
you're like I'm not gonna raise my hand
out you know your domain model is really
really important when you go into
building stuff in a no sequel world now
if you think about you know if you think
about stuff from the database level
first you're probably gonna get it wrong
because this is no no see you really
need to think about your contracts your
domain how are people gonna use this
data not how do I want to store this
data it's that's really key when you're
starting off and then a couple things to
consider about that version
compatibility how you think the system
is gonna evolve like do you know what
you're doing are you kind of putting
something out there for people to goof
off with and you're gonna try and change
stuff as it rolls in production how is
that going to work in the long run
version compatibility of your domain
having a rich domain versus an anemic
domain we'll go into that a little bit
and the serialization I mean no sequel
you're gonna have a bunch of network the
JVM is talking to each other so you're
gonna have to make sure you tackle the
serialization and different different
kinds of no sequel of different types of
serialization so it's something you
really need to think about it front
sequel structured query language knows
equal be kind of really bad for querying
actually
so you want to think about you know we
were thinking about this you want to
make sure you can get your objects based
on their natural keys it almost sounds
obvious but you know it goes back to
don't think about the database first if
you think about the database first
you're gonna fall into the solo I'm just
gonna query for stuff and when you've
got a whole bunch of don't like your
domain objects sitting in this nice
place for super fast access you just
want to be able to get it real fast not
ask like hey get me this some long query
or whatever you want to know exactly
what you want so when you design your
your model you want to you want to think
about that stuff up front and remember
think differently you know I can't I
keep I keep coming back the database
model because we've had a bunch of
developers work on this project and I
don't know how many times oh here we go
back to the same problem people well
I'll query no you that doesn't perform
what we know it so um just because you
have no sequel as a data store doesn't
mean it's a database um you wanna kind
of think differently about this and
think about how you want to get this
stuff really quickly and design for that
so having said that then that kind of
goes into how's your domain model gonna
gonna look you have like the rich domain
versus the anemic domain which is more
of like a rich service model so the two
different so you know since not a lot of
people raise their hands talking about
domain layers the rich domains are
really great if you can get your objects
by key get everything you need in one
big chunk and and the objects know how
to operate on themselves so if you have
some kind of operation that you're that
you want to do with your domain layer if
you build that into the object you can
pull your object out pull it out of your
no sequel world and you know call
methods right off that let it do its own
thing really great if you know what you
want if you've been able to design stuff
to be able to get your objects out
immediately let them do their own thing
the other way to think about it is
having more of an anemic domain
which is good if you need a lot of logic
at the service level so moves your logic
out of the domain maybe it's a good idea
if you've got really frequent domain
changes if you've got a lot of different
views or you have to use builder
patterns to put stuff together maybe
something you think of we experimented
with both and found use cases for each
but it depends on the case you
definitely but it's something you
definitely want to consider and think
about
and one thing that we did a little bunch
of and we'll get into a little bit more
is connecting stuff connecting stuff
together with aspects make stuff easier
to write but the aspect manage the
relationships developers can just write
code put in aspects annotations and you
can abstract your no sequel
implementation now Murli we're talking
about jsr 107 3 4 7 3 4 7 107 so
hopefully soon will actually have a
standard for caching and if we have that
then you'll be really happy you
abstracted your stuff out so talking
about getting stuff by key key objects
we went down the road of actually
creating key based objects and the whole
thought behind it was get everything by
its natural key again we don't want to
have to query our cache we don't want to
have to query the grid for anything we
want to be able to say ok we know we
want here's the key just give me give me
everything in 2 hops because you would
have liked a service of some kind or
your interface or view or whatever go to
your key object get your keys and then
go back and get all of your stuff and
it's ok to have a separate cache for
keys
it's ok it doesn't so
one of the principals Martin Fowler
mentioned is no sequels open-source our
stuffs not open-source so I can't go
into gritty detail but I kind of just
drew up a parallel example we kind of
started like a startup ish so it's time
for a startup company so in kind of a
parallel thing that's a little bit
different imagine you've got users with
profile it's kind of like a force query
kind of thing you've got a bunch of
events the more events you have you can
get trophies for stuff so you have kind
of two different views to look at things
you can either go to go to a user's
profile get all their trophies get all
their events see all their buddies or
whatever and you can go to an event get
all the people that were there get all
the trophies that were accrued there or
go to a marker see all the events there
with that marker so it's like you know
the same data but kind of in a kind of
different view something that's really
easy to fall in the trap of well I'm
just gonna query by event ID or I'm just
gonna query by this ID which kind of
ends up not working so well so one way
to tackle that problem there you know
and if these are kind of your two
different views if you're taking
pictures of this don't go take me too
hard I just really kind of put this
together as an example two different
kind of views to do things either you've
got a user with multiple stuff and your
domain or you've got a marker you know
multiple users multiple events multiple
trophies multiple activities that you
know basically a geolocation or you've
got a user who's participated in
multiple events has multiple trophies
they've been in multiple activities and
they have marked multiple things so one
way to be able to get this stuff really
quickly is have basically different key
based objects that you can get all of
your associated things in like the two
gifts you know going back to this I mean
it's this this kind of get all your keys
and then just get all your objects with
their natural keys so whenever you have
related stuff
if you want to get things by a marker
you can get your marker keys object then
based on your keys in good old
Association if you want to get a view
based on a user get your user Keys get
all get everything back by key by doing
this then you've really avoid having to
run queries we just kind of neat and
then an easy way to manage this so the
keys end up getting populated you know
you define the relationships beforehand
you populate your keys so you can be
able to perform your gets out them
pretty quickly and we designed aspects
essentially to manage the relationship
with the cache so if you're programming
and looking at the domain model you
might have like user dot get events or
something like that and for that we've
got an annotation that basically just
abstracts all that cache stuff out or
you're no sequel your grid stuff so you
can just say you know marker get users
annotated with the cache get our
annotation and then that's smart enough
to know I've got a list of keys here
stored I'm gonna go get my keys and then
go get everything ends up being a really
efficient kind of pattern to get data
really quickly without having to run
queries so that's kind of Keys objects
domain stuff then the talk a little bit
too about something else which is sorry
yeah caching in cache again no sequel is
really really valuable it's great get
data really fast really cool really
great for performance and then kind of
another problem to solve is processing
how do you how do you manage all all
this data like you know we get GP you
know someone goes for a seven mile run
we've got all the GPS coordinates for
the run the FuelBand tracks your
activity all day so we've got a whole
lot of metrics you
this thing in your computer you sync it
to her Bluetooth we've got a lot of data
to crunch and then you take that and you
figure out what achievements you get
what what trophies you might accrue if
there's any events going on special
things for the Olympics all these kind
of things we have to do a lot of
processing on this data if you're
networked in with other people how does
your data relate to that so no sequel is
awesome for doing like grid processing
the data grid kind of stuff asynchronous
processing kind of traditionally you
handle it with JMS or something like
that
need JMS is alright after a while it
gets kind of annoying you have to worry
about your connect I mean you know kind
of old JMS systems really get worse and
worse over time JBoss messaging even
like go with a queue okay a queue that
sounds great I'm gonna do everything a
database yeah and then you're gonna
punish your database with all this
queuing stuff but it's asynchronous
great and you're moving the processing
kind of somewhere else off of the users
path but I mean it's kind of annoying to
maintain so if you have an elastic data
grid you've actually got a ton of
processing at your fingertips got all
these little network JVMs that can do
things pretty convenient especially if
your interface is already sitting on top
of the grid it's really great to just
put something in there and let it do its
thing and new sequel solutions are great
for it process the data where it lives
just scale your grid out when you need
more processing and when it's done you
know this right there I don't have to
worry about the old kind of JMS way you
know application you send it off to some
kind of messaging processor you do its
thing goes back to the database and you
have to reget it later that's actually
really annoying if you have a cache and
you want data really fast because you
know application ones gonna do stuff
it's gonna go to application two it's
gonna process it with JMS to go back the
database if to invalidate your cache
another old way to do stuff is using
stored procedures
for heavy lifting again a pretty big
bottleneck if you've got a lot of data
to process store procedures sound great
man a start procedure next data that's
gonna be awesome mmm yeah you actually
when you process a lot of data there's
gonna punish your database and if that's
your central point of data it's gonna
slow everything else down
so really bad for scale if you have a
grid then it's really great take your
stuff plopping the grid you can scale
your nodes up and down as you want and
you can do your processing right in
there go back to the database when you
need to not a big deal and then you know
kind of a common way to do this you've
got some kind of dispatcher sent it off
you've got a process listener living in
your grid you get your process and
you'll need some kind of job indicator
most likely like if you're sending data
back to your platform it's processing
stuff you're probably gonna have an
interface that actually cares when it's
done to tell the user something useful
and so that's either gonna have to pull
or have some kind of event sent back so
that knows to do something I called it
the done checker probably not a very
great name but that'll get your status
back and then whatever you have whatever
your job indicator does whether that
sends an event off to your interface or
you've got some kind of web service
pulling it or something like that then
you know the process is done and you can
always monitor your know there's lots of
ways to monitor the grid to figure out
if you need to scale or not but ten at
the length of time it takes your job
indicator to change statuses is usually
a pretty good indicator of is your grid
big enough is a processing fast enough
what's it doing
yeah so those are my patterns I wanted
to talk about Thanks so as you saw they
they did a pretty interesting
implementation of relationship
management on Nike+ we kind of went
through it pretty quickly but when you
have a domain model with one too many
and many
many relationships in it and you want to
store it in a no sequel store or
in-memory data grid you have to make
decisions about how am I going to
navigate those relationships from my
application code and there's really only
three ways to do it and I had a just a
pattern name for each you can you can
serialize everything together like a
user and his trophies or you can have a
separate cache or collection whatever
the right term is given the technology
you're using one for users one for
trophies and then you have to have a way
of getting all the trophies for a user
so you can either query the trophies
cache for the user ID if each trophy
knows what what user he's for or you can
have a list of trophy IDs in the user
object and then when you read the user
you get all the trophy IDs and you do a
get all essentially from the trophies
cache and the third possibility is
something like a relationship object
which is kind of necessary for many to
many relationships where you have a
cache of those and and you you query the
cache so what what what chris has done
is they've come up with an annotation
driven way of navigating relationships
where the objects are mapped to
different caches and I know there's one
other user in the room here who has done
a similar thing so these kinds of
problems are emerging and solutions
being invented I have a friend who uses
MongoDB and they they have a similar
problem they have inter document
references expressed as URL and a URLs
identifying related documents in
different collections they have the
exact same problem so we we spent most
of our time on domain object storage
patterns and case study intentionally
because it's the most prevalent usage
pattern for this kind of technology but
I do want to cover some of the other
ones and save some time for Q&amp;amp;A so let
me drill into session state management
this is probably a very familiar picture
to everybody you have a cluster of
application servers with some
applications deployed they have sessions
in them it doesn't really matter if it's
the service pack
httpsession or if it's your own
abstraction of a session you generally
have some data that belongs to the
session and these these can be very heap
consuming depending on the UI framework
you're using it's not unheard of to have
50 megabyte sessions it's not unheard of
to have session state exhausting app
server heaps limiting the number of
concurrent sessions you can run from a
given app server so with session state
management usage pattern what happens is
sessions state is moved to a backing
store and you may still have a small
cache in the application server of small
or frequently used session state items
so the the motivations for doing this
are slightly different than the other
motivations I went through earlier for
no sequel usage patterns in general they
are usually scalability you want to be
able to serve more concurrent sessions
from a given application server instance
than you could without managing session
State in a no sequel store and they also
may include operational benefits
operational efficiencies like being able
to hot deploy a new release of your
application without losing sessions and
we even have examples of companies that
are replicating the session state
between sites that companies running
multi-site active active architectures
and replicating session state between
sites so that a user session may get
directed from one site to another
without any disconcerting experience so
that's that's the session state
management usage pattern there are there
are some performance considerations that
I'd like to point out with this just
just to be candid since you're taking
state that used to be locally accessible
in process and you're moving it to
another process accessing that state now
now costs an inter process communication
and it's going to be higher latency so
yes you can have more concurrent
sessions than the apps
but accessing the state of each session
might take a little bit longer and that
might translate to a slightly higher
response time from the application
server to up to a user interface and it
might also translate to lower throughput
request throughput of the application
server so the the motivation for doing
this is is going to be things like more
concurrent sessions perhaps server
operational benefits and in comparison
to hoping for higher performance from
this so service response caching this is
a very effective we we have some pretty
good examples of this it's a it's a
pattern where a client of a service
checks a cache first to see if a service
response is already in the cache and if
not calls the service gets the response
puts it in the cache and returns it and
then the subsequent requests can hit the
cache this is a classic cache a side
pattern it requires that you're able to
compute a cache key from the incoming
request and it also raises some
interesting invalidation requirements so
for example if you're caching some kind
of a document let's say let's say an XML
document that you got from some kind of
soap service that XML document may have
been composed may have been rendered
from some domain object graph and if any
one of those underlying domain objects
changes subsequent to rendering the
document that means the document is
stale now and so you have to keep track
of the dependencies of documents on
objects so this can actually be done
with a key value store you can have a
cache in a key value store where for
each domain object you're keeping a list
of documents that have been rendered
from that domain object and if a domain
object happens to change you can go to
this list of documents and invalid
the documents cache the service response
cache for all documents that depend on
that domain object I know a retailer
right here in San Francisco that's doing
this to purge Akamai they they it's not
they're doing it with web pages that
have product inventory on them but when
product inventory changes they they go
purge Akamai of that webpage and they
they're keeping track of what pages
depend on what product inventory objects
with a little cash like this we have a
customer in the hotel reservations
industry who is doing this with hotel
availability queries and their their
their clients are Orbitz Expedia kayak
etc etc so that their their position in
their in their industry value chain
their system is just getting hammered
with hotel availability queries all the
time and if they have to call a back-end
central reservation system to get the
answer to an availability query they
cache the answer and the next time same
availability query comes they can return
it from cache and that their capacity to
do that is directly related to their
their performance as a business so
that's service response caching it's a
very simple usage pattern but very
effective in in some situations finally
work management this is a more rare but
some good examples you can use a a no
sequel store or a an in-memory data grid
to basically coordinate a lot of work
and coordinate passing jobs to workers
holding the inputs for the job capturing
the outputs from the jobs so this
diagram is actually from a coherence
user that has a farm of about 1000 1500
worker processes that are that are doing
analysis of variance computations and
they have a pretty small cluster of
coherence
a couple of applications servers that
OnCue jobs and when a job is on queued
these worker processes compete to
consume it one of them gets it does the
computation puts the results back and
then competes to consume the next one
these guys are executing analysis of
variance calculations at a rate of
several hundred per second with this
architecture and it's a very large
deployment of coherence extend clients
so this is one of the more advanced work
management use cases that that we know
of and that's I think the the end of the
the usage patterns I'd like to just go
back and for memories just a jog our
memory show you the whole list again so
we went through a little bit of diagram
a little bit of example of every one of
these except enterprise integration and
this is what we have seen emerge in the
last three to five years working with
in-memory data grids and no sequel so at
this time I'd like to open the floor to
questions we have about seven minutes
left in an hour
any questions any comments out there yes
the what
sure
sure so if you're familiar with Gregor
hope and Bobbie Wolf's enterprise
integration patterns book they describe
a pattern and they're called competing
consumers it's based on an older
messaging paradigm but within them when
a message is published consumers compete
to consume the message and the first one
that gets it does whatever the message
entails so in this case the workers are
notified of a job awaiting execution
through an eventing model it's not
messaging it's it's a eventing feature
in the in-memory data grid so all the
the workers are JVMs and they all get a
notification of a job insertion into a
queue and they all attempt to claim the
job concurrently and only one of them
wins and when it wins it changes its
state from idle to busy and proceeds to
execute the job and then when it's done
it caches the results and changes that
state back from busy to idle the
question was just could I elaborate on
the the worker processes so these are
these are java virtual machines running
in a sun grid engine deployment and
they're sort of dynamically started and
masse and that this this company is now
getting into predictive provisioning of
how many worker processes they'll need
based on sort of upstream indicators of
the amount of work that's coming yes
yes this company reported at open world
on Monday or Tuesday that they are
getting nine times more throughput with
this architecture than they've ever
gotten before I think it's the the
ability to pass jobs and associated data
to and from the workers faster via data
grid than they could via a relational
database no go ahead
but most most data grids are are in
memory I mean the the the it's basically
network speed instead of potentially
disk speed
yeah I mean one of the things that
Martin's book describes in in really
good detail is that is the concepts of
replication and quorums so most of these
kind of technologies are our failsafe
think they can survive the failure of a
process or a machine by having enough
replicas elsewhere in the cluster that
if there is a failure that the data can
be accessed from just one of the
duplicate locations let me move on to
your question well actually let me let
me jump in real quick on that because
yeah no but it's a really good point
because it is possible it is possible to
bring a whole grid down it is great to
have like the redundant JVM so you know
one goes down if you got like I don't
know 100 when it goes down you've got 99
they can rebalance and you're cool but
if something goes catastrophic way wrong
and you're in you know it is possible
that if I mean if your system is
designed to always just get data from
there it really had a single plant there
so I mean if you're designing large
systems it's always good to keep in mind
you know what happens if this goes down
do I have a fallback
maybe performance will suck if I just
hit the database but is that still
possible to do in your architecture so
it's a good call
yeah in terms of operating these kinds
of systems not everyone has to be
continuously available but Chris for
example they want their application to
be continuously available and there are
there are certain events that currently
require a cold start at at least let me
speak specifically to coherence now
changing upgrading a major version
upgrade of coherence requires a cold
start most other things ideally could be
done with rolling restart we it's also a
very common practice to do Bluegreen
deployment if you're familiar with that
if you it's on Martin Fowler's blog it's
basically the idea of running two silos
and bleeding traffic between silos
that's that's probably the most common
approach to continuous availability that
that I've seen go ahead
so if you go by martin fowler's
definitions of key value stores its key
based access only and document stores
have query features that know how that
know something about the content of the
document so to speak and so i don't want
to imply that all no no sequel
technologies have any query capabilities
because no sequel technologies do have
query capabilities but i think one of
the hard problems is the query
capabilities are not designed to join
like join documents across collections
of documents join values in a key value
store across different caches so there
are there are emerging other
technologies that can do full sequel
join type queries against a relational
database and still attempt to leverage
the benefits of caching for example
there's a hibernate grid that's starting
to come out Oracle's had a top linked
grid out for a few years that it's
basically the integration of object
relational mapping and in-memory data
grids so the it's a JPA provider that
can can query the cache when when when
possible but if the query is too complex
it'll delegate the query to the database
and then and then put the results in
cache so there's a there are quite a few
usage patterns there that are kind of
beyond the scope of this talk or the
kind of narrower focused in this talk
and it's also possible to have like a
habit cache with your relationships kind
of pre-populated into it so if you need
to join you know different caches if you
have you can have a separate kind of
cache that has the relationships between
the caches so you can still kind of do
that key pattern use it to make sure
it's built into you know all those
relationships are kind of built
to your domain mom I know that kind of
in our implementation querying was
really bad I you know doesn't mean it's
always bad I personally don't like it
because I it's causing me personal pain
but I mean if there's definitely
querying that you need in your
architecture every of course every case
is different I would try there are cases
where you know we use the database for
specific things and we just try to make
sure we you know I don't want to say it
contain it or isolated but you know
design in such a way where you know we
maybe just don't need it for really
really fast access of things especially
when the systems under a lot of load
that typically is our biggest bottleneck
so I think there was someone in the back
of the room yes I'm trying to go on
order I was not able to hear the
question ah yeah yes so that that
introduction slide the question was what
was the problem that was being solved by
the architecture that featured Hadoop
and a data grid if I if I understand you
correctly yeah
so that particular company had to do
they had to do a big data computation
job and then cache the results of the
computation so um I'll describe just
quickly about what that web application
did so if you want to go find out who's
been searching for you on the Internet
that's that's the answer they were
providing so like let's say let's say I
go do a search for Chris Davis and you
and you go do a search for Chris Davis
and we happen to know that he lives in
Portland and he's you know thirty years
old or whatever so a bunch of us do a
search for Chris Davis and now now
tomorrow Chris Davis wants to know you
know who's been searching for me well
that what Hadoop is doing is it's saying
all right I had a hundred searches for
Chris Davis who who were all the
searchers so that that's that's the Map
Reduce problem for every person that was
searched for give me all the searcher
that were searching for them so that
what they were cashing in in in the
datagrid was a who searched for you
record so if Chris logs into this web
app tomorrow and and says who's been
searching for me he the who searched for
you records are are cached so that that
was the that was the problem they were
solving so I think if you have a massive
computation job where you want the
results of the computation to be quickly
accessible that's the justification for
that architecture you had a question
question was does Nike have a
sophisticated approach for key
generation we'd you have it
well well for key generation all of our
keys are goods and yeah so what we do is
kind of behind all of our objects you
know at some point we have to go back to
the database to get stuff to bring it
into the cache anyway so we do have like
basically we've got key objects that
manage relationships and we've got
relationship caches that manage
relationships so we can always go back
you know if you think about kind of
users and events every time a user does
something it can be categorized as event
all kinds of stuff I went for a run and
made a friend I've got a trophy all this
stuff lots of events users and then
they're all related to different things
so I mean we've got a cache that
contains relationships just between kind
of different objects so if we've got an
object key and we want to say I want
users to events I can just go to my kind
of relationship bucket and say okay I've
got this key what are all the
relationships and then use that to get
corresponding caches and the case where
and that's if things aren't or you kind
of lump together so the session ended
five minutes ago I think we should cut
it off and release everyone to happy
hour thank you very much for attending</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>