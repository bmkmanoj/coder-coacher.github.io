<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Oracle Cloud Infrastructure Fundamentals - Lesson 06 - Load Balancer Service | Coder Coacher - Coaching Coders</title><meta content="Oracle Cloud Infrastructure Fundamentals - Lesson 06 - Load Balancer Service - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Oracle Cloud Infrastructure Fundamentals - Lesson 06 - Load Balancer Service</b></h2><h5 class="post__date">2018-01-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uQXeSv9NffA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everyone thanks for joining us today
we are going to talk about Oracle cloud
infrastructure load balancing service in
this lesson we will talk about the load
balancing service and its core concepts
we will also take a brief look at how a
public load balancer is managed within
the Oracle cloud infrastructure so
Oracle cloud infrastructure load
balancing service provides an automated
traffic distribution from one entry
point into multiple back-end servers in
your virtual cloud network
this helps to load balanced large
amounts of traffic which could overwhelm
a single server it gives a mechanism to
scale out an application tier by adding
more servers and also provides the
application layer availability so even
if one availability domain has an issue
you can still be up and running in other
availability domains load balancer is a
regional service load balancers always
come in pairs active and passive and the
public load balancers live in two
separate availability domains providing
high availability with no single point
of failure the Oracle cloud
infrastructure load balancer supports
TCP and usual HTTP protocols as well
HTTP to HTTPS akut supporting things
like data compression server push
multiplexing of requests all of these
features are come supported for security
purposes it also supports SSL offloading
SSL termination SSL n2n and SSL
tunneling let's talk about some of the
key differentiators for the load
balancer service 1 we can deploy the
service either as a public facing
whether a listener is running on the
public IP and the back-end services
servers or on the inside we could also
use the same service to load balancer
within the to use to load balance within
the OCI within the Oracle cloud
infrastructure between tiers keeping it
entirely private another nice feature of
the Oracle cloud infrastructure a load
balancer
says you get a public or dedicated IP
address you don't have to worry about
getting a cname and dealing with that to
use this service the listener listens on
that service port on this IP address and
it is mapped to the user's Oracle cloud
infrastructure tenancy the load balancer
comes in three different sizes 100
megabits per second 400 megabits per
second and 8 gigabits per second these
sizes are for aggregate throughput the
nice thing about having this much
capacity praveen is it's always
available to the user
there is no warmup period when using
these shapes this aggregate throughput
performance is always available and
lastly there is a single load balancer
for HTTP and TCP protocols so this just
makes things easier to use in general so
let's move forward and discuss some of
the load balancer core concepts and how
the load balancer service works so there
are two kinds of load balancers that are
available in the Oracle cloud
infrastructure public load balancer in a
private load balancer let's talk about
the public load balancer first when you
create a public load balancer you select
to availability domains for the load
balancer to reside in for instance in
this case the load balancer resides in
availability domain 1 and availability
domain 2 because Oregon or
infrastructure is going to create two
copies of the load balancer to make the
service highly available you need to
have two subnets when you are creating a
public load balancer for instance in
this in this case subnet 1 and subnet 2
are the two subnets which are used while
creating the public load balancer the
public load balancer sits at the edge of
a virtual cloud network what happens
next is that there is a primary load
balancer selected automatically to hold
the public IP and a secondary load
balancer in an active standby
configuration this is completely
invisible to
user there is no requirement or
capability to designate primary or
secondary load balancer next we have a
listener this is the public IP address
and the service ports that are open up
to sit between the internal internet and
your back-end service in case one of the
availability domain goes down the
listener will fail over to the other
availability domain automatically and
when we see a dotted line up at the top
will be the new path for the traffic
this high availability is built-in the
user doesn't have to manage that high
availability remember there is no way or
reason to change which load balancer is
acting as the primary load balancer it
is all banished by the service itself
and it is completely invisible from the
user perspective now let's talk about
the second type of load balancer which
is the private load balancer for private
load balancer the implementation is a
bit different because in case of a
private load balancer it's it's trying
to load balancer traffic all within the
Oracle cloud infrastructure within the
private load balancer instead of two
copies of the load balancers going to
two separate availability domains the
private load balancer has both the
active and the passive load balancers in
the same availability to main that is
why when you are creating a private load
balancer you don't need to specify two
different subnets you can have a single
subnet which has both the active and the
passive load balancers present in the
same availability domain in same subnet
this does mean that if the availability
domain goes down or has a outage on the
availably domain the load balancer will
have no other way to failover having
said that let me clarify over here that
other than this particular difference
all other capabilities of the public
load balancer and a private load
balancer are the same and
touch upon some additional concepts in
the next slide all of those concepts
will remain the same for both the public
and the private road balancer all right
so let's talk about some of the concepts
of with when you are creating a load
balancer these are some of the
components that you actually are
creating so number one is the backend
server so with any load balancer we need
to have a back-end server it's the
actual application server which is
responsible for generating responses to
any incoming requests like HTTP or TCP
traffic etc and generally with the load
balancer you would want to see two or
more application servers or back-end
servers per availability to Main Aur
subnets being load balanced - so in this
case you can see that there are back-end
servers in subnet 3 and there are two
back-end servers in subnet 4 within the
given availability domain or subnet you
can have a back-end set this would be
the servers in that availability domain
that are available to answer the
incoming requests which are coming up at
the on the listener of the load balancer
pakkun sets are logical entities that
simply contain a list of available
back-end servers and a corresponding
health check policy and the back-end
sets can have like an span across
availability debates so just like in the
example given there is a single back-end
set which has 4 back end servers which
are span across two different
availability domains in two different
subnets so it's completely open from
that perspective that you can have back
and set which has availability servers
which has back-end servers across
multiple different availability domains
within each back and set you also need
to define a load balancing policy which
is how the next server will be chosen
this can be based on IP hash mechanism
leased connection and weighted round
robin
the IP hash policy using an incoming
uses an incoming request source IP
address as a hashing key to route
non-sticky traffic to the same back-end
server the load balancer routes requests
from the same client to the same package
server as long as that server is
available this policy honors server rate
settings when establishing the initial
connection which actually you provide
when you are creating a back-end server
you have the ability to provide the
particular wait settings to each
back-end server that you create IP have
any assures ensures that requests from a
particular client or August directed to
the same back-end server as long as it
available now one thing to like remember
in in high P hash policy is that
multiple clients that connect to a load
balancer through a proxy or NAT router
might appear to have the same source IP
address so if you are choosing the IP
hash policy for your load balancing the
load balancer would always probably see
the data see the traffic's coming up
from the same ip address if the clients
are using some kind of a proxy or NAT
router and in that case the the traffic
would always be routed to the same
back-end servers as well so these things
are supposed to be considered when you
are designing the policy on the load
balancer the next is the least
connection policy least connection
policy routes incoming non-sticky
request traffic to the back-end server
with the fewest active connections this
policy helps you maintain an equal
distribution of the active connections
with the back-end servers you can assign
a weight to each back-end server as well
just like you could assign a back weight
in the case of IP hash connections which
can further help you to control the
traffic distribution now again in TCP
use cases a connection can be active but
have no current traffic such connections
do not serve as a good old metric as
well so we should keep that in mind as
well when we are choosing lease
connection policy for our routing
policies
the third is the round-robin which is
the default load balancer policy this
policy distributes incoming traffic
sequentially to each server in a
back-end setlist after each server has
received a connection the load balancer
repeats the list in the same order it's
a very basic and simple load balancing
algorithm it works best when all the
back-end servers has similar capacity
and the processing load required by each
request does not vary significantly
alright so moving further there is also
health check policy to check the backend
servers and make sure the services are
up if the services has failed for the
parameters in the health check policy
the backend server will be removed until
the service returns another basic
concept is the listener concept which is
a global entity bound with the local
load balancers IP address on which will
be create the virtual load balance
service so these are the top like the
basic five concepts that you need to
keep in mind when you're creating a load
balancer and at the end of the deck when
we actually go through the process of
creating a load balancer you will see
the different components like a back-end
server back-end said health tracks the
listener and the load balancer policy
all coming up together to help you in
creating the load balancer one thing to
remember here is that that though a
private load balancer has both of its
active and passive entities in a single
availability domain it doesn't mean that
the back-end servers can't be in all
three availability domains so just like
we talked in the previous slide the all
the components on this one like the
back-end server back-end site and all
those are completely same for the
private load balancer and the public
load balancer so in in in the private
load balancers case the back-end servers
can be in all three availability domains
there is no limitation to that as we
discussed before again there are three
shapes available for the load balancing
service the sizes are for ATK
capacity and you can also see the
scaling SSL handshakes in each shape so
there is a hundred megabits per second
shape 408 gigs shape as well so let's
talk about the some of the protocol that
is supported by the load balancing
service so in case of a TCP load
balancer the load balancer deals with
the delivery of messages only so with no
regard to the content of the message so
basically it's layer 4 in case of an
HTTP load balancer it operates at a
higher application level layer we
support like SSL termination and
end-to-end SSL tunnels for both the TCP
load balancer and the HTTP load balancer
once again the traffic the traffic
shaping policies like round-robin lease
connection IP hash both are supported
for both load balancers like HTTP and
TCP you also have the ability to mark
some of the back-end servers for backup
drain or offline so if you mark your
back-end servers as backup the load
balancer forwards ingress traffic to
this back-end server only when all other
back-end servers not marked as backup
fail the health check policy this
configuration is useful for handling
disaster recovery scenarios you can also
mark your back-end servers to drain that
would mean that the load balancer would
stop forwarding the new TCP connections
and new non-sticky HTTP request to this
back-end server so an administrator can
take the server out of rotation for
maintenance purposes and the third is
the that you can also mark them as
offline so the load balancer just
doesn't forward any ingress traffic to
the back-end server because it's marked
as offline and these markings are again
available for both kind of load
balancers you can do the same with this
eb you can do the same with HTTP as well
in case of the
HTTP load balancer we also support
x-forwarded-for which basically allows
the back-end server to learn the IP
address of the original client in case
of health checks so for HTTP the health
check can check for the server response
codes and I use the regular expression
to look for a match in the body content
and with case of TCP we have the simple
ping based health checks okay so the
load balancer health check API this is
one of the kind of a new features from
the load balancing team the
non-financial service provides health
status indicators that use your health
check policies to report on the general
health of your load balancers and their
components so you can see health status
indicators on the console list and
details page for load balancers back and
sets and back-end servers you also can
use the load balancing API to retrieve
this information there are four levels
of health as indicators as shown in the
slide they are okay
warning critical in unknown us and the
health check API is available for the
load balancer back-end servers and
back-end sets so these four different
health status indicators are different
have a different have kind of a
different meaning meaning for each of
the component that you use against and a
detailed meaning of each component for
each different resource within the load
balancing service is available on the
documentation side some of the current
mutations which I should mention here is
that health check is operated after
every three minutes
there is no fine granularity available
right now and it doesn't provide it does
not provide any historical data so let's
take a look at how a public load
balancer can be created and what would
be the example configuration of a public
load balancer so to create test and
create and test a public load balancer
first of all you navigate to the
networking console within the within the
Oracle cloud infrastructure console page
within the networking console you click
on the load balancing service and when
you are and then create a load balancer
when you are creating a public load
balancer you need to provide the name
the shape again from a shape perspective
you can choose either 100 400 megabits
per second or 8 gigs per second then you
choose the virtual cloud network that it
is associated to and within the
visibility area you can choose what kind
of load balancer is this is this the
public load balancer or a private load
balancer here we are actually showing
the reactivating a public load balancer
since it's a public load balancer it
would have two subnets that it needs to
create the reason is that for a public
load balancer like we talked before it
needs to have a it needs to have two
different subnets because two different
two separate Pub load balancers will be
created where in active passive modes in
two different availability domains so
that two subnets mentioned over here the
load balancer subnet one and the load
balancer subnet two are present in two
separate subnets in two different
availability domains and then you can
click create to get created to create
the load balancer once we have created
the load balancer you first of all
create a back-end set in a back-end set
you have to provide the name policy
whether you want to use SSL and then
what kind of health check API that you
want to use
once you have created the backend set
then you can create back-end servers
within that back and set
now again back-end servers can be across
availability domains so within the
backend server you need to provide the
instance the port that it needs to
connect to and any weighted to the
policy that you have already set up for
your back and set the server's can be
across the malleability domains
completely open from that end once you
actually go through this rules are also
added automatically to the different
security lists between your load
balancer and your back-end server and
there would be a list of security list
rules that are being added and you would
be given an overview of those as well
once the backend server and the backend
set is also created you go on and create
a listener in case of a listener again
you just provide a name and then a
protocol which kind of load balancer is
this the port that it's listening on and
if you want to use SSL for security and
then associate the listener to a
particular back-end set which you have
just created once this is done your all
the steps required for creating a public
load balancer are completed you need to
just go to the public load balancer
subnet security list to allow the
internet traffic on that on that
particular subnet of the load balancer
so that the listener of load balancer
can receive ingress traffic from the
internet once done once done you can
verify the weather in public by the load
balancer works at this stage you should
also take a look at the security lists
of your lower balancer and the security
list of your back-end servers so that
you get to know what kind of traffic is
being allowed between them when what
kind of traffic is being allowed from
the Internet towards the load balancer
and from the load balancer to the
back and said this will help you
troubleshoot in there any issues on your
load balancers back-end sets or back-end
servers one thing to mention what here
at the end is that we have talked about
different load balancers both you
private or a public load balancer but we
use the same API or the CLI to create
both kind of back-end servers there is
no difference in the API or CLI
perspective so that's about it this is
these this page actually gives you a
quick summary of what we have learned in
this lesson and thank you for joining us</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>