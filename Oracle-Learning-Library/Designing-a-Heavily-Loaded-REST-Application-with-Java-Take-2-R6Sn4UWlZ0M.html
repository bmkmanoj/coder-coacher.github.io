<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Designing a Heavily Loaded REST Application with Java, Take 2 | Coder Coacher - Coaching Coders</title><meta content="Designing a Heavily Loaded REST Application with Java, Take 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Designing a Heavily Loaded REST Application with Java, Take 2</b></h2><h5 class="post__date">2013-02-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/R6Sn4UWlZ0M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you for coming to our presentation
its name is designing heavily loud
addressed applications in Java take two
so either is here anybody who was on to
take one last year no that's great
because it's really new for you now I'm
kidding we editing new things through
old presentation and we want to share
the findings that we found during the
last year with you so my name is Luca
Kasich and I work as a quality assurance
director in our software this is spinach
like hurt and he works in us too he is a
java architect and he developed and
designed most of this service that we
will show you today and the last but not
the least yeah cupola shark from the
Oracle check team and Yaqoob works in
the jersey theme in Prague Jack sorry ok
so what's on our what's on the agenda
for today so at the beginning I will
show you the service how it looks like
from the user point of view to put it
into the context to see how many users
we have how many clients are connecting
to the service and what it actually does
then spinning we'll talk about the
design about the architecture of the
service about things that we had to
solve on the way to design this heavily
loaded rest application and at the end
Yacoub will show you how we edit Jersey
the jax-rs to the to our application and
how it helped and what is it good for so
I most high-performance services we are
from a vast I don't know if you know
about I was is the other software's
provider of avast antivirus and this is
the most widespread antivirus in the
world and to let me take your attention
I wake you up after the lunch I prepare
a quiz question for you and you can get
the nice Parker Pen over there no no
this is not Park Rosario come on that's
over there is Parker okay healthy and
the question is how many users or how
many users does the others have it's a
million so how much hundred thirty
millions no it's more no 161 it could be
today in my presentation is 160 so this
is yours and you can stop by we have
some other goodies for you so what a
service that we created in a vast ass as
you probably know the most attacks to
your computer comes when you are
browsing the internet so when you are
browsing some innocent websites that has
been infected your computer the true 250
exploits got infected too and the bad
guys are stealing the passwords and
credit cards and everything so we were
thinking it was how to improve it
improve the user experience to like to
warn you that you are on a bed side or
on the side with the bad reputation and
we created a plugin for the most common
browsers and this plug-in is actually a
client of the web service which is
sitting in the back end so let me show
you how it looks like ah
forgot to mention one thing when I
started in a bust two and a half years
ago I was very surprised that the
technology that is used to most by the
cyber criminals to explore your computer
is actually Java so good to know so how
the client looked like so this is the
common browser I think it's chrome and
you can see in the small icon over there
and it's green so its signal izing that
the website that you are on is fine it's
okay and it has good web reputation in
our in our database and I said that its
web reputation because the users can
vote also so they are involved in the in
the data gathering can we mix it
together with our data that we that we
have about a website and then we provide
information for users and also you may
be mentioned you may be noticed the
icons in the search results so you know
before before visiting the website
before clicking the hyperlink what's the
reputation of the side or the URL so i
would look behind the curtain ah ok that
was the service from the last year this
year we have a special service that we
will be used for the measurements and
for the for the jersey and so on and
this is a new service of a vast and it's
fishing so when the principle is the
same when you go on a fishing side we
warned you we show you this nice
dialogue that you shouldn't go there
that the website seems suspicious and
they it probably only pretends that's
your bank and they will steal the
credentials for him so now what's behind
the curtain so we have the browser and
the browser is sending the request to
the web application in back-end so it's
like get writing it's like
it's the reputation of the website
sending the water of the user get the
world that you already submitted and
also get a fishing study further of the
of the domain also there are some
responses but the thing that I want to
emphasis on the side slide is that we
are answering 100,000 requests per
second you can imagine we have 160
million of users and their load is like
really huge and in the database we have
hundred millions of record so you can
the web service require some tuning and
really must perform really really well
because you don't want to wait for the
response minute because you want to
browse the internet right so that's how
does that's how the service looks like
from the user perspective and I will now
invite spinach to continue with the
architecture ok so in the beginning I
have to say that developing this
application wasn't very easy to easy
task for us and we were a challenging
challenging a lot of problems in the
beginning so let's begin by describing
the original application there are 16
notes and each node consisted of both
application node application instance
and Cassandra instance so the coins were
connecting to the 16th notes through do
the prep plug-in installed in that
process and this began this plug-in
about sending json messages to these
servers a wrapping URL under
investigation the plugin was sending
that is urls to one specific domain name
covering 16 IP addresses the local
domain res / monster solving these to my
name it into into one of these 16
addresses so it provided us with a
simple
I don't repent around the winner
advancing because the Cassandra
instances were communicating on another
through the backend network
unfortunately this design didn't work
well for us we were I think two main
problems the first problem was that
there were two too many open running
threats and the CPU was very busy by
because of the huge context switching
also the other the other problem was
Cassandra end is its network performance
because Cassandra was busy by a huge
number of reads and also by by internal
communication among the notes so let me
illustrate the problem on a dis triangle
where each corner represents one of the
three main computer computer resources
the CPU input of the operation like this
and network communication and memory
each point in this area represents an
applications consumption of one of the
three of these three resources so the
original application could be put on the
edge between CPU and I 0 because it was
very busy by because of the context
switching and CP 0 wooden fence if you
had to do a lot of work and although it
was quite I or intensive because of the
reads the diff number of reads and
because of the communication among
between between two nodes so our task
was to was to do some optimization the
first optimization was to ink to
decrease the cpu utilization and the
second the second one was to to reduce
the number of i/o operations reducing
cpu cpu utilization was done by was done
by using even driven a synchronous
request processing instead of
the previous one which used the model
where each request was processed by one
thread now in the new morality we use
one thread for processing more
connections I'm going to speak about it
right wrong reduce or limiting the
number or reducing the number of i/o
operations was achieved by during array
application and aunt Cassandra and
Cassandra now runs on a separate note
and the number of this nose is less than
then the original set up in the original
set up it also frees the memory and we
could use this new newly free memory to
caching so now we use cheapest cable
distributed cache and we read a lot of
requests from responses from this cache
and just we reduce the number of of
reeds so now directs Directorate
rectangle represents the new new new
architecture on the new application and
now it is closer to memory because now
we are we use the chain post cash and it
it needs it requires some memory and
this is the new the new architecture and
you can see that the number of
application now and also remains the
same but there are two new nodes running
Cassandra and as the number of Cassandra
knows is lesser than then it was it also
results in in in a better internal
communication between thinkers and
journals and on this graph you can see
the dell do load on a note from from
from the application notes and it it's
sine waves like shape corresponds to two
daily usage of internet so it
corresponds to users how they
how they are connecting to the internet
during the day so the upper graph
represents shows the number of requests
requests executed or performed a second
so you can see that we could reach the
15,000 limit of operations of requests
per second and the D lower the lower on
the lower graph shows the utilization of
CPU so it is about five fifty fifty
percent of utilization so it's it's okay
okay so now I would like to say
something about about the options that a
Java programmer has today if he or she
wants to program high performance
applications so there are basically
three options java ee orgy home or g2e
because of Roman version 6 there is
support for a synchronous HTTP request
processing as well as for a synchronous
call invocations of EGP methods in
version 77 there is a there is a good
very good improvement in jax-rs to 2.0
because now just RS supports also a
synchronous processing yahoo polish i
will cover this topic right on on the
opposite side in terms of complexity
there is a java niño API but the
downside of this of this application
interface is that it is quite low low
level and it requires a lot experience
from programmers so it is quite prone to
making errors by inexperienced
programmers and the third option is
moving one of Joe and I of frameworks
which is something in between low level
Java niño and the high level Java EE so
if you want to if you want to perform
some signals signals operations and you
do not you do not want to use the high
level API of HR EE you can choose among
these and I offering works so for
example now you can use meta grizzly or
apache mina what Nina is quite obsolete
now I think okay so now let me explain
how this and I of frameworks basically
work by opening the abdomen and looking
into their guts the pivotal point of of
any niño framework is an IO selector
this selector is responsible for
registering the open open channels for
connections and emitting events and each
of these events represent some for
example for example man attempted to
connect to the server or two or some
indication that summer some data are
available for editing or that the
channel is ready for for writing data
there are also two to three pools the
first pool is called both pool and the
second one is called worker thread pool
the boss who is responsible for
wrestling at applications tcp/ip port
and it acts it is accepting incoming
connections the worker pool is
responsible for for the business of of
the application it receives it is
responsible for writing and preparing
for a reading from channels so the whole
system works like that a threat from the
boss pool opens a server side socket and
this server side socket is registered at
this niño selector and the boss the
boss head starts playing the selector
and while an event is available in this
sector the boss takes it and perhaps it
drops it into an internal representation
of the connection and passes it to one
selected threat from from the worker
the worker takes the new digital open
connection and register it at BNI Oh
selector for read and variety events and
also it starts pulling this selector for
the events writing to the new the new
channel any threat from the worker pool
takes care of more threats of paper
don't know more connections also the
size of the pool is fixed typically the
size of the of the threat or the number
of the threats in the network of thread
pool is twice as many as the number of
CPU cores similarly similarly the the
size of the possible is also fixed
typically the number of threads running
in the pool in the post pool is equal to
the number of ports at which the
application is listening while okay when
when the death threat working that
except some some event for example read
event from the selector it perhaps it
into a message and this message is sent
to one of the of handlers of request
handlers attached to to to the worker
thread and this thread this handler is
responsible for performing to business
logic relating to do the message an
attention must be paid when handling
requests performing blocking IO
operations because the worker thread is
waiting until until the hunt the handler
finishes processing the request so
during during the hunger is processing
the request the worker thread is unable
to process possibly other other events
waiting in the selector so it is very
different it is very important not not
to block the work of thread a long time
so for example if so the picture shows
the situation where we're 22 threads
from the whirlpool are processing short
short lasting short-lasting events
violet the third one is processing some
or is performing some possibly blocking
I of operation so if it happens it is
necessary to to separate the logic from
the worker from verb from the handler
and / from this logic not on or not in
the worker tool worker thread but in a
in a threat originating from another
thread pool so on this picture you can
see a new a new thread pool and the
blocking operations are performed
performed by one thread from this new
new thread pool and the community
communication between the worker pool
and between the blocked work of that
pool as i call it is is mediated but by
the task you so also in contrast to to
the work of thread pool the size of the
new blocked worker thread pool is
typically flexible because the threats
inside this this blocked for the pool
does not almost nothing so it doesn't
use cpu a lot because it just waits
until the blocking operation is done so
the number of of the threats that are
running in inside this this red bull can
be quite larger ok so that's all what I
wanted to say in terms of an i/o
operations blocking operations events
and the architecture and now i'm going
to pass the mic to do a group which is
who is going to talk about Chuck's RS
thanks for coming so now if the neck
didn't convince you that you don't want
to ride
it's such a code I will try to show
something to kind of motivate you why to
not not go this way so here what you
cannot see but you have an idea how it
works in low-level world this is a not
not complete source code of handling
just single HTTP method they put vote
put vote operation so it didn't fit into
the slide even if the foundation is
small so not only that I was guys had to
spend quite a lot of time with
developing the solution the code is not
you know really well suited for further
maintenance so just to wrap up what we
have seen so far so about the low level
and IO code it performs great if you
spend a lot of time a lot of energy you
will end up with a solution which
performs great no question about it so
you don't need that much infrastructure
you save some money there but at the
same time this is silly something hard
to write it's hard to read it so if you
I don't know how a new developer to
understand what the code does is silly
it's not a simple simple task to
understand the code and it's a of course
hard to maintain so it takes out of time
to deal with a low level solution to to
make it right to make it work for you
and it's it's really easy to make
mistakes so what else can you can use
so this slide depicts what's available
currently in Java EE world this is about
java ee 6 so there is a jax-rs standard
API for writing rest web services so who
never seen jax-rs code mr. easier and so
we are probably quite familiar with with
jax-rs jax-rs one dot one is part of
Joey six this several implementations
available so the API is quite popular
it's widely adopted but unfortunately
the synchronous support is missing from
the adi so if you want to write a
non-blocking code that's not possible
with a standard API so would we did last
year during the ball I wired jersey
dress is a reference implementation of
jax-rs I I've added directly into the
low level stuff that I was guys put
together and it helped us to to make the
code more readable so the infrastructure
was still there of the niño code but I
i I've wrapped Jersey directly into it
and we good something chose that better
to maintain at least and also the
measurement shown us that we didn't get
any penalty in performance point of view
so the solution still performed really
great so now I just updated the slide
because last Friday the new jax-rs
version 2 dot 0 it entered the public
review stage so it's still working
progress but it's being finalized and
the
to be part of java ee 7 so you could get
some implementation probably next year
so what's what's there in jax RS 2 dot
oh and what's what's definitely missing
in jax i responded wanna a synchronous
processing that's what we should help us
in this case and then some other
addition additions our client api so you
don't need to rely on a proprietary
implementation client api's filters and
interceptors i will show a short
demonstration of that later on server
side connect so that not only client can
dictate put media type to retrieve from
the seller but also server could now
kind of decide what what would be sent
over to the client he / media support
and validation support be should be also
covered in the in the new jax-rs api so
now you can probably read this so if you
remember the slide showing the low-level
code now now we can you can read it it's
a lot of annotations in there but you
can imagine that such a code is it's
much easier to to maintain no cannon can
you read it from from the back no maybe
I can
I'm trying to zoom but doesn't doesn't
help I know you have to test me that
business logic is just just maybe three
lines of code otherwise I'm submitting a
new runnable to a vote executor and you
can see in both the the new addition to
the API so there is a possibility to
inject an icing response to the resource
method there is the new ad at suspend
annotation so you inject the response
and then you can do whatever you you you
wish you can just returned from the
method and later on when the work is
done you call the resume method on that
response start instance and the good
thing is that the selector tread is
fried right away when the when the
method is left so this shows how the
synchronous operation signal processing
works in jax-rs to the toll so what did
we get it's apparent that the code is is
much cleaner this is much easier to
write read and maintain performance
impact as I said last year when I wired
George directly into the low-level
solution was almost no penalty now I
have some data from real clients from
production and the penalty is there of
course but it's surprisingly low so
before I show you the numbers let me
switch to NetBeans and show you how i
get them how i get the numbers how i
measured
the server how load it and why I go to
numbers so I'm switching pune means now
okay can you read it now okay thanks so
i am running the application on one note
i will be loading it from another note
and to connect to the server and to get
the live data i am using and beans and
genomics connection so on the server
side i'm using the jammer matrix
utilities that helped me to register the
n beans i need to to measure so here you
can you can see that I i create a new
meter this is just for demonstration
purpose I I wanted to show you at least
two options but they they give you more
so I am with just two lines of code I am
registering a new ambien and it is how
it's being utilized so there is another
resource method i am just measuring the
dates so i call the mark method and the
timer context i get here i used to to
time how long did it take to process all
the business logic so this is a
synchronous operation and i have a
finally block here when i stop the timer
so whatever happens it gets stopped so
this is from the server side and as I
said this utilities will just register
new and beans for me so that I can
connect connect via a jmx remotely and
see the data so let's have a look
I have the service started already so
first title I will show its it's silly
up and running switching to the command
line now and yeah I hope you can read it
so just a bit so here I am I have a
simple simple jax-rs to roto based
client so I'm along check it directly
from maven so now I'm I'm making a
request it's my even stuff and I got
response so the URI I provided its no no
fishing no danger there so the
application is life I try to connect to
it maybe I'm already connected yeah a
vag a konso here standard stuff and
using Oracle jbm so you can see I hope
pretty low CPU usage I haven't loaded
the application yet so it's just served
me one request and that that was it I
can c do excuse me the n beans so this
is the request responses and the j
console allows me to also see see graphs
so here i have a one-minute right so i
can show what what happens there nothing
happens it was just the single request i
have sent so now let's put some load on
it and let's see what what happens so
i'm switching back to the the command
line connecting to another machine and
i'm using the Apache benchmark tool to
stress the server to start the
application so
am launching thousand concurrent clients
and I'm sending this big number of
requests it doesn't matter I just want
to load the application here is the
request data so what about guys are
using now and they didn't mention it
they switch to using google protocol
buffers so this contains the google
protocol buffer data encoding the uri
that i'm asking the fishing information
for an amusing application of its stream
media type so let's let's run it and
let's get back to the j console to see
what what happens there so here you can
see the number of requests is raising
and also if i show here the cpu usage
raised as well it's now slightly below
and eight percent the surveys test so of
course the response time is is bad for
the for the j console as well you should
have an idea so let's see you get here
it's slightly growing okay
I can I can of course shoulder that the
service is still too are running so
let's switch the client again and now I
can maybe try a different view our I
that I I get some more interesting data
here we go you can try the the original
request okay take some time now zero so
this is this is how we migrate so just
to just to wrap wrap up i used the gamma
matrix utilities to register and beans
on the server side and then connected by
our standard jconsole to the to the
server if you wish some more detailed
information you might want to utilize
visualvm which is also part of the reco
JVM distribution so you can you can use
it also to profile the application i got
i got issues with the with the network
so i didn't succeed it in connecting
wire visualvm but it's just due to some
time network witches i believe maybe i
can i can take the opportunity and show
the client as well as it was also added
to the jax-rs so this is what i learned
from even and you can see how are you
you create a client for you in jax-rs to
dot all here i am configuring it i'm
registering the google protocol buffer
providers it's not not part of jersey
but i'm probably going to edit i did
there and most of registering a login
filter now i'm getting the client with
the configuration above and yes protocol
buffer staff i'm preparing the request
data
and here is the jax-rs client call so
you can see how how through and this is
always so the target your eyes is taken
from the command line and I'm requesting
application of that stream and using
HTTP post method so that's probably
eight regarding the demonstration so
getting back to the to the slides okay
so now what we get from the from the
production so this is the graphs I
realized only very lightly that it's not
really comparable but you see the
numbers and really the penalty is not
that bad it's apparent that the low
level solution is much better you cannot
cannot get anything comparable to to it
with a higher level stuff but you can
see that with a low level a solution on
top of grizzly and IO framework I am
serving and it's it's a different
hardware configuration I'm serving 18 a
thousand requests per second or
something something above with Jersey to
do oh and it's not final yet it's a we
didn't release it jax-rs is not final
yet who Jersey is not final yet it's an
early access implementation so with that
implementation on top of grizzly again I
was able to serve above 11,000 requests
per second so as I said I i think that
the numbers are pretty pretty nice so
you definitely need more infrastructure
need more hardware but you don't need
ten times more machines just
twice as much and things might get
improved as we finalize Jersey so this
is the data coming from the coming from
the production from real clients so I
have a another example for you we
realized when measuring that benchmark
went well but when we tied the real data
from real clients the HTTP headers were
screwed up so we didn't get well you
know the numbers we needed so here's a
little example what you can do even with
a higher level solution the jax-rs stood
at all in such a situation so there is a
new concept of prima jink a quest
filters we can register the filter as a
provider and you can tweak the incoming
requests before they are handled by the
resource methods so here it's pretty
simple just for demonstration purpose
you probably don't want such a code to
go into into production but you can see
that the filter has a simple filter
method it takes a container request
context of three and then you can trick
the request so I'm just enforcing the XF
adder is set to application of that
stream but you can you can do much more
the container request context allows you
to to to tweak the request as you wish
so this is just a demonstration how it
works should you need more information
on jax-rs to dot 0 or Jersey to which is
the reference implementation then here
is some details on another talk we have
it mark
which are the coast peclet tomorrow so
we if you have time and you are more
interested this talk will be more about
coding so we will be showing some live
coding demonstrations there so just to
compare to to show you what what what we
get so low level and IO called performs
great but it's really hard to write
takes time to write it it's hard to
maintain as opposed to a jax-rs based
code where the performance is worse it's
not that bad but it's definitely worse
and the code is much easier to write
read maintain so this is the comparison
God and just to conclude so I've seen it
it's always a tide of so I tell you get
a you know great peripheral perform
performance or you you get a cleaner
code you cannot probably get get both so
the goal was to be able to serve a
hundred hundred thousand requests per
second so it's definitely possible it
depends on your application so it's more
it's most likely that you would need to
use some synchronous no non-blocking
operations of course the architecture
design of your application must be
tailored to the use case but you you
don't need to go that low so that the
technology stack doesn't need to be as
well as possible you can you can take
some higher a lot of stuff and save some
time so what we have seen was jax-rs to
the dough the new additions that help
you to develop this kind of applications
and as I said it's always up to you to
this
right what do you want what do you want
to save what you want to to get so that
was it from from a so last year we got a
lot of questions so we wanted to some
more time for for them so now we are
ready to transfer excuse me I can cannot
hear is there any my
you mean jerseys simmer gently jetty
sorry yes actually actually we start for
it okay so if we consider it to use a
gently server yes yes yes because there
is some support for a synchronous even
processing cores oh yes you right and we
started with it Jersey and we had to
abandon it because we couldn't achieve
good results I know about this video
also tried to use these are synchronous
asynchronous extension or synchronous
amount of jealousy but we didn't succeed
in a tree Kincaid to actually boot
result so maybe it was our fault but we
couldn't do it so so we have we had to
abandon stop using that jetty and start
using method you didn't talk to us yet
right JD JD no I with it we haven't used
to committee
okay so the question was how would I
compare if I understood correctly how
would I compare jet a synchronous staff
with with Jack Suarez okay so my
suggestion would be to go with a
standard thing so July is a widely
adopted standard so I think that maybe
they would also implement this welcome
any other questions okay over there
so the question was whether we do some
offline analysis of and I didn't get the
second part you mean you mean in a
buster okay here's a there is a lot of
offline processing in Cassandra I
haven't shown it on the slides but of
course because because as I said before
there is cash the our caches and these
questions must be updated regularly so
in order to in order to update them we
have to use we have to implement some
offline processing on top of Cassandra
so there are a lot of a lot of offline
processing and the results of this
processing goes goes to 22 the caches in
in principle sorry yes yes okay so the
question was whether Jersey handles the
threats itself so yes it does it uses
the threats from the container but it
has some means to to manage the threats
of its own or as you as you seen when
you get the the sink context injected
the response injected you can spawn your
own rights as well I can add it add it
to something because the witcher's is
running on top of grizzly niño
framework and niño has the similar does
it similarly as I showed on on on on
some slides so there is possible worker
pool and it works as I as I showed one
clarification jax-rs is container
independent so you can
put it on top of whatever you've aged
there is an IP I to implement and use
another containers as well so net a
satellite container that will do as well
another question anybody there so if I
understood correctly the question was
whether there is a plan to provide the
mbeans directly within jersey right ok
so the younger matrix provides its own
and beans for jersey van I didn't think
about putting this directly into jersey
yet but there is a an internal IP I that
you can use to and that's what they do
you can you can plug into the resource
method invocation mechanism so you can
instrument the ambience there this way
I'm not sure whether we are going to
provide this or not another question
anybody
okay so the question was where the
performance drop come from the proper in
space we are working on it we are trying
to improve the performance working on it
yeah yeah that it will a lot more stuff
than there is a you don't have just one
one single resource method so you need
to route request the right way you need
to inject all the staff invoke the the
correct resource method you have a sub
locator so some you know dynamic things
also coming into the play so any jax-rs
implementation does a lot more stuff
than just you know sitting on top of the
yeah we are working on it the message is
that we take the the performance
seriously and we are trying to improve
on this I expected much much bigger
difference I expected much bigger
difference so I don't I don't think that
it's that bad another another question
anybody so thank you again for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>