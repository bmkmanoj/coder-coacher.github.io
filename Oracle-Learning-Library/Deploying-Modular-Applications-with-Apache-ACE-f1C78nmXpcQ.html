<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deploying Modular Applications with Apache ACE | Coder Coacher - Coaching Coders</title><meta content="Deploying Modular Applications with Apache ACE - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deploying Modular Applications with Apache ACE</b></h2><h5 class="post__date">2013-01-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/f1C78nmXpcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to this session about deploying
modular applications with patchy ace
I'll start by briefly introducing myself
my name is Marshall of omens I am a
fellow at luminous technologies a Dutch
company and also a member of the apache
software foundation so heavily involved
in open-source development as well
that's my Twitter handle that's the best
I could get and let me quickly also
introduce Apache ace it's a top-level
project at Apache since december two
thousand eleven it's basically a
software distribution framework for osgi
and while we're going to be talking
about it for the next hour or so we
currently have a quite active community
11 committers and the URL at the slide
gives you more information about the
project so let's start with the agenda
i'm first going to talk a little bit
more about modularity in general
explaining why it's important to have it
and why you should use it how you should
use it in java so a little bit about
osgi they're not too much then i'm going
to be talking about deployment and
deployment complexity because with
modularity comes a lot of complexity at
deployment time so i'm going to be
explaining how to deal with that and
that's of course where our patch ea's
comes in so that's what I'm be talking
about most of the time and then I'll
discuss a little bit about different
target systems that you can use
obviously osgi containers but there's
some other stuff as well and finally
we'll move all of that into the cloud
I'll explain how to do that with ace how
to configure that etc and talk a little
bit about future direction stuff that
we're still working on that we're trying
to figure out and get implemented so
starting with modularity
modularity itself is nothing new we've
seen it in IT we've seen it in other
disciplines it is a good way to build
more complex systems out of smaller more
manageable building blocks and in fact
in IT it's nothing new we've been doing
modularity at least in the designs for a
long time already if you look at the
average architecture document this will
always feature some kind of layering and
within these layers you'll have
different modules with different
responsibilities but for a long time
that's also where modularity ended in
Java because when you started
implementing your application you would
throw everything together on this great
big class path and it would all be one
big bowl of classes that could interact
in all kinds of ways that weren't really
specified in the architecture document
so modularity is great that's probably
also a good idea to try and enforce it a
little bit more at the runtime and
that's where OSGi comes in and I'll
explain a little bit about that later so
why do modularity well one of the big
advantages of building a system in a
modular way is that it makes your whole
application more maintainable you can
work on individual modules evolve them
over time update them without actually
having to worry about all the other
parts of the system your modules should
be fairly self-contained might have some
api's through the outside world but
those are always well defined so it's
relatively easy to evolve a module maybe
to re-implement it completely if there's
some new technology coming up so that
that's where modularity gives you a lot
of benefits in terms of maintaining an
application and I guess most of you have
experienced this that's after time if
you don't design your application well
enough it becomes harder and harder to
change things
up to the point where you maybe even
consider to just rewrite the whole thing
because everything you change makes the
application fall over or become so
difficult to do that you rather not do
it and that's really a bad reason for
redesigning or re-start you're starting
from scratch you should never reach that
point ideally another reason for being
modular is adapting to change and
especially again on these longer running
projects there's always going to be
changes at least in the Netherlands
customers don't always know upfront
exactly what they want they might do and
they might give you a list of features
and requirements but those are going to
change and that's logical because the
world around us changes so these
requirements will evolve over time as
well and therefore we need to deal with
those changes and again modularity helps
you deal with that you can more easily
replace one or a couple of modules in
case your requirements completely change
and there's less risk of having to start
over in such scenarios so that's that's
great of well as well and another often
mentioned advantage of modularity is
what i call the quest for reuse and
going back in time a little bit reuse
has been around for well i guess ever
since somebody invented the clipboard to
start copy pasting stuff and as you can
see from the picture you can do a lot of
nice things from just copying and
pasting stuff and reassembling things in
in some new and interesting ways but
there's some obvious downsides here with
creating the copies you're creating a
maintenance nightmare because every bug
fix you make to one copy doesn't
automatically propagate through the
other copies and it gets worth it if you
start changing those those copies a
little bit as well so that might not be
ideal
also usually in this scenario you don't
have clean api's sure you just copying a
piece of code and reusing it in a
context that maybe it wasn't designed
for adult so quite some time ago we
invented objects an object-oriented was
going to be the answer to all problems
we had concerning reuse just now we had
these nice objects they have an API they
have an implementation that you can hide
from the outside world so surely once we
all start programming in an
object-oriented way things would be
great and we would have reuse of a lot
of components well that didn't really
happen objects have been around for
maybe 30 years now or something and it's
not always easy to reuse them partly
that's because an object never exists by
itself you might have a whole hierarchy
of inheritance so you cannot just copy
one class you have to copy the whole
hierarchy even if you have this sign on
your wall in the company that says
inheritance is evil you should use
composition instead you still need all
those composites to make a class work
outside of its original context plus
maybe a class is also a little bit too
small as a unit of resource maybe you
want something a little bit bigger than
that and that's where more component or
module based systems come in and I'm a
big car fan so I always use the example
of the formula one where they have
perfected this this modular approach
they can replace parts of of a Formula
One car pretty quickly they have nice
and convenient interfaces and they can
work on these individual components and
keep updating them and improving them
and then sticking them on the car and
see if they work and these are typically
a little bit bigger compared to just the
the parts that you saw in the previous
photo which was just the gearbox
lots of axles and stuff so if we want to
use these kinds of components or modules
in Java at the moment the best sort of
de facto standard framework to use is
osgi and going to explain an osgi really
quickly just going to ask who's already
familiar with those GI before almost
everybody I'll do this fairly quickly so
oh she is a way to create modules in
Java and in Java we already have a way
to package stuff together which is the
jar file and in a jar file we can stick
different files classes other artifacts
and a jar file always has a manifest and
this manifest is used by osgi to put
some extra metadata in and to define
what this module is all about so that
starts with a symbolic name and version
to identify the module and next in this
example is a bundle class path because
in osgi each module or each bundle is
completely isolated from the outside
world so it also has its own class path
and here you see we simply include
everything that's directly stored in the
jar file and we have this one jar that's
embedded inside the jar that's also on
the classpath next up is the bundle
activator and that's sort of the main
method for oci a bundle activator has a
start and a stop method and those are
the entry points that get invoked when
your bundle gets started and gets
stopped you get a reference to the
bundle context which is sort of your API
with the osgi framework so you can talk
to it and here is where you can do your
stuff and you also just define the
bundle activator in the manifest osgi
will instantiate it and invoke these
methods
like I said if you don't do anything all
the classes inside this jar file are
stay inside the jar which is not always
convenient because there are definitely
some things you want to share with the
outside world for example a service
interface that you might implement so
what you can do is state in the manifest
which packages you want to export and so
you can only export at the package level
not the individual class or you need to
take into account that restriction when
designing your code but usually that's
not a big issue and you can as you can
see i'm not sure if everybody can see it
in the back but you can also assign a
version to a package and that's
important because osgi supports
versioning supports updating and can
even run two different versions of a
package side-by-side so exporting a
package means that it becomes available
for other bundles to use and I've drawn
that below in the slide some kind of
shared space where all these packages
live and a resolver that tries to hook
up these packages in case other bundles
needed because that's the other side you
can not only export something you can
also import it and that's adds packages
to basically the classpath of this
bundle they become visible somebody else
needs to export that package obviously
if there's nobody else that can do that
the OSGi runtime will give you an error
message and your bundle will not start
so you get information about that but
normally the resolver will just silently
hook you up with somebody exporting the
right version of this package and you
can just start using it that way so
that's osgi at the sort of class loader
level and then there's one mechanism on
top which is the service registry and
that's really the mechanism for bundles
to communicate with each other
so they can share an interface and they
can publish a service in the service
registry and other bundles can look up
that surface and start invoking methods
on it and in osgi invoking methods on
services is really quick it's not like
there's some marshaling going on behind
the scenes or anything they're basically
just playing java method calls so you
don't have to worry about performance
limitations or anything and it's okay to
have lots of services in your osgi
container one final big advantage of
osgi is that all these bundles that are
running side by side can be updated
installed and installed without
affecting the rest of the bundles so you
get a dynamic environment and where you
can run an update bundles without
stopping the whole world basically so
that's osgi in a nutshell on to the
problem that sort of evolves from
modular design and that's taming all the
complexity that comes with deployment
and just to define what i mean by
deployment but we can have many
different modules many different
artifacts and usually you stick them in
some kind of repository and then there
are lots of different ways you can
combine these artifacts into
applications and assign them to
different targets and if you only have a
couple of artifacts and a couple of
targets that's probably still doable by
hand once you get hundreds of artifacts
and hundreds of targets you probably
don't want to maintain that by hand
anymore so to sort of resolve that
problem of mapping all these artifacts
on two different targets and to also do
that over time because what is defined
today might change tomorrow so you also
want to be able to evolve that and
remember over time how this mapping was
so you can always look back at the
history of a target and see okay this
was first installed and then that and
that etc and keeping track of all of
that is basically what Apache ace does
for you so it helps you make this
problem more manageable by automating it
so why would you want to do it well you
want to automate it because it's not
longer doable by hand it also gives you
at runtime a lot of insight into who
uses what so if a customer calls and has
a problem you can instantly see okay he
has these targets and these artifacts
are actually running now on these
targets so that might give you a clue as
to what's going on with this system the
history also helps you can always look
back over time what has changed whether
perhaps any changes that that broke
something etc so that's that's always
interesting to to be able to see that
and also not unimportant by automating
this and consistently automating it's
during development during testing and
during production you get a single way
of deploying everything from your IDE
basically or from your continuous
integration server all the way up to
production so you don't introduce new
possible ways of malfunctioning just
because you're using a different
mechanism during development than during
production and once you have such a
system in place it's also interesting
because it opens up the door for a
couple of possible extensions and I'll
get into those a little bit a little bit
later I first want to start with just a
generic topology and this shouldn't be
taken too literal there's many different
ways you can deploy ace but this is just
a generic picture we're in the center
you have a provisioning server that's
sort of the heart of the system that's
what all this mapping between artifacts
and targets resides we have a component
repository we
we externalized because a lot of people
might already have such a ripple story
might be a maven repository it might be
an osgi bundle repository or something
like that so we want to be able to to
use those on the right we have all kinds
of different targets and targets talk to
the server through a management agent a
management agent is also just in the OC
i bundle and it is responsible for
talking to the server checking if there
are updates for the system and actually
deploying those updates and all the way
on the left we have a client which
nowadays is usually just a web browser
and you can use that to to interact with
the server to configure everything etc
so zooming in a little bit more on this
provisioning server there are three
major subsystems dependency management
deployment and feedback I'll go over
each of them in in order and we'll start
with dependency management and what's
that that's basically two things one a
way to organize all these different
artifacts that we have and typically a
larger osgi application might consist of
hundreds of artifacts so you really get
a lot of them and just looking at a list
of them doesn't really tell you that
much anymore so we need some kind of
mechanism to group that and the second
issue is done how to map these on to the
targets and for organizing artifacts we
have a system for grouping them actually
two levels of grouping artifacts are
grouped first into features and features
again in two distributions and I always
make the analogy of ikea here because
IKEA makes modular furniture and they
don't sell the individual bolts and
planks and stuff but they configure them
into chairs and cupboards and stuff and
give them nice names so customers can
order a fr or a packs
cupboard or something like that and
that's what we're trying to do here as
well because these individual artifacts
they're so technical if you're not a
developer you probably don't know what
to do with them but once you start
grouping them into functional building
blocks the whole thing becomes way more
manageable so that's that's basically
what we're trying to do when doing
dependency management a year in osgi and
we actually store that data into a store
repository and there you have the
mapping between artifacts features and
distributions then the next step mapping
them onto the targets so we now we have
distributions which can consist of many
different artifacts and we somehow need
to map them onto targets why did we
split this off from the previous slide
because you could also say why not stick
it in there with the rest and that's
because a lot of the time this data
might already be available in an
external system you might have some kind
of CRM system which already tells you
okay this customer bought these
different versions of the product or
something like that so we decided to
keep that in a separate repository as
well so you can more easily replace it
if you need to and here we keep the
mapping of distributions and targets and
again this is a many-to-many mapping so
you can install multiple distributions
on the single target and vice versa and
to manage all that I already explained
we have a web interface and I always
make a disclaimer that this one was
designed by developers so it's not
really nice to look at we can probably
do a better job on this and at the same
time we've had many discussions with
people about what kind of user interface
do they want on top of ace and everybody
wants something different so it's kind
of hard for us to make one interface
that everybody's happy with so what we
did we added a REST API as well so you
can programmatically talk to it and we
even have a Java API
case you want to talk directly from osgi
components to this server so that way
you can make your own user interface if
you think you need something else so
that concludes dependency management
next up is deployment and deployment is
really all about getting the right
artifacts to the right targets it
basically gets its information from
everything we did in the dependency
management section it just sort of
organizes this information in a
different way a way that is really
suited to creating a scalable system
that allows you to quickly distribute to
many different targets at the same time
server-side it consists of a deployment
repository and on the target we have the
management agent which actually
initiates the communication with this
server part and the deployment
repository basically only keeps a
mapping now between targets and
artifacts so all the features and
distributions that we had to make this
more comprehensible for humans we throw
them away again because machines can
handle big numbers of artifacts they
don't need the levels in between and
just create a straight mapping from that
and that actually gives you a repository
that looks somewhat like this we have
different targets in there in this
example to and for each target we keep
different versions of the software so
every time in the dependency management
section you change something ace will
calculate for you okay what does this
change mean which targets actually are
affected by this change so which targets
need to be updated and that means that
well not every change will affect all
targets so you will get different
versions of each target every time
something changes a new version for that
target will be created a list of
artifacts will be made that belong to
this version and that's what will be
stored in this repository
and well as you can guess the management
agent on the other side communicates
with this repository and we can break
the management agent down in a couple of
individual parts there's a schedule it
in there we have a cache for caching all
the versions so we can more quickly roll
back to all the versions don't need to
go over the network there's an audit
loci we'll talk about that a little bit
later and we've abstracted away some
mechanisms that most people will want to
change such as for example
identification which is a simple API
that determines how to generate a unique
identification for a target system and
depending on what the target system is
if it's some kind of server or maybe an
embedded device you might have a
different way of creating that unique
identification might be a MAC address of
a network in the face or something in
the device or whatever so this
management agent uses a concept called
deployment packages and they're actually
part of an osgi standard called
deployment admin and deployment packages
are basically a way to package up all
the changes or all the artifacts that
you need to install a version of the
software on a target and create create
one big jar file out of them and this
jar file will either contain everything
or in case of a fix or Delta package you
can also send a jar file that's just the
Delta between two different versions so
you don't have to send everything every
time a nice feature is that any
installations or updates are
transactional so if somewhere during the
installation of your bundle something
goes wrong it will automatically roll
back all the changes it did and get you
back to the last known working version
which well with hundreds of different
bundles can be rather difficult to do if
you have to do all of that by hand and
probably you don't want to end up with
half a new version
as well so that's a good feature to have
we can sign these packages to make them
more secure make sure nobody's tampered
with them which in a lot of environments
is also very interesting and maybe the
coolest feature is that we can create
resource processors and resource
processors allow us to work with new
types of artifacts and install them on a
target artifacts that we previously
didn't think about and there you can
think about maybe a database schema for
a database that you're using on this
target system or maybe a Debian package
that you want to install on the
operating system that this target is
running on and the resource process is
just a Java bundle it is some code that
will be shipped along with this artifact
and you can use these codes to on the
target install this artifact so it might
talk to the database and make all the
schema changes for you and all of this
again happens in this transaction so
something along the way it goes wrong
you can roll everything back and go back
to the previous version of course you
have to write your database code in such
a way that you can actually do that so
not only should it make schema changes
it should also be able to roll them back
again but now that's done your problem
to solve but at least you have a
mechanism for for making that work and
the OC i spec actually has a example of
a resource processor called auto config
which is used to ship configuration data
which is something almost every
application needs so that's good to have
so that sort of concludes the first two
parts of the server and there's three
repositories involve the store the
license and the deployment repository
and basically if you make a change to
either the store or license repository
that has implications on the deployment
repository so ace will sort of calculate
that for you and create a new version of
that deployment repository
that leaves us with one last bit and
that's feedback and arguably that's
maybe the most important one because
feedback allows you to as the name says
get feedback about what happens on a
target because it's nice to ship all
kinds of new software and other
artifacts to it but if you're not sure
that this actually works then the system
is not really that useful so what we've
done there is on the actual targets we
keep what we call an audit log which is
a log file that records every life cycle
change that occurs on a target so
obviously this is every time something
gets it gets added or gets updated
through the management agent but we also
log stuff like okay now the user has
switched off the system now it's coming
back on so all those changes are
recorded as well and not only record do
we record them we also send them back to
the server so we can process them
offline because targets will not always
be on 24 7 depending on what type of
device they are and most certainly they
will not always be reachable from
whatever machine you're using to to
monitor them hopefully they can contact
the provisioning server but most of the
time not the other way around so keeping
these logs on the server allows us to do
all kinds of interesting processing and
in fact we've already seen a lot of
people who said well this is such a
useful feature can I add my own
application logging to this as well so I
can get some application logs on my
server and analyze them there so we
already built a system in a way that you
can easily extend it and add your own
logs as well so that's ace the server
part in a nutshell now I promised to
also talk a little bit about the
different targets the different
containers that we can deploy to
and the most obvious ones are actually
just plain osgi implementations there's
three major open-source ones Apache
Felix I'm a committer so I'm placing
that at the top and this Eclipse Equinox
Eclipse has started to use osgi ever
since version 3 was released before that
they had their own proprietary plug in
mechanism but that's ancient history by
now and there's a third one that's
called knopfler fish or however you
pronounce that that's always a little
bit trickier there's lots of other ones
out there these are the three major open
source one there's commercial ones as
well and they're the smaller open source
versions also so naturally these
frameworks are are good targets for for
Ace and the osgi specification really is
good enough that it doesn't matter which
framework you choose your code runs on
any of them what's also interesting is
that you can deploy directly to
application servers and i'm naming
glassfish as an example here because
there are already other application
service such as jboss and well old old
major ones are starting to support osgi
are in various stages of that but
glassfish is a good example because they
really started from scratch they started
on top of Apache Felix and they built
the whole application server as a set of
modules on top of osgi that's
interesting because that no doubt sped
up the development of glassfish itself
it's also interesting because maybe you
can then just deploy the parts of
glassfish that you really need for your
application maybe it's not really java
ee compatible then anymore because then
it needs certain things to always be
available but that might not be that
important for you and maybe the other
more
interesting part is it also allows you
to directly deploy osgi modules into the
application server so you can build your
own applications in a modular way and
just like with the plane osgi containers
all we really need to do is just get
this management agent stick it into
glassfish and configure it so it can
talk to the ACE server and we can use
that to actually get new code onto the
application server out of the box we
even provide some code that helps you
with that so we have a component that
can easily launch version of glassfish
get the management agent inside and help
you set up that system due to some
licensing restrictions glassfish has an
incompatible license with some Apache
stuff we cannot actually ship it with a
copy of glassfish so you have to sort of
get the zip file yourself and put it
next to the code we have but then it
will work so that's really interesting
and a good way for future enterprise
applications to become more modular and
to make deployments easier another
option and this is way out there on a
java conference so i won't talk about it
for too long but there's also an Apache
project called seelix which basically is
a modular runtime for C code and while
there's less and less C code being used
in some areas there's still some legacy
C code available and you might also want
to modularize that and you might also
want to be able to update update that in
a more dynamic way so seelix make this
makes this more modular and also sort of
interoperates with apache ace and
supports actually these deployment
packages so with ace you can also ship
see bundles or modules on to a system
and updated in that way obviously AC
runtime probably isn't as dynamic as a
Java one so you probably end up have
to restart the application after a
change that you make depends a little
bit on the change some stuff they can
add on the fly such as new dll's but
some stuff is is harder to do in a
dynamic way but they they go a long way
and another one maybe also a little bit
outside of the scope here is deploying
on Android and just as a quick overview
and draw it uses Java the language
probably already in trouble for saying
that but it does seem to work and they
run on a different virtual machine
called dalvik which has slightly
different pipe code and actually in
Android you have many different
instances of that virtual machine one
for each application on the other hand
osgi allows you to run different
applications side by side in the same
virtual machine well each has its
advantages osgi has an advantage that if
you get communication between
applications due to the fact that
they're all in the same virtual machine
that communication is going to be very
quick it's just method calls you also
get more reuse if you have libraries
that are shared by multiple applications
they're running in the same virtual
machine again so you can easily reuse
that and don't have to have multiple
copies lying around on the other hand
dalvik has the great advantage that if
one application crashes it doesn't bring
the whole virtual machine down because
this a single virtual machine for every
application so as with a lot of things
in life there's different trade-offs
here so you might end up with a
combination of the two it's definitely
interesting that if you develop all your
applications in a modular way that even
for Android you can deploy all these
modules together as a single application
on such a platform
so after a very long introduction that
finally brings us to the cloud aspect of
this talk and let's take a look at what
we need to do to actually run all this
stuff in the cloud and first I want to
go back to the topology slide that I
showed earlier and apart from adding the
the clouds that everybody has on their
cloud slides there's one extra part
which is the node manager and we can
just run ace in the cloud that's not any
different from running it on a local
system we can get the component
repository in the clouds and then the
next step is okay now I actually want to
run targets in the cloud so we need to
do something extra to be able to create
bootstrap those new targets and actually
run them and that's what we call the
node manager and zooming in to that for
a little while the node manager is a
component that is responsible for
bootstrapping the actual note so the
compute node that runs in the cloud it
will bootstrap java it will boot strap
the oci framework install a management
agent and actually launch that and then
this management agent will be configured
all ready to go back to ace to get the
artifacts if you configured for it and
those will be shipped to the system and
typically on Amazon we can start a note
from scratch in about two minutes or so
so that's fairly okay another thing to
note manager does is it measures all
kinds of performance data and I'll get
back to that in the slider to but that
allows us to to monitor how busy a node
is and maybe do something if it becomes
too busy so is configure is out of the
box already configured to be used in a
cloud under the covers we actually use a
very popular library
II called Jay cloud which is kind of an
abstraction layer and what we did is we
use that and we implemented that for now
for Amazon it's quite easy using Jay
clouds to add support for other clouds
as well that's just something we haven't
gotten to yet and what you need to do in
ace is there's a sample configuration
file you need to fill that out and add
some real values to that and once you've
done that you can simply deploy ace in a
cloud and start working with it so what
do you need to do you need to tell it
where the a server can actually be
reached so that's a URL of where you
actually installed ace it can be in the
cloud it doesn't have to be you can run
ace outside of the cloud and still have
nodes running in the cloud an Amazon you
need to tell amazon what machine ID you
want to use and what location so you can
configure that here as well and most
important something hooked up to your
credit card you need to enter your
access key and password so you can talk
to the Amazon api's and actually start
new notes then we have a type prefix
which is just a convenience feature
because in the amazon web console you
see a name for every note that gets
created and if you use that same amazon
account for other things than just
starting notes with ace you can use this
prefix it will be stuck on in front of
every note that ace makes so you can
easily identify those nodes and then we
have a couple of things that configure
and run the whole bootstrapping
mechanism in this case we have a machine
image that didn't include an Oracle JVM
by default so we have a tiny script that
will fetch that and install it we've
opened up a few extra ports because by
default all the ports are closed or you
can open up a few extra ones
if you need a communication from the
outside and you can configure things as
run this as root or not and even fetch
some extra files if you need them during
the bootstrap process so that's all you
need to do and then you're ready to run
ace in the cloud and how does that
actually work you go to the web
interface and the web interface contains
a column where you can see different
targets that you have configured and
here you can just create a new target
double click on it and you'll get a
dialog that looks a little bit like this
I think we already updated it is a
little bit old screen shot but it shows
the basics it shows you that you can
simply hit the start button and that
will actually start the communication
with Amazon start up a note do the whole
bootstrap process and get this node up
and running so that's basically all you
need to do just create a new target hit
start wait for maybe two minutes and you
know it is up and running so that's
really easy and cool to do then I
already told you there's something else
running as part of this node manager and
that's a monitoring framework and that's
actually extensible so you can add your
own probes to it and just for for a demo
we added some some simple ones such as
CPU usage disk usage network traffic and
memory usage and all the information
that's aggregated by these probes is
sent again back to the server so it can
be analyzed there and we actually have
some simple graphing options here you
can see I think nine seconds of network
traffic so it's not really that
interesting but you can plot for longer
periods as well and this is important
because this is usually information that
you can use if you want to do your own
accounting based on how much of an
application your customer
are using you might use it as the basis
for a clustering solution detecting that
a node gets very busy and maybe creating
another node and stick a load balancer
in front of that so that's really what
the monitoring part of ace is is for and
finally just to show you a little bit
about how we do cloud support under the
covers we have a monitoring or a node
launch API and this really is the API
that you need to implement if you want
to add support for a different type of
cloud or maybe your own private cloud or
whatever it's fairly simple you need to
be able to start and stop notes you can
create a default configuration which is
some kind of node launcher configuration
interface there you can add your cloud
specific settings and if you've done
that you can just start and stop nodes
so this should be too hard to implement
for your own cloud and especially if you
use J clouds to implement all of this
it's it's it's not that hard to do so
that's really how we can run ace in the
cloud and I want to finish off with some
future directions and just to give you
an idea of what we're working on right
now and probably the biggest one at the
moment is support for dynamic clustering
and that can mean many things and we're
working on many things in that area on
the wall hand for example osgi has a
specification called remote services
that allows you to distribute
applications over multiple nodes get
sort of a federated service registry and
do remote invocations so that's one part
of this solution we're currently also
working on supporting different load
balancers so we can stick a load
balancer in front of
application have that communicate with
some kind of cluster manager and send
requests to different nodes that are
running in behind that and make all of
that in such a way that it's really
dynamic that we can when load is high
add extra nodes and when it's low again
scale back and actually in a session
tomorrow I'll add a short plug to that
in a few minutes we have a real world
use case of how we use that already
today so it's not all future but it's
definitely not done yet so it's
something we're working on at the moment
and trying to to improve to other things
we want to do is to integrate better
with on the one hand a project called
and Otto this is an open source project
that is focused on creating modular
components for cloud applications so it
contains a lot of components that you
use in typical cloud applications
naturally it supports a party is already
but we want to integrate with that a
little bit more it also allows you to or
use all kinds of no sequel solutions and
run them in osgi at rest api is in a
really convenient and easy way we have
Enterprise Search solutions and there's
lots of components that were working on
and making sure that we have a
comprehensive stack for building cloud
applications and the other project is B
and D tools this is something completely
different this is actually an IDE plugin
to make working with osgi a lot easier
and this is currently available for
Eclipse only so one of the things we're
hoping is that somebody ports this
environment to other IDEs as well and
what we're trying to do is integrate
with this development environment so
that from your IDE you can directly
deploy stuff onto cloud notes just by
hitting safe and having ace in the
background pick up all the artifacts
that you created uploading them to the
provisioning server
then maybe spreading them out to the
different nodes obviously that wouldn't
be production notes but for quick
testing it would be very convenient if
you could publish such changes to do
your testing service or maybe your
development service even without having
to do extra steps yourself so that
that's still some work to be done there
we have all the rest api is in place to
make that work but but yeah thus there's
still stuff left to do and as promised
there's a nice session tomorrow which i
will be giving together with my
colleague Paul Becker this is a real
world use case about using osgi in a
cloud environment and we've actually
used it to build a system for dutch
schools that creates a personalized
learning environment so that's a really
cool project and it shows off some of
the stuff we can already do with dynamic
clustering etc and that's all based on
apache ace and the indata project so if
you want to know more more from real
world use cases from the trenches so to
speak visit that session okay that's
actually it for me so I think I have a
couple of minutes left for questions so
yeah yeah yeah you can do that as well
yeah so that that would be your other
option use SSH or in oci we also have a
thing called web console which is a
web-based way to create interaction with
the osgi framework and really look at
individual bundles and start and stop
them through a Web API whether you want
to expose all of that to your customers
that's up to you but that's definitely
also a way to do it yeah yeah in the
back
really
yes it's something we I didn't show but
actually when you use the web interface
of ace you need to log into it and you
can have different roles and based on
your role their stuff you can and cannot
do so that's that's one part of the
solution we have for that and also in a
lot of organizations you see that you
have different provisioning servers for
development for production and we also
have ways to sort of promote artifacts
from one environment to the other so
that way you don't get in each other's
ways that completely isolated if you
want that and you're just transferring
stuff to production in a very control
way so that that's up to you there's
different ways to set it up yeah a lots
of different so yeah I'm not I don't
know if it will coexist it's definitely
something we want to interoperate with
because the carafe features already
define groupings of artifacts just like
we can do an a so for our first version
of support hopefully will be to be able
to read these craft features and
directly use them in ace that that's one
thing and I think from dad as many other
interesting stuff we could do actually I
filed a bug report nkf a long time a bit
go because carafe features don't support
the mechanism of being updated right now
and that's something we really need for
ace to work carafe can just uninstall
and reinstall new stuff and there's a
there's a technical difference in osgi
compared to just updating a bundle so
there's some work to figure out there
but we're definitely talking to that
community is well trying to make them
work together yep
jenkins they can provide features that's
not yet available a sort of standard
integration bundle for Jenkins for stuff
like bamboo for the integration surface
we have the rest api so creating a sort
of a small script for that would be
fairly straightforward but we haven't
included that yet in ace would be it
would be a nice contribution to have
that yeah so if you want to help us out
with that please do yeah yeah that was
actually one of the resource processes
that I briefly mentioned was for
configuration files so that's already
included in ace by default so we can
provision bundles and configuration
files and you can extend that mechanism
yourself yeah
and we currently don't have an
integration for taiko but in the end
taiko is also just a development
environment to create osgi applications
so i think based on the rest api is that
we have writing section integration
would not be that hard if you're using
taiko and also maybe Nexus as a
repository no then you could have used
nexus support for the oci bundle
repository and use that directly in ace
but it's also fairly straightforward to
sort of promote bundles coming out of
taiko and stick them in the repository
for ace but it's not done yet that's
another area where we could use some
help yeah that yeah that we've looked
into that but haven't done it yet so
that's one of the other repositories we
would love to to add support for ya so
not on yet but shouldn't be too hard as
well yeah yeah
I think at the moment the current
biggest implementation is a couple of
thousand of targets and those are
actually embedded devices moving around
inside cars so they are all an offline
all the time we've done experiments to
prove that a scales way beyond thousands
of systems but that's currently the
largest deployment that I know of in the
field I mean not everybody tells me what
they're doing with ace but there yeah
that's that's what I know yeah okay then
that's it thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>